[
  {
    "discussion_id": "2177647483",
    "pr_number": 6929,
    "pr_file": "packages/openai/src/responses/openai-responses-language-model.test.ts",
    "created_at": "2025-07-01T13:44:29+00:00",
    "commented_code": "});\n \n   describe('doStream', () => {\n+    const prepareReasoningStreamResponse = (",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2177647483",
        "repo_full_name": "vercel/ai",
        "pr_number": 6929,
        "pr_file": "packages/openai/src/responses/openai-responses-language-model.test.ts",
        "discussion_id": "2177647483",
        "commented_code": "@@ -1175,6 +1428,68 @@ describe('OpenAIResponsesLanguageModel', () => {\n   });\n \n   describe('doStream', () => {\n+    const prepareReasoningStreamResponse = (",
        "comment_created_at": "2025-07-01T13:44:29+00:00",
        "comment_author": "lgrammel",
        "comment_body": "instead of flags, just set up custom prepare methods or if it's a single test define the test input in the test\r\n\r\nprefer less magic / thinking in tests, often it is very helpful to be able to look at the raw input without any indirections / logic",
        "pr_file_module": null
      },
      {
        "comment_id": "2177663551",
        "repo_full_name": "vercel/ai",
        "pr_number": 6929,
        "pr_file": "packages/openai/src/responses/openai-responses-language-model.test.ts",
        "discussion_id": "2177647483",
        "commented_code": "@@ -1175,6 +1428,68 @@ describe('OpenAIResponsesLanguageModel', () => {\n   });\n \n   describe('doStream', () => {\n+    const prepareReasoningStreamResponse = (",
        "comment_created_at": "2025-07-01T13:51:29+00:00",
        "comment_author": "jonaslalin",
        "comment_body": "Sure, I have now moved it to each individual test instead.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2141814041",
    "pr_number": 6720,
    "pr_file": "packages/ai/core/generate-text/stream-text.test.ts",
    "created_at": "2025-06-12T06:26:47+00:00",
    "commented_code": "expect(chunks.filter(chunk => chunk.type === 'raw')).toHaveLength(0);\n     });\n+\n+    it('should call onChunk with raw chunks when includeRawChunks is enabled', async () => {\n+      const onChunkCalls: Array<{ type: string; rawValue?: unknown }> = [];\n+\n+      const mockRawChunks = [\n+        { type: 'stream-start', data: 'start' },\n+        { type: 'response-metadata', id: 'test-id', modelId: 'test-model' },\n+        { type: 'text-delta', content: 'Hello' },\n+        { type: 'text-delta', content: ', world!' },\n+        { type: 'finish', reason: 'stop' },\n+      ];\n+\n+      const modelWithRawChunks = new MockLanguageModelV2({\n+        doStream: async options => {\n+          const chunks = [\n+            { type: 'stream-start' as const, warnings: [] },\n+            ...(options.includeRawChunks\n+              ? mockRawChunks.map(rawChunk => ({\n+                  type: 'raw' as const,\n+                  rawValue: rawChunk,\n+                }))\n+              : []),",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2141814041",
        "repo_full_name": "vercel/ai",
        "pr_number": 6720,
        "pr_file": "packages/ai/core/generate-text/stream-text.test.ts",
        "discussion_id": "2141814041",
        "commented_code": "@@ -6632,5 +6634,94 @@ describe('streamText', () => {\n \n       expect(chunks.filter(chunk => chunk.type === 'raw')).toHaveLength(0);\n     });\n+\n+    it('should call onChunk with raw chunks when includeRawChunks is enabled', async () => {\n+      const onChunkCalls: Array<{ type: string; rawValue?: unknown }> = [];\n+\n+      const mockRawChunks = [\n+        { type: 'stream-start', data: 'start' },\n+        { type: 'response-metadata', id: 'test-id', modelId: 'test-model' },\n+        { type: 'text-delta', content: 'Hello' },\n+        { type: 'text-delta', content: ', world!' },\n+        { type: 'finish', reason: 'stop' },\n+      ];\n+\n+      const modelWithRawChunks = new MockLanguageModelV2({\n+        doStream: async options => {\n+          const chunks = [\n+            { type: 'stream-start' as const, warnings: [] },\n+            ...(options.includeRawChunks\n+              ? mockRawChunks.map(rawChunk => ({\n+                  type: 'raw' as const,\n+                  rawValue: rawChunk,\n+                }))\n+              : []),",
        "comment_created_at": "2025-06-12T06:26:47+00:00",
        "comment_author": "lgrammel",
        "comment_body": "just inline the parts. unit tests should be as straightforward as possible. if you want to check that includeRawChunks is passed correctly, add a separate test for just that.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2128928940",
    "pr_number": 6643,
    "pr_file": "packages/google/src/google-generative-ai-language-model.test.ts",
    "created_at": "2025-06-05T13:57:47+00:00",
    "commented_code": "prompt: TEST_PROMPT,\n     });\n \n-    expect(content).toMatchInlineSnapshot(`\n-      [\n-        {\n-          \"text\": \"Hello, World!\",\n-          \"type\": \"text\",\n-        },\n-      ]\n+    const text = content\n+      .filter(\n+        (item): item is { type: 'text'; text: string } =>\n+          item.type === 'text' && (item as any).thought !== true,\n+      )\n+      .map(item => item.text)\n+      .join('');\n+    const reasoning = content\n+      .filter(\n+        (item): item is { type: 'text'; text: string; thought?: boolean } =>\n+          item.type === 'text' && (item as any).thought === true,\n+      )\n+      .map(item => ({ type: 'text', text: item.text }));\n+\n+    expect(text).toMatchInlineSnapshot(`\n+      \"Hello, World!\"\n     `);\n+    expect(reasoning).toStrictEqual([]);",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2128928940",
        "repo_full_name": "vercel/ai",
        "pr_number": 6643,
        "pr_file": "packages/google/src/google-generative-ai-language-model.test.ts",
        "discussion_id": "2128928940",
        "commented_code": "@@ -223,14 +223,24 @@ describe('doGenerate', () => {\n       prompt: TEST_PROMPT,\n     });\n \n-    expect(content).toMatchInlineSnapshot(`\n-      [\n-        {\n-          \"text\": \"Hello, World!\",\n-          \"type\": \"text\",\n-        },\n-      ]\n+    const text = content\n+      .filter(\n+        (item): item is { type: 'text'; text: string } =>\n+          item.type === 'text' && (item as any).thought !== true,\n+      )\n+      .map(item => item.text)\n+      .join('');\n+    const reasoning = content\n+      .filter(\n+        (item): item is { type: 'text'; text: string; thought?: boolean } =>\n+          item.type === 'text' && (item as any).thought === true,\n+      )\n+      .map(item => ({ type: 'text', text: item.text }));\n+\n+    expect(text).toMatchInlineSnapshot(`\n+      \"Hello, World!\"\n     `);\n+    expect(reasoning).toStrictEqual([]);",
        "comment_created_at": "2025-06-05T13:57:47+00:00",
        "comment_author": "lgrammel",
        "comment_body": "an inline snapshot on content is prob easier, also checks order. in general such logic in tests is usually a code smell",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2063860038",
    "pr_number": 5770,
    "pr_file": "packages/ai/core/util/chat-store.test.ts",
    "created_at": "2025-04-28T15:00:00+00:00",
    "commented_code": "+import { beforeEach, describe, expect, it, vi } from 'vitest';\n+import type { UIMessage } from '../types';\n+import { type ChatState, ChatStore } from './chat-store';\n+\n+const initStore = (chats?: Record<string, Pick<ChatState, 'messages'>>) => {\n+  const store = new ChatStore({ chats });\n+  return store;\n+};",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2063860038",
        "repo_full_name": "vercel/ai",
        "pr_number": 5770,
        "pr_file": "packages/ai/core/util/chat-store.test.ts",
        "discussion_id": "2063860038",
        "commented_code": "@@ -0,0 +1,1090 @@\n+import { beforeEach, describe, expect, it, vi } from 'vitest';\n+import type { UIMessage } from '../types';\n+import { type ChatState, ChatStore } from './chat-store';\n+\n+const initStore = (chats?: Record<string, Pick<ChatState, 'messages'>>) => {\n+  const store = new ChatStore({ chats });\n+  return store;\n+};",
        "comment_created_at": "2025-04-28T15:00:00+00:00",
        "comment_author": "lgrammel",
        "comment_body": "is this needed? might make sense to just call `new ChatStore` in the tests to be explicit.",
        "pr_file_module": null
      },
      {
        "comment_id": "2063861271",
        "repo_full_name": "vercel/ai",
        "pr_number": 5770,
        "pr_file": "packages/ai/core/util/chat-store.test.ts",
        "discussion_id": "2063860038",
        "commented_code": "@@ -0,0 +1,1090 @@\n+import { beforeEach, describe, expect, it, vi } from 'vitest';\n+import type { UIMessage } from '../types';\n+import { type ChatState, ChatStore } from './chat-store';\n+\n+const initStore = (chats?: Record<string, Pick<ChatState, 'messages'>>) => {\n+  const store = new ChatStore({ chats });\n+  return store;\n+};",
        "comment_created_at": "2025-04-28T15:00:37+00:00",
        "comment_author": "lgrammel",
        "comment_body": "(then you can also inline some variables in the tests to see how the store would look like)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2063867299",
    "pr_number": 5770,
    "pr_file": "packages/ai/core/util/chat-store.test.ts",
    "created_at": "2025-04-28T15:03:32+00:00",
    "commented_code": "+import { beforeEach, describe, expect, it, vi } from 'vitest';\n+import type { UIMessage } from '../types';\n+import { type ChatState, ChatStore } from './chat-store';\n+\n+const initStore = (chats?: Record<string, Pick<ChatState, 'messages'>>) => {\n+  const store = new ChatStore({ chats });\n+  return store;\n+};\n+\n+describe('ChatStore', () => {\n+  describe('initialization', () => {\n+    it('initializes with a single chat', () => {\n+      const id = 'chat-1';\n+      const messages = [\n+        { id: '1', content: 'hello', role: 'user', parts: [] },\n+        { id: '2', content: 'world', role: 'assistant', parts: [] },\n+      ] as UIMessage[];\n+      const chats = {\n+        [id]: { messages },\n+      };\n+      const store = initStore(chats);\n+      expect(store.getMessages(id)).toEqual(messages);\n+      expect(store.totalChats).toEqual(1);\n+    });\n+\n+    it('initializes with multiple chats', () => {\n+      const [id1, id2] = ['chat-1', 'chat-2'];\n+      const [messages1, messages2] = [\n+        [\n+          { id: '1', content: 'hello', role: 'user', parts: [] },\n+          { id: '2', content: 'world', role: 'assistant', parts: [] },\n+        ] as UIMessage[],\n+        [\n+          { id: '1', content: 'beep', role: 'user', parts: [] },\n+          { id: '2', content: 'boop', role: 'assistant', parts: [] },\n+        ] as UIMessage[],\n+      ];\n+      const chats = {\n+        [id1]: { messages: messages1 },\n+        [id2]: { messages: messages2 },\n+      };\n+      const store = initStore(chats);\n+      expect(store.getMessages(id1)).toEqual(messages1);\n+      expect(store.getMessages(id2)).toEqual(messages2);\n+      expect(store.totalChats).toEqual(2);\n+    });\n+\n+    it('initializes with empty chat store', () => {\n+      const store = initStore();\n+      expect(store.totalChats).toEqual(0);\n+    });\n+  });\n+\n+  describe('setMessages', () => {\n+    it('notifies subscribers', () => {\n+      const id = 'chat-1';\n+      const onChatMessagesChanged = vi.fn();\n+      const store = initStore({\n+        [id]: { messages: [] },\n+      });\n+      const unsubscribe = store.subscribe({\n+        onChatMessagesChanged,\n+        onChatStatusChanged: vi.fn(),\n+        onChatErrorChanged: vi.fn(),\n+      });\n+      const messages: UIMessage[] = [\n+        { id: '1', content: 'x', role: 'user', parts: [] },\n+        { id: '2', content: 'y', role: 'assistant', parts: [] },\n+        { id: '3', content: 'z', role: 'user', parts: [] },\n+      ];\n+      store.setMessages({ id, messages });\n+      expect(store.getMessages(id)).toEqual(messages);\n+      expect(onChatMessagesChanged).toHaveBeenCalledOnce();\n+      unsubscribe();\n+      store.setMessages({ id, messages: [] });\n+      expect(onChatMessagesChanged).toHaveBeenCalledOnce();\n+    });",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2063867299",
        "repo_full_name": "vercel/ai",
        "pr_number": 5770,
        "pr_file": "packages/ai/core/util/chat-store.test.ts",
        "discussion_id": "2063867299",
        "commented_code": "@@ -0,0 +1,1090 @@\n+import { beforeEach, describe, expect, it, vi } from 'vitest';\n+import type { UIMessage } from '../types';\n+import { type ChatState, ChatStore } from './chat-store';\n+\n+const initStore = (chats?: Record<string, Pick<ChatState, 'messages'>>) => {\n+  const store = new ChatStore({ chats });\n+  return store;\n+};\n+\n+describe('ChatStore', () => {\n+  describe('initialization', () => {\n+    it('initializes with a single chat', () => {\n+      const id = 'chat-1';\n+      const messages = [\n+        { id: '1', content: 'hello', role: 'user', parts: [] },\n+        { id: '2', content: 'world', role: 'assistant', parts: [] },\n+      ] as UIMessage[];\n+      const chats = {\n+        [id]: { messages },\n+      };\n+      const store = initStore(chats);\n+      expect(store.getMessages(id)).toEqual(messages);\n+      expect(store.totalChats).toEqual(1);\n+    });\n+\n+    it('initializes with multiple chats', () => {\n+      const [id1, id2] = ['chat-1', 'chat-2'];\n+      const [messages1, messages2] = [\n+        [\n+          { id: '1', content: 'hello', role: 'user', parts: [] },\n+          { id: '2', content: 'world', role: 'assistant', parts: [] },\n+        ] as UIMessage[],\n+        [\n+          { id: '1', content: 'beep', role: 'user', parts: [] },\n+          { id: '2', content: 'boop', role: 'assistant', parts: [] },\n+        ] as UIMessage[],\n+      ];\n+      const chats = {\n+        [id1]: { messages: messages1 },\n+        [id2]: { messages: messages2 },\n+      };\n+      const store = initStore(chats);\n+      expect(store.getMessages(id1)).toEqual(messages1);\n+      expect(store.getMessages(id2)).toEqual(messages2);\n+      expect(store.totalChats).toEqual(2);\n+    });\n+\n+    it('initializes with empty chat store', () => {\n+      const store = initStore();\n+      expect(store.totalChats).toEqual(0);\n+    });\n+  });\n+\n+  describe('setMessages', () => {\n+    it('notifies subscribers', () => {\n+      const id = 'chat-1';\n+      const onChatMessagesChanged = vi.fn();\n+      const store = initStore({\n+        [id]: { messages: [] },\n+      });\n+      const unsubscribe = store.subscribe({\n+        onChatMessagesChanged,\n+        onChatStatusChanged: vi.fn(),\n+        onChatErrorChanged: vi.fn(),\n+      });\n+      const messages: UIMessage[] = [\n+        { id: '1', content: 'x', role: 'user', parts: [] },\n+        { id: '2', content: 'y', role: 'assistant', parts: [] },\n+        { id: '3', content: 'z', role: 'user', parts: [] },\n+      ];\n+      store.setMessages({ id, messages });\n+      expect(store.getMessages(id)).toEqual(messages);\n+      expect(onChatMessagesChanged).toHaveBeenCalledOnce();\n+      unsubscribe();\n+      store.setMessages({ id, messages: [] });\n+      expect(onChatMessagesChanged).toHaveBeenCalledOnce();\n+    });",
        "comment_created_at": "2025-04-28T15:03:32+00:00",
        "comment_author": "lgrammel",
        "comment_body": "this test can be split up into several tests for the individual callbacks. should also test that they are invoked with the expected objects. testing `store.getmessages` should be a separate test as well.\r\n\r\n(one `it` test should ideally only test 1 \"thing\" so they can fail individually)",
        "pr_file_module": null
      },
      {
        "comment_id": "2066994194",
        "repo_full_name": "vercel/ai",
        "pr_number": 5770,
        "pr_file": "packages/ai/core/util/chat-store.test.ts",
        "discussion_id": "2063867299",
        "commented_code": "@@ -0,0 +1,1090 @@\n+import { beforeEach, describe, expect, it, vi } from 'vitest';\n+import type { UIMessage } from '../types';\n+import { type ChatState, ChatStore } from './chat-store';\n+\n+const initStore = (chats?: Record<string, Pick<ChatState, 'messages'>>) => {\n+  const store = new ChatStore({ chats });\n+  return store;\n+};\n+\n+describe('ChatStore', () => {\n+  describe('initialization', () => {\n+    it('initializes with a single chat', () => {\n+      const id = 'chat-1';\n+      const messages = [\n+        { id: '1', content: 'hello', role: 'user', parts: [] },\n+        { id: '2', content: 'world', role: 'assistant', parts: [] },\n+      ] as UIMessage[];\n+      const chats = {\n+        [id]: { messages },\n+      };\n+      const store = initStore(chats);\n+      expect(store.getMessages(id)).toEqual(messages);\n+      expect(store.totalChats).toEqual(1);\n+    });\n+\n+    it('initializes with multiple chats', () => {\n+      const [id1, id2] = ['chat-1', 'chat-2'];\n+      const [messages1, messages2] = [\n+        [\n+          { id: '1', content: 'hello', role: 'user', parts: [] },\n+          { id: '2', content: 'world', role: 'assistant', parts: [] },\n+        ] as UIMessage[],\n+        [\n+          { id: '1', content: 'beep', role: 'user', parts: [] },\n+          { id: '2', content: 'boop', role: 'assistant', parts: [] },\n+        ] as UIMessage[],\n+      ];\n+      const chats = {\n+        [id1]: { messages: messages1 },\n+        [id2]: { messages: messages2 },\n+      };\n+      const store = initStore(chats);\n+      expect(store.getMessages(id1)).toEqual(messages1);\n+      expect(store.getMessages(id2)).toEqual(messages2);\n+      expect(store.totalChats).toEqual(2);\n+    });\n+\n+    it('initializes with empty chat store', () => {\n+      const store = initStore();\n+      expect(store.totalChats).toEqual(0);\n+    });\n+  });\n+\n+  describe('setMessages', () => {\n+    it('notifies subscribers', () => {\n+      const id = 'chat-1';\n+      const onChatMessagesChanged = vi.fn();\n+      const store = initStore({\n+        [id]: { messages: [] },\n+      });\n+      const unsubscribe = store.subscribe({\n+        onChatMessagesChanged,\n+        onChatStatusChanged: vi.fn(),\n+        onChatErrorChanged: vi.fn(),\n+      });\n+      const messages: UIMessage[] = [\n+        { id: '1', content: 'x', role: 'user', parts: [] },\n+        { id: '2', content: 'y', role: 'assistant', parts: [] },\n+        { id: '3', content: 'z', role: 'user', parts: [] },\n+      ];\n+      store.setMessages({ id, messages });\n+      expect(store.getMessages(id)).toEqual(messages);\n+      expect(onChatMessagesChanged).toHaveBeenCalledOnce();\n+      unsubscribe();\n+      store.setMessages({ id, messages: [] });\n+      expect(onChatMessagesChanged).toHaveBeenCalledOnce();\n+    });",
        "comment_created_at": "2025-04-29T17:11:24+00:00",
        "comment_author": "iteratetograceness",
        "comment_body": "aligned! will pivot!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2026216450",
    "pr_number": 5496,
    "pr_file": "packages/openai/src/openai-transcription-model.test.ts",
    "created_at": "2025-04-03T05:21:21+00:00",
    "commented_code": "+import { createTestServer } from '@ai-sdk/provider-utils/test';\n+import { OpenAITranscriptionModel } from './openai-transcription-model';\n+import { createOpenAI } from './openai-provider';\n+import { readFile } from 'node:fs/promises';\n+import path from 'node:path';\n+\n+const audioData = await readFile(path.join(__dirname, 'transcript-test.mp3'));\n+const provider = createOpenAI({ apiKey: 'test-api-key' });\n+const model = provider.transcription('whisper-1');\n+\n+const server = createTestServer({\n+  'https://api.openai.com/v1/audio/transcriptions': {},\n+});\n+\n+describe('doGenerate', () => {\n+  function prepareJsonResponse({\n+    headers,\n+  }: {\n+    headers?: Record<string, string>;\n+  } = {}) {\n+    server.urls['https://api.openai.com/v1/audio/transcriptions'].response = {\n+      type: 'json-value',\n+      headers,\n+      body: {\n+        transcript: {\n+          text: 'Hello from the Vercel AI SDK!',\n+          segments: [\n+            {\n+              text: 'Hello',\n+              startSecond: 0,\n+              endSecond: 5,\n+            },\n+            {\n+              text: 'from',\n+              startSecond: 5,\n+              endSecond: 10,\n+            },\n+            {\n+              text: 'the',\n+              startSecond: 10,\n+              endSecond: 15,\n+            },\n+            {\n+              text: 'Vercel',\n+              startSecond: 15,\n+              endSecond: 20,\n+            },\n+            {\n+              text: 'AI',\n+              startSecond: 20,\n+              endSecond: 25,\n+            },\n+            {\n+              text: 'SDK',\n+              startSecond: 25,\n+              endSecond: 30,\n+            },\n+            {\n+              text: '!',\n+              startSecond: 30,\n+              endSecond: 35,\n+            },\n+          ],\n+          durationInSeconds: 35,\n+          language: 'en',\n+          mime_type: 'audio/mp3',\n+        },\n+        providerMetadata: {\n+          'test-provider': 'test-value',\n+        },\n+      },\n+    };\n+  }\n+\n+  it('should pass the model and the settings', async () => {\n+    prepareJsonResponse();\n+\n+    await model.doGenerate({\n+      audio: audioData,\n+    });\n+\n+    expect(await server.calls[0].requestBodyMultipart).toMatchObject({\n+      model: 'whisper-1',\n+    });\n+  });\n+\n+  it('should pass headers', async () => {\n+    prepareJsonResponse();\n+\n+    const provider = createOpenAI({\n+      apiKey: 'test-api-key',\n+      organization: 'test-organization',\n+      project: 'test-project',\n+      headers: {\n+        'Custom-Provider-Header': 'provider-header-value',\n+      },\n+    });\n+\n+    await provider.transcription('whisper-1').doGenerate({\n+      audio: audioData,\n+      headers: {\n+        'Custom-Request-Header': 'request-header-value',\n+      },\n+    });\n+\n+    expect(server.calls[0].requestHeaders).toMatchObject({\n+      authorization: 'Bearer test-api-key',\n+      'content-type': expect.stringMatching(\n+        /^multipart\\/form-data; boundary=----formdata-undici-\\d+$/,\n+      ),\n+      'custom-provider-header': 'provider-header-value',\n+      'custom-request-header': 'request-header-value',\n+      'openai-organization': 'test-organization',\n+      'openai-project': 'test-project',\n+    });\n+  });\n+\n+  it('should extract the transcription text', async () => {\n+    prepareJsonResponse();\n+\n+    const result = await model.doGenerate({\n+      audio: audioData,\n+    });\n+\n+    expect(result.transcript.text).toBe('Hello from the Vercel AI SDK!');\n+  });\n+\n+  it('should include response data with timestamp, modelId and headers', async () => {\n+    prepareJsonResponse({\n+      headers: {\n+        'x-request-id': 'test-request-id',\n+        'x-ratelimit-remaining': '123',\n+      },\n+    });\n+\n+    const testDate = new Date('2024-03-15T12:00:00Z');\n+\n+    const customModel = new OpenAITranscriptionModel(\n+      'whisper-1',\n+      {},\n+      {\n+        provider: 'test-provider',\n+        url: () => 'https://api.openai.com/v1/audio/transcriptions',\n+        headers: () => ({}),\n+        _internal: {\n+          currentDate: () => testDate,\n+        },\n+      },\n+    );\n+\n+    const result = await customModel.doGenerate({\n+      audio: audioData,\n+    });\n+\n+    expect(result.response).toStrictEqual({\n+      timestamp: testDate,\n+      modelId: 'whisper-1',\n+      headers: {\n+        'content-length': '510',\n+        'content-type': 'application/json',\n+        'x-request-id': 'test-request-id',\n+        'x-ratelimit-remaining': '123',\n+      },\n+    });\n+  });\n+\n+  it('should use real date when no custom date provider is specified', async () => {\n+    prepareJsonResponse();\n+    const beforeDate = new Date();\n+\n+    const result = await model.doGenerate({\n+      audio: audioData,\n+    });\n+\n+    const afterDate = new Date();\n+\n+    expect(result.response.timestamp.getTime()).toBeGreaterThanOrEqual(\n+      beforeDate.getTime(),\n+    );\n+    expect(result.response.timestamp.getTime()).toBeLessThanOrEqual(\n+      afterDate.getTime(),\n+    );\n+    expect(result.response.modelId).toBe('whisper-1');\n+  });",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2026216450",
        "repo_full_name": "vercel/ai",
        "pr_number": 5496,
        "pr_file": "packages/openai/src/openai-transcription-model.test.ts",
        "discussion_id": "2026216450",
        "commented_code": "@@ -0,0 +1,185 @@\n+import { createTestServer } from '@ai-sdk/provider-utils/test';\n+import { OpenAITranscriptionModel } from './openai-transcription-model';\n+import { createOpenAI } from './openai-provider';\n+import { readFile } from 'node:fs/promises';\n+import path from 'node:path';\n+\n+const audioData = await readFile(path.join(__dirname, 'transcript-test.mp3'));\n+const provider = createOpenAI({ apiKey: 'test-api-key' });\n+const model = provider.transcription('whisper-1');\n+\n+const server = createTestServer({\n+  'https://api.openai.com/v1/audio/transcriptions': {},\n+});\n+\n+describe('doGenerate', () => {\n+  function prepareJsonResponse({\n+    headers,\n+  }: {\n+    headers?: Record<string, string>;\n+  } = {}) {\n+    server.urls['https://api.openai.com/v1/audio/transcriptions'].response = {\n+      type: 'json-value',\n+      headers,\n+      body: {\n+        transcript: {\n+          text: 'Hello from the Vercel AI SDK!',\n+          segments: [\n+            {\n+              text: 'Hello',\n+              startSecond: 0,\n+              endSecond: 5,\n+            },\n+            {\n+              text: 'from',\n+              startSecond: 5,\n+              endSecond: 10,\n+            },\n+            {\n+              text: 'the',\n+              startSecond: 10,\n+              endSecond: 15,\n+            },\n+            {\n+              text: 'Vercel',\n+              startSecond: 15,\n+              endSecond: 20,\n+            },\n+            {\n+              text: 'AI',\n+              startSecond: 20,\n+              endSecond: 25,\n+            },\n+            {\n+              text: 'SDK',\n+              startSecond: 25,\n+              endSecond: 30,\n+            },\n+            {\n+              text: '!',\n+              startSecond: 30,\n+              endSecond: 35,\n+            },\n+          ],\n+          durationInSeconds: 35,\n+          language: 'en',\n+          mime_type: 'audio/mp3',\n+        },\n+        providerMetadata: {\n+          'test-provider': 'test-value',\n+        },\n+      },\n+    };\n+  }\n+\n+  it('should pass the model and the settings', async () => {\n+    prepareJsonResponse();\n+\n+    await model.doGenerate({\n+      audio: audioData,\n+    });\n+\n+    expect(await server.calls[0].requestBodyMultipart).toMatchObject({\n+      model: 'whisper-1',\n+    });\n+  });\n+\n+  it('should pass headers', async () => {\n+    prepareJsonResponse();\n+\n+    const provider = createOpenAI({\n+      apiKey: 'test-api-key',\n+      organization: 'test-organization',\n+      project: 'test-project',\n+      headers: {\n+        'Custom-Provider-Header': 'provider-header-value',\n+      },\n+    });\n+\n+    await provider.transcription('whisper-1').doGenerate({\n+      audio: audioData,\n+      headers: {\n+        'Custom-Request-Header': 'request-header-value',\n+      },\n+    });\n+\n+    expect(server.calls[0].requestHeaders).toMatchObject({\n+      authorization: 'Bearer test-api-key',\n+      'content-type': expect.stringMatching(\n+        /^multipart\\/form-data; boundary=----formdata-undici-\\d+$/,\n+      ),\n+      'custom-provider-header': 'provider-header-value',\n+      'custom-request-header': 'request-header-value',\n+      'openai-organization': 'test-organization',\n+      'openai-project': 'test-project',\n+    });\n+  });\n+\n+  it('should extract the transcription text', async () => {\n+    prepareJsonResponse();\n+\n+    const result = await model.doGenerate({\n+      audio: audioData,\n+    });\n+\n+    expect(result.transcript.text).toBe('Hello from the Vercel AI SDK!');\n+  });\n+\n+  it('should include response data with timestamp, modelId and headers', async () => {\n+    prepareJsonResponse({\n+      headers: {\n+        'x-request-id': 'test-request-id',\n+        'x-ratelimit-remaining': '123',\n+      },\n+    });\n+\n+    const testDate = new Date('2024-03-15T12:00:00Z');\n+\n+    const customModel = new OpenAITranscriptionModel(\n+      'whisper-1',\n+      {},\n+      {\n+        provider: 'test-provider',\n+        url: () => 'https://api.openai.com/v1/audio/transcriptions',\n+        headers: () => ({}),\n+        _internal: {\n+          currentDate: () => testDate,\n+        },\n+      },\n+    );\n+\n+    const result = await customModel.doGenerate({\n+      audio: audioData,\n+    });\n+\n+    expect(result.response).toStrictEqual({\n+      timestamp: testDate,\n+      modelId: 'whisper-1',\n+      headers: {\n+        'content-length': '510',\n+        'content-type': 'application/json',\n+        'x-request-id': 'test-request-id',\n+        'x-ratelimit-remaining': '123',\n+      },\n+    });\n+  });\n+\n+  it('should use real date when no custom date provider is specified', async () => {\n+    prepareJsonResponse();\n+    const beforeDate = new Date();\n+\n+    const result = await model.doGenerate({\n+      audio: audioData,\n+    });\n+\n+    const afterDate = new Date();\n+\n+    expect(result.response.timestamp.getTime()).toBeGreaterThanOrEqual(\n+      beforeDate.getTime(),\n+    );\n+    expect(result.response.timestamp.getTime()).toBeLessThanOrEqual(\n+      afterDate.getTime(),\n+    );\n+    expect(result.response.modelId).toBe('whisper-1');\n+  });",
        "comment_created_at": "2025-04-03T05:21:21+00:00",
        "comment_author": "lgrammel",
        "comment_body": "please stub the dates instead. see e.g. \r\n\r\nhttps://github.com/vercel/ai/blob/main/packages/ai/core/generate-text/generate-text.test.ts#L1280\r\n\r\n```ts\r\n  _internal: {\r\n    generateId = originalGenerateId,\r\n    currentDate = () => new Date(),\r\n  } = {},\r\n  ```\r\n  \r\nTests should never have any variable aspects such as dates. With stubbed values we can exactly test the passthrough.",
        "pr_file_module": null
      },
      {
        "comment_id": "2027682385",
        "repo_full_name": "vercel/ai",
        "pr_number": 5496,
        "pr_file": "packages/openai/src/openai-transcription-model.test.ts",
        "discussion_id": "2026216450",
        "commented_code": "@@ -0,0 +1,185 @@\n+import { createTestServer } from '@ai-sdk/provider-utils/test';\n+import { OpenAITranscriptionModel } from './openai-transcription-model';\n+import { createOpenAI } from './openai-provider';\n+import { readFile } from 'node:fs/promises';\n+import path from 'node:path';\n+\n+const audioData = await readFile(path.join(__dirname, 'transcript-test.mp3'));\n+const provider = createOpenAI({ apiKey: 'test-api-key' });\n+const model = provider.transcription('whisper-1');\n+\n+const server = createTestServer({\n+  'https://api.openai.com/v1/audio/transcriptions': {},\n+});\n+\n+describe('doGenerate', () => {\n+  function prepareJsonResponse({\n+    headers,\n+  }: {\n+    headers?: Record<string, string>;\n+  } = {}) {\n+    server.urls['https://api.openai.com/v1/audio/transcriptions'].response = {\n+      type: 'json-value',\n+      headers,\n+      body: {\n+        transcript: {\n+          text: 'Hello from the Vercel AI SDK!',\n+          segments: [\n+            {\n+              text: 'Hello',\n+              startSecond: 0,\n+              endSecond: 5,\n+            },\n+            {\n+              text: 'from',\n+              startSecond: 5,\n+              endSecond: 10,\n+            },\n+            {\n+              text: 'the',\n+              startSecond: 10,\n+              endSecond: 15,\n+            },\n+            {\n+              text: 'Vercel',\n+              startSecond: 15,\n+              endSecond: 20,\n+            },\n+            {\n+              text: 'AI',\n+              startSecond: 20,\n+              endSecond: 25,\n+            },\n+            {\n+              text: 'SDK',\n+              startSecond: 25,\n+              endSecond: 30,\n+            },\n+            {\n+              text: '!',\n+              startSecond: 30,\n+              endSecond: 35,\n+            },\n+          ],\n+          durationInSeconds: 35,\n+          language: 'en',\n+          mime_type: 'audio/mp3',\n+        },\n+        providerMetadata: {\n+          'test-provider': 'test-value',\n+        },\n+      },\n+    };\n+  }\n+\n+  it('should pass the model and the settings', async () => {\n+    prepareJsonResponse();\n+\n+    await model.doGenerate({\n+      audio: audioData,\n+    });\n+\n+    expect(await server.calls[0].requestBodyMultipart).toMatchObject({\n+      model: 'whisper-1',\n+    });\n+  });\n+\n+  it('should pass headers', async () => {\n+    prepareJsonResponse();\n+\n+    const provider = createOpenAI({\n+      apiKey: 'test-api-key',\n+      organization: 'test-organization',\n+      project: 'test-project',\n+      headers: {\n+        'Custom-Provider-Header': 'provider-header-value',\n+      },\n+    });\n+\n+    await provider.transcription('whisper-1').doGenerate({\n+      audio: audioData,\n+      headers: {\n+        'Custom-Request-Header': 'request-header-value',\n+      },\n+    });\n+\n+    expect(server.calls[0].requestHeaders).toMatchObject({\n+      authorization: 'Bearer test-api-key',\n+      'content-type': expect.stringMatching(\n+        /^multipart\\/form-data; boundary=----formdata-undici-\\d+$/,\n+      ),\n+      'custom-provider-header': 'provider-header-value',\n+      'custom-request-header': 'request-header-value',\n+      'openai-organization': 'test-organization',\n+      'openai-project': 'test-project',\n+    });\n+  });\n+\n+  it('should extract the transcription text', async () => {\n+    prepareJsonResponse();\n+\n+    const result = await model.doGenerate({\n+      audio: audioData,\n+    });\n+\n+    expect(result.transcript.text).toBe('Hello from the Vercel AI SDK!');\n+  });\n+\n+  it('should include response data with timestamp, modelId and headers', async () => {\n+    prepareJsonResponse({\n+      headers: {\n+        'x-request-id': 'test-request-id',\n+        'x-ratelimit-remaining': '123',\n+      },\n+    });\n+\n+    const testDate = new Date('2024-03-15T12:00:00Z');\n+\n+    const customModel = new OpenAITranscriptionModel(\n+      'whisper-1',\n+      {},\n+      {\n+        provider: 'test-provider',\n+        url: () => 'https://api.openai.com/v1/audio/transcriptions',\n+        headers: () => ({}),\n+        _internal: {\n+          currentDate: () => testDate,\n+        },\n+      },\n+    );\n+\n+    const result = await customModel.doGenerate({\n+      audio: audioData,\n+    });\n+\n+    expect(result.response).toStrictEqual({\n+      timestamp: testDate,\n+      modelId: 'whisper-1',\n+      headers: {\n+        'content-length': '510',\n+        'content-type': 'application/json',\n+        'x-request-id': 'test-request-id',\n+        'x-ratelimit-remaining': '123',\n+      },\n+    });\n+  });\n+\n+  it('should use real date when no custom date provider is specified', async () => {\n+    prepareJsonResponse();\n+    const beforeDate = new Date();\n+\n+    const result = await model.doGenerate({\n+      audio: audioData,\n+    });\n+\n+    const afterDate = new Date();\n+\n+    expect(result.response.timestamp.getTime()).toBeGreaterThanOrEqual(\n+      beforeDate.getTime(),\n+    );\n+    expect(result.response.timestamp.getTime()).toBeLessThanOrEqual(\n+      afterDate.getTime(),\n+    );\n+    expect(result.response.modelId).toBe('whisper-1');\n+  });",
        "comment_created_at": "2025-04-03T20:22:58+00:00",
        "comment_author": "haydenbleasel",
        "comment_body": "Understood. If that's the case, we may want to re-address the image tests for bedrock, google vertex and openai later as it's copied from them.",
        "pr_file_module": null
      }
    ]
  }
]