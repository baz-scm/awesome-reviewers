[
  {
    "discussion_id": "1849832378",
    "pr_number": 3781,
    "pr_file": "packages/openai-compatible/src/openai-compatible-chat-settings.ts",
    "created_at": "2024-11-20T08:26:16+00:00",
    "commented_code": "+export type OpenAICompatibleChatModelId = string;\n+\n+export interface OpenAICompatibleChatSettings {\n+  /**\n+A unique identifier representing your end-user, which can help the provider to\n+monitor and detect abuse.\n+  */\n+  user?: string;\n+\n+  /**\n+Default object generation mode that should be used with this model when\n+no mode is specified. Should be the mode with the best results for this\n+model. `undefined` can be returned if object generation is not supported.\n+\n+This is needed to generate the best objects possible w/o requiring the\n+user to explicitly specify the object generation mode.\n+  */\n+  // TODO(shaper): This is really model-specific, move to config or elsewhere?\n+  defaultObjectGenerationMode?: 'json' | 'tool' | undefined;",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "1849832378",
        "repo_full_name": "vercel/ai",
        "pr_number": 3781,
        "pr_file": "packages/openai-compatible/src/openai-compatible-chat-settings.ts",
        "discussion_id": "1849832378",
        "commented_code": "@@ -0,0 +1,20 @@\n+export type OpenAICompatibleChatModelId = string;\n+\n+export interface OpenAICompatibleChatSettings {\n+  /**\n+A unique identifier representing your end-user, which can help the provider to\n+monitor and detect abuse.\n+  */\n+  user?: string;\n+\n+  /**\n+Default object generation mode that should be used with this model when\n+no mode is specified. Should be the mode with the best results for this\n+model. `undefined` can be returned if object generation is not supported.\n+\n+This is needed to generate the best objects possible w/o requiring the\n+user to explicitly specify the object generation mode.\n+  */\n+  // TODO(shaper): This is really model-specific, move to config or elsewhere?\n+  defaultObjectGenerationMode?: 'json' | 'tool' | undefined;",
        "comment_created_at": "2024-11-20T08:26:16+00:00",
        "comment_author": "lgrammel",
        "comment_body": "can you make it a constructor parameter (in the options) for the model that is then defined in the providers? (which would have that knowledge)",
        "pr_file_module": null
      },
      {
        "comment_id": "1851098886",
        "repo_full_name": "vercel/ai",
        "pr_number": 3781,
        "pr_file": "packages/openai-compatible/src/openai-compatible-chat-settings.ts",
        "discussion_id": "1849832378",
        "commented_code": "@@ -0,0 +1,20 @@\n+export type OpenAICompatibleChatModelId = string;\n+\n+export interface OpenAICompatibleChatSettings {\n+  /**\n+A unique identifier representing your end-user, which can help the provider to\n+monitor and detect abuse.\n+  */\n+  user?: string;\n+\n+  /**\n+Default object generation mode that should be used with this model when\n+no mode is specified. Should be the mode with the best results for this\n+model. `undefined` can be returned if object generation is not supported.\n+\n+This is needed to generate the best objects possible w/o requiring the\n+user to explicitly specify the object generation mode.\n+  */\n+  // TODO(shaper): This is really model-specific, move to config or elsewhere?\n+  defaultObjectGenerationMode?: 'json' | 'tool' | undefined;",
        "comment_created_at": "2024-11-20T23:08:37+00:00",
        "comment_author": "shaper",
        "comment_body": "By `options` do you mean `config` e.g. `OpenAICompatibleChatLanguageModel` constructor signature is `(modelId, settings, config)`?\r\n\r\nI'll move it there and see how to expose it to the concrete provider impl which today just passes a settings object (where I had it when you commented), but we could add an options or model-config arg as well.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1849834797",
    "pr_number": 3781,
    "pr_file": "packages/openai-compatible/src/openai-compatible-chat-language-model.ts",
    "created_at": "2024-11-20T08:27:39+00:00",
    "commented_code": "+import {\n+  InvalidResponseDataError,\n+  LanguageModelV1,\n+  LanguageModelV1CallWarning,\n+  LanguageModelV1FinishReason,\n+  LanguageModelV1ProviderMetadata,\n+  LanguageModelV1StreamPart,\n+  UnsupportedFunctionalityError,\n+} from '@ai-sdk/provider';\n+import {\n+  FetchFunction,\n+  ParseResult,\n+  combineHeaders,\n+  createEventSourceResponseHandler,\n+  createJsonResponseHandler,\n+  generateId,\n+  isParsableJson,\n+  postJsonToApi,\n+} from '@ai-sdk/provider-utils';\n+import { z } from 'zod';\n+import { convertToOpenAICompatibleChatMessages } from './convert-to-openai-compatible-chat-messages';\n+import { getResponseMetadata } from './get-response-metadata';\n+import {\n+  OpenAICompatibleChatModelId,\n+  OpenAICompatibleChatSettings,\n+} from './openai-compatible-chat-settings';\n+import {\n+  openAICompatibleErrorDataSchema,\n+  openAICompatibleFailedResponseHandler,\n+} from './openai-compatible-error';\n+import { prepareTools } from './openai-compatible-prepare-tools';\n+import { mapOpenAICompatibleFinishReason } from './map-openai-compatible-finish-reason';\n+\n+type OpenAICompatibleChatConfig = {\n+  provider: string;\n+  headers: () => Record<string, string | undefined>;\n+  url: (options: { modelId: string; path: string }) => string;\n+  fetch?: FetchFunction;\n+};\n+\n+export class OpenAICompatibleChatLanguageModel implements LanguageModelV1 {\n+  readonly specificationVersion = 'v1';\n+\n+  readonly supportsStructuredOutputs = false;\n+\n+  readonly modelId: OpenAICompatibleChatModelId;\n+  readonly settings: OpenAICompatibleChatSettings;\n+\n+  private readonly config: OpenAICompatibleChatConfig;\n+\n+  constructor(\n+    modelId: OpenAICompatibleChatModelId,\n+    settings: OpenAICompatibleChatSettings,\n+    config: OpenAICompatibleChatConfig,",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "1849834797",
        "repo_full_name": "vercel/ai",
        "pr_number": 3781,
        "pr_file": "packages/openai-compatible/src/openai-compatible-chat-language-model.ts",
        "discussion_id": "1849834797",
        "commented_code": "@@ -0,0 +1,537 @@\n+import {\n+  InvalidResponseDataError,\n+  LanguageModelV1,\n+  LanguageModelV1CallWarning,\n+  LanguageModelV1FinishReason,\n+  LanguageModelV1ProviderMetadata,\n+  LanguageModelV1StreamPart,\n+  UnsupportedFunctionalityError,\n+} from '@ai-sdk/provider';\n+import {\n+  FetchFunction,\n+  ParseResult,\n+  combineHeaders,\n+  createEventSourceResponseHandler,\n+  createJsonResponseHandler,\n+  generateId,\n+  isParsableJson,\n+  postJsonToApi,\n+} from '@ai-sdk/provider-utils';\n+import { z } from 'zod';\n+import { convertToOpenAICompatibleChatMessages } from './convert-to-openai-compatible-chat-messages';\n+import { getResponseMetadata } from './get-response-metadata';\n+import {\n+  OpenAICompatibleChatModelId,\n+  OpenAICompatibleChatSettings,\n+} from './openai-compatible-chat-settings';\n+import {\n+  openAICompatibleErrorDataSchema,\n+  openAICompatibleFailedResponseHandler,\n+} from './openai-compatible-error';\n+import { prepareTools } from './openai-compatible-prepare-tools';\n+import { mapOpenAICompatibleFinishReason } from './map-openai-compatible-finish-reason';\n+\n+type OpenAICompatibleChatConfig = {\n+  provider: string;\n+  headers: () => Record<string, string | undefined>;\n+  url: (options: { modelId: string; path: string }) => string;\n+  fetch?: FetchFunction;\n+};\n+\n+export class OpenAICompatibleChatLanguageModel implements LanguageModelV1 {\n+  readonly specificationVersion = 'v1';\n+\n+  readonly supportsStructuredOutputs = false;\n+\n+  readonly modelId: OpenAICompatibleChatModelId;\n+  readonly settings: OpenAICompatibleChatSettings;\n+\n+  private readonly config: OpenAICompatibleChatConfig;\n+\n+  constructor(\n+    modelId: OpenAICompatibleChatModelId,\n+    settings: OpenAICompatibleChatSettings,\n+    config: OpenAICompatibleChatConfig,",
        "comment_created_at": "2024-11-20T08:27:39+00:00",
        "comment_author": "lgrammel",
        "comment_body": "include the default object generation mode in `config`",
        "pr_file_module": null
      },
      {
        "comment_id": "1851144792",
        "repo_full_name": "vercel/ai",
        "pr_number": 3781,
        "pr_file": "packages/openai-compatible/src/openai-compatible-chat-language-model.ts",
        "discussion_id": "1849834797",
        "commented_code": "@@ -0,0 +1,537 @@\n+import {\n+  InvalidResponseDataError,\n+  LanguageModelV1,\n+  LanguageModelV1CallWarning,\n+  LanguageModelV1FinishReason,\n+  LanguageModelV1ProviderMetadata,\n+  LanguageModelV1StreamPart,\n+  UnsupportedFunctionalityError,\n+} from '@ai-sdk/provider';\n+import {\n+  FetchFunction,\n+  ParseResult,\n+  combineHeaders,\n+  createEventSourceResponseHandler,\n+  createJsonResponseHandler,\n+  generateId,\n+  isParsableJson,\n+  postJsonToApi,\n+} from '@ai-sdk/provider-utils';\n+import { z } from 'zod';\n+import { convertToOpenAICompatibleChatMessages } from './convert-to-openai-compatible-chat-messages';\n+import { getResponseMetadata } from './get-response-metadata';\n+import {\n+  OpenAICompatibleChatModelId,\n+  OpenAICompatibleChatSettings,\n+} from './openai-compatible-chat-settings';\n+import {\n+  openAICompatibleErrorDataSchema,\n+  openAICompatibleFailedResponseHandler,\n+} from './openai-compatible-error';\n+import { prepareTools } from './openai-compatible-prepare-tools';\n+import { mapOpenAICompatibleFinishReason } from './map-openai-compatible-finish-reason';\n+\n+type OpenAICompatibleChatConfig = {\n+  provider: string;\n+  headers: () => Record<string, string | undefined>;\n+  url: (options: { modelId: string; path: string }) => string;\n+  fetch?: FetchFunction;\n+};\n+\n+export class OpenAICompatibleChatLanguageModel implements LanguageModelV1 {\n+  readonly specificationVersion = 'v1';\n+\n+  readonly supportsStructuredOutputs = false;\n+\n+  readonly modelId: OpenAICompatibleChatModelId;\n+  readonly settings: OpenAICompatibleChatSettings;\n+\n+  private readonly config: OpenAICompatibleChatConfig;\n+\n+  constructor(\n+    modelId: OpenAICompatibleChatModelId,\n+    settings: OpenAICompatibleChatSettings,\n+    config: OpenAICompatibleChatConfig,",
        "comment_created_at": "2024-11-21T00:10:55+00:00",
        "comment_author": "shaper",
        "comment_body": "Done. I'd like to define a type for the values `'json' | 'tool' | undefined`. It appears the first reference is in LanguageModelV1. Is it appropriate to add something [there](https://github.com/vercel/ai/blob/a334c6ad18ce13eff0e5072783c902a93754f0fe/packages/provider/src/language-model/v1/language-model-v1.ts#L39)?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2041062684",
    "pr_number": 5718,
    "pr_file": "packages/fal/src/fal-api-types.ts",
    "created_at": "2025-04-13T07:07:44+00:00",
    "commented_code": "+export type FalTranscriptionAPITypes = {\n+  /**\n+   * URL of the audio file to transcribe. Supported formats: mp3, mp4, mpeg, mpga, m4a, wav or webm.\n+   */\n+  audio_url: string;\n+\n+  /**\n+   * Task to perform on the audio file. Either transcribe or translate. Default value: \"transcribe\"\n+   */\n+  task?: 'transcribe' | 'translate';\n+\n+  /**\n+   * Language of the audio file. If set to null, the language will be automatically detected. Defaults to null.\n+   *\n+   * If translate is selected as the task, the audio will be translated to English, regardless of the language selected.\n+   */\n+  language?:",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2041062684",
        "repo_full_name": "vercel/ai",
        "pr_number": 5718,
        "pr_file": "packages/fal/src/fal-api-types.ts",
        "discussion_id": "2041062684",
        "commented_code": "@@ -0,0 +1,149 @@\n+export type FalTranscriptionAPITypes = {\n+  /**\n+   * URL of the audio file to transcribe. Supported formats: mp3, mp4, mpeg, mpga, m4a, wav or webm.\n+   */\n+  audio_url: string;\n+\n+  /**\n+   * Task to perform on the audio file. Either transcribe or translate. Default value: \"transcribe\"\n+   */\n+  task?: 'transcribe' | 'translate';\n+\n+  /**\n+   * Language of the audio file. If set to null, the language will be automatically detected. Defaults to null.\n+   *\n+   * If translate is selected as the task, the audio will be translated to English, regardless of the language selected.\n+   */\n+  language?:",
        "comment_created_at": "2025-04-13T07:07:44+00:00",
        "comment_author": "lgrammel",
        "comment_body": "This seems like something we could turn into a top-level option eventually?",
        "pr_file_module": null
      },
      {
        "comment_id": "2041155173",
        "repo_full_name": "vercel/ai",
        "pr_number": 5718,
        "pr_file": "packages/fal/src/fal-api-types.ts",
        "discussion_id": "2041062684",
        "commented_code": "@@ -0,0 +1,149 @@\n+export type FalTranscriptionAPITypes = {\n+  /**\n+   * URL of the audio file to transcribe. Supported formats: mp3, mp4, mpeg, mpga, m4a, wav or webm.\n+   */\n+  audio_url: string;\n+\n+  /**\n+   * Task to perform on the audio file. Either transcribe or translate. Default value: \"transcribe\"\n+   */\n+  task?: 'transcribe' | 'translate';\n+\n+  /**\n+   * Language of the audio file. If set to null, the language will be automatically detected. Defaults to null.\n+   *\n+   * If translate is selected as the task, the audio will be translated to English, regardless of the language selected.\n+   */\n+  language?:",
        "comment_created_at": "2025-04-13T16:05:01+00:00",
        "comment_author": "haydenbleasel",
        "comment_body": "Yep agreed - once all my current Transcribe PRs are merged, I'll open a new PR that migrates language to top level.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2036732018",
    "pr_number": 5649,
    "pr_file": "packages/openai/src/openai-speech-model.ts",
    "created_at": "2025-04-10T07:50:22+00:00",
    "commented_code": "+import {\n+  SpeechModelV1,\n+  SpeechModelV1CallOptions,\n+  SpeechModelV1CallWarning,\n+} from '@ai-sdk/provider';\n+import {\n+  combineHeaders,\n+  createBinaryResponseHandler,\n+  parseProviderOptions,\n+  postJsonToApi,\n+} from '@ai-sdk/provider-utils';\n+import { z } from 'zod';\n+import { OpenAIConfig } from './openai-config';\n+import { openaiFailedResponseHandler } from './openai-error';\n+import {\n+  OpenAISpeechModelId,\n+  OpenAISpeechModelOptions,\n+} from './openai-speech-settings';\n+\n+// https://platform.openai.com/docs/api-reference/audio/createSpeech\n+const OpenAIProviderOptionsSchema = z.object({\n+  voice: z\n+    .enum([\n+      'alloy',\n+      'ash',\n+      'ballad',\n+      'coral',\n+      'echo',\n+      'fable',\n+      'onyx',\n+      'nova',\n+      'sage',\n+      'shimmer',\n+      'verse',\n+    ])\n+    .default('alloy')\n+    .optional()\n+    .describe('The voice to use when generating the audio.'),\n+  instructions: z\n+    .string()\n+    .optional()\n+    .describe(\n+      'Control the voice of your generated audio with additional instructions. Does not work with tts-1 or tts-1-hd.',\n+    ),\n+  response_format: z\n+    .enum(['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm'])\n+    .default('mp3')\n+    .describe('The format of the generated audio.'),\n+  speed: z\n+    .number()\n+    .min(0.25)\n+    .max(4.0)\n+    .default(1.0)\n+    .describe('The speed of the generated audio.'),\n+});\n+\n+export type OpenAISpeechCallOptions = Omit<\n+  SpeechModelV1CallOptions,\n+  'providerOptions'\n+> & {\n+  providerOptions?: {\n+    openai?: z.infer<typeof OpenAIProviderOptionsSchema>;\n+  };\n+};\n+\n+interface OpenAISpeechModelConfig extends OpenAIConfig {\n+  _internal?: {\n+    currentDate?: () => Date;\n+  };\n+}\n+\n+export class OpenAISpeechModel implements SpeechModelV1 {\n+  readonly specificationVersion = 'v1';\n+\n+  get provider(): string {\n+    return this.config.provider;\n+  }\n+\n+  constructor(\n+    readonly modelId: OpenAISpeechModelId,\n+    private readonly config: OpenAISpeechModelConfig,\n+  ) {}\n+\n+  private getArgs({ text, providerOptions }: OpenAISpeechCallOptions) {\n+    const warnings: SpeechModelV1CallWarning[] = [];\n+\n+    // Parse provider options\n+    const openAIOptions = parseProviderOptions({\n+      provider: 'openai',\n+      providerOptions,\n+      schema: OpenAIProviderOptionsSchema,\n+    });\n+\n+    // Create request body\n+    const requestBody: Record<string, any> = {\n+      model: this.modelId,\n+      input: text,\n+      voice: 'alloy',\n+    };\n+\n+    // Add provider-specific options\n+    if (openAIOptions) {\n+      const speechModelOptions: OpenAISpeechModelOptions = {\n+        voice: openAIOptions.voice,",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2036732018",
        "repo_full_name": "vercel/ai",
        "pr_number": 5649,
        "pr_file": "packages/openai/src/openai-speech-model.ts",
        "discussion_id": "2036732018",
        "commented_code": "@@ -0,0 +1,162 @@\n+import {\n+  SpeechModelV1,\n+  SpeechModelV1CallOptions,\n+  SpeechModelV1CallWarning,\n+} from '@ai-sdk/provider';\n+import {\n+  combineHeaders,\n+  createBinaryResponseHandler,\n+  parseProviderOptions,\n+  postJsonToApi,\n+} from '@ai-sdk/provider-utils';\n+import { z } from 'zod';\n+import { OpenAIConfig } from './openai-config';\n+import { openaiFailedResponseHandler } from './openai-error';\n+import {\n+  OpenAISpeechModelId,\n+  OpenAISpeechModelOptions,\n+} from './openai-speech-settings';\n+\n+// https://platform.openai.com/docs/api-reference/audio/createSpeech\n+const OpenAIProviderOptionsSchema = z.object({\n+  voice: z\n+    .enum([\n+      'alloy',\n+      'ash',\n+      'ballad',\n+      'coral',\n+      'echo',\n+      'fable',\n+      'onyx',\n+      'nova',\n+      'sage',\n+      'shimmer',\n+      'verse',\n+    ])\n+    .default('alloy')\n+    .optional()\n+    .describe('The voice to use when generating the audio.'),\n+  instructions: z\n+    .string()\n+    .optional()\n+    .describe(\n+      'Control the voice of your generated audio with additional instructions. Does not work with tts-1 or tts-1-hd.',\n+    ),\n+  response_format: z\n+    .enum(['mp3', 'opus', 'aac', 'flac', 'wav', 'pcm'])\n+    .default('mp3')\n+    .describe('The format of the generated audio.'),\n+  speed: z\n+    .number()\n+    .min(0.25)\n+    .max(4.0)\n+    .default(1.0)\n+    .describe('The speed of the generated audio.'),\n+});\n+\n+export type OpenAISpeechCallOptions = Omit<\n+  SpeechModelV1CallOptions,\n+  'providerOptions'\n+> & {\n+  providerOptions?: {\n+    openai?: z.infer<typeof OpenAIProviderOptionsSchema>;\n+  };\n+};\n+\n+interface OpenAISpeechModelConfig extends OpenAIConfig {\n+  _internal?: {\n+    currentDate?: () => Date;\n+  };\n+}\n+\n+export class OpenAISpeechModel implements SpeechModelV1 {\n+  readonly specificationVersion = 'v1';\n+\n+  get provider(): string {\n+    return this.config.provider;\n+  }\n+\n+  constructor(\n+    readonly modelId: OpenAISpeechModelId,\n+    private readonly config: OpenAISpeechModelConfig,\n+  ) {}\n+\n+  private getArgs({ text, providerOptions }: OpenAISpeechCallOptions) {\n+    const warnings: SpeechModelV1CallWarning[] = [];\n+\n+    // Parse provider options\n+    const openAIOptions = parseProviderOptions({\n+      provider: 'openai',\n+      providerOptions,\n+      schema: OpenAIProviderOptionsSchema,\n+    });\n+\n+    // Create request body\n+    const requestBody: Record<string, any> = {\n+      model: this.modelId,\n+      input: text,\n+      voice: 'alloy',\n+    };\n+\n+    // Add provider-specific options\n+    if (openAIOptions) {\n+      const speechModelOptions: OpenAISpeechModelOptions = {\n+        voice: openAIOptions.voice,",
        "comment_created_at": "2025-04-10T07:50:22+00:00",
        "comment_author": "lgrammel",
        "comment_body": "voice and response_format are setting we have standardized. we usually do not duplicate standardized settings in the providerOptions",
        "pr_file_module": null
      }
    ]
  }
]