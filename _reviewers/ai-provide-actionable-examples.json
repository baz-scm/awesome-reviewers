[
  {
    "discussion_id": "2185276299",
    "pr_number": 7048,
    "pr_file": "content/providers/01-ai-sdk-providers/25-cohere.mdx",
    "created_at": "2025-07-04T12:43:00+00:00",
    "commented_code": "});\n ```\n \n-The following optional provider options are available for Cohere embedding models:\n+Cohere embedding models support provider options. You can pass them as an options argument:",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2185276299",
        "repo_full_name": "vercel/ai",
        "pr_number": 7048,
        "pr_file": "content/providers/01-ai-sdk-providers/25-cohere.mdx",
        "discussion_id": "2185276299",
        "commented_code": "@@ -134,7 +141,7 @@ await embed({\n });\n ```\n \n-The following optional provider options are available for Cohere embedding models:\n+Cohere embedding models support provider options. You can pass them as an options argument:",
        "comment_created_at": "2025-07-04T12:43:00+00:00",
        "comment_author": "nicoalbanese",
        "comment_body": "\"You can pass them as an options argument\" isn't super clear. Can we give an example in code, or specify as you did in another page `providerOptions.cohere`?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2091033004",
    "pr_number": 6337,
    "pr_file": "content/docs/02-getting-started/00-alpha.mdx",
    "created_at": "2025-05-15T12:13:04+00:00",
    "commented_code": "+---\n+title: AI SDK 5 Alpha\n+description: Get started with the latest Alpha version of the AI SDK.\n+---\n+\n+# AI SDK 5 - Alpha\n+\n+<Note>\n+  This is an early preview \u2014 AI SDK 5 is under active development. APIs may\n+  change without notice. Pin production to v4 (ai@^4).\n+</Note>\n+\n+## Installation",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2091033004",
        "repo_full_name": "vercel/ai",
        "pr_number": 6337,
        "pr_file": "content/docs/02-getting-started/00-alpha.mdx",
        "discussion_id": "2091033004",
        "commented_code": "@@ -0,0 +1,212 @@\n+---\n+title: AI SDK 5 Alpha\n+description: Get started with the latest Alpha version of the AI SDK.\n+---\n+\n+# AI SDK 5 - Alpha\n+\n+<Note>\n+  This is an early preview \u2014 AI SDK 5 is under active development. APIs may\n+  change without notice. Pin production to v4 (ai@^4).\n+</Note>\n+\n+## Installation",
        "comment_created_at": "2025-05-15T12:13:04+00:00",
        "comment_author": "lgrammel",
        "comment_body": "need to set expectations:\r\n\r\n- only for green-field prototypes (no migrations yet)\r\n- not for production use\r\n- please provide feedback\r\n- expect large breaking changes while in alpha",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2040707730",
    "pr_number": 5722,
    "pr_file": "content/providers/01-ai-sdk-providers/03-azure.mdx",
    "created_at": "2025-04-12T17:46:16+00:00",
    "commented_code": "When creating your Azure OpenAI deployment, make sure to set the DALL-E model\n   version you want to use.\n </Note>\n+\n+## Transcription Models\n+\n+You can create models that call the Azure OpenAI transcription API using the `.transcription()` factory method.\n+\n+The first argument is the model id e.g. `whisper-1`.\n+\n+```ts\n+const model = azure.transcription('whisper-1');\n+```\n+\n+You can also pass additional provider-specific options using the `providerOptions` argument. For example, supplying the input language in ISO-639-1 (e.g. `en`) format will improve accuracy and latency.\n+\n+```ts highlight=\"6\"\n+import { experimental_transcribe as transcribe } from 'ai';\n+import { azure } from '@ai-sdk/azure';\n+\n+const result = await transcribe({\n+  model: azure.transcription('whisper-1'),\n+  audio: new Uint8Array([1, 2, 3, 4]),",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2040707730",
        "repo_full_name": "vercel/ai",
        "pr_number": 5722,
        "pr_file": "content/providers/01-ai-sdk-providers/03-azure.mdx",
        "discussion_id": "2040707730",
        "commented_code": "@@ -514,3 +514,58 @@ Azure OpenAI supports DALL-E 2 and DALL-E 3 models through deployments. The capa\n   When creating your Azure OpenAI deployment, make sure to set the DALL-E model\n   version you want to use.\n </Note>\n+\n+## Transcription Models\n+\n+You can create models that call the Azure OpenAI transcription API using the `.transcription()` factory method.\n+\n+The first argument is the model id e.g. `whisper-1`.\n+\n+```ts\n+const model = azure.transcription('whisper-1');\n+```\n+\n+You can also pass additional provider-specific options using the `providerOptions` argument. For example, supplying the input language in ISO-639-1 (e.g. `en`) format will improve accuracy and latency.\n+\n+```ts highlight=\"6\"\n+import { experimental_transcribe as transcribe } from 'ai';\n+import { azure } from '@ai-sdk/azure';\n+\n+const result = await transcribe({\n+  model: azure.transcription('whisper-1'),\n+  audio: new Uint8Array([1, 2, 3, 4]),",
        "comment_created_at": "2025-04-12T17:46:16+00:00",
        "comment_author": "samdenty",
        "comment_body": "should we maybe show a fs.readFile example so they can copy paste?",
        "pr_file_module": null
      }
    ]
  }
]