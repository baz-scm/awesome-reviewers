[
  {
    "discussion_id": "1732269254",
    "pr_number": 2806,
    "pr_file": "content/docs/08-troubleshooting/05-ai-sdk-errors/api-call-error.mdx",
    "created_at": "2024-08-27T07:11:02+00:00",
    "commented_code": "+---\n+title: APICallError\n+description: Error thrown during a failed API call\n+---\n+\n+# APICallError\n+\n+## When This Error Occurs\n+\n+The `APICallError` occurs when there's an issue during an API call made by the SDK. This can happen in various scenarios, such as:\n+\n+1. Network connectivity problems\n+2. Server-side errors\n+3. Rate limiting or request timeouts\n+4. Invalid requests or authentication issues",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "1732269254",
        "repo_full_name": "vercel/ai",
        "pr_number": 2806,
        "pr_file": "content/docs/08-troubleshooting/05-ai-sdk-errors/api-call-error.mdx",
        "discussion_id": "1732269254",
        "commented_code": "@@ -0,0 +1,60 @@\n+---\n+title: APICallError\n+description: Error thrown during a failed API call\n+---\n+\n+# APICallError\n+\n+## When This Error Occurs\n+\n+The `APICallError` occurs when there's an issue during an API call made by the SDK. This can happen in various scenarios, such as:\n+\n+1. Network connectivity problems\n+2. Server-side errors\n+3. Rate limiting or request timeouts\n+4. Invalid requests or authentication issues",
        "comment_created_at": "2024-08-27T07:11:02+00:00",
        "comment_author": "lgrammel",
        "comment_body": "While this is generally true, it is really a misleading explanation.\r\n\r\nThis happens when a provider API returns with an error. Most of the time, this means that there API cannot be used in this way, e.g. invalid message structure. The user needs to carefully read the actual error message from the provider and figure out what to do.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2082994928",
    "pr_number": 6261,
    "pr_file": "content/providers/01-ai-sdk-providers/15-google-generative-ai.mdx",
    "created_at": "2025-05-10T07:27:45+00:00",
    "commented_code": "See [File Parts](/docs/foundations/prompts#file-parts) for details on how to use files in prompts.\n \n+### Reasoning (Thinking Tokens)\n+\n+Certain Google Gemini models support emitting \"thinking\" tokens, which represent the model's reasoning process before generating the final response. The AI SDK exposes these as reasoning information.\n+\n+To enable thinking tokens, set `includeThoughts: true` in the `thinkingConfig` provider option:\n+\n+```ts\n+import { google } from '@ai-sdk/google';\n+import { GoogleGenerativeAIProviderOptions } from '@ai-sdk/google';\n+import { generateText, streamText } from 'ai';\n+\n+// For generateText:\n+const { text, reasoning, reasoningDetails } = await generateText({\n+  model: google('gemini-2.5-flash-preview-04-17'), // Or other supported model\n+  providerOptions: {\n+    google: {\n+      thinkingConfig: {\n+        includeThoughts: true,\n+        // thinkingBudget: 2048, // Optional\n+      },\n+    } satisfies GoogleGenerativeAIProviderOptions,\n+  },\n+  prompt: 'Explain quantum computing in simple terms.',\n+});\n+\n+console.log('Reasoning:', reasoning);\n+console.log('Reasoning Details:', reasoningDetails);\n+console.log('Final Text:', text);\n+\n+// For streamText:\n+const result = streamText({\n+  model: google('gemini-2.5-flash-preview-04-17'), // Or other supported model\n+  providerOptions: {\n+    google: {\n+      thinkingConfig: {\n+        includeThoughts: true,\n+        // thinkingBudget: 2048, // Optional\n+      },\n+    } satisfies GoogleGenerativeAIProviderOptions,\n+  },\n+  prompt: 'Explain quantum computing in simple terms.',\n+});\n+\n+for await (const part of result.fullStream) {\n+  if (part.type === 'reasoning') {\n+    process.stdout.write(`THOUGHT: ${part.textDelta}\n`);\n+  } else if (part.type === 'text-delta') {\n+    process.stdout.write(part.textDelta);\n+  }\n+}\n+```\n+\n+When `includeThoughts` is true, parts of the API response marked with `thought: true` will be processed as reasoning.\n+\n+- In `generateText`, these contribute to the `reasoning` (string) and `reasoningDetails` (array) fields.\n+- In `streamText`, these are emitted as `reasoning` stream parts.\n+\n+<Note>\n+  Refer to the [Google Generative AI\n+  documentation](https://ai.google.dev/gemini-api/docs/thinking) for a list of\n+  models that support thinking tokens and for more details on `thinkingBudget`.\n+</Note>\n+",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2082994928",
        "repo_full_name": "vercel/ai",
        "pr_number": 6261,
        "pr_file": "content/providers/01-ai-sdk-providers/15-google-generative-ai.mdx",
        "discussion_id": "2082994928",
        "commented_code": "@@ -238,6 +243,69 @@ const result = await generateText({\n \n See [File Parts](/docs/foundations/prompts#file-parts) for details on how to use files in prompts.\n \n+### Reasoning (Thinking Tokens)\n+\n+Certain Google Gemini models support emitting \"thinking\" tokens, which represent the model's reasoning process before generating the final response. The AI SDK exposes these as reasoning information.\n+\n+To enable thinking tokens, set `includeThoughts: true` in the `thinkingConfig` provider option:\n+\n+```ts\n+import { google } from '@ai-sdk/google';\n+import { GoogleGenerativeAIProviderOptions } from '@ai-sdk/google';\n+import { generateText, streamText } from 'ai';\n+\n+// For generateText:\n+const { text, reasoning, reasoningDetails } = await generateText({\n+  model: google('gemini-2.5-flash-preview-04-17'), // Or other supported model\n+  providerOptions: {\n+    google: {\n+      thinkingConfig: {\n+        includeThoughts: true,\n+        // thinkingBudget: 2048, // Optional\n+      },\n+    } satisfies GoogleGenerativeAIProviderOptions,\n+  },\n+  prompt: 'Explain quantum computing in simple terms.',\n+});\n+\n+console.log('Reasoning:', reasoning);\n+console.log('Reasoning Details:', reasoningDetails);\n+console.log('Final Text:', text);\n+\n+// For streamText:\n+const result = streamText({\n+  model: google('gemini-2.5-flash-preview-04-17'), // Or other supported model\n+  providerOptions: {\n+    google: {\n+      thinkingConfig: {\n+        includeThoughts: true,\n+        // thinkingBudget: 2048, // Optional\n+      },\n+    } satisfies GoogleGenerativeAIProviderOptions,\n+  },\n+  prompt: 'Explain quantum computing in simple terms.',\n+});\n+\n+for await (const part of result.fullStream) {\n+  if (part.type === 'reasoning') {\n+    process.stdout.write(`THOUGHT: ${part.textDelta}\\n`);\n+  } else if (part.type === 'text-delta') {\n+    process.stdout.write(part.textDelta);\n+  }\n+}\n+```\n+\n+When `includeThoughts` is true, parts of the API response marked with `thought: true` will be processed as reasoning.\n+\n+- In `generateText`, these contribute to the `reasoning` (string) and `reasoningDetails` (array) fields.\n+- In `streamText`, these are emitted as `reasoning` stream parts.\n+\n+<Note>\n+  Refer to the [Google Generative AI\n+  documentation](https://ai.google.dev/gemini-api/docs/thinking) for a list of\n+  models that support thinking tokens and for more details on `thinkingBudget`.\n+</Note>\n+",
        "comment_created_at": "2025-05-10T07:27:45+00:00",
        "comment_author": "lgrammel",
        "comment_body": "@Und3rf10w have you tested this with the gemini api? couldn't find it in their docs",
        "pr_file_module": null
      },
      {
        "comment_id": "2083230207",
        "repo_full_name": "vercel/ai",
        "pr_number": 6261,
        "pr_file": "content/providers/01-ai-sdk-providers/15-google-generative-ai.mdx",
        "discussion_id": "2082994928",
        "commented_code": "@@ -238,6 +243,69 @@ const result = await generateText({\n \n See [File Parts](/docs/foundations/prompts#file-parts) for details on how to use files in prompts.\n \n+### Reasoning (Thinking Tokens)\n+\n+Certain Google Gemini models support emitting \"thinking\" tokens, which represent the model's reasoning process before generating the final response. The AI SDK exposes these as reasoning information.\n+\n+To enable thinking tokens, set `includeThoughts: true` in the `thinkingConfig` provider option:\n+\n+```ts\n+import { google } from '@ai-sdk/google';\n+import { GoogleGenerativeAIProviderOptions } from '@ai-sdk/google';\n+import { generateText, streamText } from 'ai';\n+\n+// For generateText:\n+const { text, reasoning, reasoningDetails } = await generateText({\n+  model: google('gemini-2.5-flash-preview-04-17'), // Or other supported model\n+  providerOptions: {\n+    google: {\n+      thinkingConfig: {\n+        includeThoughts: true,\n+        // thinkingBudget: 2048, // Optional\n+      },\n+    } satisfies GoogleGenerativeAIProviderOptions,\n+  },\n+  prompt: 'Explain quantum computing in simple terms.',\n+});\n+\n+console.log('Reasoning:', reasoning);\n+console.log('Reasoning Details:', reasoningDetails);\n+console.log('Final Text:', text);\n+\n+// For streamText:\n+const result = streamText({\n+  model: google('gemini-2.5-flash-preview-04-17'), // Or other supported model\n+  providerOptions: {\n+    google: {\n+      thinkingConfig: {\n+        includeThoughts: true,\n+        // thinkingBudget: 2048, // Optional\n+      },\n+    } satisfies GoogleGenerativeAIProviderOptions,\n+  },\n+  prompt: 'Explain quantum computing in simple terms.',\n+});\n+\n+for await (const part of result.fullStream) {\n+  if (part.type === 'reasoning') {\n+    process.stdout.write(`THOUGHT: ${part.textDelta}\\n`);\n+  } else if (part.type === 'text-delta') {\n+    process.stdout.write(part.textDelta);\n+  }\n+}\n+```\n+\n+When `includeThoughts` is true, parts of the API response marked with `thought: true` will be processed as reasoning.\n+\n+- In `generateText`, these contribute to the `reasoning` (string) and `reasoningDetails` (array) fields.\n+- In `streamText`, these are emitted as `reasoning` stream parts.\n+\n+<Note>\n+  Refer to the [Google Generative AI\n+  documentation](https://ai.google.dev/gemini-api/docs/thinking) for a list of\n+  models that support thinking tokens and for more details on `thinkingBudget`.\n+</Note>\n+",
        "comment_created_at": "2025-05-10T16:17:48+00:00",
        "comment_author": "Und3rf10w",
        "comment_body": "@lgrammel, I have not directly, but I'm making the assumption it works for the gemini API based off of this Google Provided Notebook: https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Get_started_thinking.ipynb\r\n\r\nI HAVE successfully tested this with the Vertex API.\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2083255546",
        "repo_full_name": "vercel/ai",
        "pr_number": 6261,
        "pr_file": "content/providers/01-ai-sdk-providers/15-google-generative-ai.mdx",
        "discussion_id": "2082994928",
        "commented_code": "@@ -238,6 +243,69 @@ const result = await generateText({\n \n See [File Parts](/docs/foundations/prompts#file-parts) for details on how to use files in prompts.\n \n+### Reasoning (Thinking Tokens)\n+\n+Certain Google Gemini models support emitting \"thinking\" tokens, which represent the model's reasoning process before generating the final response. The AI SDK exposes these as reasoning information.\n+\n+To enable thinking tokens, set `includeThoughts: true` in the `thinkingConfig` provider option:\n+\n+```ts\n+import { google } from '@ai-sdk/google';\n+import { GoogleGenerativeAIProviderOptions } from '@ai-sdk/google';\n+import { generateText, streamText } from 'ai';\n+\n+// For generateText:\n+const { text, reasoning, reasoningDetails } = await generateText({\n+  model: google('gemini-2.5-flash-preview-04-17'), // Or other supported model\n+  providerOptions: {\n+    google: {\n+      thinkingConfig: {\n+        includeThoughts: true,\n+        // thinkingBudget: 2048, // Optional\n+      },\n+    } satisfies GoogleGenerativeAIProviderOptions,\n+  },\n+  prompt: 'Explain quantum computing in simple terms.',\n+});\n+\n+console.log('Reasoning:', reasoning);\n+console.log('Reasoning Details:', reasoningDetails);\n+console.log('Final Text:', text);\n+\n+// For streamText:\n+const result = streamText({\n+  model: google('gemini-2.5-flash-preview-04-17'), // Or other supported model\n+  providerOptions: {\n+    google: {\n+      thinkingConfig: {\n+        includeThoughts: true,\n+        // thinkingBudget: 2048, // Optional\n+      },\n+    } satisfies GoogleGenerativeAIProviderOptions,\n+  },\n+  prompt: 'Explain quantum computing in simple terms.',\n+});\n+\n+for await (const part of result.fullStream) {\n+  if (part.type === 'reasoning') {\n+    process.stdout.write(`THOUGHT: ${part.textDelta}\\n`);\n+  } else if (part.type === 'text-delta') {\n+    process.stdout.write(part.textDelta);\n+  }\n+}\n+```\n+\n+When `includeThoughts` is true, parts of the API response marked with `thought: true` will be processed as reasoning.\n+\n+- In `generateText`, these contribute to the `reasoning` (string) and `reasoningDetails` (array) fields.\n+- In `streamText`, these are emitted as `reasoning` stream parts.\n+\n+<Note>\n+  Refer to the [Google Generative AI\n+  documentation](https://ai.google.dev/gemini-api/docs/thinking) for a list of\n+  models that support thinking tokens and for more details on `thinkingBudget`.\n+</Note>\n+",
        "comment_created_at": "2025-05-10T17:43:01+00:00",
        "comment_author": "Und3rf10w",
        "comment_body": "@lgrammel,\r\n\r\nI tried a variation of https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Get_started_thinking.ipynb with a valid API key, and it turns out the GEMINI api doesn't yet OFFICIALLY support (read: documented) `includeThoughts`.\r\n\r\nLooking at the proto definitions for the python client, `include_thoughts` isn't yet supported: (documented) https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.types.GenerationConfig.ThinkingConfig\r\n\r\nCompare this to the vertex api documentation, where `includeThoughts` IS supported: https://cloud.google.com/vertex-ai/generative-ai/docs/reference/rest/v1/GenerationConfig#ThinkingConfig\r\n\r\nHowever, trying this in the notebook, we can see when we set a `thinkingBudget` and `includeThoughts`, the request IS valid, but it doesn't return thought candidates, despite using thinking tokens:\r\n\r\n<img width=\"1079\" alt=\"image\" src=\"https://github.com/user-attachments/assets/1ebf0780-331d-469b-baa5-6c272656f402\" />\r\n\r\n<img width=\"1219\" alt=\"image\" src=\"https://github.com/user-attachments/assets/6dc5458c-08bd-471a-83f2-f8209181e42d\" />\r\n\r\n---\r\n\r\nSo I suppose, in the Google Generative API, it WON'T provide the thoughts, but the request will still work likely it will eventually be supported. We should probably just remove the [15-google-generative-ai.mdx](https://github.com/vercel/ai/pull/6261/files/c1264af0b981b44dc2254b9e6674c2dc39566b97#diff-9708c5f7984a6b6aa554bcb69e7fafb96b5b4dc80d91db3f1d18fab1cbebacda) file edits for now?\r\n\r\n---\r\n\r\nHere's more photos playing around with the `ThinkingConfig`:\r\n\r\n<img width=\"880\" alt=\"image\" src=\"https://github.com/user-attachments/assets/f8fa556c-b629-4a93-aaab-c57899787353\" />\r\n\r\n<img width=\"1718\" alt=\"image\" src=\"https://github.com/user-attachments/assets/a9475094-c6b5-42a3-9123-765d5828708c\" />\r\n\r\n<img width=\"1716\" alt=\"image\" src=\"https://github.com/user-attachments/assets/57e006df-ff3d-4438-b9e8-5d81be4c0e9f\" />\r\n\r\n\r\n---\r\n\r\nTL;DR: While the parameter `include_thoughts` works on the Google Generative AI platform, it doesn't currently return the thought tokens from the response. It does work as expected in Vertex AI. Likely way forward is to remove the edits to [15-google-generative-ai.mdx](https://github.com/vercel/ai/pull/6261/files/c1264af0b981b44dc2254b9e6674c2dc39566b97#diff-9708c5f7984a6b6aa554bcb69e7fafb96b5b4dc80d91db3f1d18fab1cbebacda) from this PR.\r\n\r\nMaybe also:\r\n- Update changeset to be `@ai-sdk/vertex` instead of `@ai-sdk/google`\r\n- Throw a warning when `includeThoughts` is specified with an `@ai-sdk/google` provider for now? To be removed if/when that's specified?",
        "pr_file_module": null
      },
      {
        "comment_id": "2083280425",
        "repo_full_name": "vercel/ai",
        "pr_number": 6261,
        "pr_file": "content/providers/01-ai-sdk-providers/15-google-generative-ai.mdx",
        "discussion_id": "2082994928",
        "commented_code": "@@ -238,6 +243,69 @@ const result = await generateText({\n \n See [File Parts](/docs/foundations/prompts#file-parts) for details on how to use files in prompts.\n \n+### Reasoning (Thinking Tokens)\n+\n+Certain Google Gemini models support emitting \"thinking\" tokens, which represent the model's reasoning process before generating the final response. The AI SDK exposes these as reasoning information.\n+\n+To enable thinking tokens, set `includeThoughts: true` in the `thinkingConfig` provider option:\n+\n+```ts\n+import { google } from '@ai-sdk/google';\n+import { GoogleGenerativeAIProviderOptions } from '@ai-sdk/google';\n+import { generateText, streamText } from 'ai';\n+\n+// For generateText:\n+const { text, reasoning, reasoningDetails } = await generateText({\n+  model: google('gemini-2.5-flash-preview-04-17'), // Or other supported model\n+  providerOptions: {\n+    google: {\n+      thinkingConfig: {\n+        includeThoughts: true,\n+        // thinkingBudget: 2048, // Optional\n+      },\n+    } satisfies GoogleGenerativeAIProviderOptions,\n+  },\n+  prompt: 'Explain quantum computing in simple terms.',\n+});\n+\n+console.log('Reasoning:', reasoning);\n+console.log('Reasoning Details:', reasoningDetails);\n+console.log('Final Text:', text);\n+\n+// For streamText:\n+const result = streamText({\n+  model: google('gemini-2.5-flash-preview-04-17'), // Or other supported model\n+  providerOptions: {\n+    google: {\n+      thinkingConfig: {\n+        includeThoughts: true,\n+        // thinkingBudget: 2048, // Optional\n+      },\n+    } satisfies GoogleGenerativeAIProviderOptions,\n+  },\n+  prompt: 'Explain quantum computing in simple terms.',\n+});\n+\n+for await (const part of result.fullStream) {\n+  if (part.type === 'reasoning') {\n+    process.stdout.write(`THOUGHT: ${part.textDelta}\\n`);\n+  } else if (part.type === 'text-delta') {\n+    process.stdout.write(part.textDelta);\n+  }\n+}\n+```\n+\n+When `includeThoughts` is true, parts of the API response marked with `thought: true` will be processed as reasoning.\n+\n+- In `generateText`, these contribute to the `reasoning` (string) and `reasoningDetails` (array) fields.\n+- In `streamText`, these are emitted as `reasoning` stream parts.\n+\n+<Note>\n+  Refer to the [Google Generative AI\n+  documentation](https://ai.google.dev/gemini-api/docs/thinking) for a list of\n+  models that support thinking tokens and for more details on `thinkingBudget`.\n+</Note>\n+",
        "comment_created_at": "2025-05-10T20:04:12+00:00",
        "comment_author": "Und3rf10w",
        "comment_body": "Updated with [6586ef2](https://github.com/vercel/ai/pull/6261/commits/6586ef24fe06baec0fb2f1324e965a0cf901f25a). \r\n\r\n- Now add a warning when `includeThoughts` is used with the `google` provider \r\n- added a test for above \r\n- removed `includeThoughts` addition from Google provider.\r\n- Added a `generateText` example.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2026622935",
    "pr_number": 5496,
    "pr_file": "content/docs/03-ai-sdk-core/36-transcription.mdx",
    "created_at": "2025-04-03T09:50:40+00:00",
    "commented_code": "+---\n+title: Transcription\n+description: Learn how to transcribe audio with the AI SDK.\n+---\n+\n+# Transcription\n+\n+<Note type=\"warning\">Transcription is an experimental feature.</Note>\n+\n+The AI SDK provides the [`generateTranscript`](/docs/reference/ai-sdk-core/generate-transcript)\n+function to transcribe audio using a transcription model.\n+\n+```tsx\n+import { experimental_generateTranscript as generateTranscript } from 'ai';\n+import { openai } from '@ai-sdk/openai';\n+\n+const { transcript } = await generateTranscript({\n+  model: openai.transcription('whisper-1'),\n+  audio: audioData,",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2026622935",
        "repo_full_name": "vercel/ai",
        "pr_number": 5496,
        "pr_file": "content/docs/03-ai-sdk-core/36-transcription.mdx",
        "discussion_id": "2026622935",
        "commented_code": "@@ -0,0 +1,138 @@\n+---\n+title: Transcription\n+description: Learn how to transcribe audio with the AI SDK.\n+---\n+\n+# Transcription\n+\n+<Note type=\"warning\">Transcription is an experimental feature.</Note>\n+\n+The AI SDK provides the [`generateTranscript`](/docs/reference/ai-sdk-core/generate-transcript)\n+function to transcribe audio using a transcription model.\n+\n+```tsx\n+import { experimental_generateTranscript as generateTranscript } from 'ai';\n+import { openai } from '@ai-sdk/openai';\n+\n+const { transcript } = await generateTranscript({\n+  model: openai.transcription('whisper-1'),\n+  audio: audioData,",
        "comment_created_at": "2025-04-03T09:50:40+00:00",
        "comment_author": "nicoalbanese",
        "comment_body": "wonder if we can make this more copy and pasteable? e.g. pointing to a hosted url in the repo or in the local filesystem with a .mp3/.wav so it's easily replaceable?\r\n\r\nthoughts @lgrammel ?",
        "pr_file_module": null
      },
      {
        "comment_id": "2028147068",
        "repo_full_name": "vercel/ai",
        "pr_number": 5496,
        "pr_file": "content/docs/03-ai-sdk-core/36-transcription.mdx",
        "discussion_id": "2026622935",
        "commented_code": "@@ -0,0 +1,138 @@\n+---\n+title: Transcription\n+description: Learn how to transcribe audio with the AI SDK.\n+---\n+\n+# Transcription\n+\n+<Note type=\"warning\">Transcription is an experimental feature.</Note>\n+\n+The AI SDK provides the [`generateTranscript`](/docs/reference/ai-sdk-core/generate-transcript)\n+function to transcribe audio using a transcription model.\n+\n+```tsx\n+import { experimental_generateTranscript as generateTranscript } from 'ai';\n+import { openai } from '@ai-sdk/openai';\n+\n+const { transcript } = await generateTranscript({\n+  model: openai.transcription('whisper-1'),\n+  audio: audioData,",
        "comment_created_at": "2025-04-04T06:05:49+00:00",
        "comment_author": "lgrammel",
        "comment_body": "I guess we can add the fs.readFile from the executable example",
        "pr_file_module": null
      }
    ]
  }
]