[
  {
    "discussion_id": "2192159541",
    "pr_number": 7119,
    "pr_file": "content/providers/01-ai-sdk-providers/70-perplexity.mdx",
    "created_at": "2025-07-08T10:52:39+00:00",
    "commented_code": "});\n ```\n \n+Perplexity language models can also be used in the `streamText`, `generateObject`, and `streamObject` functions\n+(see [AI SDK Core](/docs/ai-sdk-core)).\n+",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2192159541",
        "repo_full_name": "vercel/ai",
        "pr_number": 7119,
        "pr_file": "content/providers/01-ai-sdk-providers/70-perplexity.mdx",
        "discussion_id": "2192159541",
        "commented_code": "@@ -77,6 +77,9 @@ const { text } = await generateText({\n });\n ```\n \n+Perplexity language models can also be used in the `streamText`, `generateObject`, and `streamObject` functions\n+(see [AI SDK Core](/docs/ai-sdk-core)).\n+",
        "comment_created_at": "2025-07-08T10:52:39+00:00",
        "comment_author": "nicoalbanese",
        "comment_body": "I would remove this - think default expectation is that a provider works across functions and that we explicitly state if it doesn't support a function.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2182496900",
    "pr_number": 7017,
    "pr_file": "content/providers/01-ai-sdk-providers/09-groq.mdx",
    "created_at": "2025-07-03T11:01:35+00:00",
    "commented_code": "});\n ```\n \n+### Image Input\n+\n+Groq's multimodal models like `meta-llama/llama-4-scout-17b-16e-instruct` support image inputs. You can include images in your messages using either URLs or base64-encoded data:",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2182496900",
        "repo_full_name": "vercel/ai",
        "pr_number": 7017,
        "pr_file": "content/providers/01-ai-sdk-providers/09-groq.mdx",
        "discussion_id": "2182496900",
        "commented_code": "@@ -110,6 +128,57 @@ const { text } = await generateText({\n });\n ```\n \n+### Image Input\n+\n+Groq's multimodal models like `meta-llama/llama-4-scout-17b-16e-instruct` support image inputs. You can include images in your messages using either URLs or base64-encoded data:",
        "comment_created_at": "2025-07-03T11:01:35+00:00",
        "comment_author": "nicoalbanese",
        "comment_body": "```suggestion\nGroq's multi-modal models like `meta-llama/llama-4-scout-17b-16e-instruct` support image inputs. You can include images in your messages using either URLs or base64-encoded data:\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2056893001",
    "pr_number": 5938,
    "pr_file": "content/docs/03-ai-sdk-core/35-image-generation.mdx",
    "created_at": "2025-04-23T21:25:28+00:00",
    "commented_code": "| Provider                                                                  | Model                                                        | Support sizes (`width x height`) or aspect ratios (`width : height`)                                                                                                |\n | ------------------------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n | [xAI Grok](/providers/ai-sdk-providers/xai#image-models)                  | `grok-2-image`                                               | 1024x768 (default)                                                                                                                                                  |\n+| [OpenAI](/providers/ai-sdk-providers/openai#image-models)                 | `gpt-image-1`                                                | 1024x1024, 1536x1024, 1024x1536                                                                                                                                     |",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2056893001",
        "repo_full_name": "vercel/ai",
        "pr_number": 5938,
        "pr_file": "content/docs/03-ai-sdk-core/35-image-generation.mdx",
        "discussion_id": "2056893001",
        "commented_code": "@@ -243,6 +243,7 @@ for (const file of result.files) {\n | Provider                                                                  | Model                                                        | Support sizes (`width x height`) or aspect ratios (`width : height`)                                                                                                |\n | ------------------------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n | [xAI Grok](/providers/ai-sdk-providers/xai#image-models)                  | `grok-2-image`                                               | 1024x768 (default)                                                                                                                                                  |\n+| [OpenAI](/providers/ai-sdk-providers/openai#image-models)                 | `gpt-image-1`                                                | 1024x1024, 1536x1024, 1024x1536                                                                                                                                     |",
        "comment_created_at": "2025-04-23T21:25:28+00:00",
        "comment_author": "samdenty",
        "comment_body": "> 1024x1024, 1536x1024, 1024x1536\r\n\r\ndo you have a link to this data?",
        "pr_file_module": null
      },
      {
        "comment_id": "2056913555",
        "repo_full_name": "vercel/ai",
        "pr_number": 5938,
        "pr_file": "content/docs/03-ai-sdk-core/35-image-generation.mdx",
        "discussion_id": "2056893001",
        "commented_code": "@@ -243,6 +243,7 @@ for (const file of result.files) {\n | Provider                                                                  | Model                                                        | Support sizes (`width x height`) or aspect ratios (`width : height`)                                                                                                |\n | ------------------------------------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n | [xAI Grok](/providers/ai-sdk-providers/xai#image-models)                  | `grok-2-image`                                               | 1024x768 (default)                                                                                                                                                  |\n+| [OpenAI](/providers/ai-sdk-providers/openai#image-models)                 | `gpt-image-1`                                                | 1024x1024, 1536x1024, 1024x1536                                                                                                                                     |",
        "comment_created_at": "2025-04-23T21:47:14+00:00",
        "comment_author": "shaper",
        "comment_body": "https://platform.openai.com/docs/api-reference/images/create#images-create-size",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2047469004",
    "pr_number": 5811,
    "pr_file": "content/providers/01-ai-sdk-providers/02-openai.mdx",
    "created_at": "2025-04-16T18:12:22+00:00",
    "commented_code": "#### Reasoning\n \n-OpenAI has introduced the `o1` and `o3` series of [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n-Currently, `o3-mini`, `o1`, `o1-mini`, and `o1-preview` are available.\n+OpenAI has introduced the `o1`,`o3`, and `o4` series of [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n+Currently, `o4`, `o3`, `o3-mini`, `o1`, `o1-mini`, and `o1-preview` are available.",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2047469004",
        "repo_full_name": "vercel/ai",
        "pr_number": 5811,
        "pr_file": "content/providers/01-ai-sdk-providers/02-openai.mdx",
        "discussion_id": "2047469004",
        "commented_code": "@@ -220,8 +220,8 @@ The following optional settings are available for OpenAI chat models:\n \n #### Reasoning\n \n-OpenAI has introduced the `o1` and `o3` series of [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n-Currently, `o3-mini`, `o1`, `o1-mini`, and `o1-preview` are available.\n+OpenAI has introduced the `o1`,`o3`, and `o4` series of [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n+Currently, `o4`, `o3`, `o3-mini`, `o1`, `o1-mini`, and `o1-preview` are available.",
        "comment_created_at": "2025-04-16T18:12:22+00:00",
        "comment_author": "tobiasbueschel",
        "comment_body": "Small correction => `o4` is not publicly available yet, but `o4-mini` is: \r\n\r\nSources:\r\n- https://platform.openai.com/docs/models/compare\r\n- https://openai.com/index/introducing-o3-and-o4-mini/",
        "pr_file_module": null
      },
      {
        "comment_id": "2047470853",
        "repo_full_name": "vercel/ai",
        "pr_number": 5811,
        "pr_file": "content/providers/01-ai-sdk-providers/02-openai.mdx",
        "discussion_id": "2047469004",
        "commented_code": "@@ -220,8 +220,8 @@ The following optional settings are available for OpenAI chat models:\n \n #### Reasoning\n \n-OpenAI has introduced the `o1` and `o3` series of [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n-Currently, `o3-mini`, `o1`, `o1-mini`, and `o1-preview` are available.\n+OpenAI has introduced the `o1`,`o3`, and `o4` series of [reasoning models](https://platform.openai.com/docs/guides/reasoning).\n+Currently, `o4`, `o3`, `o3-mini`, `o1`, `o1-mini`, and `o1-preview` are available.",
        "comment_created_at": "2025-04-16T18:13:36+00:00",
        "comment_author": "nicoalbanese",
        "comment_body": "ah great spot!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2036880852",
    "pr_number": 5649,
    "pr_file": "content/docs/03-ai-sdk-core/37-speech.mdx",
    "created_at": "2025-04-10T09:07:27+00:00",
    "commented_code": "+---\n+title: Speech\n+description: Learn how to generate speech from text with the AI SDK.\n+---\n+\n+# Speech\n+\n+<Note type=\"warning\">Speech is an experimental feature.</Note>\n+\n+The AI SDK provides the [`speak`](/docs/reference/ai-sdk-core/speak)\n+function to generate speech from text using a speech model.\n+\n+```ts\n+import { experimental_speak as speak } from 'ai';\n+import { openai } from '@ai-sdk/openai';\n+import { readFile } from 'fs/promises';\n+\n+const audio = await speak({\n+  model: openai.speech('tts-1'),\n+  text: 'Hello, world!',\n+});\n+```\n+\n+To access the generated audio:\n+\n+```ts\n+const audio = audio.audioData; // audio data e.g. Uint8Array\n+```\n+\n+## Settings\n+\n+### Provider-Specific settings\n+\n+Speech models often have provider or model-specific settings which you can set using the `providerOptions` parameter.",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2036880852",
        "repo_full_name": "vercel/ai",
        "pr_number": 5649,
        "pr_file": "content/docs/03-ai-sdk-core/37-speech.mdx",
        "discussion_id": "2036880852",
        "commented_code": "@@ -0,0 +1,145 @@\n+---\n+title: Speech\n+description: Learn how to generate speech from text with the AI SDK.\n+---\n+\n+# Speech\n+\n+<Note type=\"warning\">Speech is an experimental feature.</Note>\n+\n+The AI SDK provides the [`speak`](/docs/reference/ai-sdk-core/speak)\n+function to generate speech from text using a speech model.\n+\n+```ts\n+import { experimental_speak as speak } from 'ai';\n+import { openai } from '@ai-sdk/openai';\n+import { readFile } from 'fs/promises';\n+\n+const audio = await speak({\n+  model: openai.speech('tts-1'),\n+  text: 'Hello, world!',\n+});\n+```\n+\n+To access the generated audio:\n+\n+```ts\n+const audio = audio.audioData; // audio data e.g. Uint8Array\n+```\n+\n+## Settings\n+\n+### Provider-Specific settings\n+\n+Speech models often have provider or model-specific settings which you can set using the `providerOptions` parameter.",
        "comment_created_at": "2025-04-10T09:07:27+00:00",
        "comment_author": "nicoalbanese",
        "comment_body": "```suggestion\r\nYou can set model-specific settings with the `providerOptions` parameter.\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2026621065",
    "pr_number": 5496,
    "pr_file": "content/docs/03-ai-sdk-core/36-transcription.mdx",
    "created_at": "2025-04-03T09:49:33+00:00",
    "commented_code": "+---\n+title: Transcription\n+description: Learn how to transcribe audio with the AI SDK.\n+---\n+\n+# Transcription\n+\n+<Note type=\"warning\">Transcription is an experimental feature.</Note>\n+\n+The AI SDK provides the [`generateTranscript`](/docs/reference/ai-sdk-core/generate-transcript)\n+function to transcribe audio using a transcription model.\n+\n+```tsx\n+import { experimental_generateTranscript as generateTranscript } from 'ai';\n+import { openai } from '@ai-sdk/openai';\n+\n+const { transcript } = await generateTranscript({\n+  model: openai.transcription('whisper-1'),\n+  audio: audioData,\n+});\n+```\n+\n+The `audio` property is very flexible and can be a `Blob`, `File`, `Uint8Array`, `ArrayBuffer`, `Buffer`, `URL` or a string (e.g. a URL or base64 encoded data).",
    "repo_full_name": "vercel/ai",
    "discussion_comments": [
      {
        "comment_id": "2026621065",
        "repo_full_name": "vercel/ai",
        "pr_number": 5496,
        "pr_file": "content/docs/03-ai-sdk-core/36-transcription.mdx",
        "discussion_id": "2026621065",
        "commented_code": "@@ -0,0 +1,138 @@\n+---\n+title: Transcription\n+description: Learn how to transcribe audio with the AI SDK.\n+---\n+\n+# Transcription\n+\n+<Note type=\"warning\">Transcription is an experimental feature.</Note>\n+\n+The AI SDK provides the [`generateTranscript`](/docs/reference/ai-sdk-core/generate-transcript)\n+function to transcribe audio using a transcription model.\n+\n+```tsx\n+import { experimental_generateTranscript as generateTranscript } from 'ai';\n+import { openai } from '@ai-sdk/openai';\n+\n+const { transcript } = await generateTranscript({\n+  model: openai.transcription('whisper-1'),\n+  audio: audioData,\n+});\n+```\n+\n+The `audio` property is very flexible and can be a `Blob`, `File`, `Uint8Array`, `ArrayBuffer`, `Buffer`, `URL` or a string (e.g. a URL or base64 encoded data).",
        "comment_created_at": "2025-04-03T09:49:33+00:00",
        "comment_author": "nicoalbanese",
        "comment_body": "```suggestion\r\nThe `audio` property can be a `Blob`, `File`, `Uint8Array`, `ArrayBuffer`, `Buffer`, `URL` or a string (e.g. a URL or base64 encoded data).\r\n```",
        "pr_file_module": null
      }
    ]
  }
]