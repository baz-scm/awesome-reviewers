[
  {
    "discussion_id": "1594784899",
    "pr_number": 39496,
    "pr_file": "tests/utils/test_log_handlers.py",
    "created_at": "2024-05-08T22:54:18+00:00",
    "commented_code": "\"\"\"Test for executors which do not have `get_task_log` method, it fallbacks to reading\n         log from worker if and only if remote logs aren't found\"\"\"\n         executor_name = \"CeleryExecutor\"\n-\n-        ti = create_task_instance(\n-            dag_id=\"dag_for_testing_celery_executor_log_read\",\n-            task_id=\"task_for_testing_celery_executor_log_read\",\n-            run_type=DagRunType.SCHEDULED,\n-            execution_date=DEFAULT_DATE,\n-        )\n-        ti.state = TaskInstanceState.RUNNING\n-        ti.try_number = 2\n-        with conf_vars({(\"core\", \"executor\"): executor_name}):\n-            reload(executor_loader)\n-            fth = FileTaskHandler(\"\")\n-\n-            fth._read_from_logs_server = mock.Mock()\n-            fth._read_from_logs_server.return_value = [\"this message\"], [\"this\nlog\ncontent\"]\n-            actual = fth._read(ti=ti, try_number=2)\n-            fth._read_from_logs_server.assert_called_once()\n-            assert actual == (\"*** this message\nthis\nlog\ncontent\", {\"end_of_log\": False, \"log_pos\": 16})\n-\n-            # Previous try_number should return served logs when remote logs aren't implemented\n-            fth._read_from_logs_server = mock.Mock()\n-            fth._read_from_logs_server.return_value = [\"served logs try_number=1\"], [\"this\nlog\ncontent\"]\n-            actual = fth._read(ti=ti, try_number=1)\n-            fth._read_from_logs_server.assert_called_once()\n-            assert actual == (\n-                \"*** served logs try_number=1\nthis\nlog\ncontent\",\n-                {\"end_of_log\": True, \"log_pos\": 16},\n+        # Reading logs from worker should occur when the task is either running, deferred, or up for retry.\n+        for state in (TaskInstanceState.RUNNING, TaskInstanceState.DEFERRED, TaskInstanceState.UP_FOR_RETRY):",
    "repo_full_name": "apache/airflow",
    "discussion_comments": [
      {
        "comment_id": "1594784899",
        "repo_full_name": "apache/airflow",
        "pr_number": 39496,
        "pr_file": "tests/utils/test_log_handlers.py",
        "discussion_id": "1594784899",
        "commented_code": "@@ -317,43 +317,52 @@ def test__read_for_celery_executor_fallbacks_to_worker(self, create_task_instanc\n         \"\"\"Test for executors which do not have `get_task_log` method, it fallbacks to reading\n         log from worker if and only if remote logs aren't found\"\"\"\n         executor_name = \"CeleryExecutor\"\n-\n-        ti = create_task_instance(\n-            dag_id=\"dag_for_testing_celery_executor_log_read\",\n-            task_id=\"task_for_testing_celery_executor_log_read\",\n-            run_type=DagRunType.SCHEDULED,\n-            execution_date=DEFAULT_DATE,\n-        )\n-        ti.state = TaskInstanceState.RUNNING\n-        ti.try_number = 2\n-        with conf_vars({(\"core\", \"executor\"): executor_name}):\n-            reload(executor_loader)\n-            fth = FileTaskHandler(\"\")\n-\n-            fth._read_from_logs_server = mock.Mock()\n-            fth._read_from_logs_server.return_value = [\"this message\"], [\"this\\nlog\\ncontent\"]\n-            actual = fth._read(ti=ti, try_number=2)\n-            fth._read_from_logs_server.assert_called_once()\n-            assert actual == (\"*** this message\\nthis\\nlog\\ncontent\", {\"end_of_log\": False, \"log_pos\": 16})\n-\n-            # Previous try_number should return served logs when remote logs aren't implemented\n-            fth._read_from_logs_server = mock.Mock()\n-            fth._read_from_logs_server.return_value = [\"served logs try_number=1\"], [\"this\\nlog\\ncontent\"]\n-            actual = fth._read(ti=ti, try_number=1)\n-            fth._read_from_logs_server.assert_called_once()\n-            assert actual == (\n-                \"*** served logs try_number=1\\nthis\\nlog\\ncontent\",\n-                {\"end_of_log\": True, \"log_pos\": 16},\n+        # Reading logs from worker should occur when the task is either running, deferred, or up for retry.\n+        for state in (TaskInstanceState.RUNNING, TaskInstanceState.DEFERRED, TaskInstanceState.UP_FOR_RETRY):",
        "comment_created_at": "2024-05-08T22:54:18+00:00",
        "comment_author": "ferruzzi",
        "comment_body": "If you are wrapping the entire test in a  \"for\" loop, you should consider making it a parameterized test.  Something like this should replace your for loop without any other changes needed, and provide more useful information if one of them starts failing.\r\n\r\n\r\n```suggestion\r\n@pytest.mark.parametrize(\r\n    \"state\",\r\n    [TaskInstanceState.RUNNING, TaskInstanceState.DEFERRED, TaskInstanceState.UP_FOR_RETRY]\r\ndef test__read_for_celery_executor_fallbacks_to_worker(self, state, create_task_instance):\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1594971540",
        "repo_full_name": "apache/airflow",
        "pr_number": 39496,
        "pr_file": "tests/utils/test_log_handlers.py",
        "discussion_id": "1594784899",
        "commented_code": "@@ -317,43 +317,52 @@ def test__read_for_celery_executor_fallbacks_to_worker(self, create_task_instanc\n         \"\"\"Test for executors which do not have `get_task_log` method, it fallbacks to reading\n         log from worker if and only if remote logs aren't found\"\"\"\n         executor_name = \"CeleryExecutor\"\n-\n-        ti = create_task_instance(\n-            dag_id=\"dag_for_testing_celery_executor_log_read\",\n-            task_id=\"task_for_testing_celery_executor_log_read\",\n-            run_type=DagRunType.SCHEDULED,\n-            execution_date=DEFAULT_DATE,\n-        )\n-        ti.state = TaskInstanceState.RUNNING\n-        ti.try_number = 2\n-        with conf_vars({(\"core\", \"executor\"): executor_name}):\n-            reload(executor_loader)\n-            fth = FileTaskHandler(\"\")\n-\n-            fth._read_from_logs_server = mock.Mock()\n-            fth._read_from_logs_server.return_value = [\"this message\"], [\"this\\nlog\\ncontent\"]\n-            actual = fth._read(ti=ti, try_number=2)\n-            fth._read_from_logs_server.assert_called_once()\n-            assert actual == (\"*** this message\\nthis\\nlog\\ncontent\", {\"end_of_log\": False, \"log_pos\": 16})\n-\n-            # Previous try_number should return served logs when remote logs aren't implemented\n-            fth._read_from_logs_server = mock.Mock()\n-            fth._read_from_logs_server.return_value = [\"served logs try_number=1\"], [\"this\\nlog\\ncontent\"]\n-            actual = fth._read(ti=ti, try_number=1)\n-            fth._read_from_logs_server.assert_called_once()\n-            assert actual == (\n-                \"*** served logs try_number=1\\nthis\\nlog\\ncontent\",\n-                {\"end_of_log\": True, \"log_pos\": 16},\n+        # Reading logs from worker should occur when the task is either running, deferred, or up for retry.\n+        for state in (TaskInstanceState.RUNNING, TaskInstanceState.DEFERRED, TaskInstanceState.UP_FOR_RETRY):",
        "comment_created_at": "2024-05-09T05:10:53+00:00",
        "comment_author": "kahlstrm",
        "comment_body": "Good point üëç  Not too familiar with pytest specifics, was thinking that there must be a better solution for this üòÑ ",
        "pr_file_module": null
      },
      {
        "comment_id": "1595873553",
        "repo_full_name": "apache/airflow",
        "pr_number": 39496,
        "pr_file": "tests/utils/test_log_handlers.py",
        "discussion_id": "1594784899",
        "commented_code": "@@ -317,43 +317,52 @@ def test__read_for_celery_executor_fallbacks_to_worker(self, create_task_instanc\n         \"\"\"Test for executors which do not have `get_task_log` method, it fallbacks to reading\n         log from worker if and only if remote logs aren't found\"\"\"\n         executor_name = \"CeleryExecutor\"\n-\n-        ti = create_task_instance(\n-            dag_id=\"dag_for_testing_celery_executor_log_read\",\n-            task_id=\"task_for_testing_celery_executor_log_read\",\n-            run_type=DagRunType.SCHEDULED,\n-            execution_date=DEFAULT_DATE,\n-        )\n-        ti.state = TaskInstanceState.RUNNING\n-        ti.try_number = 2\n-        with conf_vars({(\"core\", \"executor\"): executor_name}):\n-            reload(executor_loader)\n-            fth = FileTaskHandler(\"\")\n-\n-            fth._read_from_logs_server = mock.Mock()\n-            fth._read_from_logs_server.return_value = [\"this message\"], [\"this\\nlog\\ncontent\"]\n-            actual = fth._read(ti=ti, try_number=2)\n-            fth._read_from_logs_server.assert_called_once()\n-            assert actual == (\"*** this message\\nthis\\nlog\\ncontent\", {\"end_of_log\": False, \"log_pos\": 16})\n-\n-            # Previous try_number should return served logs when remote logs aren't implemented\n-            fth._read_from_logs_server = mock.Mock()\n-            fth._read_from_logs_server.return_value = [\"served logs try_number=1\"], [\"this\\nlog\\ncontent\"]\n-            actual = fth._read(ti=ti, try_number=1)\n-            fth._read_from_logs_server.assert_called_once()\n-            assert actual == (\n-                \"*** served logs try_number=1\\nthis\\nlog\\ncontent\",\n-                {\"end_of_log\": True, \"log_pos\": 16},\n+        # Reading logs from worker should occur when the task is either running, deferred, or up for retry.\n+        for state in (TaskInstanceState.RUNNING, TaskInstanceState.DEFERRED, TaskInstanceState.UP_FOR_RETRY):",
        "comment_created_at": "2024-05-09T19:18:16+00:00",
        "comment_author": "ferruzzi",
        "comment_body": "Yup, the TLDR on a `parameterize` is you provide it with a parameter name and a list of values, and it runs the test once for each of those values.  You can pass multiple parameters in as well.  It gets a little more complicated, you can find examples of that in the code if you want to look into it.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1999385213",
    "pr_number": 47440,
    "pr_file": "tests/api_fastapi/core_api/routes/public/test_dags.py",
    "created_at": "2025-03-17T18:26:44+00:00",
    "commented_code": "3,\n                 [DAG3_ID, DAG1_ID, DAG2_ID],\n             ),\n+            ({\"order_by\": [\"-dag_id\", \"dag_display_name\"]}, 2, [DAG2_ID, DAG1_ID]),\n+            ({\"order_by\": [\"dag_display_name\", \"-next_dagrun\"]}, 2, [DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"last_run_state\", \"-dag_display_name\", \"dag_id\"]}, 2, [DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"-last_run_start_date\", \"dag_display_name\", \"next_dagrun\", \"dag_id\"]}, 2, [ DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"dag_display_name\", \"-last_run_state\", \"next_dagrun\", \"dag_id\", \"last_run_start_date\"]}, 2, [DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"dag_display_name\", \"dag_id\"]}, 2, [DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"-dag_display_name\", \"-dag_id\"]}, 2, [DAG2_ID, DAG1_ID]),\n+            ({\"order_by\": [\"last_run_state\", \"dag_id\"], \"only_active\": False},3, [DAG1_ID, DAG3_ID, DAG2_ID]),\n+            ({\"order_by\": [\"-last_run_state\", \"-dag_id\"], \"only_active\": False},3, [DAG3_ID, DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"-last_run_start_date\", \"dag_id\"], \"only_active\": False},3, [DAG3_ID, DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"last_run_start_date\", \"-dag_id\"], \"only_active\": False},3, [DAG1_ID, DAG3_ID, DAG2_ID]),",
    "repo_full_name": "apache/airflow",
    "discussion_comments": [
      {
        "comment_id": "1999385213",
        "repo_full_name": "apache/airflow",
        "pr_number": 47440,
        "pr_file": "tests/api_fastapi/core_api/routes/public/test_dags.py",
        "discussion_id": "1999385213",
        "commented_code": "@@ -228,6 +228,17 @@ class TestGetDags(TestDagEndpoint):\n                 3,\n                 [DAG3_ID, DAG1_ID, DAG2_ID],\n             ),\n+            ({\"order_by\": [\"-dag_id\", \"dag_display_name\"]}, 2, [DAG2_ID, DAG1_ID]),\n+            ({\"order_by\": [\"dag_display_name\", \"-next_dagrun\"]}, 2, [DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"last_run_state\", \"-dag_display_name\", \"dag_id\"]}, 2, [DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"-last_run_start_date\", \"dag_display_name\", \"next_dagrun\", \"dag_id\"]}, 2, [ DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"dag_display_name\", \"-last_run_state\", \"next_dagrun\", \"dag_id\", \"last_run_start_date\"]}, 2, [DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"dag_display_name\", \"dag_id\"]}, 2, [DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"-dag_display_name\", \"-dag_id\"]}, 2, [DAG2_ID, DAG1_ID]),\n+            ({\"order_by\": [\"last_run_state\", \"dag_id\"], \"only_active\": False},3, [DAG1_ID, DAG3_ID, DAG2_ID]),\n+            ({\"order_by\": [\"-last_run_state\", \"-dag_id\"], \"only_active\": False},3, [DAG3_ID, DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"-last_run_start_date\", \"dag_id\"], \"only_active\": False},3, [DAG3_ID, DAG1_ID, DAG2_ID]),\n+            ({\"order_by\": [\"last_run_start_date\", \"-dag_id\"], \"only_active\": False},3, [DAG1_ID, DAG3_ID, DAG2_ID]),",
        "comment_created_at": "2025-03-17T18:26:44+00:00",
        "comment_author": "pierrejeambrun",
        "comment_body": "Can you reorganize this and put tests that sort on the same criteria next to each other. For instance `criteria1` is 'last_run_state', then `criteria2` is \"display_name\" so we can more easily compare.\r\n\r\nAlso for the second sort to take effect you need data where the first criteria is equal. I'm not sure we have this at the moment.\r\n\r\nBasically we need to tests where:\r\n`{\"order_by\": [\"criteria1\", \"criteria2\"]}` will yield a different result than `{\"order_by\": [\"criteria1\", \"-criteria2\"]}` to highlight that `criteria2` sorting is actually doing something and taken into account.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2176192598",
    "pr_number": 52607,
    "pr_file": "providers/apache/beam/tests/unit/apache/beam/operators/test_beam.py",
    "created_at": "2025-07-01T00:46:23+00:00",
    "commented_code": "assert f\"{TASK_ID} completed with response Pipeline has finished SUCCESSFULLY\" in caplog.text\n \n     def test_early_dataflow_id_xcom_push(self, default_options, pipeline_options):\n-        with mock.patch.object(BeamBasePipelineOperator, \"xcom_push\") as mock_xcom_push:\n-            op = BeamBasePipelineOperator(\n-                **self.default_op_kwargs,\n-                default_pipeline_options=copy.deepcopy(default_options),\n-                pipeline_options=copy.deepcopy(pipeline_options),\n-                dataflow_config={},\n-            )\n-            sample_df_job_id = \"sample_df_job_id_value\"\n-            op._execute_context = MagicMock()\n-\n-            assert op.dataflow_job_id is None\n-\n-            op.dataflow_job_id = sample_df_job_id\n-            mock_xcom_push.assert_called_once_with(\n-                context=op._execute_context, key=\"dataflow_job_id\", value=sample_df_job_id\n-            )\n-            mock_xcom_push.reset_mock()\n-            op.dataflow_job_id = \"sample_df_job_same_value_id\"\n-            mock_xcom_push.assert_not_called()\n+        op = BeamBasePipelineOperator(\n+            **self.default_op_kwargs,\n+            default_pipeline_options=copy.deepcopy(default_options),\n+            pipeline_options=copy.deepcopy(pipeline_options),\n+            dataflow_config={},\n+        )\n+        sample_df_job_id = \"sample_df_job_id_value\"\n+        # Mock the task instance with xcom_push method\n+        mock_ti = MagicMock()\n+        op._execute_context = {\"ti\": mock_ti}\n+\n+        assert op.dataflow_job_id is None\n+\n+        op.dataflow_job_id = sample_df_job_id\n+        mock_ti.xcom_push.assert_called_once_with(key=\"dataflow_job_id\", value=sample_df_job_id)\n+        mock_ti.xcom_push.reset_mock()\n+        op.dataflow_job_id = \"sample_df_job_same_value_id\"\n+        mock_ti.xcom_push.assert_not_called()",
    "repo_full_name": "apache/airflow",
    "discussion_comments": [
      {
        "comment_id": "2176192598",
        "repo_full_name": "apache/airflow",
        "pr_number": 52607,
        "pr_file": "providers/apache/beam/tests/unit/apache/beam/operators/test_beam.py",
        "discussion_id": "2176192598",
        "commented_code": "@@ -116,25 +116,24 @@ def test_async_execute_logging_should_execute_successfully(self, caplog):\n         assert f\"{TASK_ID} completed with response Pipeline has finished SUCCESSFULLY\" in caplog.text\n \n     def test_early_dataflow_id_xcom_push(self, default_options, pipeline_options):\n-        with mock.patch.object(BeamBasePipelineOperator, \"xcom_push\") as mock_xcom_push:\n-            op = BeamBasePipelineOperator(\n-                **self.default_op_kwargs,\n-                default_pipeline_options=copy.deepcopy(default_options),\n-                pipeline_options=copy.deepcopy(pipeline_options),\n-                dataflow_config={},\n-            )\n-            sample_df_job_id = \"sample_df_job_id_value\"\n-            op._execute_context = MagicMock()\n-\n-            assert op.dataflow_job_id is None\n-\n-            op.dataflow_job_id = sample_df_job_id\n-            mock_xcom_push.assert_called_once_with(\n-                context=op._execute_context, key=\"dataflow_job_id\", value=sample_df_job_id\n-            )\n-            mock_xcom_push.reset_mock()\n-            op.dataflow_job_id = \"sample_df_job_same_value_id\"\n-            mock_xcom_push.assert_not_called()\n+        op = BeamBasePipelineOperator(\n+            **self.default_op_kwargs,\n+            default_pipeline_options=copy.deepcopy(default_options),\n+            pipeline_options=copy.deepcopy(pipeline_options),\n+            dataflow_config={},\n+        )\n+        sample_df_job_id = \"sample_df_job_id_value\"\n+        # Mock the task instance with xcom_push method\n+        mock_ti = MagicMock()\n+        op._execute_context = {\"ti\": mock_ti}\n+\n+        assert op.dataflow_job_id is None\n+\n+        op.dataflow_job_id = sample_df_job_id\n+        mock_ti.xcom_push.assert_called_once_with(key=\"dataflow_job_id\", value=sample_df_job_id)\n+        mock_ti.xcom_push.reset_mock()\n+        op.dataflow_job_id = \"sample_df_job_same_value_id\"\n+        mock_ti.xcom_push.assert_not_called()",
        "comment_created_at": "2025-07-01T00:46:23+00:00",
        "comment_author": "kyungjunleeme",
        "comment_body": "```suggestion\r\n        # Mock TaskInstance and inject into execution context\r\n        mock_ti = MagicMock()\r\n        op._execute_context = {\"ti\": mock_ti}\r\n    \r\n        assert op.dataflow_job_id is None\r\n   \r\n        op.dataflow_job_id = sample_df_job_id\r\n        assert any(\r\n            kwargs.get(\"key\") == \"dataflow_job_id\" and kwargs.get(\"value\") == sample_df_job_id\r\n            for _, kwargs in mock_ti.xcom_push.call_args_list\r\n        )\r\n        \r\n        # If the same value is set again, it should not push to XCom again\r\n        mock_ti.reset_mock()\r\n        op.dataflow_job_id = sample_df_job_id\r\n    \r\n        assert mock_ti.xcom_push.call_count == 0\r\n```\r\n\r\nI have tested this code.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2176915465",
    "pr_number": 52408,
    "pr_file": "airflow-core/tests/unit/api_fastapi/core_api/routes/ui/test_config.py",
    "created_at": "2025-07-01T09:00:13+00:00",
    "commented_code": "yield\n \n \n-class TestGetConfig:\n+@pytest.mark.mock_plugin_manager(plugins=[])\n+class TestGetConfigWithNoPlugins:",
    "repo_full_name": "apache/airflow",
    "discussion_comments": [
      {
        "comment_id": "2176915465",
        "repo_full_name": "apache/airflow",
        "pr_number": 52408,
        "pr_file": "airflow-core/tests/unit/api_fastapi/core_api/routes/ui/test_config.py",
        "discussion_id": "2176915465",
        "commented_code": "@@ -56,7 +59,8 @@ def mock_config_data():\n         yield\n \n \n-class TestGetConfig:\n+@pytest.mark.mock_plugin_manager(plugins=[])\n+class TestGetConfigWithNoPlugins:",
        "comment_created_at": "2025-07-01T09:00:13+00:00",
        "comment_author": "pierrejeambrun",
        "comment_body": "1 class per endpoint. Multiple method for different test cases. We shouldn't  have two classes there.",
        "pr_file_module": null
      }
    ]
  }
]