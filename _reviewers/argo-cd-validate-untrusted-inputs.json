[
  {
    "discussion_id": "2150344437",
    "pr_number": 23403,
    "pr_file": "util/helm/cmd.go",
    "created_at": "2025-06-16T15:51:50+00:00",
    "commented_code": "args = append(args, \"--insecure-skip-tls-verify\")\n \t}\n \n-\targs = append(args, \"--repo\", repo, chartName)\n+\tif directPull {\n+\t\tif version == \"\" {\n+\t\t\treturn \"\", fmt.Errorf(\"failed to fetch chart '%s': version should be defined fetching by direct url\", chartName)\n+\t\t}\n+\t\targs = append(args, fmt.Sprintf(\"%s/%s-%s.tgz\", repo, chartName, version))",
    "repo_full_name": "argoproj/argo-cd",
    "discussion_comments": [
      {
        "comment_id": "2150344437",
        "repo_full_name": "argoproj/argo-cd",
        "pr_number": 23403,
        "pr_file": "util/helm/cmd.go",
        "discussion_id": "2150344437",
        "commented_code": "@@ -245,7 +242,17 @@ func (c *Cmd) Fetch(repo, chartName, version, destination string, creds Creds, p\n \t\targs = append(args, \"--insecure-skip-tls-verify\")\n \t}\n \n-\targs = append(args, \"--repo\", repo, chartName)\n+\tif directPull {\n+\t\tif version == \"\" {\n+\t\t\treturn \"\", fmt.Errorf(\"failed to fetch chart '%s': version should be defined fetching by direct url\", chartName)\n+\t\t}\n+\t\targs = append(args, fmt.Sprintf(\"%s/%s-%s.tgz\", repo, chartName, version))",
        "comment_created_at": "2025-06-16T15:51:50+00:00",
        "comment_author": "crenshaw-dev",
        "comment_body": "Do we need to be concerned about someone constructing a link that tries to access stuff they shouldn't be accessing? Do we need some validation on repo, chartName, and version beyond what already exists?",
        "pr_file_module": null
      },
      {
        "comment_id": "2150368329",
        "repo_full_name": "argoproj/argo-cd",
        "pr_number": 23403,
        "pr_file": "util/helm/cmd.go",
        "discussion_id": "2150344437",
        "commented_code": "@@ -245,7 +242,17 @@ func (c *Cmd) Fetch(repo, chartName, version, destination string, creds Creds, p\n \t\targs = append(args, \"--insecure-skip-tls-verify\")\n \t}\n \n-\targs = append(args, \"--repo\", repo, chartName)\n+\tif directPull {\n+\t\tif version == \"\" {\n+\t\t\treturn \"\", fmt.Errorf(\"failed to fetch chart '%s': version should be defined fetching by direct url\", chartName)\n+\t\t}\n+\t\targs = append(args, fmt.Sprintf(\"%s/%s-%s.tgz\", repo, chartName, version))",
        "comment_created_at": "2025-06-16T16:04:44+00:00",
        "comment_author": "fm1ck3y",
        "comment_body": "I think that for direct pull this condition is necessary only for the user to understand where he made a mistake. \r\nIf we try to download a chart without a version, of course there will be a 404 error, but the user will not have enough information to understand what the problem was",
        "pr_file_module": null
      },
      {
        "comment_id": "2150645277",
        "repo_full_name": "argoproj/argo-cd",
        "pr_number": 23403,
        "pr_file": "util/helm/cmd.go",
        "discussion_id": "2150344437",
        "commented_code": "@@ -245,7 +242,17 @@ func (c *Cmd) Fetch(repo, chartName, version, destination string, creds Creds, p\n \t\targs = append(args, \"--insecure-skip-tls-verify\")\n \t}\n \n-\targs = append(args, \"--repo\", repo, chartName)\n+\tif directPull {\n+\t\tif version == \"\" {\n+\t\t\treturn \"\", fmt.Errorf(\"failed to fetch chart '%s': version should be defined fetching by direct url\", chartName)\n+\t\t}\n+\t\targs = append(args, fmt.Sprintf(\"%s/%s-%s.tgz\", repo, chartName, version))",
        "comment_created_at": "2025-06-16T18:50:31+00:00",
        "comment_author": "crenshaw-dev",
        "comment_body": "I guess I'm thinking more of a malicious scenario, where a user passes `repoName=../../../etc/passwd` or similar. It's not an easy attack path, but it seems like it would be super easy to validate against.",
        "pr_file_module": null
      },
      {
        "comment_id": "2150720708",
        "repo_full_name": "argoproj/argo-cd",
        "pr_number": 23403,
        "pr_file": "util/helm/cmd.go",
        "discussion_id": "2150344437",
        "commented_code": "@@ -245,7 +242,17 @@ func (c *Cmd) Fetch(repo, chartName, version, destination string, creds Creds, p\n \t\targs = append(args, \"--insecure-skip-tls-verify\")\n \t}\n \n-\targs = append(args, \"--repo\", repo, chartName)\n+\tif directPull {\n+\t\tif version == \"\" {\n+\t\t\treturn \"\", fmt.Errorf(\"failed to fetch chart '%s': version should be defined fetching by direct url\", chartName)\n+\t\t}\n+\t\targs = append(args, fmt.Sprintf(\"%s/%s-%s.tgz\", repo, chartName, version))",
        "comment_created_at": "2025-06-16T19:35:02+00:00",
        "comment_author": "fm1ck3y",
        "comment_body": "Yes, you are right, I think I misunderstood you in a previous reply\r\nI think it will be enough here to check on correct URL. Anyway Iwill think about the implementation and come back with an updated PR",
        "pr_file_module": null
      },
      {
        "comment_id": "2152885748",
        "repo_full_name": "argoproj/argo-cd",
        "pr_number": 23403,
        "pr_file": "util/helm/cmd.go",
        "discussion_id": "2150344437",
        "commented_code": "@@ -245,7 +242,17 @@ func (c *Cmd) Fetch(repo, chartName, version, destination string, creds Creds, p\n \t\targs = append(args, \"--insecure-skip-tls-verify\")\n \t}\n \n-\targs = append(args, \"--repo\", repo, chartName)\n+\tif directPull {\n+\t\tif version == \"\" {\n+\t\t\treturn \"\", fmt.Errorf(\"failed to fetch chart '%s': version should be defined fetching by direct url\", chartName)\n+\t\t}\n+\t\targs = append(args, fmt.Sprintf(\"%s/%s-%s.tgz\", repo, chartName, version))",
        "comment_created_at": "2025-06-17T18:16:21+00:00",
        "comment_author": "fm1ck3y",
        "comment_body": "Done! Let me know if there is anything else that needs to be considered",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1870012269",
    "pr_number": 18646,
    "pr_file": "util/oci/client.go",
    "created_at": "2024-12-04T17:42:19+00:00",
    "commented_code": "+package oci\n+\n+import (\n+\t\"context\"\n+\t\"crypto/tls\"\n+\t\"crypto/x509\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"io/fs\"\n+\t\"math\"\n+\t\"net/http\"\n+\t\"os\"\n+\t\"path\"\n+\t\"path/filepath\"\n+\t\"slices\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"oras.land/oras-go/v2/content/oci\"\n+\n+\tv1 \"github.com/opencontainers/image-spec/specs-go/v1\"\n+\n+\t\"github.com/Masterminds/semver/v3\"\n+\t\"github.com/argoproj/pkg/sync\"\n+\tlog \"github.com/sirupsen/logrus\"\n+\n+\t\"github.com/argoproj/argo-cd/v2/util/cache\"\n+\targoio \"github.com/argoproj/argo-cd/v2/util/io\"\n+\t\"github.com/argoproj/argo-cd/v2/util/io/files\"\n+\t\"github.com/argoproj/argo-cd/v2/util/proxy\"\n+\n+\t\"oras.land/oras-go/v2\"\n+\t\"oras.land/oras-go/v2/content/file\"\n+\t\"oras.land/oras-go/v2/registry/remote\"\n+\t\"oras.land/oras-go/v2/registry/remote/auth\"\n+)\n+\n+var (\n+\tglobalLock = sync.NewKeyLock()\n+\tindexLock  = sync.NewKeyLock()\n+)\n+\n+var _ Client = &nativeOCIClient{}\n+\n+type indexCache interface {\n+\tSetHelmIndex(repo string, indexData []byte) error\n+\tGetHelmIndex(repo string, indexData *[]byte) error\n+}\n+\n+// Client is a generic oci client interface\n+type Client interface {\n+\tResolveRevision(ctx context.Context, revision string, noCache bool) (string, error)\n+\tDigestMetadata(ctx context.Context, digest, project string) (*v1.Manifest, error)\n+\tCleanCache(revision string, project string) error\n+\tExtract(ctx context.Context, revision string, project string, manifestMaxExtractedSize int64, disableManifestMaxExtractedSize bool) (string, argoio.Closer, error)\n+\tTestRepo(ctx context.Context) (bool, error)\n+}\n+\n+type Creds struct {\n+\tUsername           string\n+\tPassword           string\n+\tCAPath             string\n+\tCertData           []byte\n+\tKeyData            []byte\n+\tInsecureSkipVerify bool\n+\tInsecureHttpOnly   bool\n+}\n+\n+type ClientOpts func(c *nativeOCIClient)\n+\n+func WithIndexCache(indexCache indexCache) ClientOpts {\n+\treturn func(c *nativeOCIClient) {\n+\t\tc.indexCache = indexCache\n+\t}\n+}\n+\n+func WithImagePaths(repoCachePaths argoio.TempPaths) ClientOpts {\n+\treturn func(c *nativeOCIClient) {\n+\t\tc.repoCachePaths = repoCachePaths\n+\t}\n+}\n+\n+func NewClient(repoURL string, creds Creds, proxy, noProxy string, layerMediaTypes []string, opts ...ClientOpts) (Client, error) {\n+\treturn NewClientWithLock(repoURL, creds, globalLock, proxy, noProxy, layerMediaTypes, opts...)\n+}\n+\n+func NewClientWithLock(repoURL string, creds Creds, repoLock sync.KeyLock, proxyUrl, noProxy string, layerMediaTypes []string, opts ...ClientOpts) (Client, error) {\n+\tociRepo := strings.TrimPrefix(repoURL, \"oci://\")\n+\trepo, err := remote.NewRepository(ociRepo)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"failed to initialize repository: %w\", err)\n+\t}\n+\n+\trepo.PlainHTTP = creds.InsecureHttpOnly\n+\n+\tvar tlsConf *tls.Config\n+\tif !repo.PlainHTTP {\n+\t\ttlsConf, err = newTLSConfig(creds)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"failed setup tlsConfig: %w\", err)\n+\t\t}\n+\t}\n+\n+\tclient := &http.Client{Transport: &http.Transport{\n+\t\tProxy:             proxy.GetCallback(proxyUrl, noProxy),\n+\t\tTLSClientConfig:   tlsConf,\n+\t\tDisableKeepAlives: true,\n+\t}}\n+\trepo.Client = &auth.Client{\n+\t\tClient: client,\n+\t\tCache:  nil,\n+\t\tCredential: auth.StaticCredential(repo.Reference.Registry, auth.Credential{\n+\t\t\tUsername: creds.Username,\n+\t\t\tPassword: creds.Password,\n+\t\t}),\n+\t}\n+\n+\treturn newClientWithLock(ociRepo, creds, repoLock, repo, func(ctx context.Context, last string) ([]string, error) {\n+\t\tvar t []string\n+\t\terr := repo.Tags(ctx, last, func(tags []string) error {\n+\t\t\tt = append(t, tags...)\n+\t\t\treturn nil\n+\t\t})\n+\n+\t\treturn t, err\n+\t}, layerMediaTypes, opts...), nil\n+}\n+\n+func newClientWithLock(repoURL string, creds Creds, repoLock sync.KeyLock, repo oras.ReadOnlyTarget, tagsFunc func(context.Context, string) ([]string, error), layerMediaTypes []string, opts ...ClientOpts) Client {\n+\tc := &nativeOCIClient{\n+\t\tcreds:             creds,\n+\t\trepoURL:           repoURL,\n+\t\trepoLock:          repoLock,\n+\t\trepo:              repo,\n+\t\ttagsFunc:          tagsFunc,\n+\t\tallowedMediaTypes: layerMediaTypes,\n+\t}\n+\tfor i := range opts {\n+\t\topts[i](c)\n+\t}\n+\treturn c\n+}\n+\n+// nativeOCIClient implements Client interface using oras-go\n+type nativeOCIClient struct {\n+\tcreds             Creds\n+\trepoURL           string\n+\trepo              oras.ReadOnlyTarget\n+\ttagsFunc          func(context.Context, string) ([]string, error)\n+\trepoLock          sync.KeyLock\n+\tindexCache        indexCache\n+\trepoCachePaths    argoio.TempPaths\n+\tallowedMediaTypes []string\n+}\n+\n+// TestRepo verifies that the remote OCI repo can be connected to.\n+func (c *nativeOCIClient) TestRepo(ctx context.Context) (bool, error) {\n+\t_, err := c.tagsFunc(ctx, \"\")\n+\treturn err == nil, err\n+}\n+\n+func (c *nativeOCIClient) Extract(ctx context.Context, digest string, project string, manifestMaxExtractedSize int64, disableManifestMaxExtractedSize bool) (string, argoio.Closer, error) {\n+\tcachedPath, err := c.getCachedPath(digest, project)\n+\tif err != nil {\n+\t\treturn \"\", nil, err\n+\t}\n+\n+\tc.repoLock.Lock(cachedPath)\n+\tdefer c.repoLock.Unlock(cachedPath)\n+\n+\texists, err := fileExists(cachedPath)\n+\tif err != nil {\n+\t\treturn \"\", nil, err\n+\t}\n+\n+\tif !exists {\n+\t\tociManifest, err := getOCIManifest(ctx, digest, c.repo)\n+\t\tif err != nil {\n+\t\t\treturn \"\", nil, err\n+\t\t}\n+\n+\t\tif len(ociManifest.Layers) != 1 {\n+\t\t\treturn \"\", nil, fmt.Errorf(\"expected only a single oci layer, got %d\", len(ociManifest.Layers))\n+\t\t}\n+\n+\t\tif !slices.Contains(c.allowedMediaTypes, ociManifest.Layers[0].MediaType) {\n+\t\t\treturn \"\", nil, fmt.Errorf(\"oci layer media type %s is not in the list of allowed media types\", ociManifest.Layers[0].MediaType)\n+\t\t}\n+\n+\t\terr = saveCompressedImageToPath(ctx, digest, c.repo, cachedPath)\n+\t\tif err != nil {\n+\t\t\treturn \"\", nil, err\n+\t\t}\n+\t}\n+\n+\tmaxSize := manifestMaxExtractedSize\n+\tif disableManifestMaxExtractedSize {\n+\t\tmaxSize = math.MaxInt64\n+\t}\n+\n+\tmanifestsDir, err := extractContentToManifestsDir(ctx, cachedPath, digest, maxSize, c.allowedMediaTypes)\n+\tif err != nil {\n+\t\treturn manifestsDir, nil, err\n+\t}\n+\n+\treturn manifestsDir, argoio.NewCloser(func() error {\n+\t\treturn os.RemoveAll(manifestsDir)\n+\t}), nil\n+}\n+\n+func (c *nativeOCIClient) getCachedPath(version, project string) (string, error) {\n+\tkeyData, err := json.Marshal(map[string]string{\"url\": c.repoURL, \"project\": project, \"version\": version})\n+\tif err != nil {\n+\t\treturn \"\", err\n+\t}\n+\treturn c.repoCachePaths.GetPath(string(keyData))\n+}\n+\n+// CleanCache is invoked on a hard-refresh or when the manifest cache has expired. This removes the OCI image from the cached path.\n+func (c *nativeOCIClient) CleanCache(revision, project string) error {\n+\tcachePath, err := c.getCachedPath(revision, project)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\treturn os.RemoveAll(cachePath)\n+}\n+\n+// DigestMetadata extracts the OCI manifest for a given revision and returns it to the caller.\n+func (c *nativeOCIClient) DigestMetadata(ctx context.Context, digest, project string) (*v1.Manifest, error) {\n+\tpath, err := c.getCachedPath(digest, project)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\trepo, err := oci.NewFromTar(ctx, path)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\treturn getOCIManifest(ctx, digest, repo)\n+}\n+\n+func (c *nativeOCIClient) ResolveRevision(ctx context.Context, revision string, noCache bool) (string, error) {\n+\tconstraints, err := semver.NewConstraint(revision)\n+\tif err == nil {\n+\t\ttags, err := c.getTags(ctx, noCache)\n+\t\tif err != nil {\n+\t\t\treturn \"\", fmt.Errorf(\"error fetching tags: %w\", err)\n+\t\t}\n+\t\tversion, err := tags.MaxVersion(constraints)\n+\t\tif err != nil {\n+\t\t\treturn \"\", fmt.Errorf(\"no version for constraints: %w\", err)\n+\t\t}\n+\t\treturn c.resolveDigest(ctx, version.String())\n+\t}\n+\n+\treturn c.resolveDigest(ctx, revision)\n+}\n+\n+func (c *nativeOCIClient) getTags(ctx context.Context, noCache bool) (*TagsList, error) {\n+\tindexLock.Lock(c.repoURL)\n+\tdefer indexLock.Unlock(c.repoURL)\n+\n+\tvar data []byte\n+\tif !noCache && c.indexCache != nil {\n+\t\tif err := c.indexCache.GetHelmIndex(c.repoURL, &data); err != nil && !errors.Is(err, cache.ErrCacheMiss) {\n+\t\t\tlog.Warnf(\"Failed to load index cache for repo: %s: %s\", c.repoLock, err)\n+\t\t}\n+\t}\n+\n+\ttags := &TagsList{}\n+\tif len(data) == 0 {\n+\t\tstart := time.Now()\n+\t\tresult, err := c.tagsFunc(ctx, \"\")\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"failed to get tags: %w\", err)\n+\t\t}\n+\n+\t\tfor _, tag := range result {\n+\t\t\t// By convention: Change underscore (_) back to plus (+) to get valid SemVer\n+\t\t\tconvertedTag := strings.ReplaceAll(tag, \"_\", \"+\")\n+\t\t\ttags.Tags = append(tags.Tags, convertedTag)\n+\t\t}\n+\n+\t\tlog.WithFields(\n+\t\t\tlog.Fields{\"seconds\": time.Since(start).Seconds(), \"repo\": c.repoURL},\n+\t\t).Info(\"took to get tags\")\n+\n+\t\tif c.indexCache != nil {\n+\t\t\tif err := c.indexCache.SetHelmIndex(c.repoURL, data); err != nil {\n+\t\t\t\tlog.Warnf(\"Failed to store tags list cache for repo: %s: %s\", c.repoURL, err)\n+\t\t\t}\n+\t\t}\n+\t} else {\n+\t\terr := json.Unmarshal(data, tags)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"failed to decode tags: %w\", err)\n+\t\t}\n+\t}\n+\n+\treturn tags, nil\n+}\n+\n+// resolveDigest resolves a digest from a tag.\n+func (c *nativeOCIClient) resolveDigest(ctx context.Context, revision string) (string, error) {\n+\tdescriptor, err := c.repo.Resolve(ctx, revision)\n+\tif err != nil {\n+\t\treturn \"\", fmt.Errorf(\"cannot get digest for revision %s: %w\", revision, err)\n+\t}\n+\n+\treturn descriptor.Digest.String(), nil\n+}\n+\n+func newTLSConfig(creds Creds) (*tls.Config, error) {\n+\ttlsConfig := &tls.Config{InsecureSkipVerify: creds.InsecureSkipVerify}\n+\n+\tif creds.CAPath != \"\" {\n+\t\tcaData, err := os.ReadFile(creds.CAPath)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\tcaCertPool := x509.NewCertPool()\n+\t\tcaCertPool.AppendCertsFromPEM(caData)\n+\t\ttlsConfig.RootCAs = caCertPool\n+\t}\n+\n+\t// If a client cert & key is provided then configure TLS config accordingly.\n+\tif len(creds.CertData) > 0 && len(creds.KeyData) > 0 {\n+\t\tcert, err := tls.X509KeyPair(creds.CertData, creds.KeyData)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\ttlsConfig.Certificates = []tls.Certificate{cert}\n+\t}\n+\t// nolint:staticcheck\n+\ttlsConfig.BuildNameToCertificate()\n+\n+\treturn tlsConfig, nil\n+}\n+\n+func fileExists(filePath string) (bool, error) {\n+\tif _, err := os.Stat(filePath); err != nil {\n+\t\tif os.IsNotExist(err) {\n+\t\t\treturn false, nil\n+\t\t} else {\n+\t\t\treturn false, err\n+\t\t}\n+\t}\n+\treturn true, nil\n+}\n+\n+func isHelmOCI(mediaType string) bool {\n+\treturn mediaType == \"application/vnd.cncf.helm.chart.content.v1.tar+gzip\"\n+}\n+\n+func isCompressedLayer(mediaType string) bool {\n+\treturn strings.HasSuffix(mediaType, \"tar+gzip\") || strings.HasSuffix(mediaType, \"tar\")\n+}\n+\n+func createTarFile(from, to string) error {\n+\tf, err := os.Create(to)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t_, err = files.Tar(from, nil, nil, f)\n+\tif err != nil {\n+\t\t_ = os.RemoveAll(to)\n+\t}\n+\treturn f.Close()\n+}\n+\n+// saveCompressedImageToPath downloads a remote OCI image on a given digest and stores it as a TAR file in cachedPath.\n+func saveCompressedImageToPath(ctx context.Context, digest string, repo oras.ReadOnlyTarget, cachedPath string) error {\n+\ttempDir, err := files.CreateTempDir(os.TempDir())\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer os.RemoveAll(tempDir)\n+\n+\tstore, err := oci.New(tempDir)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Copy remote repo at the given digest to the scratch dir.\n+\t_, err = oras.Copy(ctx, repo, digest, store, digest, oras.DefaultCopyOptions)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Remove redundant ingest folder; this is an artifact from the oras.Copy call above\n+\terr = os.RemoveAll(path.Join(tempDir, \"ingest\"))\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Save contents to tar file\n+\treturn createTarFile(tempDir, cachedPath)\n+}\n+\n+// extractContentToManifestsDir looks up a locally stored OCI image, and extracts the embedded compressed layer which contains\n+// K8s manifests to a temporary directory\n+func extractContentToManifestsDir(ctx context.Context, cachedPath, digest string, maxSize int64, allowedMediaTypes []string) (string, error) {\n+\tmanifestsDir, err := files.CreateTempDir(os.TempDir())\n+\tif err != nil {\n+\t\treturn manifestsDir, err\n+\t}\n+\n+\tociReadOnlyStore, err := oci.NewFromTar(ctx, cachedPath)\n+\tif err != nil {\n+\t\treturn manifestsDir, err\n+\t}\n+\n+\ttempDir, err := files.CreateTempDir(os.TempDir())\n+\tif err != nil {\n+\t\treturn manifestsDir, err\n+\t}\n+\tdefer os.RemoveAll(tempDir)\n+\n+\tfs, err := newCompressedLayerFileStore(manifestsDir, tempDir, maxSize, allowedMediaTypes)\n+\tif err != nil {\n+\t\treturn manifestsDir, err\n+\t}\n+\tdefer fs.Close()\n+\n+\t// copies the whole artifact to the tempdir, here compressedLayerFileStore.Push will be called\n+\t_, err = oras.Copy(ctx, ociReadOnlyStore, digest, fs, digest, oras.DefaultCopyOptions)\n+\treturn manifestsDir, err\n+}\n+\n+type compressedLayerExtracterStore struct {\n+\t*file.Store\n+\ttempDir           string\n+\tdest              string\n+\tmaxSize           int64\n+\tallowedMediaTypes []string\n+}\n+\n+func newCompressedLayerFileStore(dest, tempDir string, maxSize int64, allowedMediaTypes []string) (*compressedLayerExtracterStore, error) {\n+\tf, err := file.New(tempDir)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\treturn &compressedLayerExtracterStore{f, tempDir, dest, maxSize, allowedMediaTypes}, nil\n+}\n+\n+// Push looks in all the layers of an OCI image. Once it finds a layer that is compressed, it extracts the layer to a tempDir\n+// and then renames the temp dir to the directory where the repo-server expects to find k8s manifests.\n+func (s *compressedLayerExtracterStore) Push(ctx context.Context, desc v1.Descriptor, content io.Reader) error {\n+\tif isCompressedLayer(desc.MediaType) {\n+\t\ttempDir, err := files.CreateTempDir(os.TempDir())\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tdefer os.RemoveAll(tempDir)\n+\n+\t\tif strings.HasSuffix(desc.MediaType, \"tar+gzip\") {\n+\t\t\terr = files.Untgz(tempDir, content, s.maxSize, false)\n+\t\t} else {\n+\t\t\terr = files.Untar(tempDir, content, s.maxSize, false)\n+\t\t}\n+\n+\t\tif err != nil {\n+\t\t\treturn fmt.Errorf(\"could not decompress layer: %w\", err)\n+\t\t}\n+\n+\t\tinfos, err := os.ReadDir(tempDir)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\n+\t\tif isHelmOCI(desc.MediaType) {\n+\t\t\t// For a Helm chart we expect a single tarfile in the directory\n+\t\t\tif len(infos) != 1 {\n+\t\t\t\treturn fmt.Errorf(\"expected 1 file, found %v\", len(infos))\n+\t\t\t}\n+\t\t}\n+\n+\t\tif len(infos) == 1 && infos[0].IsDir() {\n+\t\t\t// Here we assume that this is a directory which has been decompressed. We need to move the contents of\n+\t\t\t// the dir into our intended destination.\n+\t\t\tsrcDir := filepath.Join(tempDir, infos[0].Name())\n+\t\t\treturn filepath.WalkDir(srcDir, func(path string, d fs.DirEntry, err error) error {\n+\t\t\t\tif path != srcDir {\n+\t\t\t\t\t// Calculate the relative path from srcDir\n+\t\t\t\t\trelPath, err := filepath.Rel(srcDir, path)\n+\t\t\t\t\tif err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tdstPath := filepath.Join(s.dest, relPath)",
    "repo_full_name": "argoproj/argo-cd",
    "discussion_comments": [
      {
        "comment_id": "1870012269",
        "repo_full_name": "argoproj/argo-cd",
        "pr_number": 18646,
        "pr_file": "util/oci/client.go",
        "discussion_id": "1870012269",
        "commented_code": "@@ -0,0 +1,544 @@\n+package oci\n+\n+import (\n+\t\"context\"\n+\t\"crypto/tls\"\n+\t\"crypto/x509\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"io/fs\"\n+\t\"math\"\n+\t\"net/http\"\n+\t\"os\"\n+\t\"path\"\n+\t\"path/filepath\"\n+\t\"slices\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"oras.land/oras-go/v2/content/oci\"\n+\n+\tv1 \"github.com/opencontainers/image-spec/specs-go/v1\"\n+\n+\t\"github.com/Masterminds/semver/v3\"\n+\t\"github.com/argoproj/pkg/sync\"\n+\tlog \"github.com/sirupsen/logrus\"\n+\n+\t\"github.com/argoproj/argo-cd/v2/util/cache\"\n+\targoio \"github.com/argoproj/argo-cd/v2/util/io\"\n+\t\"github.com/argoproj/argo-cd/v2/util/io/files\"\n+\t\"github.com/argoproj/argo-cd/v2/util/proxy\"\n+\n+\t\"oras.land/oras-go/v2\"\n+\t\"oras.land/oras-go/v2/content/file\"\n+\t\"oras.land/oras-go/v2/registry/remote\"\n+\t\"oras.land/oras-go/v2/registry/remote/auth\"\n+)\n+\n+var (\n+\tglobalLock = sync.NewKeyLock()\n+\tindexLock  = sync.NewKeyLock()\n+)\n+\n+var _ Client = &nativeOCIClient{}\n+\n+type indexCache interface {\n+\tSetHelmIndex(repo string, indexData []byte) error\n+\tGetHelmIndex(repo string, indexData *[]byte) error\n+}\n+\n+// Client is a generic oci client interface\n+type Client interface {\n+\tResolveRevision(ctx context.Context, revision string, noCache bool) (string, error)\n+\tDigestMetadata(ctx context.Context, digest, project string) (*v1.Manifest, error)\n+\tCleanCache(revision string, project string) error\n+\tExtract(ctx context.Context, revision string, project string, manifestMaxExtractedSize int64, disableManifestMaxExtractedSize bool) (string, argoio.Closer, error)\n+\tTestRepo(ctx context.Context) (bool, error)\n+}\n+\n+type Creds struct {\n+\tUsername           string\n+\tPassword           string\n+\tCAPath             string\n+\tCertData           []byte\n+\tKeyData            []byte\n+\tInsecureSkipVerify bool\n+\tInsecureHttpOnly   bool\n+}\n+\n+type ClientOpts func(c *nativeOCIClient)\n+\n+func WithIndexCache(indexCache indexCache) ClientOpts {\n+\treturn func(c *nativeOCIClient) {\n+\t\tc.indexCache = indexCache\n+\t}\n+}\n+\n+func WithImagePaths(repoCachePaths argoio.TempPaths) ClientOpts {\n+\treturn func(c *nativeOCIClient) {\n+\t\tc.repoCachePaths = repoCachePaths\n+\t}\n+}\n+\n+func NewClient(repoURL string, creds Creds, proxy, noProxy string, layerMediaTypes []string, opts ...ClientOpts) (Client, error) {\n+\treturn NewClientWithLock(repoURL, creds, globalLock, proxy, noProxy, layerMediaTypes, opts...)\n+}\n+\n+func NewClientWithLock(repoURL string, creds Creds, repoLock sync.KeyLock, proxyUrl, noProxy string, layerMediaTypes []string, opts ...ClientOpts) (Client, error) {\n+\tociRepo := strings.TrimPrefix(repoURL, \"oci://\")\n+\trepo, err := remote.NewRepository(ociRepo)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"failed to initialize repository: %w\", err)\n+\t}\n+\n+\trepo.PlainHTTP = creds.InsecureHttpOnly\n+\n+\tvar tlsConf *tls.Config\n+\tif !repo.PlainHTTP {\n+\t\ttlsConf, err = newTLSConfig(creds)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"failed setup tlsConfig: %w\", err)\n+\t\t}\n+\t}\n+\n+\tclient := &http.Client{Transport: &http.Transport{\n+\t\tProxy:             proxy.GetCallback(proxyUrl, noProxy),\n+\t\tTLSClientConfig:   tlsConf,\n+\t\tDisableKeepAlives: true,\n+\t}}\n+\trepo.Client = &auth.Client{\n+\t\tClient: client,\n+\t\tCache:  nil,\n+\t\tCredential: auth.StaticCredential(repo.Reference.Registry, auth.Credential{\n+\t\t\tUsername: creds.Username,\n+\t\t\tPassword: creds.Password,\n+\t\t}),\n+\t}\n+\n+\treturn newClientWithLock(ociRepo, creds, repoLock, repo, func(ctx context.Context, last string) ([]string, error) {\n+\t\tvar t []string\n+\t\terr := repo.Tags(ctx, last, func(tags []string) error {\n+\t\t\tt = append(t, tags...)\n+\t\t\treturn nil\n+\t\t})\n+\n+\t\treturn t, err\n+\t}, layerMediaTypes, opts...), nil\n+}\n+\n+func newClientWithLock(repoURL string, creds Creds, repoLock sync.KeyLock, repo oras.ReadOnlyTarget, tagsFunc func(context.Context, string) ([]string, error), layerMediaTypes []string, opts ...ClientOpts) Client {\n+\tc := &nativeOCIClient{\n+\t\tcreds:             creds,\n+\t\trepoURL:           repoURL,\n+\t\trepoLock:          repoLock,\n+\t\trepo:              repo,\n+\t\ttagsFunc:          tagsFunc,\n+\t\tallowedMediaTypes: layerMediaTypes,\n+\t}\n+\tfor i := range opts {\n+\t\topts[i](c)\n+\t}\n+\treturn c\n+}\n+\n+// nativeOCIClient implements Client interface using oras-go\n+type nativeOCIClient struct {\n+\tcreds             Creds\n+\trepoURL           string\n+\trepo              oras.ReadOnlyTarget\n+\ttagsFunc          func(context.Context, string) ([]string, error)\n+\trepoLock          sync.KeyLock\n+\tindexCache        indexCache\n+\trepoCachePaths    argoio.TempPaths\n+\tallowedMediaTypes []string\n+}\n+\n+// TestRepo verifies that the remote OCI repo can be connected to.\n+func (c *nativeOCIClient) TestRepo(ctx context.Context) (bool, error) {\n+\t_, err := c.tagsFunc(ctx, \"\")\n+\treturn err == nil, err\n+}\n+\n+func (c *nativeOCIClient) Extract(ctx context.Context, digest string, project string, manifestMaxExtractedSize int64, disableManifestMaxExtractedSize bool) (string, argoio.Closer, error) {\n+\tcachedPath, err := c.getCachedPath(digest, project)\n+\tif err != nil {\n+\t\treturn \"\", nil, err\n+\t}\n+\n+\tc.repoLock.Lock(cachedPath)\n+\tdefer c.repoLock.Unlock(cachedPath)\n+\n+\texists, err := fileExists(cachedPath)\n+\tif err != nil {\n+\t\treturn \"\", nil, err\n+\t}\n+\n+\tif !exists {\n+\t\tociManifest, err := getOCIManifest(ctx, digest, c.repo)\n+\t\tif err != nil {\n+\t\t\treturn \"\", nil, err\n+\t\t}\n+\n+\t\tif len(ociManifest.Layers) != 1 {\n+\t\t\treturn \"\", nil, fmt.Errorf(\"expected only a single oci layer, got %d\", len(ociManifest.Layers))\n+\t\t}\n+\n+\t\tif !slices.Contains(c.allowedMediaTypes, ociManifest.Layers[0].MediaType) {\n+\t\t\treturn \"\", nil, fmt.Errorf(\"oci layer media type %s is not in the list of allowed media types\", ociManifest.Layers[0].MediaType)\n+\t\t}\n+\n+\t\terr = saveCompressedImageToPath(ctx, digest, c.repo, cachedPath)\n+\t\tif err != nil {\n+\t\t\treturn \"\", nil, err\n+\t\t}\n+\t}\n+\n+\tmaxSize := manifestMaxExtractedSize\n+\tif disableManifestMaxExtractedSize {\n+\t\tmaxSize = math.MaxInt64\n+\t}\n+\n+\tmanifestsDir, err := extractContentToManifestsDir(ctx, cachedPath, digest, maxSize, c.allowedMediaTypes)\n+\tif err != nil {\n+\t\treturn manifestsDir, nil, err\n+\t}\n+\n+\treturn manifestsDir, argoio.NewCloser(func() error {\n+\t\treturn os.RemoveAll(manifestsDir)\n+\t}), nil\n+}\n+\n+func (c *nativeOCIClient) getCachedPath(version, project string) (string, error) {\n+\tkeyData, err := json.Marshal(map[string]string{\"url\": c.repoURL, \"project\": project, \"version\": version})\n+\tif err != nil {\n+\t\treturn \"\", err\n+\t}\n+\treturn c.repoCachePaths.GetPath(string(keyData))\n+}\n+\n+// CleanCache is invoked on a hard-refresh or when the manifest cache has expired. This removes the OCI image from the cached path.\n+func (c *nativeOCIClient) CleanCache(revision, project string) error {\n+\tcachePath, err := c.getCachedPath(revision, project)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\treturn os.RemoveAll(cachePath)\n+}\n+\n+// DigestMetadata extracts the OCI manifest for a given revision and returns it to the caller.\n+func (c *nativeOCIClient) DigestMetadata(ctx context.Context, digest, project string) (*v1.Manifest, error) {\n+\tpath, err := c.getCachedPath(digest, project)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\trepo, err := oci.NewFromTar(ctx, path)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\treturn getOCIManifest(ctx, digest, repo)\n+}\n+\n+func (c *nativeOCIClient) ResolveRevision(ctx context.Context, revision string, noCache bool) (string, error) {\n+\tconstraints, err := semver.NewConstraint(revision)\n+\tif err == nil {\n+\t\ttags, err := c.getTags(ctx, noCache)\n+\t\tif err != nil {\n+\t\t\treturn \"\", fmt.Errorf(\"error fetching tags: %w\", err)\n+\t\t}\n+\t\tversion, err := tags.MaxVersion(constraints)\n+\t\tif err != nil {\n+\t\t\treturn \"\", fmt.Errorf(\"no version for constraints: %w\", err)\n+\t\t}\n+\t\treturn c.resolveDigest(ctx, version.String())\n+\t}\n+\n+\treturn c.resolveDigest(ctx, revision)\n+}\n+\n+func (c *nativeOCIClient) getTags(ctx context.Context, noCache bool) (*TagsList, error) {\n+\tindexLock.Lock(c.repoURL)\n+\tdefer indexLock.Unlock(c.repoURL)\n+\n+\tvar data []byte\n+\tif !noCache && c.indexCache != nil {\n+\t\tif err := c.indexCache.GetHelmIndex(c.repoURL, &data); err != nil && !errors.Is(err, cache.ErrCacheMiss) {\n+\t\t\tlog.Warnf(\"Failed to load index cache for repo: %s: %s\", c.repoLock, err)\n+\t\t}\n+\t}\n+\n+\ttags := &TagsList{}\n+\tif len(data) == 0 {\n+\t\tstart := time.Now()\n+\t\tresult, err := c.tagsFunc(ctx, \"\")\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"failed to get tags: %w\", err)\n+\t\t}\n+\n+\t\tfor _, tag := range result {\n+\t\t\t// By convention: Change underscore (_) back to plus (+) to get valid SemVer\n+\t\t\tconvertedTag := strings.ReplaceAll(tag, \"_\", \"+\")\n+\t\t\ttags.Tags = append(tags.Tags, convertedTag)\n+\t\t}\n+\n+\t\tlog.WithFields(\n+\t\t\tlog.Fields{\"seconds\": time.Since(start).Seconds(), \"repo\": c.repoURL},\n+\t\t).Info(\"took to get tags\")\n+\n+\t\tif c.indexCache != nil {\n+\t\t\tif err := c.indexCache.SetHelmIndex(c.repoURL, data); err != nil {\n+\t\t\t\tlog.Warnf(\"Failed to store tags list cache for repo: %s: %s\", c.repoURL, err)\n+\t\t\t}\n+\t\t}\n+\t} else {\n+\t\terr := json.Unmarshal(data, tags)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"failed to decode tags: %w\", err)\n+\t\t}\n+\t}\n+\n+\treturn tags, nil\n+}\n+\n+// resolveDigest resolves a digest from a tag.\n+func (c *nativeOCIClient) resolveDigest(ctx context.Context, revision string) (string, error) {\n+\tdescriptor, err := c.repo.Resolve(ctx, revision)\n+\tif err != nil {\n+\t\treturn \"\", fmt.Errorf(\"cannot get digest for revision %s: %w\", revision, err)\n+\t}\n+\n+\treturn descriptor.Digest.String(), nil\n+}\n+\n+func newTLSConfig(creds Creds) (*tls.Config, error) {\n+\ttlsConfig := &tls.Config{InsecureSkipVerify: creds.InsecureSkipVerify}\n+\n+\tif creds.CAPath != \"\" {\n+\t\tcaData, err := os.ReadFile(creds.CAPath)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\tcaCertPool := x509.NewCertPool()\n+\t\tcaCertPool.AppendCertsFromPEM(caData)\n+\t\ttlsConfig.RootCAs = caCertPool\n+\t}\n+\n+\t// If a client cert & key is provided then configure TLS config accordingly.\n+\tif len(creds.CertData) > 0 && len(creds.KeyData) > 0 {\n+\t\tcert, err := tls.X509KeyPair(creds.CertData, creds.KeyData)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t\ttlsConfig.Certificates = []tls.Certificate{cert}\n+\t}\n+\t// nolint:staticcheck\n+\ttlsConfig.BuildNameToCertificate()\n+\n+\treturn tlsConfig, nil\n+}\n+\n+func fileExists(filePath string) (bool, error) {\n+\tif _, err := os.Stat(filePath); err != nil {\n+\t\tif os.IsNotExist(err) {\n+\t\t\treturn false, nil\n+\t\t} else {\n+\t\t\treturn false, err\n+\t\t}\n+\t}\n+\treturn true, nil\n+}\n+\n+func isHelmOCI(mediaType string) bool {\n+\treturn mediaType == \"application/vnd.cncf.helm.chart.content.v1.tar+gzip\"\n+}\n+\n+func isCompressedLayer(mediaType string) bool {\n+\treturn strings.HasSuffix(mediaType, \"tar+gzip\") || strings.HasSuffix(mediaType, \"tar\")\n+}\n+\n+func createTarFile(from, to string) error {\n+\tf, err := os.Create(to)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t_, err = files.Tar(from, nil, nil, f)\n+\tif err != nil {\n+\t\t_ = os.RemoveAll(to)\n+\t}\n+\treturn f.Close()\n+}\n+\n+// saveCompressedImageToPath downloads a remote OCI image on a given digest and stores it as a TAR file in cachedPath.\n+func saveCompressedImageToPath(ctx context.Context, digest string, repo oras.ReadOnlyTarget, cachedPath string) error {\n+\ttempDir, err := files.CreateTempDir(os.TempDir())\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tdefer os.RemoveAll(tempDir)\n+\n+\tstore, err := oci.New(tempDir)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Copy remote repo at the given digest to the scratch dir.\n+\t_, err = oras.Copy(ctx, repo, digest, store, digest, oras.DefaultCopyOptions)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Remove redundant ingest folder; this is an artifact from the oras.Copy call above\n+\terr = os.RemoveAll(path.Join(tempDir, \"ingest\"))\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Save contents to tar file\n+\treturn createTarFile(tempDir, cachedPath)\n+}\n+\n+// extractContentToManifestsDir looks up a locally stored OCI image, and extracts the embedded compressed layer which contains\n+// K8s manifests to a temporary directory\n+func extractContentToManifestsDir(ctx context.Context, cachedPath, digest string, maxSize int64, allowedMediaTypes []string) (string, error) {\n+\tmanifestsDir, err := files.CreateTempDir(os.TempDir())\n+\tif err != nil {\n+\t\treturn manifestsDir, err\n+\t}\n+\n+\tociReadOnlyStore, err := oci.NewFromTar(ctx, cachedPath)\n+\tif err != nil {\n+\t\treturn manifestsDir, err\n+\t}\n+\n+\ttempDir, err := files.CreateTempDir(os.TempDir())\n+\tif err != nil {\n+\t\treturn manifestsDir, err\n+\t}\n+\tdefer os.RemoveAll(tempDir)\n+\n+\tfs, err := newCompressedLayerFileStore(manifestsDir, tempDir, maxSize, allowedMediaTypes)\n+\tif err != nil {\n+\t\treturn manifestsDir, err\n+\t}\n+\tdefer fs.Close()\n+\n+\t// copies the whole artifact to the tempdir, here compressedLayerFileStore.Push will be called\n+\t_, err = oras.Copy(ctx, ociReadOnlyStore, digest, fs, digest, oras.DefaultCopyOptions)\n+\treturn manifestsDir, err\n+}\n+\n+type compressedLayerExtracterStore struct {\n+\t*file.Store\n+\ttempDir           string\n+\tdest              string\n+\tmaxSize           int64\n+\tallowedMediaTypes []string\n+}\n+\n+func newCompressedLayerFileStore(dest, tempDir string, maxSize int64, allowedMediaTypes []string) (*compressedLayerExtracterStore, error) {\n+\tf, err := file.New(tempDir)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\treturn &compressedLayerExtracterStore{f, tempDir, dest, maxSize, allowedMediaTypes}, nil\n+}\n+\n+// Push looks in all the layers of an OCI image. Once it finds a layer that is compressed, it extracts the layer to a tempDir\n+// and then renames the temp dir to the directory where the repo-server expects to find k8s manifests.\n+func (s *compressedLayerExtracterStore) Push(ctx context.Context, desc v1.Descriptor, content io.Reader) error {\n+\tif isCompressedLayer(desc.MediaType) {\n+\t\ttempDir, err := files.CreateTempDir(os.TempDir())\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\t\tdefer os.RemoveAll(tempDir)\n+\n+\t\tif strings.HasSuffix(desc.MediaType, \"tar+gzip\") {\n+\t\t\terr = files.Untgz(tempDir, content, s.maxSize, false)\n+\t\t} else {\n+\t\t\terr = files.Untar(tempDir, content, s.maxSize, false)\n+\t\t}\n+\n+\t\tif err != nil {\n+\t\t\treturn fmt.Errorf(\"could not decompress layer: %w\", err)\n+\t\t}\n+\n+\t\tinfos, err := os.ReadDir(tempDir)\n+\t\tif err != nil {\n+\t\t\treturn err\n+\t\t}\n+\n+\t\tif isHelmOCI(desc.MediaType) {\n+\t\t\t// For a Helm chart we expect a single tarfile in the directory\n+\t\t\tif len(infos) != 1 {\n+\t\t\t\treturn fmt.Errorf(\"expected 1 file, found %v\", len(infos))\n+\t\t\t}\n+\t\t}\n+\n+\t\tif len(infos) == 1 && infos[0].IsDir() {\n+\t\t\t// Here we assume that this is a directory which has been decompressed. We need to move the contents of\n+\t\t\t// the dir into our intended destination.\n+\t\t\tsrcDir := filepath.Join(tempDir, infos[0].Name())\n+\t\t\treturn filepath.WalkDir(srcDir, func(path string, d fs.DirEntry, err error) error {\n+\t\t\t\tif path != srcDir {\n+\t\t\t\t\t// Calculate the relative path from srcDir\n+\t\t\t\t\trelPath, err := filepath.Rel(srcDir, path)\n+\t\t\t\t\tif err != nil {\n+\t\t\t\t\t\treturn err\n+\t\t\t\t\t}\n+\n+\t\t\t\t\tdstPath := filepath.Join(s.dest, relPath)",
        "comment_created_at": "2024-12-04T17:42:19+00:00",
        "comment_author": "crenshaw-dev",
        "comment_body": "Ditto re: securejoin. If `relPath` refers to a symlink, this join could end up referring to something above `s.dest`.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1867971485",
    "pr_number": 21044,
    "pr_file": "applicationset/generators/plugin.go",
    "created_at": "2024-12-03T15:45:53+00:00",
    "commented_code": "return res, nil\n }\n \n-func (g *PluginGenerator) getPluginFromGenerator(ctx context.Context, appSetName string, generatorConfig *argoprojiov1alpha1.PluginGenerator) (*plugin.Service, error) {\n-\tcm, err := g.getConfigMap(ctx, generatorConfig.ConfigMapRef.Name)\n+func (g *PluginGenerator) getPluginConfigNamespaceOrDefaultToAppSetNamespace(plugin *argoprojiov1alpha1.PluginGenerator, applicationSetInfo *argoprojiov1alpha1.ApplicationSet) string {\n+\tif plugin.ConfigMapRef.Namespace != \"\" {\n+\t\treturn plugin.ConfigMapRef.Namespace\n+\t}\n+\treturn applicationSetInfo.Namespace",
    "repo_full_name": "argoproj/argo-cd",
    "discussion_comments": [
      {
        "comment_id": "1867971485",
        "repo_full_name": "argoproj/argo-cd",
        "pr_number": 21044,
        "pr_file": "applicationset/generators/plugin.go",
        "discussion_id": "1867971485",
        "commented_code": "@@ -86,12 +88,19 @@ func (g *PluginGenerator) GenerateParams(appSetGenerator *argoprojiov1alpha1.App\n \treturn res, nil\n }\n \n-func (g *PluginGenerator) getPluginFromGenerator(ctx context.Context, appSetName string, generatorConfig *argoprojiov1alpha1.PluginGenerator) (*plugin.Service, error) {\n-\tcm, err := g.getConfigMap(ctx, generatorConfig.ConfigMapRef.Name)\n+func (g *PluginGenerator) getPluginConfigNamespaceOrDefaultToAppSetNamespace(plugin *argoprojiov1alpha1.PluginGenerator, applicationSetInfo *argoprojiov1alpha1.ApplicationSet) string {\n+\tif plugin.ConfigMapRef.Namespace != \"\" {\n+\t\treturn plugin.ConfigMapRef.Namespace\n+\t}\n+\treturn applicationSetInfo.Namespace",
        "comment_created_at": "2024-12-03T15:45:53+00:00",
        "comment_author": "crenshaw-dev",
        "comment_body": "We should probably require that ConfigMaps outside the argocd namespace have some label advertising them as available for use as a plugin. Otherwise users might use the AppSet as a way to try to leak information from arbitrary ConfigMaps which they may or may not have access to.",
        "pr_file_module": null
      },
      {
        "comment_id": "1867988542",
        "repo_full_name": "argoproj/argo-cd",
        "pr_number": 21044,
        "pr_file": "applicationset/generators/plugin.go",
        "discussion_id": "1867971485",
        "commented_code": "@@ -86,12 +88,19 @@ func (g *PluginGenerator) GenerateParams(appSetGenerator *argoprojiov1alpha1.App\n \treturn res, nil\n }\n \n-func (g *PluginGenerator) getPluginFromGenerator(ctx context.Context, appSetName string, generatorConfig *argoprojiov1alpha1.PluginGenerator) (*plugin.Service, error) {\n-\tcm, err := g.getConfigMap(ctx, generatorConfig.ConfigMapRef.Name)\n+func (g *PluginGenerator) getPluginConfigNamespaceOrDefaultToAppSetNamespace(plugin *argoprojiov1alpha1.PluginGenerator, applicationSetInfo *argoprojiov1alpha1.ApplicationSet) string {\n+\tif plugin.ConfigMapRef.Namespace != \"\" {\n+\t\treturn plugin.ConfigMapRef.Namespace\n+\t}\n+\treturn applicationSetInfo.Namespace",
        "comment_created_at": "2024-12-03T15:56:10+00:00",
        "comment_author": "OpenGuidou",
        "comment_body": "Agreed !",
        "pr_file_module": null
      },
      {
        "comment_id": "1868033027",
        "repo_full_name": "argoproj/argo-cd",
        "pr_number": 21044,
        "pr_file": "applicationset/generators/plugin.go",
        "discussion_id": "1867971485",
        "commented_code": "@@ -86,12 +88,19 @@ func (g *PluginGenerator) GenerateParams(appSetGenerator *argoprojiov1alpha1.App\n \treturn res, nil\n }\n \n-func (g *PluginGenerator) getPluginFromGenerator(ctx context.Context, appSetName string, generatorConfig *argoprojiov1alpha1.PluginGenerator) (*plugin.Service, error) {\n-\tcm, err := g.getConfigMap(ctx, generatorConfig.ConfigMapRef.Name)\n+func (g *PluginGenerator) getPluginConfigNamespaceOrDefaultToAppSetNamespace(plugin *argoprojiov1alpha1.PluginGenerator, applicationSetInfo *argoprojiov1alpha1.ApplicationSet) string {\n+\tif plugin.ConfigMapRef.Namespace != \"\" {\n+\t\treturn plugin.ConfigMapRef.Namespace\n+\t}\n+\treturn applicationSetInfo.Namespace",
        "comment_created_at": "2024-12-03T16:24:29+00:00",
        "comment_author": "OpenGuidou",
        "comment_body": "Added in the pr",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1791891447",
    "pr_number": 20074,
    "pr_file": "cmd/argocd/commands/plugin.go",
    "created_at": "2024-10-08T13:34:22+00:00",
    "commented_code": "+package commands\n+\n+import (\n+\tpluginError \"errors\"\n+\t\"fmt\"\n+\t\"os\"\n+\t\"os/exec\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+)\n+\n+type ArgoCDCLIOptions struct {\n+\tPluginHandler PluginHandler\n+\tArguments     []string\n+}\n+\n+// PluginHandler parses command line arguments\n+// and performs executable filename lookups to search\n+// for valid plugin files, and execute found plugins.\n+type PluginHandler interface {\n+\t// LookForPlugin will iterate over a list of given prefixes\n+\t// in order to recognize valid plugin filenames.\n+\t// The first filepath to match a prefix is returned.\n+\tLookForPlugin(filename string) (string, bool)\n+\t// ExecutePlugin receives an executable's filepath, a slice\n+\t// of arguments, and a slice of environment variables\n+\t// to relay to the executable.\n+\tExecutePlugin(executablePath string, cmdArgs, environment []string) error\n+}\n+\n+// DefaultPluginHandler implements the PluginHandler interface\n+type DefaultPluginHandler struct {\n+\tValidPrefixes []string\n+}\n+\n+// NewDefaultPluginHandler instantiates the DefaultPluginHandler\n+func NewDefaultPluginHandler(validPrefixes []string) *DefaultPluginHandler {\n+\treturn &DefaultPluginHandler{\n+\t\tValidPrefixes: validPrefixes,\n+\t}\n+}\n+\n+// HandlePluginCommand is  responsible for finding and executing a plugin when a command isn't recognized as a built-in command\n+func HandlePluginCommand(pluginHandler PluginHandler, cmdArgs []string, minArgs int) error {\n+\tvar remainingArgs []string // this will contain all \"non-flag\" arguments\n+\tfor _, arg := range cmdArgs {\n+\t\t// if you encounter a flag, break the loop\n+\t\t// For eg. If cmdArgs is [\"argocd\", \"foo\", \"-v\"],\n+\t\t// it will store [\"argocd\", \"foo\"] in remainingArgs\n+\t\t// and stop when it hits the flag -v\n+\t\tif strings.HasPrefix(arg, \"-\") {\n+\t\t\tbreak\n+\t\t}\n+\t\tremainingArgs = append(remainingArgs, strings.Replace(arg, \"-\", \"_\", -1))\n+\t}\n+\n+\tif len(remainingArgs) == 0 {\n+\t\t// the length of cmdArgs is at least 1\n+\t\treturn fmt.Errorf(\"flags cannot be placed before plugin name: %s\", cmdArgs[0])\n+\t}\n+\n+\tfoundPluginPath := \"\"\n+\n+\t// try to find the binary, starting at longest possible name with given cmdArgs\n+\tfor len(remainingArgs) > 0 {\n+\t\tpath, found := pluginHandler.LookForPlugin(strings.Join(remainingArgs, \"-\"))\n+\t\tif !found {\n+\t\t\tremainingArgs = remainingArgs[:len(remainingArgs)-1]\n+\t\t\tif len(remainingArgs) < minArgs {\n+\t\t\t\tbreak\n+\t\t\t}\n+\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\tfoundPluginPath = path\n+\t\tbreak\n+\t}\n+\n+\tif len(foundPluginPath) == 0 {\n+\t\treturn nil\n+\t}\n+\n+\t// Execute the plugin that is found\n+\tif err := pluginHandler.ExecutePlugin(foundPluginPath, cmdArgs[len(remainingArgs):], os.Environ()); err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn nil\n+}\n+\n+// LookForPlugin implements PluginHandler\n+func (h *DefaultPluginHandler) LookForPlugin(filename string) (string, bool) {\n+\tfor _, prefix := range h.ValidPrefixes {\n+\t\tpath, err := exec.LookPath(fmt.Sprintf(\"%s-%s\", prefix, filename))\n+\t\tif shouldSkipOnLookPathErr(err) || len(path) == 0 {\n+\t\t\tcontinue\n+\t\t}\n+\t\treturn path, true\n+\t}\n+\treturn \"\", false\n+}\n+\n+// ExecutePlugin implements PluginHandler and executes a plugin found\n+func (h *DefaultPluginHandler) ExecutePlugin(executablePath string, cmdArgs, environment []string) error {\n+\tcmd := Command(executablePath, cmdArgs...)\n+\tcmd.Stdout = os.Stdout\n+\tcmd.Stderr = os.Stderr\n+\tcmd.Stdin = os.Stdin\n+\tcmd.Env = environment\n+\n+\terr := cmd.Run()\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Exit with status 0 if successful, though in most use cases this won't be reached\n+\tos.Exit(0)\n+\treturn nil\n+}\n+\n+// Command creates a new command for all OSs\n+func Command(name string, arg ...string) *exec.Cmd {\n+\tcmd := &exec.Cmd{\n+\t\tPath: name,\n+\t\tArgs: append([]string{name}, arg...),\n+\t}\n+\tif filepath.Base(name) == name {\n+\t\tlp, err := exec.LookPath(name)\n+\t\tif lp != \"\" && !shouldSkipOnLookPathErr(err) {",
    "repo_full_name": "argoproj/argo-cd",
    "discussion_comments": [
      {
        "comment_id": "1791891447",
        "repo_full_name": "argoproj/argo-cd",
        "pr_number": 20074,
        "pr_file": "cmd/argocd/commands/plugin.go",
        "discussion_id": "1791891447",
        "commented_code": "@@ -0,0 +1,143 @@\n+package commands\n+\n+import (\n+\tpluginError \"errors\"\n+\t\"fmt\"\n+\t\"os\"\n+\t\"os/exec\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+)\n+\n+type ArgoCDCLIOptions struct {\n+\tPluginHandler PluginHandler\n+\tArguments     []string\n+}\n+\n+// PluginHandler parses command line arguments\n+// and performs executable filename lookups to search\n+// for valid plugin files, and execute found plugins.\n+type PluginHandler interface {\n+\t// LookForPlugin will iterate over a list of given prefixes\n+\t// in order to recognize valid plugin filenames.\n+\t// The first filepath to match a prefix is returned.\n+\tLookForPlugin(filename string) (string, bool)\n+\t// ExecutePlugin receives an executable's filepath, a slice\n+\t// of arguments, and a slice of environment variables\n+\t// to relay to the executable.\n+\tExecutePlugin(executablePath string, cmdArgs, environment []string) error\n+}\n+\n+// DefaultPluginHandler implements the PluginHandler interface\n+type DefaultPluginHandler struct {\n+\tValidPrefixes []string\n+}\n+\n+// NewDefaultPluginHandler instantiates the DefaultPluginHandler\n+func NewDefaultPluginHandler(validPrefixes []string) *DefaultPluginHandler {\n+\treturn &DefaultPluginHandler{\n+\t\tValidPrefixes: validPrefixes,\n+\t}\n+}\n+\n+// HandlePluginCommand is  responsible for finding and executing a plugin when a command isn't recognized as a built-in command\n+func HandlePluginCommand(pluginHandler PluginHandler, cmdArgs []string, minArgs int) error {\n+\tvar remainingArgs []string // this will contain all \"non-flag\" arguments\n+\tfor _, arg := range cmdArgs {\n+\t\t// if you encounter a flag, break the loop\n+\t\t// For eg. If cmdArgs is [\"argocd\", \"foo\", \"-v\"],\n+\t\t// it will store [\"argocd\", \"foo\"] in remainingArgs\n+\t\t// and stop when it hits the flag -v\n+\t\tif strings.HasPrefix(arg, \"-\") {\n+\t\t\tbreak\n+\t\t}\n+\t\tremainingArgs = append(remainingArgs, strings.Replace(arg, \"-\", \"_\", -1))\n+\t}\n+\n+\tif len(remainingArgs) == 0 {\n+\t\t// the length of cmdArgs is at least 1\n+\t\treturn fmt.Errorf(\"flags cannot be placed before plugin name: %s\", cmdArgs[0])\n+\t}\n+\n+\tfoundPluginPath := \"\"\n+\n+\t// try to find the binary, starting at longest possible name with given cmdArgs\n+\tfor len(remainingArgs) > 0 {\n+\t\tpath, found := pluginHandler.LookForPlugin(strings.Join(remainingArgs, \"-\"))\n+\t\tif !found {\n+\t\t\tremainingArgs = remainingArgs[:len(remainingArgs)-1]\n+\t\t\tif len(remainingArgs) < minArgs {\n+\t\t\t\tbreak\n+\t\t\t}\n+\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\tfoundPluginPath = path\n+\t\tbreak\n+\t}\n+\n+\tif len(foundPluginPath) == 0 {\n+\t\treturn nil\n+\t}\n+\n+\t// Execute the plugin that is found\n+\tif err := pluginHandler.ExecutePlugin(foundPluginPath, cmdArgs[len(remainingArgs):], os.Environ()); err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn nil\n+}\n+\n+// LookForPlugin implements PluginHandler\n+func (h *DefaultPluginHandler) LookForPlugin(filename string) (string, bool) {\n+\tfor _, prefix := range h.ValidPrefixes {\n+\t\tpath, err := exec.LookPath(fmt.Sprintf(\"%s-%s\", prefix, filename))\n+\t\tif shouldSkipOnLookPathErr(err) || len(path) == 0 {\n+\t\t\tcontinue\n+\t\t}\n+\t\treturn path, true\n+\t}\n+\treturn \"\", false\n+}\n+\n+// ExecutePlugin implements PluginHandler and executes a plugin found\n+func (h *DefaultPluginHandler) ExecutePlugin(executablePath string, cmdArgs, environment []string) error {\n+\tcmd := Command(executablePath, cmdArgs...)\n+\tcmd.Stdout = os.Stdout\n+\tcmd.Stderr = os.Stderr\n+\tcmd.Stdin = os.Stdin\n+\tcmd.Env = environment\n+\n+\terr := cmd.Run()\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Exit with status 0 if successful, though in most use cases this won't be reached\n+\tos.Exit(0)\n+\treturn nil\n+}\n+\n+// Command creates a new command for all OSs\n+func Command(name string, arg ...string) *exec.Cmd {\n+\tcmd := &exec.Cmd{\n+\t\tPath: name,\n+\t\tArgs: append([]string{name}, arg...),\n+\t}\n+\tif filepath.Base(name) == name {\n+\t\tlp, err := exec.LookPath(name)\n+\t\tif lp != \"\" && !shouldSkipOnLookPathErr(err) {",
        "comment_created_at": "2024-10-08T13:34:22+00:00",
        "comment_author": "leoluz",
        "comment_body": "This may lead to security implications. For example: if someone has their `PATH` configured as `PATH=.:/usr/bin`, the first `.` makes the current directory available in the PATH which enables different types of exploits. Go 1.19+ will return `ErrDot` to notify us that the return value from `LookPath()` is a relative path. We shouldn't ignore this error. Instead, we should fail and return an error stating that the executable wasn't found. Also, we must state in the docs that the plugin executable must be in the path and should not be provided as relative path.",
        "pr_file_module": null
      },
      {
        "comment_id": "1965321078",
        "repo_full_name": "argoproj/argo-cd",
        "pr_number": 20074,
        "pr_file": "cmd/argocd/commands/plugin.go",
        "discussion_id": "1791891447",
        "commented_code": "@@ -0,0 +1,143 @@\n+package commands\n+\n+import (\n+\tpluginError \"errors\"\n+\t\"fmt\"\n+\t\"os\"\n+\t\"os/exec\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+)\n+\n+type ArgoCDCLIOptions struct {\n+\tPluginHandler PluginHandler\n+\tArguments     []string\n+}\n+\n+// PluginHandler parses command line arguments\n+// and performs executable filename lookups to search\n+// for valid plugin files, and execute found plugins.\n+type PluginHandler interface {\n+\t// LookForPlugin will iterate over a list of given prefixes\n+\t// in order to recognize valid plugin filenames.\n+\t// The first filepath to match a prefix is returned.\n+\tLookForPlugin(filename string) (string, bool)\n+\t// ExecutePlugin receives an executable's filepath, a slice\n+\t// of arguments, and a slice of environment variables\n+\t// to relay to the executable.\n+\tExecutePlugin(executablePath string, cmdArgs, environment []string) error\n+}\n+\n+// DefaultPluginHandler implements the PluginHandler interface\n+type DefaultPluginHandler struct {\n+\tValidPrefixes []string\n+}\n+\n+// NewDefaultPluginHandler instantiates the DefaultPluginHandler\n+func NewDefaultPluginHandler(validPrefixes []string) *DefaultPluginHandler {\n+\treturn &DefaultPluginHandler{\n+\t\tValidPrefixes: validPrefixes,\n+\t}\n+}\n+\n+// HandlePluginCommand is  responsible for finding and executing a plugin when a command isn't recognized as a built-in command\n+func HandlePluginCommand(pluginHandler PluginHandler, cmdArgs []string, minArgs int) error {\n+\tvar remainingArgs []string // this will contain all \"non-flag\" arguments\n+\tfor _, arg := range cmdArgs {\n+\t\t// if you encounter a flag, break the loop\n+\t\t// For eg. If cmdArgs is [\"argocd\", \"foo\", \"-v\"],\n+\t\t// it will store [\"argocd\", \"foo\"] in remainingArgs\n+\t\t// and stop when it hits the flag -v\n+\t\tif strings.HasPrefix(arg, \"-\") {\n+\t\t\tbreak\n+\t\t}\n+\t\tremainingArgs = append(remainingArgs, strings.Replace(arg, \"-\", \"_\", -1))\n+\t}\n+\n+\tif len(remainingArgs) == 0 {\n+\t\t// the length of cmdArgs is at least 1\n+\t\treturn fmt.Errorf(\"flags cannot be placed before plugin name: %s\", cmdArgs[0])\n+\t}\n+\n+\tfoundPluginPath := \"\"\n+\n+\t// try to find the binary, starting at longest possible name with given cmdArgs\n+\tfor len(remainingArgs) > 0 {\n+\t\tpath, found := pluginHandler.LookForPlugin(strings.Join(remainingArgs, \"-\"))\n+\t\tif !found {\n+\t\t\tremainingArgs = remainingArgs[:len(remainingArgs)-1]\n+\t\t\tif len(remainingArgs) < minArgs {\n+\t\t\t\tbreak\n+\t\t\t}\n+\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\tfoundPluginPath = path\n+\t\tbreak\n+\t}\n+\n+\tif len(foundPluginPath) == 0 {\n+\t\treturn nil\n+\t}\n+\n+\t// Execute the plugin that is found\n+\tif err := pluginHandler.ExecutePlugin(foundPluginPath, cmdArgs[len(remainingArgs):], os.Environ()); err != nil {\n+\t\treturn err\n+\t}\n+\n+\treturn nil\n+}\n+\n+// LookForPlugin implements PluginHandler\n+func (h *DefaultPluginHandler) LookForPlugin(filename string) (string, bool) {\n+\tfor _, prefix := range h.ValidPrefixes {\n+\t\tpath, err := exec.LookPath(fmt.Sprintf(\"%s-%s\", prefix, filename))\n+\t\tif shouldSkipOnLookPathErr(err) || len(path) == 0 {\n+\t\t\tcontinue\n+\t\t}\n+\t\treturn path, true\n+\t}\n+\treturn \"\", false\n+}\n+\n+// ExecutePlugin implements PluginHandler and executes a plugin found\n+func (h *DefaultPluginHandler) ExecutePlugin(executablePath string, cmdArgs, environment []string) error {\n+\tcmd := Command(executablePath, cmdArgs...)\n+\tcmd.Stdout = os.Stdout\n+\tcmd.Stderr = os.Stderr\n+\tcmd.Stdin = os.Stdin\n+\tcmd.Env = environment\n+\n+\terr := cmd.Run()\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// Exit with status 0 if successful, though in most use cases this won't be reached\n+\tos.Exit(0)\n+\treturn nil\n+}\n+\n+// Command creates a new command for all OSs\n+func Command(name string, arg ...string) *exec.Cmd {\n+\tcmd := &exec.Cmd{\n+\t\tPath: name,\n+\t\tArgs: append([]string{name}, arg...),\n+\t}\n+\tif filepath.Base(name) == name {\n+\t\tlp, err := exec.LookPath(name)\n+\t\tif lp != \"\" && !shouldSkipOnLookPathErr(err) {",
        "comment_created_at": "2025-02-21T11:23:41+00:00",
        "comment_author": "nitishfy",
        "comment_body": "marking it as resolved since we execute plugins only found in the absolute path and not relative path.",
        "pr_file_module": null
      }
    ]
  }
]