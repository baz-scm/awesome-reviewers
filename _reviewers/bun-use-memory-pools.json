[
  {
    "discussion_id": "2191503936",
    "pr_number": 20440,
    "pr_file": "src/install/isolated_install/Installer.zig",
    "created_at": "2025-07-08T05:22:55+00:00",
    "commented_code": "+pub const Installer = struct {\n+    trusted_dependencies_mutex: bun.Mutex,\n+    // this is not const for `lockfile.trusted_dependencies`\n+    lockfile: *Lockfile,\n+\n+    summary: PackageInstall.Summary = .{ .successfully_installed = .empty },\n+    installed: Bitset,\n+    install_node: ?*Progress.Node,\n+    scripts_node: ?*Progress.Node,\n+\n+    manager: *PackageManager,\n+    command_ctx: Command.Context,\n+\n+    store: *const Store,\n+\n+    tasks: bun.UnboundedQueue(Task, .next) = .{},\n+    preallocated_tasks: Task.Preallocated,\n+\n+    trusted_dependencies_from_update_requests: std.AutoArrayHashMapUnmanaged(TruncatedPackageNameHash, void),\n+\n+    pub fn deinit(this: *const Installer) void {\n+        this.trusted_dependencies_from_update_requests.deinit(this.lockfile.allocator);\n+    }\n+\n+    pub fn resumeTask(this: *Installer, entry_id: Store.Entry.Id) void {\n+        const task = this.preallocated_tasks.get();\n+\n+        task.* = .{\n+            .entry_id = entry_id,\n+            .installer = this,\n+            .err = null,\n+        };\n+\n+        this.manager.thread_pool.schedule(.from(&task.task));\n+    }\n+\n+    pub fn onPackageExtracted(this: *Installer, task_id: install.Task.Id) void {\n+        if (this.manager.task_queue.fetchRemove(task_id)) |removed| {\n+            for (removed.value.items) |install_ctx| {\n+                const entry_id = install_ctx.isolated_package_install_context;\n+                this.resumeTask(entry_id);\n+            }\n+        }\n+    }\n+\n+    pub fn onTaskFail(this: *Installer, entry_id: Store.Entry.Id, err: Task.Error) void {\n+        const string_buf = this.lockfile.buffers.string_bytes.items;\n+\n+        const entries = this.store.entries.slice();\n+        const entry_node_ids = entries.items(.node_id);\n+\n+        const nodes = this.store.nodes.slice();\n+        const node_pkg_ids = nodes.items(.pkg_id);\n+\n+        const pkgs = this.lockfile.packages.slice();\n+        const pkg_names = pkgs.items(.name);\n+        const pkg_resolutions = pkgs.items(.resolution);\n+\n+        const node_id = entry_node_ids[entry_id.get()];\n+        const pkg_id = node_pkg_ids[node_id.get()];\n+\n+        const pkg_name = pkg_names[pkg_id];\n+        const pkg_res = pkg_resolutions[pkg_id];\n+\n+        switch (err) {\n+            .link_package => |link_err| {\n+                Output.err(link_err, \"failed to link package: {s}@{}\", .{\n+                    pkg_name.slice(string_buf),\n+                    pkg_res.fmt(string_buf, .auto),\n+                });\n+            },\n+            .symlink_dependencies => |symlink_err| {\n+                Output.err(symlink_err, \"failed to symlink dependencies for package: {s}@{}\", .{\n+                    pkg_name.slice(string_buf),\n+                    pkg_res.fmt(string_buf, .auto),\n+                });\n+            },\n+            else => {},\n+        }\n+        Output.flush();\n+\n+        // attempt deleting the package so the next install will install it again\n+        switch (pkg_res.tag) {\n+            .uninitialized,\n+            .single_file_module,\n+            .root,\n+            .workspace,\n+            .symlink,\n+            => {},\n+\n+            _ => {},\n+\n+            // to be safe make sure we only delete packages in the store\n+            .npm,\n+            .git,\n+            .github,\n+            .local_tarball,\n+            .remote_tarball,\n+            .folder,\n+            => {\n+                var store_path: bun.RelPath(.{ .sep = .auto }) = .init();\n+                defer store_path.deinit();\n+\n+                store_path.appendFmt(\"node_modules/{}\", .{\n+                    Store.Entry.fmtStorePath(entry_id, this.store, this.lockfile),\n+                });\n+\n+                _ = sys.unlink(store_path.sliceZ());\n+            },\n+        }\n+\n+        if (this.manager.options.enable.fail_early) {\n+            Global.exit(1);\n+        }\n+\n+        this.summary.fail += 1;\n+\n+        this.decrementPendingTasks(entry_id);\n+        this.resumeAvailableTasks();\n+    }\n+\n+    pub fn onTask(this: *Installer, task_entry_id: Store.Entry.Id) void {\n+        const entries = this.store.entries.slice();\n+        const entry_steps = entries.items(.step);\n+        const step = entry_steps[task_entry_id.get()].load(.monotonic);\n+\n+        if (step != .done) {\n+            // only done will unblock other packages\n+            return;\n+        }\n+\n+        this.onTaskSuccess(task_entry_id);\n+    }\n+\n+    pub fn decrementPendingTasks(this: *Installer, entry_id: Store.Entry.Id) void {\n+        _ = entry_id;\n+        this.manager.decrementPendingTasks();\n+    }\n+\n+    pub fn onTaskSkipped(this: *Installer, entry_id: Store.Entry.Id) void {\n+        this.summary.skipped += 1;\n+        this.decrementPendingTasks(entry_id);\n+        this.store.entries.items(.step)[entry_id.get()].store(.done, .monotonic);\n+        if (this.install_node) |node| {\n+            node.completeOne();\n+        }\n+        this.resumeAvailableTasks();\n+    }\n+\n+    pub fn onTaskSuccess(this: *Installer, entry_id: Store.Entry.Id) void {\n+        this.decrementPendingTasks(entry_id);\n+        this.resumeAvailableTasks();\n+\n+        const pkg_id = pkg_id: {\n+            if (entry_id == .root) {\n+                return;\n+            }\n+\n+            const node_id = this.store.entries.items(.node_id)[entry_id.get()];\n+            const nodes = this.store.nodes.slice();\n+\n+            const dep_id = nodes.items(.dep_id)[node_id.get()];\n+\n+            if (dep_id == invalid_dependency_id) {\n+                // should be coverd by `entry_id == .root` above, but\n+                // just in case\n+                return;\n+            }\n+\n+            const dep = this.lockfile.buffers.dependencies.items[dep_id];\n+\n+            if (dep.behavior.isWorkspaceOnly()) {\n+                return;\n+            }\n+\n+            break :pkg_id nodes.items(.pkg_id)[node_id.get()];\n+        };\n+\n+        const is_duplicate = this.installed.isSet(pkg_id);\n+        this.summary.success += @intFromBool(!is_duplicate);\n+        this.installed.set(pkg_id);\n+        if (this.install_node) |node| {\n+            node.completeOne();\n+        }\n+    }\n+\n+    pub fn resumeAvailableTasks(this: *Installer) void {\n+        const entries = this.store.entries.slice();\n+        const entry_deps = entries.items(.dependencies);\n+        const entry_steps = entries.items(.step);\n+\n+        var parent_dedupe: std.AutoArrayHashMap(Store.Entry.Id, void) = .init(bun.default_allocator);\n+        defer parent_dedupe.deinit();\n+\n+        next_entry: for (0..this.store.entries.len) |_entry_id| {\n+            const entry_id: Store.Entry.Id = .from(@intCast(_entry_id));\n+\n+            const entry_step = entry_steps[entry_id.get()].load(.monotonic);\n+            if (entry_step != .blocked) {\n+                continue;\n+            }\n+\n+            const deps = entry_deps[entry_id.get()];\n+            for (deps.slice()) |dep| {\n+                switch (entry_steps[dep.entry_id.get()].load(.monotonic)) {\n+                    .done => {},\n+                    else => {\n+                        parent_dedupe.clearRetainingCapacity();\n+                        if (!this.store.isCycle(entry_id, dep.entry_id, &parent_dedupe)) {\n+                            continue :next_entry;\n+                        }\n+                    },\n+                }\n+            }\n+\n+            entry_steps[entry_id.get()].store(.symlink_dependency_binaries, .monotonic);\n+            this.resumeTask(entry_id);\n+        }\n+    }\n+\n+    pub const Task = struct {\n+        const Preallocated = bun.HiveArray(Task, 128).Fallback;\n+\n+        entry_id: Store.Entry.Id,\n+        installer: *Installer,\n+\n+        task: ThreadPool.Task = .{ .callback = &callback },\n+        next: ?*Task = null,\n+\n+        err: ?Error,\n+\n+        const Error = union(Step) {\n+            link_package: sys.Error,\n+            symlink_dependencies: sys.Error,\n+            check_if_blocked,\n+            symlink_dependency_binaries,\n+            run_preinstall: anyerror,\n+            binaries: anyerror,\n+            @\"run (post)install and (pre/post)prepare\": anyerror,\n+            done,\n+            blocked,\n+\n+            pub fn clone(this: *const Error, allocator: std.mem.Allocator) Error {\n+                return switch (this.*) {\n+                    .link_package => |err| .{ .link_package = err.clone(allocator) },\n+                    .symlink_dependencies => |err| .{ .symlink_dependencies = err.clone(allocator) },\n+                    .check_if_blocked => .check_if_blocked,\n+                    .symlink_dependency_binaries => .symlink_dependency_binaries,\n+                    .run_preinstall => |err| .{ .run_preinstall = err },\n+                    .binaries => |err| .{ .binaries = err },\n+                    .@\"run (post)install and (pre/post)prepare\" => |err| .{ .@\"run (post)install and (pre/post)prepare\" = err },\n+                    .done => .done,\n+                    .blocked => .blocked,\n+                };\n+            }\n+        };\n+\n+        pub const Step = enum(u8) {\n+            link_package,\n+            symlink_dependencies,\n+\n+            check_if_blocked,\n+\n+            // blocked can only happen here\n+\n+            symlink_dependency_binaries,\n+            run_preinstall,\n+\n+            // pause here while preinstall runs\n+\n+            binaries,\n+            @\"run (post)install and (pre/post)prepare\",\n+\n+            // pause again while remaining scripts run.\n+\n+            done,\n+            blocked,\n+        };\n+\n+        fn nextStep(this: *Task, comptime current_step: Step) Step {\n+            const next_step: Step = switch (comptime current_step) {\n+                .link_package => .symlink_dependencies,\n+                .symlink_dependencies => .check_if_blocked,\n+                .check_if_blocked => .symlink_dependency_binaries,\n+                .symlink_dependency_binaries => .run_preinstall,\n+                .run_preinstall => .binaries,\n+                .binaries => .@\"run (post)install and (pre/post)prepare\",\n+                .@\"run (post)install and (pre/post)prepare\" => .done,\n+\n+                .done,\n+                .blocked,\n+                => @compileError(\"unexpected step\"),\n+            };\n+\n+            this.installer.store.entries.items(.step)[this.entry_id.get()].store(next_step, .monotonic);\n+\n+            return next_step;\n+        }\n+\n+        const Yield = union(enum) {\n+            yield,\n+            done,\n+            fail: Error,\n+\n+            pub fn failure(e: Error) Yield {\n+                return .{ .fail = e };\n+            }\n+        };\n+\n+        fn run(this: *Task) OOM!Yield {\n+            const installer = this.installer;\n+            const manager = installer.manager;\n+            const lockfile = installer.lockfile;\n+\n+            const pkgs = installer.lockfile.packages.slice();\n+            const pkg_names = pkgs.items(.name);\n+            const pkg_name_hashes = pkgs.items(.name_hash);\n+            const pkg_resolutions = pkgs.items(.resolution);\n+            const pkg_bins = pkgs.items(.bin);\n+            const pkg_script_lists = pkgs.items(.scripts);\n+\n+            const entries = installer.store.entries.slice();\n+            const entry_node_ids = entries.items(.node_id);\n+            const entry_dependencies = entries.items(.dependencies);\n+            const entry_steps = entries.items(.step);\n+            const entry_scripts = entries.items(.scripts);\n+\n+            const nodes = installer.store.nodes.slice();\n+            const node_pkg_ids = nodes.items(.pkg_id);\n+            const node_dep_ids = nodes.items(.dep_id);\n+\n+            const node_id = entry_node_ids[this.entry_id.get()];\n+            const pkg_id = node_pkg_ids[node_id.get()];\n+            const dep_id = node_dep_ids[node_id.get()];\n+\n+            const pkg_name = pkg_names[pkg_id];\n+            const pkg_name_hash = pkg_name_hashes[pkg_id];\n+            const pkg_res = pkg_resolutions[pkg_id];\n+\n+            return next_step: switch (entry_steps[this.entry_id.get()].load(.monotonic)) {\n+                inline .link_package => |current_step| {\n+                    const string_buf = lockfile.buffers.string_bytes.items;\n+\n+                    if (pkg_res.tag == .folder) {\n+                        // the folder does not exist in the cache\n+                        const folder_dir = switch (bun.openDirForIteration(FD.cwd(), pkg_res.value.folder.slice(string_buf))) {\n+                            .result => |fd| fd,\n+                            .err => |err| return .failure(.{ .link_package = err }),\n+                        };\n+                        defer folder_dir.close();\n+\n+                        var src: bun.AbsPath(.{ .unit = .os, .sep = .auto }) = .initTopLevelDir();\n+                        defer src.deinit();\n+                        src.append(pkg_res.value.folder.slice(string_buf));\n+\n+                        var dest: bun.RelPath(.{ .unit = .os, .sep = .auto }) = .init();\n+                        defer dest.deinit();\n+\n+                        installer.appendStorePath(&dest, this.entry_id);\n+\n+                        var hardlinker: Hardlinker = .{\n+                            .src_dir = folder_dir,\n+                            .src = src,\n+                            .dest = dest,\n+                        };\n+\n+                        switch (try hardlinker.link(&.{comptime bun.OSPathLiteral(\"node_modules\")})) {\n+                            .result => {},\n+                            .err => |err| return .failure(.{ .link_package = err }),\n+                        }\n+\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const patch_info = try installer.packagePatchInfo(\n+                        pkg_name,\n+                        pkg_name_hash,\n+                        &pkg_res,\n+                    );\n+\n+                    var pkg_cache_dir_subpath: bun.RelPath(.{ .sep = .auto }) = .from(switch (pkg_res.tag) {\n+                        .npm => manager.cachedNPMPackageFolderName(pkg_name.slice(string_buf), pkg_res.value.npm.version, patch_info.contentsHash()),\n+                        .git => manager.cachedGitFolderName(&pkg_res.value.git, patch_info.contentsHash()),\n+                        .github => manager.cachedGitHubFolderName(&pkg_res.value.github, patch_info.contentsHash()),\n+                        .local_tarball => manager.cachedTarballFolderName(pkg_res.value.local_tarball, patch_info.contentsHash()),\n+                        .remote_tarball => manager.cachedTarballFolderName(pkg_res.value.remote_tarball, patch_info.contentsHash()),\n+\n+                        else => unreachable,\n+                    });\n+                    defer pkg_cache_dir_subpath.deinit();\n+\n+                    const cache_dir, const cache_dir_path = manager.getCacheDirectoryAndAbsPath();\n+                    defer cache_dir_path.deinit();\n+\n+                    var dest_subpath: bun.RelPath(.{ .sep = .auto, .unit = .os }) = .init();\n+                    defer dest_subpath.deinit();\n+\n+                    installer.appendStorePath(&dest_subpath, this.entry_id);\n+\n+                    // link the package\n+                    if (comptime Environment.isMac) {\n+                        if (install.PackageInstall.supported_method == .clonefile) hardlink_fallback: {\n+                            switch (sys.clonefileat(cache_dir, pkg_cache_dir_subpath.sliceZ(), FD.cwd(), dest_subpath.sliceZ())) {\n+                                .result => {\n+                                    // success! move to next step\n+                                    continue :next_step this.nextStep(current_step);\n+                                },\n+                                .err => |clonefile_err1| {\n+                                    switch (clonefile_err1.getErrno()) {\n+                                        .XDEV => break :hardlink_fallback,\n+                                        .OPNOTSUPP => break :hardlink_fallback,\n+                                        .NOENT => {\n+                                            const parent_dest_dir = std.fs.path.dirname(dest_subpath.slice()) orelse {\n+                                                return .failure(.{ .link_package = clonefile_err1 });\n+                                            };\n+\n+                                            FD.cwd().makePath(u8, parent_dest_dir) catch {};\n+\n+                                            switch (sys.clonefileat(cache_dir, pkg_cache_dir_subpath.sliceZ(), FD.cwd(), dest_subpath.sliceZ())) {\n+                                                .result => {\n+                                                    continue :next_step this.nextStep(current_step);\n+                                                },\n+                                                .err => |clonefile_err2| {\n+                                                    return .failure(.{ .link_package = clonefile_err2 });\n+                                                },\n+                                            }\n+                                        },\n+                                        else => {\n+                                            break :hardlink_fallback;\n+                                        },\n+                                    }\n+                                },\n+                            }\n+                        }\n+                    }\n+\n+                    const cached_package_dir = cached_package_dir: {\n+                        if (comptime Environment.isWindows) {\n+                            break :cached_package_dir switch (sys.openDirAtWindowsA(\n+                                cache_dir,\n+                                pkg_cache_dir_subpath.slice(),\n+                                .{ .iterable = true, .can_rename_or_delete = false, .read_only = true },\n+                            )) {\n+                                .result => |dir_fd| dir_fd,\n+                                .err => |err| {\n+                                    return .failure(.{ .link_package = err });\n+                                },\n+                            };\n+                        }\n+                        break :cached_package_dir switch (sys.openat(\n+                            cache_dir,\n+                            pkg_cache_dir_subpath.sliceZ(),\n+                            bun.O.DIRECTORY | bun.O.CLOEXEC | bun.O.RDONLY,\n+                            0,\n+                        )) {\n+                            .result => |fd| fd,\n+                            .err => |err| {\n+                                return .failure(.{ .link_package = err });\n+                            },\n+                        };\n+                    };\n+                    defer cached_package_dir.close();\n+\n+                    var src: bun.AbsPath(.{ .sep = .auto, .unit = .os }) = .from(cache_dir_path.slice());\n+                    defer src.deinit();\n+                    src.append(pkg_cache_dir_subpath.slice());\n+\n+                    var hardlinker: Hardlinker = .{\n+                        .src_dir = cached_package_dir,\n+                        .src = src,\n+                        .dest = dest_subpath,\n+                    };\n+\n+                    switch (try hardlinker.link(&.{})) {\n+                        .result => {},\n+                        .err => |err| return .failure(.{ .link_package = err }),\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .symlink_dependencies => |current_step| {\n+                    const string_buf = lockfile.buffers.string_bytes.items;\n+                    const dependencies = lockfile.buffers.dependencies.items;\n+\n+                    for (entry_dependencies[this.entry_id.get()].slice()) |dep| {\n+                        const dep_node_id = entry_node_ids[dep.entry_id.get()];\n+                        const dep_dep_id = node_dep_ids[dep_node_id.get()];\n+                        const dep_name = dependencies[dep_dep_id].name;\n+\n+                        var dest: bun.Path(.{ .sep = .auto }) = .initTopLevelDir();\n+                        defer dest.deinit();\n+\n+                        installer.appendStoreNodeModulesPath(&dest, this.entry_id);\n+                        dest.append(dep_name.slice(string_buf));\n+\n+                        var dep_store_path: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                        defer dep_store_path.deinit();\n+\n+                        installer.appendStorePath(&dep_store_path, dep.entry_id);\n+\n+                        const target = target: {\n+                            var dest_save = dest.save();\n+                            defer dest_save.restore();\n+\n+                            dest.undo(1);\n+                            break :target dest.relative(&dep_store_path);\n+                        };\n+                        defer target.deinit();\n+\n+                        const symlinker: Symlinker = .{\n+                            .dest = dest,\n+                            .target = target,\n+                            .fallback_junction_target = dep_store_path,\n+                        };\n+\n+                        const link_strategy: Symlinker.Strategy = if (pkg_res.tag == .root or pkg_res.tag == .workspace)\n+                            // root and workspace packages ensure their dependency symlinks\n+                            // exist unconditionally. To make sure it's fast, first readlink\n+                            // then create the symlink if necessary\n+                            .expect_existing\n+                        else\n+                            .expect_missing;\n+\n+                        switch (symlinker.ensureSymlink(link_strategy)) {\n+                            .result => {},\n+                            .err => |err| {\n+                                return .failure(.{ .symlink_dependencies = err });\n+                            },\n+                        }\n+                    }\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .check_if_blocked => |current_step| {\n+                    // preinstall scripts need to run before binaries can be linked. Block here if any dependencies\n+                    // of this entry are not finished. Do not count cycles towards blocking.\n+\n+                    var parent_dedupe: std.AutoArrayHashMap(Store.Entry.Id, void) = .init(bun.default_allocator);\n+                    defer parent_dedupe.deinit();\n+\n+                    const deps = entry_dependencies[this.entry_id.get()];\n+                    for (deps.slice()) |dep| {\n+                        if (entry_steps[dep.entry_id.get()].load(.monotonic) != .done) {\n+                            if (installer.store.isCycle(this.entry_id, dep.entry_id, &parent_dedupe)) {\n+                                parent_dedupe.clearRetainingCapacity();\n+                                continue;\n+                            }\n+\n+                            entry_steps[this.entry_id.get()].store(.blocked, .monotonic);\n+                            return .yield;\n+                        }\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .symlink_dependency_binaries => |current_step| {\n+                    installer.linkDependencyBins(this.entry_id) catch |err| {\n+                        return .failure(.{ .binaries = err });\n+                    };\n+\n+                    switch (pkg_res.tag) {\n+                        .uninitialized,\n+                        .root,\n+                        .workspace,\n+                        .folder,\n+                        .symlink,\n+                        .single_file_module,\n+                        => {},\n+\n+                        _ => {},\n+\n+                        .npm,\n+                        .git,\n+                        .github,\n+                        .local_tarball,\n+                        .remote_tarball,\n+                        => {\n+                            const string_buf = lockfile.buffers.string_bytes.items;\n+\n+                            var hidden_hoisted_node_modules: bun.Path(.{ .sep = .auto }) = .init();\n+                            defer hidden_hoisted_node_modules.deinit();\n+\n+                            hidden_hoisted_node_modules.append(\n+                                \"node_modules\" ++ std.fs.path.sep_str ++ \".bun\" ++ std.fs.path.sep_str ++ \"node_modules\",\n+                            );\n+                            hidden_hoisted_node_modules.append(pkg_name.slice(installer.lockfile.buffers.string_bytes.items));\n+\n+                            var target: bun.RelPath(.{ .sep = .auto }) = .init();\n+                            defer target.deinit();\n+\n+                            target.append(\"..\");\n+                            if (strings.containsChar(pkg_name.slice(installer.lockfile.buffers.string_bytes.items), '/')) {\n+                                target.append(\"..\");\n+                            }\n+\n+                            target.appendFmt(\"{}/node_modules/{s}\", .{\n+                                Store.Entry.fmtStorePath(this.entry_id, installer.store, installer.lockfile),\n+                                pkg_name.slice(string_buf),\n+                            });\n+\n+                            var full_target: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                            defer full_target.deinit();\n+\n+                            installer.appendStorePath(&full_target, this.entry_id);\n+\n+                            const symlinker: Symlinker = .{\n+                                .dest = hidden_hoisted_node_modules,\n+                                .target = target,\n+                                .fallback_junction_target = full_target,\n+                            };\n+                            _ = symlinker.ensureSymlink(.ignore_failure);\n+                        },\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .run_preinstall => |current_step| {\n+                    if (!installer.manager.options.do.run_scripts or this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const string_buf = installer.lockfile.buffers.string_bytes.items;\n+\n+                    const dep = installer.lockfile.buffers.dependencies.items[dep_id];\n+                    const truncated_dep_name_hash: TruncatedPackageNameHash = @truncate(dep.name_hash);\n+\n+                    const is_trusted, const is_trusted_through_update_request = brk: {\n+                        if (installer.trusted_dependencies_from_update_requests.contains(truncated_dep_name_hash)) {\n+                            break :brk .{ true, true };\n+                        }\n+                        if (installer.lockfile.hasTrustedDependency(dep.name.slice(string_buf))) {\n+                            break :brk .{ true, false };\n+                        }\n+                        break :brk .{ false, false };\n+                    };\n+\n+                    var pkg_cwd: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                    defer pkg_cwd.deinit();\n+\n+                    installer.appendStorePath(&pkg_cwd, this.entry_id);\n+\n+                    if (pkg_res.tag != .root and (pkg_res.tag == .workspace or is_trusted)) {\n+                        const pkg_scripts: *Package.Scripts = &pkg_script_lists[pkg_id];\n+\n+                        var log = bun.logger.Log.init(bun.default_allocator);\n+                        defer log.deinit();\n+\n+                        const scripts_list = pkg_scripts.getList(\n+                            &log,\n+                            installer.lockfile,\n+                            &pkg_cwd,\n+                            dep.name.slice(string_buf),\n+                            &pkg_res,\n+                        ) catch |err| {\n+                            return .failure(.{ .run_preinstall = err });\n+                        };\n+\n+                        if (scripts_list) |list| {\n+                            entry_scripts[this.entry_id.get()] = bun.create(bun.default_allocator, Package.Scripts.List, list);\n+\n+                            if (is_trusted_through_update_request) {\n+                                const trusted_dep_to_add = try installer.manager.allocator.dupe(u8, dep.name.slice(string_buf));\n+\n+                                installer.trusted_dependencies_mutex.lock();\n+                                defer installer.trusted_dependencies_mutex.unlock();\n+\n+                                try installer.manager.trusted_deps_to_add_to_package_json.append(\n+                                    installer.manager.allocator,\n+                                    trusted_dep_to_add,\n+                                );\n+                                if (installer.lockfile.trusted_dependencies == null) {\n+                                    installer.lockfile.trusted_dependencies = .{};\n+                                }\n+                                try installer.lockfile.trusted_dependencies.?.put(installer.manager.allocator, truncated_dep_name_hash, {});\n+                            }\n+\n+                            if (list.first_index != 0) {\n+                                // has scripts but not a preinstall\n+                                continue :next_step this.nextStep(current_step);\n+                            }\n+\n+                            installer.manager.spawnPackageLifecycleScripts(\n+                                installer.command_ctx,\n+                                list,\n+                                dep.behavior.optional,\n+                                false,\n+                                .{\n+                                    .entry_id = this.entry_id,\n+                                    .installer = installer,\n+                                },\n+                            ) catch |err| {\n+                                return .failure(.{ .run_preinstall = err });\n+                            };\n+\n+                            return .yield;\n+                        }\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .binaries => |current_step| {\n+                    if (this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const bin = pkg_bins[pkg_id];\n+                    if (bin.tag == .none) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const string_buf = installer.lockfile.buffers.string_bytes.items;\n+                    const dependencies = installer.lockfile.buffers.dependencies.items;\n+\n+                    const dep_name = dependencies[dep_id].name.slice(string_buf);\n+\n+                    var abs_target_buf: bun.PathBuffer = undefined;\n+                    var abs_dest_buf: bun.PathBuffer = undefined;\n+                    var rel_buf: bun.PathBuffer = undefined;\n+\n+                    var seen: bun.StringHashMap(void) = .init(bun.default_allocator);\n+                    defer seen.deinit();\n+\n+                    var node_modules_path: bun.AbsPath(.{}) = .initTopLevelDir();\n+                    defer node_modules_path.deinit();\n+\n+                    installer.appendStoreNodeModulesPath(&node_modules_path, this.entry_id);\n+\n+                    var bin_linker: Bin.Linker = .{\n+                        .bin = bin,\n+                        .global_bin_path = installer.manager.options.bin_path,\n+                        .package_name = strings.StringOrTinyString.init(dep_name),\n+                        .string_buf = string_buf,\n+                        .extern_string_buf = installer.lockfile.buffers.extern_strings.items,\n+                        .seen = &seen,\n+                        .node_modules_path = &node_modules_path,\n+                        .abs_target_buf = &abs_target_buf,\n+                        .abs_dest_buf = &abs_dest_buf,\n+                        .rel_buf = &rel_buf,\n+                    };\n+\n+                    bin_linker.link(false);\n+\n+                    if (bin_linker.err) |err| {\n+                        return .failure(.{ .binaries = err });\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .@\"run (post)install and (pre/post)prepare\" => |current_step| {\n+                    if (!installer.manager.options.do.run_scripts or this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    var list = entry_scripts[this.entry_id.get()] orelse {\n+                        continue :next_step this.nextStep(current_step);\n+                    };\n+\n+                    if (list.first_index == 0) {\n+                        for (list.items[1..], 1..) |item, i| {\n+                            if (item != null) {\n+                                list.first_index = @intCast(i);\n+                                break;\n+                            }\n+                        }\n+                    }\n+\n+                    if (list.first_index == 0) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const dep = installer.lockfile.buffers.dependencies.items[dep_id];\n+\n+                    installer.manager.spawnPackageLifecycleScripts(\n+                        installer.command_ctx,\n+                        list.*,\n+                        dep.behavior.optional,\n+                        false,\n+                        .{\n+                            .entry_id = this.entry_id,\n+                            .installer = installer,\n+                        },\n+                    ) catch |err| {\n+                        return .failure(.{ .@\"run (post)install and (pre/post)prepare\" = err });\n+                    };\n+\n+                    // when these scripts finish the package install will be\n+                    // complete. the task does not have anymore work to complete\n+                    // so it does not return to the thread pool.\n+\n+                    return .yield;\n+                },\n+\n+                .done => {\n+                    return .done;\n+                },\n+\n+                .blocked => {\n+                    bun.debugAssert(false);\n+                    return .yield;\n+                },\n+            };\n+        }\n+\n+        pub fn callback(task: *ThreadPool.Task) void {\n+            const this: *Task = @fieldParentPtr(\"task\", task);\n+\n+            const res = this.run() catch |err| switch (err) {\n+                error.OutOfMemory => bun.outOfMemory(),\n+            };\n+\n+            switch (res) {\n+                .yield => {},\n+                .done => {\n+                    this.installer.tasks.push(this);\n+                    this.installer.manager.wake();\n+                },\n+                .fail => |err| {\n+                    this.installer.store.entries.items(.step)[this.entry_id.get()].store(.done, .monotonic);\n+                    this.err = err.clone(bun.default_allocator);\n+                    this.installer.tasks.push(this);\n+                    this.installer.manager.wake();\n+                },\n+            }\n+        }\n+    };\n+\n+    const PatchInfo = union(enum) {\n+        none,\n+        remove: struct {\n+            name_and_version_hash: u64,\n+        },\n+        patch: struct {\n+            name_and_version_hash: u64,\n+            patch_path: string,\n+            contents_hash: u64,\n+        },\n+\n+        pub fn contentsHash(this: *const @This()) ?u64 {\n+            return switch (this.*) {\n+                .none, .remove => null,\n+                .patch => |patch| patch.contents_hash,\n+            };\n+        }\n+\n+        pub fn nameAndVersionHash(this: *const @This()) ?u64 {\n+            return switch (this.*) {\n+                .none, .remove => null,\n+                .patch => |patch| patch.name_and_version_hash,\n+            };\n+        }\n+    };\n+\n+    pub fn packagePatchInfo(\n+        this: *Installer,\n+        pkg_name: String,\n+        pkg_name_hash: PackageNameHash,\n+        pkg_res: *const Resolution,\n+    ) OOM!PatchInfo {\n+        if (this.lockfile.patched_dependencies.entries.len == 0 and this.manager.patched_dependencies_to_remove.entries.len == 0) {\n+            return .none;\n+        }\n+\n+        const string_buf = this.lockfile.buffers.string_bytes.items;\n+\n+        var version_buf: std.ArrayListUnmanaged(u8) = .empty;\n+        defer version_buf.deinit(bun.default_allocator);\n+\n+        var writer = version_buf.writer(this.lockfile.allocator);\n+        try writer.print(\"{s}@\", .{pkg_name.slice(string_buf)});\n+\n+        switch (pkg_res.tag) {\n+            .workspace => {\n+                if (this.lockfile.workspace_versions.get(pkg_name_hash)) |workspace_version| {\n+                    try writer.print(\"{}\", .{workspace_version.fmt(string_buf)});\n+                }\n+            },\n+            else => {\n+                try writer.print(\"{}\", .{pkg_res.fmt(string_buf, .posix)});\n+            },\n+        }\n+\n+        const name_and_version_hash = String.Builder.stringHash(version_buf.items);\n+\n+        if (this.lockfile.patched_dependencies.get(name_and_version_hash)) |patch| {\n+            return .{\n+                .patch = .{\n+                    .name_and_version_hash = name_and_version_hash,\n+                    .patch_path = patch.path.slice(string_buf),\n+                    .contents_hash = patch.patchfileHash().?,\n+                },\n+            };\n+        }\n+\n+        if (this.manager.patched_dependencies_to_remove.contains(name_and_version_hash)) {\n+            return .{\n+                .remove = .{\n+                    .name_and_version_hash = name_and_version_hash,\n+                },\n+            };\n+        }\n+\n+        return .none;\n+    }\n+\n+    pub fn linkDependencyBins(this: *const Installer, parent_entry_id: Store.Entry.Id) !void {\n+        const lockfile = this.lockfile;\n+        const store = this.store;\n+\n+        const string_buf = lockfile.buffers.string_bytes.items;\n+        const extern_string_buf = lockfile.buffers.extern_strings.items;\n+\n+        const entries = store.entries.slice();\n+        const entry_node_ids = entries.items(.node_id);\n+        const entry_deps = entries.items(.dependencies);\n+\n+        const nodes = store.nodes.slice();\n+        const node_pkg_ids = nodes.items(.pkg_id);\n+        const node_dep_ids = nodes.items(.dep_id);\n+\n+        const pkgs = lockfile.packages.slice();\n+        const pkg_bins = pkgs.items(.bin);\n+\n+        var link_target_buf: bun.PathBuffer = undefined;",
    "repo_full_name": "oven-sh/bun",
    "discussion_comments": [
      {
        "comment_id": "2191503936",
        "repo_full_name": "oven-sh/bun",
        "pr_number": 20440,
        "pr_file": "src/install/isolated_install/Installer.zig",
        "discussion_id": "2191503936",
        "commented_code": "@@ -0,0 +1,1074 @@\n+pub const Installer = struct {\n+    trusted_dependencies_mutex: bun.Mutex,\n+    // this is not const for `lockfile.trusted_dependencies`\n+    lockfile: *Lockfile,\n+\n+    summary: PackageInstall.Summary = .{ .successfully_installed = .empty },\n+    installed: Bitset,\n+    install_node: ?*Progress.Node,\n+    scripts_node: ?*Progress.Node,\n+\n+    manager: *PackageManager,\n+    command_ctx: Command.Context,\n+\n+    store: *const Store,\n+\n+    tasks: bun.UnboundedQueue(Task, .next) = .{},\n+    preallocated_tasks: Task.Preallocated,\n+\n+    trusted_dependencies_from_update_requests: std.AutoArrayHashMapUnmanaged(TruncatedPackageNameHash, void),\n+\n+    pub fn deinit(this: *const Installer) void {\n+        this.trusted_dependencies_from_update_requests.deinit(this.lockfile.allocator);\n+    }\n+\n+    pub fn resumeTask(this: *Installer, entry_id: Store.Entry.Id) void {\n+        const task = this.preallocated_tasks.get();\n+\n+        task.* = .{\n+            .entry_id = entry_id,\n+            .installer = this,\n+            .err = null,\n+        };\n+\n+        this.manager.thread_pool.schedule(.from(&task.task));\n+    }\n+\n+    pub fn onPackageExtracted(this: *Installer, task_id: install.Task.Id) void {\n+        if (this.manager.task_queue.fetchRemove(task_id)) |removed| {\n+            for (removed.value.items) |install_ctx| {\n+                const entry_id = install_ctx.isolated_package_install_context;\n+                this.resumeTask(entry_id);\n+            }\n+        }\n+    }\n+\n+    pub fn onTaskFail(this: *Installer, entry_id: Store.Entry.Id, err: Task.Error) void {\n+        const string_buf = this.lockfile.buffers.string_bytes.items;\n+\n+        const entries = this.store.entries.slice();\n+        const entry_node_ids = entries.items(.node_id);\n+\n+        const nodes = this.store.nodes.slice();\n+        const node_pkg_ids = nodes.items(.pkg_id);\n+\n+        const pkgs = this.lockfile.packages.slice();\n+        const pkg_names = pkgs.items(.name);\n+        const pkg_resolutions = pkgs.items(.resolution);\n+\n+        const node_id = entry_node_ids[entry_id.get()];\n+        const pkg_id = node_pkg_ids[node_id.get()];\n+\n+        const pkg_name = pkg_names[pkg_id];\n+        const pkg_res = pkg_resolutions[pkg_id];\n+\n+        switch (err) {\n+            .link_package => |link_err| {\n+                Output.err(link_err, \"failed to link package: {s}@{}\", .{\n+                    pkg_name.slice(string_buf),\n+                    pkg_res.fmt(string_buf, .auto),\n+                });\n+            },\n+            .symlink_dependencies => |symlink_err| {\n+                Output.err(symlink_err, \"failed to symlink dependencies for package: {s}@{}\", .{\n+                    pkg_name.slice(string_buf),\n+                    pkg_res.fmt(string_buf, .auto),\n+                });\n+            },\n+            else => {},\n+        }\n+        Output.flush();\n+\n+        // attempt deleting the package so the next install will install it again\n+        switch (pkg_res.tag) {\n+            .uninitialized,\n+            .single_file_module,\n+            .root,\n+            .workspace,\n+            .symlink,\n+            => {},\n+\n+            _ => {},\n+\n+            // to be safe make sure we only delete packages in the store\n+            .npm,\n+            .git,\n+            .github,\n+            .local_tarball,\n+            .remote_tarball,\n+            .folder,\n+            => {\n+                var store_path: bun.RelPath(.{ .sep = .auto }) = .init();\n+                defer store_path.deinit();\n+\n+                store_path.appendFmt(\"node_modules/{}\", .{\n+                    Store.Entry.fmtStorePath(entry_id, this.store, this.lockfile),\n+                });\n+\n+                _ = sys.unlink(store_path.sliceZ());\n+            },\n+        }\n+\n+        if (this.manager.options.enable.fail_early) {\n+            Global.exit(1);\n+        }\n+\n+        this.summary.fail += 1;\n+\n+        this.decrementPendingTasks(entry_id);\n+        this.resumeAvailableTasks();\n+    }\n+\n+    pub fn onTask(this: *Installer, task_entry_id: Store.Entry.Id) void {\n+        const entries = this.store.entries.slice();\n+        const entry_steps = entries.items(.step);\n+        const step = entry_steps[task_entry_id.get()].load(.monotonic);\n+\n+        if (step != .done) {\n+            // only done will unblock other packages\n+            return;\n+        }\n+\n+        this.onTaskSuccess(task_entry_id);\n+    }\n+\n+    pub fn decrementPendingTasks(this: *Installer, entry_id: Store.Entry.Id) void {\n+        _ = entry_id;\n+        this.manager.decrementPendingTasks();\n+    }\n+\n+    pub fn onTaskSkipped(this: *Installer, entry_id: Store.Entry.Id) void {\n+        this.summary.skipped += 1;\n+        this.decrementPendingTasks(entry_id);\n+        this.store.entries.items(.step)[entry_id.get()].store(.done, .monotonic);\n+        if (this.install_node) |node| {\n+            node.completeOne();\n+        }\n+        this.resumeAvailableTasks();\n+    }\n+\n+    pub fn onTaskSuccess(this: *Installer, entry_id: Store.Entry.Id) void {\n+        this.decrementPendingTasks(entry_id);\n+        this.resumeAvailableTasks();\n+\n+        const pkg_id = pkg_id: {\n+            if (entry_id == .root) {\n+                return;\n+            }\n+\n+            const node_id = this.store.entries.items(.node_id)[entry_id.get()];\n+            const nodes = this.store.nodes.slice();\n+\n+            const dep_id = nodes.items(.dep_id)[node_id.get()];\n+\n+            if (dep_id == invalid_dependency_id) {\n+                // should be coverd by `entry_id == .root` above, but\n+                // just in case\n+                return;\n+            }\n+\n+            const dep = this.lockfile.buffers.dependencies.items[dep_id];\n+\n+            if (dep.behavior.isWorkspaceOnly()) {\n+                return;\n+            }\n+\n+            break :pkg_id nodes.items(.pkg_id)[node_id.get()];\n+        };\n+\n+        const is_duplicate = this.installed.isSet(pkg_id);\n+        this.summary.success += @intFromBool(!is_duplicate);\n+        this.installed.set(pkg_id);\n+        if (this.install_node) |node| {\n+            node.completeOne();\n+        }\n+    }\n+\n+    pub fn resumeAvailableTasks(this: *Installer) void {\n+        const entries = this.store.entries.slice();\n+        const entry_deps = entries.items(.dependencies);\n+        const entry_steps = entries.items(.step);\n+\n+        var parent_dedupe: std.AutoArrayHashMap(Store.Entry.Id, void) = .init(bun.default_allocator);\n+        defer parent_dedupe.deinit();\n+\n+        next_entry: for (0..this.store.entries.len) |_entry_id| {\n+            const entry_id: Store.Entry.Id = .from(@intCast(_entry_id));\n+\n+            const entry_step = entry_steps[entry_id.get()].load(.monotonic);\n+            if (entry_step != .blocked) {\n+                continue;\n+            }\n+\n+            const deps = entry_deps[entry_id.get()];\n+            for (deps.slice()) |dep| {\n+                switch (entry_steps[dep.entry_id.get()].load(.monotonic)) {\n+                    .done => {},\n+                    else => {\n+                        parent_dedupe.clearRetainingCapacity();\n+                        if (!this.store.isCycle(entry_id, dep.entry_id, &parent_dedupe)) {\n+                            continue :next_entry;\n+                        }\n+                    },\n+                }\n+            }\n+\n+            entry_steps[entry_id.get()].store(.symlink_dependency_binaries, .monotonic);\n+            this.resumeTask(entry_id);\n+        }\n+    }\n+\n+    pub const Task = struct {\n+        const Preallocated = bun.HiveArray(Task, 128).Fallback;\n+\n+        entry_id: Store.Entry.Id,\n+        installer: *Installer,\n+\n+        task: ThreadPool.Task = .{ .callback = &callback },\n+        next: ?*Task = null,\n+\n+        err: ?Error,\n+\n+        const Error = union(Step) {\n+            link_package: sys.Error,\n+            symlink_dependencies: sys.Error,\n+            check_if_blocked,\n+            symlink_dependency_binaries,\n+            run_preinstall: anyerror,\n+            binaries: anyerror,\n+            @\"run (post)install and (pre/post)prepare\": anyerror,\n+            done,\n+            blocked,\n+\n+            pub fn clone(this: *const Error, allocator: std.mem.Allocator) Error {\n+                return switch (this.*) {\n+                    .link_package => |err| .{ .link_package = err.clone(allocator) },\n+                    .symlink_dependencies => |err| .{ .symlink_dependencies = err.clone(allocator) },\n+                    .check_if_blocked => .check_if_blocked,\n+                    .symlink_dependency_binaries => .symlink_dependency_binaries,\n+                    .run_preinstall => |err| .{ .run_preinstall = err },\n+                    .binaries => |err| .{ .binaries = err },\n+                    .@\"run (post)install and (pre/post)prepare\" => |err| .{ .@\"run (post)install and (pre/post)prepare\" = err },\n+                    .done => .done,\n+                    .blocked => .blocked,\n+                };\n+            }\n+        };\n+\n+        pub const Step = enum(u8) {\n+            link_package,\n+            symlink_dependencies,\n+\n+            check_if_blocked,\n+\n+            // blocked can only happen here\n+\n+            symlink_dependency_binaries,\n+            run_preinstall,\n+\n+            // pause here while preinstall runs\n+\n+            binaries,\n+            @\"run (post)install and (pre/post)prepare\",\n+\n+            // pause again while remaining scripts run.\n+\n+            done,\n+            blocked,\n+        };\n+\n+        fn nextStep(this: *Task, comptime current_step: Step) Step {\n+            const next_step: Step = switch (comptime current_step) {\n+                .link_package => .symlink_dependencies,\n+                .symlink_dependencies => .check_if_blocked,\n+                .check_if_blocked => .symlink_dependency_binaries,\n+                .symlink_dependency_binaries => .run_preinstall,\n+                .run_preinstall => .binaries,\n+                .binaries => .@\"run (post)install and (pre/post)prepare\",\n+                .@\"run (post)install and (pre/post)prepare\" => .done,\n+\n+                .done,\n+                .blocked,\n+                => @compileError(\"unexpected step\"),\n+            };\n+\n+            this.installer.store.entries.items(.step)[this.entry_id.get()].store(next_step, .monotonic);\n+\n+            return next_step;\n+        }\n+\n+        const Yield = union(enum) {\n+            yield,\n+            done,\n+            fail: Error,\n+\n+            pub fn failure(e: Error) Yield {\n+                return .{ .fail = e };\n+            }\n+        };\n+\n+        fn run(this: *Task) OOM!Yield {\n+            const installer = this.installer;\n+            const manager = installer.manager;\n+            const lockfile = installer.lockfile;\n+\n+            const pkgs = installer.lockfile.packages.slice();\n+            const pkg_names = pkgs.items(.name);\n+            const pkg_name_hashes = pkgs.items(.name_hash);\n+            const pkg_resolutions = pkgs.items(.resolution);\n+            const pkg_bins = pkgs.items(.bin);\n+            const pkg_script_lists = pkgs.items(.scripts);\n+\n+            const entries = installer.store.entries.slice();\n+            const entry_node_ids = entries.items(.node_id);\n+            const entry_dependencies = entries.items(.dependencies);\n+            const entry_steps = entries.items(.step);\n+            const entry_scripts = entries.items(.scripts);\n+\n+            const nodes = installer.store.nodes.slice();\n+            const node_pkg_ids = nodes.items(.pkg_id);\n+            const node_dep_ids = nodes.items(.dep_id);\n+\n+            const node_id = entry_node_ids[this.entry_id.get()];\n+            const pkg_id = node_pkg_ids[node_id.get()];\n+            const dep_id = node_dep_ids[node_id.get()];\n+\n+            const pkg_name = pkg_names[pkg_id];\n+            const pkg_name_hash = pkg_name_hashes[pkg_id];\n+            const pkg_res = pkg_resolutions[pkg_id];\n+\n+            return next_step: switch (entry_steps[this.entry_id.get()].load(.monotonic)) {\n+                inline .link_package => |current_step| {\n+                    const string_buf = lockfile.buffers.string_bytes.items;\n+\n+                    if (pkg_res.tag == .folder) {\n+                        // the folder does not exist in the cache\n+                        const folder_dir = switch (bun.openDirForIteration(FD.cwd(), pkg_res.value.folder.slice(string_buf))) {\n+                            .result => |fd| fd,\n+                            .err => |err| return .failure(.{ .link_package = err }),\n+                        };\n+                        defer folder_dir.close();\n+\n+                        var src: bun.AbsPath(.{ .unit = .os, .sep = .auto }) = .initTopLevelDir();\n+                        defer src.deinit();\n+                        src.append(pkg_res.value.folder.slice(string_buf));\n+\n+                        var dest: bun.RelPath(.{ .unit = .os, .sep = .auto }) = .init();\n+                        defer dest.deinit();\n+\n+                        installer.appendStorePath(&dest, this.entry_id);\n+\n+                        var hardlinker: Hardlinker = .{\n+                            .src_dir = folder_dir,\n+                            .src = src,\n+                            .dest = dest,\n+                        };\n+\n+                        switch (try hardlinker.link(&.{comptime bun.OSPathLiteral(\"node_modules\")})) {\n+                            .result => {},\n+                            .err => |err| return .failure(.{ .link_package = err }),\n+                        }\n+\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const patch_info = try installer.packagePatchInfo(\n+                        pkg_name,\n+                        pkg_name_hash,\n+                        &pkg_res,\n+                    );\n+\n+                    var pkg_cache_dir_subpath: bun.RelPath(.{ .sep = .auto }) = .from(switch (pkg_res.tag) {\n+                        .npm => manager.cachedNPMPackageFolderName(pkg_name.slice(string_buf), pkg_res.value.npm.version, patch_info.contentsHash()),\n+                        .git => manager.cachedGitFolderName(&pkg_res.value.git, patch_info.contentsHash()),\n+                        .github => manager.cachedGitHubFolderName(&pkg_res.value.github, patch_info.contentsHash()),\n+                        .local_tarball => manager.cachedTarballFolderName(pkg_res.value.local_tarball, patch_info.contentsHash()),\n+                        .remote_tarball => manager.cachedTarballFolderName(pkg_res.value.remote_tarball, patch_info.contentsHash()),\n+\n+                        else => unreachable,\n+                    });\n+                    defer pkg_cache_dir_subpath.deinit();\n+\n+                    const cache_dir, const cache_dir_path = manager.getCacheDirectoryAndAbsPath();\n+                    defer cache_dir_path.deinit();\n+\n+                    var dest_subpath: bun.RelPath(.{ .sep = .auto, .unit = .os }) = .init();\n+                    defer dest_subpath.deinit();\n+\n+                    installer.appendStorePath(&dest_subpath, this.entry_id);\n+\n+                    // link the package\n+                    if (comptime Environment.isMac) {\n+                        if (install.PackageInstall.supported_method == .clonefile) hardlink_fallback: {\n+                            switch (sys.clonefileat(cache_dir, pkg_cache_dir_subpath.sliceZ(), FD.cwd(), dest_subpath.sliceZ())) {\n+                                .result => {\n+                                    // success! move to next step\n+                                    continue :next_step this.nextStep(current_step);\n+                                },\n+                                .err => |clonefile_err1| {\n+                                    switch (clonefile_err1.getErrno()) {\n+                                        .XDEV => break :hardlink_fallback,\n+                                        .OPNOTSUPP => break :hardlink_fallback,\n+                                        .NOENT => {\n+                                            const parent_dest_dir = std.fs.path.dirname(dest_subpath.slice()) orelse {\n+                                                return .failure(.{ .link_package = clonefile_err1 });\n+                                            };\n+\n+                                            FD.cwd().makePath(u8, parent_dest_dir) catch {};\n+\n+                                            switch (sys.clonefileat(cache_dir, pkg_cache_dir_subpath.sliceZ(), FD.cwd(), dest_subpath.sliceZ())) {\n+                                                .result => {\n+                                                    continue :next_step this.nextStep(current_step);\n+                                                },\n+                                                .err => |clonefile_err2| {\n+                                                    return .failure(.{ .link_package = clonefile_err2 });\n+                                                },\n+                                            }\n+                                        },\n+                                        else => {\n+                                            break :hardlink_fallback;\n+                                        },\n+                                    }\n+                                },\n+                            }\n+                        }\n+                    }\n+\n+                    const cached_package_dir = cached_package_dir: {\n+                        if (comptime Environment.isWindows) {\n+                            break :cached_package_dir switch (sys.openDirAtWindowsA(\n+                                cache_dir,\n+                                pkg_cache_dir_subpath.slice(),\n+                                .{ .iterable = true, .can_rename_or_delete = false, .read_only = true },\n+                            )) {\n+                                .result => |dir_fd| dir_fd,\n+                                .err => |err| {\n+                                    return .failure(.{ .link_package = err });\n+                                },\n+                            };\n+                        }\n+                        break :cached_package_dir switch (sys.openat(\n+                            cache_dir,\n+                            pkg_cache_dir_subpath.sliceZ(),\n+                            bun.O.DIRECTORY | bun.O.CLOEXEC | bun.O.RDONLY,\n+                            0,\n+                        )) {\n+                            .result => |fd| fd,\n+                            .err => |err| {\n+                                return .failure(.{ .link_package = err });\n+                            },\n+                        };\n+                    };\n+                    defer cached_package_dir.close();\n+\n+                    var src: bun.AbsPath(.{ .sep = .auto, .unit = .os }) = .from(cache_dir_path.slice());\n+                    defer src.deinit();\n+                    src.append(pkg_cache_dir_subpath.slice());\n+\n+                    var hardlinker: Hardlinker = .{\n+                        .src_dir = cached_package_dir,\n+                        .src = src,\n+                        .dest = dest_subpath,\n+                    };\n+\n+                    switch (try hardlinker.link(&.{})) {\n+                        .result => {},\n+                        .err => |err| return .failure(.{ .link_package = err }),\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .symlink_dependencies => |current_step| {\n+                    const string_buf = lockfile.buffers.string_bytes.items;\n+                    const dependencies = lockfile.buffers.dependencies.items;\n+\n+                    for (entry_dependencies[this.entry_id.get()].slice()) |dep| {\n+                        const dep_node_id = entry_node_ids[dep.entry_id.get()];\n+                        const dep_dep_id = node_dep_ids[dep_node_id.get()];\n+                        const dep_name = dependencies[dep_dep_id].name;\n+\n+                        var dest: bun.Path(.{ .sep = .auto }) = .initTopLevelDir();\n+                        defer dest.deinit();\n+\n+                        installer.appendStoreNodeModulesPath(&dest, this.entry_id);\n+                        dest.append(dep_name.slice(string_buf));\n+\n+                        var dep_store_path: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                        defer dep_store_path.deinit();\n+\n+                        installer.appendStorePath(&dep_store_path, dep.entry_id);\n+\n+                        const target = target: {\n+                            var dest_save = dest.save();\n+                            defer dest_save.restore();\n+\n+                            dest.undo(1);\n+                            break :target dest.relative(&dep_store_path);\n+                        };\n+                        defer target.deinit();\n+\n+                        const symlinker: Symlinker = .{\n+                            .dest = dest,\n+                            .target = target,\n+                            .fallback_junction_target = dep_store_path,\n+                        };\n+\n+                        const link_strategy: Symlinker.Strategy = if (pkg_res.tag == .root or pkg_res.tag == .workspace)\n+                            // root and workspace packages ensure their dependency symlinks\n+                            // exist unconditionally. To make sure it's fast, first readlink\n+                            // then create the symlink if necessary\n+                            .expect_existing\n+                        else\n+                            .expect_missing;\n+\n+                        switch (symlinker.ensureSymlink(link_strategy)) {\n+                            .result => {},\n+                            .err => |err| {\n+                                return .failure(.{ .symlink_dependencies = err });\n+                            },\n+                        }\n+                    }\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .check_if_blocked => |current_step| {\n+                    // preinstall scripts need to run before binaries can be linked. Block here if any dependencies\n+                    // of this entry are not finished. Do not count cycles towards blocking.\n+\n+                    var parent_dedupe: std.AutoArrayHashMap(Store.Entry.Id, void) = .init(bun.default_allocator);\n+                    defer parent_dedupe.deinit();\n+\n+                    const deps = entry_dependencies[this.entry_id.get()];\n+                    for (deps.slice()) |dep| {\n+                        if (entry_steps[dep.entry_id.get()].load(.monotonic) != .done) {\n+                            if (installer.store.isCycle(this.entry_id, dep.entry_id, &parent_dedupe)) {\n+                                parent_dedupe.clearRetainingCapacity();\n+                                continue;\n+                            }\n+\n+                            entry_steps[this.entry_id.get()].store(.blocked, .monotonic);\n+                            return .yield;\n+                        }\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .symlink_dependency_binaries => |current_step| {\n+                    installer.linkDependencyBins(this.entry_id) catch |err| {\n+                        return .failure(.{ .binaries = err });\n+                    };\n+\n+                    switch (pkg_res.tag) {\n+                        .uninitialized,\n+                        .root,\n+                        .workspace,\n+                        .folder,\n+                        .symlink,\n+                        .single_file_module,\n+                        => {},\n+\n+                        _ => {},\n+\n+                        .npm,\n+                        .git,\n+                        .github,\n+                        .local_tarball,\n+                        .remote_tarball,\n+                        => {\n+                            const string_buf = lockfile.buffers.string_bytes.items;\n+\n+                            var hidden_hoisted_node_modules: bun.Path(.{ .sep = .auto }) = .init();\n+                            defer hidden_hoisted_node_modules.deinit();\n+\n+                            hidden_hoisted_node_modules.append(\n+                                \"node_modules\" ++ std.fs.path.sep_str ++ \".bun\" ++ std.fs.path.sep_str ++ \"node_modules\",\n+                            );\n+                            hidden_hoisted_node_modules.append(pkg_name.slice(installer.lockfile.buffers.string_bytes.items));\n+\n+                            var target: bun.RelPath(.{ .sep = .auto }) = .init();\n+                            defer target.deinit();\n+\n+                            target.append(\"..\");\n+                            if (strings.containsChar(pkg_name.slice(installer.lockfile.buffers.string_bytes.items), '/')) {\n+                                target.append(\"..\");\n+                            }\n+\n+                            target.appendFmt(\"{}/node_modules/{s}\", .{\n+                                Store.Entry.fmtStorePath(this.entry_id, installer.store, installer.lockfile),\n+                                pkg_name.slice(string_buf),\n+                            });\n+\n+                            var full_target: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                            defer full_target.deinit();\n+\n+                            installer.appendStorePath(&full_target, this.entry_id);\n+\n+                            const symlinker: Symlinker = .{\n+                                .dest = hidden_hoisted_node_modules,\n+                                .target = target,\n+                                .fallback_junction_target = full_target,\n+                            };\n+                            _ = symlinker.ensureSymlink(.ignore_failure);\n+                        },\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .run_preinstall => |current_step| {\n+                    if (!installer.manager.options.do.run_scripts or this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const string_buf = installer.lockfile.buffers.string_bytes.items;\n+\n+                    const dep = installer.lockfile.buffers.dependencies.items[dep_id];\n+                    const truncated_dep_name_hash: TruncatedPackageNameHash = @truncate(dep.name_hash);\n+\n+                    const is_trusted, const is_trusted_through_update_request = brk: {\n+                        if (installer.trusted_dependencies_from_update_requests.contains(truncated_dep_name_hash)) {\n+                            break :brk .{ true, true };\n+                        }\n+                        if (installer.lockfile.hasTrustedDependency(dep.name.slice(string_buf))) {\n+                            break :brk .{ true, false };\n+                        }\n+                        break :brk .{ false, false };\n+                    };\n+\n+                    var pkg_cwd: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                    defer pkg_cwd.deinit();\n+\n+                    installer.appendStorePath(&pkg_cwd, this.entry_id);\n+\n+                    if (pkg_res.tag != .root and (pkg_res.tag == .workspace or is_trusted)) {\n+                        const pkg_scripts: *Package.Scripts = &pkg_script_lists[pkg_id];\n+\n+                        var log = bun.logger.Log.init(bun.default_allocator);\n+                        defer log.deinit();\n+\n+                        const scripts_list = pkg_scripts.getList(\n+                            &log,\n+                            installer.lockfile,\n+                            &pkg_cwd,\n+                            dep.name.slice(string_buf),\n+                            &pkg_res,\n+                        ) catch |err| {\n+                            return .failure(.{ .run_preinstall = err });\n+                        };\n+\n+                        if (scripts_list) |list| {\n+                            entry_scripts[this.entry_id.get()] = bun.create(bun.default_allocator, Package.Scripts.List, list);\n+\n+                            if (is_trusted_through_update_request) {\n+                                const trusted_dep_to_add = try installer.manager.allocator.dupe(u8, dep.name.slice(string_buf));\n+\n+                                installer.trusted_dependencies_mutex.lock();\n+                                defer installer.trusted_dependencies_mutex.unlock();\n+\n+                                try installer.manager.trusted_deps_to_add_to_package_json.append(\n+                                    installer.manager.allocator,\n+                                    trusted_dep_to_add,\n+                                );\n+                                if (installer.lockfile.trusted_dependencies == null) {\n+                                    installer.lockfile.trusted_dependencies = .{};\n+                                }\n+                                try installer.lockfile.trusted_dependencies.?.put(installer.manager.allocator, truncated_dep_name_hash, {});\n+                            }\n+\n+                            if (list.first_index != 0) {\n+                                // has scripts but not a preinstall\n+                                continue :next_step this.nextStep(current_step);\n+                            }\n+\n+                            installer.manager.spawnPackageLifecycleScripts(\n+                                installer.command_ctx,\n+                                list,\n+                                dep.behavior.optional,\n+                                false,\n+                                .{\n+                                    .entry_id = this.entry_id,\n+                                    .installer = installer,\n+                                },\n+                            ) catch |err| {\n+                                return .failure(.{ .run_preinstall = err });\n+                            };\n+\n+                            return .yield;\n+                        }\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .binaries => |current_step| {\n+                    if (this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const bin = pkg_bins[pkg_id];\n+                    if (bin.tag == .none) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const string_buf = installer.lockfile.buffers.string_bytes.items;\n+                    const dependencies = installer.lockfile.buffers.dependencies.items;\n+\n+                    const dep_name = dependencies[dep_id].name.slice(string_buf);\n+\n+                    var abs_target_buf: bun.PathBuffer = undefined;\n+                    var abs_dest_buf: bun.PathBuffer = undefined;\n+                    var rel_buf: bun.PathBuffer = undefined;\n+\n+                    var seen: bun.StringHashMap(void) = .init(bun.default_allocator);\n+                    defer seen.deinit();\n+\n+                    var node_modules_path: bun.AbsPath(.{}) = .initTopLevelDir();\n+                    defer node_modules_path.deinit();\n+\n+                    installer.appendStoreNodeModulesPath(&node_modules_path, this.entry_id);\n+\n+                    var bin_linker: Bin.Linker = .{\n+                        .bin = bin,\n+                        .global_bin_path = installer.manager.options.bin_path,\n+                        .package_name = strings.StringOrTinyString.init(dep_name),\n+                        .string_buf = string_buf,\n+                        .extern_string_buf = installer.lockfile.buffers.extern_strings.items,\n+                        .seen = &seen,\n+                        .node_modules_path = &node_modules_path,\n+                        .abs_target_buf = &abs_target_buf,\n+                        .abs_dest_buf = &abs_dest_buf,\n+                        .rel_buf = &rel_buf,\n+                    };\n+\n+                    bin_linker.link(false);\n+\n+                    if (bin_linker.err) |err| {\n+                        return .failure(.{ .binaries = err });\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .@\"run (post)install and (pre/post)prepare\" => |current_step| {\n+                    if (!installer.manager.options.do.run_scripts or this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    var list = entry_scripts[this.entry_id.get()] orelse {\n+                        continue :next_step this.nextStep(current_step);\n+                    };\n+\n+                    if (list.first_index == 0) {\n+                        for (list.items[1..], 1..) |item, i| {\n+                            if (item != null) {\n+                                list.first_index = @intCast(i);\n+                                break;\n+                            }\n+                        }\n+                    }\n+\n+                    if (list.first_index == 0) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const dep = installer.lockfile.buffers.dependencies.items[dep_id];\n+\n+                    installer.manager.spawnPackageLifecycleScripts(\n+                        installer.command_ctx,\n+                        list.*,\n+                        dep.behavior.optional,\n+                        false,\n+                        .{\n+                            .entry_id = this.entry_id,\n+                            .installer = installer,\n+                        },\n+                    ) catch |err| {\n+                        return .failure(.{ .@\"run (post)install and (pre/post)prepare\" = err });\n+                    };\n+\n+                    // when these scripts finish the package install will be\n+                    // complete. the task does not have anymore work to complete\n+                    // so it does not return to the thread pool.\n+\n+                    return .yield;\n+                },\n+\n+                .done => {\n+                    return .done;\n+                },\n+\n+                .blocked => {\n+                    bun.debugAssert(false);\n+                    return .yield;\n+                },\n+            };\n+        }\n+\n+        pub fn callback(task: *ThreadPool.Task) void {\n+            const this: *Task = @fieldParentPtr(\"task\", task);\n+\n+            const res = this.run() catch |err| switch (err) {\n+                error.OutOfMemory => bun.outOfMemory(),\n+            };\n+\n+            switch (res) {\n+                .yield => {},\n+                .done => {\n+                    this.installer.tasks.push(this);\n+                    this.installer.manager.wake();\n+                },\n+                .fail => |err| {\n+                    this.installer.store.entries.items(.step)[this.entry_id.get()].store(.done, .monotonic);\n+                    this.err = err.clone(bun.default_allocator);\n+                    this.installer.tasks.push(this);\n+                    this.installer.manager.wake();\n+                },\n+            }\n+        }\n+    };\n+\n+    const PatchInfo = union(enum) {\n+        none,\n+        remove: struct {\n+            name_and_version_hash: u64,\n+        },\n+        patch: struct {\n+            name_and_version_hash: u64,\n+            patch_path: string,\n+            contents_hash: u64,\n+        },\n+\n+        pub fn contentsHash(this: *const @This()) ?u64 {\n+            return switch (this.*) {\n+                .none, .remove => null,\n+                .patch => |patch| patch.contents_hash,\n+            };\n+        }\n+\n+        pub fn nameAndVersionHash(this: *const @This()) ?u64 {\n+            return switch (this.*) {\n+                .none, .remove => null,\n+                .patch => |patch| patch.name_and_version_hash,\n+            };\n+        }\n+    };\n+\n+    pub fn packagePatchInfo(\n+        this: *Installer,\n+        pkg_name: String,\n+        pkg_name_hash: PackageNameHash,\n+        pkg_res: *const Resolution,\n+    ) OOM!PatchInfo {\n+        if (this.lockfile.patched_dependencies.entries.len == 0 and this.manager.patched_dependencies_to_remove.entries.len == 0) {\n+            return .none;\n+        }\n+\n+        const string_buf = this.lockfile.buffers.string_bytes.items;\n+\n+        var version_buf: std.ArrayListUnmanaged(u8) = .empty;\n+        defer version_buf.deinit(bun.default_allocator);\n+\n+        var writer = version_buf.writer(this.lockfile.allocator);\n+        try writer.print(\"{s}@\", .{pkg_name.slice(string_buf)});\n+\n+        switch (pkg_res.tag) {\n+            .workspace => {\n+                if (this.lockfile.workspace_versions.get(pkg_name_hash)) |workspace_version| {\n+                    try writer.print(\"{}\", .{workspace_version.fmt(string_buf)});\n+                }\n+            },\n+            else => {\n+                try writer.print(\"{}\", .{pkg_res.fmt(string_buf, .posix)});\n+            },\n+        }\n+\n+        const name_and_version_hash = String.Builder.stringHash(version_buf.items);\n+\n+        if (this.lockfile.patched_dependencies.get(name_and_version_hash)) |patch| {\n+            return .{\n+                .patch = .{\n+                    .name_and_version_hash = name_and_version_hash,\n+                    .patch_path = patch.path.slice(string_buf),\n+                    .contents_hash = patch.patchfileHash().?,\n+                },\n+            };\n+        }\n+\n+        if (this.manager.patched_dependencies_to_remove.contains(name_and_version_hash)) {\n+            return .{\n+                .remove = .{\n+                    .name_and_version_hash = name_and_version_hash,\n+                },\n+            };\n+        }\n+\n+        return .none;\n+    }\n+\n+    pub fn linkDependencyBins(this: *const Installer, parent_entry_id: Store.Entry.Id) !void {\n+        const lockfile = this.lockfile;\n+        const store = this.store;\n+\n+        const string_buf = lockfile.buffers.string_bytes.items;\n+        const extern_string_buf = lockfile.buffers.extern_strings.items;\n+\n+        const entries = store.entries.slice();\n+        const entry_node_ids = entries.items(.node_id);\n+        const entry_deps = entries.items(.dependencies);\n+\n+        const nodes = store.nodes.slice();\n+        const node_pkg_ids = nodes.items(.pkg_id);\n+        const node_dep_ids = nodes.items(.dep_id);\n+\n+        const pkgs = lockfile.packages.slice();\n+        const pkg_bins = pkgs.items(.bin);\n+\n+        var link_target_buf: bun.PathBuffer = undefined;",
        "comment_created_at": "2025-07-08T05:22:55+00:00",
        "comment_author": "Jarred-Sumner",
        "comment_body": "```suggestion\n        const link_target_buf = bun.PathBufferPool.get();\n        defer bun.PathBufferPool.put(link_target_buf);\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2191504392",
    "pr_number": 20440,
    "pr_file": "src/install/isolated_install/Installer.zig",
    "created_at": "2025-07-08T05:23:18+00:00",
    "commented_code": "+pub const Installer = struct {\n+    trusted_dependencies_mutex: bun.Mutex,\n+    // this is not const for `lockfile.trusted_dependencies`\n+    lockfile: *Lockfile,\n+\n+    summary: PackageInstall.Summary = .{ .successfully_installed = .empty },\n+    installed: Bitset,\n+    install_node: ?*Progress.Node,\n+    scripts_node: ?*Progress.Node,\n+\n+    manager: *PackageManager,\n+    command_ctx: Command.Context,\n+\n+    store: *const Store,\n+\n+    tasks: bun.UnboundedQueue(Task, .next) = .{},\n+    preallocated_tasks: Task.Preallocated,\n+\n+    trusted_dependencies_from_update_requests: std.AutoArrayHashMapUnmanaged(TruncatedPackageNameHash, void),\n+\n+    pub fn deinit(this: *const Installer) void {\n+        this.trusted_dependencies_from_update_requests.deinit(this.lockfile.allocator);\n+    }\n+\n+    pub fn resumeTask(this: *Installer, entry_id: Store.Entry.Id) void {\n+        const task = this.preallocated_tasks.get();\n+\n+        task.* = .{\n+            .entry_id = entry_id,\n+            .installer = this,\n+            .err = null,\n+        };\n+\n+        this.manager.thread_pool.schedule(.from(&task.task));\n+    }\n+\n+    pub fn onPackageExtracted(this: *Installer, task_id: install.Task.Id) void {\n+        if (this.manager.task_queue.fetchRemove(task_id)) |removed| {\n+            for (removed.value.items) |install_ctx| {\n+                const entry_id = install_ctx.isolated_package_install_context;\n+                this.resumeTask(entry_id);\n+            }\n+        }\n+    }\n+\n+    pub fn onTaskFail(this: *Installer, entry_id: Store.Entry.Id, err: Task.Error) void {\n+        const string_buf = this.lockfile.buffers.string_bytes.items;\n+\n+        const entries = this.store.entries.slice();\n+        const entry_node_ids = entries.items(.node_id);\n+\n+        const nodes = this.store.nodes.slice();\n+        const node_pkg_ids = nodes.items(.pkg_id);\n+\n+        const pkgs = this.lockfile.packages.slice();\n+        const pkg_names = pkgs.items(.name);\n+        const pkg_resolutions = pkgs.items(.resolution);\n+\n+        const node_id = entry_node_ids[entry_id.get()];\n+        const pkg_id = node_pkg_ids[node_id.get()];\n+\n+        const pkg_name = pkg_names[pkg_id];\n+        const pkg_res = pkg_resolutions[pkg_id];\n+\n+        switch (err) {\n+            .link_package => |link_err| {\n+                Output.err(link_err, \"failed to link package: {s}@{}\", .{\n+                    pkg_name.slice(string_buf),\n+                    pkg_res.fmt(string_buf, .auto),\n+                });\n+            },\n+            .symlink_dependencies => |symlink_err| {\n+                Output.err(symlink_err, \"failed to symlink dependencies for package: {s}@{}\", .{\n+                    pkg_name.slice(string_buf),\n+                    pkg_res.fmt(string_buf, .auto),\n+                });\n+            },\n+            else => {},\n+        }\n+        Output.flush();\n+\n+        // attempt deleting the package so the next install will install it again\n+        switch (pkg_res.tag) {\n+            .uninitialized,\n+            .single_file_module,\n+            .root,\n+            .workspace,\n+            .symlink,\n+            => {},\n+\n+            _ => {},\n+\n+            // to be safe make sure we only delete packages in the store\n+            .npm,\n+            .git,\n+            .github,\n+            .local_tarball,\n+            .remote_tarball,\n+            .folder,\n+            => {\n+                var store_path: bun.RelPath(.{ .sep = .auto }) = .init();\n+                defer store_path.deinit();\n+\n+                store_path.appendFmt(\"node_modules/{}\", .{\n+                    Store.Entry.fmtStorePath(entry_id, this.store, this.lockfile),\n+                });\n+\n+                _ = sys.unlink(store_path.sliceZ());\n+            },\n+        }\n+\n+        if (this.manager.options.enable.fail_early) {\n+            Global.exit(1);\n+        }\n+\n+        this.summary.fail += 1;\n+\n+        this.decrementPendingTasks(entry_id);\n+        this.resumeAvailableTasks();\n+    }\n+\n+    pub fn onTask(this: *Installer, task_entry_id: Store.Entry.Id) void {\n+        const entries = this.store.entries.slice();\n+        const entry_steps = entries.items(.step);\n+        const step = entry_steps[task_entry_id.get()].load(.monotonic);\n+\n+        if (step != .done) {\n+            // only done will unblock other packages\n+            return;\n+        }\n+\n+        this.onTaskSuccess(task_entry_id);\n+    }\n+\n+    pub fn decrementPendingTasks(this: *Installer, entry_id: Store.Entry.Id) void {\n+        _ = entry_id;\n+        this.manager.decrementPendingTasks();\n+    }\n+\n+    pub fn onTaskSkipped(this: *Installer, entry_id: Store.Entry.Id) void {\n+        this.summary.skipped += 1;\n+        this.decrementPendingTasks(entry_id);\n+        this.store.entries.items(.step)[entry_id.get()].store(.done, .monotonic);\n+        if (this.install_node) |node| {\n+            node.completeOne();\n+        }\n+        this.resumeAvailableTasks();\n+    }\n+\n+    pub fn onTaskSuccess(this: *Installer, entry_id: Store.Entry.Id) void {\n+        this.decrementPendingTasks(entry_id);\n+        this.resumeAvailableTasks();\n+\n+        const pkg_id = pkg_id: {\n+            if (entry_id == .root) {\n+                return;\n+            }\n+\n+            const node_id = this.store.entries.items(.node_id)[entry_id.get()];\n+            const nodes = this.store.nodes.slice();\n+\n+            const dep_id = nodes.items(.dep_id)[node_id.get()];\n+\n+            if (dep_id == invalid_dependency_id) {\n+                // should be coverd by `entry_id == .root` above, but\n+                // just in case\n+                return;\n+            }\n+\n+            const dep = this.lockfile.buffers.dependencies.items[dep_id];\n+\n+            if (dep.behavior.isWorkspaceOnly()) {\n+                return;\n+            }\n+\n+            break :pkg_id nodes.items(.pkg_id)[node_id.get()];\n+        };\n+\n+        const is_duplicate = this.installed.isSet(pkg_id);\n+        this.summary.success += @intFromBool(!is_duplicate);\n+        this.installed.set(pkg_id);\n+        if (this.install_node) |node| {\n+            node.completeOne();\n+        }\n+    }\n+\n+    pub fn resumeAvailableTasks(this: *Installer) void {\n+        const entries = this.store.entries.slice();\n+        const entry_deps = entries.items(.dependencies);\n+        const entry_steps = entries.items(.step);\n+\n+        var parent_dedupe: std.AutoArrayHashMap(Store.Entry.Id, void) = .init(bun.default_allocator);\n+        defer parent_dedupe.deinit();\n+\n+        next_entry: for (0..this.store.entries.len) |_entry_id| {\n+            const entry_id: Store.Entry.Id = .from(@intCast(_entry_id));\n+\n+            const entry_step = entry_steps[entry_id.get()].load(.monotonic);\n+            if (entry_step != .blocked) {\n+                continue;\n+            }\n+\n+            const deps = entry_deps[entry_id.get()];\n+            for (deps.slice()) |dep| {\n+                switch (entry_steps[dep.entry_id.get()].load(.monotonic)) {\n+                    .done => {},\n+                    else => {\n+                        parent_dedupe.clearRetainingCapacity();\n+                        if (!this.store.isCycle(entry_id, dep.entry_id, &parent_dedupe)) {\n+                            continue :next_entry;\n+                        }\n+                    },\n+                }\n+            }\n+\n+            entry_steps[entry_id.get()].store(.symlink_dependency_binaries, .monotonic);\n+            this.resumeTask(entry_id);\n+        }\n+    }\n+\n+    pub const Task = struct {\n+        const Preallocated = bun.HiveArray(Task, 128).Fallback;\n+\n+        entry_id: Store.Entry.Id,\n+        installer: *Installer,\n+\n+        task: ThreadPool.Task = .{ .callback = &callback },\n+        next: ?*Task = null,\n+\n+        err: ?Error,\n+\n+        const Error = union(Step) {\n+            link_package: sys.Error,\n+            symlink_dependencies: sys.Error,\n+            check_if_blocked,\n+            symlink_dependency_binaries,\n+            run_preinstall: anyerror,\n+            binaries: anyerror,\n+            @\"run (post)install and (pre/post)prepare\": anyerror,\n+            done,\n+            blocked,\n+\n+            pub fn clone(this: *const Error, allocator: std.mem.Allocator) Error {\n+                return switch (this.*) {\n+                    .link_package => |err| .{ .link_package = err.clone(allocator) },\n+                    .symlink_dependencies => |err| .{ .symlink_dependencies = err.clone(allocator) },\n+                    .check_if_blocked => .check_if_blocked,\n+                    .symlink_dependency_binaries => .symlink_dependency_binaries,\n+                    .run_preinstall => |err| .{ .run_preinstall = err },\n+                    .binaries => |err| .{ .binaries = err },\n+                    .@\"run (post)install and (pre/post)prepare\" => |err| .{ .@\"run (post)install and (pre/post)prepare\" = err },\n+                    .done => .done,\n+                    .blocked => .blocked,\n+                };\n+            }\n+        };\n+\n+        pub const Step = enum(u8) {\n+            link_package,\n+            symlink_dependencies,\n+\n+            check_if_blocked,\n+\n+            // blocked can only happen here\n+\n+            symlink_dependency_binaries,\n+            run_preinstall,\n+\n+            // pause here while preinstall runs\n+\n+            binaries,\n+            @\"run (post)install and (pre/post)prepare\",\n+\n+            // pause again while remaining scripts run.\n+\n+            done,\n+            blocked,\n+        };\n+\n+        fn nextStep(this: *Task, comptime current_step: Step) Step {\n+            const next_step: Step = switch (comptime current_step) {\n+                .link_package => .symlink_dependencies,\n+                .symlink_dependencies => .check_if_blocked,\n+                .check_if_blocked => .symlink_dependency_binaries,\n+                .symlink_dependency_binaries => .run_preinstall,\n+                .run_preinstall => .binaries,\n+                .binaries => .@\"run (post)install and (pre/post)prepare\",\n+                .@\"run (post)install and (pre/post)prepare\" => .done,\n+\n+                .done,\n+                .blocked,\n+                => @compileError(\"unexpected step\"),\n+            };\n+\n+            this.installer.store.entries.items(.step)[this.entry_id.get()].store(next_step, .monotonic);\n+\n+            return next_step;\n+        }\n+\n+        const Yield = union(enum) {\n+            yield,\n+            done,\n+            fail: Error,\n+\n+            pub fn failure(e: Error) Yield {\n+                return .{ .fail = e };\n+            }\n+        };\n+\n+        fn run(this: *Task) OOM!Yield {\n+            const installer = this.installer;\n+            const manager = installer.manager;\n+            const lockfile = installer.lockfile;\n+\n+            const pkgs = installer.lockfile.packages.slice();\n+            const pkg_names = pkgs.items(.name);\n+            const pkg_name_hashes = pkgs.items(.name_hash);\n+            const pkg_resolutions = pkgs.items(.resolution);\n+            const pkg_bins = pkgs.items(.bin);\n+            const pkg_script_lists = pkgs.items(.scripts);\n+\n+            const entries = installer.store.entries.slice();\n+            const entry_node_ids = entries.items(.node_id);\n+            const entry_dependencies = entries.items(.dependencies);\n+            const entry_steps = entries.items(.step);\n+            const entry_scripts = entries.items(.scripts);\n+\n+            const nodes = installer.store.nodes.slice();\n+            const node_pkg_ids = nodes.items(.pkg_id);\n+            const node_dep_ids = nodes.items(.dep_id);\n+\n+            const node_id = entry_node_ids[this.entry_id.get()];\n+            const pkg_id = node_pkg_ids[node_id.get()];\n+            const dep_id = node_dep_ids[node_id.get()];\n+\n+            const pkg_name = pkg_names[pkg_id];\n+            const pkg_name_hash = pkg_name_hashes[pkg_id];\n+            const pkg_res = pkg_resolutions[pkg_id];\n+\n+            return next_step: switch (entry_steps[this.entry_id.get()].load(.monotonic)) {\n+                inline .link_package => |current_step| {\n+                    const string_buf = lockfile.buffers.string_bytes.items;\n+\n+                    if (pkg_res.tag == .folder) {\n+                        // the folder does not exist in the cache\n+                        const folder_dir = switch (bun.openDirForIteration(FD.cwd(), pkg_res.value.folder.slice(string_buf))) {\n+                            .result => |fd| fd,\n+                            .err => |err| return .failure(.{ .link_package = err }),\n+                        };\n+                        defer folder_dir.close();\n+\n+                        var src: bun.AbsPath(.{ .unit = .os, .sep = .auto }) = .initTopLevelDir();\n+                        defer src.deinit();\n+                        src.append(pkg_res.value.folder.slice(string_buf));\n+\n+                        var dest: bun.RelPath(.{ .unit = .os, .sep = .auto }) = .init();\n+                        defer dest.deinit();\n+\n+                        installer.appendStorePath(&dest, this.entry_id);\n+\n+                        var hardlinker: Hardlinker = .{\n+                            .src_dir = folder_dir,\n+                            .src = src,\n+                            .dest = dest,\n+                        };\n+\n+                        switch (try hardlinker.link(&.{comptime bun.OSPathLiteral(\"node_modules\")})) {\n+                            .result => {},\n+                            .err => |err| return .failure(.{ .link_package = err }),\n+                        }\n+\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const patch_info = try installer.packagePatchInfo(\n+                        pkg_name,\n+                        pkg_name_hash,\n+                        &pkg_res,\n+                    );\n+\n+                    var pkg_cache_dir_subpath: bun.RelPath(.{ .sep = .auto }) = .from(switch (pkg_res.tag) {\n+                        .npm => manager.cachedNPMPackageFolderName(pkg_name.slice(string_buf), pkg_res.value.npm.version, patch_info.contentsHash()),\n+                        .git => manager.cachedGitFolderName(&pkg_res.value.git, patch_info.contentsHash()),\n+                        .github => manager.cachedGitHubFolderName(&pkg_res.value.github, patch_info.contentsHash()),\n+                        .local_tarball => manager.cachedTarballFolderName(pkg_res.value.local_tarball, patch_info.contentsHash()),\n+                        .remote_tarball => manager.cachedTarballFolderName(pkg_res.value.remote_tarball, patch_info.contentsHash()),\n+\n+                        else => unreachable,\n+                    });\n+                    defer pkg_cache_dir_subpath.deinit();\n+\n+                    const cache_dir, const cache_dir_path = manager.getCacheDirectoryAndAbsPath();\n+                    defer cache_dir_path.deinit();\n+\n+                    var dest_subpath: bun.RelPath(.{ .sep = .auto, .unit = .os }) = .init();\n+                    defer dest_subpath.deinit();\n+\n+                    installer.appendStorePath(&dest_subpath, this.entry_id);\n+\n+                    // link the package\n+                    if (comptime Environment.isMac) {\n+                        if (install.PackageInstall.supported_method == .clonefile) hardlink_fallback: {\n+                            switch (sys.clonefileat(cache_dir, pkg_cache_dir_subpath.sliceZ(), FD.cwd(), dest_subpath.sliceZ())) {\n+                                .result => {\n+                                    // success! move to next step\n+                                    continue :next_step this.nextStep(current_step);\n+                                },\n+                                .err => |clonefile_err1| {\n+                                    switch (clonefile_err1.getErrno()) {\n+                                        .XDEV => break :hardlink_fallback,\n+                                        .OPNOTSUPP => break :hardlink_fallback,\n+                                        .NOENT => {\n+                                            const parent_dest_dir = std.fs.path.dirname(dest_subpath.slice()) orelse {\n+                                                return .failure(.{ .link_package = clonefile_err1 });\n+                                            };\n+\n+                                            FD.cwd().makePath(u8, parent_dest_dir) catch {};\n+\n+                                            switch (sys.clonefileat(cache_dir, pkg_cache_dir_subpath.sliceZ(), FD.cwd(), dest_subpath.sliceZ())) {\n+                                                .result => {\n+                                                    continue :next_step this.nextStep(current_step);\n+                                                },\n+                                                .err => |clonefile_err2| {\n+                                                    return .failure(.{ .link_package = clonefile_err2 });\n+                                                },\n+                                            }\n+                                        },\n+                                        else => {\n+                                            break :hardlink_fallback;\n+                                        },\n+                                    }\n+                                },\n+                            }\n+                        }\n+                    }\n+\n+                    const cached_package_dir = cached_package_dir: {\n+                        if (comptime Environment.isWindows) {\n+                            break :cached_package_dir switch (sys.openDirAtWindowsA(\n+                                cache_dir,\n+                                pkg_cache_dir_subpath.slice(),\n+                                .{ .iterable = true, .can_rename_or_delete = false, .read_only = true },\n+                            )) {\n+                                .result => |dir_fd| dir_fd,\n+                                .err => |err| {\n+                                    return .failure(.{ .link_package = err });\n+                                },\n+                            };\n+                        }\n+                        break :cached_package_dir switch (sys.openat(\n+                            cache_dir,\n+                            pkg_cache_dir_subpath.sliceZ(),\n+                            bun.O.DIRECTORY | bun.O.CLOEXEC | bun.O.RDONLY,\n+                            0,\n+                        )) {\n+                            .result => |fd| fd,\n+                            .err => |err| {\n+                                return .failure(.{ .link_package = err });\n+                            },\n+                        };\n+                    };\n+                    defer cached_package_dir.close();\n+\n+                    var src: bun.AbsPath(.{ .sep = .auto, .unit = .os }) = .from(cache_dir_path.slice());\n+                    defer src.deinit();\n+                    src.append(pkg_cache_dir_subpath.slice());\n+\n+                    var hardlinker: Hardlinker = .{\n+                        .src_dir = cached_package_dir,\n+                        .src = src,\n+                        .dest = dest_subpath,\n+                    };\n+\n+                    switch (try hardlinker.link(&.{})) {\n+                        .result => {},\n+                        .err => |err| return .failure(.{ .link_package = err }),\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .symlink_dependencies => |current_step| {\n+                    const string_buf = lockfile.buffers.string_bytes.items;\n+                    const dependencies = lockfile.buffers.dependencies.items;\n+\n+                    for (entry_dependencies[this.entry_id.get()].slice()) |dep| {\n+                        const dep_node_id = entry_node_ids[dep.entry_id.get()];\n+                        const dep_dep_id = node_dep_ids[dep_node_id.get()];\n+                        const dep_name = dependencies[dep_dep_id].name;\n+\n+                        var dest: bun.Path(.{ .sep = .auto }) = .initTopLevelDir();\n+                        defer dest.deinit();\n+\n+                        installer.appendStoreNodeModulesPath(&dest, this.entry_id);\n+                        dest.append(dep_name.slice(string_buf));\n+\n+                        var dep_store_path: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                        defer dep_store_path.deinit();\n+\n+                        installer.appendStorePath(&dep_store_path, dep.entry_id);\n+\n+                        const target = target: {\n+                            var dest_save = dest.save();\n+                            defer dest_save.restore();\n+\n+                            dest.undo(1);\n+                            break :target dest.relative(&dep_store_path);\n+                        };\n+                        defer target.deinit();\n+\n+                        const symlinker: Symlinker = .{\n+                            .dest = dest,\n+                            .target = target,\n+                            .fallback_junction_target = dep_store_path,\n+                        };\n+\n+                        const link_strategy: Symlinker.Strategy = if (pkg_res.tag == .root or pkg_res.tag == .workspace)\n+                            // root and workspace packages ensure their dependency symlinks\n+                            // exist unconditionally. To make sure it's fast, first readlink\n+                            // then create the symlink if necessary\n+                            .expect_existing\n+                        else\n+                            .expect_missing;\n+\n+                        switch (symlinker.ensureSymlink(link_strategy)) {\n+                            .result => {},\n+                            .err => |err| {\n+                                return .failure(.{ .symlink_dependencies = err });\n+                            },\n+                        }\n+                    }\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .check_if_blocked => |current_step| {\n+                    // preinstall scripts need to run before binaries can be linked. Block here if any dependencies\n+                    // of this entry are not finished. Do not count cycles towards blocking.\n+\n+                    var parent_dedupe: std.AutoArrayHashMap(Store.Entry.Id, void) = .init(bun.default_allocator);\n+                    defer parent_dedupe.deinit();\n+\n+                    const deps = entry_dependencies[this.entry_id.get()];\n+                    for (deps.slice()) |dep| {\n+                        if (entry_steps[dep.entry_id.get()].load(.monotonic) != .done) {\n+                            if (installer.store.isCycle(this.entry_id, dep.entry_id, &parent_dedupe)) {\n+                                parent_dedupe.clearRetainingCapacity();\n+                                continue;\n+                            }\n+\n+                            entry_steps[this.entry_id.get()].store(.blocked, .monotonic);\n+                            return .yield;\n+                        }\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .symlink_dependency_binaries => |current_step| {\n+                    installer.linkDependencyBins(this.entry_id) catch |err| {\n+                        return .failure(.{ .binaries = err });\n+                    };\n+\n+                    switch (pkg_res.tag) {\n+                        .uninitialized,\n+                        .root,\n+                        .workspace,\n+                        .folder,\n+                        .symlink,\n+                        .single_file_module,\n+                        => {},\n+\n+                        _ => {},\n+\n+                        .npm,\n+                        .git,\n+                        .github,\n+                        .local_tarball,\n+                        .remote_tarball,\n+                        => {\n+                            const string_buf = lockfile.buffers.string_bytes.items;\n+\n+                            var hidden_hoisted_node_modules: bun.Path(.{ .sep = .auto }) = .init();\n+                            defer hidden_hoisted_node_modules.deinit();\n+\n+                            hidden_hoisted_node_modules.append(\n+                                \"node_modules\" ++ std.fs.path.sep_str ++ \".bun\" ++ std.fs.path.sep_str ++ \"node_modules\",\n+                            );\n+                            hidden_hoisted_node_modules.append(pkg_name.slice(installer.lockfile.buffers.string_bytes.items));\n+\n+                            var target: bun.RelPath(.{ .sep = .auto }) = .init();\n+                            defer target.deinit();\n+\n+                            target.append(\"..\");\n+                            if (strings.containsChar(pkg_name.slice(installer.lockfile.buffers.string_bytes.items), '/')) {\n+                                target.append(\"..\");\n+                            }\n+\n+                            target.appendFmt(\"{}/node_modules/{s}\", .{\n+                                Store.Entry.fmtStorePath(this.entry_id, installer.store, installer.lockfile),\n+                                pkg_name.slice(string_buf),\n+                            });\n+\n+                            var full_target: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                            defer full_target.deinit();\n+\n+                            installer.appendStorePath(&full_target, this.entry_id);\n+\n+                            const symlinker: Symlinker = .{\n+                                .dest = hidden_hoisted_node_modules,\n+                                .target = target,\n+                                .fallback_junction_target = full_target,\n+                            };\n+                            _ = symlinker.ensureSymlink(.ignore_failure);\n+                        },\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .run_preinstall => |current_step| {\n+                    if (!installer.manager.options.do.run_scripts or this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const string_buf = installer.lockfile.buffers.string_bytes.items;\n+\n+                    const dep = installer.lockfile.buffers.dependencies.items[dep_id];\n+                    const truncated_dep_name_hash: TruncatedPackageNameHash = @truncate(dep.name_hash);\n+\n+                    const is_trusted, const is_trusted_through_update_request = brk: {\n+                        if (installer.trusted_dependencies_from_update_requests.contains(truncated_dep_name_hash)) {\n+                            break :brk .{ true, true };\n+                        }\n+                        if (installer.lockfile.hasTrustedDependency(dep.name.slice(string_buf))) {\n+                            break :brk .{ true, false };\n+                        }\n+                        break :brk .{ false, false };\n+                    };\n+\n+                    var pkg_cwd: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                    defer pkg_cwd.deinit();\n+\n+                    installer.appendStorePath(&pkg_cwd, this.entry_id);\n+\n+                    if (pkg_res.tag != .root and (pkg_res.tag == .workspace or is_trusted)) {\n+                        const pkg_scripts: *Package.Scripts = &pkg_script_lists[pkg_id];\n+\n+                        var log = bun.logger.Log.init(bun.default_allocator);\n+                        defer log.deinit();\n+\n+                        const scripts_list = pkg_scripts.getList(\n+                            &log,\n+                            installer.lockfile,\n+                            &pkg_cwd,\n+                            dep.name.slice(string_buf),\n+                            &pkg_res,\n+                        ) catch |err| {\n+                            return .failure(.{ .run_preinstall = err });\n+                        };\n+\n+                        if (scripts_list) |list| {\n+                            entry_scripts[this.entry_id.get()] = bun.create(bun.default_allocator, Package.Scripts.List, list);\n+\n+                            if (is_trusted_through_update_request) {\n+                                const trusted_dep_to_add = try installer.manager.allocator.dupe(u8, dep.name.slice(string_buf));\n+\n+                                installer.trusted_dependencies_mutex.lock();\n+                                defer installer.trusted_dependencies_mutex.unlock();\n+\n+                                try installer.manager.trusted_deps_to_add_to_package_json.append(\n+                                    installer.manager.allocator,\n+                                    trusted_dep_to_add,\n+                                );\n+                                if (installer.lockfile.trusted_dependencies == null) {\n+                                    installer.lockfile.trusted_dependencies = .{};\n+                                }\n+                                try installer.lockfile.trusted_dependencies.?.put(installer.manager.allocator, truncated_dep_name_hash, {});\n+                            }\n+\n+                            if (list.first_index != 0) {\n+                                // has scripts but not a preinstall\n+                                continue :next_step this.nextStep(current_step);\n+                            }\n+\n+                            installer.manager.spawnPackageLifecycleScripts(\n+                                installer.command_ctx,\n+                                list,\n+                                dep.behavior.optional,\n+                                false,\n+                                .{\n+                                    .entry_id = this.entry_id,\n+                                    .installer = installer,\n+                                },\n+                            ) catch |err| {\n+                                return .failure(.{ .run_preinstall = err });\n+                            };\n+\n+                            return .yield;\n+                        }\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .binaries => |current_step| {\n+                    if (this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const bin = pkg_bins[pkg_id];\n+                    if (bin.tag == .none) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const string_buf = installer.lockfile.buffers.string_bytes.items;\n+                    const dependencies = installer.lockfile.buffers.dependencies.items;\n+\n+                    const dep_name = dependencies[dep_id].name.slice(string_buf);\n+\n+                    var abs_target_buf: bun.PathBuffer = undefined;\n+                    var abs_dest_buf: bun.PathBuffer = undefined;\n+                    var rel_buf: bun.PathBuffer = undefined;\n+\n+                    var seen: bun.StringHashMap(void) = .init(bun.default_allocator);\n+                    defer seen.deinit();\n+\n+                    var node_modules_path: bun.AbsPath(.{}) = .initTopLevelDir();\n+                    defer node_modules_path.deinit();\n+\n+                    installer.appendStoreNodeModulesPath(&node_modules_path, this.entry_id);\n+\n+                    var bin_linker: Bin.Linker = .{\n+                        .bin = bin,\n+                        .global_bin_path = installer.manager.options.bin_path,\n+                        .package_name = strings.StringOrTinyString.init(dep_name),\n+                        .string_buf = string_buf,\n+                        .extern_string_buf = installer.lockfile.buffers.extern_strings.items,\n+                        .seen = &seen,\n+                        .node_modules_path = &node_modules_path,\n+                        .abs_target_buf = &abs_target_buf,\n+                        .abs_dest_buf = &abs_dest_buf,\n+                        .rel_buf = &rel_buf,\n+                    };\n+\n+                    bin_linker.link(false);\n+\n+                    if (bin_linker.err) |err| {\n+                        return .failure(.{ .binaries = err });\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .@\"run (post)install and (pre/post)prepare\" => |current_step| {\n+                    if (!installer.manager.options.do.run_scripts or this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    var list = entry_scripts[this.entry_id.get()] orelse {\n+                        continue :next_step this.nextStep(current_step);\n+                    };\n+\n+                    if (list.first_index == 0) {\n+                        for (list.items[1..], 1..) |item, i| {\n+                            if (item != null) {\n+                                list.first_index = @intCast(i);\n+                                break;\n+                            }\n+                        }\n+                    }\n+\n+                    if (list.first_index == 0) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const dep = installer.lockfile.buffers.dependencies.items[dep_id];\n+\n+                    installer.manager.spawnPackageLifecycleScripts(\n+                        installer.command_ctx,\n+                        list.*,\n+                        dep.behavior.optional,\n+                        false,\n+                        .{\n+                            .entry_id = this.entry_id,\n+                            .installer = installer,\n+                        },\n+                    ) catch |err| {\n+                        return .failure(.{ .@\"run (post)install and (pre/post)prepare\" = err });\n+                    };\n+\n+                    // when these scripts finish the package install will be\n+                    // complete. the task does not have anymore work to complete\n+                    // so it does not return to the thread pool.\n+\n+                    return .yield;\n+                },\n+\n+                .done => {\n+                    return .done;\n+                },\n+\n+                .blocked => {\n+                    bun.debugAssert(false);\n+                    return .yield;\n+                },\n+            };\n+        }\n+\n+        pub fn callback(task: *ThreadPool.Task) void {\n+            const this: *Task = @fieldParentPtr(\"task\", task);\n+\n+            const res = this.run() catch |err| switch (err) {\n+                error.OutOfMemory => bun.outOfMemory(),\n+            };\n+\n+            switch (res) {\n+                .yield => {},\n+                .done => {\n+                    this.installer.tasks.push(this);\n+                    this.installer.manager.wake();\n+                },\n+                .fail => |err| {\n+                    this.installer.store.entries.items(.step)[this.entry_id.get()].store(.done, .monotonic);\n+                    this.err = err.clone(bun.default_allocator);\n+                    this.installer.tasks.push(this);\n+                    this.installer.manager.wake();\n+                },\n+            }\n+        }\n+    };\n+\n+    const PatchInfo = union(enum) {\n+        none,\n+        remove: struct {\n+            name_and_version_hash: u64,\n+        },\n+        patch: struct {\n+            name_and_version_hash: u64,\n+            patch_path: string,\n+            contents_hash: u64,\n+        },\n+\n+        pub fn contentsHash(this: *const @This()) ?u64 {\n+            return switch (this.*) {\n+                .none, .remove => null,\n+                .patch => |patch| patch.contents_hash,\n+            };\n+        }\n+\n+        pub fn nameAndVersionHash(this: *const @This()) ?u64 {\n+            return switch (this.*) {\n+                .none, .remove => null,\n+                .patch => |patch| patch.name_and_version_hash,\n+            };\n+        }\n+    };\n+\n+    pub fn packagePatchInfo(\n+        this: *Installer,\n+        pkg_name: String,\n+        pkg_name_hash: PackageNameHash,\n+        pkg_res: *const Resolution,\n+    ) OOM!PatchInfo {\n+        if (this.lockfile.patched_dependencies.entries.len == 0 and this.manager.patched_dependencies_to_remove.entries.len == 0) {\n+            return .none;\n+        }\n+\n+        const string_buf = this.lockfile.buffers.string_bytes.items;\n+\n+        var version_buf: std.ArrayListUnmanaged(u8) = .empty;\n+        defer version_buf.deinit(bun.default_allocator);\n+\n+        var writer = version_buf.writer(this.lockfile.allocator);\n+        try writer.print(\"{s}@\", .{pkg_name.slice(string_buf)});\n+\n+        switch (pkg_res.tag) {\n+            .workspace => {\n+                if (this.lockfile.workspace_versions.get(pkg_name_hash)) |workspace_version| {\n+                    try writer.print(\"{}\", .{workspace_version.fmt(string_buf)});\n+                }\n+            },\n+            else => {\n+                try writer.print(\"{}\", .{pkg_res.fmt(string_buf, .posix)});\n+            },\n+        }\n+\n+        const name_and_version_hash = String.Builder.stringHash(version_buf.items);\n+\n+        if (this.lockfile.patched_dependencies.get(name_and_version_hash)) |patch| {\n+            return .{\n+                .patch = .{\n+                    .name_and_version_hash = name_and_version_hash,\n+                    .patch_path = patch.path.slice(string_buf),\n+                    .contents_hash = patch.patchfileHash().?,\n+                },\n+            };\n+        }\n+\n+        if (this.manager.patched_dependencies_to_remove.contains(name_and_version_hash)) {\n+            return .{\n+                .remove = .{\n+                    .name_and_version_hash = name_and_version_hash,\n+                },\n+            };\n+        }\n+\n+        return .none;\n+    }\n+\n+    pub fn linkDependencyBins(this: *const Installer, parent_entry_id: Store.Entry.Id) !void {\n+        const lockfile = this.lockfile;\n+        const store = this.store;\n+\n+        const string_buf = lockfile.buffers.string_bytes.items;\n+        const extern_string_buf = lockfile.buffers.extern_strings.items;\n+\n+        const entries = store.entries.slice();\n+        const entry_node_ids = entries.items(.node_id);\n+        const entry_deps = entries.items(.dependencies);\n+\n+        const nodes = store.nodes.slice();\n+        const node_pkg_ids = nodes.items(.pkg_id);\n+        const node_dep_ids = nodes.items(.dep_id);\n+\n+        const pkgs = lockfile.packages.slice();\n+        const pkg_bins = pkgs.items(.bin);\n+\n+        var link_target_buf: bun.PathBuffer = undefined;\n+        var link_dest_buf: bun.PathBuffer = undefined;",
    "repo_full_name": "oven-sh/bun",
    "discussion_comments": [
      {
        "comment_id": "2191504392",
        "repo_full_name": "oven-sh/bun",
        "pr_number": 20440,
        "pr_file": "src/install/isolated_install/Installer.zig",
        "discussion_id": "2191504392",
        "commented_code": "@@ -0,0 +1,1074 @@\n+pub const Installer = struct {\n+    trusted_dependencies_mutex: bun.Mutex,\n+    // this is not const for `lockfile.trusted_dependencies`\n+    lockfile: *Lockfile,\n+\n+    summary: PackageInstall.Summary = .{ .successfully_installed = .empty },\n+    installed: Bitset,\n+    install_node: ?*Progress.Node,\n+    scripts_node: ?*Progress.Node,\n+\n+    manager: *PackageManager,\n+    command_ctx: Command.Context,\n+\n+    store: *const Store,\n+\n+    tasks: bun.UnboundedQueue(Task, .next) = .{},\n+    preallocated_tasks: Task.Preallocated,\n+\n+    trusted_dependencies_from_update_requests: std.AutoArrayHashMapUnmanaged(TruncatedPackageNameHash, void),\n+\n+    pub fn deinit(this: *const Installer) void {\n+        this.trusted_dependencies_from_update_requests.deinit(this.lockfile.allocator);\n+    }\n+\n+    pub fn resumeTask(this: *Installer, entry_id: Store.Entry.Id) void {\n+        const task = this.preallocated_tasks.get();\n+\n+        task.* = .{\n+            .entry_id = entry_id,\n+            .installer = this,\n+            .err = null,\n+        };\n+\n+        this.manager.thread_pool.schedule(.from(&task.task));\n+    }\n+\n+    pub fn onPackageExtracted(this: *Installer, task_id: install.Task.Id) void {\n+        if (this.manager.task_queue.fetchRemove(task_id)) |removed| {\n+            for (removed.value.items) |install_ctx| {\n+                const entry_id = install_ctx.isolated_package_install_context;\n+                this.resumeTask(entry_id);\n+            }\n+        }\n+    }\n+\n+    pub fn onTaskFail(this: *Installer, entry_id: Store.Entry.Id, err: Task.Error) void {\n+        const string_buf = this.lockfile.buffers.string_bytes.items;\n+\n+        const entries = this.store.entries.slice();\n+        const entry_node_ids = entries.items(.node_id);\n+\n+        const nodes = this.store.nodes.slice();\n+        const node_pkg_ids = nodes.items(.pkg_id);\n+\n+        const pkgs = this.lockfile.packages.slice();\n+        const pkg_names = pkgs.items(.name);\n+        const pkg_resolutions = pkgs.items(.resolution);\n+\n+        const node_id = entry_node_ids[entry_id.get()];\n+        const pkg_id = node_pkg_ids[node_id.get()];\n+\n+        const pkg_name = pkg_names[pkg_id];\n+        const pkg_res = pkg_resolutions[pkg_id];\n+\n+        switch (err) {\n+            .link_package => |link_err| {\n+                Output.err(link_err, \"failed to link package: {s}@{}\", .{\n+                    pkg_name.slice(string_buf),\n+                    pkg_res.fmt(string_buf, .auto),\n+                });\n+            },\n+            .symlink_dependencies => |symlink_err| {\n+                Output.err(symlink_err, \"failed to symlink dependencies for package: {s}@{}\", .{\n+                    pkg_name.slice(string_buf),\n+                    pkg_res.fmt(string_buf, .auto),\n+                });\n+            },\n+            else => {},\n+        }\n+        Output.flush();\n+\n+        // attempt deleting the package so the next install will install it again\n+        switch (pkg_res.tag) {\n+            .uninitialized,\n+            .single_file_module,\n+            .root,\n+            .workspace,\n+            .symlink,\n+            => {},\n+\n+            _ => {},\n+\n+            // to be safe make sure we only delete packages in the store\n+            .npm,\n+            .git,\n+            .github,\n+            .local_tarball,\n+            .remote_tarball,\n+            .folder,\n+            => {\n+                var store_path: bun.RelPath(.{ .sep = .auto }) = .init();\n+                defer store_path.deinit();\n+\n+                store_path.appendFmt(\"node_modules/{}\", .{\n+                    Store.Entry.fmtStorePath(entry_id, this.store, this.lockfile),\n+                });\n+\n+                _ = sys.unlink(store_path.sliceZ());\n+            },\n+        }\n+\n+        if (this.manager.options.enable.fail_early) {\n+            Global.exit(1);\n+        }\n+\n+        this.summary.fail += 1;\n+\n+        this.decrementPendingTasks(entry_id);\n+        this.resumeAvailableTasks();\n+    }\n+\n+    pub fn onTask(this: *Installer, task_entry_id: Store.Entry.Id) void {\n+        const entries = this.store.entries.slice();\n+        const entry_steps = entries.items(.step);\n+        const step = entry_steps[task_entry_id.get()].load(.monotonic);\n+\n+        if (step != .done) {\n+            // only done will unblock other packages\n+            return;\n+        }\n+\n+        this.onTaskSuccess(task_entry_id);\n+    }\n+\n+    pub fn decrementPendingTasks(this: *Installer, entry_id: Store.Entry.Id) void {\n+        _ = entry_id;\n+        this.manager.decrementPendingTasks();\n+    }\n+\n+    pub fn onTaskSkipped(this: *Installer, entry_id: Store.Entry.Id) void {\n+        this.summary.skipped += 1;\n+        this.decrementPendingTasks(entry_id);\n+        this.store.entries.items(.step)[entry_id.get()].store(.done, .monotonic);\n+        if (this.install_node) |node| {\n+            node.completeOne();\n+        }\n+        this.resumeAvailableTasks();\n+    }\n+\n+    pub fn onTaskSuccess(this: *Installer, entry_id: Store.Entry.Id) void {\n+        this.decrementPendingTasks(entry_id);\n+        this.resumeAvailableTasks();\n+\n+        const pkg_id = pkg_id: {\n+            if (entry_id == .root) {\n+                return;\n+            }\n+\n+            const node_id = this.store.entries.items(.node_id)[entry_id.get()];\n+            const nodes = this.store.nodes.slice();\n+\n+            const dep_id = nodes.items(.dep_id)[node_id.get()];\n+\n+            if (dep_id == invalid_dependency_id) {\n+                // should be coverd by `entry_id == .root` above, but\n+                // just in case\n+                return;\n+            }\n+\n+            const dep = this.lockfile.buffers.dependencies.items[dep_id];\n+\n+            if (dep.behavior.isWorkspaceOnly()) {\n+                return;\n+            }\n+\n+            break :pkg_id nodes.items(.pkg_id)[node_id.get()];\n+        };\n+\n+        const is_duplicate = this.installed.isSet(pkg_id);\n+        this.summary.success += @intFromBool(!is_duplicate);\n+        this.installed.set(pkg_id);\n+        if (this.install_node) |node| {\n+            node.completeOne();\n+        }\n+    }\n+\n+    pub fn resumeAvailableTasks(this: *Installer) void {\n+        const entries = this.store.entries.slice();\n+        const entry_deps = entries.items(.dependencies);\n+        const entry_steps = entries.items(.step);\n+\n+        var parent_dedupe: std.AutoArrayHashMap(Store.Entry.Id, void) = .init(bun.default_allocator);\n+        defer parent_dedupe.deinit();\n+\n+        next_entry: for (0..this.store.entries.len) |_entry_id| {\n+            const entry_id: Store.Entry.Id = .from(@intCast(_entry_id));\n+\n+            const entry_step = entry_steps[entry_id.get()].load(.monotonic);\n+            if (entry_step != .blocked) {\n+                continue;\n+            }\n+\n+            const deps = entry_deps[entry_id.get()];\n+            for (deps.slice()) |dep| {\n+                switch (entry_steps[dep.entry_id.get()].load(.monotonic)) {\n+                    .done => {},\n+                    else => {\n+                        parent_dedupe.clearRetainingCapacity();\n+                        if (!this.store.isCycle(entry_id, dep.entry_id, &parent_dedupe)) {\n+                            continue :next_entry;\n+                        }\n+                    },\n+                }\n+            }\n+\n+            entry_steps[entry_id.get()].store(.symlink_dependency_binaries, .monotonic);\n+            this.resumeTask(entry_id);\n+        }\n+    }\n+\n+    pub const Task = struct {\n+        const Preallocated = bun.HiveArray(Task, 128).Fallback;\n+\n+        entry_id: Store.Entry.Id,\n+        installer: *Installer,\n+\n+        task: ThreadPool.Task = .{ .callback = &callback },\n+        next: ?*Task = null,\n+\n+        err: ?Error,\n+\n+        const Error = union(Step) {\n+            link_package: sys.Error,\n+            symlink_dependencies: sys.Error,\n+            check_if_blocked,\n+            symlink_dependency_binaries,\n+            run_preinstall: anyerror,\n+            binaries: anyerror,\n+            @\"run (post)install and (pre/post)prepare\": anyerror,\n+            done,\n+            blocked,\n+\n+            pub fn clone(this: *const Error, allocator: std.mem.Allocator) Error {\n+                return switch (this.*) {\n+                    .link_package => |err| .{ .link_package = err.clone(allocator) },\n+                    .symlink_dependencies => |err| .{ .symlink_dependencies = err.clone(allocator) },\n+                    .check_if_blocked => .check_if_blocked,\n+                    .symlink_dependency_binaries => .symlink_dependency_binaries,\n+                    .run_preinstall => |err| .{ .run_preinstall = err },\n+                    .binaries => |err| .{ .binaries = err },\n+                    .@\"run (post)install and (pre/post)prepare\" => |err| .{ .@\"run (post)install and (pre/post)prepare\" = err },\n+                    .done => .done,\n+                    .blocked => .blocked,\n+                };\n+            }\n+        };\n+\n+        pub const Step = enum(u8) {\n+            link_package,\n+            symlink_dependencies,\n+\n+            check_if_blocked,\n+\n+            // blocked can only happen here\n+\n+            symlink_dependency_binaries,\n+            run_preinstall,\n+\n+            // pause here while preinstall runs\n+\n+            binaries,\n+            @\"run (post)install and (pre/post)prepare\",\n+\n+            // pause again while remaining scripts run.\n+\n+            done,\n+            blocked,\n+        };\n+\n+        fn nextStep(this: *Task, comptime current_step: Step) Step {\n+            const next_step: Step = switch (comptime current_step) {\n+                .link_package => .symlink_dependencies,\n+                .symlink_dependencies => .check_if_blocked,\n+                .check_if_blocked => .symlink_dependency_binaries,\n+                .symlink_dependency_binaries => .run_preinstall,\n+                .run_preinstall => .binaries,\n+                .binaries => .@\"run (post)install and (pre/post)prepare\",\n+                .@\"run (post)install and (pre/post)prepare\" => .done,\n+\n+                .done,\n+                .blocked,\n+                => @compileError(\"unexpected step\"),\n+            };\n+\n+            this.installer.store.entries.items(.step)[this.entry_id.get()].store(next_step, .monotonic);\n+\n+            return next_step;\n+        }\n+\n+        const Yield = union(enum) {\n+            yield,\n+            done,\n+            fail: Error,\n+\n+            pub fn failure(e: Error) Yield {\n+                return .{ .fail = e };\n+            }\n+        };\n+\n+        fn run(this: *Task) OOM!Yield {\n+            const installer = this.installer;\n+            const manager = installer.manager;\n+            const lockfile = installer.lockfile;\n+\n+            const pkgs = installer.lockfile.packages.slice();\n+            const pkg_names = pkgs.items(.name);\n+            const pkg_name_hashes = pkgs.items(.name_hash);\n+            const pkg_resolutions = pkgs.items(.resolution);\n+            const pkg_bins = pkgs.items(.bin);\n+            const pkg_script_lists = pkgs.items(.scripts);\n+\n+            const entries = installer.store.entries.slice();\n+            const entry_node_ids = entries.items(.node_id);\n+            const entry_dependencies = entries.items(.dependencies);\n+            const entry_steps = entries.items(.step);\n+            const entry_scripts = entries.items(.scripts);\n+\n+            const nodes = installer.store.nodes.slice();\n+            const node_pkg_ids = nodes.items(.pkg_id);\n+            const node_dep_ids = nodes.items(.dep_id);\n+\n+            const node_id = entry_node_ids[this.entry_id.get()];\n+            const pkg_id = node_pkg_ids[node_id.get()];\n+            const dep_id = node_dep_ids[node_id.get()];\n+\n+            const pkg_name = pkg_names[pkg_id];\n+            const pkg_name_hash = pkg_name_hashes[pkg_id];\n+            const pkg_res = pkg_resolutions[pkg_id];\n+\n+            return next_step: switch (entry_steps[this.entry_id.get()].load(.monotonic)) {\n+                inline .link_package => |current_step| {\n+                    const string_buf = lockfile.buffers.string_bytes.items;\n+\n+                    if (pkg_res.tag == .folder) {\n+                        // the folder does not exist in the cache\n+                        const folder_dir = switch (bun.openDirForIteration(FD.cwd(), pkg_res.value.folder.slice(string_buf))) {\n+                            .result => |fd| fd,\n+                            .err => |err| return .failure(.{ .link_package = err }),\n+                        };\n+                        defer folder_dir.close();\n+\n+                        var src: bun.AbsPath(.{ .unit = .os, .sep = .auto }) = .initTopLevelDir();\n+                        defer src.deinit();\n+                        src.append(pkg_res.value.folder.slice(string_buf));\n+\n+                        var dest: bun.RelPath(.{ .unit = .os, .sep = .auto }) = .init();\n+                        defer dest.deinit();\n+\n+                        installer.appendStorePath(&dest, this.entry_id);\n+\n+                        var hardlinker: Hardlinker = .{\n+                            .src_dir = folder_dir,\n+                            .src = src,\n+                            .dest = dest,\n+                        };\n+\n+                        switch (try hardlinker.link(&.{comptime bun.OSPathLiteral(\"node_modules\")})) {\n+                            .result => {},\n+                            .err => |err| return .failure(.{ .link_package = err }),\n+                        }\n+\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const patch_info = try installer.packagePatchInfo(\n+                        pkg_name,\n+                        pkg_name_hash,\n+                        &pkg_res,\n+                    );\n+\n+                    var pkg_cache_dir_subpath: bun.RelPath(.{ .sep = .auto }) = .from(switch (pkg_res.tag) {\n+                        .npm => manager.cachedNPMPackageFolderName(pkg_name.slice(string_buf), pkg_res.value.npm.version, patch_info.contentsHash()),\n+                        .git => manager.cachedGitFolderName(&pkg_res.value.git, patch_info.contentsHash()),\n+                        .github => manager.cachedGitHubFolderName(&pkg_res.value.github, patch_info.contentsHash()),\n+                        .local_tarball => manager.cachedTarballFolderName(pkg_res.value.local_tarball, patch_info.contentsHash()),\n+                        .remote_tarball => manager.cachedTarballFolderName(pkg_res.value.remote_tarball, patch_info.contentsHash()),\n+\n+                        else => unreachable,\n+                    });\n+                    defer pkg_cache_dir_subpath.deinit();\n+\n+                    const cache_dir, const cache_dir_path = manager.getCacheDirectoryAndAbsPath();\n+                    defer cache_dir_path.deinit();\n+\n+                    var dest_subpath: bun.RelPath(.{ .sep = .auto, .unit = .os }) = .init();\n+                    defer dest_subpath.deinit();\n+\n+                    installer.appendStorePath(&dest_subpath, this.entry_id);\n+\n+                    // link the package\n+                    if (comptime Environment.isMac) {\n+                        if (install.PackageInstall.supported_method == .clonefile) hardlink_fallback: {\n+                            switch (sys.clonefileat(cache_dir, pkg_cache_dir_subpath.sliceZ(), FD.cwd(), dest_subpath.sliceZ())) {\n+                                .result => {\n+                                    // success! move to next step\n+                                    continue :next_step this.nextStep(current_step);\n+                                },\n+                                .err => |clonefile_err1| {\n+                                    switch (clonefile_err1.getErrno()) {\n+                                        .XDEV => break :hardlink_fallback,\n+                                        .OPNOTSUPP => break :hardlink_fallback,\n+                                        .NOENT => {\n+                                            const parent_dest_dir = std.fs.path.dirname(dest_subpath.slice()) orelse {\n+                                                return .failure(.{ .link_package = clonefile_err1 });\n+                                            };\n+\n+                                            FD.cwd().makePath(u8, parent_dest_dir) catch {};\n+\n+                                            switch (sys.clonefileat(cache_dir, pkg_cache_dir_subpath.sliceZ(), FD.cwd(), dest_subpath.sliceZ())) {\n+                                                .result => {\n+                                                    continue :next_step this.nextStep(current_step);\n+                                                },\n+                                                .err => |clonefile_err2| {\n+                                                    return .failure(.{ .link_package = clonefile_err2 });\n+                                                },\n+                                            }\n+                                        },\n+                                        else => {\n+                                            break :hardlink_fallback;\n+                                        },\n+                                    }\n+                                },\n+                            }\n+                        }\n+                    }\n+\n+                    const cached_package_dir = cached_package_dir: {\n+                        if (comptime Environment.isWindows) {\n+                            break :cached_package_dir switch (sys.openDirAtWindowsA(\n+                                cache_dir,\n+                                pkg_cache_dir_subpath.slice(),\n+                                .{ .iterable = true, .can_rename_or_delete = false, .read_only = true },\n+                            )) {\n+                                .result => |dir_fd| dir_fd,\n+                                .err => |err| {\n+                                    return .failure(.{ .link_package = err });\n+                                },\n+                            };\n+                        }\n+                        break :cached_package_dir switch (sys.openat(\n+                            cache_dir,\n+                            pkg_cache_dir_subpath.sliceZ(),\n+                            bun.O.DIRECTORY | bun.O.CLOEXEC | bun.O.RDONLY,\n+                            0,\n+                        )) {\n+                            .result => |fd| fd,\n+                            .err => |err| {\n+                                return .failure(.{ .link_package = err });\n+                            },\n+                        };\n+                    };\n+                    defer cached_package_dir.close();\n+\n+                    var src: bun.AbsPath(.{ .sep = .auto, .unit = .os }) = .from(cache_dir_path.slice());\n+                    defer src.deinit();\n+                    src.append(pkg_cache_dir_subpath.slice());\n+\n+                    var hardlinker: Hardlinker = .{\n+                        .src_dir = cached_package_dir,\n+                        .src = src,\n+                        .dest = dest_subpath,\n+                    };\n+\n+                    switch (try hardlinker.link(&.{})) {\n+                        .result => {},\n+                        .err => |err| return .failure(.{ .link_package = err }),\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .symlink_dependencies => |current_step| {\n+                    const string_buf = lockfile.buffers.string_bytes.items;\n+                    const dependencies = lockfile.buffers.dependencies.items;\n+\n+                    for (entry_dependencies[this.entry_id.get()].slice()) |dep| {\n+                        const dep_node_id = entry_node_ids[dep.entry_id.get()];\n+                        const dep_dep_id = node_dep_ids[dep_node_id.get()];\n+                        const dep_name = dependencies[dep_dep_id].name;\n+\n+                        var dest: bun.Path(.{ .sep = .auto }) = .initTopLevelDir();\n+                        defer dest.deinit();\n+\n+                        installer.appendStoreNodeModulesPath(&dest, this.entry_id);\n+                        dest.append(dep_name.slice(string_buf));\n+\n+                        var dep_store_path: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                        defer dep_store_path.deinit();\n+\n+                        installer.appendStorePath(&dep_store_path, dep.entry_id);\n+\n+                        const target = target: {\n+                            var dest_save = dest.save();\n+                            defer dest_save.restore();\n+\n+                            dest.undo(1);\n+                            break :target dest.relative(&dep_store_path);\n+                        };\n+                        defer target.deinit();\n+\n+                        const symlinker: Symlinker = .{\n+                            .dest = dest,\n+                            .target = target,\n+                            .fallback_junction_target = dep_store_path,\n+                        };\n+\n+                        const link_strategy: Symlinker.Strategy = if (pkg_res.tag == .root or pkg_res.tag == .workspace)\n+                            // root and workspace packages ensure their dependency symlinks\n+                            // exist unconditionally. To make sure it's fast, first readlink\n+                            // then create the symlink if necessary\n+                            .expect_existing\n+                        else\n+                            .expect_missing;\n+\n+                        switch (symlinker.ensureSymlink(link_strategy)) {\n+                            .result => {},\n+                            .err => |err| {\n+                                return .failure(.{ .symlink_dependencies = err });\n+                            },\n+                        }\n+                    }\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .check_if_blocked => |current_step| {\n+                    // preinstall scripts need to run before binaries can be linked. Block here if any dependencies\n+                    // of this entry are not finished. Do not count cycles towards blocking.\n+\n+                    var parent_dedupe: std.AutoArrayHashMap(Store.Entry.Id, void) = .init(bun.default_allocator);\n+                    defer parent_dedupe.deinit();\n+\n+                    const deps = entry_dependencies[this.entry_id.get()];\n+                    for (deps.slice()) |dep| {\n+                        if (entry_steps[dep.entry_id.get()].load(.monotonic) != .done) {\n+                            if (installer.store.isCycle(this.entry_id, dep.entry_id, &parent_dedupe)) {\n+                                parent_dedupe.clearRetainingCapacity();\n+                                continue;\n+                            }\n+\n+                            entry_steps[this.entry_id.get()].store(.blocked, .monotonic);\n+                            return .yield;\n+                        }\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .symlink_dependency_binaries => |current_step| {\n+                    installer.linkDependencyBins(this.entry_id) catch |err| {\n+                        return .failure(.{ .binaries = err });\n+                    };\n+\n+                    switch (pkg_res.tag) {\n+                        .uninitialized,\n+                        .root,\n+                        .workspace,\n+                        .folder,\n+                        .symlink,\n+                        .single_file_module,\n+                        => {},\n+\n+                        _ => {},\n+\n+                        .npm,\n+                        .git,\n+                        .github,\n+                        .local_tarball,\n+                        .remote_tarball,\n+                        => {\n+                            const string_buf = lockfile.buffers.string_bytes.items;\n+\n+                            var hidden_hoisted_node_modules: bun.Path(.{ .sep = .auto }) = .init();\n+                            defer hidden_hoisted_node_modules.deinit();\n+\n+                            hidden_hoisted_node_modules.append(\n+                                \"node_modules\" ++ std.fs.path.sep_str ++ \".bun\" ++ std.fs.path.sep_str ++ \"node_modules\",\n+                            );\n+                            hidden_hoisted_node_modules.append(pkg_name.slice(installer.lockfile.buffers.string_bytes.items));\n+\n+                            var target: bun.RelPath(.{ .sep = .auto }) = .init();\n+                            defer target.deinit();\n+\n+                            target.append(\"..\");\n+                            if (strings.containsChar(pkg_name.slice(installer.lockfile.buffers.string_bytes.items), '/')) {\n+                                target.append(\"..\");\n+                            }\n+\n+                            target.appendFmt(\"{}/node_modules/{s}\", .{\n+                                Store.Entry.fmtStorePath(this.entry_id, installer.store, installer.lockfile),\n+                                pkg_name.slice(string_buf),\n+                            });\n+\n+                            var full_target: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                            defer full_target.deinit();\n+\n+                            installer.appendStorePath(&full_target, this.entry_id);\n+\n+                            const symlinker: Symlinker = .{\n+                                .dest = hidden_hoisted_node_modules,\n+                                .target = target,\n+                                .fallback_junction_target = full_target,\n+                            };\n+                            _ = symlinker.ensureSymlink(.ignore_failure);\n+                        },\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .run_preinstall => |current_step| {\n+                    if (!installer.manager.options.do.run_scripts or this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const string_buf = installer.lockfile.buffers.string_bytes.items;\n+\n+                    const dep = installer.lockfile.buffers.dependencies.items[dep_id];\n+                    const truncated_dep_name_hash: TruncatedPackageNameHash = @truncate(dep.name_hash);\n+\n+                    const is_trusted, const is_trusted_through_update_request = brk: {\n+                        if (installer.trusted_dependencies_from_update_requests.contains(truncated_dep_name_hash)) {\n+                            break :brk .{ true, true };\n+                        }\n+                        if (installer.lockfile.hasTrustedDependency(dep.name.slice(string_buf))) {\n+                            break :brk .{ true, false };\n+                        }\n+                        break :brk .{ false, false };\n+                    };\n+\n+                    var pkg_cwd: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                    defer pkg_cwd.deinit();\n+\n+                    installer.appendStorePath(&pkg_cwd, this.entry_id);\n+\n+                    if (pkg_res.tag != .root and (pkg_res.tag == .workspace or is_trusted)) {\n+                        const pkg_scripts: *Package.Scripts = &pkg_script_lists[pkg_id];\n+\n+                        var log = bun.logger.Log.init(bun.default_allocator);\n+                        defer log.deinit();\n+\n+                        const scripts_list = pkg_scripts.getList(\n+                            &log,\n+                            installer.lockfile,\n+                            &pkg_cwd,\n+                            dep.name.slice(string_buf),\n+                            &pkg_res,\n+                        ) catch |err| {\n+                            return .failure(.{ .run_preinstall = err });\n+                        };\n+\n+                        if (scripts_list) |list| {\n+                            entry_scripts[this.entry_id.get()] = bun.create(bun.default_allocator, Package.Scripts.List, list);\n+\n+                            if (is_trusted_through_update_request) {\n+                                const trusted_dep_to_add = try installer.manager.allocator.dupe(u8, dep.name.slice(string_buf));\n+\n+                                installer.trusted_dependencies_mutex.lock();\n+                                defer installer.trusted_dependencies_mutex.unlock();\n+\n+                                try installer.manager.trusted_deps_to_add_to_package_json.append(\n+                                    installer.manager.allocator,\n+                                    trusted_dep_to_add,\n+                                );\n+                                if (installer.lockfile.trusted_dependencies == null) {\n+                                    installer.lockfile.trusted_dependencies = .{};\n+                                }\n+                                try installer.lockfile.trusted_dependencies.?.put(installer.manager.allocator, truncated_dep_name_hash, {});\n+                            }\n+\n+                            if (list.first_index != 0) {\n+                                // has scripts but not a preinstall\n+                                continue :next_step this.nextStep(current_step);\n+                            }\n+\n+                            installer.manager.spawnPackageLifecycleScripts(\n+                                installer.command_ctx,\n+                                list,\n+                                dep.behavior.optional,\n+                                false,\n+                                .{\n+                                    .entry_id = this.entry_id,\n+                                    .installer = installer,\n+                                },\n+                            ) catch |err| {\n+                                return .failure(.{ .run_preinstall = err });\n+                            };\n+\n+                            return .yield;\n+                        }\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .binaries => |current_step| {\n+                    if (this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const bin = pkg_bins[pkg_id];\n+                    if (bin.tag == .none) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const string_buf = installer.lockfile.buffers.string_bytes.items;\n+                    const dependencies = installer.lockfile.buffers.dependencies.items;\n+\n+                    const dep_name = dependencies[dep_id].name.slice(string_buf);\n+\n+                    var abs_target_buf: bun.PathBuffer = undefined;\n+                    var abs_dest_buf: bun.PathBuffer = undefined;\n+                    var rel_buf: bun.PathBuffer = undefined;\n+\n+                    var seen: bun.StringHashMap(void) = .init(bun.default_allocator);\n+                    defer seen.deinit();\n+\n+                    var node_modules_path: bun.AbsPath(.{}) = .initTopLevelDir();\n+                    defer node_modules_path.deinit();\n+\n+                    installer.appendStoreNodeModulesPath(&node_modules_path, this.entry_id);\n+\n+                    var bin_linker: Bin.Linker = .{\n+                        .bin = bin,\n+                        .global_bin_path = installer.manager.options.bin_path,\n+                        .package_name = strings.StringOrTinyString.init(dep_name),\n+                        .string_buf = string_buf,\n+                        .extern_string_buf = installer.lockfile.buffers.extern_strings.items,\n+                        .seen = &seen,\n+                        .node_modules_path = &node_modules_path,\n+                        .abs_target_buf = &abs_target_buf,\n+                        .abs_dest_buf = &abs_dest_buf,\n+                        .rel_buf = &rel_buf,\n+                    };\n+\n+                    bin_linker.link(false);\n+\n+                    if (bin_linker.err) |err| {\n+                        return .failure(.{ .binaries = err });\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .@\"run (post)install and (pre/post)prepare\" => |current_step| {\n+                    if (!installer.manager.options.do.run_scripts or this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    var list = entry_scripts[this.entry_id.get()] orelse {\n+                        continue :next_step this.nextStep(current_step);\n+                    };\n+\n+                    if (list.first_index == 0) {\n+                        for (list.items[1..], 1..) |item, i| {\n+                            if (item != null) {\n+                                list.first_index = @intCast(i);\n+                                break;\n+                            }\n+                        }\n+                    }\n+\n+                    if (list.first_index == 0) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const dep = installer.lockfile.buffers.dependencies.items[dep_id];\n+\n+                    installer.manager.spawnPackageLifecycleScripts(\n+                        installer.command_ctx,\n+                        list.*,\n+                        dep.behavior.optional,\n+                        false,\n+                        .{\n+                            .entry_id = this.entry_id,\n+                            .installer = installer,\n+                        },\n+                    ) catch |err| {\n+                        return .failure(.{ .@\"run (post)install and (pre/post)prepare\" = err });\n+                    };\n+\n+                    // when these scripts finish the package install will be\n+                    // complete. the task does not have anymore work to complete\n+                    // so it does not return to the thread pool.\n+\n+                    return .yield;\n+                },\n+\n+                .done => {\n+                    return .done;\n+                },\n+\n+                .blocked => {\n+                    bun.debugAssert(false);\n+                    return .yield;\n+                },\n+            };\n+        }\n+\n+        pub fn callback(task: *ThreadPool.Task) void {\n+            const this: *Task = @fieldParentPtr(\"task\", task);\n+\n+            const res = this.run() catch |err| switch (err) {\n+                error.OutOfMemory => bun.outOfMemory(),\n+            };\n+\n+            switch (res) {\n+                .yield => {},\n+                .done => {\n+                    this.installer.tasks.push(this);\n+                    this.installer.manager.wake();\n+                },\n+                .fail => |err| {\n+                    this.installer.store.entries.items(.step)[this.entry_id.get()].store(.done, .monotonic);\n+                    this.err = err.clone(bun.default_allocator);\n+                    this.installer.tasks.push(this);\n+                    this.installer.manager.wake();\n+                },\n+            }\n+        }\n+    };\n+\n+    const PatchInfo = union(enum) {\n+        none,\n+        remove: struct {\n+            name_and_version_hash: u64,\n+        },\n+        patch: struct {\n+            name_and_version_hash: u64,\n+            patch_path: string,\n+            contents_hash: u64,\n+        },\n+\n+        pub fn contentsHash(this: *const @This()) ?u64 {\n+            return switch (this.*) {\n+                .none, .remove => null,\n+                .patch => |patch| patch.contents_hash,\n+            };\n+        }\n+\n+        pub fn nameAndVersionHash(this: *const @This()) ?u64 {\n+            return switch (this.*) {\n+                .none, .remove => null,\n+                .patch => |patch| patch.name_and_version_hash,\n+            };\n+        }\n+    };\n+\n+    pub fn packagePatchInfo(\n+        this: *Installer,\n+        pkg_name: String,\n+        pkg_name_hash: PackageNameHash,\n+        pkg_res: *const Resolution,\n+    ) OOM!PatchInfo {\n+        if (this.lockfile.patched_dependencies.entries.len == 0 and this.manager.patched_dependencies_to_remove.entries.len == 0) {\n+            return .none;\n+        }\n+\n+        const string_buf = this.lockfile.buffers.string_bytes.items;\n+\n+        var version_buf: std.ArrayListUnmanaged(u8) = .empty;\n+        defer version_buf.deinit(bun.default_allocator);\n+\n+        var writer = version_buf.writer(this.lockfile.allocator);\n+        try writer.print(\"{s}@\", .{pkg_name.slice(string_buf)});\n+\n+        switch (pkg_res.tag) {\n+            .workspace => {\n+                if (this.lockfile.workspace_versions.get(pkg_name_hash)) |workspace_version| {\n+                    try writer.print(\"{}\", .{workspace_version.fmt(string_buf)});\n+                }\n+            },\n+            else => {\n+                try writer.print(\"{}\", .{pkg_res.fmt(string_buf, .posix)});\n+            },\n+        }\n+\n+        const name_and_version_hash = String.Builder.stringHash(version_buf.items);\n+\n+        if (this.lockfile.patched_dependencies.get(name_and_version_hash)) |patch| {\n+            return .{\n+                .patch = .{\n+                    .name_and_version_hash = name_and_version_hash,\n+                    .patch_path = patch.path.slice(string_buf),\n+                    .contents_hash = patch.patchfileHash().?,\n+                },\n+            };\n+        }\n+\n+        if (this.manager.patched_dependencies_to_remove.contains(name_and_version_hash)) {\n+            return .{\n+                .remove = .{\n+                    .name_and_version_hash = name_and_version_hash,\n+                },\n+            };\n+        }\n+\n+        return .none;\n+    }\n+\n+    pub fn linkDependencyBins(this: *const Installer, parent_entry_id: Store.Entry.Id) !void {\n+        const lockfile = this.lockfile;\n+        const store = this.store;\n+\n+        const string_buf = lockfile.buffers.string_bytes.items;\n+        const extern_string_buf = lockfile.buffers.extern_strings.items;\n+\n+        const entries = store.entries.slice();\n+        const entry_node_ids = entries.items(.node_id);\n+        const entry_deps = entries.items(.dependencies);\n+\n+        const nodes = store.nodes.slice();\n+        const node_pkg_ids = nodes.items(.pkg_id);\n+        const node_dep_ids = nodes.items(.dep_id);\n+\n+        const pkgs = lockfile.packages.slice();\n+        const pkg_bins = pkgs.items(.bin);\n+\n+        var link_target_buf: bun.PathBuffer = undefined;\n+        var link_dest_buf: bun.PathBuffer = undefined;",
        "comment_created_at": "2025-07-08T05:23:18+00:00",
        "comment_author": "Jarred-Sumner",
        "comment_body": "```suggestion\n        const link_dest_buf = bun.PathBufferPool.get();\n        defer bun.PathBufferPool.put(link_dest_buf);\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2191504855",
    "pr_number": 20440,
    "pr_file": "src/install/isolated_install/Installer.zig",
    "created_at": "2025-07-08T05:23:44+00:00",
    "commented_code": "+pub const Installer = struct {\n+    trusted_dependencies_mutex: bun.Mutex,\n+    // this is not const for `lockfile.trusted_dependencies`\n+    lockfile: *Lockfile,\n+\n+    summary: PackageInstall.Summary = .{ .successfully_installed = .empty },\n+    installed: Bitset,\n+    install_node: ?*Progress.Node,\n+    scripts_node: ?*Progress.Node,\n+\n+    manager: *PackageManager,\n+    command_ctx: Command.Context,\n+\n+    store: *const Store,\n+\n+    tasks: bun.UnboundedQueue(Task, .next) = .{},\n+    preallocated_tasks: Task.Preallocated,\n+\n+    trusted_dependencies_from_update_requests: std.AutoArrayHashMapUnmanaged(TruncatedPackageNameHash, void),\n+\n+    pub fn deinit(this: *const Installer) void {\n+        this.trusted_dependencies_from_update_requests.deinit(this.lockfile.allocator);\n+    }\n+\n+    pub fn resumeTask(this: *Installer, entry_id: Store.Entry.Id) void {\n+        const task = this.preallocated_tasks.get();\n+\n+        task.* = .{\n+            .entry_id = entry_id,\n+            .installer = this,\n+            .err = null,\n+        };\n+\n+        this.manager.thread_pool.schedule(.from(&task.task));\n+    }\n+\n+    pub fn onPackageExtracted(this: *Installer, task_id: install.Task.Id) void {\n+        if (this.manager.task_queue.fetchRemove(task_id)) |removed| {\n+            for (removed.value.items) |install_ctx| {\n+                const entry_id = install_ctx.isolated_package_install_context;\n+                this.resumeTask(entry_id);\n+            }\n+        }\n+    }\n+\n+    pub fn onTaskFail(this: *Installer, entry_id: Store.Entry.Id, err: Task.Error) void {\n+        const string_buf = this.lockfile.buffers.string_bytes.items;\n+\n+        const entries = this.store.entries.slice();\n+        const entry_node_ids = entries.items(.node_id);\n+\n+        const nodes = this.store.nodes.slice();\n+        const node_pkg_ids = nodes.items(.pkg_id);\n+\n+        const pkgs = this.lockfile.packages.slice();\n+        const pkg_names = pkgs.items(.name);\n+        const pkg_resolutions = pkgs.items(.resolution);\n+\n+        const node_id = entry_node_ids[entry_id.get()];\n+        const pkg_id = node_pkg_ids[node_id.get()];\n+\n+        const pkg_name = pkg_names[pkg_id];\n+        const pkg_res = pkg_resolutions[pkg_id];\n+\n+        switch (err) {\n+            .link_package => |link_err| {\n+                Output.err(link_err, \"failed to link package: {s}@{}\", .{\n+                    pkg_name.slice(string_buf),\n+                    pkg_res.fmt(string_buf, .auto),\n+                });\n+            },\n+            .symlink_dependencies => |symlink_err| {\n+                Output.err(symlink_err, \"failed to symlink dependencies for package: {s}@{}\", .{\n+                    pkg_name.slice(string_buf),\n+                    pkg_res.fmt(string_buf, .auto),\n+                });\n+            },\n+            else => {},\n+        }\n+        Output.flush();\n+\n+        // attempt deleting the package so the next install will install it again\n+        switch (pkg_res.tag) {\n+            .uninitialized,\n+            .single_file_module,\n+            .root,\n+            .workspace,\n+            .symlink,\n+            => {},\n+\n+            _ => {},\n+\n+            // to be safe make sure we only delete packages in the store\n+            .npm,\n+            .git,\n+            .github,\n+            .local_tarball,\n+            .remote_tarball,\n+            .folder,\n+            => {\n+                var store_path: bun.RelPath(.{ .sep = .auto }) = .init();\n+                defer store_path.deinit();\n+\n+                store_path.appendFmt(\"node_modules/{}\", .{\n+                    Store.Entry.fmtStorePath(entry_id, this.store, this.lockfile),\n+                });\n+\n+                _ = sys.unlink(store_path.sliceZ());\n+            },\n+        }\n+\n+        if (this.manager.options.enable.fail_early) {\n+            Global.exit(1);\n+        }\n+\n+        this.summary.fail += 1;\n+\n+        this.decrementPendingTasks(entry_id);\n+        this.resumeAvailableTasks();\n+    }\n+\n+    pub fn onTask(this: *Installer, task_entry_id: Store.Entry.Id) void {\n+        const entries = this.store.entries.slice();\n+        const entry_steps = entries.items(.step);\n+        const step = entry_steps[task_entry_id.get()].load(.monotonic);\n+\n+        if (step != .done) {\n+            // only done will unblock other packages\n+            return;\n+        }\n+\n+        this.onTaskSuccess(task_entry_id);\n+    }\n+\n+    pub fn decrementPendingTasks(this: *Installer, entry_id: Store.Entry.Id) void {\n+        _ = entry_id;\n+        this.manager.decrementPendingTasks();\n+    }\n+\n+    pub fn onTaskSkipped(this: *Installer, entry_id: Store.Entry.Id) void {\n+        this.summary.skipped += 1;\n+        this.decrementPendingTasks(entry_id);\n+        this.store.entries.items(.step)[entry_id.get()].store(.done, .monotonic);\n+        if (this.install_node) |node| {\n+            node.completeOne();\n+        }\n+        this.resumeAvailableTasks();\n+    }\n+\n+    pub fn onTaskSuccess(this: *Installer, entry_id: Store.Entry.Id) void {\n+        this.decrementPendingTasks(entry_id);\n+        this.resumeAvailableTasks();\n+\n+        const pkg_id = pkg_id: {\n+            if (entry_id == .root) {\n+                return;\n+            }\n+\n+            const node_id = this.store.entries.items(.node_id)[entry_id.get()];\n+            const nodes = this.store.nodes.slice();\n+\n+            const dep_id = nodes.items(.dep_id)[node_id.get()];\n+\n+            if (dep_id == invalid_dependency_id) {\n+                // should be coverd by `entry_id == .root` above, but\n+                // just in case\n+                return;\n+            }\n+\n+            const dep = this.lockfile.buffers.dependencies.items[dep_id];\n+\n+            if (dep.behavior.isWorkspaceOnly()) {\n+                return;\n+            }\n+\n+            break :pkg_id nodes.items(.pkg_id)[node_id.get()];\n+        };\n+\n+        const is_duplicate = this.installed.isSet(pkg_id);\n+        this.summary.success += @intFromBool(!is_duplicate);\n+        this.installed.set(pkg_id);\n+        if (this.install_node) |node| {\n+            node.completeOne();\n+        }\n+    }\n+\n+    pub fn resumeAvailableTasks(this: *Installer) void {\n+        const entries = this.store.entries.slice();\n+        const entry_deps = entries.items(.dependencies);\n+        const entry_steps = entries.items(.step);\n+\n+        var parent_dedupe: std.AutoArrayHashMap(Store.Entry.Id, void) = .init(bun.default_allocator);\n+        defer parent_dedupe.deinit();\n+\n+        next_entry: for (0..this.store.entries.len) |_entry_id| {\n+            const entry_id: Store.Entry.Id = .from(@intCast(_entry_id));\n+\n+            const entry_step = entry_steps[entry_id.get()].load(.monotonic);\n+            if (entry_step != .blocked) {\n+                continue;\n+            }\n+\n+            const deps = entry_deps[entry_id.get()];\n+            for (deps.slice()) |dep| {\n+                switch (entry_steps[dep.entry_id.get()].load(.monotonic)) {\n+                    .done => {},\n+                    else => {\n+                        parent_dedupe.clearRetainingCapacity();\n+                        if (!this.store.isCycle(entry_id, dep.entry_id, &parent_dedupe)) {\n+                            continue :next_entry;\n+                        }\n+                    },\n+                }\n+            }\n+\n+            entry_steps[entry_id.get()].store(.symlink_dependency_binaries, .monotonic);\n+            this.resumeTask(entry_id);\n+        }\n+    }\n+\n+    pub const Task = struct {\n+        const Preallocated = bun.HiveArray(Task, 128).Fallback;\n+\n+        entry_id: Store.Entry.Id,\n+        installer: *Installer,\n+\n+        task: ThreadPool.Task = .{ .callback = &callback },\n+        next: ?*Task = null,\n+\n+        err: ?Error,\n+\n+        const Error = union(Step) {\n+            link_package: sys.Error,\n+            symlink_dependencies: sys.Error,\n+            check_if_blocked,\n+            symlink_dependency_binaries,\n+            run_preinstall: anyerror,\n+            binaries: anyerror,\n+            @\"run (post)install and (pre/post)prepare\": anyerror,\n+            done,\n+            blocked,\n+\n+            pub fn clone(this: *const Error, allocator: std.mem.Allocator) Error {\n+                return switch (this.*) {\n+                    .link_package => |err| .{ .link_package = err.clone(allocator) },\n+                    .symlink_dependencies => |err| .{ .symlink_dependencies = err.clone(allocator) },\n+                    .check_if_blocked => .check_if_blocked,\n+                    .symlink_dependency_binaries => .symlink_dependency_binaries,\n+                    .run_preinstall => |err| .{ .run_preinstall = err },\n+                    .binaries => |err| .{ .binaries = err },\n+                    .@\"run (post)install and (pre/post)prepare\" => |err| .{ .@\"run (post)install and (pre/post)prepare\" = err },\n+                    .done => .done,\n+                    .blocked => .blocked,\n+                };\n+            }\n+        };\n+\n+        pub const Step = enum(u8) {\n+            link_package,\n+            symlink_dependencies,\n+\n+            check_if_blocked,\n+\n+            // blocked can only happen here\n+\n+            symlink_dependency_binaries,\n+            run_preinstall,\n+\n+            // pause here while preinstall runs\n+\n+            binaries,\n+            @\"run (post)install and (pre/post)prepare\",\n+\n+            // pause again while remaining scripts run.\n+\n+            done,\n+            blocked,\n+        };\n+\n+        fn nextStep(this: *Task, comptime current_step: Step) Step {\n+            const next_step: Step = switch (comptime current_step) {\n+                .link_package => .symlink_dependencies,\n+                .symlink_dependencies => .check_if_blocked,\n+                .check_if_blocked => .symlink_dependency_binaries,\n+                .symlink_dependency_binaries => .run_preinstall,\n+                .run_preinstall => .binaries,\n+                .binaries => .@\"run (post)install and (pre/post)prepare\",\n+                .@\"run (post)install and (pre/post)prepare\" => .done,\n+\n+                .done,\n+                .blocked,\n+                => @compileError(\"unexpected step\"),\n+            };\n+\n+            this.installer.store.entries.items(.step)[this.entry_id.get()].store(next_step, .monotonic);\n+\n+            return next_step;\n+        }\n+\n+        const Yield = union(enum) {\n+            yield,\n+            done,\n+            fail: Error,\n+\n+            pub fn failure(e: Error) Yield {\n+                return .{ .fail = e };\n+            }\n+        };\n+\n+        fn run(this: *Task) OOM!Yield {\n+            const installer = this.installer;\n+            const manager = installer.manager;\n+            const lockfile = installer.lockfile;\n+\n+            const pkgs = installer.lockfile.packages.slice();\n+            const pkg_names = pkgs.items(.name);\n+            const pkg_name_hashes = pkgs.items(.name_hash);\n+            const pkg_resolutions = pkgs.items(.resolution);\n+            const pkg_bins = pkgs.items(.bin);\n+            const pkg_script_lists = pkgs.items(.scripts);\n+\n+            const entries = installer.store.entries.slice();\n+            const entry_node_ids = entries.items(.node_id);\n+            const entry_dependencies = entries.items(.dependencies);\n+            const entry_steps = entries.items(.step);\n+            const entry_scripts = entries.items(.scripts);\n+\n+            const nodes = installer.store.nodes.slice();\n+            const node_pkg_ids = nodes.items(.pkg_id);\n+            const node_dep_ids = nodes.items(.dep_id);\n+\n+            const node_id = entry_node_ids[this.entry_id.get()];\n+            const pkg_id = node_pkg_ids[node_id.get()];\n+            const dep_id = node_dep_ids[node_id.get()];\n+\n+            const pkg_name = pkg_names[pkg_id];\n+            const pkg_name_hash = pkg_name_hashes[pkg_id];\n+            const pkg_res = pkg_resolutions[pkg_id];\n+\n+            return next_step: switch (entry_steps[this.entry_id.get()].load(.monotonic)) {\n+                inline .link_package => |current_step| {\n+                    const string_buf = lockfile.buffers.string_bytes.items;\n+\n+                    if (pkg_res.tag == .folder) {\n+                        // the folder does not exist in the cache\n+                        const folder_dir = switch (bun.openDirForIteration(FD.cwd(), pkg_res.value.folder.slice(string_buf))) {\n+                            .result => |fd| fd,\n+                            .err => |err| return .failure(.{ .link_package = err }),\n+                        };\n+                        defer folder_dir.close();\n+\n+                        var src: bun.AbsPath(.{ .unit = .os, .sep = .auto }) = .initTopLevelDir();\n+                        defer src.deinit();\n+                        src.append(pkg_res.value.folder.slice(string_buf));\n+\n+                        var dest: bun.RelPath(.{ .unit = .os, .sep = .auto }) = .init();\n+                        defer dest.deinit();\n+\n+                        installer.appendStorePath(&dest, this.entry_id);\n+\n+                        var hardlinker: Hardlinker = .{\n+                            .src_dir = folder_dir,\n+                            .src = src,\n+                            .dest = dest,\n+                        };\n+\n+                        switch (try hardlinker.link(&.{comptime bun.OSPathLiteral(\"node_modules\")})) {\n+                            .result => {},\n+                            .err => |err| return .failure(.{ .link_package = err }),\n+                        }\n+\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const patch_info = try installer.packagePatchInfo(\n+                        pkg_name,\n+                        pkg_name_hash,\n+                        &pkg_res,\n+                    );\n+\n+                    var pkg_cache_dir_subpath: bun.RelPath(.{ .sep = .auto }) = .from(switch (pkg_res.tag) {\n+                        .npm => manager.cachedNPMPackageFolderName(pkg_name.slice(string_buf), pkg_res.value.npm.version, patch_info.contentsHash()),\n+                        .git => manager.cachedGitFolderName(&pkg_res.value.git, patch_info.contentsHash()),\n+                        .github => manager.cachedGitHubFolderName(&pkg_res.value.github, patch_info.contentsHash()),\n+                        .local_tarball => manager.cachedTarballFolderName(pkg_res.value.local_tarball, patch_info.contentsHash()),\n+                        .remote_tarball => manager.cachedTarballFolderName(pkg_res.value.remote_tarball, patch_info.contentsHash()),\n+\n+                        else => unreachable,\n+                    });\n+                    defer pkg_cache_dir_subpath.deinit();\n+\n+                    const cache_dir, const cache_dir_path = manager.getCacheDirectoryAndAbsPath();\n+                    defer cache_dir_path.deinit();\n+\n+                    var dest_subpath: bun.RelPath(.{ .sep = .auto, .unit = .os }) = .init();\n+                    defer dest_subpath.deinit();\n+\n+                    installer.appendStorePath(&dest_subpath, this.entry_id);\n+\n+                    // link the package\n+                    if (comptime Environment.isMac) {\n+                        if (install.PackageInstall.supported_method == .clonefile) hardlink_fallback: {\n+                            switch (sys.clonefileat(cache_dir, pkg_cache_dir_subpath.sliceZ(), FD.cwd(), dest_subpath.sliceZ())) {\n+                                .result => {\n+                                    // success! move to next step\n+                                    continue :next_step this.nextStep(current_step);\n+                                },\n+                                .err => |clonefile_err1| {\n+                                    switch (clonefile_err1.getErrno()) {\n+                                        .XDEV => break :hardlink_fallback,\n+                                        .OPNOTSUPP => break :hardlink_fallback,\n+                                        .NOENT => {\n+                                            const parent_dest_dir = std.fs.path.dirname(dest_subpath.slice()) orelse {\n+                                                return .failure(.{ .link_package = clonefile_err1 });\n+                                            };\n+\n+                                            FD.cwd().makePath(u8, parent_dest_dir) catch {};\n+\n+                                            switch (sys.clonefileat(cache_dir, pkg_cache_dir_subpath.sliceZ(), FD.cwd(), dest_subpath.sliceZ())) {\n+                                                .result => {\n+                                                    continue :next_step this.nextStep(current_step);\n+                                                },\n+                                                .err => |clonefile_err2| {\n+                                                    return .failure(.{ .link_package = clonefile_err2 });\n+                                                },\n+                                            }\n+                                        },\n+                                        else => {\n+                                            break :hardlink_fallback;\n+                                        },\n+                                    }\n+                                },\n+                            }\n+                        }\n+                    }\n+\n+                    const cached_package_dir = cached_package_dir: {\n+                        if (comptime Environment.isWindows) {\n+                            break :cached_package_dir switch (sys.openDirAtWindowsA(\n+                                cache_dir,\n+                                pkg_cache_dir_subpath.slice(),\n+                                .{ .iterable = true, .can_rename_or_delete = false, .read_only = true },\n+                            )) {\n+                                .result => |dir_fd| dir_fd,\n+                                .err => |err| {\n+                                    return .failure(.{ .link_package = err });\n+                                },\n+                            };\n+                        }\n+                        break :cached_package_dir switch (sys.openat(\n+                            cache_dir,\n+                            pkg_cache_dir_subpath.sliceZ(),\n+                            bun.O.DIRECTORY | bun.O.CLOEXEC | bun.O.RDONLY,\n+                            0,\n+                        )) {\n+                            .result => |fd| fd,\n+                            .err => |err| {\n+                                return .failure(.{ .link_package = err });\n+                            },\n+                        };\n+                    };\n+                    defer cached_package_dir.close();\n+\n+                    var src: bun.AbsPath(.{ .sep = .auto, .unit = .os }) = .from(cache_dir_path.slice());\n+                    defer src.deinit();\n+                    src.append(pkg_cache_dir_subpath.slice());\n+\n+                    var hardlinker: Hardlinker = .{\n+                        .src_dir = cached_package_dir,\n+                        .src = src,\n+                        .dest = dest_subpath,\n+                    };\n+\n+                    switch (try hardlinker.link(&.{})) {\n+                        .result => {},\n+                        .err => |err| return .failure(.{ .link_package = err }),\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .symlink_dependencies => |current_step| {\n+                    const string_buf = lockfile.buffers.string_bytes.items;\n+                    const dependencies = lockfile.buffers.dependencies.items;\n+\n+                    for (entry_dependencies[this.entry_id.get()].slice()) |dep| {\n+                        const dep_node_id = entry_node_ids[dep.entry_id.get()];\n+                        const dep_dep_id = node_dep_ids[dep_node_id.get()];\n+                        const dep_name = dependencies[dep_dep_id].name;\n+\n+                        var dest: bun.Path(.{ .sep = .auto }) = .initTopLevelDir();\n+                        defer dest.deinit();\n+\n+                        installer.appendStoreNodeModulesPath(&dest, this.entry_id);\n+                        dest.append(dep_name.slice(string_buf));\n+\n+                        var dep_store_path: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                        defer dep_store_path.deinit();\n+\n+                        installer.appendStorePath(&dep_store_path, dep.entry_id);\n+\n+                        const target = target: {\n+                            var dest_save = dest.save();\n+                            defer dest_save.restore();\n+\n+                            dest.undo(1);\n+                            break :target dest.relative(&dep_store_path);\n+                        };\n+                        defer target.deinit();\n+\n+                        const symlinker: Symlinker = .{\n+                            .dest = dest,\n+                            .target = target,\n+                            .fallback_junction_target = dep_store_path,\n+                        };\n+\n+                        const link_strategy: Symlinker.Strategy = if (pkg_res.tag == .root or pkg_res.tag == .workspace)\n+                            // root and workspace packages ensure their dependency symlinks\n+                            // exist unconditionally. To make sure it's fast, first readlink\n+                            // then create the symlink if necessary\n+                            .expect_existing\n+                        else\n+                            .expect_missing;\n+\n+                        switch (symlinker.ensureSymlink(link_strategy)) {\n+                            .result => {},\n+                            .err => |err| {\n+                                return .failure(.{ .symlink_dependencies = err });\n+                            },\n+                        }\n+                    }\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .check_if_blocked => |current_step| {\n+                    // preinstall scripts need to run before binaries can be linked. Block here if any dependencies\n+                    // of this entry are not finished. Do not count cycles towards blocking.\n+\n+                    var parent_dedupe: std.AutoArrayHashMap(Store.Entry.Id, void) = .init(bun.default_allocator);\n+                    defer parent_dedupe.deinit();\n+\n+                    const deps = entry_dependencies[this.entry_id.get()];\n+                    for (deps.slice()) |dep| {\n+                        if (entry_steps[dep.entry_id.get()].load(.monotonic) != .done) {\n+                            if (installer.store.isCycle(this.entry_id, dep.entry_id, &parent_dedupe)) {\n+                                parent_dedupe.clearRetainingCapacity();\n+                                continue;\n+                            }\n+\n+                            entry_steps[this.entry_id.get()].store(.blocked, .monotonic);\n+                            return .yield;\n+                        }\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .symlink_dependency_binaries => |current_step| {\n+                    installer.linkDependencyBins(this.entry_id) catch |err| {\n+                        return .failure(.{ .binaries = err });\n+                    };\n+\n+                    switch (pkg_res.tag) {\n+                        .uninitialized,\n+                        .root,\n+                        .workspace,\n+                        .folder,\n+                        .symlink,\n+                        .single_file_module,\n+                        => {},\n+\n+                        _ => {},\n+\n+                        .npm,\n+                        .git,\n+                        .github,\n+                        .local_tarball,\n+                        .remote_tarball,\n+                        => {\n+                            const string_buf = lockfile.buffers.string_bytes.items;\n+\n+                            var hidden_hoisted_node_modules: bun.Path(.{ .sep = .auto }) = .init();\n+                            defer hidden_hoisted_node_modules.deinit();\n+\n+                            hidden_hoisted_node_modules.append(\n+                                \"node_modules\" ++ std.fs.path.sep_str ++ \".bun\" ++ std.fs.path.sep_str ++ \"node_modules\",\n+                            );\n+                            hidden_hoisted_node_modules.append(pkg_name.slice(installer.lockfile.buffers.string_bytes.items));\n+\n+                            var target: bun.RelPath(.{ .sep = .auto }) = .init();\n+                            defer target.deinit();\n+\n+                            target.append(\"..\");\n+                            if (strings.containsChar(pkg_name.slice(installer.lockfile.buffers.string_bytes.items), '/')) {\n+                                target.append(\"..\");\n+                            }\n+\n+                            target.appendFmt(\"{}/node_modules/{s}\", .{\n+                                Store.Entry.fmtStorePath(this.entry_id, installer.store, installer.lockfile),\n+                                pkg_name.slice(string_buf),\n+                            });\n+\n+                            var full_target: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                            defer full_target.deinit();\n+\n+                            installer.appendStorePath(&full_target, this.entry_id);\n+\n+                            const symlinker: Symlinker = .{\n+                                .dest = hidden_hoisted_node_modules,\n+                                .target = target,\n+                                .fallback_junction_target = full_target,\n+                            };\n+                            _ = symlinker.ensureSymlink(.ignore_failure);\n+                        },\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .run_preinstall => |current_step| {\n+                    if (!installer.manager.options.do.run_scripts or this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const string_buf = installer.lockfile.buffers.string_bytes.items;\n+\n+                    const dep = installer.lockfile.buffers.dependencies.items[dep_id];\n+                    const truncated_dep_name_hash: TruncatedPackageNameHash = @truncate(dep.name_hash);\n+\n+                    const is_trusted, const is_trusted_through_update_request = brk: {\n+                        if (installer.trusted_dependencies_from_update_requests.contains(truncated_dep_name_hash)) {\n+                            break :brk .{ true, true };\n+                        }\n+                        if (installer.lockfile.hasTrustedDependency(dep.name.slice(string_buf))) {\n+                            break :brk .{ true, false };\n+                        }\n+                        break :brk .{ false, false };\n+                    };\n+\n+                    var pkg_cwd: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                    defer pkg_cwd.deinit();\n+\n+                    installer.appendStorePath(&pkg_cwd, this.entry_id);\n+\n+                    if (pkg_res.tag != .root and (pkg_res.tag == .workspace or is_trusted)) {\n+                        const pkg_scripts: *Package.Scripts = &pkg_script_lists[pkg_id];\n+\n+                        var log = bun.logger.Log.init(bun.default_allocator);\n+                        defer log.deinit();\n+\n+                        const scripts_list = pkg_scripts.getList(\n+                            &log,\n+                            installer.lockfile,\n+                            &pkg_cwd,\n+                            dep.name.slice(string_buf),\n+                            &pkg_res,\n+                        ) catch |err| {\n+                            return .failure(.{ .run_preinstall = err });\n+                        };\n+\n+                        if (scripts_list) |list| {\n+                            entry_scripts[this.entry_id.get()] = bun.create(bun.default_allocator, Package.Scripts.List, list);\n+\n+                            if (is_trusted_through_update_request) {\n+                                const trusted_dep_to_add = try installer.manager.allocator.dupe(u8, dep.name.slice(string_buf));\n+\n+                                installer.trusted_dependencies_mutex.lock();\n+                                defer installer.trusted_dependencies_mutex.unlock();\n+\n+                                try installer.manager.trusted_deps_to_add_to_package_json.append(\n+                                    installer.manager.allocator,\n+                                    trusted_dep_to_add,\n+                                );\n+                                if (installer.lockfile.trusted_dependencies == null) {\n+                                    installer.lockfile.trusted_dependencies = .{};\n+                                }\n+                                try installer.lockfile.trusted_dependencies.?.put(installer.manager.allocator, truncated_dep_name_hash, {});\n+                            }\n+\n+                            if (list.first_index != 0) {\n+                                // has scripts but not a preinstall\n+                                continue :next_step this.nextStep(current_step);\n+                            }\n+\n+                            installer.manager.spawnPackageLifecycleScripts(\n+                                installer.command_ctx,\n+                                list,\n+                                dep.behavior.optional,\n+                                false,\n+                                .{\n+                                    .entry_id = this.entry_id,\n+                                    .installer = installer,\n+                                },\n+                            ) catch |err| {\n+                                return .failure(.{ .run_preinstall = err });\n+                            };\n+\n+                            return .yield;\n+                        }\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .binaries => |current_step| {\n+                    if (this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const bin = pkg_bins[pkg_id];\n+                    if (bin.tag == .none) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const string_buf = installer.lockfile.buffers.string_bytes.items;\n+                    const dependencies = installer.lockfile.buffers.dependencies.items;\n+\n+                    const dep_name = dependencies[dep_id].name.slice(string_buf);\n+\n+                    var abs_target_buf: bun.PathBuffer = undefined;\n+                    var abs_dest_buf: bun.PathBuffer = undefined;\n+                    var rel_buf: bun.PathBuffer = undefined;\n+\n+                    var seen: bun.StringHashMap(void) = .init(bun.default_allocator);\n+                    defer seen.deinit();\n+\n+                    var node_modules_path: bun.AbsPath(.{}) = .initTopLevelDir();\n+                    defer node_modules_path.deinit();\n+\n+                    installer.appendStoreNodeModulesPath(&node_modules_path, this.entry_id);\n+\n+                    var bin_linker: Bin.Linker = .{\n+                        .bin = bin,\n+                        .global_bin_path = installer.manager.options.bin_path,\n+                        .package_name = strings.StringOrTinyString.init(dep_name),\n+                        .string_buf = string_buf,\n+                        .extern_string_buf = installer.lockfile.buffers.extern_strings.items,\n+                        .seen = &seen,\n+                        .node_modules_path = &node_modules_path,\n+                        .abs_target_buf = &abs_target_buf,\n+                        .abs_dest_buf = &abs_dest_buf,\n+                        .rel_buf = &rel_buf,\n+                    };\n+\n+                    bin_linker.link(false);\n+\n+                    if (bin_linker.err) |err| {\n+                        return .failure(.{ .binaries = err });\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .@\"run (post)install and (pre/post)prepare\" => |current_step| {\n+                    if (!installer.manager.options.do.run_scripts or this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    var list = entry_scripts[this.entry_id.get()] orelse {\n+                        continue :next_step this.nextStep(current_step);\n+                    };\n+\n+                    if (list.first_index == 0) {\n+                        for (list.items[1..], 1..) |item, i| {\n+                            if (item != null) {\n+                                list.first_index = @intCast(i);\n+                                break;\n+                            }\n+                        }\n+                    }\n+\n+                    if (list.first_index == 0) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const dep = installer.lockfile.buffers.dependencies.items[dep_id];\n+\n+                    installer.manager.spawnPackageLifecycleScripts(\n+                        installer.command_ctx,\n+                        list.*,\n+                        dep.behavior.optional,\n+                        false,\n+                        .{\n+                            .entry_id = this.entry_id,\n+                            .installer = installer,\n+                        },\n+                    ) catch |err| {\n+                        return .failure(.{ .@\"run (post)install and (pre/post)prepare\" = err });\n+                    };\n+\n+                    // when these scripts finish the package install will be\n+                    // complete. the task does not have anymore work to complete\n+                    // so it does not return to the thread pool.\n+\n+                    return .yield;\n+                },\n+\n+                .done => {\n+                    return .done;\n+                },\n+\n+                .blocked => {\n+                    bun.debugAssert(false);\n+                    return .yield;\n+                },\n+            };\n+        }\n+\n+        pub fn callback(task: *ThreadPool.Task) void {\n+            const this: *Task = @fieldParentPtr(\"task\", task);\n+\n+            const res = this.run() catch |err| switch (err) {\n+                error.OutOfMemory => bun.outOfMemory(),\n+            };\n+\n+            switch (res) {\n+                .yield => {},\n+                .done => {\n+                    this.installer.tasks.push(this);\n+                    this.installer.manager.wake();\n+                },\n+                .fail => |err| {\n+                    this.installer.store.entries.items(.step)[this.entry_id.get()].store(.done, .monotonic);\n+                    this.err = err.clone(bun.default_allocator);\n+                    this.installer.tasks.push(this);\n+                    this.installer.manager.wake();\n+                },\n+            }\n+        }\n+    };\n+\n+    const PatchInfo = union(enum) {\n+        none,\n+        remove: struct {\n+            name_and_version_hash: u64,\n+        },\n+        patch: struct {\n+            name_and_version_hash: u64,\n+            patch_path: string,\n+            contents_hash: u64,\n+        },\n+\n+        pub fn contentsHash(this: *const @This()) ?u64 {\n+            return switch (this.*) {\n+                .none, .remove => null,\n+                .patch => |patch| patch.contents_hash,\n+            };\n+        }\n+\n+        pub fn nameAndVersionHash(this: *const @This()) ?u64 {\n+            return switch (this.*) {\n+                .none, .remove => null,\n+                .patch => |patch| patch.name_and_version_hash,\n+            };\n+        }\n+    };\n+\n+    pub fn packagePatchInfo(\n+        this: *Installer,\n+        pkg_name: String,\n+        pkg_name_hash: PackageNameHash,\n+        pkg_res: *const Resolution,\n+    ) OOM!PatchInfo {\n+        if (this.lockfile.patched_dependencies.entries.len == 0 and this.manager.patched_dependencies_to_remove.entries.len == 0) {\n+            return .none;\n+        }\n+\n+        const string_buf = this.lockfile.buffers.string_bytes.items;\n+\n+        var version_buf: std.ArrayListUnmanaged(u8) = .empty;\n+        defer version_buf.deinit(bun.default_allocator);\n+\n+        var writer = version_buf.writer(this.lockfile.allocator);\n+        try writer.print(\"{s}@\", .{pkg_name.slice(string_buf)});\n+\n+        switch (pkg_res.tag) {\n+            .workspace => {\n+                if (this.lockfile.workspace_versions.get(pkg_name_hash)) |workspace_version| {\n+                    try writer.print(\"{}\", .{workspace_version.fmt(string_buf)});\n+                }\n+            },\n+            else => {\n+                try writer.print(\"{}\", .{pkg_res.fmt(string_buf, .posix)});\n+            },\n+        }\n+\n+        const name_and_version_hash = String.Builder.stringHash(version_buf.items);\n+\n+        if (this.lockfile.patched_dependencies.get(name_and_version_hash)) |patch| {\n+            return .{\n+                .patch = .{\n+                    .name_and_version_hash = name_and_version_hash,\n+                    .patch_path = patch.path.slice(string_buf),\n+                    .contents_hash = patch.patchfileHash().?,\n+                },\n+            };\n+        }\n+\n+        if (this.manager.patched_dependencies_to_remove.contains(name_and_version_hash)) {\n+            return .{\n+                .remove = .{\n+                    .name_and_version_hash = name_and_version_hash,\n+                },\n+            };\n+        }\n+\n+        return .none;\n+    }\n+\n+    pub fn linkDependencyBins(this: *const Installer, parent_entry_id: Store.Entry.Id) !void {\n+        const lockfile = this.lockfile;\n+        const store = this.store;\n+\n+        const string_buf = lockfile.buffers.string_bytes.items;\n+        const extern_string_buf = lockfile.buffers.extern_strings.items;\n+\n+        const entries = store.entries.slice();\n+        const entry_node_ids = entries.items(.node_id);\n+        const entry_deps = entries.items(.dependencies);\n+\n+        const nodes = store.nodes.slice();\n+        const node_pkg_ids = nodes.items(.pkg_id);\n+        const node_dep_ids = nodes.items(.dep_id);\n+\n+        const pkgs = lockfile.packages.slice();\n+        const pkg_bins = pkgs.items(.bin);\n+\n+        var link_target_buf: bun.PathBuffer = undefined;\n+        var link_dest_buf: bun.PathBuffer = undefined;\n+        var link_rel_buf: bun.PathBuffer = undefined;",
    "repo_full_name": "oven-sh/bun",
    "discussion_comments": [
      {
        "comment_id": "2191504855",
        "repo_full_name": "oven-sh/bun",
        "pr_number": 20440,
        "pr_file": "src/install/isolated_install/Installer.zig",
        "discussion_id": "2191504855",
        "commented_code": "@@ -0,0 +1,1074 @@\n+pub const Installer = struct {\n+    trusted_dependencies_mutex: bun.Mutex,\n+    // this is not const for `lockfile.trusted_dependencies`\n+    lockfile: *Lockfile,\n+\n+    summary: PackageInstall.Summary = .{ .successfully_installed = .empty },\n+    installed: Bitset,\n+    install_node: ?*Progress.Node,\n+    scripts_node: ?*Progress.Node,\n+\n+    manager: *PackageManager,\n+    command_ctx: Command.Context,\n+\n+    store: *const Store,\n+\n+    tasks: bun.UnboundedQueue(Task, .next) = .{},\n+    preallocated_tasks: Task.Preallocated,\n+\n+    trusted_dependencies_from_update_requests: std.AutoArrayHashMapUnmanaged(TruncatedPackageNameHash, void),\n+\n+    pub fn deinit(this: *const Installer) void {\n+        this.trusted_dependencies_from_update_requests.deinit(this.lockfile.allocator);\n+    }\n+\n+    pub fn resumeTask(this: *Installer, entry_id: Store.Entry.Id) void {\n+        const task = this.preallocated_tasks.get();\n+\n+        task.* = .{\n+            .entry_id = entry_id,\n+            .installer = this,\n+            .err = null,\n+        };\n+\n+        this.manager.thread_pool.schedule(.from(&task.task));\n+    }\n+\n+    pub fn onPackageExtracted(this: *Installer, task_id: install.Task.Id) void {\n+        if (this.manager.task_queue.fetchRemove(task_id)) |removed| {\n+            for (removed.value.items) |install_ctx| {\n+                const entry_id = install_ctx.isolated_package_install_context;\n+                this.resumeTask(entry_id);\n+            }\n+        }\n+    }\n+\n+    pub fn onTaskFail(this: *Installer, entry_id: Store.Entry.Id, err: Task.Error) void {\n+        const string_buf = this.lockfile.buffers.string_bytes.items;\n+\n+        const entries = this.store.entries.slice();\n+        const entry_node_ids = entries.items(.node_id);\n+\n+        const nodes = this.store.nodes.slice();\n+        const node_pkg_ids = nodes.items(.pkg_id);\n+\n+        const pkgs = this.lockfile.packages.slice();\n+        const pkg_names = pkgs.items(.name);\n+        const pkg_resolutions = pkgs.items(.resolution);\n+\n+        const node_id = entry_node_ids[entry_id.get()];\n+        const pkg_id = node_pkg_ids[node_id.get()];\n+\n+        const pkg_name = pkg_names[pkg_id];\n+        const pkg_res = pkg_resolutions[pkg_id];\n+\n+        switch (err) {\n+            .link_package => |link_err| {\n+                Output.err(link_err, \"failed to link package: {s}@{}\", .{\n+                    pkg_name.slice(string_buf),\n+                    pkg_res.fmt(string_buf, .auto),\n+                });\n+            },\n+            .symlink_dependencies => |symlink_err| {\n+                Output.err(symlink_err, \"failed to symlink dependencies for package: {s}@{}\", .{\n+                    pkg_name.slice(string_buf),\n+                    pkg_res.fmt(string_buf, .auto),\n+                });\n+            },\n+            else => {},\n+        }\n+        Output.flush();\n+\n+        // attempt deleting the package so the next install will install it again\n+        switch (pkg_res.tag) {\n+            .uninitialized,\n+            .single_file_module,\n+            .root,\n+            .workspace,\n+            .symlink,\n+            => {},\n+\n+            _ => {},\n+\n+            // to be safe make sure we only delete packages in the store\n+            .npm,\n+            .git,\n+            .github,\n+            .local_tarball,\n+            .remote_tarball,\n+            .folder,\n+            => {\n+                var store_path: bun.RelPath(.{ .sep = .auto }) = .init();\n+                defer store_path.deinit();\n+\n+                store_path.appendFmt(\"node_modules/{}\", .{\n+                    Store.Entry.fmtStorePath(entry_id, this.store, this.lockfile),\n+                });\n+\n+                _ = sys.unlink(store_path.sliceZ());\n+            },\n+        }\n+\n+        if (this.manager.options.enable.fail_early) {\n+            Global.exit(1);\n+        }\n+\n+        this.summary.fail += 1;\n+\n+        this.decrementPendingTasks(entry_id);\n+        this.resumeAvailableTasks();\n+    }\n+\n+    pub fn onTask(this: *Installer, task_entry_id: Store.Entry.Id) void {\n+        const entries = this.store.entries.slice();\n+        const entry_steps = entries.items(.step);\n+        const step = entry_steps[task_entry_id.get()].load(.monotonic);\n+\n+        if (step != .done) {\n+            // only done will unblock other packages\n+            return;\n+        }\n+\n+        this.onTaskSuccess(task_entry_id);\n+    }\n+\n+    pub fn decrementPendingTasks(this: *Installer, entry_id: Store.Entry.Id) void {\n+        _ = entry_id;\n+        this.manager.decrementPendingTasks();\n+    }\n+\n+    pub fn onTaskSkipped(this: *Installer, entry_id: Store.Entry.Id) void {\n+        this.summary.skipped += 1;\n+        this.decrementPendingTasks(entry_id);\n+        this.store.entries.items(.step)[entry_id.get()].store(.done, .monotonic);\n+        if (this.install_node) |node| {\n+            node.completeOne();\n+        }\n+        this.resumeAvailableTasks();\n+    }\n+\n+    pub fn onTaskSuccess(this: *Installer, entry_id: Store.Entry.Id) void {\n+        this.decrementPendingTasks(entry_id);\n+        this.resumeAvailableTasks();\n+\n+        const pkg_id = pkg_id: {\n+            if (entry_id == .root) {\n+                return;\n+            }\n+\n+            const node_id = this.store.entries.items(.node_id)[entry_id.get()];\n+            const nodes = this.store.nodes.slice();\n+\n+            const dep_id = nodes.items(.dep_id)[node_id.get()];\n+\n+            if (dep_id == invalid_dependency_id) {\n+                // should be coverd by `entry_id == .root` above, but\n+                // just in case\n+                return;\n+            }\n+\n+            const dep = this.lockfile.buffers.dependencies.items[dep_id];\n+\n+            if (dep.behavior.isWorkspaceOnly()) {\n+                return;\n+            }\n+\n+            break :pkg_id nodes.items(.pkg_id)[node_id.get()];\n+        };\n+\n+        const is_duplicate = this.installed.isSet(pkg_id);\n+        this.summary.success += @intFromBool(!is_duplicate);\n+        this.installed.set(pkg_id);\n+        if (this.install_node) |node| {\n+            node.completeOne();\n+        }\n+    }\n+\n+    pub fn resumeAvailableTasks(this: *Installer) void {\n+        const entries = this.store.entries.slice();\n+        const entry_deps = entries.items(.dependencies);\n+        const entry_steps = entries.items(.step);\n+\n+        var parent_dedupe: std.AutoArrayHashMap(Store.Entry.Id, void) = .init(bun.default_allocator);\n+        defer parent_dedupe.deinit();\n+\n+        next_entry: for (0..this.store.entries.len) |_entry_id| {\n+            const entry_id: Store.Entry.Id = .from(@intCast(_entry_id));\n+\n+            const entry_step = entry_steps[entry_id.get()].load(.monotonic);\n+            if (entry_step != .blocked) {\n+                continue;\n+            }\n+\n+            const deps = entry_deps[entry_id.get()];\n+            for (deps.slice()) |dep| {\n+                switch (entry_steps[dep.entry_id.get()].load(.monotonic)) {\n+                    .done => {},\n+                    else => {\n+                        parent_dedupe.clearRetainingCapacity();\n+                        if (!this.store.isCycle(entry_id, dep.entry_id, &parent_dedupe)) {\n+                            continue :next_entry;\n+                        }\n+                    },\n+                }\n+            }\n+\n+            entry_steps[entry_id.get()].store(.symlink_dependency_binaries, .monotonic);\n+            this.resumeTask(entry_id);\n+        }\n+    }\n+\n+    pub const Task = struct {\n+        const Preallocated = bun.HiveArray(Task, 128).Fallback;\n+\n+        entry_id: Store.Entry.Id,\n+        installer: *Installer,\n+\n+        task: ThreadPool.Task = .{ .callback = &callback },\n+        next: ?*Task = null,\n+\n+        err: ?Error,\n+\n+        const Error = union(Step) {\n+            link_package: sys.Error,\n+            symlink_dependencies: sys.Error,\n+            check_if_blocked,\n+            symlink_dependency_binaries,\n+            run_preinstall: anyerror,\n+            binaries: anyerror,\n+            @\"run (post)install and (pre/post)prepare\": anyerror,\n+            done,\n+            blocked,\n+\n+            pub fn clone(this: *const Error, allocator: std.mem.Allocator) Error {\n+                return switch (this.*) {\n+                    .link_package => |err| .{ .link_package = err.clone(allocator) },\n+                    .symlink_dependencies => |err| .{ .symlink_dependencies = err.clone(allocator) },\n+                    .check_if_blocked => .check_if_blocked,\n+                    .symlink_dependency_binaries => .symlink_dependency_binaries,\n+                    .run_preinstall => |err| .{ .run_preinstall = err },\n+                    .binaries => |err| .{ .binaries = err },\n+                    .@\"run (post)install and (pre/post)prepare\" => |err| .{ .@\"run (post)install and (pre/post)prepare\" = err },\n+                    .done => .done,\n+                    .blocked => .blocked,\n+                };\n+            }\n+        };\n+\n+        pub const Step = enum(u8) {\n+            link_package,\n+            symlink_dependencies,\n+\n+            check_if_blocked,\n+\n+            // blocked can only happen here\n+\n+            symlink_dependency_binaries,\n+            run_preinstall,\n+\n+            // pause here while preinstall runs\n+\n+            binaries,\n+            @\"run (post)install and (pre/post)prepare\",\n+\n+            // pause again while remaining scripts run.\n+\n+            done,\n+            blocked,\n+        };\n+\n+        fn nextStep(this: *Task, comptime current_step: Step) Step {\n+            const next_step: Step = switch (comptime current_step) {\n+                .link_package => .symlink_dependencies,\n+                .symlink_dependencies => .check_if_blocked,\n+                .check_if_blocked => .symlink_dependency_binaries,\n+                .symlink_dependency_binaries => .run_preinstall,\n+                .run_preinstall => .binaries,\n+                .binaries => .@\"run (post)install and (pre/post)prepare\",\n+                .@\"run (post)install and (pre/post)prepare\" => .done,\n+\n+                .done,\n+                .blocked,\n+                => @compileError(\"unexpected step\"),\n+            };\n+\n+            this.installer.store.entries.items(.step)[this.entry_id.get()].store(next_step, .monotonic);\n+\n+            return next_step;\n+        }\n+\n+        const Yield = union(enum) {\n+            yield,\n+            done,\n+            fail: Error,\n+\n+            pub fn failure(e: Error) Yield {\n+                return .{ .fail = e };\n+            }\n+        };\n+\n+        fn run(this: *Task) OOM!Yield {\n+            const installer = this.installer;\n+            const manager = installer.manager;\n+            const lockfile = installer.lockfile;\n+\n+            const pkgs = installer.lockfile.packages.slice();\n+            const pkg_names = pkgs.items(.name);\n+            const pkg_name_hashes = pkgs.items(.name_hash);\n+            const pkg_resolutions = pkgs.items(.resolution);\n+            const pkg_bins = pkgs.items(.bin);\n+            const pkg_script_lists = pkgs.items(.scripts);\n+\n+            const entries = installer.store.entries.slice();\n+            const entry_node_ids = entries.items(.node_id);\n+            const entry_dependencies = entries.items(.dependencies);\n+            const entry_steps = entries.items(.step);\n+            const entry_scripts = entries.items(.scripts);\n+\n+            const nodes = installer.store.nodes.slice();\n+            const node_pkg_ids = nodes.items(.pkg_id);\n+            const node_dep_ids = nodes.items(.dep_id);\n+\n+            const node_id = entry_node_ids[this.entry_id.get()];\n+            const pkg_id = node_pkg_ids[node_id.get()];\n+            const dep_id = node_dep_ids[node_id.get()];\n+\n+            const pkg_name = pkg_names[pkg_id];\n+            const pkg_name_hash = pkg_name_hashes[pkg_id];\n+            const pkg_res = pkg_resolutions[pkg_id];\n+\n+            return next_step: switch (entry_steps[this.entry_id.get()].load(.monotonic)) {\n+                inline .link_package => |current_step| {\n+                    const string_buf = lockfile.buffers.string_bytes.items;\n+\n+                    if (pkg_res.tag == .folder) {\n+                        // the folder does not exist in the cache\n+                        const folder_dir = switch (bun.openDirForIteration(FD.cwd(), pkg_res.value.folder.slice(string_buf))) {\n+                            .result => |fd| fd,\n+                            .err => |err| return .failure(.{ .link_package = err }),\n+                        };\n+                        defer folder_dir.close();\n+\n+                        var src: bun.AbsPath(.{ .unit = .os, .sep = .auto }) = .initTopLevelDir();\n+                        defer src.deinit();\n+                        src.append(pkg_res.value.folder.slice(string_buf));\n+\n+                        var dest: bun.RelPath(.{ .unit = .os, .sep = .auto }) = .init();\n+                        defer dest.deinit();\n+\n+                        installer.appendStorePath(&dest, this.entry_id);\n+\n+                        var hardlinker: Hardlinker = .{\n+                            .src_dir = folder_dir,\n+                            .src = src,\n+                            .dest = dest,\n+                        };\n+\n+                        switch (try hardlinker.link(&.{comptime bun.OSPathLiteral(\"node_modules\")})) {\n+                            .result => {},\n+                            .err => |err| return .failure(.{ .link_package = err }),\n+                        }\n+\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const patch_info = try installer.packagePatchInfo(\n+                        pkg_name,\n+                        pkg_name_hash,\n+                        &pkg_res,\n+                    );\n+\n+                    var pkg_cache_dir_subpath: bun.RelPath(.{ .sep = .auto }) = .from(switch (pkg_res.tag) {\n+                        .npm => manager.cachedNPMPackageFolderName(pkg_name.slice(string_buf), pkg_res.value.npm.version, patch_info.contentsHash()),\n+                        .git => manager.cachedGitFolderName(&pkg_res.value.git, patch_info.contentsHash()),\n+                        .github => manager.cachedGitHubFolderName(&pkg_res.value.github, patch_info.contentsHash()),\n+                        .local_tarball => manager.cachedTarballFolderName(pkg_res.value.local_tarball, patch_info.contentsHash()),\n+                        .remote_tarball => manager.cachedTarballFolderName(pkg_res.value.remote_tarball, patch_info.contentsHash()),\n+\n+                        else => unreachable,\n+                    });\n+                    defer pkg_cache_dir_subpath.deinit();\n+\n+                    const cache_dir, const cache_dir_path = manager.getCacheDirectoryAndAbsPath();\n+                    defer cache_dir_path.deinit();\n+\n+                    var dest_subpath: bun.RelPath(.{ .sep = .auto, .unit = .os }) = .init();\n+                    defer dest_subpath.deinit();\n+\n+                    installer.appendStorePath(&dest_subpath, this.entry_id);\n+\n+                    // link the package\n+                    if (comptime Environment.isMac) {\n+                        if (install.PackageInstall.supported_method == .clonefile) hardlink_fallback: {\n+                            switch (sys.clonefileat(cache_dir, pkg_cache_dir_subpath.sliceZ(), FD.cwd(), dest_subpath.sliceZ())) {\n+                                .result => {\n+                                    // success! move to next step\n+                                    continue :next_step this.nextStep(current_step);\n+                                },\n+                                .err => |clonefile_err1| {\n+                                    switch (clonefile_err1.getErrno()) {\n+                                        .XDEV => break :hardlink_fallback,\n+                                        .OPNOTSUPP => break :hardlink_fallback,\n+                                        .NOENT => {\n+                                            const parent_dest_dir = std.fs.path.dirname(dest_subpath.slice()) orelse {\n+                                                return .failure(.{ .link_package = clonefile_err1 });\n+                                            };\n+\n+                                            FD.cwd().makePath(u8, parent_dest_dir) catch {};\n+\n+                                            switch (sys.clonefileat(cache_dir, pkg_cache_dir_subpath.sliceZ(), FD.cwd(), dest_subpath.sliceZ())) {\n+                                                .result => {\n+                                                    continue :next_step this.nextStep(current_step);\n+                                                },\n+                                                .err => |clonefile_err2| {\n+                                                    return .failure(.{ .link_package = clonefile_err2 });\n+                                                },\n+                                            }\n+                                        },\n+                                        else => {\n+                                            break :hardlink_fallback;\n+                                        },\n+                                    }\n+                                },\n+                            }\n+                        }\n+                    }\n+\n+                    const cached_package_dir = cached_package_dir: {\n+                        if (comptime Environment.isWindows) {\n+                            break :cached_package_dir switch (sys.openDirAtWindowsA(\n+                                cache_dir,\n+                                pkg_cache_dir_subpath.slice(),\n+                                .{ .iterable = true, .can_rename_or_delete = false, .read_only = true },\n+                            )) {\n+                                .result => |dir_fd| dir_fd,\n+                                .err => |err| {\n+                                    return .failure(.{ .link_package = err });\n+                                },\n+                            };\n+                        }\n+                        break :cached_package_dir switch (sys.openat(\n+                            cache_dir,\n+                            pkg_cache_dir_subpath.sliceZ(),\n+                            bun.O.DIRECTORY | bun.O.CLOEXEC | bun.O.RDONLY,\n+                            0,\n+                        )) {\n+                            .result => |fd| fd,\n+                            .err => |err| {\n+                                return .failure(.{ .link_package = err });\n+                            },\n+                        };\n+                    };\n+                    defer cached_package_dir.close();\n+\n+                    var src: bun.AbsPath(.{ .sep = .auto, .unit = .os }) = .from(cache_dir_path.slice());\n+                    defer src.deinit();\n+                    src.append(pkg_cache_dir_subpath.slice());\n+\n+                    var hardlinker: Hardlinker = .{\n+                        .src_dir = cached_package_dir,\n+                        .src = src,\n+                        .dest = dest_subpath,\n+                    };\n+\n+                    switch (try hardlinker.link(&.{})) {\n+                        .result => {},\n+                        .err => |err| return .failure(.{ .link_package = err }),\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .symlink_dependencies => |current_step| {\n+                    const string_buf = lockfile.buffers.string_bytes.items;\n+                    const dependencies = lockfile.buffers.dependencies.items;\n+\n+                    for (entry_dependencies[this.entry_id.get()].slice()) |dep| {\n+                        const dep_node_id = entry_node_ids[dep.entry_id.get()];\n+                        const dep_dep_id = node_dep_ids[dep_node_id.get()];\n+                        const dep_name = dependencies[dep_dep_id].name;\n+\n+                        var dest: bun.Path(.{ .sep = .auto }) = .initTopLevelDir();\n+                        defer dest.deinit();\n+\n+                        installer.appendStoreNodeModulesPath(&dest, this.entry_id);\n+                        dest.append(dep_name.slice(string_buf));\n+\n+                        var dep_store_path: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                        defer dep_store_path.deinit();\n+\n+                        installer.appendStorePath(&dep_store_path, dep.entry_id);\n+\n+                        const target = target: {\n+                            var dest_save = dest.save();\n+                            defer dest_save.restore();\n+\n+                            dest.undo(1);\n+                            break :target dest.relative(&dep_store_path);\n+                        };\n+                        defer target.deinit();\n+\n+                        const symlinker: Symlinker = .{\n+                            .dest = dest,\n+                            .target = target,\n+                            .fallback_junction_target = dep_store_path,\n+                        };\n+\n+                        const link_strategy: Symlinker.Strategy = if (pkg_res.tag == .root or pkg_res.tag == .workspace)\n+                            // root and workspace packages ensure their dependency symlinks\n+                            // exist unconditionally. To make sure it's fast, first readlink\n+                            // then create the symlink if necessary\n+                            .expect_existing\n+                        else\n+                            .expect_missing;\n+\n+                        switch (symlinker.ensureSymlink(link_strategy)) {\n+                            .result => {},\n+                            .err => |err| {\n+                                return .failure(.{ .symlink_dependencies = err });\n+                            },\n+                        }\n+                    }\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .check_if_blocked => |current_step| {\n+                    // preinstall scripts need to run before binaries can be linked. Block here if any dependencies\n+                    // of this entry are not finished. Do not count cycles towards blocking.\n+\n+                    var parent_dedupe: std.AutoArrayHashMap(Store.Entry.Id, void) = .init(bun.default_allocator);\n+                    defer parent_dedupe.deinit();\n+\n+                    const deps = entry_dependencies[this.entry_id.get()];\n+                    for (deps.slice()) |dep| {\n+                        if (entry_steps[dep.entry_id.get()].load(.monotonic) != .done) {\n+                            if (installer.store.isCycle(this.entry_id, dep.entry_id, &parent_dedupe)) {\n+                                parent_dedupe.clearRetainingCapacity();\n+                                continue;\n+                            }\n+\n+                            entry_steps[this.entry_id.get()].store(.blocked, .monotonic);\n+                            return .yield;\n+                        }\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .symlink_dependency_binaries => |current_step| {\n+                    installer.linkDependencyBins(this.entry_id) catch |err| {\n+                        return .failure(.{ .binaries = err });\n+                    };\n+\n+                    switch (pkg_res.tag) {\n+                        .uninitialized,\n+                        .root,\n+                        .workspace,\n+                        .folder,\n+                        .symlink,\n+                        .single_file_module,\n+                        => {},\n+\n+                        _ => {},\n+\n+                        .npm,\n+                        .git,\n+                        .github,\n+                        .local_tarball,\n+                        .remote_tarball,\n+                        => {\n+                            const string_buf = lockfile.buffers.string_bytes.items;\n+\n+                            var hidden_hoisted_node_modules: bun.Path(.{ .sep = .auto }) = .init();\n+                            defer hidden_hoisted_node_modules.deinit();\n+\n+                            hidden_hoisted_node_modules.append(\n+                                \"node_modules\" ++ std.fs.path.sep_str ++ \".bun\" ++ std.fs.path.sep_str ++ \"node_modules\",\n+                            );\n+                            hidden_hoisted_node_modules.append(pkg_name.slice(installer.lockfile.buffers.string_bytes.items));\n+\n+                            var target: bun.RelPath(.{ .sep = .auto }) = .init();\n+                            defer target.deinit();\n+\n+                            target.append(\"..\");\n+                            if (strings.containsChar(pkg_name.slice(installer.lockfile.buffers.string_bytes.items), '/')) {\n+                                target.append(\"..\");\n+                            }\n+\n+                            target.appendFmt(\"{}/node_modules/{s}\", .{\n+                                Store.Entry.fmtStorePath(this.entry_id, installer.store, installer.lockfile),\n+                                pkg_name.slice(string_buf),\n+                            });\n+\n+                            var full_target: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                            defer full_target.deinit();\n+\n+                            installer.appendStorePath(&full_target, this.entry_id);\n+\n+                            const symlinker: Symlinker = .{\n+                                .dest = hidden_hoisted_node_modules,\n+                                .target = target,\n+                                .fallback_junction_target = full_target,\n+                            };\n+                            _ = symlinker.ensureSymlink(.ignore_failure);\n+                        },\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .run_preinstall => |current_step| {\n+                    if (!installer.manager.options.do.run_scripts or this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const string_buf = installer.lockfile.buffers.string_bytes.items;\n+\n+                    const dep = installer.lockfile.buffers.dependencies.items[dep_id];\n+                    const truncated_dep_name_hash: TruncatedPackageNameHash = @truncate(dep.name_hash);\n+\n+                    const is_trusted, const is_trusted_through_update_request = brk: {\n+                        if (installer.trusted_dependencies_from_update_requests.contains(truncated_dep_name_hash)) {\n+                            break :brk .{ true, true };\n+                        }\n+                        if (installer.lockfile.hasTrustedDependency(dep.name.slice(string_buf))) {\n+                            break :brk .{ true, false };\n+                        }\n+                        break :brk .{ false, false };\n+                    };\n+\n+                    var pkg_cwd: bun.AbsPath(.{ .sep = .auto }) = .initTopLevelDir();\n+                    defer pkg_cwd.deinit();\n+\n+                    installer.appendStorePath(&pkg_cwd, this.entry_id);\n+\n+                    if (pkg_res.tag != .root and (pkg_res.tag == .workspace or is_trusted)) {\n+                        const pkg_scripts: *Package.Scripts = &pkg_script_lists[pkg_id];\n+\n+                        var log = bun.logger.Log.init(bun.default_allocator);\n+                        defer log.deinit();\n+\n+                        const scripts_list = pkg_scripts.getList(\n+                            &log,\n+                            installer.lockfile,\n+                            &pkg_cwd,\n+                            dep.name.slice(string_buf),\n+                            &pkg_res,\n+                        ) catch |err| {\n+                            return .failure(.{ .run_preinstall = err });\n+                        };\n+\n+                        if (scripts_list) |list| {\n+                            entry_scripts[this.entry_id.get()] = bun.create(bun.default_allocator, Package.Scripts.List, list);\n+\n+                            if (is_trusted_through_update_request) {\n+                                const trusted_dep_to_add = try installer.manager.allocator.dupe(u8, dep.name.slice(string_buf));\n+\n+                                installer.trusted_dependencies_mutex.lock();\n+                                defer installer.trusted_dependencies_mutex.unlock();\n+\n+                                try installer.manager.trusted_deps_to_add_to_package_json.append(\n+                                    installer.manager.allocator,\n+                                    trusted_dep_to_add,\n+                                );\n+                                if (installer.lockfile.trusted_dependencies == null) {\n+                                    installer.lockfile.trusted_dependencies = .{};\n+                                }\n+                                try installer.lockfile.trusted_dependencies.?.put(installer.manager.allocator, truncated_dep_name_hash, {});\n+                            }\n+\n+                            if (list.first_index != 0) {\n+                                // has scripts but not a preinstall\n+                                continue :next_step this.nextStep(current_step);\n+                            }\n+\n+                            installer.manager.spawnPackageLifecycleScripts(\n+                                installer.command_ctx,\n+                                list,\n+                                dep.behavior.optional,\n+                                false,\n+                                .{\n+                                    .entry_id = this.entry_id,\n+                                    .installer = installer,\n+                                },\n+                            ) catch |err| {\n+                                return .failure(.{ .run_preinstall = err });\n+                            };\n+\n+                            return .yield;\n+                        }\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .binaries => |current_step| {\n+                    if (this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const bin = pkg_bins[pkg_id];\n+                    if (bin.tag == .none) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const string_buf = installer.lockfile.buffers.string_bytes.items;\n+                    const dependencies = installer.lockfile.buffers.dependencies.items;\n+\n+                    const dep_name = dependencies[dep_id].name.slice(string_buf);\n+\n+                    var abs_target_buf: bun.PathBuffer = undefined;\n+                    var abs_dest_buf: bun.PathBuffer = undefined;\n+                    var rel_buf: bun.PathBuffer = undefined;\n+\n+                    var seen: bun.StringHashMap(void) = .init(bun.default_allocator);\n+                    defer seen.deinit();\n+\n+                    var node_modules_path: bun.AbsPath(.{}) = .initTopLevelDir();\n+                    defer node_modules_path.deinit();\n+\n+                    installer.appendStoreNodeModulesPath(&node_modules_path, this.entry_id);\n+\n+                    var bin_linker: Bin.Linker = .{\n+                        .bin = bin,\n+                        .global_bin_path = installer.manager.options.bin_path,\n+                        .package_name = strings.StringOrTinyString.init(dep_name),\n+                        .string_buf = string_buf,\n+                        .extern_string_buf = installer.lockfile.buffers.extern_strings.items,\n+                        .seen = &seen,\n+                        .node_modules_path = &node_modules_path,\n+                        .abs_target_buf = &abs_target_buf,\n+                        .abs_dest_buf = &abs_dest_buf,\n+                        .rel_buf = &rel_buf,\n+                    };\n+\n+                    bin_linker.link(false);\n+\n+                    if (bin_linker.err) |err| {\n+                        return .failure(.{ .binaries = err });\n+                    }\n+\n+                    continue :next_step this.nextStep(current_step);\n+                },\n+                inline .@\"run (post)install and (pre/post)prepare\" => |current_step| {\n+                    if (!installer.manager.options.do.run_scripts or this.entry_id == .root) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    var list = entry_scripts[this.entry_id.get()] orelse {\n+                        continue :next_step this.nextStep(current_step);\n+                    };\n+\n+                    if (list.first_index == 0) {\n+                        for (list.items[1..], 1..) |item, i| {\n+                            if (item != null) {\n+                                list.first_index = @intCast(i);\n+                                break;\n+                            }\n+                        }\n+                    }\n+\n+                    if (list.first_index == 0) {\n+                        continue :next_step this.nextStep(current_step);\n+                    }\n+\n+                    const dep = installer.lockfile.buffers.dependencies.items[dep_id];\n+\n+                    installer.manager.spawnPackageLifecycleScripts(\n+                        installer.command_ctx,\n+                        list.*,\n+                        dep.behavior.optional,\n+                        false,\n+                        .{\n+                            .entry_id = this.entry_id,\n+                            .installer = installer,\n+                        },\n+                    ) catch |err| {\n+                        return .failure(.{ .@\"run (post)install and (pre/post)prepare\" = err });\n+                    };\n+\n+                    // when these scripts finish the package install will be\n+                    // complete. the task does not have anymore work to complete\n+                    // so it does not return to the thread pool.\n+\n+                    return .yield;\n+                },\n+\n+                .done => {\n+                    return .done;\n+                },\n+\n+                .blocked => {\n+                    bun.debugAssert(false);\n+                    return .yield;\n+                },\n+            };\n+        }\n+\n+        pub fn callback(task: *ThreadPool.Task) void {\n+            const this: *Task = @fieldParentPtr(\"task\", task);\n+\n+            const res = this.run() catch |err| switch (err) {\n+                error.OutOfMemory => bun.outOfMemory(),\n+            };\n+\n+            switch (res) {\n+                .yield => {},\n+                .done => {\n+                    this.installer.tasks.push(this);\n+                    this.installer.manager.wake();\n+                },\n+                .fail => |err| {\n+                    this.installer.store.entries.items(.step)[this.entry_id.get()].store(.done, .monotonic);\n+                    this.err = err.clone(bun.default_allocator);\n+                    this.installer.tasks.push(this);\n+                    this.installer.manager.wake();\n+                },\n+            }\n+        }\n+    };\n+\n+    const PatchInfo = union(enum) {\n+        none,\n+        remove: struct {\n+            name_and_version_hash: u64,\n+        },\n+        patch: struct {\n+            name_and_version_hash: u64,\n+            patch_path: string,\n+            contents_hash: u64,\n+        },\n+\n+        pub fn contentsHash(this: *const @This()) ?u64 {\n+            return switch (this.*) {\n+                .none, .remove => null,\n+                .patch => |patch| patch.contents_hash,\n+            };\n+        }\n+\n+        pub fn nameAndVersionHash(this: *const @This()) ?u64 {\n+            return switch (this.*) {\n+                .none, .remove => null,\n+                .patch => |patch| patch.name_and_version_hash,\n+            };\n+        }\n+    };\n+\n+    pub fn packagePatchInfo(\n+        this: *Installer,\n+        pkg_name: String,\n+        pkg_name_hash: PackageNameHash,\n+        pkg_res: *const Resolution,\n+    ) OOM!PatchInfo {\n+        if (this.lockfile.patched_dependencies.entries.len == 0 and this.manager.patched_dependencies_to_remove.entries.len == 0) {\n+            return .none;\n+        }\n+\n+        const string_buf = this.lockfile.buffers.string_bytes.items;\n+\n+        var version_buf: std.ArrayListUnmanaged(u8) = .empty;\n+        defer version_buf.deinit(bun.default_allocator);\n+\n+        var writer = version_buf.writer(this.lockfile.allocator);\n+        try writer.print(\"{s}@\", .{pkg_name.slice(string_buf)});\n+\n+        switch (pkg_res.tag) {\n+            .workspace => {\n+                if (this.lockfile.workspace_versions.get(pkg_name_hash)) |workspace_version| {\n+                    try writer.print(\"{}\", .{workspace_version.fmt(string_buf)});\n+                }\n+            },\n+            else => {\n+                try writer.print(\"{}\", .{pkg_res.fmt(string_buf, .posix)});\n+            },\n+        }\n+\n+        const name_and_version_hash = String.Builder.stringHash(version_buf.items);\n+\n+        if (this.lockfile.patched_dependencies.get(name_and_version_hash)) |patch| {\n+            return .{\n+                .patch = .{\n+                    .name_and_version_hash = name_and_version_hash,\n+                    .patch_path = patch.path.slice(string_buf),\n+                    .contents_hash = patch.patchfileHash().?,\n+                },\n+            };\n+        }\n+\n+        if (this.manager.patched_dependencies_to_remove.contains(name_and_version_hash)) {\n+            return .{\n+                .remove = .{\n+                    .name_and_version_hash = name_and_version_hash,\n+                },\n+            };\n+        }\n+\n+        return .none;\n+    }\n+\n+    pub fn linkDependencyBins(this: *const Installer, parent_entry_id: Store.Entry.Id) !void {\n+        const lockfile = this.lockfile;\n+        const store = this.store;\n+\n+        const string_buf = lockfile.buffers.string_bytes.items;\n+        const extern_string_buf = lockfile.buffers.extern_strings.items;\n+\n+        const entries = store.entries.slice();\n+        const entry_node_ids = entries.items(.node_id);\n+        const entry_deps = entries.items(.dependencies);\n+\n+        const nodes = store.nodes.slice();\n+        const node_pkg_ids = nodes.items(.pkg_id);\n+        const node_dep_ids = nodes.items(.dep_id);\n+\n+        const pkgs = lockfile.packages.slice();\n+        const pkg_bins = pkgs.items(.bin);\n+\n+        var link_target_buf: bun.PathBuffer = undefined;\n+        var link_dest_buf: bun.PathBuffer = undefined;\n+        var link_rel_buf: bun.PathBuffer = undefined;",
        "comment_created_at": "2025-07-08T05:23:44+00:00",
        "comment_author": "Jarred-Sumner",
        "comment_body": "```suggestion\n        const link_rel_buf = bun.PathBufferPool.get();\n        defer bun.PathBufferPool.put(link_rel_buf);\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2160239788",
    "pr_number": 20530,
    "pr_file": "src/StandaloneModuleGraph.zig",
    "created_at": "2025-06-22T06:46:56+00:00",
    "commented_code": "break :brk fd;\n         };\n \n+        if (Environment.isWindows) {\n+            if (inject_options.windows_hide_console) {\n+                bun.windows.editWin32BinarySubsystem(.{ .handle = cloned_executable_fd }, .windows_gui) catch |err| {\n+                    Output.err(err, \"failed to disable console on executable\", .{});\n+                    cleanup(zname, cloned_executable_fd);\n+                    Global.exit(1);\n+                };\n+            }\n+            // this should be done before embedding the content because rescle sanitizes the file\n+            if (inject_options.windows_icon) |icon_utf8| {\n+                var normalized_buf: bun.OSPathBuffer = undefined;",
    "repo_full_name": "oven-sh/bun",
    "discussion_comments": [
      {
        "comment_id": "2160239788",
        "repo_full_name": "oven-sh/bun",
        "pr_number": 20530,
        "pr_file": "src/StandaloneModuleGraph.zig",
        "discussion_id": "2160239788",
        "commented_code": "@@ -629,6 +633,41 @@ pub const StandaloneModuleGraph = struct {\n             break :brk fd;\n         };\n \n+        if (Environment.isWindows) {\n+            if (inject_options.windows_hide_console) {\n+                bun.windows.editWin32BinarySubsystem(.{ .handle = cloned_executable_fd }, .windows_gui) catch |err| {\n+                    Output.err(err, \"failed to disable console on executable\", .{});\n+                    cleanup(zname, cloned_executable_fd);\n+                    Global.exit(1);\n+                };\n+            }\n+            // this should be done before embedding the content because rescle sanitizes the file\n+            if (inject_options.windows_icon) |icon_utf8| {\n+                var normalized_buf: bun.OSPathBuffer = undefined;",
        "comment_created_at": "2025-06-22T06:46:56+00:00",
        "comment_author": "Jarred-Sumner",
        "comment_body": "```suggestion\r\n                const normalized_buf = bun.PathBufferPool.get();\r\n                defer Bun.PathBufferPool.put(normalized_buf);\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2176308050",
    "pr_number": 20745,
    "pr_file": "src/sourcemap/sourcemap.zig",
    "created_at": "2025-07-01T02:49:03+00:00",
    "commented_code": "}\n };\n \n+pub const BakeSourceProvider = opaque {\n+    extern fn BakeSourceProvider__getSourceSlice(*BakeSourceProvider) bun.String;\n+\n+    /// The last two arguments to this specify loading hints\n+    pub fn getSourceMap(\n+        provider: *BakeSourceProvider,\n+        source_filename: []const u8,\n+        load_hint: SourceMap.SourceMapLoadHint,\n+        result: SourceMap.ParseUrlResultHint,\n+    ) ?SourceMap.ParseUrl {\n+        var sfb = std.heap.stackFallback(65536, bun.default_allocator);\n+        var arena = bun.ArenaAllocator.init(sfb.get());\n+        defer arena.deinit();\n+        const allocator = arena.allocator();\n+\n+        const new_load_hint: SourceMap.SourceMapLoadHint, const parsed = parsed: {\n+            var inline_err: ?anyerror = null;\n+\n+            // try to get an inline source map\n+            if (load_hint != .is_external_map) try_inline: {\n+                const source = BakeSourceProvider__getSourceSlice(provider);\n+                defer source.deref();\n+                bun.assert(source.tag == .ZigString);\n+\n+                const found_url = (if (source.is8Bit())\n+                    findSourceMappingURL(u8, source.latin1(), allocator)\n+                else\n+                    findSourceMappingURL(u16, source.utf16(), allocator)) orelse\n+                    break :try_inline;\n+                defer found_url.deinit();\n+\n+                break :parsed .{\n+                    .is_inline_map,\n+                    parseUrl(\n+                        bun.default_allocator,\n+                        allocator,\n+                        found_url.slice(),\n+                        result,\n+                    ) catch |err| {\n+                        inline_err = err;\n+                        break :try_inline;\n+                    },\n+                };\n+            }\n+\n+            // try to load a .map file\n+            if (load_hint != .is_inline_map) try_external: {\n+                var load_path_buf: bun.PathBuffer = undefined;",
    "repo_full_name": "oven-sh/bun",
    "discussion_comments": [
      {
        "comment_id": "2176308050",
        "repo_full_name": "oven-sh/bun",
        "pr_number": 20745,
        "pr_file": "src/sourcemap/sourcemap.zig",
        "discussion_id": "2176308050",
        "commented_code": "@@ -855,6 +888,108 @@ pub const SourceProviderMap = opaque {\n     }\n };\n \n+pub const BakeSourceProvider = opaque {\n+    extern fn BakeSourceProvider__getSourceSlice(*BakeSourceProvider) bun.String;\n+\n+    /// The last two arguments to this specify loading hints\n+    pub fn getSourceMap(\n+        provider: *BakeSourceProvider,\n+        source_filename: []const u8,\n+        load_hint: SourceMap.SourceMapLoadHint,\n+        result: SourceMap.ParseUrlResultHint,\n+    ) ?SourceMap.ParseUrl {\n+        var sfb = std.heap.stackFallback(65536, bun.default_allocator);\n+        var arena = bun.ArenaAllocator.init(sfb.get());\n+        defer arena.deinit();\n+        const allocator = arena.allocator();\n+\n+        const new_load_hint: SourceMap.SourceMapLoadHint, const parsed = parsed: {\n+            var inline_err: ?anyerror = null;\n+\n+            // try to get an inline source map\n+            if (load_hint != .is_external_map) try_inline: {\n+                const source = BakeSourceProvider__getSourceSlice(provider);\n+                defer source.deref();\n+                bun.assert(source.tag == .ZigString);\n+\n+                const found_url = (if (source.is8Bit())\n+                    findSourceMappingURL(u8, source.latin1(), allocator)\n+                else\n+                    findSourceMappingURL(u16, source.utf16(), allocator)) orelse\n+                    break :try_inline;\n+                defer found_url.deinit();\n+\n+                break :parsed .{\n+                    .is_inline_map,\n+                    parseUrl(\n+                        bun.default_allocator,\n+                        allocator,\n+                        found_url.slice(),\n+                        result,\n+                    ) catch |err| {\n+                        inline_err = err;\n+                        break :try_inline;\n+                    },\n+                };\n+            }\n+\n+            // try to load a .map file\n+            if (load_hint != .is_inline_map) try_external: {\n+                var load_path_buf: bun.PathBuffer = undefined;",
        "comment_created_at": "2025-07-01T02:49:03+00:00",
        "comment_author": "Jarred-Sumner",
        "comment_body": "Use `bun.PathBufferPool`",
        "pr_file_module": null
      }
    ]
  }
]