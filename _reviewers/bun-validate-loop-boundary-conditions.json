[
  {
    "discussion_id": "2202906253",
    "pr_number": 20997,
    "pr_file": "src/s3/credentials.zig",
    "created_at": "2025-07-12T20:27:02+00:00",
    "commented_code": "return buffer[0..written];\n     }\n \n+    fn normalizeName(name: []const u8) []const u8 {\n+        if (name.len == 0) return name;\n+        var normalized_name = name;\n+        if (strings.endsWith(normalized_name, \"/\")) {\n+            normalized_name = normalized_name[0 .. normalized_name.len - 1];\n+        } else if (strings.endsWith(normalized_name, \"\\\\\")) {\n+            normalized_name = normalized_name[0 .. normalized_name.len - 1];\n+        }\n+        if (strings.startsWith(normalized_name, \"/\")) {\n+            normalized_name = normalized_name[1..];\n+        } else if (strings.startsWith(normalized_name, \"\\\\\")) {\n+            normalized_name = normalized_name[1..];\n+        }",
    "repo_full_name": "oven-sh/bun",
    "discussion_comments": [
      {
        "comment_id": "2202906253",
        "repo_full_name": "oven-sh/bun",
        "pr_number": 20997,
        "pr_file": "src/s3/credentials.zig",
        "discussion_id": "2202906253",
        "commented_code": "@@ -496,6 +496,22 @@ pub const S3Credentials = struct {\n         return buffer[0..written];\n     }\n \n+    fn normalizeName(name: []const u8) []const u8 {\n+        if (name.len == 0) return name;\n+        var normalized_name = name;\n+        if (strings.endsWith(normalized_name, \"/\")) {\n+            normalized_name = normalized_name[0 .. normalized_name.len - 1];\n+        } else if (strings.endsWith(normalized_name, \"\\\\\")) {\n+            normalized_name = normalized_name[0 .. normalized_name.len - 1];\n+        }\n+        if (strings.startsWith(normalized_name, \"/\")) {\n+            normalized_name = normalized_name[1..];\n+        } else if (strings.startsWith(normalized_name, \"\\\\\")) {\n+            normalized_name = normalized_name[1..];\n+        }",
        "comment_created_at": "2025-07-12T20:27:02+00:00",
        "comment_author": "graphite-app[bot]",
        "comment_body": "The current implementation has a potential issue with handling multiple slashes. If a string contains both a trailing forward slash and backslash (e.g., `bucket/\\`), only the forward slash will be removed because the checks are mutually exclusive with `else if`. \n\nConsider modifying the function to handle multiple trailing/leading characters by either:\n\n1. Making the checks independent (removing the `else` conditions)\n2. Using a loop to repeatedly trim slashes until none remain\n\nThis would ensure that strings like `bucket/\\` or `/\\bucket` are properly normalized regardless of the order or combination of slashes.\n```suggestion\n        while (strings.endsWith(normalized_name, \"/\") or strings.endsWith(normalized_name, \"\\\\\")) {\n            normalized_name = normalized_name[0 .. normalized_name.len - 1];\n        }\n        while (strings.startsWith(normalized_name, \"/\") or strings.startsWith(normalized_name, \"\\\\\")) {\n            normalized_name = normalized_name[1..];\n        }\n```\n  \n\n*Spotted by [Diamond](https://app.graphite.dev/diamond/?org=oven-sh&ref=ai-review-comment)*<i class='graphite__hidden'><br /><br />Is this helpful? React \ud83d\udc4d or \ud83d\udc4e to let us know.</i>",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2131487572",
    "pr_number": 20198,
    "pr_file": "src/bun.js/api/server/FileRoute.zig",
    "created_at": "2025-06-06T04:45:18+00:00",
    "commented_code": "+const FileRoute = @This();\n+\n+ref_count: RefCount,\n+server: ?AnyServer = null,\n+blob: Blob,\n+headers: Headers = .{ .allocator = bun.default_allocator },\n+status_code: u16,\n+stat_hash: bun.fs.StatHash = .{},\n+has_last_modified_header: bool,\n+has_content_length_header: bool,\n+\n+pub const InitOptions = struct {\n+    server: ?AnyServer,\n+    status_code: u16 = 200,\n+};\n+\n+pub fn lastModifiedDate(this: *const FileRoute) ?u64 {\n+    if (this.has_last_modified_header) {\n+        if (this.headers.get(\"last-modified\")) |last_modified| {\n+            var string = bun.String.init(last_modified);\n+            defer string.deref();\n+            const date_f64 = bun.String.parseDate(&string, bun.JSC.VirtualMachine.get().global);\n+            if (!std.math.isNan(date_f64) and std.math.isFinite(date_f64)) {\n+                return @intFromFloat(date_f64);\n+            }\n+        }\n+    }\n+\n+    if (this.stat_hash.last_modified_u64 > 0) {\n+        return this.stat_hash.last_modified_u64;\n+    }\n+\n+    return null;\n+}\n+\n+pub fn initFromBlob(blob: Blob, opts: InitOptions) *FileRoute {\n+    const headers = Headers.from(null, bun.default_allocator, .{ .body = &.{ .Blob = blob } }) catch bun.outOfMemory();\n+    return bun.new(FileRoute, .{\n+        .ref_count = .init(),\n+        .server = opts.server,\n+        .blob = blob,\n+        .headers = headers,\n+        .status_code = opts.status_code,\n+    });\n+}\n+\n+fn deinit(this: *FileRoute) void {\n+    this.blob.deinit();\n+    this.headers.deinit();\n+    bun.destroy(this);\n+}\n+\n+pub fn memoryCost(this: *const FileRoute) usize {\n+    return @sizeOf(FileRoute) + this.headers.memoryCost() + this.blob.reported_estimated_size;\n+}\n+\n+pub fn fromJS(globalThis: *JSC.JSGlobalObject, argument: JSC.JSValue) bun.JSError!?*FileRoute {\n+    if (argument.as(JSC.WebCore.Response)) |response| {\n+        response.body.value.toBlobIfPossible();\n+        if (response.body.value == .Blob and response.body.value.Blob.needsToReadFile()) {\n+            if (response.body.value.Blob.store.?.data.file.pathlike == .fd) {\n+                return globalThis.throwTODO(\"Support serving files from a file descriptor. Please pass a path instead.\");\n+            }\n+\n+            var blob = response.body.value.use();\n+\n+            blob.globalThis = globalThis;\n+            blob.allocator = null;\n+            response.body.value = .{ .Blob = blob.dupe() };\n+            const headers = Headers.from(response.init.headers, bun.default_allocator, .{ .body = &.{ .Blob = blob } }) catch bun.outOfMemory();\n+\n+            return bun.new(FileRoute, .{\n+                .ref_count = .init(),\n+                .server = null,\n+                .blob = blob,\n+                .headers = headers,\n+                .has_last_modified_header = headers.get(\"last-modified\") != null,\n+                .has_content_length_header = headers.get(\"content-length\") != null,\n+                .status_code = response.statusCode(),\n+            });\n+        }\n+    }\n+    if (argument.as(Blob)) |blob| {\n+        if (blob.needsToReadFile()) {\n+            var b = blob.dupe();\n+            b.globalThis = globalThis;\n+            b.allocator = null;\n+            return bun.new(FileRoute, .{\n+                .ref_count = .init(),\n+                .server = null,\n+                .blob = b,\n+                .headers = Headers.from(null, bun.default_allocator, .{ .body = &.{ .Blob = b } }) catch bun.outOfMemory(),\n+                .has_content_length_header = false,\n+                .has_last_modified_header = false,\n+                .status_code = 200,\n+            });\n+        }\n+    }\n+    return null;\n+}\n+\n+fn writeHeaders(this: *FileRoute, resp: AnyResponse) void {\n+    const entries = this.headers.entries.slice();\n+    const names = entries.items(.name);\n+    const values = entries.items(.value);\n+    const buf = this.headers.buf.items;\n+\n+    switch (resp) {\n+        inline .SSL, .TCP => |s| {\n+            for (names, values) |name, value| {\n+                s.writeHeader(name.slice(buf), value.slice(buf));\n+            }\n+        },\n+    }\n+\n+    if (!this.has_last_modified_header) {\n+        if (this.stat_hash.lastModified()) |last_modified| {\n+            resp.writeHeader(\"last-modified\", last_modified);\n+        }\n+    }\n+\n+    if (this.has_content_length_header) {\n+        resp.markWroteContentLengthHeader();\n+    }\n+}\n+\n+fn writeStatusCode(_: *FileRoute, status: u16, resp: AnyResponse) void {\n+    switch (resp) {\n+        .SSL => |r| writeStatus(true, r, status),\n+        .TCP => |r| writeStatus(false, r, status),\n+    }\n+}\n+\n+pub fn onHEADRequest(this: *FileRoute, req: *uws.Request, resp: AnyResponse) void {\n+    bun.debugAssert(this.server != null);\n+\n+    this.on(req, resp, .HEAD);\n+}\n+\n+pub fn onRequest(this: *FileRoute, req: *uws.Request, resp: AnyResponse) void {\n+    this.on(req, resp, bun.http.Method.find(req.method()) orelse .GET);\n+}\n+\n+pub fn on(this: *FileRoute, req: *uws.Request, resp: AnyResponse, method: bun.http.Method) void {\n+    bun.debugAssert(this.server != null);\n+    this.ref();\n+    if (this.server) |server| {\n+        server.onPendingRequest();\n+        resp.timeout(server.config().idleTimeout);\n+    }\n+    const path = this.blob.store.?.getPath() orelse {\n+        req.setYield(true);\n+        this.deref();\n+        return;\n+    };\n+\n+    const open_flags = bun.O.RDONLY | bun.O.CLOEXEC | bun.O.NONBLOCK;\n+    const fd_result = bun.sys.openA(\n+        path,\n+        open_flags,\n+        0,\n+    );\n+    if (fd_result == .err) {\n+        req.setYield(true);\n+        this.deref();\n+        return;\n+    }\n+\n+    const fd = fd_result.result.makeLibUVOwned() catch {\n+        req.setYield(true);\n+        this.deref();\n+        return;\n+    };\n+\n+    const input_if_modified_since_date: ?u64 = req.dateForHeader(\"if-modified-since\");\n+\n+    const can_serve_file: bool, const size: u64, const file_type: bun.io.FileType, const pollable: bool = brk: {\n+        const stat = switch (bun.sys.fstat(fd)) {\n+            .result => |s| s,\n+            .err => break :brk .{ false, 0, undefined, false },\n+        };\n+\n+        const stat_size: u64 = @intCast(@max(stat.size, 0));\n+        const _size: u64 = @min(stat_size, @as(u64, this.blob.size));\n+\n+        if (bun.S.ISDIR(@intCast(stat.mode))) {\n+            break :brk .{ false, 0, undefined, false };\n+        }\n+\n+        this.stat_hash.hash(stat, path);\n+\n+        if (bun.S.ISFIFO(@intCast(stat.mode)) or bun.S.ISCHR(@intCast(stat.mode))) {\n+            break :brk .{ true, _size, .pipe, true };\n+        }\n+\n+        if (bun.S.ISSOCK(@intCast(stat.mode))) {\n+            break :brk .{ true, _size, .socket, true };\n+        }\n+\n+        break :brk .{ true, _size, .file, false };\n+    };\n+\n+    if (!can_serve_file) {\n+        bun.Async.Closer.close(fd, if (bun.Environment.isWindows) bun.windows.libuv.Loop.get());\n+        req.setYield(true);\n+        this.deref();\n+        return;\n+    }\n+\n+    const status_code: u16 = brk: {\n+        // Unlike If-Unmodified-Since, If-Modified-Since can only be used with a\n+        // GET or HEAD. When used in combination with If-None-Match, it is\n+        // ignored, unless the server doesn't support If-None-Match.\n+        if (input_if_modified_since_date) |requested_if_modified_since| {\n+            if (method == .HEAD or method == .GET) {\n+                if (this.lastModifiedDate()) |actual_last_modified_at| {\n+                    if (actual_last_modified_at <= requested_if_modified_since) {\n+                        break :brk 304;\n+                    }\n+                }\n+            }\n+        }\n+\n+        if (size == 0 and file_type == .file and this.status_code == 200) {\n+            break :brk 204;\n+        }\n+\n+        break :brk this.status_code;\n+    };\n+\n+    req.setYield(false);\n+\n+    this.writeStatusCode(status_code, resp);\n+    resp.writeMark();\n+    this.writeHeaders(resp);\n+\n+    switch (status_code) {\n+        204, 205, 304, 307, 308 => {\n+            resp.endWithoutBody(resp.shouldCloseConnection());\n+            this.deref();\n+            return;\n+        },\n+        else => {},\n+    }\n+\n+    if (file_type == .file and !resp.state().hasWrittenContentLengthHeader()) {\n+        resp.writeHeaderInt(\"content-length\", size);\n+        resp.markWroteContentLengthHeader();\n+    }\n+\n+    if (method == .HEAD) {\n+        resp.endWithoutBody(resp.shouldCloseConnection());\n+        this.deref();\n+        return;\n+    }\n+\n+    const transfer = StreamTransfer.create(fd, resp, this, pollable, file_type != .file, file_type);\n+    transfer.start(\n+        if (file_type == .file) this.blob.offset else 0,\n+        if (file_type == .file and this.blob.size > 0) @intCast(size) else null,\n+    );\n+}\n+\n+fn onResponseComplete(this: *FileRoute, resp: AnyResponse) void {\n+    resp.clearAborted();\n+    resp.clearOnWritable();\n+    resp.clearTimeout();\n+    if (this.server) |server| {\n+        server.onStaticRequestComplete();\n+    }\n+    this.deref();\n+}\n+\n+const std = @import(\"std\");\n+const bun = @import(\"bun\");\n+const JSC = bun.JSC;\n+const uws = bun.uws;\n+const Headers = bun.http.Headers;\n+const AnyServer = JSC.API.AnyServer;\n+const Blob = JSC.WebCore.Blob;\n+const writeStatus = @import(\"../server.zig\").writeStatus;\n+const AnyResponse = uws.AnyResponse;\n+const Async = bun.Async;\n+const FileType = bun.io.FileType;\n+const Output = bun.Output;\n+\n+const StreamTransfer = struct {\n+    reader: bun.io.BufferedReader = bun.io.BufferedReader.init(StreamTransfer),\n+    fd: bun.FileDescriptor,\n+    resp: AnyResponse,\n+    route: *FileRoute,\n+\n+    defer_deinit: ?*bool = null,\n+    max_size: ?u64 = null,\n+\n+    state: packed struct(u8) {\n+        waiting_for_readable: bool = false,\n+        waiting_for_writable: bool = false,\n+        has_ended_response: bool = false,\n+        has_reader_closed: bool = false,\n+        _: u4 = 0,\n+    } = .{},\n+    const log = Output.scoped(.StreamTransfer, true);\n+\n+    pub fn create(\n+        fd: bun.FileDescriptor,\n+        resp: AnyResponse,\n+        route: *FileRoute,\n+        pollable: bool,\n+        nonblocking: bool,\n+        file_type: FileType,\n+    ) *StreamTransfer {\n+        var t = bun.new(StreamTransfer, .{\n+            .fd = fd,\n+            .resp = resp,\n+            .route = route,\n+        });\n+        t.reader.flags.close_handle = true;\n+        t.reader.flags.pollable = pollable;\n+        t.reader.flags.nonblocking = nonblocking;\n+        if (comptime bun.Environment.isPosix) {\n+            if (file_type == .socket) {\n+                t.reader.flags.socket = true;\n+            }\n+        }\n+        t.reader.setParent(t);\n+        return t;\n+    }\n+\n+    fn start(this: *StreamTransfer, start_offset: usize, size: ?usize) void {\n+        log(\"start\", .{});\n+\n+        var scope: DeinitScope = undefined;\n+        scope.enter(this);\n+        defer scope.exit();\n+\n+        this.state.waiting_for_readable = true;\n+        this.state.waiting_for_writable = true;\n+        this.max_size = size;\n+\n+        switch (if (start_offset > 0)\n+            this.reader.startFileOffset(this.fd, this.reader.flags.pollable, start_offset)\n+        else\n+            this.reader.start(this.fd, this.reader.flags.pollable)) {\n+            .err => {\n+                this.finish();\n+                return;\n+            },\n+            .result => {},\n+        }\n+\n+        this.reader.updateRef(true);\n+\n+        if (bun.Environment.isPosix) {\n+            if (this.reader.handle.getPoll()) |poll| {\n+                if (this.reader.flags.nonblocking) {\n+                    poll.flags.insert(.nonblocking);\n+                }\n+\n+                switch (this.reader.getFileType()) {\n+                    .socket => poll.flags.insert(.socket),\n+                    .nonblocking_pipe, .pipe => poll.flags.insert(.fifo),\n+                    .file => {},\n+                }\n+            }\n+        }\n+\n+        this.reader.read();\n+\n+        if (!scope.deinit_called) {\n+            // This clones some data so we could avoid that if we're already done.\n+            this.resp.onAborted(*StreamTransfer, onAborted, this);\n+        }\n+    }\n+\n+    pub fn onReadChunk(this: *StreamTransfer, chunk_: []const u8, state_: bun.io.ReadState) bool {\n+        log(\"onReadChunk\", .{});\n+\n+        var scope: DeinitScope = undefined;\n+        scope.enter(this);\n+        defer scope.exit();\n+\n+        if (this.state.has_ended_response) {\n+            this.state.waiting_for_readable = false;\n+            this.finish();\n+            return false;\n+        }\n+\n+        const chunk, const state = brk: {\n+            if (this.max_size) |*max_size| {\n+                const chunk = chunk_[0..@min(chunk_.len, max_size.*)];\n+                max_size.* -|= chunk.len;",
    "repo_full_name": "oven-sh/bun",
    "discussion_comments": [
      {
        "comment_id": "2131487572",
        "repo_full_name": "oven-sh/bun",
        "pr_number": 20198,
        "pr_file": "src/bun.js/api/server/FileRoute.zig",
        "discussion_id": "2131487572",
        "commented_code": "@@ -0,0 +1,570 @@\n+const FileRoute = @This();\n+\n+ref_count: RefCount,\n+server: ?AnyServer = null,\n+blob: Blob,\n+headers: Headers = .{ .allocator = bun.default_allocator },\n+status_code: u16,\n+stat_hash: bun.fs.StatHash = .{},\n+has_last_modified_header: bool,\n+has_content_length_header: bool,\n+\n+pub const InitOptions = struct {\n+    server: ?AnyServer,\n+    status_code: u16 = 200,\n+};\n+\n+pub fn lastModifiedDate(this: *const FileRoute) ?u64 {\n+    if (this.has_last_modified_header) {\n+        if (this.headers.get(\"last-modified\")) |last_modified| {\n+            var string = bun.String.init(last_modified);\n+            defer string.deref();\n+            const date_f64 = bun.String.parseDate(&string, bun.JSC.VirtualMachine.get().global);\n+            if (!std.math.isNan(date_f64) and std.math.isFinite(date_f64)) {\n+                return @intFromFloat(date_f64);\n+            }\n+        }\n+    }\n+\n+    if (this.stat_hash.last_modified_u64 > 0) {\n+        return this.stat_hash.last_modified_u64;\n+    }\n+\n+    return null;\n+}\n+\n+pub fn initFromBlob(blob: Blob, opts: InitOptions) *FileRoute {\n+    const headers = Headers.from(null, bun.default_allocator, .{ .body = &.{ .Blob = blob } }) catch bun.outOfMemory();\n+    return bun.new(FileRoute, .{\n+        .ref_count = .init(),\n+        .server = opts.server,\n+        .blob = blob,\n+        .headers = headers,\n+        .status_code = opts.status_code,\n+    });\n+}\n+\n+fn deinit(this: *FileRoute) void {\n+    this.blob.deinit();\n+    this.headers.deinit();\n+    bun.destroy(this);\n+}\n+\n+pub fn memoryCost(this: *const FileRoute) usize {\n+    return @sizeOf(FileRoute) + this.headers.memoryCost() + this.blob.reported_estimated_size;\n+}\n+\n+pub fn fromJS(globalThis: *JSC.JSGlobalObject, argument: JSC.JSValue) bun.JSError!?*FileRoute {\n+    if (argument.as(JSC.WebCore.Response)) |response| {\n+        response.body.value.toBlobIfPossible();\n+        if (response.body.value == .Blob and response.body.value.Blob.needsToReadFile()) {\n+            if (response.body.value.Blob.store.?.data.file.pathlike == .fd) {\n+                return globalThis.throwTODO(\"Support serving files from a file descriptor. Please pass a path instead.\");\n+            }\n+\n+            var blob = response.body.value.use();\n+\n+            blob.globalThis = globalThis;\n+            blob.allocator = null;\n+            response.body.value = .{ .Blob = blob.dupe() };\n+            const headers = Headers.from(response.init.headers, bun.default_allocator, .{ .body = &.{ .Blob = blob } }) catch bun.outOfMemory();\n+\n+            return bun.new(FileRoute, .{\n+                .ref_count = .init(),\n+                .server = null,\n+                .blob = blob,\n+                .headers = headers,\n+                .has_last_modified_header = headers.get(\"last-modified\") != null,\n+                .has_content_length_header = headers.get(\"content-length\") != null,\n+                .status_code = response.statusCode(),\n+            });\n+        }\n+    }\n+    if (argument.as(Blob)) |blob| {\n+        if (blob.needsToReadFile()) {\n+            var b = blob.dupe();\n+            b.globalThis = globalThis;\n+            b.allocator = null;\n+            return bun.new(FileRoute, .{\n+                .ref_count = .init(),\n+                .server = null,\n+                .blob = b,\n+                .headers = Headers.from(null, bun.default_allocator, .{ .body = &.{ .Blob = b } }) catch bun.outOfMemory(),\n+                .has_content_length_header = false,\n+                .has_last_modified_header = false,\n+                .status_code = 200,\n+            });\n+        }\n+    }\n+    return null;\n+}\n+\n+fn writeHeaders(this: *FileRoute, resp: AnyResponse) void {\n+    const entries = this.headers.entries.slice();\n+    const names = entries.items(.name);\n+    const values = entries.items(.value);\n+    const buf = this.headers.buf.items;\n+\n+    switch (resp) {\n+        inline .SSL, .TCP => |s| {\n+            for (names, values) |name, value| {\n+                s.writeHeader(name.slice(buf), value.slice(buf));\n+            }\n+        },\n+    }\n+\n+    if (!this.has_last_modified_header) {\n+        if (this.stat_hash.lastModified()) |last_modified| {\n+            resp.writeHeader(\"last-modified\", last_modified);\n+        }\n+    }\n+\n+    if (this.has_content_length_header) {\n+        resp.markWroteContentLengthHeader();\n+    }\n+}\n+\n+fn writeStatusCode(_: *FileRoute, status: u16, resp: AnyResponse) void {\n+    switch (resp) {\n+        .SSL => |r| writeStatus(true, r, status),\n+        .TCP => |r| writeStatus(false, r, status),\n+    }\n+}\n+\n+pub fn onHEADRequest(this: *FileRoute, req: *uws.Request, resp: AnyResponse) void {\n+    bun.debugAssert(this.server != null);\n+\n+    this.on(req, resp, .HEAD);\n+}\n+\n+pub fn onRequest(this: *FileRoute, req: *uws.Request, resp: AnyResponse) void {\n+    this.on(req, resp, bun.http.Method.find(req.method()) orelse .GET);\n+}\n+\n+pub fn on(this: *FileRoute, req: *uws.Request, resp: AnyResponse, method: bun.http.Method) void {\n+    bun.debugAssert(this.server != null);\n+    this.ref();\n+    if (this.server) |server| {\n+        server.onPendingRequest();\n+        resp.timeout(server.config().idleTimeout);\n+    }\n+    const path = this.blob.store.?.getPath() orelse {\n+        req.setYield(true);\n+        this.deref();\n+        return;\n+    };\n+\n+    const open_flags = bun.O.RDONLY | bun.O.CLOEXEC | bun.O.NONBLOCK;\n+    const fd_result = bun.sys.openA(\n+        path,\n+        open_flags,\n+        0,\n+    );\n+    if (fd_result == .err) {\n+        req.setYield(true);\n+        this.deref();\n+        return;\n+    }\n+\n+    const fd = fd_result.result.makeLibUVOwned() catch {\n+        req.setYield(true);\n+        this.deref();\n+        return;\n+    };\n+\n+    const input_if_modified_since_date: ?u64 = req.dateForHeader(\"if-modified-since\");\n+\n+    const can_serve_file: bool, const size: u64, const file_type: bun.io.FileType, const pollable: bool = brk: {\n+        const stat = switch (bun.sys.fstat(fd)) {\n+            .result => |s| s,\n+            .err => break :brk .{ false, 0, undefined, false },\n+        };\n+\n+        const stat_size: u64 = @intCast(@max(stat.size, 0));\n+        const _size: u64 = @min(stat_size, @as(u64, this.blob.size));\n+\n+        if (bun.S.ISDIR(@intCast(stat.mode))) {\n+            break :brk .{ false, 0, undefined, false };\n+        }\n+\n+        this.stat_hash.hash(stat, path);\n+\n+        if (bun.S.ISFIFO(@intCast(stat.mode)) or bun.S.ISCHR(@intCast(stat.mode))) {\n+            break :brk .{ true, _size, .pipe, true };\n+        }\n+\n+        if (bun.S.ISSOCK(@intCast(stat.mode))) {\n+            break :brk .{ true, _size, .socket, true };\n+        }\n+\n+        break :brk .{ true, _size, .file, false };\n+    };\n+\n+    if (!can_serve_file) {\n+        bun.Async.Closer.close(fd, if (bun.Environment.isWindows) bun.windows.libuv.Loop.get());\n+        req.setYield(true);\n+        this.deref();\n+        return;\n+    }\n+\n+    const status_code: u16 = brk: {\n+        // Unlike If-Unmodified-Since, If-Modified-Since can only be used with a\n+        // GET or HEAD. When used in combination with If-None-Match, it is\n+        // ignored, unless the server doesn't support If-None-Match.\n+        if (input_if_modified_since_date) |requested_if_modified_since| {\n+            if (method == .HEAD or method == .GET) {\n+                if (this.lastModifiedDate()) |actual_last_modified_at| {\n+                    if (actual_last_modified_at <= requested_if_modified_since) {\n+                        break :brk 304;\n+                    }\n+                }\n+            }\n+        }\n+\n+        if (size == 0 and file_type == .file and this.status_code == 200) {\n+            break :brk 204;\n+        }\n+\n+        break :brk this.status_code;\n+    };\n+\n+    req.setYield(false);\n+\n+    this.writeStatusCode(status_code, resp);\n+    resp.writeMark();\n+    this.writeHeaders(resp);\n+\n+    switch (status_code) {\n+        204, 205, 304, 307, 308 => {\n+            resp.endWithoutBody(resp.shouldCloseConnection());\n+            this.deref();\n+            return;\n+        },\n+        else => {},\n+    }\n+\n+    if (file_type == .file and !resp.state().hasWrittenContentLengthHeader()) {\n+        resp.writeHeaderInt(\"content-length\", size);\n+        resp.markWroteContentLengthHeader();\n+    }\n+\n+    if (method == .HEAD) {\n+        resp.endWithoutBody(resp.shouldCloseConnection());\n+        this.deref();\n+        return;\n+    }\n+\n+    const transfer = StreamTransfer.create(fd, resp, this, pollable, file_type != .file, file_type);\n+    transfer.start(\n+        if (file_type == .file) this.blob.offset else 0,\n+        if (file_type == .file and this.blob.size > 0) @intCast(size) else null,\n+    );\n+}\n+\n+fn onResponseComplete(this: *FileRoute, resp: AnyResponse) void {\n+    resp.clearAborted();\n+    resp.clearOnWritable();\n+    resp.clearTimeout();\n+    if (this.server) |server| {\n+        server.onStaticRequestComplete();\n+    }\n+    this.deref();\n+}\n+\n+const std = @import(\"std\");\n+const bun = @import(\"bun\");\n+const JSC = bun.JSC;\n+const uws = bun.uws;\n+const Headers = bun.http.Headers;\n+const AnyServer = JSC.API.AnyServer;\n+const Blob = JSC.WebCore.Blob;\n+const writeStatus = @import(\"../server.zig\").writeStatus;\n+const AnyResponse = uws.AnyResponse;\n+const Async = bun.Async;\n+const FileType = bun.io.FileType;\n+const Output = bun.Output;\n+\n+const StreamTransfer = struct {\n+    reader: bun.io.BufferedReader = bun.io.BufferedReader.init(StreamTransfer),\n+    fd: bun.FileDescriptor,\n+    resp: AnyResponse,\n+    route: *FileRoute,\n+\n+    defer_deinit: ?*bool = null,\n+    max_size: ?u64 = null,\n+\n+    state: packed struct(u8) {\n+        waiting_for_readable: bool = false,\n+        waiting_for_writable: bool = false,\n+        has_ended_response: bool = false,\n+        has_reader_closed: bool = false,\n+        _: u4 = 0,\n+    } = .{},\n+    const log = Output.scoped(.StreamTransfer, true);\n+\n+    pub fn create(\n+        fd: bun.FileDescriptor,\n+        resp: AnyResponse,\n+        route: *FileRoute,\n+        pollable: bool,\n+        nonblocking: bool,\n+        file_type: FileType,\n+    ) *StreamTransfer {\n+        var t = bun.new(StreamTransfer, .{\n+            .fd = fd,\n+            .resp = resp,\n+            .route = route,\n+        });\n+        t.reader.flags.close_handle = true;\n+        t.reader.flags.pollable = pollable;\n+        t.reader.flags.nonblocking = nonblocking;\n+        if (comptime bun.Environment.isPosix) {\n+            if (file_type == .socket) {\n+                t.reader.flags.socket = true;\n+            }\n+        }\n+        t.reader.setParent(t);\n+        return t;\n+    }\n+\n+    fn start(this: *StreamTransfer, start_offset: usize, size: ?usize) void {\n+        log(\"start\", .{});\n+\n+        var scope: DeinitScope = undefined;\n+        scope.enter(this);\n+        defer scope.exit();\n+\n+        this.state.waiting_for_readable = true;\n+        this.state.waiting_for_writable = true;\n+        this.max_size = size;\n+\n+        switch (if (start_offset > 0)\n+            this.reader.startFileOffset(this.fd, this.reader.flags.pollable, start_offset)\n+        else\n+            this.reader.start(this.fd, this.reader.flags.pollable)) {\n+            .err => {\n+                this.finish();\n+                return;\n+            },\n+            .result => {},\n+        }\n+\n+        this.reader.updateRef(true);\n+\n+        if (bun.Environment.isPosix) {\n+            if (this.reader.handle.getPoll()) |poll| {\n+                if (this.reader.flags.nonblocking) {\n+                    poll.flags.insert(.nonblocking);\n+                }\n+\n+                switch (this.reader.getFileType()) {\n+                    .socket => poll.flags.insert(.socket),\n+                    .nonblocking_pipe, .pipe => poll.flags.insert(.fifo),\n+                    .file => {},\n+                }\n+            }\n+        }\n+\n+        this.reader.read();\n+\n+        if (!scope.deinit_called) {\n+            // This clones some data so we could avoid that if we're already done.\n+            this.resp.onAborted(*StreamTransfer, onAborted, this);\n+        }\n+    }\n+\n+    pub fn onReadChunk(this: *StreamTransfer, chunk_: []const u8, state_: bun.io.ReadState) bool {\n+        log(\"onReadChunk\", .{});\n+\n+        var scope: DeinitScope = undefined;\n+        scope.enter(this);\n+        defer scope.exit();\n+\n+        if (this.state.has_ended_response) {\n+            this.state.waiting_for_readable = false;\n+            this.finish();\n+            return false;\n+        }\n+\n+        const chunk, const state = brk: {\n+            if (this.max_size) |*max_size| {\n+                const chunk = chunk_[0..@min(chunk_.len, max_size.*)];\n+                max_size.* -|= chunk.len;",
        "comment_created_at": "2025-06-06T04:45:18+00:00",
        "comment_author": "graphite-app[bot]",
        "comment_body": "The size limiting logic has a potential issue with the saturating subtraction (`-|=`). When checking if `max_size.* == 0`, it won't detect cases where the subtraction saturated at zero. Consider using regular subtraction with explicit underflow handling:\n\n```zig\nif (chunk.len >= max_size.*) {\n    const limited_chunk = chunk_[0..max_size.*];\n    max_size.* = 0;\n    break :brk .{ limited_chunk, .eof };\n} else {\n    max_size.* -= chunk.len;\n    break :brk .{ chunk, state_ };\n}\n```\n\nThis approach properly handles both the exact-size and overflow cases while ensuring the correct chunk size is returned.\n```suggestion\n            if (this.max_size) |*max_size| {\n                if (chunk_.len >= max_size.*) {\n                    const limited_chunk = chunk_[0..max_size.*];\n                    max_size.* = 0;\n                    break :brk .{ limited_chunk, .eof };\n                } else {\n                    max_size.* -= chunk_.len;\n                    break :brk .{ chunk_, state_ };\n                }\n```\n  \n\n*Spotted by [Diamond](https://app.graphite.dev/diamond/?org=oven-sh&ref=ai-review-comment)*<i class='graphite__hidden'><br /><br />Is this helpful? React \ud83d\udc4d or \ud83d\udc4e to let us know.</i>",
        "pr_file_module": null
      }
    ]
  }
]