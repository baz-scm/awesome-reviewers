[
  {
    "discussion_id": "1869261088",
    "pr_number": 6889,
    "pr_file": "checkov/secrets/plugins/detector_utils.py",
    "created_at": "2024-12-04T11:11:23+00:00",
    "commented_code": "MAX_KEYWORD_LIMIT = 500\n \n-B64_FP_REGEX = re.compile(r'\\b[A-Za-z]+_+[A-Za-z_]*[A-Za-z]\\b')\n+B64_FP_REGEX = re.compile(r'\\b[A-Za-z]+_+[A-Za-z_]*[A-Za-z]\\b|(?:\\s|=|:)([a-z]+[0-9]?[a-z]*-)+[a-z]+\\b')",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1869261088",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 6889,
        "pr_file": "checkov/secrets/plugins/detector_utils.py",
        "discussion_id": "1869261088",
        "commented_code": "@@ -26,7 +26,7 @@\n \n MAX_KEYWORD_LIMIT = 500\n \n-B64_FP_REGEX = re.compile(r'\\b[A-Za-z]+_+[A-Za-z_]*[A-Za-z]\\b')\n+B64_FP_REGEX = re.compile(r'\\b[A-Za-z]+_+[A-Za-z_]*[A-Za-z]\\b|(?:\\s|=|:)([a-z]+[0-9]?[a-z]*-)+[a-z]+\\b')",
        "comment_created_at": "2024-12-04T11:11:23+00:00",
        "comment_author": "github-advanced-security[bot]",
        "comment_body": "## Inefficient regular expression\n\nThis part of the regular expression may cause exponential backtracking on strings starting with '\\\\t' and containing many repetitions of 'aa-'.\n\n[Show more details](https://github.com/bridgecrewio/checkov/security/code-scanning/119)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1848248753",
    "pr_number": 6854,
    "pr_file": "checkov/secrets/plugins/custom_regex_detector.py",
    "created_at": "2024-11-19T12:17:46+00:00",
    "commented_code": "yield submatch, regex\n                 else:\n                     yield match, regex\n+\n+\n+def find_line_number(file_string: str, substring: str, default_line_number: int) -> int:",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1848248753",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 6854,
        "pr_file": "checkov/secrets/plugins/custom_regex_detector.py",
        "discussion_id": "1848248753",
        "commented_code": "@@ -216,3 +216,12 @@ def analyze_string(self, string: str, **kwargs: Optional[Dict[str, Any]]) -> Gen\n                         yield submatch, regex\n                 else:\n                     yield match, regex\n+\n+\n+def find_line_number(file_string: str, substring: str, default_line_number: int) -> int:",
        "comment_created_at": "2024-11-19T12:17:46+00:00",
        "comment_author": "omryMen",
        "comment_body": "this goes over the entire file which can be big\r\ninstead we can start from the line number and stop when the string contains the secret",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1624172112",
    "pr_number": 6390,
    "pr_file": "checkov/secrets/runner.py",
    "created_at": "2024-06-03T10:13:16+00:00",
    "commented_code": "}\n \n ENTROPY_CHECK_IDS = ('CKV_SECRET_6', 'CKV_SECRET_19', 'CKV_SECRET_80')\n+GENERIC_PRIVATE_KEY_CHECK_IDS = ('CKV_SECRET_10', 'CKV_SECRET_13')",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1624172112",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 6390,
        "pr_file": "checkov/secrets/runner.py",
        "discussion_id": "1624172112",
        "commented_code": "@@ -74,6 +74,7 @@\n }\n \n ENTROPY_CHECK_IDS = ('CKV_SECRET_6', 'CKV_SECRET_19', 'CKV_SECRET_80')\n+GENERIC_PRIVATE_KEY_CHECK_IDS = ('CKV_SECRET_10', 'CKV_SECRET_13')",
        "comment_created_at": "2024-06-03T10:13:16+00:00",
        "comment_author": "omryMen",
        "comment_body": "you can change this to set instead of tuple",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1269416216",
    "pr_number": 5362,
    "pr_file": "checkov/terraform/tf_parser.py",
    "created_at": "2023-07-20T12:51:33+00:00",
    "commented_code": "return module, tf_definitions\n \n+    '''\n+    This function is similar to parse_hcl_module, except that it creates a list of tuples instead of a single tuple.\n+    The objective is to create a collection of TF definitions based on directory, instead of a single big structure.\n+    This will allow us to boost performance by running on several smaller objects rather than one.\n+    '''\n+    def parse_multi_graph_hcl_module(\n+        self,\n+        source_dir: str,\n+        source: str,\n+        download_external_modules: bool = False,\n+        external_modules_download_path: str = DEFAULT_EXTERNAL_MODULES_DIR,\n+        parsing_errors: dict[str, Exception] | None = None,\n+        excluded_paths: list[str] | None = None,\n+        vars_files: list[str] | None = None,\n+        external_modules_content_cache: dict[str, ModuleContent | None] | None = None,\n+        create_graph: bool = True,\n+    ) -> list[tuple[Module, list[dict[TFDefinitionKey, dict[str, Any]]]]]:\n+        tf_definitions = self.parse_directory(\n+            directory=source_dir, out_evaluations_context={},\n+            out_parsing_errors=parsing_errors if parsing_errors is not None else {},\n+            download_external_modules=download_external_modules,\n+            external_modules_download_path=external_modules_download_path, excluded_paths=excluded_paths,\n+            vars_files=vars_files, external_modules_content_cache=external_modules_content_cache\n+        )\n+        tf_definitions = clean_parser_types(tf_definitions)\n+        tf_definitions = serialize_definitions(tf_definitions)\n+\n+        dirs_to_definitions = self.create_definition_by_dirs(tf_definitions)\n+\n+        modules_and_definitions_tuple: list[tuple[Module, list[dict[TFDefinitionKey, dict[str, Any]]]]] = []\n+        if create_graph:\n+            for source_path, definitions in dirs_to_definitions.items():\n+                module, parsed_tf_definitions = self.parse_hcl_module_from_multi_tf_definitions(definitions, source_path, source)\n+                modules_and_definitions_tuple.append((module, parsed_tf_definitions))\n+\n+        return modules_and_definitions_tuple\n+\n+    def create_definition_by_dirs(self, tf_definitions: dict[TFDefinitionKey, dict[str, list[dict[str, Any]]]]\n+                                  ) -> dict[str, list[dict[TFDefinitionKey, dict[str, Any]]]]:\n+        dirs_to_definitions: dict[str, list[dict[TFDefinitionKey, dict[str, Any]]]] = {}\n+        for tf_definition_key, tf_value in tf_definitions.items():\n+            source_module = tf_definition_key.tf_source_modules\n+            if source_module is None:\n+                # No module - add new entry to dirs_to_definitions with the path as key\n+                dir_path = os.path.dirname(tf_definition_key.file_path)\n+                if dir_path in dirs_to_definitions:\n+                    dirs_to_definitions[dir_path].append({tf_definition_key: tf_value})\n+                else:\n+                    dirs_to_definitions[dir_path] = [{tf_definition_key: tf_value}]",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1269416216",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5362,
        "pr_file": "checkov/terraform/tf_parser.py",
        "discussion_id": "1269416216",
        "commented_code": "@@ -329,6 +330,67 @@ def parse_hcl_module(\n \n         return module, tf_definitions\n \n+    '''\n+    This function is similar to parse_hcl_module, except that it creates a list of tuples instead of a single tuple.\n+    The objective is to create a collection of TF definitions based on directory, instead of a single big structure.\n+    This will allow us to boost performance by running on several smaller objects rather than one.\n+    '''\n+    def parse_multi_graph_hcl_module(\n+        self,\n+        source_dir: str,\n+        source: str,\n+        download_external_modules: bool = False,\n+        external_modules_download_path: str = DEFAULT_EXTERNAL_MODULES_DIR,\n+        parsing_errors: dict[str, Exception] | None = None,\n+        excluded_paths: list[str] | None = None,\n+        vars_files: list[str] | None = None,\n+        external_modules_content_cache: dict[str, ModuleContent | None] | None = None,\n+        create_graph: bool = True,\n+    ) -> list[tuple[Module, list[dict[TFDefinitionKey, dict[str, Any]]]]]:\n+        tf_definitions = self.parse_directory(\n+            directory=source_dir, out_evaluations_context={},\n+            out_parsing_errors=parsing_errors if parsing_errors is not None else {},\n+            download_external_modules=download_external_modules,\n+            external_modules_download_path=external_modules_download_path, excluded_paths=excluded_paths,\n+            vars_files=vars_files, external_modules_content_cache=external_modules_content_cache\n+        )\n+        tf_definitions = clean_parser_types(tf_definitions)\n+        tf_definitions = serialize_definitions(tf_definitions)\n+\n+        dirs_to_definitions = self.create_definition_by_dirs(tf_definitions)\n+\n+        modules_and_definitions_tuple: list[tuple[Module, list[dict[TFDefinitionKey, dict[str, Any]]]]] = []\n+        if create_graph:\n+            for source_path, definitions in dirs_to_definitions.items():\n+                module, parsed_tf_definitions = self.parse_hcl_module_from_multi_tf_definitions(definitions, source_path, source)\n+                modules_and_definitions_tuple.append((module, parsed_tf_definitions))\n+\n+        return modules_and_definitions_tuple\n+\n+    def create_definition_by_dirs(self, tf_definitions: dict[TFDefinitionKey, dict[str, list[dict[str, Any]]]]\n+                                  ) -> dict[str, list[dict[TFDefinitionKey, dict[str, Any]]]]:\n+        dirs_to_definitions: dict[str, list[dict[TFDefinitionKey, dict[str, Any]]]] = {}\n+        for tf_definition_key, tf_value in tf_definitions.items():\n+            source_module = tf_definition_key.tf_source_modules\n+            if source_module is None:\n+                # No module - add new entry to dirs_to_definitions with the path as key\n+                dir_path = os.path.dirname(tf_definition_key.file_path)\n+                if dir_path in dirs_to_definitions:\n+                    dirs_to_definitions[dir_path].append({tf_definition_key: tf_value})\n+                else:\n+                    dirs_to_definitions[dir_path] = [{tf_definition_key: tf_value}]",
        "comment_created_at": "2023-07-20T12:51:33+00:00",
        "comment_author": "gruebel",
        "comment_body": "you could also create a `defaultdict`, then you don't have to this check manually \r\n```python\r\ndirs_to_definitions = defaultdict(list)\r\ndirs_to_definitions[dir_path].append({tf_definition_key: tf_value})\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1264682501",
    "pr_number": 5339,
    "pr_file": "checkov/kubernetes/image_referencer/provider/k8s.py",
    "created_at": "2023-07-16T13:13:31+00:00",
    "commented_code": "return image_names\n \n \n+def _extract_images_from_spec(spec: dict[str, Any]) -> list[str]:\n+    image_names: list[str] = []",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1264682501",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5339,
        "pr_file": "checkov/kubernetes/image_referencer/provider/k8s.py",
        "discussion_id": "1264682501",
        "commented_code": "@@ -90,6 +54,20 @@ def extract_images_from_containers(containers: Any) -> list[str]:\n     return image_names\n \n \n+def _extract_images_from_spec(spec: dict[str, Any]) -> list[str]:\n+    image_names: list[str] = []",
        "comment_created_at": "2023-07-16T13:13:31+00:00",
        "comment_author": "gruebel",
        "comment_body": "how about making this a `set()` then you don't need to transform it to a set and back to list \ud83d\ude42 ",
        "pr_file_module": null
      },
      {
        "comment_id": "1264683680",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5339,
        "pr_file": "checkov/kubernetes/image_referencer/provider/k8s.py",
        "discussion_id": "1264682501",
        "commented_code": "@@ -90,6 +54,20 @@ def extract_images_from_containers(containers: Any) -> list[str]:\n     return image_names\n \n \n+def _extract_images_from_spec(spec: dict[str, Any]) -> list[str]:\n+    image_names: list[str] = []",
        "comment_created_at": "2023-07-16T13:20:55+00:00",
        "comment_author": "bo156",
        "comment_body": "good idea - fixed",
        "pr_file_module": null
      },
      {
        "comment_id": "1264686559",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5339,
        "pr_file": "checkov/kubernetes/image_referencer/provider/k8s.py",
        "discussion_id": "1264682501",
        "commented_code": "@@ -90,6 +54,20 @@ def extract_images_from_containers(containers: Any) -> list[str]:\n     return image_names\n \n \n+def _extract_images_from_spec(spec: dict[str, Any]) -> list[str]:\n+    image_names: list[str] = []",
        "comment_created_at": "2023-07-16T13:38:16+00:00",
        "comment_author": "omryMen",
        "comment_body": "maybe all of the functions here can return sets ? ",
        "pr_file_module": null
      },
      {
        "comment_id": "1264693099",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5339,
        "pr_file": "checkov/kubernetes/image_referencer/provider/k8s.py",
        "discussion_id": "1264682501",
        "commented_code": "@@ -90,6 +54,20 @@ def extract_images_from_containers(containers: Any) -> list[str]:\n     return image_names\n \n \n+def _extract_images_from_spec(spec: dict[str, Any]) -> list[str]:\n+    image_names: list[str] = []",
        "comment_created_at": "2023-07-16T14:22:11+00:00",
        "comment_author": "gruebel",
        "comment_body": "also thought the same, but I think it is a bigger change, because of the typing mismatch.",
        "pr_file_module": null
      },
      {
        "comment_id": "1264714102",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5339,
        "pr_file": "checkov/kubernetes/image_referencer/provider/k8s.py",
        "discussion_id": "1264682501",
        "commented_code": "@@ -90,6 +54,20 @@ def extract_images_from_containers(containers: Any) -> list[str]:\n     return image_names\n \n \n+def _extract_images_from_spec(spec: dict[str, Any]) -> list[str]:\n+    image_names: list[str] = []",
        "comment_created_at": "2023-07-16T16:54:42+00:00",
        "comment_author": "bo156",
        "comment_body": "Just didn't watch to change api",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1215615242",
    "pr_number": 5112,
    "pr_file": "checkov/terraform/plan_parser.py",
    "created_at": "2023-06-03T15:41:15+00:00",
    "commented_code": "\"\"\"Returns a resource address to resource changes dict\"\"\"\n \n     resource_changes_map = {}\n-\n     resource_changes = template.get(\"resource_changes\")\n-    if resource_changes and isinstance(resource_changes, list):\n-        resource_changes_map = {\n-            change.get(\"address\", \"\"): change\n-            for change in resource_changes\n-        }\n \n+    if resource_changes and isinstance(resource_changes, list):\n+        for each in resource_changes:\n+            resource_changes_map[each[\"address\"]] = each\n+            changes = []\n+\n+            # before + after are None when resources are created/destroyed, so make them safe\n+            if not each[\"change\"][\"before\"]:\n+                each[\"change\"][\"before\"] = {}\n+            if not each[\"change\"][\"after\"]:\n+                each[\"change\"][\"after\"] = {}\n+\n+            for field in each[\"change\"][\"before\"]:\n+                if each[\"change\"][\"before\"][field] != each[\"change\"][\"after\"].get(field):",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1215615242",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5112,
        "pr_file": "checkov/terraform/plan_parser.py",
        "discussion_id": "1215615242",
        "commented_code": "@@ -238,14 +239,24 @@ def _get_resource_changes(template: dict[str, Any]) -> dict[str, dict[str, Any]]\n     \"\"\"Returns a resource address to resource changes dict\"\"\"\n \n     resource_changes_map = {}\n-\n     resource_changes = template.get(\"resource_changes\")\n-    if resource_changes and isinstance(resource_changes, list):\n-        resource_changes_map = {\n-            change.get(\"address\", \"\"): change\n-            for change in resource_changes\n-        }\n \n+    if resource_changes and isinstance(resource_changes, list):\n+        for each in resource_changes:\n+            resource_changes_map[each[\"address\"]] = each\n+            changes = []\n+\n+            # before + after are None when resources are created/destroyed, so make them safe\n+            if not each[\"change\"][\"before\"]:\n+                each[\"change\"][\"before\"] = {}\n+            if not each[\"change\"][\"after\"]:\n+                each[\"change\"][\"after\"] = {}\n+\n+            for field in each[\"change\"][\"before\"]:\n+                if each[\"change\"][\"before\"][field] != each[\"change\"][\"after\"].get(field):",
        "comment_created_at": "2023-06-03T15:41:15+00:00",
        "comment_author": "gruebel",
        "comment_body": "```suggestion\r\n            for field, value in each[\"change\"][\"before\"].items():\r\n                if value != each[\"change\"][\"after\"].get(field):\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1215615444",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5112,
        "pr_file": "checkov/terraform/plan_parser.py",
        "discussion_id": "1215615242",
        "commented_code": "@@ -238,14 +239,24 @@ def _get_resource_changes(template: dict[str, Any]) -> dict[str, dict[str, Any]]\n     \"\"\"Returns a resource address to resource changes dict\"\"\"\n \n     resource_changes_map = {}\n-\n     resource_changes = template.get(\"resource_changes\")\n-    if resource_changes and isinstance(resource_changes, list):\n-        resource_changes_map = {\n-            change.get(\"address\", \"\"): change\n-            for change in resource_changes\n-        }\n \n+    if resource_changes and isinstance(resource_changes, list):\n+        for each in resource_changes:\n+            resource_changes_map[each[\"address\"]] = each\n+            changes = []\n+\n+            # before + after are None when resources are created/destroyed, so make them safe\n+            if not each[\"change\"][\"before\"]:\n+                each[\"change\"][\"before\"] = {}\n+            if not each[\"change\"][\"after\"]:\n+                each[\"change\"][\"after\"] = {}\n+\n+            for field in each[\"change\"][\"before\"]:\n+                if each[\"change\"][\"before\"][field] != each[\"change\"][\"after\"].get(field):",
        "comment_created_at": "2023-06-03T15:42:03+00:00",
        "comment_author": "gruebel",
        "comment_body": "also make sure to skip the field names `__startline__` and `__endline__`, there is aconstant `LINE_FIELD_NAMES` which stores them as a set.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1189348703",
    "pr_number": 5068,
    "pr_file": "checkov/secrets/runner.py",
    "created_at": "2023-05-10T04:34:51+00:00",
    "commented_code": "policies_list = customer_run_config.get('secretsPolicies', [])\n             suppressions = customer_run_config.get('suppressions', [])\n             if suppressions:\n-                secret_suppressions_id = [suppression['checkovPolicyId'] for suppression in suppressions if suppression['suppressionType'] == 'SecretsPolicy']\n+                secret_suppressions_id = [suppression['policyId'] for suppression in suppressions if suppression['suppressionType'] == 'SecretsPolicy']",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1189348703",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5068,
        "pr_file": "checkov/secrets/runner.py",
        "discussion_id": "1189348703",
        "commented_code": "@@ -134,7 +134,7 @@ def run(\n             policies_list = customer_run_config.get('secretsPolicies', [])\n             suppressions = customer_run_config.get('suppressions', [])\n             if suppressions:\n-                secret_suppressions_id = [suppression['checkovPolicyId'] for suppression in suppressions if suppression['suppressionType'] == 'SecretsPolicy']\n+                secret_suppressions_id = [suppression['policyId'] for suppression in suppressions if suppression['suppressionType'] == 'SecretsPolicy']",
        "comment_created_at": "2023-05-10T04:34:51+00:00",
        "comment_author": "omryMen",
        "comment_body": "can this be a set instead of list ?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1183295971",
    "pr_number": 5021,
    "pr_file": "checkov/terraform/graph_builder/local_graph.py",
    "created_at": "2023-05-03T06:48:44+00:00",
    "commented_code": "self._create_edge(target_variable, origin_node_index, \"default\", cross_variable_edges)\n         elif vertex.block_type == BlockType.TF_VARIABLE:\n             # Assuming the tfvars file is in the same directory as the variables file (best practice)\n-            target_variables = [\n-                index\n-                for index in self.vertices_block_name_map.get(BlockType.VARIABLE, {}).get(vertex.name, [])\n-                if self.get_dirname(self.vertices[index].path) == self.get_dirname(vertex.path)\n-            ]\n-            if len(target_variables) == 1:\n-                self._create_edge(target_variables[0], origin_node_index, \"default\", cross_variable_edges)\n+            target_variable = 0\n+            for index in self.vertices_block_name_map.get(BlockType.VARIABLE, {}).get(vertex.name, []):\n+                if self.get_dirname(self.vertices[index].path) == self.get_dirname(vertex.path):\n+                    target_variable = index\n+                    break\n+            if target_variable:\n+                self._create_edge(target_variable, origin_node_index, \"default\", cross_variable_edges)",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1183295971",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5021,
        "pr_file": "checkov/terraform/graph_builder/local_graph.py",
        "discussion_id": "1183295971",
        "commented_code": "@@ -287,13 +287,13 @@ def _build_edges_for_vertex(self, origin_node_index: int, vertex: TerraformBlock\n                     self._create_edge(target_variable, origin_node_index, \"default\", cross_variable_edges)\n         elif vertex.block_type == BlockType.TF_VARIABLE:\n             # Assuming the tfvars file is in the same directory as the variables file (best practice)\n-            target_variables = [\n-                index\n-                for index in self.vertices_block_name_map.get(BlockType.VARIABLE, {}).get(vertex.name, [])\n-                if self.get_dirname(self.vertices[index].path) == self.get_dirname(vertex.path)\n-            ]\n-            if len(target_variables) == 1:\n-                self._create_edge(target_variables[0], origin_node_index, \"default\", cross_variable_edges)\n+            target_variable = 0\n+            for index in self.vertices_block_name_map.get(BlockType.VARIABLE, {}).get(vertex.name, []):\n+                if self.get_dirname(self.vertices[index].path) == self.get_dirname(vertex.path):\n+                    target_variable = index\n+                    break\n+            if target_variable:\n+                self._create_edge(target_variable, origin_node_index, \"default\", cross_variable_edges)",
        "comment_created_at": "2023-05-03T06:48:44+00:00",
        "comment_author": "gruebel",
        "comment_body": "just double checking, this has no bad side effect, because we would create more often edges, right?",
        "pr_file_module": null
      },
      {
        "comment_id": "1183299879",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5021,
        "pr_file": "checkov/terraform/graph_builder/local_graph.py",
        "discussion_id": "1183295971",
        "commented_code": "@@ -287,13 +287,13 @@ def _build_edges_for_vertex(self, origin_node_index: int, vertex: TerraformBlock\n                     self._create_edge(target_variable, origin_node_index, \"default\", cross_variable_edges)\n         elif vertex.block_type == BlockType.TF_VARIABLE:\n             # Assuming the tfvars file is in the same directory as the variables file (best practice)\n-            target_variables = [\n-                index\n-                for index in self.vertices_block_name_map.get(BlockType.VARIABLE, {}).get(vertex.name, [])\n-                if self.get_dirname(self.vertices[index].path) == self.get_dirname(vertex.path)\n-            ]\n-            if len(target_variables) == 1:\n-                self._create_edge(target_variables[0], origin_node_index, \"default\", cross_variable_edges)\n+            target_variable = 0\n+            for index in self.vertices_block_name_map.get(BlockType.VARIABLE, {}).get(vertex.name, []):\n+                if self.get_dirname(self.vertices[index].path) == self.get_dirname(vertex.path):\n+                    target_variable = index\n+                    break\n+            if target_variable:\n+                self._create_edge(target_variable, origin_node_index, \"default\", cross_variable_edges)",
        "comment_created_at": "2023-05-03T06:53:52+00:00",
        "comment_author": "ChanochShayner",
        "comment_body": "Why we will create more often edges?\r\nIf we are looking for one specific target variable we can stop the iteration.",
        "pr_file_module": null
      },
      {
        "comment_id": "1183339869",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5021,
        "pr_file": "checkov/terraform/graph_builder/local_graph.py",
        "discussion_id": "1183295971",
        "commented_code": "@@ -287,13 +287,13 @@ def _build_edges_for_vertex(self, origin_node_index: int, vertex: TerraformBlock\n                     self._create_edge(target_variable, origin_node_index, \"default\", cross_variable_edges)\n         elif vertex.block_type == BlockType.TF_VARIABLE:\n             # Assuming the tfvars file is in the same directory as the variables file (best practice)\n-            target_variables = [\n-                index\n-                for index in self.vertices_block_name_map.get(BlockType.VARIABLE, {}).get(vertex.name, [])\n-                if self.get_dirname(self.vertices[index].path) == self.get_dirname(vertex.path)\n-            ]\n-            if len(target_variables) == 1:\n-                self._create_edge(target_variables[0], origin_node_index, \"default\", cross_variable_edges)\n+            target_variable = 0\n+            for index in self.vertices_block_name_map.get(BlockType.VARIABLE, {}).get(vertex.name, []):\n+                if self.get_dirname(self.vertices[index].path) == self.get_dirname(vertex.path):\n+                    target_variable = index\n+                    break\n+            if target_variable:\n+                self._create_edge(target_variable, origin_node_index, \"default\", cross_variable_edges)",
        "comment_created_at": "2023-05-03T07:40:45+00:00",
        "comment_author": "gruebel",
        "comment_body": "if we for some reason get more than 1 `target_variables`, we didn't create an edge before and just continued. If the tests are passing, then it is probably not an issue \ud83d\ude04 ",
        "pr_file_module": null
      }
    ]
  }
]