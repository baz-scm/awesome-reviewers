[
  {
    "discussion_id": "2134636730",
    "pr_number": 7111,
    "pr_file": "checkov/terraform/module_loading/module_finder.py",
    "created_at": "2025-06-08T11:23:16+00:00",
    "commented_code": "def find_modules(path: str) -> List[ModuleDownload]:\n     modules_found: list[ModuleDownload] = []\n \n+    # Leverage modules.json to better inform discovery. If we have this,\n+    # there should be no need to walk and gather modules\n+    if env_vars_config.CHECKOV_EXPERIMENTAL_TERRAFORM_MANAGED_MODULES:",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "2134636730",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 7111,
        "pr_file": "checkov/terraform/module_loading/module_finder.py",
        "discussion_id": "2134636730",
        "commented_code": "@@ -36,6 +36,22 @@ def __str__(self) -> str:\n def find_modules(path: str) -> List[ModuleDownload]:\n     modules_found: list[ModuleDownload] = []\n \n+    # Leverage modules.json to better inform discovery. If we have this,\n+    # there should be no need to walk and gather modules\n+    if env_vars_config.CHECKOV_EXPERIMENTAL_TERRAFORM_MANAGED_MODULES:",
        "comment_created_at": "2025-06-08T11:23:16+00:00",
        "comment_author": "lirshindalman",
        "comment_body": "Please consider extracting this logic into a separate function for better readability\r\n\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2134665093",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 7111,
        "pr_file": "checkov/terraform/module_loading/module_finder.py",
        "discussion_id": "2134636730",
        "commented_code": "@@ -36,6 +36,22 @@ def __str__(self) -> str:\n def find_modules(path: str) -> List[ModuleDownload]:\n     modules_found: list[ModuleDownload] = []\n \n+    # Leverage modules.json to better inform discovery. If we have this,\n+    # there should be no need to walk and gather modules\n+    if env_vars_config.CHECKOV_EXPERIMENTAL_TERRAFORM_MANAGED_MODULES:",
        "comment_created_at": "2025-06-08T12:19:27+00:00",
        "comment_author": "thentenaar",
        "comment_body": "Done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2106139276",
    "pr_number": 7180,
    "pr_file": "checkov/terraform/plan_utils.py",
    "created_at": "2025-05-25T09:23:10+00:00",
    "commented_code": "continue\n         resource_name = definition_path[1]\n         resource_definition = resource_type_dict.get(resource_name, resource_type_dict)\n-        if resource_definition and resource_definition.get(TF_PLAN_RESOURCE_ADDRESS) == entity_id:\n+        if not isinstance(resource_definition, dict):\n+            entity_context['start_line'] = resource_type_dict['start_line'][0]\n+            entity_context['end_line'] = resource_type_dict['end_line'][0]\n+            entity_context[\"code_lines\"] = definitions_raw[full_file_path][\n+                entity_context[\"start_line\"]: entity_context[\"end_line\"]\n+            ]\n+            entity_context['address'] = resource_type_dict[TF_PLAN_RESOURCE_ADDRESS]\n+            return entity_context",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "2106139276",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 7180,
        "pr_file": "checkov/terraform/plan_utils.py",
        "discussion_id": "2106139276",
        "commented_code": "@@ -116,7 +127,15 @@ def get_entity_context(\n             continue\n         resource_name = definition_path[1]\n         resource_definition = resource_type_dict.get(resource_name, resource_type_dict)\n-        if resource_definition and resource_definition.get(TF_PLAN_RESOURCE_ADDRESS) == entity_id:\n+        if not isinstance(resource_definition, dict):\n+            entity_context['start_line'] = resource_type_dict['start_line'][0]\n+            entity_context['end_line'] = resource_type_dict['end_line'][0]\n+            entity_context[\"code_lines\"] = definitions_raw[full_file_path][\n+                entity_context[\"start_line\"]: entity_context[\"end_line\"]\n+            ]\n+            entity_context['address'] = resource_type_dict[TF_PLAN_RESOURCE_ADDRESS]\n+            return entity_context",
        "comment_created_at": "2025-05-25T09:23:10+00:00",
        "comment_author": "maxamel",
        "comment_body": "Seems this logic is identical to the one we're running in the \"elif\" clause, can you extract that into a function and use it from both clauses ?",
        "pr_file_module": null
      },
      {
        "comment_id": "2106141676",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 7180,
        "pr_file": "checkov/terraform/plan_utils.py",
        "discussion_id": "2106139276",
        "commented_code": "@@ -116,7 +127,15 @@ def get_entity_context(\n             continue\n         resource_name = definition_path[1]\n         resource_definition = resource_type_dict.get(resource_name, resource_type_dict)\n-        if resource_definition and resource_definition.get(TF_PLAN_RESOURCE_ADDRESS) == entity_id:\n+        if not isinstance(resource_definition, dict):\n+            entity_context['start_line'] = resource_type_dict['start_line'][0]\n+            entity_context['end_line'] = resource_type_dict['end_line'][0]\n+            entity_context[\"code_lines\"] = definitions_raw[full_file_path][\n+                entity_context[\"start_line\"]: entity_context[\"end_line\"]\n+            ]\n+            entity_context['address'] = resource_type_dict[TF_PLAN_RESOURCE_ADDRESS]\n+            return entity_context",
        "comment_created_at": "2025-05-25T09:32:50+00:00",
        "comment_author": "omriyoffe-panw",
        "comment_body": "Done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1991772609",
    "pr_number": 7047,
    "pr_file": "checkov/terraform/graph_builder/foreach/foreach_entity_handler.py",
    "created_at": "2025-03-12T15:35:48+00:00",
    "commented_code": "def _create_new_resources_count(self, statement: int, block_idx: int) -> None:\n         main_resource = self.local_graph.vertices[block_idx]\n+        virtual_resources_names = []\n         for i in range(statement):\n-            self._create_new_resource(main_resource, i, resource_idx=block_idx, foreach_idx=i)\n+            virtual_resource_name = self._create_new_resource(main_resource, i, resource_idx=block_idx, foreach_idx=i)",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1991772609",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 7047,
        "pr_file": "checkov/terraform/graph_builder/foreach/foreach_entity_handler.py",
        "discussion_id": "1991772609",
        "commented_code": "@@ -63,12 +64,18 @@ def _handle_dynamic_statement(self, blocks_to_render: list[int]) -> FOR_EACH_BLO\n \n     def _create_new_resources_count(self, statement: int, block_idx: int) -> None:\n         main_resource = self.local_graph.vertices[block_idx]\n+        virtual_resources_names = []\n         for i in range(statement):\n-            self._create_new_resource(main_resource, i, resource_idx=block_idx, foreach_idx=i)\n+            virtual_resource_name = self._create_new_resource(main_resource, i, resource_idx=block_idx, foreach_idx=i)",
        "comment_created_at": "2025-03-12T15:35:48+00:00",
        "comment_author": "bo156",
        "comment_body": "looks like an almost identical copy of a previous usage, please extract to function",
        "pr_file_module": null
      },
      {
        "comment_id": "1998469154",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 7047,
        "pr_file": "checkov/terraform/graph_builder/foreach/foreach_entity_handler.py",
        "discussion_id": "1991772609",
        "commented_code": "@@ -63,12 +64,18 @@ def _handle_dynamic_statement(self, blocks_to_render: list[int]) -> FOR_EACH_BLO\n \n     def _create_new_resources_count(self, statement: int, block_idx: int) -> None:\n         main_resource = self.local_graph.vertices[block_idx]\n+        virtual_resources_names = []\n         for i in range(statement):\n-            self._create_new_resource(main_resource, i, resource_idx=block_idx, foreach_idx=i)\n+            virtual_resource_name = self._create_new_resource(main_resource, i, resource_idx=block_idx, foreach_idx=i)",
        "comment_created_at": "2025-03-17T10:45:58+00:00",
        "comment_author": "omriyoffe-panw",
        "comment_body": "Done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1991779487",
    "pr_number": 7047,
    "pr_file": "checkov/terraform/graph_builder/local_graph.py",
    "created_at": "2025-03-12T15:39:25+00:00",
    "commented_code": "if target_variable:\n                 self.create_edge(target_variable, origin_node_index, \"default\", cross_variable_edges)\n \n+        if \"virtual_resources\" in vertex.config:\n+            for i, v in enumerate(self.vertices):\n+                if v.name in vertex.config[\"virtual_resources\"]:\n+                    self.create_edge(i, origin_node_index, \"virtual_resource\")",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1991779487",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 7047,
        "pr_file": "checkov/terraform/graph_builder/local_graph.py",
        "discussion_id": "1991779487",
        "commented_code": "@@ -377,6 +377,11 @@ def _build_edges_for_vertex(self, origin_node_index: int, vertex: TerraformBlock\n             if target_variable:\n                 self.create_edge(target_variable, origin_node_index, \"default\", cross_variable_edges)\n \n+        if \"virtual_resources\" in vertex.config:\n+            for i, v in enumerate(self.vertices):\n+                if v.name in vertex.config[\"virtual_resources\"]:\n+                    self.create_edge(i, origin_node_index, \"virtual_resource\")",
        "comment_created_at": "2025-03-12T15:39:25+00:00",
        "comment_author": "bo156",
        "comment_body": "1. do we have a const for edge label? if yes use it, if not just create a const for this str.\r\n2. extract it to a function called `create_virtual_resources_edges`, which can be called from the `create_edges` function as well",
        "pr_file_module": null
      },
      {
        "comment_id": "1998478258",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 7047,
        "pr_file": "checkov/terraform/graph_builder/local_graph.py",
        "discussion_id": "1991779487",
        "commented_code": "@@ -377,6 +377,11 @@ def _build_edges_for_vertex(self, origin_node_index: int, vertex: TerraformBlock\n             if target_variable:\n                 self.create_edge(target_variable, origin_node_index, \"default\", cross_variable_edges)\n \n+        if \"virtual_resources\" in vertex.config:\n+            for i, v in enumerate(self.vertices):\n+                if v.name in vertex.config[\"virtual_resources\"]:\n+                    self.create_edge(i, origin_node_index, \"virtual_resource\")",
        "comment_created_at": "2025-03-17T10:51:19+00:00",
        "comment_author": "omriyoffe-panw",
        "comment_body": "Done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1978999430",
    "pr_number": 7032,
    "pr_file": "checkov/terraform/base_runner.py",
    "created_at": "2025-03-04T09:29:50+00:00",
    "commented_code": "resource_registry.load_external_checks(directory)\n                 self.graph_registry.load_external_checks(directory)\n \n-    def get_connected_node(self, entity: dict[str, Any], root_folder: str) -> Optional[Dict[str, Any]]:\n-        connected_entity = entity.get(\"connected_node\")\n-        if not connected_entity:\n+    def _get_connected_node_data(self, connected_nodes_per_resource_types: dict[tuple[str], Any], root_folder: str,\n+                                 connected_resource_types: list[tuple[str]]) -> Optional[Dict[str, Any]]:\n+        if not connected_resource_types or not connected_nodes_per_resource_types:\n             return None\n+        existing_tuple = next((item for item in connected_resource_types if item in connected_nodes_per_resource_types), None)",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1978999430",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 7032,
        "pr_file": "checkov/terraform/base_runner.py",
        "discussion_id": "1978999430",
        "commented_code": "@@ -106,10 +107,14 @@ def load_external_checks(self, external_checks_dir: list[str] | None) -> None:\n                 resource_registry.load_external_checks(directory)\n                 self.graph_registry.load_external_checks(directory)\n \n-    def get_connected_node(self, entity: dict[str, Any], root_folder: str) -> Optional[Dict[str, Any]]:\n-        connected_entity = entity.get(\"connected_node\")\n-        if not connected_entity:\n+    def _get_connected_node_data(self, connected_nodes_per_resource_types: dict[tuple[str], Any], root_folder: str,\n+                                 connected_resource_types: list[tuple[str]]) -> Optional[Dict[str, Any]]:\n+        if not connected_resource_types or not connected_nodes_per_resource_types:\n             return None\n+        existing_tuple = next((item for item in connected_resource_types if item in connected_nodes_per_resource_types), None)",
        "comment_created_at": "2025-03-04T09:29:50+00:00",
        "comment_author": "bo156",
        "comment_body": "can you extract this one-liner to a function to make it more readable? \r\nalso `existing_tuple` is an unclear name",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1536812809",
    "pr_number": 6109,
    "pr_file": "checkov/common/bridgecrew/integration_features/features/suppressions_integration.py",
    "created_at": "2024-03-24T13:10:15+00:00",
    "commented_code": "return False\n \n+    def _check_suppression_v2(self, record: Record, suppression: dict[str, Any]) -> bool:\n+        if record.check_id not in suppression['checkovPolicyIds']:\n+            return False\n+\n+        type = suppression['ruleType']\n+\n+        if type == 'policy':  # TODO policy suppression not supported via UI yet but we just need to set the correct type value here\n+            # We just checked the policy ID above\n+            return True\n+        elif type == 'finding':\n+            pass  # TODO how to map them?\n+        elif type == 'file':\n+            record_file_path = record.repo_file_path if record.repo_file_path.startswith('/') else f'/{record.repo_file_path}'\n+            for file_suppression in suppression['files']:\n+                suppression_file_path = file_suppression['filePath']\n+                suppression_file_path = suppression_file_path if suppression_file_path.startswith('/') else f'/{suppression_file_path}'\n+                if self.bc_integration.repo_matches(file_suppression['repositoryName']) \\\n+                        and (suppression_file_path == record_file_path\n+                             or suppression_file_path == convert_to_unix_path(record_file_path)):",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1536812809",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 6109,
        "pr_file": "checkov/common/bridgecrew/integration_features/features/suppressions_integration.py",
        "discussion_id": "1536812809",
        "commented_code": "@@ -186,6 +226,30 @@ def _check_suppression(self, record: Record, suppression: dict[str, Any]) -> boo\n \n         return False\n \n+    def _check_suppression_v2(self, record: Record, suppression: dict[str, Any]) -> bool:\n+        if record.check_id not in suppression['checkovPolicyIds']:\n+            return False\n+\n+        type = suppression['ruleType']\n+\n+        if type == 'policy':  # TODO policy suppression not supported via UI yet but we just need to set the correct type value here\n+            # We just checked the policy ID above\n+            return True\n+        elif type == 'finding':\n+            pass  # TODO how to map them?\n+        elif type == 'file':\n+            record_file_path = record.repo_file_path if record.repo_file_path.startswith('/') else f'/{record.repo_file_path}'\n+            for file_suppression in suppression['files']:\n+                suppression_file_path = file_suppression['filePath']\n+                suppression_file_path = suppression_file_path if suppression_file_path.startswith('/') else f'/{suppression_file_path}'\n+                if self.bc_integration.repo_matches(file_suppression['repositoryName']) \\\n+                        and (suppression_file_path == record_file_path\n+                             or suppression_file_path == convert_to_unix_path(record_file_path)):",
        "comment_created_at": "2024-03-24T13:10:15+00:00",
        "comment_author": "tronxd",
        "comment_body": "please refactor the condition into a function to understand what we check for",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1573781368",
    "pr_number": 6195,
    "pr_file": "checkov/terraform/plan_parser.py",
    "created_at": "2024-04-21T14:31:25+00:00",
    "commented_code": "return cast(\"list[dict[str, Any]]\", root_module_conf.get(\"resources\", []))\n \n \n+def _get_provider(template: dict[str, Any]) -> dict[str, dict[str, Any]]:\n+    \"\"\"Returns the provider dict\"\"\"\n+\n+    provider_map = {}\n+    provider_config = template.get(\"configuration\", {}).get(\"provider_config\", None)\n+\n+    if provider_config and isinstance(provider_config, dict):\n+        for provider_key, provider_data in provider_config.items():\n+            if (provider_key.startswith('module.') or provider_key.startswith('__') or provider_key in {'start_line', 'end_line'}):",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1573781368",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 6195,
        "pr_file": "checkov/terraform/plan_parser.py",
        "discussion_id": "1573781368",
        "commented_code": "@@ -242,6 +242,28 @@ def _get_module_call_resources(module_address: str, root_module_conf: dict[str,\n     return cast(\"list[dict[str, Any]]\", root_module_conf.get(\"resources\", []))\n \n \n+def _get_provider(template: dict[str, Any]) -> dict[str, dict[str, Any]]:\n+    \"\"\"Returns the provider dict\"\"\"\n+\n+    provider_map = {}\n+    provider_config = template.get(\"configuration\", {}).get(\"provider_config\", None)\n+\n+    if provider_config and isinstance(provider_config, dict):\n+        for provider_key, provider_data in provider_config.items():\n+            if (provider_key.startswith('module.') or provider_key.startswith('__') or provider_key in {'start_line', 'end_line'}):",
        "comment_created_at": "2024-04-21T14:31:25+00:00",
        "comment_author": "ChanochShayner",
        "comment_body": "maybe worth moving the conditions to a func - `_is_provider_key`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1432818681",
    "pr_number": 5889,
    "pr_file": "checkov/sast/engines/prisma_engine.py",
    "created_at": "2023-12-20T14:54:43+00:00",
    "commented_code": "report = SastReport(f'{self.check_type.lower()}_{lang.value}', prisma_report.run_metadata, lang, sast_report)\n                 report.sast_reachability = prisma_report.reachability_report[lang]\n                 reports.append(report)\n-        return reports\n \n+        all_report = self.split_sast_cdk_reports(reports)\n+        return all_report\n+    \n+    def split_sast_cdk_reports(self, sast_reports: List[SastReport]) -> List[Union[SastReport, CDKReport]]:\n+        cdk_reports: List[CDKReport] = []\n+        for report in sast_reports:\n+            for lang, rule_matches in report.sast_report.rule_match.items():\n+                sast_rule_matches: Dict[str, RuleMatch] = {}\n+                for policy_id, rule_match in rule_matches.items():\n+                    if rule_match.metadata.framework != 'CDK':\n+                        sast_rule_matches[policy_id] = rule_match\n+                        continue\n+                    if lang not in [c.language for c in cdk_reports]:\n+                        new_cdk_report = PrismaReport(rule_match={lang: {}}, errors=report.sast_report.errors,\n+                                                  profiler=report.sast_report.profiler,\n+                                                  run_metadata=report.sast_report.run_metadata,\n+                                                  imports={}, reachability_report={})\n+                        new_report = CDKReport(f'cdk_{lang.value}', report.sast_report.run_metadata, lang, new_cdk_report)\n+                        cdk_reports.append(new_report)\n+                    for cdk_report in cdk_reports:\n+                        if cdk_report.language == lang:\n+                            cdk_report.cdk_report.rule_match[lang][policy_id] = rule_match\n+                            for failed_check in report.failed_checks:\n+                                if failed_check.check_id == policy_id:\n+                                    cdk_report.failed_checks.append(failed_check)\n+                                \n+                            for skiped_check in report.skipped_checks:\n+                                if skiped_check.check_id == policy_id:\n+                                    cdk_report.skipped_checks.append(skiped_check)\n+                            break\n+                if sast_rule_matches:\n+                    report.sast_report.rule_match[lang] = sast_rule_matches\n+                else:\n+                    report.sast_report.rule_match = {}\n+                self._update_sast_report_checks(report, cdk_reports)\n+\n+        return self._get_all_reports()\n+\n+    def _update_sast_report_checks(self, report: SastReport, cdk_reports: List[CDKReport]) -> None:\n+        sast_failed_checks = []\n+        sast_skiped_checks = []\n+\n+        for fail_check in report.failed_checks:\n+            for cdk_report in cdk_reports:\n+                if report.language == cdk_report.language and fail_check.check_id not in [f.check_id for f in cdk_report.failed_checks]:\n+                    sast_failed_checks.append(fail_check)\n+                    break\n+            else:\n+                sast_failed_checks = report.failed_checks\n+                break\n+\n+        for skip_check in report.skipped_checks:\n+            for cdk_report in cdk_reports:\n+                if report.language == cdk_report.language and skip_check.check_id not in [s.check_id for s in cdk_report.skipped_checks]:\n+                    sast_skiped_checks.append(skip_check)\n+                    break\n+            else:\n+                sast_skiped_checks = report.skipped_checks\n+                break",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1432818681",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5889,
        "pr_file": "checkov/sast/engines/prisma_engine.py",
        "discussion_id": "1432818681",
        "commented_code": "@@ -351,8 +356,83 @@ def create_report(self, prisma_report: PrismaReport) -> List[SastReport]:\n                 report = SastReport(f'{self.check_type.lower()}_{lang.value}', prisma_report.run_metadata, lang, sast_report)\n                 report.sast_reachability = prisma_report.reachability_report[lang]\n                 reports.append(report)\n-        return reports\n \n+        all_report = self.split_sast_cdk_reports(reports)\n+        return all_report\n+    \n+    def split_sast_cdk_reports(self, sast_reports: List[SastReport]) -> List[Union[SastReport, CDKReport]]:\n+        cdk_reports: List[CDKReport] = []\n+        for report in sast_reports:\n+            for lang, rule_matches in report.sast_report.rule_match.items():\n+                sast_rule_matches: Dict[str, RuleMatch] = {}\n+                for policy_id, rule_match in rule_matches.items():\n+                    if rule_match.metadata.framework != 'CDK':\n+                        sast_rule_matches[policy_id] = rule_match\n+                        continue\n+                    if lang not in [c.language for c in cdk_reports]:\n+                        new_cdk_report = PrismaReport(rule_match={lang: {}}, errors=report.sast_report.errors,\n+                                                  profiler=report.sast_report.profiler,\n+                                                  run_metadata=report.sast_report.run_metadata,\n+                                                  imports={}, reachability_report={})\n+                        new_report = CDKReport(f'cdk_{lang.value}', report.sast_report.run_metadata, lang, new_cdk_report)\n+                        cdk_reports.append(new_report)\n+                    for cdk_report in cdk_reports:\n+                        if cdk_report.language == lang:\n+                            cdk_report.cdk_report.rule_match[lang][policy_id] = rule_match\n+                            for failed_check in report.failed_checks:\n+                                if failed_check.check_id == policy_id:\n+                                    cdk_report.failed_checks.append(failed_check)\n+                                \n+                            for skiped_check in report.skipped_checks:\n+                                if skiped_check.check_id == policy_id:\n+                                    cdk_report.skipped_checks.append(skiped_check)\n+                            break\n+                if sast_rule_matches:\n+                    report.sast_report.rule_match[lang] = sast_rule_matches\n+                else:\n+                    report.sast_report.rule_match = {}\n+                self._update_sast_report_checks(report, cdk_reports)\n+\n+        return self._get_all_reports()\n+\n+    def _update_sast_report_checks(self, report: SastReport, cdk_reports: List[CDKReport]) -> None:\n+        sast_failed_checks = []\n+        sast_skiped_checks = []\n+\n+        for fail_check in report.failed_checks:\n+            for cdk_report in cdk_reports:\n+                if report.language == cdk_report.language and fail_check.check_id not in [f.check_id for f in cdk_report.failed_checks]:\n+                    sast_failed_checks.append(fail_check)\n+                    break\n+            else:\n+                sast_failed_checks = report.failed_checks\n+                break\n+\n+        for skip_check in report.skipped_checks:\n+            for cdk_report in cdk_reports:\n+                if report.language == cdk_report.language and skip_check.check_id not in [s.check_id for s in cdk_report.skipped_checks]:\n+                    sast_skiped_checks.append(skip_check)\n+                    break\n+            else:\n+                sast_skiped_checks = report.skipped_checks\n+                break",
        "comment_created_at": "2023-12-20T14:54:43+00:00",
        "comment_author": "tronxd",
        "comment_body": "the failed/skipped logic looks the same, put it into a function that iterates on a check lists",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1273377328",
    "pr_number": 5375,
    "pr_file": "checkov/terraform/runner.py",
    "created_at": "2023-07-25T11:12:43+00:00",
    "commented_code": "parsing_errors: dict[str, Exception] = {}\n         self.load_external_checks(external_checks_dir)\n         local_graph = None\n-\n+        all_graphs = []\n         if self.context is None or self.definitions is None or self.breadcrumbs is None:\n             self.definitions = {}\n             logging.info(\"Scanning root folder and producing fresh tf_definitions and context\")\n             if root_folder:\n                 root_folder = os.path.abspath(root_folder)\n-\n-                local_graph, self.definitions = self.graph_manager.build_graph_from_source_directory(\n-                    source_dir=root_folder,\n-                    local_graph_class=self.graph_class,\n-                    download_external_modules=runner_filter.download_external_modules,\n-                    external_modules_download_path=runner_filter.external_modules_download_path,\n-                    parsing_errors=parsing_errors,\n-                    excluded_paths=runner_filter.excluded_paths,\n-                    vars_files=runner_filter.var_files,\n-                    create_graph=CHECKOV_CREATE_GRAPH,\n-                )\n+                tf_split_graph = strtobool(os.getenv('TF_SPLIT_GRAPH', 'False'))",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1273377328",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5375,
        "pr_file": "checkov/terraform/runner.py",
        "discussion_id": "1273377328",
        "commented_code": "@@ -116,47 +117,73 @@ def run(\n         parsing_errors: dict[str, Exception] = {}\n         self.load_external_checks(external_checks_dir)\n         local_graph = None\n-\n+        all_graphs = []\n         if self.context is None or self.definitions is None or self.breadcrumbs is None:\n             self.definitions = {}\n             logging.info(\"Scanning root folder and producing fresh tf_definitions and context\")\n             if root_folder:\n                 root_folder = os.path.abspath(root_folder)\n-\n-                local_graph, self.definitions = self.graph_manager.build_graph_from_source_directory(\n-                    source_dir=root_folder,\n-                    local_graph_class=self.graph_class,\n-                    download_external_modules=runner_filter.download_external_modules,\n-                    external_modules_download_path=runner_filter.external_modules_download_path,\n-                    parsing_errors=parsing_errors,\n-                    excluded_paths=runner_filter.excluded_paths,\n-                    vars_files=runner_filter.var_files,\n-                    create_graph=CHECKOV_CREATE_GRAPH,\n-                )\n+                tf_split_graph = strtobool(os.getenv('TF_SPLIT_GRAPH', 'False'))",
        "comment_created_at": "2023-07-25T11:12:43+00:00",
        "comment_author": "bo156",
        "comment_body": "as this part begins to be a bit big - what do you think about splitting the `if/else` block to a new function called `_generate_graphs_list` (or something like that)?",
        "pr_file_module": null
      },
      {
        "comment_id": "1273548193",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5375,
        "pr_file": "checkov/terraform/runner.py",
        "discussion_id": "1273377328",
        "commented_code": "@@ -116,47 +117,73 @@ def run(\n         parsing_errors: dict[str, Exception] = {}\n         self.load_external_checks(external_checks_dir)\n         local_graph = None\n-\n+        all_graphs = []\n         if self.context is None or self.definitions is None or self.breadcrumbs is None:\n             self.definitions = {}\n             logging.info(\"Scanning root folder and producing fresh tf_definitions and context\")\n             if root_folder:\n                 root_folder = os.path.abspath(root_folder)\n-\n-                local_graph, self.definitions = self.graph_manager.build_graph_from_source_directory(\n-                    source_dir=root_folder,\n-                    local_graph_class=self.graph_class,\n-                    download_external_modules=runner_filter.download_external_modules,\n-                    external_modules_download_path=runner_filter.external_modules_download_path,\n-                    parsing_errors=parsing_errors,\n-                    excluded_paths=runner_filter.excluded_paths,\n-                    vars_files=runner_filter.var_files,\n-                    create_graph=CHECKOV_CREATE_GRAPH,\n-                )\n+                tf_split_graph = strtobool(os.getenv('TF_SPLIT_GRAPH', 'False'))",
        "comment_created_at": "2023-07-25T13:29:07+00:00",
        "comment_author": "maxamel",
        "comment_body": "I thought about it but the problem is here we are outputting the graph but also updating the self.definitions. So the definitions update will be like a silent side effect.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1269090015",
    "pr_number": 5362,
    "pr_file": "checkov/terraform/tf_parser.py",
    "created_at": "2023-07-20T08:00:17+00:00",
    "commented_code": "return module, tf_definitions\n \n+    def parse_multi_graph_hcl_module(\n+        self,\n+        source_dir: str,\n+        source: str,\n+        download_external_modules: bool = False,\n+        external_modules_download_path: str = DEFAULT_EXTERNAL_MODULES_DIR,\n+        parsing_errors: dict[str, Exception] | None = None,\n+        excluded_paths: list[str] | None = None,\n+        vars_files: list[str] | None = None,\n+        external_modules_content_cache: dict[str, ModuleContent | None] | None = None,\n+        create_graph: bool = True,\n+    ) -> list[Tuple[Module, Dict[TFDefinitionKey, Dict[str, Any]]]]:\n+        tf_definitions = self.parse_directory(\n+            directory=source_dir, out_evaluations_context={},\n+            out_parsing_errors=parsing_errors if parsing_errors is not None else {},\n+            download_external_modules=download_external_modules,\n+            external_modules_download_path=external_modules_download_path, excluded_paths=excluded_paths,\n+            vars_files=vars_files, external_modules_content_cache=external_modules_content_cache\n+        )\n+        tf_definitions = clean_parser_types(tf_definitions)\n+        tf_definitions = serialize_definitions(tf_definitions)\n+\n+        dirs_to_definitions: dict[str, list[dict[TFDefinitionKey, dict[str, Any]]]] = {}",
    "repo_full_name": "bridgecrewio/checkov",
    "discussion_comments": [
      {
        "comment_id": "1269090015",
        "repo_full_name": "bridgecrewio/checkov",
        "pr_number": 5362,
        "pr_file": "checkov/terraform/tf_parser.py",
        "discussion_id": "1269090015",
        "commented_code": "@@ -329,6 +330,58 @@ def parse_hcl_module(\n \n         return module, tf_definitions\n \n+    def parse_multi_graph_hcl_module(\n+        self,\n+        source_dir: str,\n+        source: str,\n+        download_external_modules: bool = False,\n+        external_modules_download_path: str = DEFAULT_EXTERNAL_MODULES_DIR,\n+        parsing_errors: dict[str, Exception] | None = None,\n+        excluded_paths: list[str] | None = None,\n+        vars_files: list[str] | None = None,\n+        external_modules_content_cache: dict[str, ModuleContent | None] | None = None,\n+        create_graph: bool = True,\n+    ) -> list[Tuple[Module, Dict[TFDefinitionKey, Dict[str, Any]]]]:\n+        tf_definitions = self.parse_directory(\n+            directory=source_dir, out_evaluations_context={},\n+            out_parsing_errors=parsing_errors if parsing_errors is not None else {},\n+            download_external_modules=download_external_modules,\n+            external_modules_download_path=external_modules_download_path, excluded_paths=excluded_paths,\n+            vars_files=vars_files, external_modules_content_cache=external_modules_content_cache\n+        )\n+        tf_definitions = clean_parser_types(tf_definitions)\n+        tf_definitions = serialize_definitions(tf_definitions)\n+\n+        dirs_to_definitions: dict[str, list[dict[TFDefinitionKey, dict[str, Any]]]] = {}",
        "comment_created_at": "2023-07-20T08:00:17+00:00",
        "comment_author": "bo156",
        "comment_body": "would split the creation of this dict to a function like `_build_dirs_to_definitions`",
        "pr_file_module": null
      }
    ]
  }
]