[
  {
    "discussion_id": "2278721489",
    "pr_number": 85538,
    "pr_file": "src/Functions/keyvaluepair/impl/StateHandlerImpl.h",
    "created_at": "2025-08-15T09:58:09+00:00",
    "commented_code": "* */\n     class PairWriter\n     {\n-        absl::flat_hash_map<std::string_view, std::string_view> & map;\n+        std::map<std::string_view, std::string_view> & map;",
    "repo_full_name": "ClickHouse/ClickHouse",
    "discussion_comments": [
      {
        "comment_id": "2278721489",
        "repo_full_name": "ClickHouse/ClickHouse",
        "pr_number": 85538,
        "pr_file": "src/Functions/keyvaluepair/impl/StateHandlerImpl.h",
        "discussion_id": "2278721489",
        "commented_code": "@@ -637,13 +636,13 @@ struct ReferencesMapStateHandler : public StateHandlerImpl<false>\n      * */\n     class PairWriter\n     {\n-        absl::flat_hash_map<std::string_view, std::string_view> & map;\n+        std::map<std::string_view, std::string_view> & map;",
        "comment_created_at": "2025-08-15T09:58:09+00:00",
        "comment_author": "kssenii",
        "comment_body": "Why need this change?",
        "pr_file_module": null
      },
      {
        "comment_id": "2279821128",
        "repo_full_name": "ClickHouse/ClickHouse",
        "pr_number": 85538,
        "pr_file": "src/Functions/keyvaluepair/impl/StateHandlerImpl.h",
        "discussion_id": "2278721489",
        "commented_code": "@@ -637,13 +636,13 @@ struct ReferencesMapStateHandler : public StateHandlerImpl<false>\n      * */\n     class PairWriter\n     {\n-        absl::flat_hash_map<std::string_view, std::string_view> & map;\n+        std::map<std::string_view, std::string_view> & map;",
        "comment_created_at": "2025-08-15T20:22:18+00:00",
        "comment_author": "arthurpassos",
        "comment_body": "This function is used to parse hive columns (key-values) from the file path. `absl::flat_hash_map` is unordered and some parts of ClickHouse (especially the distributed part that relies on zookeper) depend on `ColumnsDescription:;toString` equality.\r\n\r\nIn a nutshell, during the development of https://github.com/ClickHouse/ClickHouse/pull/81040, we were getting a few schema mismatch exceptions simply because of the order of the columns",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1631020489",
    "pr_number": 63665,
    "pr_file": "tests/queries/0_stateless/03094_virtual_column_table_name.reference",
    "created_at": "2024-06-07T10:46:14+00:00",
    "commented_code": "+-- { echoOn }\n+SELECT _table FROM d1;\n+d1\n+d1\n+SELECT count(_table) FROM d1 WHERE _table = 'd1' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d1 WHERE value = 10;\n+d1\t1\t10\n+SELECT _table FROM d2;\n+d2\n+d2\n+SELECT count(_table) FROM d2 WHERE _table = 'd2' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d2 WHERE value = 40;\n+d2\t4\t40\n+SELECT _table, value FROM d3 WHERE _table = 6;\n+6\t60\n+SELECT _table FROM d4;\n+d4\n+d4\n+SELECT count(_table) FROM d4 WHERE _table = 'd4' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d4 WHERE value = 40;\n+d4\t4\t40\n+SELECT _table FROM m1 ORDER BY _table ASC;\n+d1\n+d1\n+d2\n+d2",
    "repo_full_name": "ClickHouse/ClickHouse",
    "discussion_comments": [
      {
        "comment_id": "1631020489",
        "repo_full_name": "ClickHouse/ClickHouse",
        "pr_number": 63665,
        "pr_file": "tests/queries/0_stateless/03094_virtual_column_table_name.reference",
        "discussion_id": "1631020489",
        "commented_code": "@@ -0,0 +1,47 @@\n+-- { echoOn }\n+SELECT _table FROM d1;\n+d1\n+d1\n+SELECT count(_table) FROM d1 WHERE _table = 'd1' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d1 WHERE value = 10;\n+d1\t1\t10\n+SELECT _table FROM d2;\n+d2\n+d2\n+SELECT count(_table) FROM d2 WHERE _table = 'd2' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d2 WHERE value = 40;\n+d2\t4\t40\n+SELECT _table, value FROM d3 WHERE _table = 6;\n+6\t60\n+SELECT _table FROM d4;\n+d4\n+d4\n+SELECT count(_table) FROM d4 WHERE _table = 'd4' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d4 WHERE value = 40;\n+d4\t4\t40\n+SELECT _table FROM m1 ORDER BY _table ASC;\n+d1\n+d1\n+d2\n+d2",
        "comment_created_at": "2024-06-07T10:46:14+00:00",
        "comment_author": "divanik",
        "comment_body": "Could you, please, explain why this behavior is a desired one and we do not want to see m1 here?\n\n",
        "pr_file_module": null
      },
      {
        "comment_id": "1632351522",
        "repo_full_name": "ClickHouse/ClickHouse",
        "pr_number": 63665,
        "pr_file": "tests/queries/0_stateless/03094_virtual_column_table_name.reference",
        "discussion_id": "1631020489",
        "commented_code": "@@ -0,0 +1,47 @@\n+-- { echoOn }\n+SELECT _table FROM d1;\n+d1\n+d1\n+SELECT count(_table) FROM d1 WHERE _table = 'd1' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d1 WHERE value = 10;\n+d1\t1\t10\n+SELECT _table FROM d2;\n+d2\n+d2\n+SELECT count(_table) FROM d2 WHERE _table = 'd2' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d2 WHERE value = 40;\n+d2\t4\t40\n+SELECT _table, value FROM d3 WHERE _table = 6;\n+6\t60\n+SELECT _table FROM d4;\n+d4\n+d4\n+SELECT count(_table) FROM d4 WHERE _table = 'd4' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d4 WHERE value = 40;\n+d4\t4\t40\n+SELECT _table FROM m1 ORDER BY _table ASC;\n+d1\n+d1\n+d2\n+d2",
        "comment_created_at": "2024-06-09T16:51:22+00:00",
        "comment_author": "wudidapaopao",
        "comment_body": "Currently, the _table virtual column is only supported for tables with the Merge engine. \r\nThe behavior is such that when querying a table using the Merge engine, the _table virtual column returns the actual names of the underlying tables that the Merge table aggregates data from, rather than returning the name of the Merge table itself. And this PR extends this virtual column to all tables.\r\nhttps://clickhouse.com/docs/en/engines/table-engines/special/merge#virtual-columns",
        "pr_file_module": null
      },
      {
        "comment_id": "1899186357",
        "repo_full_name": "ClickHouse/ClickHouse",
        "pr_number": 63665,
        "pr_file": "tests/queries/0_stateless/03094_virtual_column_table_name.reference",
        "discussion_id": "1631020489",
        "commented_code": "@@ -0,0 +1,47 @@\n+-- { echoOn }\n+SELECT _table FROM d1;\n+d1\n+d1\n+SELECT count(_table) FROM d1 WHERE _table = 'd1' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d1 WHERE value = 10;\n+d1\t1\t10\n+SELECT _table FROM d2;\n+d2\n+d2\n+SELECT count(_table) FROM d2 WHERE _table = 'd2' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d2 WHERE value = 40;\n+d2\t4\t40\n+SELECT _table, value FROM d3 WHERE _table = 6;\n+6\t60\n+SELECT _table FROM d4;\n+d4\n+d4\n+SELECT count(_table) FROM d4 WHERE _table = 'd4' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d4 WHERE value = 40;\n+d4\t4\t40\n+SELECT _table FROM m1 ORDER BY _table ASC;\n+d1\n+d1\n+d2\n+d2",
        "comment_created_at": "2024-12-29T20:07:18+00:00",
        "comment_author": "alexey-milovidov",
        "comment_body": "Let's make it always to be the inner-most table.\r\n\r\nIt will break the current behavior when a Merge table is created on top of more Merge tables, but it will be ok.",
        "pr_file_module": null
      },
      {
        "comment_id": "1913074275",
        "repo_full_name": "ClickHouse/ClickHouse",
        "pr_number": 63665,
        "pr_file": "tests/queries/0_stateless/03094_virtual_column_table_name.reference",
        "discussion_id": "1631020489",
        "commented_code": "@@ -0,0 +1,47 @@\n+-- { echoOn }\n+SELECT _table FROM d1;\n+d1\n+d1\n+SELECT count(_table) FROM d1 WHERE _table = 'd1' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d1 WHERE value = 10;\n+d1\t1\t10\n+SELECT _table FROM d2;\n+d2\n+d2\n+SELECT count(_table) FROM d2 WHERE _table = 'd2' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d2 WHERE value = 40;\n+d2\t4\t40\n+SELECT _table, value FROM d3 WHERE _table = 6;\n+6\t60\n+SELECT _table FROM d4;\n+d4\n+d4\n+SELECT count(_table) FROM d4 WHERE _table = 'd4' GROUP BY _table;\n+2\n+SELECT _table, key, value FROM d4 WHERE value = 40;\n+d4\t4\t40\n+SELECT _table FROM m1 ORDER BY _table ASC;\n+d1\n+d1\n+d2\n+d2",
        "comment_created_at": "2025-01-13T11:54:24+00:00",
        "comment_author": "divanik",
        "comment_body": "I'd like if the breaking change is a separate PR.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2217959802",
    "pr_number": 84084,
    "pr_file": "src/Disks/ObjectStorages/MetadataStorageFromPlainObjectStorage.h",
    "created_at": "2025-07-20T20:53:35+00:00",
    "commented_code": "const IMetadataStorage & getStorageForNonTransactionalReads() const override;\n \n-    void addBlobToMetadata(const std::string & /* path */, ObjectStorageKey /* object_key */, uint64_t /* size_in_bytes */) override\n-    {\n-        /// Noop",
    "repo_full_name": "ClickHouse/ClickHouse",
    "discussion_comments": [
      {
        "comment_id": "2217959802",
        "repo_full_name": "ClickHouse/ClickHouse",
        "pr_number": 84084,
        "pr_file": "src/Disks/ObjectStorages/MetadataStorageFromPlainObjectStorage.h",
        "discussion_id": "2217959802",
        "commented_code": "@@ -117,11 +116,6 @@ class MetadataStorageFromPlainObjectStorageTransaction : public IMetadataTransac\n \n     const IMetadataStorage & getStorageForNonTransactionalReads() const override;\n \n-    void addBlobToMetadata(const std::string & /* path */, ObjectStorageKey /* object_key */, uint64_t /* size_in_bytes */) override\n-    {\n-        /// Noop",
        "comment_created_at": "2025-07-20T20:53:35+00:00",
        "comment_author": "azat",
        "comment_body": "This ignores the `WriteMode::Append` writes, which sounds very bad, since it is used in a few places in MergeTree code (at least), for example for `txn_version.txt`\r\n\r\nRefs: https://github.com/ClickHouse/ClickHouse/pull/84084/commits/91cf0ff1813a80028258b94aa4a1961fbfa9116b",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1969753834",
    "pr_number": 76596,
    "pr_file": "tests/queries/0_stateless/02731_analyzer_join_resolve_nested.reference",
    "created_at": "2025-02-25T13:10:21+00:00",
    "commented_code": "0\tUInt32\n (((1,'s'),'s'),'s')\ts\tTuple(\n    t Tuple(\n        t Tuple(\n            t UInt32,\n            s String),\n        s String),\n    s String)\tString\n (((2,'s'),'s'),'s')\ts\tTuple(\n    t Tuple(\n        t Tuple(\n            t UInt32,\n            s String),\n        s String),\n    s String)\tString\n-(((0,''),''),'')\t\tTuple(\n    t Tuple(\n        t Tuple(\n            t UInt32,\n            s String),\n        s String),\n    s String)\tString\n+(((3,'s'),'s'),'s')\t\tTuple(\n    t Tuple(\n        t Tuple(\n            t UInt32,\n            s String),\n        s String),\n    s String)\tString",
    "repo_full_name": "ClickHouse/ClickHouse",
    "discussion_comments": [
      {
        "comment_id": "1969753834",
        "repo_full_name": "ClickHouse/ClickHouse",
        "pr_number": 76596,
        "pr_file": "tests/queries/0_stateless/02731_analyzer_join_resolve_nested.reference",
        "discussion_id": "1969753834",
        "commented_code": "@@ -93,7 +93,7 @@\n 0\tUInt32\n (((1,'s'),'s'),'s')\ts\tTuple(\\n    t Tuple(\\n        t Tuple(\\n            t UInt32,\\n            s String),\\n        s String),\\n    s String)\tString\n (((2,'s'),'s'),'s')\ts\tTuple(\\n    t Tuple(\\n        t Tuple(\\n            t UInt32,\\n            s String),\\n        s String),\\n    s String)\tString\n-(((0,''),''),'')\t\tTuple(\\n    t Tuple(\\n        t Tuple(\\n            t UInt32,\\n            s String),\\n        s String),\\n    s String)\tString\n+(((3,'s'),'s'),'s')\t\tTuple(\\n    t Tuple(\\n        t Tuple(\\n            t UInt32,\\n            s String),\\n        s String),\\n    s String)\tString",
        "comment_created_at": "2025-02-25T13:10:21+00:00",
        "comment_author": "CurtizJ",
        "comment_body": "This case has been changed:\r\n\r\n```sql\r\nDROP TABLE IF EXISTS ttta;\r\nDROP TABLE IF EXISTS tttb;\r\n\r\nSET enable_analyzer = 1;\r\n\r\nCREATE table ttta (x Int32, t Tuple(t Tuple(t Tuple(t Tuple(t UInt32, s String), s String), s String), s String)) ENGINE = MergeTree ORDER BY x;\r\nINSERT INTO ttta VALUES (1, ((((1, 's'), 's'), 's'), 's')), (2, ((((2, 's'), 's'), 's'), 's'));\r\n\r\nCREATE table tttb (x Int32, t Tuple(t Tuple(t Tuple(t Tuple(t Int32, s String), s String), s String), s String)) ENGINE = MergeTree ORDER BY x;\r\nINSERT INTO tttb VALUES (2, ((((2, 's'), 's'), 's'), 's')), (3, ((((3, 's'), 's'), 's'), 's'));\r\n```\r\n\r\n```sql\r\nSELECT t.* FROM ttta FULL JOIN tttb USING (t.t) SETTINGS optimize_functions_to_subcolumns = 0;\r\nEXPLAIN QUERY TREE dump_ast = 1, dump_tree = 0 SELECT t.* FROM ttta FULL JOIN tttb USING (t.t) SETTINGS optimize_functions_to_subcolumns = 0;\r\n\r\n(((1,'s'),'s'),'s')     s\r\n(((2,'s'),'s'),'s')     s\r\n(((0,''),''),'')\r\nSELECT\r\n    getSubcolumn(__table1.t, \\'t\\') AS `t.t`,\r\n    getSubcolumn(__table1.t, \\'s\\') AS `t.s`\r\nFROM default.ttta AS __table1\r\nALL FULL OUTER JOIN default.tttb AS __table2 USING (`t.t`)\r\nSETTINGS optimize_functions_to_subcolumns = 0\r\n```\r\n\r\n```sql\r\nSELECT t.* FROM ttta FULL JOIN tttb USING (t.t) SETTINGS optimize_functions_to_subcolumns = 1;\r\nEXPLAIN QUERY TREE dump_ast = 1, dump_tree = 0 SELECT t.* FROM ttta FULL JOIN tttb USING (t.t) SETTINGS optimize_functions_to_subcolumns = 1;\r\n\r\n(((1,'s'),'s'),'s')     s\r\n(((2,'s'),'s'),'s')     s\r\n(((3,'s'),'s'),'s')\r\nSELECT\r\n    __table1.`t.t` AS `t.t`,\r\n    __table1.`t.s` AS `t.s`\r\nFROM default.ttta AS __table1\r\nALL FULL OUTER JOIN default.tttb AS __table2 USING (`t.t`)\r\nSETTINGS optimize_functions_to_subcolumns = 1\r\n```\r\n\r\nWithout `optimize_functions_to_subcolumns` `t.*` is expanded to `getSubcolumn(__table1.t, \\'t\\') AS t.t,\r\n    getSubcolumn(__table1.t, \\'s\\') AS t.s`. The first column doesn't match the key in `USING` and is filled with the default value for the third row.\r\n\r\nWith `optimize_functions_to_subcolumns` `t.*` is expanded to `__table1.t.t AS t.t, __table1.t.s AS t.s` and now the first column matches the key in `USING` and filled as a key of join.\r\n\r\nI think the second behavior is more correct. @novikd or @vdimir, could you confirm this?\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "1987006064",
        "repo_full_name": "ClickHouse/ClickHouse",
        "pr_number": 76596,
        "pr_file": "tests/queries/0_stateless/02731_analyzer_join_resolve_nested.reference",
        "discussion_id": "1969753834",
        "commented_code": "@@ -93,7 +93,7 @@\n 0\tUInt32\n (((1,'s'),'s'),'s')\ts\tTuple(\\n    t Tuple(\\n        t Tuple(\\n            t UInt32,\\n            s String),\\n        s String),\\n    s String)\tString\n (((2,'s'),'s'),'s')\ts\tTuple(\\n    t Tuple(\\n        t Tuple(\\n            t UInt32,\\n            s String),\\n        s String),\\n    s String)\tString\n-(((0,''),''),'')\t\tTuple(\\n    t Tuple(\\n        t Tuple(\\n            t UInt32,\\n            s String),\\n        s String),\\n    s String)\tString\n+(((3,'s'),'s'),'s')\t\tTuple(\\n    t Tuple(\\n        t Tuple(\\n            t UInt32,\\n            s String),\\n        s String),\\n    s String)\tString",
        "comment_created_at": "2025-03-10T10:24:25+00:00",
        "comment_author": "vdimir",
        "comment_body": "Makes sense. Actually, all those cases look like corner cases, so I added such tests mainly to ensure that they don\u2019t crash or cause logical errors and to inspect them carefully when making changes.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2200650724",
    "pr_number": 83408,
    "pr_file": "src/Databases/DatabaseReplicated.h",
    "created_at": "2025-07-11T12:50:08+00:00",
    "commented_code": "String getEngineName() const override { return \"Replicated\"; }\n \n+    bool isReadOnly() const override { return is_readonly.load(std::memory_order_relaxed); }",
    "repo_full_name": "ClickHouse/ClickHouse",
    "discussion_comments": [
      {
        "comment_id": "2200650724",
        "repo_full_name": "ClickHouse/ClickHouse",
        "pr_number": 83408,
        "pr_file": "src/Databases/DatabaseReplicated.h",
        "discussion_id": "2200650724",
        "commented_code": "@@ -49,6 +50,8 @@ class DatabaseReplicated : public DatabaseAtomic\n \n     String getEngineName() const override { return \"Replicated\"; }\n \n+    bool isReadOnly() const override { return is_readonly.load(std::memory_order_relaxed); }",
        "comment_created_at": "2025-07-11T12:50:08+00:00",
        "comment_author": "aalexfvk",
        "comment_body": "It seems that semantic of this method for `IDatabase` means if databse provides read-only access to data. But you use it for metadata modification.\r\nMaybe new method is needed.",
        "pr_file_module": null
      },
      {
        "comment_id": "2214246237",
        "repo_full_name": "ClickHouse/ClickHouse",
        "pr_number": 83408,
        "pr_file": "src/Databases/DatabaseReplicated.h",
        "discussion_id": "2200650724",
        "commented_code": "@@ -49,6 +50,8 @@ class DatabaseReplicated : public DatabaseAtomic\n \n     String getEngineName() const override { return \"Replicated\"; }\n \n+    bool isReadOnly() const override { return is_readonly.load(std::memory_order_relaxed); }",
        "comment_created_at": "2025-07-17T20:36:02+00:00",
        "comment_author": "k-morozov",
        "comment_body": "The logic was updated, status readonly we take from status method.",
        "pr_file_module": null
      }
    ]
  }
]