[
  {
    "discussion_id": "2148829196",
    "pr_number": 1336,
    "pr_file": "codex-cli/tests/raw-exec-process-group.test.ts",
    "created_at": "2025-06-15T21:16:49+00:00",
    "commented_code": "* @throws {Error} If the process is still alive after 500ms\n  */\n async function ensureProcessGone(pid: number) {\n-  const timeout = 500;\n+  const timeout = 1000;\n   const deadline = Date.now() + timeout;",
    "repo_full_name": "openai/codex",
    "discussion_comments": [
      {
        "comment_id": "2148829196",
        "repo_full_name": "openai/codex",
        "pr_number": 1336,
        "pr_file": "codex-cli/tests/raw-exec-process-group.test.ts",
        "discussion_id": "2148829196",
        "commented_code": "@@ -68,11 +74,19 @@ describe(\"rawExec \u2013 abort kills entire process group\", () => {\n  * @throws {Error} If the process is still alive after 500ms\n  */\n async function ensureProcessGone(pid: number) {\n-  const timeout = 500;\n+  const timeout = 1000;\n   const deadline = Date.now() + timeout;",
        "comment_created_at": "2025-06-15T21:16:49+00:00",
        "comment_author": "Copilot",
        "comment_body": "[nitpick] Extract this magic timeout value into a named constant or configuration so its purpose and trade-offs are clearer and reusable.\n```suggestion\n  const deadline = Date.now() + PROCESS_TERMINATION_TIMEOUT_MS;\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2148829199",
    "pr_number": 1336,
    "pr_file": "codex-cli/src/utils/openai-client.ts",
    "created_at": "2025-06-15T21:16:50+00:00",
    "commented_code": "});\n   }\n \n+  if (config.provider?.toLowerCase() === \"githubcopilot\") {\n+    return new GithubCopilotClient({\n+      apiKey: getApiKey(config.provider),\n+      baseURL: getBaseUrl(config.provider),\n+      timeout: OPENAI_TIMEOUT_MS,\n+      defaultHeaders: headers,\n+    });\n+  }\n+\n   return new OpenAI({\n     apiKey: getApiKey(config.provider),\n     baseURL: getBaseUrl(config.provider),\n     timeout: OPENAI_TIMEOUT_MS,\n     defaultHeaders: headers,\n   });\n }\n+\n+export class GithubCopilotClient extends OpenAI {\n+  private copilotToken: string | null = null;\n+  private copilotTokenExpiration = new Date();\n+  private githubAPIKey: string;\n+\n+  constructor(opts: ClientOptions = {}) {\n+    super(opts);\n+    if (!opts.apiKey) {\n+      throw new Errors.OpenAIError(\"missing github copilot token\");\n+    }\n+    this.githubAPIKey = opts.apiKey;\n+  }\n+\n+  private async _getGithubCopilotToken(): Promise<string | undefined> {\n+    if (\n+      this.copilotToken &&\n+      this.copilotTokenExpiration.getTime() > Date.now()\n+    ) {\n+      return this.copilotToken;\n+    }\n+    const resp = await fetch(\n+      \"https://api.github.com/copilot_internal/v2/token\",\n+      {\n+        method: \"GET\",\n+        headers: GithubCopilotClient._mergeGithubHeaders({\n+          \"Authorization\": `bearer ${this.githubAPIKey}`,\n+          \"Accept\": \"application/json\",\n+          \"Content-Type\": \"application/json\",\n+        }),\n+      },\n+    );\n+    if (!resp.ok) {\n+      const text = await resp.text();\n+      throw new Error(\"unable to get github copilot auth token: \" + text);\n+    }\n+    const text = await resp.text();\n+    const { token, refresh_in } = JSON.parse(text);\n+    if (typeof token !== \"string\" || typeof refresh_in !== \"number\") {\n+      throw new Errors.OpenAIError(\n+        `unexpected response from copilot auth: ${text}`,\n+      );\n+    }\n+    this.copilotToken = token;\n+    this.copilotTokenExpiration = new Date(Date.now() + refresh_in * 1000);\n+    return token;\n+  }\n+\n+  protected override authHeaders(\n+    _opts: Core.FinalRequestOptions,\n+  ): Core.Headers {\n+    return {};\n+  }\n+\n+  protected override async prepareOptions(\n+    opts: Core.FinalRequestOptions<unknown>,\n+  ): Promise<void> {\n+    const token = await this._getGithubCopilotToken();\n+    opts.headers ??= {};\n+    if (token) {\n+      opts.headers[\"Authorization\"] = `Bearer ${token}`;\n+      opts.headers = GithubCopilotClient._mergeGithubHeaders(opts.headers);\n+    } else {\n+      throw new Errors.OpenAIError(\"Unable to handle auth\");\n+    }\n+    return super.prepareOptions(opts);\n+  }\n+\n+  static async getLoginURL(): Promise<{\n+    device_code: string;\n+    user_code: string;\n+    verification_uri: string;\n+  }> {\n+    const resp = await fetch(\"https://github.com/login/device/code\", {\n+      method: \"POST\",\n+      headers: this._mergeGithubHeaders({\n+        \"Content-Type\": \"application/json\",\n+        \"accept\": \"application/json\",\n+      }),\n+      body: JSON.stringify({\n+        client_id: \"Iv1.b507a08c87ecfe98\",",
    "repo_full_name": "openai/codex",
    "discussion_comments": [
      {
        "comment_id": "2148829199",
        "repo_full_name": "openai/codex",
        "pr_number": 1336,
        "pr_file": "codex-cli/src/utils/openai-client.ts",
        "discussion_id": "2148829199",
        "commented_code": "@@ -42,10 +45,166 @@ export function createOpenAIClient(\n     });\n   }\n \n+  if (config.provider?.toLowerCase() === \"githubcopilot\") {\n+    return new GithubCopilotClient({\n+      apiKey: getApiKey(config.provider),\n+      baseURL: getBaseUrl(config.provider),\n+      timeout: OPENAI_TIMEOUT_MS,\n+      defaultHeaders: headers,\n+    });\n+  }\n+\n   return new OpenAI({\n     apiKey: getApiKey(config.provider),\n     baseURL: getBaseUrl(config.provider),\n     timeout: OPENAI_TIMEOUT_MS,\n     defaultHeaders: headers,\n   });\n }\n+\n+export class GithubCopilotClient extends OpenAI {\n+  private copilotToken: string | null = null;\n+  private copilotTokenExpiration = new Date();\n+  private githubAPIKey: string;\n+\n+  constructor(opts: ClientOptions = {}) {\n+    super(opts);\n+    if (!opts.apiKey) {\n+      throw new Errors.OpenAIError(\"missing github copilot token\");\n+    }\n+    this.githubAPIKey = opts.apiKey;\n+  }\n+\n+  private async _getGithubCopilotToken(): Promise<string | undefined> {\n+    if (\n+      this.copilotToken &&\n+      this.copilotTokenExpiration.getTime() > Date.now()\n+    ) {\n+      return this.copilotToken;\n+    }\n+    const resp = await fetch(\n+      \"https://api.github.com/copilot_internal/v2/token\",\n+      {\n+        method: \"GET\",\n+        headers: GithubCopilotClient._mergeGithubHeaders({\n+          \"Authorization\": `bearer ${this.githubAPIKey}`,\n+          \"Accept\": \"application/json\",\n+          \"Content-Type\": \"application/json\",\n+        }),\n+      },\n+    );\n+    if (!resp.ok) {\n+      const text = await resp.text();\n+      throw new Error(\"unable to get github copilot auth token: \" + text);\n+    }\n+    const text = await resp.text();\n+    const { token, refresh_in } = JSON.parse(text);\n+    if (typeof token !== \"string\" || typeof refresh_in !== \"number\") {\n+      throw new Errors.OpenAIError(\n+        `unexpected response from copilot auth: ${text}`,\n+      );\n+    }\n+    this.copilotToken = token;\n+    this.copilotTokenExpiration = new Date(Date.now() + refresh_in * 1000);\n+    return token;\n+  }\n+\n+  protected override authHeaders(\n+    _opts: Core.FinalRequestOptions,\n+  ): Core.Headers {\n+    return {};\n+  }\n+\n+  protected override async prepareOptions(\n+    opts: Core.FinalRequestOptions<unknown>,\n+  ): Promise<void> {\n+    const token = await this._getGithubCopilotToken();\n+    opts.headers ??= {};\n+    if (token) {\n+      opts.headers[\"Authorization\"] = `Bearer ${token}`;\n+      opts.headers = GithubCopilotClient._mergeGithubHeaders(opts.headers);\n+    } else {\n+      throw new Errors.OpenAIError(\"Unable to handle auth\");\n+    }\n+    return super.prepareOptions(opts);\n+  }\n+\n+  static async getLoginURL(): Promise<{\n+    device_code: string;\n+    user_code: string;\n+    verification_uri: string;\n+  }> {\n+    const resp = await fetch(\"https://github.com/login/device/code\", {\n+      method: \"POST\",\n+      headers: this._mergeGithubHeaders({\n+        \"Content-Type\": \"application/json\",\n+        \"accept\": \"application/json\",\n+      }),\n+      body: JSON.stringify({\n+        client_id: \"Iv1.b507a08c87ecfe98\",",
        "comment_created_at": "2025-06-15T21:16:50+00:00",
        "comment_author": "Copilot",
        "comment_body": "[nitpick] This GitHub OAuth client ID is hardcoded. Consider making it a configurable constant or retrieving it from environment or config to ease updates and testing.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2058773732",
    "pr_number": 575,
    "pr_file": "codex-cli/src/utils/config.ts",
    "created_at": "2025-04-24T15:55:22+00:00",
    "commented_code": "saveHistory: boolean;\n     sensitivePatterns: Array<string>;\n   };\n+  output?: {",
    "repo_full_name": "openai/codex",
    "discussion_comments": [
      {
        "comment_id": "2058773732",
        "repo_full_name": "openai/codex",
        "pr_number": 575,
        "pr_file": "codex-cli/src/utils/config.ts",
        "discussion_id": "2058773732",
        "commented_code": "@@ -139,6 +145,10 @@ export type AppConfig = {\n     saveHistory: boolean;\n     sensitivePatterns: Array<string>;\n   };\n+  output?: {",
        "comment_created_at": "2025-04-24T15:55:22+00:00",
        "comment_author": "bolinfest",
        "comment_body": "I think we need a different name and maybe a level of two of depth.\r\n\r\nThat is, this not configuring the general \"output\" of Codex CLI. (To me, this name implies the \"output\" that I see as a user.) It is configuring something extremely specific: truncation parameters for the `shell` tool call.\r\n\r\nThis makes me wonder if should have a top level config entry named `\"tools\"` where keys are tool names that point to dictionaries of arbitrary properties for configuring that tool, so the JSON would look like:\r\n\r\n```json\r\n\"tools\": {\r\n  \"shell\": {\r\n    \"maxBytes\": 12410,\r\n    \"maxLines\": 256\r\n  }\r\n}\r\n```\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2061405280",
        "repo_full_name": "openai/codex",
        "pr_number": 575,
        "pr_file": "codex-cli/src/utils/config.ts",
        "discussion_id": "2058773732",
        "commented_code": "@@ -139,6 +145,10 @@ export type AppConfig = {\n     saveHistory: boolean;\n     sensitivePatterns: Array<string>;\n   };\n+  output?: {",
        "comment_created_at": "2025-04-26T15:35:09+00:00",
        "comment_author": "syllogismos",
        "comment_body": "I changed the config to have these keywords now instead.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2058776679",
    "pr_number": 575,
    "pr_file": "codex-cli/src/utils/agent/sandbox/raw-exec.ts",
    "created_at": "2025-04-24T15:56:56+00:00",
    "commented_code": "return new Promise<ExecResult>((resolve) => {\n     // Collect stdout and stderr up to configured limits.\n-    const stdoutCollector = createTruncatingCollector(child.stdout!);\n-    const stderrCollector = createTruncatingCollector(child.stderr!);\n+    const config = loadConfig();",
    "repo_full_name": "openai/codex",
    "discussion_comments": [
      {
        "comment_id": "2058776679",
        "repo_full_name": "openai/codex",
        "pr_number": 575,
        "pr_file": "codex-cli/src/utils/agent/sandbox/raw-exec.ts",
        "discussion_id": "2058776679",
        "commented_code": "@@ -144,8 +145,20 @@ export function exec(\n \n   return new Promise<ExecResult>((resolve) => {\n     // Collect stdout and stderr up to configured limits.\n-    const stdoutCollector = createTruncatingCollector(child.stdout!);\n-    const stderrCollector = createTruncatingCollector(child.stderr!);\n+    const config = loadConfig();",
        "comment_created_at": "2025-04-24T15:56:56+00:00",
        "comment_author": "bolinfest",
        "comment_body": "I don't think we should be loading the config at arbitrary places in the code. That means the config could change over the course of the run, which in some cases could be helpful, but in other cases I think could be quite dangerous because it could unintentionally change the behavior of a long-running agent.\r\n\r\nToday, `loadConfig()` is called once in `cli.tsx` (as it should be) and then it should be threaded through from there.",
        "pr_file_module": null
      },
      {
        "comment_id": "2061417364",
        "repo_full_name": "openai/codex",
        "pr_number": 575,
        "pr_file": "codex-cli/src/utils/agent/sandbox/raw-exec.ts",
        "discussion_id": "2058776679",
        "commented_code": "@@ -144,8 +145,20 @@ export function exec(\n \n   return new Promise<ExecResult>((resolve) => {\n     // Collect stdout and stderr up to configured limits.\n-    const stdoutCollector = createTruncatingCollector(child.stdout!);\n-    const stderrCollector = createTruncatingCollector(child.stderr!);\n+    const config = loadConfig();",
        "comment_created_at": "2025-04-26T16:04:53+00:00",
        "comment_author": "syllogismos",
        "comment_body": "You are absolutely right, we should only load config once, to be more predictable, now the config is properly being threaded until `raw_exec.ts`.\r\n\r\nPlease let me know if I'm missing anything.\r\n\r\nconfig goes from `cli.tsx` to `app.tsx` to `TerminalChat` to `AgentLoop` and then to `handle-exec-command.ts` all these have config already including `handleExecCommand` function. but with in this file theres a helper function `execCommand` where config is not passed anymore, I have introduced a new config param for this helper, and while calling this helper function im passing `config` every in the file `handle-exec-command.ts`\r\n\r\nthe helper function `execCommand` uses either `execApplyPatch` or `exec` functions further downstream.\r\n\r\nSo I handled `exec` function in `exec.ts` file to have config and which further uses `macos_seatbelt` and `raw_exec` or just `raw_exec`.\r\n\r\nI have threaded the config variable to all these downstream functions that need them, according to the flow I mentioned as far as I am aware.\r\n\r\nPlease let me know if I'm missing any other flows. I think other flows like `cli-singlepass` `TerminalChatPastRollout` flows don't need this particular config propogation.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2054911410",
    "pr_number": 537,
    "pr_file": "codex-cli/src/utils/config.ts",
    "created_at": "2025-04-22T21:28:08+00:00",
    "commented_code": "}\n \n export function getBaseUrl(provider: string = \"openai\"): string | undefined {\n-  // If the provider is `openai` and `OPENAI_BASE_URL` is set, use it\n-  if (provider === \"openai\" && OPENAI_BASE_URL !== \"\") {\n-    return OPENAI_BASE_URL;\n-  }\n-\n   // Check for a PROVIDER-specific override: e.g. OLLAMA_BASE_URL\n   const envKey = `${provider.toUpperCase()}_BASE_URL`;\n   if (process.env[envKey]) {\n     return process.env[envKey];\n   }\n \n-  // Use the default URL from providers if available\n-  const providerInfo = providers[provider.toLowerCase()];\n+  // Get providers config from config file\n+  const config = loadConfig();\n+  const providersConfig = config.providers;",
    "repo_full_name": "openai/codex",
    "discussion_comments": [
      {
        "comment_id": "2054911410",
        "repo_full_name": "openai/codex",
        "pr_number": 537,
        "pr_file": "codex-cli/src/utils/config.ts",
        "discussion_id": "2054911410",
        "commented_code": "@@ -42,19 +42,22 @@ export function setApiKey(apiKey: string): void {\n }\n \n export function getBaseUrl(provider: string = \"openai\"): string | undefined {\n-  // If the provider is `openai` and `OPENAI_BASE_URL` is set, use it\n-  if (provider === \"openai\" && OPENAI_BASE_URL !== \"\") {\n-    return OPENAI_BASE_URL;\n-  }\n-\n   // Check for a PROVIDER-specific override: e.g. OLLAMA_BASE_URL\n   const envKey = `${provider.toUpperCase()}_BASE_URL`;\n   if (process.env[envKey]) {\n     return process.env[envKey];\n   }\n \n-  // Use the default URL from providers if available\n-  const providerInfo = providers[provider.toLowerCase()];\n+  // Get providers config from config file\n+  const config = loadConfig();\n+  const providersConfig = config.providers;",
        "comment_created_at": "2025-04-22T21:28:08+00:00",
        "comment_author": "tibo-openai",
        "comment_body": "We should either refactor this so that config.providers has a sane default or so that when it is empty it defaults to `providers` here instead of an empty record.",
        "pr_file_module": null
      }
    ]
  }
]