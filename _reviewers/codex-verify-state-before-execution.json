[
  {
    "discussion_id": "2059379949",
    "pr_number": 635,
    "pr_file": "codex-cli/src/utils/agent/agent-loop.ts",
    "created_at": "2025-04-24T23:45:32+00:00",
    "commented_code": "//   2. If the user calls `cancel()` in the small window right after the\n         //      item was staged we can still abort the delivery because the\n         //      generation counter will have been bumped by `cancel()`.\n-        setTimeout(() => {\n+        // Balance performance with user experience:\n+        // - Process tokens immediately with queueMicrotask for internal logic\n+        // - Use a minimal delay (3ms) for terminal rendering to maintain readable streaming\n+        queueMicrotask(() => {\n+          // Process token immediately for internal logic\n           if (\n             thisGeneration === this.generation &&\n             !this.canceled &&\n             !this.hardAbort.signal.aborted\n           ) {\n-            this.onItem(item);\n-            // Mark as delivered so flush won't re-emit it\n-            staged[idx] = undefined;\n+            // Only the visual rendering gets the small delay\n+            // Double-check cancellation state right before emitting to avoid race conditions\n+            setTimeout(() => {",
    "repo_full_name": "openai/codex",
    "discussion_comments": [
      {
        "comment_id": "2059379949",
        "repo_full_name": "openai/codex",
        "pr_number": 635,
        "pr_file": "codex-cli/src/utils/agent/agent-loop.ts",
        "discussion_id": "2059379949",
        "commented_code": "@@ -563,16 +563,31 @@ export class AgentLoop {\n         //   2. If the user calls `cancel()` in the small window right after the\n         //      item was staged we can still abort the delivery because the\n         //      generation counter will have been bumped by `cancel()`.\n-        setTimeout(() => {\n+        // Balance performance with user experience:\n+        // - Process tokens immediately with queueMicrotask for internal logic\n+        // - Use a minimal delay (3ms) for terminal rendering to maintain readable streaming\n+        queueMicrotask(() => {\n+          // Process token immediately for internal logic\n           if (\n             thisGeneration === this.generation &&\n             !this.canceled &&\n             !this.hardAbort.signal.aborted\n           ) {\n-            this.onItem(item);\n-            // Mark as delivered so flush won't re-emit it\n-            staged[idx] = undefined;\n+            // Only the visual rendering gets the small delay\n+            // Double-check cancellation state right before emitting to avoid race conditions\n+            setTimeout(() => {",
        "comment_created_at": "2025-04-24T23:45:32+00:00",
        "comment_author": "tibo-openai",
        "comment_body": "If the user cancels within this delay then we will have inconsistent state between the transcript and what was emitted with this.onItem. This seems like a source of bugs, why is this change made?",
        "pr_file_module": null
      },
      {
        "comment_id": "2059390815",
        "repo_full_name": "openai/codex",
        "pr_number": 635,
        "pr_file": "codex-cli/src/utils/agent/agent-loop.ts",
        "discussion_id": "2059379949",
        "commented_code": "@@ -563,16 +563,31 @@ export class AgentLoop {\n         //   2. If the user calls `cancel()` in the small window right after the\n         //      item was staged we can still abort the delivery because the\n         //      generation counter will have been bumped by `cancel()`.\n-        setTimeout(() => {\n+        // Balance performance with user experience:\n+        // - Process tokens immediately with queueMicrotask for internal logic\n+        // - Use a minimal delay (3ms) for terminal rendering to maintain readable streaming\n+        queueMicrotask(() => {\n+          // Process token immediately for internal logic\n           if (\n             thisGeneration === this.generation &&\n             !this.canceled &&\n             !this.hardAbort.signal.aborted\n           ) {\n-            this.onItem(item);\n-            // Mark as delivered so flush won't re-emit it\n-            staged[idx] = undefined;\n+            // Only the visual rendering gets the small delay\n+            // Double-check cancellation state right before emitting to avoid race conditions\n+            setTimeout(() => {",
        "comment_created_at": "2025-04-25T00:07:29+00:00",
        "comment_author": "tomascupr",
        "comment_body": "I was focused on performance and thought this is more robust from the UX perspective but I didn't think about the potential inconsistency. Valid concern. Let me simplify. Thank you for feedback. I still think the performance improvement is worth it unless I'm missing something. ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2059380794",
    "pr_number": 635,
    "pr_file": "codex-cli/src/utils/agent/agent-loop.ts",
    "created_at": "2025-04-24T23:47:31+00:00",
    "commented_code": "this.onLoading(false);\n       };\n \n-      // Delay flush slightly to allow a near\u2011simultaneous cancel() to land.\n-      setTimeout(flush, 30);\n+      // Use queueMicrotask for immediate processing with a small delay for UI rendering\n+      queueMicrotask(() => {\n+        // Use a small delay to make sure UI rendering is smooth\n+        // Double-check cancellation state right before flushing to avoid race conditions\n+        setTimeout(() => {",
    "repo_full_name": "openai/codex",
    "discussion_comments": [
      {
        "comment_id": "2059380794",
        "repo_full_name": "openai/codex",
        "pr_number": 635,
        "pr_file": "codex-cli/src/utils/agent/agent-loop.ts",
        "discussion_id": "2059380794",
        "commented_code": "@@ -1196,8 +1211,20 @@ export class AgentLoop {\n         this.onLoading(false);\n       };\n \n-      // Delay flush slightly to allow a near\u2011simultaneous cancel() to land.\n-      setTimeout(flush, 30);\n+      // Use queueMicrotask for immediate processing with a small delay for UI rendering\n+      queueMicrotask(() => {\n+        // Use a small delay to make sure UI rendering is smooth\n+        // Double-check cancellation state right before flushing to avoid race conditions\n+        setTimeout(() => {",
        "comment_created_at": "2025-04-24T23:47:31+00:00",
        "comment_author": "tibo-openai",
        "comment_body": "What do we achieve here by nesting a setTimeout directly within a queueMicrotask?",
        "pr_file_module": null
      },
      {
        "comment_id": "2059388046",
        "repo_full_name": "openai/codex",
        "pr_number": 635,
        "pr_file": "codex-cli/src/utils/agent/agent-loop.ts",
        "discussion_id": "2059380794",
        "commented_code": "@@ -1196,8 +1211,20 @@ export class AgentLoop {\n         this.onLoading(false);\n       };\n \n-      // Delay flush slightly to allow a near\u2011simultaneous cancel() to land.\n-      setTimeout(flush, 30);\n+      // Use queueMicrotask for immediate processing with a small delay for UI rendering\n+      queueMicrotask(() => {\n+        // Use a small delay to make sure UI rendering is smooth\n+        // Double-check cancellation state right before flushing to avoid race conditions\n+        setTimeout(() => {",
        "comment_created_at": "2025-04-25T00:02:00+00:00",
        "comment_author": "tomascupr",
        "comment_body": "I replaced the original 10ms delay with a 3ms delay, making token streaming about 3x faster while keeping it readable for users. The nested approach (queueMicrotask \u2192 setTimeout) adds an extra cancellation check point, preventing \"ghost tokens\" from appearing after the user hits cancel. I can simplify but thought this is more robust UX.",
        "pr_file_module": null
      }
    ]
  }
]