[
  {
    "discussion_id": "2202835856",
    "pr_number": 1529,
    "pr_file": "codex-rs/tui/src/app.rs",
    "created_at": "2025-07-12T17:22:08+00:00",
    "commented_code": "}\n     }\n }\n+\n+#[cfg(test)]\n+mod tests {\n+    #![allow(clippy::unwrap_used)]\n+    use super::*;\n+    use codex_core::protocol::AgentMessageEvent;\n+    use codex_core::protocol::EventMsg;\n+    use codex_core::protocol::TaskCompleteEvent;\n+    use pretty_assertions::assert_eq;\n+\n+    #[test]\n+    fn test_create_compact_summary_prompt_with_content() {\n+        let summary_text = \"User asked about Rust. I explained ownership and borrowing.\";\n+        let result = create_compact_summary_prompt(summary_text);\n+\n+        let expected = COMPACT_SUMMARY_TEMPLATE.replace(",
    "repo_full_name": "openai/codex",
    "discussion_comments": [
      {
        "comment_id": "2202835856",
        "repo_full_name": "openai/codex",
        "pr_number": 1529,
        "pr_file": "codex-rs/tui/src/app.rs",
        "discussion_id": "2202835856",
        "commented_code": "@@ -357,3 +429,119 @@ impl<'a> App<'a> {\n         }\n     }\n }\n+\n+#[cfg(test)]\n+mod tests {\n+    #![allow(clippy::unwrap_used)]\n+    use super::*;\n+    use codex_core::protocol::AgentMessageEvent;\n+    use codex_core::protocol::EventMsg;\n+    use codex_core::protocol::TaskCompleteEvent;\n+    use pretty_assertions::assert_eq;\n+\n+    #[test]\n+    fn test_create_compact_summary_prompt_with_content() {\n+        let summary_text = \"User asked about Rust. I explained ownership and borrowing.\";\n+        let result = create_compact_summary_prompt(summary_text);\n+\n+        let expected = COMPACT_SUMMARY_TEMPLATE.replace(",
        "comment_created_at": "2025-07-12T17:22:08+00:00",
        "comment_author": "bolinfest",
        "comment_body": "I would just `assert_eq!()` using a string literal that, yes, is a copy of `COMPACT_SUMMARY_TEMPLATE`. Again, I would use `r#`.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2202873208",
    "pr_number": 1547,
    "pr_file": "codex-rs/core/src/openai_tools.rs",
    "created_at": "2025-07-12T19:05:25+00:00",
    "commented_code": "\"type\": \"function\",\n     })\n }\n+#[cfg(test)]\n+mod tests {\n+    #![allow(clippy::unwrap_used)]\n+    use super::*;\n+    use crate::client_common::Prompt;\n+    use mcp_types::{Tool, ToolInputSchema};\n+\n+    fn dummy_tool() -> (String, Tool) {\n+        (\n+            \"srv.dummy\".to_string(),\n+            Tool {\n+                annotations: None,\n+                description: Some(\"dummy\".into()),\n+                input_schema: ToolInputSchema {\n+                    properties: None,\n+                    required: None,\n+                    r#type: \"object\".to_string(),\n+                },\n+                name: \"dummy\".into(),\n+            },\n+        )\n+    }\n+\n+    #[test]\n+    fn responses_includes_default_and_extra() {\n+        let mut prompt = Prompt::default();\n+        let (name, tool) = dummy_tool();\n+        prompt.extra_tools.insert(name.clone(), tool);\n+\n+        let tools = create_tools_json_for_responses_api(&prompt, \"gpt-4\").unwrap();\n+        assert_eq!(tools.len(), 2);\n+        assert_eq!(tools[0][\"type\"], \"function\");\n+        assert_eq!(tools[0][\"name\"], \"shell\");\n+        assert!(\n+            tools\n+                .iter()\n+                .any(|t| t.get(\"name\") == Some(&name.clone().into()))",
    "repo_full_name": "openai/codex",
    "discussion_comments": [
      {
        "comment_id": "2202873208",
        "repo_full_name": "openai/codex",
        "pr_number": 1547,
        "pr_file": "codex-rs/core/src/openai_tools.rs",
        "discussion_id": "2202873208",
        "commented_code": "@@ -155,3 +155,71 @@ fn mcp_tool_to_openai_tool(\n         \"type\": \"function\",\n     })\n }\n+#[cfg(test)]\n+mod tests {\n+    #![allow(clippy::unwrap_used)]\n+    use super::*;\n+    use crate::client_common::Prompt;\n+    use mcp_types::{Tool, ToolInputSchema};\n+\n+    fn dummy_tool() -> (String, Tool) {\n+        (\n+            \"srv.dummy\".to_string(),\n+            Tool {\n+                annotations: None,\n+                description: Some(\"dummy\".into()),\n+                input_schema: ToolInputSchema {\n+                    properties: None,\n+                    required: None,\n+                    r#type: \"object\".to_string(),\n+                },\n+                name: \"dummy\".into(),\n+            },\n+        )\n+    }\n+\n+    #[test]\n+    fn responses_includes_default_and_extra() {\n+        let mut prompt = Prompt::default();\n+        let (name, tool) = dummy_tool();\n+        prompt.extra_tools.insert(name.clone(), tool);\n+\n+        let tools = create_tools_json_for_responses_api(&prompt, \"gpt-4\").unwrap();\n+        assert_eq!(tools.len(), 2);\n+        assert_eq!(tools[0][\"type\"], \"function\");\n+        assert_eq!(tools[0][\"name\"], \"shell\");\n+        assert!(\n+            tools\n+                .iter()\n+                .any(|t| t.get(\"name\") == Some(&name.clone().into()))",
        "comment_created_at": "2025-07-12T19:05:25+00:00",
        "comment_author": "bolinfest",
        "comment_body": "Maybe use `find(|t| t.get(\"name\").as_ref() == Some(\"srv.dummy\")` on `tools.iter()` or something like that and then do an `assert_eq!()` on the value returned from `find()`?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2202874282",
    "pr_number": 1547,
    "pr_file": "codex-rs/core/src/openai_tools.rs",
    "created_at": "2025-07-12T19:07:30+00:00",
    "commented_code": "\"type\": \"function\",\n     })\n }\n+#[cfg(test)]\n+mod tests {\n+    #![allow(clippy::unwrap_used)]\n+    use super::*;\n+    use crate::client_common::Prompt;\n+    use mcp_types::{Tool, ToolInputSchema};\n+\n+    fn dummy_tool() -> (String, Tool) {\n+        (\n+            \"srv.dummy\".to_string(),\n+            Tool {\n+                annotations: None,\n+                description: Some(\"dummy\".into()),\n+                input_schema: ToolInputSchema {\n+                    properties: None,\n+                    required: None,\n+                    r#type: \"object\".to_string(),\n+                },\n+                name: \"dummy\".into(),\n+            },\n+        )\n+    }\n+\n+    #[test]\n+    fn responses_includes_default_and_extra() {\n+        let mut prompt = Prompt::default();\n+        let (name, tool) = dummy_tool();\n+        prompt.extra_tools.insert(name.clone(), tool);\n+\n+        let tools = create_tools_json_for_responses_api(&prompt, \"gpt-4\").unwrap();\n+        assert_eq!(tools.len(), 2);\n+        assert_eq!(tools[0][\"type\"], \"function\");\n+        assert_eq!(tools[0][\"name\"], \"shell\");\n+        assert!(\n+            tools\n+                .iter()\n+                .any(|t| t.get(\"name\") == Some(&name.clone().into()))\n+        );\n+    }\n+\n+    #[test]",
    "repo_full_name": "openai/codex",
    "discussion_comments": [
      {
        "comment_id": "2202874282",
        "repo_full_name": "openai/codex",
        "pr_number": 1547,
        "pr_file": "codex-rs/core/src/openai_tools.rs",
        "discussion_id": "2202874282",
        "commented_code": "@@ -155,3 +155,71 @@ fn mcp_tool_to_openai_tool(\n         \"type\": \"function\",\n     })\n }\n+#[cfg(test)]\n+mod tests {\n+    #![allow(clippy::unwrap_used)]\n+    use super::*;\n+    use crate::client_common::Prompt;\n+    use mcp_types::{Tool, ToolInputSchema};\n+\n+    fn dummy_tool() -> (String, Tool) {\n+        (\n+            \"srv.dummy\".to_string(),\n+            Tool {\n+                annotations: None,\n+                description: Some(\"dummy\".into()),\n+                input_schema: ToolInputSchema {\n+                    properties: None,\n+                    required: None,\n+                    r#type: \"object\".to_string(),\n+                },\n+                name: \"dummy\".into(),\n+            },\n+        )\n+    }\n+\n+    #[test]\n+    fn responses_includes_default_and_extra() {\n+        let mut prompt = Prompt::default();\n+        let (name, tool) = dummy_tool();\n+        prompt.extra_tools.insert(name.clone(), tool);\n+\n+        let tools = create_tools_json_for_responses_api(&prompt, \"gpt-4\").unwrap();\n+        assert_eq!(tools.len(), 2);\n+        assert_eq!(tools[0][\"type\"], \"function\");\n+        assert_eq!(tools[0][\"name\"], \"shell\");\n+        assert!(\n+            tools\n+                .iter()\n+                .any(|t| t.get(\"name\") == Some(&name.clone().into()))\n+        );\n+    }\n+\n+    #[test]",
        "comment_created_at": "2025-07-12T19:07:30+00:00",
        "comment_author": "bolinfest",
        "comment_body": "For both of these tests, can we just assert the entire string/serde_json::Value that we get back? I realize this means that we will have to update this test if we change the default tools, but I think having a test that verifies _everything_ (and effectively documents what we send on the wire) is worth that maintenance cost.",
        "pr_file_module": null
      },
      {
        "comment_id": "2202988541",
        "repo_full_name": "openai/codex",
        "pr_number": 1547,
        "pr_file": "codex-rs/core/src/openai_tools.rs",
        "discussion_id": "2202874282",
        "commented_code": "@@ -155,3 +155,71 @@ fn mcp_tool_to_openai_tool(\n         \"type\": \"function\",\n     })\n }\n+#[cfg(test)]\n+mod tests {\n+    #![allow(clippy::unwrap_used)]\n+    use super::*;\n+    use crate::client_common::Prompt;\n+    use mcp_types::{Tool, ToolInputSchema};\n+\n+    fn dummy_tool() -> (String, Tool) {\n+        (\n+            \"srv.dummy\".to_string(),\n+            Tool {\n+                annotations: None,\n+                description: Some(\"dummy\".into()),\n+                input_schema: ToolInputSchema {\n+                    properties: None,\n+                    required: None,\n+                    r#type: \"object\".to_string(),\n+                },\n+                name: \"dummy\".into(),\n+            },\n+        )\n+    }\n+\n+    #[test]\n+    fn responses_includes_default_and_extra() {\n+        let mut prompt = Prompt::default();\n+        let (name, tool) = dummy_tool();\n+        prompt.extra_tools.insert(name.clone(), tool);\n+\n+        let tools = create_tools_json_for_responses_api(&prompt, \"gpt-4\").unwrap();\n+        assert_eq!(tools.len(), 2);\n+        assert_eq!(tools[0][\"type\"], \"function\");\n+        assert_eq!(tools[0][\"name\"], \"shell\");\n+        assert!(\n+            tools\n+                .iter()\n+                .any(|t| t.get(\"name\") == Some(&name.clone().into()))\n+        );\n+    }\n+\n+    #[test]",
        "comment_created_at": "2025-07-12T22:52:56+00:00",
        "comment_author": "aibrahim-oai",
        "comment_body": "Done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2202864002",
    "pr_number": 1541,
    "pr_file": "codex-rs/core/src/client.rs",
    "created_at": "2025-07-12T18:30:15+00:00",
    "commented_code": "tokio::spawn(process_sse(stream, tx_event));\n     Ok(ResponseStream { rx_event })\n }\n+\n+#[cfg(test)]\n+mod tests {\n+    use super::*;\n+    use tokio::sync::mpsc;\n+    use tokio_test::io::Builder as IoBuilder;\n+\n+    /// Helper that runs the SSE parser on the provided chunks and collects all events.\n+    async fn collect_events(chunks: &[&[u8]]) -> Vec<Result<ResponseEvent>> {\n+        let mut builder = IoBuilder::new();\n+        for chunk in chunks {\n+            builder.read(chunk);\n+        }\n+\n+        let reader = builder.build();\n+        let stream = ReaderStream::new(reader).map_err(CodexErr::Io);\n+        let (tx, mut rx) = mpsc::channel::<Result<ResponseEvent>>(16);\n+        tokio::spawn(process_sse(stream, tx));\n+\n+        let mut events = Vec::new();\n+        while let Some(ev) = rx.recv().await {\n+            events.push(ev);\n+        }\n+        events\n+    }\n+\n+    #[tokio::test]\n+    async fn parses_items_and_completed() {\n+        let item1 = serde_json::json!({\n+            \"type\": \"response.output_item.done\",\n+            \"item\": {\n+                \"type\": \"message\",\n+                \"role\": \"assistant\",\n+                \"content\": [{\"type\": \"output_text\", \"text\": \"Hello\"}]\n+            }\n+        })\n+        .to_string();\n+\n+        let item2 = serde_json::json!({\n+            \"type\": \"response.output_item.done\",\n+            \"item\": {\n+                \"type\": \"message\",\n+                \"role\": \"assistant\",\n+                \"content\": [{\"type\": \"output_text\", \"text\": \"World\"}]\n+            }\n+        })\n+        .to_string();\n+\n+        let completed = serde_json::json!({\n+            \"type\": \"response.completed\",\n+            \"response\": {\"id\": \"resp1\"}\n+        })\n+        .to_string();\n+\n+        let sse1 = format!(\"event: response.output_item.done\ndata: {item1}\n\n\");\n+        let sse2 = format!(\"event: response.output_item.done\ndata: {item2}\n\n\");\n+        let sse3 = format!(\"event: response.completed\ndata: {completed}\n\n\");\n+\n+        let events = collect_events(&[sse1.as_bytes(), sse2.as_bytes(), sse3.as_bytes()]).await;\n+\n+        assert_eq!(events.len(), 3);\n+\n+        match &events[0] {\n+            Ok(ResponseEvent::OutputItemDone(ResponseItem::Message { role, .. })) => {\n+                assert_eq!(role, \"assistant\")\n+            }\n+            other => panic!(\"unexpected first event: {other:?}\"),\n+        }\n+\n+        match &events[1] {\n+            Ok(ResponseEvent::OutputItemDone(ResponseItem::Message { role, .. })) => {\n+                assert_eq!(role, \"assistant\")\n+            }\n+            other => panic!(\"unexpected second event: {other:?}\"),\n+        }\n+\n+        match &events[2] {\n+            Ok(ResponseEvent::Completed {\n+                response_id,\n+                token_usage,\n+            }) => {\n+                assert_eq!(response_id, \"resp1\");\n+                assert!(token_usage.is_none());\n+            }\n+            other => panic!(\"unexpected third event: {other:?}\"),\n+        }\n+    }",
    "repo_full_name": "openai/codex",
    "discussion_comments": [
      {
        "comment_id": "2202864002",
        "repo_full_name": "openai/codex",
        "pr_number": 1541,
        "pr_file": "codex-rs/core/src/client.rs",
        "discussion_id": "2202864002",
        "commented_code": "@@ -391,3 +391,122 @@ async fn stream_from_fixture(path: impl AsRef<Path>) -> Result<ResponseStream> {\n     tokio::spawn(process_sse(stream, tx_event));\n     Ok(ResponseStream { rx_event })\n }\n+\n+#[cfg(test)]\n+mod tests {\n+    use super::*;\n+    use tokio::sync::mpsc;\n+    use tokio_test::io::Builder as IoBuilder;\n+\n+    /// Helper that runs the SSE parser on the provided chunks and collects all events.\n+    async fn collect_events(chunks: &[&[u8]]) -> Vec<Result<ResponseEvent>> {\n+        let mut builder = IoBuilder::new();\n+        for chunk in chunks {\n+            builder.read(chunk);\n+        }\n+\n+        let reader = builder.build();\n+        let stream = ReaderStream::new(reader).map_err(CodexErr::Io);\n+        let (tx, mut rx) = mpsc::channel::<Result<ResponseEvent>>(16);\n+        tokio::spawn(process_sse(stream, tx));\n+\n+        let mut events = Vec::new();\n+        while let Some(ev) = rx.recv().await {\n+            events.push(ev);\n+        }\n+        events\n+    }\n+\n+    #[tokio::test]\n+    async fn parses_items_and_completed() {\n+        let item1 = serde_json::json!({\n+            \"type\": \"response.output_item.done\",\n+            \"item\": {\n+                \"type\": \"message\",\n+                \"role\": \"assistant\",\n+                \"content\": [{\"type\": \"output_text\", \"text\": \"Hello\"}]\n+            }\n+        })\n+        .to_string();\n+\n+        let item2 = serde_json::json!({\n+            \"type\": \"response.output_item.done\",\n+            \"item\": {\n+                \"type\": \"message\",\n+                \"role\": \"assistant\",\n+                \"content\": [{\"type\": \"output_text\", \"text\": \"World\"}]\n+            }\n+        })\n+        .to_string();\n+\n+        let completed = serde_json::json!({\n+            \"type\": \"response.completed\",\n+            \"response\": {\"id\": \"resp1\"}\n+        })\n+        .to_string();\n+\n+        let sse1 = format!(\"event: response.output_item.done\\ndata: {item1}\\n\\n\");\n+        let sse2 = format!(\"event: response.output_item.done\\ndata: {item2}\\n\\n\");\n+        let sse3 = format!(\"event: response.completed\\ndata: {completed}\\n\\n\");\n+\n+        let events = collect_events(&[sse1.as_bytes(), sse2.as_bytes(), sse3.as_bytes()]).await;\n+\n+        assert_eq!(events.len(), 3);\n+\n+        match &events[0] {\n+            Ok(ResponseEvent::OutputItemDone(ResponseItem::Message { role, .. })) => {\n+                assert_eq!(role, \"assistant\")\n+            }\n+            other => panic!(\"unexpected first event: {other:?}\"),\n+        }\n+\n+        match &events[1] {\n+            Ok(ResponseEvent::OutputItemDone(ResponseItem::Message { role, .. })) => {\n+                assert_eq!(role, \"assistant\")\n+            }\n+            other => panic!(\"unexpected second event: {other:?}\"),\n+        }\n+\n+        match &events[2] {\n+            Ok(ResponseEvent::Completed {\n+                response_id,\n+                token_usage,\n+            }) => {\n+                assert_eq!(response_id, \"resp1\");\n+                assert!(token_usage.is_none());\n+            }\n+            other => panic!(\"unexpected third event: {other:?}\"),\n+        }\n+    }",
        "comment_created_at": "2025-07-12T18:30:15+00:00",
        "comment_author": "bolinfest",
        "comment_body": "This is a natural thing to do, but whenever possible, please just do one big `assert_eq!()` rather than doing a bunch of piecemeal `assert_eq!()` calls, so something like:\r\n\r\n```suggestion\r\n        assert_eq!(events, vec![\r\n            Ok(ResponseEvent::OutputItemDone(ResponseItem::Message { role: \"assistant\" }),\r\n            Ok(ResponseEvent::OutputItemDone(ResponseItem::Message { role, \"assistant\" }),\r\n            Ok(ResponseEvent::Completed { response_id: \"resp1\", token_usage: None })\r\n        ]);\r\n```\r\n\r\nI think you can also potentially do an `iter` / `collect()` on `events` to convert `Vec<Result<T>>` into `Result<Vec<T>>`.\r\n\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2203048690",
        "repo_full_name": "openai/codex",
        "pr_number": 1541,
        "pr_file": "codex-rs/core/src/client.rs",
        "discussion_id": "2202864002",
        "commented_code": "@@ -391,3 +391,122 @@ async fn stream_from_fixture(path: impl AsRef<Path>) -> Result<ResponseStream> {\n     tokio::spawn(process_sse(stream, tx_event));\n     Ok(ResponseStream { rx_event })\n }\n+\n+#[cfg(test)]\n+mod tests {\n+    use super::*;\n+    use tokio::sync::mpsc;\n+    use tokio_test::io::Builder as IoBuilder;\n+\n+    /// Helper that runs the SSE parser on the provided chunks and collects all events.\n+    async fn collect_events(chunks: &[&[u8]]) -> Vec<Result<ResponseEvent>> {\n+        let mut builder = IoBuilder::new();\n+        for chunk in chunks {\n+            builder.read(chunk);\n+        }\n+\n+        let reader = builder.build();\n+        let stream = ReaderStream::new(reader).map_err(CodexErr::Io);\n+        let (tx, mut rx) = mpsc::channel::<Result<ResponseEvent>>(16);\n+        tokio::spawn(process_sse(stream, tx));\n+\n+        let mut events = Vec::new();\n+        while let Some(ev) = rx.recv().await {\n+            events.push(ev);\n+        }\n+        events\n+    }\n+\n+    #[tokio::test]\n+    async fn parses_items_and_completed() {\n+        let item1 = serde_json::json!({\n+            \"type\": \"response.output_item.done\",\n+            \"item\": {\n+                \"type\": \"message\",\n+                \"role\": \"assistant\",\n+                \"content\": [{\"type\": \"output_text\", \"text\": \"Hello\"}]\n+            }\n+        })\n+        .to_string();\n+\n+        let item2 = serde_json::json!({\n+            \"type\": \"response.output_item.done\",\n+            \"item\": {\n+                \"type\": \"message\",\n+                \"role\": \"assistant\",\n+                \"content\": [{\"type\": \"output_text\", \"text\": \"World\"}]\n+            }\n+        })\n+        .to_string();\n+\n+        let completed = serde_json::json!({\n+            \"type\": \"response.completed\",\n+            \"response\": {\"id\": \"resp1\"}\n+        })\n+        .to_string();\n+\n+        let sse1 = format!(\"event: response.output_item.done\\ndata: {item1}\\n\\n\");\n+        let sse2 = format!(\"event: response.output_item.done\\ndata: {item2}\\n\\n\");\n+        let sse3 = format!(\"event: response.completed\\ndata: {completed}\\n\\n\");\n+\n+        let events = collect_events(&[sse1.as_bytes(), sse2.as_bytes(), sse3.as_bytes()]).await;\n+\n+        assert_eq!(events.len(), 3);\n+\n+        match &events[0] {\n+            Ok(ResponseEvent::OutputItemDone(ResponseItem::Message { role, .. })) => {\n+                assert_eq!(role, \"assistant\")\n+            }\n+            other => panic!(\"unexpected first event: {other:?}\"),\n+        }\n+\n+        match &events[1] {\n+            Ok(ResponseEvent::OutputItemDone(ResponseItem::Message { role, .. })) => {\n+                assert_eq!(role, \"assistant\")\n+            }\n+            other => panic!(\"unexpected second event: {other:?}\"),\n+        }\n+\n+        match &events[2] {\n+            Ok(ResponseEvent::Completed {\n+                response_id,\n+                token_usage,\n+            }) => {\n+                assert_eq!(response_id, \"resp1\");\n+                assert!(token_usage.is_none());\n+            }\n+            other => panic!(\"unexpected third event: {other:?}\"),\n+        }\n+    }",
        "comment_created_at": "2025-07-13T02:02:34+00:00",
        "comment_author": "aibrahim-oai",
        "comment_body": "`ResponseEvent` doesn't have `==` impl",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2091742715",
    "pr_number": 942,
    "pr_file": "codex-rs/apply-patch/src/lib.rs",
    "created_at": "2025-05-15T18:20:33+00:00",
    "commented_code": "\"#\n         );\n     }\n+\n+    #[test]\n+    fn test_apply_patch_should_resolve_absolute_paths_in_cwd() {\n+        let session_dir = tempdir().unwrap();\n+        let relative_path = \"source.txt\";\n+\n+        // Note that we need this file to exists for the patch to be \"verified\"\n+        // and parsed correctly.\n+        let session_file_path = session_dir.path().join(relative_path);\n+        fs::write(&session_file_path, \"session directory content\n\").unwrap();\n+\n+        let argv = vec![\n+            \"apply_patch\".to_string(),\n+            r#\"*** Begin Patch\n+*** Update File: source.txt\n+@@\n+-session directory content\n++updated session directory content\n+*** End Patch\"#\n+                .to_string(),\n+        ];\n+\n+        let result = maybe_parse_apply_patch_verified(&argv, session_dir.path());\n+        assert!(matches!(result, MaybeApplyPatchVerified::Body(_)));",
    "repo_full_name": "openai/codex",
    "discussion_comments": [
      {
        "comment_id": "2091742715",
        "repo_full_name": "openai/codex",
        "pr_number": 942,
        "pr_file": "codex-rs/apply-patch/src/lib.rs",
        "discussion_id": "2091742715",
        "commented_code": "@@ -1137,4 +1138,55 @@ g\n \"#\n         );\n     }\n+\n+    #[test]\n+    fn test_apply_patch_should_resolve_absolute_paths_in_cwd() {\n+        let session_dir = tempdir().unwrap();\n+        let relative_path = \"source.txt\";\n+\n+        // Note that we need this file to exists for the patch to be \"verified\"\n+        // and parsed correctly.\n+        let session_file_path = session_dir.path().join(relative_path);\n+        fs::write(&session_file_path, \"session directory content\\n\").unwrap();\n+\n+        let argv = vec![\n+            \"apply_patch\".to_string(),\n+            r#\"*** Begin Patch\n+*** Update File: source.txt\n+@@\n+-session directory content\n++updated session directory content\n+*** End Patch\"#\n+                .to_string(),\n+        ];\n+\n+        let result = maybe_parse_apply_patch_verified(&argv, session_dir.path());\n+        assert!(matches!(result, MaybeApplyPatchVerified::Body(_)));",
        "comment_created_at": "2025-05-15T18:20:33+00:00",
        "comment_author": "bolinfest",
        "comment_body": "For clarity, would you mind just doing `assert_eq!` on the full struct? Admittedly, I think you need to `derive(PartialEq)` on `MaybeApplyPatchVerified` and some things to do that.\r\n\r\nWhen possible, I find that to be much stronger than doing `assert_eq!` on individual fields.",
        "pr_file_module": null
      }
    ]
  }
]