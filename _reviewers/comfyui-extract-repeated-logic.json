[
  {
    "discussion_id": "2201962487",
    "pr_number": 8875,
    "pr_file": "server.py",
    "created_at": "2025-07-11T22:07:49+00:00",
    "commented_code": "ram_free = comfy.model_management.get_free_memory(cpu_device)\n             vram_total, torch_vram_total = comfy.model_management.get_total_memory(device, torch_total_too=True)\n             vram_free, torch_vram_free = comfy.model_management.get_free_memory(device, torch_free_too=True)\n+            required_frontend_version = open(os.path.join(os.path.dirname(__file__), \"requirements.txt\")).readline().split(\"==\")[1].strip()",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "2201962487",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 8875,
        "pr_file": "server.py",
        "discussion_id": "2201962487",
        "commented_code": "@@ -553,13 +553,15 @@ async def system_stats(request):\n             ram_free = comfy.model_management.get_free_memory(cpu_device)\n             vram_total, torch_vram_total = comfy.model_management.get_total_memory(device, torch_total_too=True)\n             vram_free, torch_vram_free = comfy.model_management.get_free_memory(device, torch_free_too=True)\n+            required_frontend_version = open(os.path.join(os.path.dirname(__file__), \"requirements.txt\")).readline().split(\"==\")[1].strip()",
        "comment_created_at": "2025-07-11T22:07:49+00:00",
        "comment_author": "christian-byrne",
        "comment_body": "In this module server.py, we already import the `FrontendManager`. We may be able to make this more robust by just refactoring `FrontendManager.check_frontend_version` into two functinos and moving the version parsing to a new function like `get_frontend_version`. Then we can call that `get_frontend_version` here",
        "pr_file_module": null
      },
      {
        "comment_id": "2202474583",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 8875,
        "pr_file": "server.py",
        "discussion_id": "2201962487",
        "commented_code": "@@ -553,13 +553,15 @@ async def system_stats(request):\n             ram_free = comfy.model_management.get_free_memory(cpu_device)\n             vram_total, torch_vram_total = comfy.model_management.get_total_memory(device, torch_total_too=True)\n             vram_free, torch_vram_free = comfy.model_management.get_free_memory(device, torch_free_too=True)\n+            required_frontend_version = open(os.path.join(os.path.dirname(__file__), \"requirements.txt\")).readline().split(\"==\")[1].strip()",
        "comment_created_at": "2025-07-12T09:39:05+00:00",
        "comment_author": "shivansh-gupta4",
        "comment_body": "Thank you for the feedback and apologies for not meeting your expectations. I\u2019ve made the necessary changes in the latest commit:\r\n\r\n- Created a new function `get_required_frontend_version()`\r\n- Added a helper function to validate whether a version string is a valid SemVer\r\n- Included a unit test for this logic in `frontend_manager_test.py`\r\n\r\nPlease let me know if there are any further improvements you'd like me to make \u2014 I\u2019d be happy to adjust accordingly.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2192878525",
    "pr_number": 8833,
    "pr_file": "nodes.py",
    "created_at": "2025-07-08T15:48:28+00:00",
    "commented_code": "disable_noise = True\n         return common_ksampler(model, noise_seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise, disable_noise=disable_noise, start_step=start_at_step, last_step=end_at_step, force_full_denoise=force_full_denoise)\n \n-class SaveImage:\n+\n+class SaveImage(io.ComfyNodeV3):\n+    @classmethod\n+    def DEFINE_SCHEMA(cls):\n+        return io.SchemaV3(\n+            node_id=\"SaveImage\",\n+            display_name=\"Save Image\",\n+            description=\"Saves the input images to your ComfyUI output directory.\",\n+            category=\"image\",\n+            inputs=[\n+                io.Image.Input(\n+                    \"images\",\n+                    display_name=\"images\",\n+                    tooltip=\"The images to save.\",\n+                ),\n+                io.String.Input(\n+                    \"filename_prefix\",\n+                    default=\"ComfyUI\",\n+                    tooltip=\"The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes.\",\n+                ),\n+            ],\n+            hidden=[io.Hidden.prompt, io.Hidden.extra_pnginfo],\n+            is_output_node=True,\n+        )\n+\n     def __init__(self):\n+        super().__init__()",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "2192878525",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 8833,
        "pr_file": "nodes.py",
        "discussion_id": "2192878525",
        "commented_code": "@@ -1550,34 +1550,39 @@ def sample(self, model, add_noise, noise_seed, steps, cfg, sampler_name, schedul\n             disable_noise = True\n         return common_ksampler(model, noise_seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise, disable_noise=disable_noise, start_step=start_at_step, last_step=end_at_step, force_full_denoise=force_full_denoise)\n \n-class SaveImage:\n+\n+class SaveImage(io.ComfyNodeV3):\n+    @classmethod\n+    def DEFINE_SCHEMA(cls):\n+        return io.SchemaV3(\n+            node_id=\"SaveImage\",\n+            display_name=\"Save Image\",\n+            description=\"Saves the input images to your ComfyUI output directory.\",\n+            category=\"image\",\n+            inputs=[\n+                io.Image.Input(\n+                    \"images\",\n+                    display_name=\"images\",\n+                    tooltip=\"The images to save.\",\n+                ),\n+                io.String.Input(\n+                    \"filename_prefix\",\n+                    default=\"ComfyUI\",\n+                    tooltip=\"The prefix for the file to save. This may include formatting information such as %date:yyyy-MM-dd% or %Empty Latent Image.width% to include values from nodes.\",\n+                ),\n+            ],\n+            hidden=[io.Hidden.prompt, io.Hidden.extra_pnginfo],\n+            is_output_node=True,\n+        )\n+\n     def __init__(self):\n+        super().__init__()",
        "comment_created_at": "2025-07-08T15:48:28+00:00",
        "comment_author": "Kosinkadink",
        "comment_body": "In v3, __init__/self will no longer be accessible in the execute function (since it receives a modified class type) - you may need to move these hardcoded values into the body of execute. Since this node in v1 was being referenced by others as you mentioned, maybe we should extract the guts of execute into a separate function that expects all the values that are currently stored in self to be passed in explicitly.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2192891732",
    "pr_number": 8833,
    "pr_file": "nodes.py",
    "created_at": "2025-07-08T15:54:56+00:00",
    "commented_code": "results.append({\n                 \"filename\": file,\n                 \"subfolder\": subfolder,\n-                \"type\": self.type\n+                \"type\": self.type,\n             })\n             counter += 1\n \n         return { \"ui\": { \"images\": results } }\n \n+\n class PreviewImage(SaveImage):\n+    @classmethod",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "2192891732",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 8833,
        "pr_file": "nodes.py",
        "discussion_id": "2192891732",
        "commented_code": "@@ -1599,44 +1604,69 @@ def save_images(self, images, filename_prefix=\"ComfyUI\", prompt=None, extra_pngi\n             results.append({\n                 \"filename\": file,\n                 \"subfolder\": subfolder,\n-                \"type\": self.type\n+                \"type\": self.type,\n             })\n             counter += 1\n \n         return { \"ui\": { \"images\": results } }\n \n+\n class PreviewImage(SaveImage):\n+    @classmethod",
        "comment_created_at": "2025-07-08T15:54:56+00:00",
        "comment_author": "Kosinkadink",
        "comment_body": "For PreviewImage, I have actually already extracted the logic to work directly with NodeOutput with a helper! Example is in nodes_v3_test.py (the ui= portion): https://github.com/comfyanonymous/ComfyUI/blob/aff52712915fc61dfd487a53e31687ae6f2be51a/comfy_extras/nodes_v3_test.py#L99",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1485632516",
    "pr_number": 2750,
    "pr_file": "comfy/model_management.py",
    "created_at": "2024-02-11T17:22:51+00:00",
    "commented_code": "dev = get_torch_device()\n \n     if hasattr(dev, 'type') and (dev.type == 'cpu' or dev.type == 'mps'):\n-        mem_free_total = psutil.virtual_memory().available\n-        mem_free_torch = mem_free_total\n+        if os.path.isfile('/sys/fs/cgroup/memory/memory.limit_in_bytes'):\n+            with open('/sys/fs/cgroup/memory/memory.limit_in_bytes', 'r') as f:\n+                mem_used_total = psutil.virtual_memory().used\n+                mem_total = int(f.read())",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "1485632516",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 2750,
        "pr_file": "comfy/model_management.py",
        "discussion_id": "1485632516",
        "commented_code": "@@ -650,8 +656,15 @@ def get_free_memory(dev=None, torch_free_too=False):\n         dev = get_torch_device()\n \n     if hasattr(dev, 'type') and (dev.type == 'cpu' or dev.type == 'mps'):\n-        mem_free_total = psutil.virtual_memory().available\n-        mem_free_torch = mem_free_total\n+        if os.path.isfile('/sys/fs/cgroup/memory/memory.limit_in_bytes'):\n+            with open('/sys/fs/cgroup/memory/memory.limit_in_bytes', 'r') as f:\n+                mem_used_total = psutil.virtual_memory().used\n+                mem_total = int(f.read())",
        "comment_created_at": "2024-02-11T17:22:51+00:00",
        "comment_author": "comfyanonymous",
        "comment_body": "Since these few lines are repeated above can you put them into their own function?",
        "pr_file_module": null
      },
      {
        "comment_id": "1486563129",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 2750,
        "pr_file": "comfy/model_management.py",
        "discussion_id": "1485632516",
        "commented_code": "@@ -650,8 +656,15 @@ def get_free_memory(dev=None, torch_free_too=False):\n         dev = get_torch_device()\n \n     if hasattr(dev, 'type') and (dev.type == 'cpu' or dev.type == 'mps'):\n-        mem_free_total = psutil.virtual_memory().available\n-        mem_free_torch = mem_free_total\n+        if os.path.isfile('/sys/fs/cgroup/memory/memory.limit_in_bytes'):\n+            with open('/sys/fs/cgroup/memory/memory.limit_in_bytes', 'r') as f:\n+                mem_used_total = psutil.virtual_memory().used\n+                mem_total = int(f.read())",
        "comment_created_at": "2024-02-12T17:55:49+00:00",
        "comment_author": "aireet",
        "comment_body": "> Since these few lines are repeated above can you put them into their own function?\r\n\r\ndone, i put them in get_containerd_memory_limit",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1788285557",
    "pr_number": 5152,
    "pr_file": "app/frontend_management.py",
    "created_at": "2024-10-04T20:39:27+00:00",
    "commented_code": "return cls.DEFAULT_FRONTEND_PATH\n \n         repo_owner, repo_name, version = cls.parse_version_string(version_string)\n+\n+        if version.startswith(\"v\"):",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "1788285557",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 5152,
        "pr_file": "app/frontend_management.py",
        "discussion_id": "1788285557",
        "commented_code": "@@ -151,6 +151,15 @@ def init_frontend_unsafe(cls, version_string: str, provider: Optional[FrontEndPr\n             return cls.DEFAULT_FRONTEND_PATH\n \n         repo_owner, repo_name, version = cls.parse_version_string(version_string)\n+\n+        if version.startswith(\"v\"):",
        "comment_created_at": "2024-10-04T20:39:27+00:00",
        "comment_author": "huchenlei",
        "comment_body": "Can you try avoid repeating this get expected path logic here? Extract it into a function?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1567255047",
    "pr_number": 2666,
    "pr_file": "execution.py",
    "created_at": "2024-04-16T12:15:43+00:00",
    "commented_code": "else:\n         return str(x)\n \n-def recursive_execute(server, prompt, outputs, current_item, extra_data, executed, prompt_id, outputs_ui, object_storage):",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "1567255047",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 2666,
        "pr_file": "execution.py",
        "discussion_id": "1567255047",
        "commented_code": "@@ -116,53 +234,143 @@ def format_value(x):\n     else:\n         return str(x)\n \n-def recursive_execute(server, prompt, outputs, current_item, extra_data, executed, prompt_id, outputs_ui, object_storage):",
        "comment_created_at": "2024-04-16T12:15:43+00:00",
        "comment_author": "kvochko",
        "comment_body": "This function has become too complex. Would you please consider refactoring and documenting? For refactoring I would suggest splitting into a separate function:\r\n* the handling of a resolved pending subgraph,\r\n* the else branch of the same condition,\r\n* the handling of the returned subgraph.\r\n\r\nFor documentation, could you please add a comment explaining the `pending_subgraph_results` structure (a dictionary of node_id -> List of tuples, where each tuple consists of an `is_subgraph` flag and the links to the outputs of that subgraph), and what it's used for?",
        "pr_file_module": null
      },
      {
        "comment_id": "1642099932",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 2666,
        "pr_file": "execution.py",
        "discussion_id": "1567255047",
        "commented_code": "@@ -116,53 +234,143 @@ def format_value(x):\n     else:\n         return str(x)\n \n-def recursive_execute(server, prompt, outputs, current_item, extra_data, executed, prompt_id, outputs_ui, object_storage):",
        "comment_created_at": "2024-06-17T03:15:41+00:00",
        "comment_author": "guill",
        "comment_body": "I realized I never responded to this comment. I attempted to refactor this, but enough data has to be passed around between all components that I'm not convinced it's actually more readable/maintainable.\r\n\r\nAny opinion? https://github.com/guill/ComfyUI/commit/2ff98c09a7547e6694f1280a3f5295c99c55a9a7",
        "pr_file_module": null
      },
      {
        "comment_id": "1660525857",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 2666,
        "pr_file": "execution.py",
        "discussion_id": "1567255047",
        "commented_code": "@@ -116,53 +234,143 @@ def format_value(x):\n     else:\n         return str(x)\n \n-def recursive_execute(server, prompt, outputs, current_item, extra_data, executed, prompt_id, outputs_ui, object_storage):",
        "comment_created_at": "2024-07-01T06:20:16+00:00",
        "comment_author": "kvochko",
        "comment_body": "I think simply splitting this into smaller functions has merit of its own, even if there is lots of data passed between components - otherwise we're breaking the single responsibility principle. However, this is a matter of taste, not function, so feel free to ignore it if you don't agree.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1772898511",
    "pr_number": 2164,
    "pr_file": "server.py",
    "created_at": "2024-09-24T08:29:06+00:00",
    "commented_code": "else:\n                 return web.json_response({\"error\": \"no prompt\", \"node_errors\": []}, status=400)\n \n+        @routes.post(\"/prompt_async\")\n+        async def post_prompt_async(request):\n+            print(\"yeeehaw\")\n+            resp_code = 200\n+            out_string = \"\"\n+            json_data = await request.json()\n+            json_data = self.trigger_on_prompt(json_data)\n+\n+            if \"number\" in json_data:",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "1772898511",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 2164,
        "pr_file": "server.py",
        "discussion_id": "1772898511",
        "commented_code": "@@ -488,6 +488,48 @@ async def post_prompt(request):\n             else:\n                 return web.json_response({\"error\": \"no prompt\", \"node_errors\": []}, status=400)\n \n+        @routes.post(\"/prompt_async\")\n+        async def post_prompt_async(request):\n+            print(\"yeeehaw\")\n+            resp_code = 200\n+            out_string = \"\"\n+            json_data = await request.json()\n+            json_data = self.trigger_on_prompt(json_data)\n+\n+            if \"number\" in json_data:",
        "comment_created_at": "2024-09-24T08:29:06+00:00",
        "comment_author": "mcmonkey4eva",
        "comment_body": "should factor out the common `/prompt` variant code into a single function, and only contain the unique bits at the end in the individual impls",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1173276977",
    "pr_number": 541,
    "pr_file": "folder_paths.py",
    "created_at": "2023-04-21T03:50:09+00:00",
    "commented_code": "return None\n \n \n+# determine base_dir rely on annotation if name is 'filename.ext [annotation]' format\n+# otherwise use default_path as base_dir\n+def get_annotated_filepath(name, default_dir=None):\n+    if name.endswith(\"[output]\"):\n+        base_dir = get_output_directory()\n+        name = name[:-9]\n+    elif name.endswith(\"[input]\"):\n+        base_dir = get_input_directory()\n+        name = name[:-8]\n+    elif name.endswith(\"[temp]\"):\n+        base_dir = get_temp_directory()\n+        name = name[:-7]",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "1173276977",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 541,
        "pr_file": "folder_paths.py",
        "discussion_id": "1173276977",
        "commented_code": "@@ -68,6 +68,41 @@ def get_directory_by_type(type_name):\n     return None\n \n \n+# determine base_dir rely on annotation if name is 'filename.ext [annotation]' format\n+# otherwise use default_path as base_dir\n+def get_annotated_filepath(name, default_dir=None):\n+    if name.endswith(\"[output]\"):\n+        base_dir = get_output_directory()\n+        name = name[:-9]\n+    elif name.endswith(\"[input]\"):\n+        base_dir = get_input_directory()\n+        name = name[:-8]\n+    elif name.endswith(\"[temp]\"):\n+        base_dir = get_temp_directory()\n+        name = name[:-7]",
        "comment_created_at": "2023-04-21T03:50:09+00:00",
        "comment_author": "comfyanonymous",
        "comment_body": "Can you move this code into another function so that there's less code duplication with your exists_annotated_filepath function?",
        "pr_file_module": null
      },
      {
        "comment_id": "1173343327",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 541,
        "pr_file": "folder_paths.py",
        "discussion_id": "1173276977",
        "commented_code": "@@ -68,6 +68,41 @@ def get_directory_by_type(type_name):\n     return None\n \n \n+# determine base_dir rely on annotation if name is 'filename.ext [annotation]' format\n+# otherwise use default_path as base_dir\n+def get_annotated_filepath(name, default_dir=None):\n+    if name.endswith(\"[output]\"):\n+        base_dir = get_output_directory()\n+        name = name[:-9]\n+    elif name.endswith(\"[input]\"):\n+        base_dir = get_input_directory()\n+        name = name[:-8]\n+    elif name.endswith(\"[temp]\"):\n+        base_dir = get_temp_directory()\n+        name = name[:-7]",
        "comment_created_at": "2023-04-21T06:15:24+00:00",
        "comment_author": "ltdrdata",
        "comment_body": "refactoring done.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1183188554",
    "pr_number": 606,
    "pr_file": "comfy/sd.py",
    "created_at": "2023-05-03T02:14:16+00:00",
    "commented_code": "self.device = device\n \n     def decode_tiled_(self, samples, tile_x=64, tile_y=64, overlap = 16):\n+        it_1 = -(samples.shape[2] // -(tile_y * 2 - overlap)) * -(samples.shape[3] // -(tile_x // 2 - overlap))",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "1183188554",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 606,
        "pr_file": "comfy/sd.py",
        "discussion_id": "1183188554",
        "commented_code": "@@ -437,11 +438,16 @@ def __init__(self, ckpt_path=None, scale_factor=0.18215, device=None, config=Non\n         self.device = device\n \n     def decode_tiled_(self, samples, tile_x=64, tile_y=64, overlap = 16):\n+        it_1 = -(samples.shape[2] // -(tile_y * 2 - overlap)) * -(samples.shape[3] // -(tile_x // 2 - overlap))",
        "comment_created_at": "2023-05-03T02:14:16+00:00",
        "comment_author": "comfyanonymous",
        "comment_body": "I feel like this should be its own function in comfy/utils.py\r\n",
        "pr_file_module": null
      }
    ]
  }
]