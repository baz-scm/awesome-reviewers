[
  {
    "discussion_id": "2134171141",
    "pr_number": 8456,
    "pr_file": "server.py",
    "created_at": "2025-06-07T21:35:21+00:00",
    "commented_code": "self.prompt_queue.delete_history_item(id_to_delete)\n \n             return web.Response(status=200)\n+        \n+        @routes.get(\"/templates_version\")\n+        async def get_workflow_templates_version(request):\n+            \"\"\"Reads the version number of comfyui-workflow-templates from the requirements.txt file.\"\"\"\n+            try:\n+                current_dir = os.path.dirname(__file__)\n+                requirements_path = os.path.join(current_dir, 'requirements.txt')\n+\n+                version = \"not_found\"\n+                with open(requirements_path, 'r', encoding='utf-8') as f:\n+                    for line in f:\n+                        if line.startswith('comfyui-workflow-templates=='):\n+                            version = line.strip().split('==')[1]\n+                            break\n+            except FileNotFoundError:\n+                version = \"requirements.txt not found\"\n+            except Exception as e:\n+                print(f\"Error reading version in get_workflow_templates_version: {e}\")",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "2134171141",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 8456,
        "pr_file": "server.py",
        "discussion_id": "2134171141",
        "commented_code": "@@ -711,6 +711,27 @@ async def post_history(request):\n                     self.prompt_queue.delete_history_item(id_to_delete)\n \n             return web.Response(status=200)\n+        \n+        @routes.get(\"/templates_version\")\n+        async def get_workflow_templates_version(request):\n+            \"\"\"Reads the version number of comfyui-workflow-templates from the requirements.txt file.\"\"\"\n+            try:\n+                current_dir = os.path.dirname(__file__)\n+                requirements_path = os.path.join(current_dir, 'requirements.txt')\n+\n+                version = \"not_found\"\n+                with open(requirements_path, 'r', encoding='utf-8') as f:\n+                    for line in f:\n+                        if line.startswith('comfyui-workflow-templates=='):\n+                            version = line.strip().split('==')[1]\n+                            break\n+            except FileNotFoundError:\n+                version = \"requirements.txt not found\"\n+            except Exception as e:\n+                print(f\"Error reading version in get_workflow_templates_version: {e}\")",
        "comment_created_at": "2025-06-07T21:35:21+00:00",
        "comment_author": "webfiltered",
        "comment_body": "Prefer `logging` over `print` for all messaging.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2050916274",
    "pr_number": 7632,
    "pr_file": "comfy/sd.py",
    "created_at": "2025-04-18T17:36:52+00:00",
    "commented_code": "clip_target.clip = comfy.text_encoders.lumina2.te(**llama_detect(clip_data))\n             clip_target.tokenizer = comfy.text_encoders.lumina2.LuminaTokenizer\n             tokenizer_data[\"spiece_model\"] = clip_data[0].get(\"spiece_model\", None)\n+        elif te_model == TEModel.LLAMA3_8:\n+            print(\"Single LLAMA3_8 for HiDreams\")",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "2050916274",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 7632,
        "pr_file": "comfy/sd.py",
        "discussion_id": "2050916274",
        "commented_code": "@@ -827,6 +828,10 @@ class EmptyClass:\n             clip_target.clip = comfy.text_encoders.lumina2.te(**llama_detect(clip_data))\n             clip_target.tokenizer = comfy.text_encoders.lumina2.LuminaTokenizer\n             tokenizer_data[\"spiece_model\"] = clip_data[0].get(\"spiece_model\", None)\n+        elif te_model == TEModel.LLAMA3_8:\n+            print(\"Single LLAMA3_8 for HiDreams\")",
        "comment_created_at": "2025-04-18T17:36:52+00:00",
        "comment_author": "bigcat88",
        "comment_body": "please, use `logging.info` instead of `print` everywhere if possible",
        "pr_file_module": null
      },
      {
        "comment_id": "2051116477",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 7632,
        "pr_file": "comfy/sd.py",
        "discussion_id": "2050916274",
        "commented_code": "@@ -827,6 +828,10 @@ class EmptyClass:\n             clip_target.clip = comfy.text_encoders.lumina2.te(**llama_detect(clip_data))\n             clip_target.tokenizer = comfy.text_encoders.lumina2.LuminaTokenizer\n             tokenizer_data[\"spiece_model\"] = clip_data[0].get(\"spiece_model\", None)\n+        elif te_model == TEModel.LLAMA3_8:\n+            print(\"Single LLAMA3_8 for HiDreams\")",
        "comment_created_at": "2025-04-18T21:00:39+00:00",
        "comment_author": "envy-ai",
        "comment_body": "Done.\r\n\r\nI've pushed the changes to my repo.  Is there anything else I need to do for you to be able to review them here?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1894377395",
    "pr_number": 6138,
    "pr_file": "comfy/model_base.py",
    "created_at": "2024-12-20T20:47:36+00:00",
    "commented_code": "mask = torch.ones_like(noise)[:, :1]\n \n         mask = torch.mean(mask, dim=1, keepdim=True)\n-        print(mask.shape)",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "1894377395",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 6138,
        "pr_file": "comfy/model_base.py",
        "discussion_id": "1894377395",
        "commented_code": "@@ -754,7 +754,6 @@ def concat_cond(self, **kwargs):\n             mask = torch.ones_like(noise)[:, :1]\n \n         mask = torch.mean(mask, dim=1, keepdim=True)\n-        print(mask.shape)",
        "comment_created_at": "2024-12-20T20:47:36+00:00",
        "comment_author": "huchenlei",
        "comment_body": "Cleanup debug logs.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1883017201",
    "pr_number": 6028,
    "pr_file": "comfy/ldm/models/autoencoder.py",
    "created_at": "2024-12-12T23:16:26+00:00",
    "commented_code": "if self.use_ema:\n             self.model_ema = LitEma(self, decay=ema_decay)\n-            logpy.info(f\"Keeping EMAs of {len(list(self.model_ema.buffers()))}.\")",
    "repo_full_name": "comfyanonymous/ComfyUI",
    "discussion_comments": [
      {
        "comment_id": "1883017201",
        "repo_full_name": "comfyanonymous/ComfyUI",
        "pr_number": 6028,
        "pr_file": "comfy/ldm/models/autoencoder.py",
        "discussion_id": "1883017201",
        "commented_code": "@@ -52,7 +54,7 @@ def __init__(\n \n         if self.use_ema:\n             self.model_ema = LitEma(self, decay=ema_decay)\n-            logpy.info(f\"Keeping EMAs of {len(list(self.model_ema.buffers()))}.\")",
        "comment_created_at": "2024-12-12T23:16:26+00:00",
        "comment_author": "huchenlei",
        "comment_body": "Replacing `logpy` with python's built-in logging module. `logpy` is not used in this project.",
        "pr_file_module": null
      }
    ]
  }
]