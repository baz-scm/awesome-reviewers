[
  {
    "discussion_id": "2216444636",
    "pr_number": 6395,
    "pr_file": "core/llm/toolSupport.ts",
    "created_at": "2025-07-18T16:26:56+00:00",
    "commented_code": "import { parseProxyModelName } from \"@continuedev/config-yaml\";\n+import { ModelDescription } from \"..\";\n \n-export const PROVIDER_TOOL_SUPPORT: Record<string, (model: string) => boolean> =\n-  {\n-    \"continue-proxy\": (model) => {\n-      try {\n-        const { provider, model: _model } = parseProxyModelName(model);\n-        if (provider && _model && provider !== \"continue-proxy\") {\n-          const fn = PROVIDER_TOOL_SUPPORT[provider];\n-          if (fn) {\n-            return fn(_model);\n-          }\n+export const NATIVE_TOOL_SUPPORT: Record<string, (model: string) => boolean> = {\n+  \"continue-proxy\": (model) => {\n+    try {\n+      const { provider, model: _model } = parseProxyModelName(model);\n+      if (provider && _model && provider !== \"continue-proxy\") {\n+        const fn = NATIVE_TOOL_SUPPORT[provider];\n+        if (fn) {\n+          return fn(_model);\n         }\n-      } catch (e) {}\n+      }\n+    } catch (e) {}\n \n-      return [\n+    return [\n+      \"claude-3-5\",\n+      \"claude-3.5\",\n+      \"claude-3-7\",\n+      \"claude-3.7\",\n+      \"claude-sonnet-4\",\n+      \"claude-4-sonnet\",\n+      \"gpt-4\",\n+      \"o3\",\n+      \"gemini\",\n+      \"claude-opus-4\",\n+    ].some((part) => model.toLowerCase().startsWith(part));\n+  },\n+  anthropic: (model) => {\n+    if (\n+      [\n         \"claude-3-5\",\n         \"claude-3.5\",\n         \"claude-3-7\",\n         \"claude-3.7\",\n         \"claude-sonnet-4\",\n         \"claude-4-sonnet\",\n-        \"gpt-4\",\n-        \"o3\",\n-        \"gemini\",\n         \"claude-opus-4\",\n-      ].some((part) => model.toLowerCase().startsWith(part));\n-    },\n-    anthropic: (model) => {\n-      if (\n-        [\n-          \"claude-3-5\",\n-          \"claude-3.5\",\n-          \"claude-3-7\",\n-          \"claude-3.7\",\n-          \"claude-sonnet-4\",\n-          \"claude-4-sonnet\",\n-          \"claude-opus-4\",\n-        ].some((part) => model.toLowerCase().startsWith(part))\n-      ) {\n-        return true;\n-      }\n+      ].some((part) => model.toLowerCase().startsWith(part))\n+    ) {\n+      return true;\n+    }\n \n-      return false;\n-    },\n-    azure: (model) => {\n-      if (\n-        model.toLowerCase().startsWith(\"gpt-4\") ||\n-        model.toLowerCase().startsWith(\"o3\")\n-      )\n-        return true;\n-      return false;\n-    },\n-    openai: (model) => {\n-      // https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling\n-      if (\n-        model.toLowerCase().startsWith(\"gpt-4\") ||\n-        model.toLowerCase().startsWith(\"o3\")\n-      ) {\n-        return true;\n-      }\n-      // firworks-ai https://docs.fireworks.ai/guides/function-calling\n-      if (model.startsWith(\"accounts/fireworks/models/\")) {\n-        switch (model.substring(26)) {\n-          case \"llama-v3p1-405b-instruct\":\n-          case \"llama-v3p1-70b-instruct\":\n-          case \"qwen2p5-72b-instruct\":\n-          case \"firefunction-v1\":\n-          case \"firefunction-v2\":\n-            return true;\n-          default:\n-            return false;\n-        }\n+    return false;\n+  },\n+  azure: (model) => {\n+    if (\n+      model.toLowerCase().startsWith(\"gpt-4\") ||\n+      model.toLowerCase().startsWith(\"o3\")\n+    )\n+      return true;\n+    return false;\n+  },\n+  openai: (model) => {\n+    // https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling\n+    if (\n+      model.toLowerCase().startsWith(\"gpt-4\") ||\n+      model.toLowerCase().startsWith(\"o3\")\n+    ) {\n+      return true;\n+    }\n+    // firworks-ai https://docs.fireworks.ai/guides/function-calling\n+    if (model.startsWith(\"accounts/fireworks/models/\")) {\n+      switch (model.substring(26)) {\n+        case \"llama-v3p1-405b-instruct\":\n+        case \"llama-v3p1-70b-instruct\":\n+        case \"qwen2p5-72b-instruct\":\n+        case \"firefunction-v1\":\n+        case \"firefunction-v2\":\n+          return true;\n+        default:\n+          return false;\n       }\n+    }\n \n-      return false;\n-    },\n-    cohere: (model) => {\n-      return model.toLowerCase().startsWith(\"command\");\n-    },\n-    gemini: (model) => {\n-      // All gemini models support function calling\n-      return model.toLowerCase().includes(\"gemini\");\n-    },\n-    vertexai: (model) => {\n-      // All gemini models except flash 2.0 lite support function calling\n-      return (\n-        model.toLowerCase().includes(\"gemini\") &&\n-        !model.toLowerCase().includes(\"lite\")\n-      );\n-    },\n-    bedrock: (model) => {\n-      if (\n-        [\n-          \"claude-3-5-sonnet\",\n-          \"claude-3.5-sonnet\",\n-          \"claude-3-7-sonnet\",\n-          \"claude-3.7-sonnet\",\n-          \"claude-sonnet-4\",\n-          \"claude-4-sonnet\",\n-          \"claude-opus-4\",\n-          \"nova-lite\",\n-          \"nova-pro\",\n-          \"nova-micro\",\n-          \"nova-premier\",\n-        ].some((part) => model.toLowerCase().includes(part))\n-      ) {\n-        return true;\n-      }\n+    return false;\n+  },\n+  cohere: (model) => {\n+    return model.toLowerCase().startsWith(\"command\");\n+  },\n+  gemini: (model) => {\n+    // All gemini models support function calling\n+    return model.toLowerCase().includes(\"gemini\");\n+  },\n+  vertexai: (model) => {\n+    // All gemini models except flash 2.0 lite support function calling\n+    return (\n+      model.toLowerCase().includes(\"gemini\") &&\n+      !model.toLowerCase().includes(\"lite\")\n+    );\n+  },\n+  bedrock: (model) => {\n+    if (\n+      [\n+        \"claude-3-5-sonnet\",\n+        \"claude-3.5-sonnet\",\n+        \"claude-3-7-sonnet\",\n+        \"claude-3.7-sonnet\",\n+        \"claude-sonnet-4\",\n+        \"claude-4-sonnet\",\n+        \"claude-opus-4\",\n+        \"nova-lite\",\n+        \"nova-pro\",\n+        \"nova-micro\",\n+        \"nova-premier\",\n+      ].some((part) => model.toLowerCase().includes(part))\n+    ) {\n+      return true;\n+    }\n \n+    return false;\n+  },\n+  mistral: (model) => {\n+    // https://docs.mistral.ai/capabilities/function_calling/\n+    return (\n+      !model.toLowerCase().includes(\"mamba\") &&\n+      [\n+        \"devstral\",\n+        \"codestral\",\n+        \"mistral-large\",\n+        \"mistral-small\",\n+        \"pixtral\",\n+        \"ministral\",\n+        \"mistral-nemo\",\n+        \"devstral\",\n+      ].some((part) => model.toLowerCase().includes(part))\n+    );\n+  },\n+  // https://ollama.com/search?c=tools\n+  ollama: (model) => {\n+    let modelName = \"\";\n+    // Extract the model name after the last slash to support other registries\n+    if (model.includes(\"/\")) {\n+      let parts = model.split(\"/\");\n+      modelName = parts[parts.length - 1];\n+    } else {\n+      modelName = model;\n+    }\n+\n+    if (\n+      [\"vision\", \"math\", \"guard\", \"mistrallite\", \"mistral-openorca\"].some(\n+        (part) => modelName.toLowerCase().includes(part),\n+      )\n+    ) {\n       return false;\n-    },\n-    mistral: (model) => {\n-      // https://docs.mistral.ai/capabilities/function_calling/\n-      return (\n-        !model.toLowerCase().includes(\"mamba\") &&\n-        [\n-          \"devstral\",\n-          \"codestral\",\n-          \"mistral-large\",\n-          \"mistral-small\",\n-          \"pixtral\",\n-          \"ministral\",\n-          \"mistral-nemo\",\n-          \"devstral\",\n-        ].some((part) => model.toLowerCase().includes(part))\n-      );\n-    },\n-    // https://ollama.com/search?c=tools\n-    ollama: (model) => {\n-      let modelName = \"\";\n-      // Extract the model name after the last slash to support other registries\n-      if (model.includes(\"/\")) {\n-        let parts = model.split(\"/\");\n-        modelName = parts[parts.length - 1];\n-      } else {\n-        modelName = model;\n-      }\n+    }\n+    if (\n+      [\n+        \"cogito\",\n+        \"llama3.3\",\n+        \"qwq\",\n+        \"llama3.2\",\n+        \"llama3.1\",\n+        \"qwen2\",\n+        \"qwen3\",\n+        \"mixtral\",\n+        \"command-r\",\n+        \"command-a\",\n+        \"smollm2\",\n+        \"hermes3\",\n+        \"athene-v2\",\n+        \"nemotron\",\n+        \"llama3-groq\",\n+        \"granite3\",\n+        \"granite-3\",\n+        \"aya-expanse\",\n+        \"firefunction-v2\",\n+        \"mistral\",\n+        \"devstral\",\n+      ].some((part) => modelName.toLowerCase().includes(part))\n+    ) {\n+      return true;\n+    }\n \n-      if (\n-        [\"vision\", \"math\", \"guard\", \"mistrallite\", \"mistral-openorca\"].some(\n-          (part) => modelName.toLowerCase().includes(part),\n-        )\n-      ) {\n-        return false;\n-      }\n-      if (\n-        [\n-          \"cogito\",\n-          \"llama3.3\",\n-          \"qwq\",\n-          \"llama3.2\",\n-          \"llama3.1\",\n-          \"qwen2\",\n-          \"qwen3\",\n-          \"mixtral\",\n-          \"command-r\",\n-          \"command-a\",\n-          \"smollm2\",\n-          \"hermes3\",\n-          \"athene-v2\",\n-          \"nemotron\",\n-          \"llama3-groq\",\n-          \"granite3\",\n-          \"granite-3\",\n-          \"aya-expanse\",\n-          \"firefunction-v2\",\n-          \"mistral\",\n-          \"devstral\",\n-        ].some((part) => modelName.toLowerCase().includes(part))\n-      ) {\n-        return true;\n-      }\n+    return false;\n+  },\n+  sambanova: (model) => {\n+    // https://docs.sambanova.ai/cloud/docs/capabilities/function-calling\n+    if (\n+      model.toLowerCase().startsWith(\"meta-llama-3\") ||\n+      model.toLowerCase().includes(\"llama-4\") ||\n+      model.toLowerCase().includes(\"deepseek\")\n+    ) {\n+      return true;\n+    }\n \n-      return false;\n-    },\n-    sambanova: (model) => {\n-      // https://docs.sambanova.ai/cloud/docs/capabilities/function-calling\n-      if (\n-        model.toLowerCase().startsWith(\"meta-llama-3\") ||\n-        model.toLowerCase().includes(\"llama-4\") ||\n-        model.toLowerCase().includes(\"deepseek\")\n-      ) {\n-        return true;\n-      }\n+    return false;\n+  },\n+  deepseek: (model) => {\n+    // https://api-docs.deepseek.com/quick_start/pricing\n+    // https://api-docs.deepseek.com/guides/function_calling\n+    if (model === \"deepseek-reasoner\" || model === \"deepseek-chat\") {\n+      return true;\n+    }\n \n+    return false;\n+  },\n+  watsonx: (model) => {\n+    if (model.toLowerCase().includes(\"guard\")) {\n       return false;\n-    },\n-    deepseek: (model) => {\n-      // https://api-docs.deepseek.com/quick_start/pricing\n-      // https://api-docs.deepseek.com/guides/function_calling\n-      if (model === \"deepseek-reasoner\" || model === \"deepseek-chat\") {\n-        return true;\n-      }\n+    }\n+    if (\n+      [\n+        \"llama-3\",\n+        \"llama-4\",\n+        \"mistral\",\n+        \"codestral\",\n+        \"granite-3\",\n+        \"devstral\",\n+      ].some((part) => model.toLowerCase().includes(part))\n+    ) {\n+      return true;\n+    }\n \n+    return false;\n+  },\n+  openrouter: (model) => {\n+    // https://openrouter.ai/models?fmt=cards&supported_parameters=tools\n+    if (\n+      [\"vision\", \"math\", \"guard\", \"mistrallite\", \"mistral-openorca\"].some(\n+        (part) => model.toLowerCase().includes(part),\n+      )\n+    ) {\n       return false;\n-    },\n-    watsonx: (model) => {\n-      if (model.toLowerCase().includes(\"guard\")) {\n-        return false;\n-      }\n-      if (\n-        [\n-          \"llama-3\",\n-          \"llama-4\",\n-          \"mistral\",\n-          \"codestral\",\n-          \"granite-3\",\n-          \"devstral\",\n-        ].some((part) => model.toLowerCase().includes(part))\n-      ) {\n-        return true;\n-      }\n+    }\n \n-      return false;\n-    },\n-    openrouter: (model) => {\n-      // https://openrouter.ai/models?fmt=cards&supported_parameters=tools\n-      if (\n-        [\"vision\", \"math\", \"guard\", \"mistrallite\", \"mistral-openorca\"].some(\n-          (part) => model.toLowerCase().includes(part),\n-        )\n-      ) {\n-        return false;\n+    const supportedPrefixes = [\n+      \"openai/gpt-3.5\",\n+      \"openai/gpt-4\",\n+      \"openai/o1\",\n+      \"openai/o3\",\n+      \"openai/o4\",\n+      \"anthropic/claude-3\",\n+      \"anthropic/claude-4\",\n+      \"microsoft/phi-3\",\n+      \"google/gemini-flash-1.5\",\n+      \"google/gemini-2\",\n+      \"google/gemini-pro\",\n+      \"x-ai/grok\",\n+      \"qwen/qwen3\",\n+      \"qwen/qwen-\",\n+      \"cohere/command-r\",\n+      \"cohere/command-a\",\n+      \"ai21/jamba-1.6\",\n+      \"mistralai/mistral\",\n+      \"mistralai/ministral\",\n+      \"mistralai/codestral\",\n+      \"mistralai/mixtral\",\n+      \"mistral/ministral\",\n+      \"mistral/devstral\",\n+      \"mistralai/pixtral\",\n+      \"meta-llama/llama-3.3\",\n+      \"amazon/nova\",\n+      \"deepseek/deepseek-r1\",\n+      \"deepseek/deepseek-chat\",\n+      \"meta-llama/llama-4\",\n+      \"all-hands/openhands-lm-32b\",\n+    ];\n+    for (const prefix of supportedPrefixes) {\n+      if (model.toLowerCase().startsWith(prefix)) {\n+        return true;\n       }\n+    }\n \n-      const supportedPrefixes = [\n-        \"openai/gpt-3.5\",\n-        \"openai/gpt-4\",\n-        \"openai/o1\",\n-        \"openai/o3\",\n-        \"openai/o4\",\n-        \"anthropic/claude-3\",\n-        \"anthropic/claude-4\",\n-        \"microsoft/phi-3\",\n-        \"google/gemini-flash-1.5\",\n-        \"google/gemini-2\",\n-        \"google/gemini-pro\",\n-        \"x-ai/grok\",\n-        \"qwen/qwen3\",\n-        \"qwen/qwen-\",\n-        \"cohere/command-r\",\n-        \"cohere/command-a\",\n-        \"ai21/jamba-1.6\",\n-        \"mistralai/mistral\",\n-        \"mistralai/ministral\",\n-        \"mistralai/codestral\",\n-        \"mistralai/mixtral\",\n-        \"mistral/ministral\",\n-        \"mistral/devstral\",\n-        \"mistralai/pixtral\",\n-        \"meta-llama/llama-3.3\",\n-        \"amazon/nova\",\n-        \"deepseek/deepseek-r1\",\n-        \"deepseek/deepseek-chat\",\n-        \"meta-llama/llama-4\",\n-        \"all-hands/openhands-lm-32b\",\n-      ];\n-      for (const prefix of supportedPrefixes) {\n-        if (model.toLowerCase().startsWith(prefix)) {\n-          return true;\n-        }\n+    const specificModels = [\n+      \"qwen/qwq-32b\",\n+      \"qwen/qwen-2.5-72b-instruct\",\n+      \"meta-llama/llama-3.2-3b-instruct\",\n+      \"meta-llama/llama-3-8b-instruct\",\n+      \"meta-llama/llama-3-70b-instruct\",\n+      \"arcee-ai/caller-large\",\n+      \"nousresearch/hermes-3-llama-3.1-70b\",\n+    ];\n+    for (const model of specificModels) {\n+      if (model.toLowerCase() === model) {",
    "repo_full_name": "continuedev/continue",
    "discussion_comments": [
      {
        "comment_id": "2216444636",
        "repo_full_name": "continuedev/continue",
        "pr_number": 6395,
        "pr_file": "core/llm/toolSupport.ts",
        "discussion_id": "2216444636",
        "commented_code": "@@ -1,289 +1,317 @@\n import { parseProxyModelName } from \"@continuedev/config-yaml\";\n+import { ModelDescription } from \"..\";\n \n-export const PROVIDER_TOOL_SUPPORT: Record<string, (model: string) => boolean> =\n-  {\n-    \"continue-proxy\": (model) => {\n-      try {\n-        const { provider, model: _model } = parseProxyModelName(model);\n-        if (provider && _model && provider !== \"continue-proxy\") {\n-          const fn = PROVIDER_TOOL_SUPPORT[provider];\n-          if (fn) {\n-            return fn(_model);\n-          }\n+export const NATIVE_TOOL_SUPPORT: Record<string, (model: string) => boolean> = {\n+  \"continue-proxy\": (model) => {\n+    try {\n+      const { provider, model: _model } = parseProxyModelName(model);\n+      if (provider && _model && provider !== \"continue-proxy\") {\n+        const fn = NATIVE_TOOL_SUPPORT[provider];\n+        if (fn) {\n+          return fn(_model);\n         }\n-      } catch (e) {}\n+      }\n+    } catch (e) {}\n \n-      return [\n+    return [\n+      \"claude-3-5\",\n+      \"claude-3.5\",\n+      \"claude-3-7\",\n+      \"claude-3.7\",\n+      \"claude-sonnet-4\",\n+      \"claude-4-sonnet\",\n+      \"gpt-4\",\n+      \"o3\",\n+      \"gemini\",\n+      \"claude-opus-4\",\n+    ].some((part) => model.toLowerCase().startsWith(part));\n+  },\n+  anthropic: (model) => {\n+    if (\n+      [\n         \"claude-3-5\",\n         \"claude-3.5\",\n         \"claude-3-7\",\n         \"claude-3.7\",\n         \"claude-sonnet-4\",\n         \"claude-4-sonnet\",\n-        \"gpt-4\",\n-        \"o3\",\n-        \"gemini\",\n         \"claude-opus-4\",\n-      ].some((part) => model.toLowerCase().startsWith(part));\n-    },\n-    anthropic: (model) => {\n-      if (\n-        [\n-          \"claude-3-5\",\n-          \"claude-3.5\",\n-          \"claude-3-7\",\n-          \"claude-3.7\",\n-          \"claude-sonnet-4\",\n-          \"claude-4-sonnet\",\n-          \"claude-opus-4\",\n-        ].some((part) => model.toLowerCase().startsWith(part))\n-      ) {\n-        return true;\n-      }\n+      ].some((part) => model.toLowerCase().startsWith(part))\n+    ) {\n+      return true;\n+    }\n \n-      return false;\n-    },\n-    azure: (model) => {\n-      if (\n-        model.toLowerCase().startsWith(\"gpt-4\") ||\n-        model.toLowerCase().startsWith(\"o3\")\n-      )\n-        return true;\n-      return false;\n-    },\n-    openai: (model) => {\n-      // https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling\n-      if (\n-        model.toLowerCase().startsWith(\"gpt-4\") ||\n-        model.toLowerCase().startsWith(\"o3\")\n-      ) {\n-        return true;\n-      }\n-      // firworks-ai https://docs.fireworks.ai/guides/function-calling\n-      if (model.startsWith(\"accounts/fireworks/models/\")) {\n-        switch (model.substring(26)) {\n-          case \"llama-v3p1-405b-instruct\":\n-          case \"llama-v3p1-70b-instruct\":\n-          case \"qwen2p5-72b-instruct\":\n-          case \"firefunction-v1\":\n-          case \"firefunction-v2\":\n-            return true;\n-          default:\n-            return false;\n-        }\n+    return false;\n+  },\n+  azure: (model) => {\n+    if (\n+      model.toLowerCase().startsWith(\"gpt-4\") ||\n+      model.toLowerCase().startsWith(\"o3\")\n+    )\n+      return true;\n+    return false;\n+  },\n+  openai: (model) => {\n+    // https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling\n+    if (\n+      model.toLowerCase().startsWith(\"gpt-4\") ||\n+      model.toLowerCase().startsWith(\"o3\")\n+    ) {\n+      return true;\n+    }\n+    // firworks-ai https://docs.fireworks.ai/guides/function-calling\n+    if (model.startsWith(\"accounts/fireworks/models/\")) {\n+      switch (model.substring(26)) {\n+        case \"llama-v3p1-405b-instruct\":\n+        case \"llama-v3p1-70b-instruct\":\n+        case \"qwen2p5-72b-instruct\":\n+        case \"firefunction-v1\":\n+        case \"firefunction-v2\":\n+          return true;\n+        default:\n+          return false;\n       }\n+    }\n \n-      return false;\n-    },\n-    cohere: (model) => {\n-      return model.toLowerCase().startsWith(\"command\");\n-    },\n-    gemini: (model) => {\n-      // All gemini models support function calling\n-      return model.toLowerCase().includes(\"gemini\");\n-    },\n-    vertexai: (model) => {\n-      // All gemini models except flash 2.0 lite support function calling\n-      return (\n-        model.toLowerCase().includes(\"gemini\") &&\n-        !model.toLowerCase().includes(\"lite\")\n-      );\n-    },\n-    bedrock: (model) => {\n-      if (\n-        [\n-          \"claude-3-5-sonnet\",\n-          \"claude-3.5-sonnet\",\n-          \"claude-3-7-sonnet\",\n-          \"claude-3.7-sonnet\",\n-          \"claude-sonnet-4\",\n-          \"claude-4-sonnet\",\n-          \"claude-opus-4\",\n-          \"nova-lite\",\n-          \"nova-pro\",\n-          \"nova-micro\",\n-          \"nova-premier\",\n-        ].some((part) => model.toLowerCase().includes(part))\n-      ) {\n-        return true;\n-      }\n+    return false;\n+  },\n+  cohere: (model) => {\n+    return model.toLowerCase().startsWith(\"command\");\n+  },\n+  gemini: (model) => {\n+    // All gemini models support function calling\n+    return model.toLowerCase().includes(\"gemini\");\n+  },\n+  vertexai: (model) => {\n+    // All gemini models except flash 2.0 lite support function calling\n+    return (\n+      model.toLowerCase().includes(\"gemini\") &&\n+      !model.toLowerCase().includes(\"lite\")\n+    );\n+  },\n+  bedrock: (model) => {\n+    if (\n+      [\n+        \"claude-3-5-sonnet\",\n+        \"claude-3.5-sonnet\",\n+        \"claude-3-7-sonnet\",\n+        \"claude-3.7-sonnet\",\n+        \"claude-sonnet-4\",\n+        \"claude-4-sonnet\",\n+        \"claude-opus-4\",\n+        \"nova-lite\",\n+        \"nova-pro\",\n+        \"nova-micro\",\n+        \"nova-premier\",\n+      ].some((part) => model.toLowerCase().includes(part))\n+    ) {\n+      return true;\n+    }\n \n+    return false;\n+  },\n+  mistral: (model) => {\n+    // https://docs.mistral.ai/capabilities/function_calling/\n+    return (\n+      !model.toLowerCase().includes(\"mamba\") &&\n+      [\n+        \"devstral\",\n+        \"codestral\",\n+        \"mistral-large\",\n+        \"mistral-small\",\n+        \"pixtral\",\n+        \"ministral\",\n+        \"mistral-nemo\",\n+        \"devstral\",\n+      ].some((part) => model.toLowerCase().includes(part))\n+    );\n+  },\n+  // https://ollama.com/search?c=tools\n+  ollama: (model) => {\n+    let modelName = \"\";\n+    // Extract the model name after the last slash to support other registries\n+    if (model.includes(\"/\")) {\n+      let parts = model.split(\"/\");\n+      modelName = parts[parts.length - 1];\n+    } else {\n+      modelName = model;\n+    }\n+\n+    if (\n+      [\"vision\", \"math\", \"guard\", \"mistrallite\", \"mistral-openorca\"].some(\n+        (part) => modelName.toLowerCase().includes(part),\n+      )\n+    ) {\n       return false;\n-    },\n-    mistral: (model) => {\n-      // https://docs.mistral.ai/capabilities/function_calling/\n-      return (\n-        !model.toLowerCase().includes(\"mamba\") &&\n-        [\n-          \"devstral\",\n-          \"codestral\",\n-          \"mistral-large\",\n-          \"mistral-small\",\n-          \"pixtral\",\n-          \"ministral\",\n-          \"mistral-nemo\",\n-          \"devstral\",\n-        ].some((part) => model.toLowerCase().includes(part))\n-      );\n-    },\n-    // https://ollama.com/search?c=tools\n-    ollama: (model) => {\n-      let modelName = \"\";\n-      // Extract the model name after the last slash to support other registries\n-      if (model.includes(\"/\")) {\n-        let parts = model.split(\"/\");\n-        modelName = parts[parts.length - 1];\n-      } else {\n-        modelName = model;\n-      }\n+    }\n+    if (\n+      [\n+        \"cogito\",\n+        \"llama3.3\",\n+        \"qwq\",\n+        \"llama3.2\",\n+        \"llama3.1\",\n+        \"qwen2\",\n+        \"qwen3\",\n+        \"mixtral\",\n+        \"command-r\",\n+        \"command-a\",\n+        \"smollm2\",\n+        \"hermes3\",\n+        \"athene-v2\",\n+        \"nemotron\",\n+        \"llama3-groq\",\n+        \"granite3\",\n+        \"granite-3\",\n+        \"aya-expanse\",\n+        \"firefunction-v2\",\n+        \"mistral\",\n+        \"devstral\",\n+      ].some((part) => modelName.toLowerCase().includes(part))\n+    ) {\n+      return true;\n+    }\n \n-      if (\n-        [\"vision\", \"math\", \"guard\", \"mistrallite\", \"mistral-openorca\"].some(\n-          (part) => modelName.toLowerCase().includes(part),\n-        )\n-      ) {\n-        return false;\n-      }\n-      if (\n-        [\n-          \"cogito\",\n-          \"llama3.3\",\n-          \"qwq\",\n-          \"llama3.2\",\n-          \"llama3.1\",\n-          \"qwen2\",\n-          \"qwen3\",\n-          \"mixtral\",\n-          \"command-r\",\n-          \"command-a\",\n-          \"smollm2\",\n-          \"hermes3\",\n-          \"athene-v2\",\n-          \"nemotron\",\n-          \"llama3-groq\",\n-          \"granite3\",\n-          \"granite-3\",\n-          \"aya-expanse\",\n-          \"firefunction-v2\",\n-          \"mistral\",\n-          \"devstral\",\n-        ].some((part) => modelName.toLowerCase().includes(part))\n-      ) {\n-        return true;\n-      }\n+    return false;\n+  },\n+  sambanova: (model) => {\n+    // https://docs.sambanova.ai/cloud/docs/capabilities/function-calling\n+    if (\n+      model.toLowerCase().startsWith(\"meta-llama-3\") ||\n+      model.toLowerCase().includes(\"llama-4\") ||\n+      model.toLowerCase().includes(\"deepseek\")\n+    ) {\n+      return true;\n+    }\n \n-      return false;\n-    },\n-    sambanova: (model) => {\n-      // https://docs.sambanova.ai/cloud/docs/capabilities/function-calling\n-      if (\n-        model.toLowerCase().startsWith(\"meta-llama-3\") ||\n-        model.toLowerCase().includes(\"llama-4\") ||\n-        model.toLowerCase().includes(\"deepseek\")\n-      ) {\n-        return true;\n-      }\n+    return false;\n+  },\n+  deepseek: (model) => {\n+    // https://api-docs.deepseek.com/quick_start/pricing\n+    // https://api-docs.deepseek.com/guides/function_calling\n+    if (model === \"deepseek-reasoner\" || model === \"deepseek-chat\") {\n+      return true;\n+    }\n \n+    return false;\n+  },\n+  watsonx: (model) => {\n+    if (model.toLowerCase().includes(\"guard\")) {\n       return false;\n-    },\n-    deepseek: (model) => {\n-      // https://api-docs.deepseek.com/quick_start/pricing\n-      // https://api-docs.deepseek.com/guides/function_calling\n-      if (model === \"deepseek-reasoner\" || model === \"deepseek-chat\") {\n-        return true;\n-      }\n+    }\n+    if (\n+      [\n+        \"llama-3\",\n+        \"llama-4\",\n+        \"mistral\",\n+        \"codestral\",\n+        \"granite-3\",\n+        \"devstral\",\n+      ].some((part) => model.toLowerCase().includes(part))\n+    ) {\n+      return true;\n+    }\n \n+    return false;\n+  },\n+  openrouter: (model) => {\n+    // https://openrouter.ai/models?fmt=cards&supported_parameters=tools\n+    if (\n+      [\"vision\", \"math\", \"guard\", \"mistrallite\", \"mistral-openorca\"].some(\n+        (part) => model.toLowerCase().includes(part),\n+      )\n+    ) {\n       return false;\n-    },\n-    watsonx: (model) => {\n-      if (model.toLowerCase().includes(\"guard\")) {\n-        return false;\n-      }\n-      if (\n-        [\n-          \"llama-3\",\n-          \"llama-4\",\n-          \"mistral\",\n-          \"codestral\",\n-          \"granite-3\",\n-          \"devstral\",\n-        ].some((part) => model.toLowerCase().includes(part))\n-      ) {\n-        return true;\n-      }\n+    }\n \n-      return false;\n-    },\n-    openrouter: (model) => {\n-      // https://openrouter.ai/models?fmt=cards&supported_parameters=tools\n-      if (\n-        [\"vision\", \"math\", \"guard\", \"mistrallite\", \"mistral-openorca\"].some(\n-          (part) => model.toLowerCase().includes(part),\n-        )\n-      ) {\n-        return false;\n+    const supportedPrefixes = [\n+      \"openai/gpt-3.5\",\n+      \"openai/gpt-4\",\n+      \"openai/o1\",\n+      \"openai/o3\",\n+      \"openai/o4\",\n+      \"anthropic/claude-3\",\n+      \"anthropic/claude-4\",\n+      \"microsoft/phi-3\",\n+      \"google/gemini-flash-1.5\",\n+      \"google/gemini-2\",\n+      \"google/gemini-pro\",\n+      \"x-ai/grok\",\n+      \"qwen/qwen3\",\n+      \"qwen/qwen-\",\n+      \"cohere/command-r\",\n+      \"cohere/command-a\",\n+      \"ai21/jamba-1.6\",\n+      \"mistralai/mistral\",\n+      \"mistralai/ministral\",\n+      \"mistralai/codestral\",\n+      \"mistralai/mixtral\",\n+      \"mistral/ministral\",\n+      \"mistral/devstral\",\n+      \"mistralai/pixtral\",\n+      \"meta-llama/llama-3.3\",\n+      \"amazon/nova\",\n+      \"deepseek/deepseek-r1\",\n+      \"deepseek/deepseek-chat\",\n+      \"meta-llama/llama-4\",\n+      \"all-hands/openhands-lm-32b\",\n+    ];\n+    for (const prefix of supportedPrefixes) {\n+      if (model.toLowerCase().startsWith(prefix)) {\n+        return true;\n       }\n+    }\n \n-      const supportedPrefixes = [\n-        \"openai/gpt-3.5\",\n-        \"openai/gpt-4\",\n-        \"openai/o1\",\n-        \"openai/o3\",\n-        \"openai/o4\",\n-        \"anthropic/claude-3\",\n-        \"anthropic/claude-4\",\n-        \"microsoft/phi-3\",\n-        \"google/gemini-flash-1.5\",\n-        \"google/gemini-2\",\n-        \"google/gemini-pro\",\n-        \"x-ai/grok\",\n-        \"qwen/qwen3\",\n-        \"qwen/qwen-\",\n-        \"cohere/command-r\",\n-        \"cohere/command-a\",\n-        \"ai21/jamba-1.6\",\n-        \"mistralai/mistral\",\n-        \"mistralai/ministral\",\n-        \"mistralai/codestral\",\n-        \"mistralai/mixtral\",\n-        \"mistral/ministral\",\n-        \"mistral/devstral\",\n-        \"mistralai/pixtral\",\n-        \"meta-llama/llama-3.3\",\n-        \"amazon/nova\",\n-        \"deepseek/deepseek-r1\",\n-        \"deepseek/deepseek-chat\",\n-        \"meta-llama/llama-4\",\n-        \"all-hands/openhands-lm-32b\",\n-      ];\n-      for (const prefix of supportedPrefixes) {\n-        if (model.toLowerCase().startsWith(prefix)) {\n-          return true;\n-        }\n+    const specificModels = [\n+      \"qwen/qwq-32b\",\n+      \"qwen/qwen-2.5-72b-instruct\",\n+      \"meta-llama/llama-3.2-3b-instruct\",\n+      \"meta-llama/llama-3-8b-instruct\",\n+      \"meta-llama/llama-3-70b-instruct\",\n+      \"arcee-ai/caller-large\",\n+      \"nousresearch/hermes-3-llama-3.1-70b\",\n+    ];\n+    for (const model of specificModels) {\n+      if (model.toLowerCase() === model) {",
        "comment_created_at": "2025-07-18T16:26:56+00:00",
        "comment_author": "cubic-dev-ai[bot]",
        "comment_body": "<!-- metadata:{\"confidence\":9,\"steps\":[{\"text\":\"\",\"toolCalls\":[{\"args\":{\"command\":\"grep -R \\\"PROVIDER_TOOL_SUPPORT\\\" -n\"},\"toolName\":\"executeCommand\"}]},{\"text\":\"\",\"toolCalls\":[{\"args\":{\"command\":\"nl -ba core/llm/toolSupport.ts | sed -n '210,380p'\"},\"toolName\":\"executeCommand\"}]},{\"text\":\"\",\"toolCalls\":[{\"args\":{\"command\":\"grep -R \\\"PROVIDER_TOOL_SUPPORT\\\" -n --include='*.ts'\"},\"toolName\":\"executeCommand\"}]},{\"text\":\"\",\"toolCalls\":[{\"args\":{\"command\":\"grep -R \\\"PROVIDER_TOOL_SUPPORT\\\" --line-number\"},\"toolName\":\"executeCommand\"}]},{\"text\":\"\",\"toolCalls\":[{\"args\":{\"command\":\"grep -n \\\"for (const model of specificModels)\\\" -R core/llm/toolSupport.ts\"},\"toolName\":\"executeCommand\"}]},{\"text\":\"\",\"toolCalls\":[{\"args\":{\"command\":\"git diff -U0 | head -n 400\"},\"toolName\":\"executeCommand\"}]},{\"text\":\"\",\"toolCalls\":[{\"args\":{\"command\":\"git diff HEAD~1 -- core/llm/toolSupport.ts\"},\"toolName\":\"executeCommand\"}]}]} -->\nThe condition is always true because it compares a string to its lowercase version of itself; due to the shadowed variable, this causes the function to return true on the first iteration for every input, so openrouter support detection is incorrect.\n\n<details>\n<summary>Prompt for AI agents</summary>\n\n```\nAddress the following comment on core/llm/toolSupport.ts at line 275:\n\n<comment>The condition is always true because it compares a string to its lowercase version of itself; due to the shadowed variable, this causes the function to return true on the first iteration for every input, so openrouter support detection is incorrect.</comment>\n\n<file context>\n@@ -1,289 +1,317 @@\n import { parseProxyModelName } from &quot;@continuedev/config-yaml&quot;;\n+import { ModelDescription } from &quot;..&quot;;\n \n-export const PROVIDER_TOOL_SUPPORT: Record&lt;string, (model: string) =&gt; boolean&gt; =\n-  {\n-    &quot;continue-proxy&quot;: (model) =&gt; {\n-      try {\n-        const { provider, model: _model } = parseProxyModelName(model);\n-        if (provider &amp;&amp; _model &amp;&amp; provider !== &quot;continue-proxy&quot;) {\n-          const fn = PROVIDER_TOOL_SUPPORT[provider];\n-          if (fn) {\n-            return fn(_model);\n-          }\n+export const NATIVE_TOOL_SUPPORT: Record&lt;string, (model: string) =&gt; boolean&gt; = {\n+  &quot;continue-proxy&quot;: (model) =&gt; {\n+    try {\n+      const { provider, model: _model } = parseProxyModelName(model);\n+      if (provider &amp;&amp; _model &amp;&amp; provider !== &quot;continue-proxy&quot;) {\n+        const fn = NATIVE_TOOL_SUPPORT[provider];\n+        if (fn) {\n+          return fn(_model);\n         }\n-      } catch (e) {}\n+      }\n+    } catch (e) {}\n \n-      return [\n+    return [\n+      &quot;claude-3-5&quot;,\n+      &quot;claude-3.5&quot;,\n+      &quot;claude-3-7&quot;,\n+      &quot;claude-3.7&quot;,\n+      &quot;claude-sonnet-4&quot;,\n+      &quot;claude-4-sonnet&quot;,\n+      &quot;gpt-4&quot;,\n+      &quot;o3&quot;,\n+      &quot;gemini&quot;,\n+      &quot;claude-opus-4&quot;,\n+    ].some((part) =&gt; model.toLowerCase().startsWith(part));\n+  },\n+  anthropic: (model) =&gt; {\n+    if (\n+      [\n         &quot;claude-3-5&quot;,\n         &quot;claude-3.5&quot;,\n         &quot;claude-3-7&quot;,\n         &quot;claude-3.7&quot;,\n         &quot;claude-sonnet-4&quot;,\n         &quot;claude-4-sonnet&quot;,\n-        &quot;gpt-4&quot;,\n-        &quot;o3&quot;,\n-        &quot;gemini&quot;,\n         &quot;claude-opus-4&quot;,\n-      ].some((part) =&gt; model.toLowerCase().startsWith(part));\n-    },\n-    anthropic: (model) =&gt; {\n-      if (\n-        [\n-          &quot;claude-3-5&quot;,\n-          &quot;claude-3.5&quot;,\n-          &quot;claude-3-7&quot;,\n-          &quot;claude-3.7&quot;,\n-          &quot;claude-sonnet-4&quot;,\n-          &quot;claude-4-sonnet&quot;,\n-          &quot;claude-opus-4&quot;,\n-        ].some((part) =&gt; model.toLowerCase().startsWith(part))\n-      ) {\n-        return true;\n-      }\n+      ].some((part) =&gt; model.toLowerCase().startsWith(part))\n+    ) {\n+      return true;\n+    }\n \n-      return false;\n-    },\n-    azure: (model) =&gt; {\n-      if (\n-        model.toLowerCase().startsWith(&quot;gpt-4&quot;) ||\n-        model.toLowerCase().startsWith(&quot;o3&quot;)\n-      )\n-        return true;\n-      return false;\n-    },\n-    openai: (model) =&gt; {\n-      // https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling\n-      if (\n-        model.toLowerCase().startsWith(&quot;gpt-4&quot;) ||\n-        model.toLowerCase().startsWith(&quot;o3&quot;)\n-      ) {\n-        return true;\n-      }\n-      // firworks-ai https://docs.fireworks.ai/guides/function-calling\n-      if (model.startsWith(&quot;accounts/fireworks/models/&quot;)) {\n-        switch (model.substring(26)) {\n-          case &quot;llama-v3p1-405b-instruct&quot;:\n-          case &quot;llama-v3p1-70b-instruct&quot;:\n-          case &quot;qwen2p5-72b-instruct&quot;:\n-          case &quot;firefunction-v1&quot;:\n-          case &quot;firefunction-v2&quot;:\n-            return true;\n-          default:\n-            return false;\n-        }\n+    return false;\n+  },\n+  azure: (model) =&gt; {\n+    if (\n+      model.toLowerCase().startsWith(&quot;gpt-4&quot;) ||\n+      model.toLowerCase().startsWith(&quot;o3&quot;)\n+    )\n+      return true;\n+    return false;\n+  },\n+  openai: (model) =&gt; {\n+    // https://platform.openai.com/docs/guides/function-calling#models-supporting-function-calling\n+    if (\n+      model.toLowerCase().startsWith(&quot;gpt-4&quot;) ||\n+      model.toLowerCase().startsWith(&quot;o3&quot;)\n+    ) {\n+      return true;\n+    }\n+    // firworks-ai https://docs.fireworks.ai/guides/function-calling\n+    if (model.startsWith(&quot;accounts/fireworks/models/&quot;)) {\n+      switch (model.substring(26)) {\n+        case &quot;llama-v3p1-405b-instruct&quot;:\n+        case &quot;llama-v3p1-70b-instruct&quot;:\n+        case &quot;qwen2p5-72b-instruct&quot;:\n+        case &quot;firefunction-v1&quot;:\n+        case &quot;firefunction-v2&quot;:\n+          return true;\n+        default:\n+          return false;\n       }\n+    }\n \n-      return false;\n-    },\n-    cohere: (model) =&gt; {\n-      return model.toLowerCase().startsWith(&quot;command&quot;);\n-    },\n-    gemini: (model) =&gt; {\n-      // All gemini models support function calling\n-      return model.toLowerCase().includes(&quot;gemini&quot;);\n-    },\n-    vertexai: (model) =&gt; {\n-      // All gemini models except flash 2.0 lite support function calling\n-      return (\n-        model.toLowerCase().includes(&quot;gemini&quot;) &amp;&amp;\n-        !model.toLowerCase().includes(&quot;lite&quot;)\n-      );\n-    },\n-    bedrock: (model) =&gt; {\n-      if (\n-        [\n-          &quot;claude-3-5-sonnet&quot;,\n-          &quot;claude-3.5-sonnet&quot;,\n-          &quot;claude-3-7-sonnet&quot;,\n-          &quot;claude-3.7-sonnet&quot;,\n-          &quot;claude-sonnet-4&quot;,\n-          &quot;claude-4-sonnet&quot;,\n-          &quot;claude-opus-4&quot;,\n-          &quot;nova-lite&quot;,\n-          &quot;nova-pro&quot;,\n-          &quot;nova-micro&quot;,\n-          &quot;nova-premier&quot;,\n-        ].some((part) =&gt; model.toLowerCase().includes(part))\n-      ) {\n-        return true;\n-      }\n+    return false;\n+  },\n+  cohere: (model) =&gt; {\n+    return model.toLowerCase().startsWith(&quot;command&quot;);\n+  },\n+  gemini: (model) =&gt; {\n+    // All gemini models support function calling\n+    return model.toLowerCase().includes(&quot;gemini&quot;);\n+  },\n+  vertexai: (model) =&gt; {\n+    // All gemini models except flash 2.0 lite support function calling\n+    return (\n+      model.toLowerCase().includes(&quot;gemini&quot;) &amp;&amp;\n+      !model.toLowerCase().includes(&quot;lite&quot;)\n+    );\n+  },\n+  bedrock: (model) =&gt; {\n+    if (\n+      [\n+        &quot;claude-3-5-sonnet&quot;,\n+        &quot;claude-3.5-sonnet&quot;,\n+        &quot;claude-3-7-sonnet&quot;,\n+        &quot;claude-3.7-sonnet&quot;,\n+        &quot;claude-sonnet-4&quot;,\n+        &quot;claude-4-sonnet&quot;,\n+        &quot;claude-opus-4&quot;,\n+        &quot;nova-lite&quot;,\n+        &quot;nova-pro&quot;,\n+        &quot;nova-micro&quot;,\n+        &quot;nova-premier&quot;,\n+      ].some((part) =&gt; model.toLowerCase().includes(part))\n+    ) {\n+      return true;\n+    }\n \n+    return false;\n+  },\n+  mistral: (model) =&gt; {\n+    // https://docs.mistral.ai/capabilities/function_calling/\n+    return (\n+      !model.toLowerCase().includes(&quot;mamba&quot;) &amp;&amp;\n+      [\n+        &quot;devstral&quot;,\n+        &quot;codestral&quot;,\n+        &quot;mistral-large&quot;,\n+        &quot;mistral-small&quot;,\n+        &quot;pixtral&quot;,\n+        &quot;ministral&quot;,\n+        &quot;mistral-nemo&quot;,\n+        &quot;devstral&quot;,\n+      ].some((part) =&gt; model.toLowerCase().includes(part))\n+    );\n+  },\n+  // https://ollama.com/search?c=tools\n+  ollama: (model) =&gt; {\n+    let modelName = &quot;&quot;;\n+    // Extract the model name after the last slash to support other registries\n+    if (model.includes(&quot;/&quot;)) {\n+      let parts = model.split(&quot;/&quot;);\n+      modelName = parts[parts.length - 1];\n+    } else {\n+      modelName = model;\n+    }\n+\n+    if (\n+      [&quot;vision&quot;, &quot;math&quot;, &quot;guard&quot;, &quot;mistrallite&quot;, &quot;mistral-openorca&quot;].some(\n+        (part) =&gt; modelName.toLowerCase().includes(part),\n+      )\n+    ) {\n       return false;\n-    },\n-    mistral: (model) =&gt; {\n-      // https://docs.mistral.ai/capabilities/function_calling/\n-      return (\n-        !model.toLowerCase().includes(&quot;mamba&quot;) &amp;&amp;\n-        [\n-          &quot;devstral&quot;,\n-          &quot;codestral&quot;,\n-          &quot;mistral-large&quot;,\n-          &quot;mistral-small&quot;,\n-          &quot;pixtral&quot;,\n-          &quot;ministral&quot;,\n-          &quot;mistral-nemo&quot;,\n-          &quot;devstral&quot;,\n-        ].some((part) =&gt; model.toLowerCase().includes(part))\n-      );\n-    },\n-    // https://ollama.com/search?c=tools\n-    ollama: (model) =&gt; {\n-      let modelName = &quot;&quot;;\n-      // Extract the model name after the last slash to support other registries\n-      if (model.includes(&quot;/&quot;)) {\n-        let parts = model.split(&quot;/&quot;);\n-        modelName = parts[parts.length - 1];\n-      } else {\n-        modelName = model;\n-      }\n+    }\n+    if (\n+      [\n+        &quot;cogito&quot;,\n+        &quot;llama3.3&quot;,\n+        &quot;qwq&quot;,\n+        &quot;llama3.2&quot;,\n+        &quot;llama3.1&quot;,\n+        &quot;qwen2&quot;,\n+        &quot;qwen3&quot;,\n+        &quot;mixtral&quot;,\n+        &quot;command-r&quot;,\n+        &quot;command-a&quot;,\n+        &quot;smollm2&quot;,\n+        &quot;hermes3&quot;,\n+        &quot;athene-v2&quot;,\n+        &quot;nemotron&quot;,\n+        &quot;llama3-groq&quot;,\n+        &quot;granite3&quot;,\n+        &quot;granite-3&quot;,\n+        &quot;aya-expanse&quot;,\n+        &quot;firefunction-v2&quot;,\n+        &quot;mistral&quot;,\n+        &quot;devstral&quot;,\n+      ].some((part) =&gt; modelName.toLowerCase().includes(part))\n+    ) {\n+      return true;\n+    }\n \n-      if (\n-        [&quot;vision&quot;, &quot;math&quot;, &quot;guard&quot;, &quot;mistrallite&quot;, &quot;mistral-openorca&quot;].some(\n-          (part) =&gt; modelName.toLowerCase().includes(part),\n-        )\n-      ) {\n-        return false;\n-      }\n-      if (\n-        [\n-          &quot;cogito&quot;,\n-          &quot;llama3.3&quot;,\n-          &quot;qwq&quot;,\n-          &quot;llama3.2&quot;,\n-          &quot;llama3.1&quot;,\n-          &quot;qwen2&quot;,\n-          &quot;qwen3&quot;,\n-          &quot;mixtral&quot;,\n-          &quot;command-r&quot;,\n-          &quot;command-a&quot;,\n-          &quot;smollm2&quot;,\n-          &quot;hermes3&quot;,\n-          &quot;athene-v2&quot;,\n-          &quot;nemotron&quot;,\n-          &quot;llama3-groq&quot;,\n-          &quot;granite3&quot;,\n-          &quot;granite-3&quot;,\n-          &quot;aya-expanse&quot;,\n-          &quot;firefunction-v2&quot;,\n-          &quot;mistral&quot;,\n-          &quot;devstral&quot;,\n-        ].some((part) =&gt; modelName.toLowerCase().includes(part))\n-      ) {\n-        return true;\n-      }\n+    return false;\n+  },\n+  sambanova: (model) =&gt; {\n+    // https://docs.sambanova.ai/cloud/docs/capabilities/function-calling\n+    if (\n+      model.toLowerCase().startsWith(&quot;meta-llama-3&quot;) ||\n+      model.toLowerCase().includes(&quot;llama-4&quot;) ||\n+      model.toLowerCase().includes(&quot;deepseek&quot;)\n+    ) {\n+      return true;\n+    }\n \n-      return false;\n-    },\n-    sambanova: (model) =&gt; {\n-      // https://docs.sambanova.ai/cloud/docs/capabilities/function-calling\n-      if (\n-        model.toLowerCase().startsWith(&quot;meta-llama-3&quot;) ||\n-        model.toLowerCase().includes(&quot;llama-4&quot;) ||\n-        model.toLowerCase().includes(&quot;deepseek&quot;)\n-      ) {\n-        return true;\n-      }\n+    return false;\n+  },\n+  deepseek: (model) =&gt; {\n+    // https://api-docs.deepseek.com/quick_start/pricing\n+    // https://api-docs.deepseek.com/guides/function_calling\n+    if (model === &quot;deepseek-reasoner&quot; || model === &quot;deepseek-chat&quot;) {\n+      return true;\n+    }\n \n+    return false;\n+  },\n+  watsonx: (model) =&gt; {\n+    if (model.toLowerCase().includes(&quot;guard&quot;)) {\n       return false;\n-    },\n-    deepseek: (model) =&gt; {\n-      // https://api-docs.deepseek.com/quick_start/pricing\n-      // https://api-docs.deepseek.com/guides/function_calling\n-      if (model === &quot;deepseek-reasoner&quot; || model === &quot;deepseek-chat&quot;) {\n-        return true;\n-      }\n+    }\n+    if (\n+      [\n+        &quot;llama-3&quot;,\n+        &quot;llama-4&quot;,\n+        &quot;mistral&quot;,\n+        &quot;codestral&quot;,\n+        &quot;granite-3&quot;,\n+        &quot;devstral&quot;,\n+      ].some((part) =&gt; model.toLowerCase().includes(part))\n+    ) {\n+      return true;\n+    }\n \n+    return false;\n+  },\n+  openrouter: (model) =&gt; {\n+    // https://openrouter.ai/models?fmt=cards&amp;supported_parameters=tools\n+    if (\n+      [&quot;vision&quot;, &quot;math&quot;, &quot;guard&quot;, &quot;mistrallite&quot;, &quot;mistral-openorca&quot;].some(\n+        (part) =&gt; model.toLowerCase().includes(part),\n+      )\n+    ) {\n       return false;\n-    },\n-    watsonx: (model) =&gt; {\n-      if (model.toLowerCase().includes(&quot;guard&quot;)) {\n-        return false;\n-      }\n-      if (\n-        [\n-          &quot;llama-3&quot;,\n-          &quot;llama-4&quot;,\n-          &quot;mistral&quot;,\n-          &quot;codestral&quot;,\n-          &quot;granite-3&quot;,\n-          &quot;devstral&quot;,\n-        ].some((part) =&gt; model.toLowerCase().includes(part))\n-      ) {\n-        return true;\n-      }\n+    }\n \n-      return false;\n-    },\n-    openrouter: (model) =&gt; {\n-      // https://openrouter.ai/models?fmt=cards&amp;supported_parameters=tools\n-      if (\n-        [&quot;vision&quot;, &quot;math&quot;, &quot;guard&quot;, &quot;mistrallite&quot;, &quot;mistral-openorca&quot;].some(\n-          (part) =&gt; model.toLowerCase().includes(part),\n-        )\n-      ) {\n-        return false;\n+    const supportedPrefixes = [\n+      &quot;openai/gpt-3.5&quot;,\n+      &quot;openai/gpt-4&quot;,\n+      &quot;openai/o1&quot;,\n+      &quot;openai/o3&quot;,\n+      &quot;openai/o4&quot;,\n+      &quot;anthropic/claude-3&quot;,\n+      &quot;anthropic/claude-4&quot;,\n+      &quot;microsoft/phi-3&quot;,\n+      &quot;google/gemini-flash-1.5&quot;,\n+      &quot;google/gemini-2&quot;,\n+      &quot;google/gemini-pro&quot;,\n+      &quot;x-ai/grok&quot;,\n+      &quot;qwen/qwen3&quot;,\n+      &quot;qwen/qwen-&quot;,\n+      &quot;cohere/command-r&quot;,\n+      &quot;cohere/command-a&quot;,\n+      &quot;ai21/jamba-1.6&quot;,\n+      &quot;mistralai/mistral&quot;,\n+      &quot;mistralai/ministral&quot;,\n+      &quot;mistralai/codestral&quot;,\n+      &quot;mistralai/mixtral&quot;,\n+      &quot;mistral/ministral&quot;,\n+      &quot;mistral/devstral&quot;,\n+      &quot;mistralai/pixtral&quot;,\n+      &quot;meta-llama/llama-3.3&quot;,\n+      &quot;amazon/nova&quot;,\n+      &quot;deepseek/deepseek-r1&quot;,\n+      &quot;deepseek/deepseek-chat&quot;,\n+      &quot;meta-llama/llama-4&quot;,\n+      &quot;all-hands/openhands-lm-32b&quot;,\n+    ];\n+    for (const prefix of supportedPrefixes) {\n+      if (model.toLowerCase().startsWith(prefix)) {\n+        return true;\n       }\n+    }\n \n-      const supportedPrefixes = [\n-        &quot;openai/gpt-3.5&quot;,\n-        &quot;openai/gpt-4&quot;,\n-        &quot;openai/o1&quot;,\n-        &quot;openai/o3&quot;,\n-        &quot;openai/o4&quot;,\n-        &quot;anthropic/claude-3&quot;,\n-        &quot;anthropic/claude-4&quot;,\n-        &quot;microsoft/phi-3&quot;,\n-        &quot;google/gemini-flash-1.5&quot;,\n-        &quot;google/gemini-2&quot;,\n-        &quot;google/gemini-pro&quot;,\n-        &quot;x-ai/grok&quot;,\n-        &quot;qwen/qwen3&quot;,\n-        &quot;qwen/qwen-&quot;,\n-        &quot;cohere/command-r&quot;,\n-        &quot;cohere/command-a&quot;,\n-        &quot;ai21/jamba-1.6&quot;,\n-        &quot;mistralai/mistral&quot;,\n-        &quot;mistralai/ministral&quot;,\n-        &quot;mistralai/codestral&quot;,\n-        &quot;mistralai/mixtral&quot;,\n-        &quot;mistral/ministral&quot;,\n-        &quot;mistral/devstral&quot;,\n-        &quot;mistralai/pixtral&quot;,\n-        &quot;meta-llama/llama-3.3&quot;,\n-        &quot;amazon/nova&quot;,\n-        &quot;deepseek/deepseek-r1&quot;,\n-        &quot;deepseek/deepseek-chat&quot;,\n-        &quot;meta-llama/llama-4&quot;,\n-        &quot;all-hands/openhands-lm-32b&quot;,\n-      ];\n-      for (const prefix of supportedPrefixes) {\n-        if (model.toLowerCase().startsWith(prefix)) {\n-          return true;\n-        }\n+    const specificModels = [\n+      &quot;qwen/qwq-32b&quot;,\n+      &quot;qwen/qwen-2.5-72b-instruct&quot;,\n+      &quot;meta-llama/llama-3.2-3b-instruct&quot;,\n+      &quot;meta-llama/llama-3-8b-instruct&quot;,\n+      &quot;meta-llama/llama-3-70b-instruct&quot;,\n+      &quot;arcee-ai/caller-large&quot;,\n+      &quot;nousresearch/hermes-3-llama-3.1-70b&quot;,\n+    ];\n+    for (const model of specificModels) {\n+      if (model.toLowerCase() === model) {\n+        return true;\n       }\n+    }\n \n-      const specificModels = [\n-        &quot;qwen/qwq-32b&quot;,\n-        &quot;qwen/qwen-2.5-72b-instruct&quot;,\n-        &quot;meta-llama/llama-3.2-3b-instruct&quot;,\n-        &quot;meta-llama/llama-3-8b-instruct&quot;,\n-        &quot;meta-llama/llama-3-70b-instruct&quot;,\n-        &quot;arcee-ai/caller-large&quot;,\n-        &quot;nousresearch/hermes-3-llama-3.1-70b&quot;,\n-      ];\n-      for (const model of specificModels) {\n-        if (model.toLowerCase() === model) {\n-          return true;\n-        }\n+    const supportedContains = [&quot;llama-3.1&quot;];\n+    for (const model of supportedContains) {\n+      if (model.toLowerCase().includes(model)) {\n+        return true;\n       }\n+    }\n \n-      const supportedContains = [&quot;llama-3.1&quot;];\n-      for (const model of supportedContains) {\n-        if (model.toLowerCase().includes(model)) {\n-          return true;\n-        }\n-      }\n+    return false;\n+  },\n+};\n \n-      return false;\n-    },\n-  };\n+export function isRecommendedAgentModel(modelName: string): boolean {\n+  // AND behavior\n+  const recs: RegExp[][] = [\n+    [/o[134]/],\n+    [/deepseek/, /r1|reasoner/],\n+    [/gemini/, /2\\.5/, /pro/],\n+    [/gpt/, /4/],\n+    [/claude/, /sonnet/, /3\\.5|3\\.7|3-5|3-7|-4/],\n+    [/claude/, /opus/, /-4/],\n+  ];\n+  for (const combo of recs) {\n+    if (combo.every((regex) =&gt; modelName.toLowerCase().match(regex))) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+export function modelSupportsNativeTools(modelDescription: ModelDescription) {\n+  if (modelDescription.capabilities?.tools !== undefined) {\n+    return modelDescription.capabilities.tools;\n+  }\n+  const providerSupport = NATIVE_TOOL_SUPPORT[modelDescription.provider];\n+  if (!providerSupport) {\n+    return false;\n+  }\n+  return providerSupport(modelDescription.model) ?? false;\n+}\n</file context>\n```\n\n</details>",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1999117258",
    "pr_number": 4687,
    "pr_file": "core/diff/util.ts",
    "created_at": "2025-03-17T16:08:51+00:00",
    "commented_code": "};\n \n function linesMatchPerfectly(lineA: string, lineB: string): boolean {\n-  return lineA === lineB && lineA !== \"\";\n+\n+//checks if two lines match exactly ignoring trailing whitespace differences\n+//this prevents false mismatches in diff handling when trailing spaces are stripped\n+\n+  return lineA.trimEnd() === lineB.trimEnd() && lineA !== \"\";",
    "repo_full_name": "continuedev/continue",
    "discussion_comments": [
      {
        "comment_id": "1999117258",
        "repo_full_name": "continuedev/continue",
        "pr_number": 4687,
        "pr_file": "core/diff/util.ts",
        "discussion_id": "1999117258",
        "commented_code": "@@ -16,7 +16,11 @@ export type MatchLineResult = {\n };\n \n function linesMatchPerfectly(lineA: string, lineB: string): boolean {\n-  return lineA === lineB && lineA !== \"\";\n+\n+//checks if two lines match exactly ignoring trailing whitespace differences\n+//this prevents false mismatches in diff handling when trailing spaces are stripped\n+\n+  return lineA.trimEnd() === lineB.trimEnd() && lineA !== \"\";",
        "comment_created_at": "2025-03-17T16:08:51+00:00",
        "comment_author": "owtaylor",
        "comment_body": "This fixes up one case where we are comparing oldLines to newLines, but checking over the code, this isn't the only place where we might have issues:\r\n\r\n - in `matchLine()`, after calling `linesMatchPerfectly()`, we make more references to `oldLines[i]` that potentially might need changes.\r\n - In streamDiff(), we have:\r\n```\r\n         if (oldLinesCopy[0] !== newLine) {\r\n          yield { type: \"new\", line: newLine };\r\n        } else {\r\n          isLineRemoval = true;\r\n        }\r\n```\r\n   which looks suspicious, but I'm pretty sure can never actually be hit: if `oldLinesCopy[0] === newLine` then `isPerfectMatch` should have been true and the case will be `\"same\"` not `\"old\"`. Needs double checking.\r\n\r\nBut the takeaway for me here is that the test cases need updating to test different cases where lines differ only in trailing whitespace. From the `continue/core` directory, you can run:\r\n\r\n```\r\n$ npm test  diff/streamDiff.test.ts\r\n```\r\n\r\nto run streamDiff test cases. Add a test case to check the `linesMatchPerfectly` case, add a test case case that exercises:       `// This is a way to fix indentation, but only for sufficiently long lines to avoid matching whitespace or short lines` when the indentation changes *and* there is a change in whitespace.\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2001883020",
        "repo_full_name": "continuedev/continue",
        "pr_number": 4687,
        "pr_file": "core/diff/util.ts",
        "discussion_id": "1999117258",
        "commented_code": "@@ -16,7 +16,11 @@ export type MatchLineResult = {\n };\n \n function linesMatchPerfectly(lineA: string, lineB: string): boolean {\n-  return lineA === lineB && lineA !== \"\";\n+\n+//checks if two lines match exactly ignoring trailing whitespace differences\n+//this prevents false mismatches in diff handling when trailing spaces are stripped\n+\n+  return lineA.trimEnd() === lineB.trimEnd() && lineA !== \"\";",
        "comment_created_at": "2025-03-18T19:53:09+00:00",
        "comment_author": "panyamkeerthana",
        "comment_body": "Thanks for the review, I have made the following changes:\r\n\r\n-Added a test case for oldLinesCopy[0] === newLine that confirmed it\u2019s already handled as \"same\" or \"old\", so the else statement was unnecessary and removed.\r\n-Trimmed oldLines throughout and added a test to ensure trailing whitespaces are correctly treated as \"same\", preventing incorrect diffs.\r\n-Added a test to verify that indentation changes in long lines don\u2019t cause unnecessary diffs.\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2001910310",
    "pr_number": 4687,
    "pr_file": "core/diff/util.ts",
    "created_at": "2025-03-18T20:11:09+00:00",
    "commented_code": "const isEndBracket = END_BRACKETS.includes(newLine.trim());\n \n   for (let i = 0; i < oldLines.length; i++) {\n+    // trims trailing whitespaces from the old line before comparison\n+    //this ensures trailing spaces don't affect matching.\n+    const oldLineTrimmed = oldLines[i].trimEnd();\n     // Don't match end bracket lines if too far away\n     if (i > 4 && isEndBracket) {\n       return { matchIndex: -1, isPerfectMatch: false, newLine };\n     }\n \n-    if (linesMatchPerfectly(newLine, oldLines[i])) {\n+    if (linesMatchPerfectly(newLine, oldLineTrimmed)) {\n       return { matchIndex: i, isPerfectMatch: true, newLine };",
    "repo_full_name": "continuedev/continue",
    "discussion_comments": [
      {
        "comment_id": "2001910310",
        "repo_full_name": "continuedev/continue",
        "pr_number": 4687,
        "pr_file": "core/diff/util.ts",
        "discussion_id": "2001910310",
        "commented_code": "@@ -62,24 +62,27 @@ export function matchLine(\n   const isEndBracket = END_BRACKETS.includes(newLine.trim());\n \n   for (let i = 0; i < oldLines.length; i++) {\n+    // trims trailing whitespaces from the old line before comparison\n+    //this ensures trailing spaces don't affect matching.\n+    const oldLineTrimmed = oldLines[i].trimEnd();\n     // Don't match end bracket lines if too far away\n     if (i > 4 && isEndBracket) {\n       return { matchIndex: -1, isPerfectMatch: false, newLine };\n     }\n \n-    if (linesMatchPerfectly(newLine, oldLines[i])) {\n+    if (linesMatchPerfectly(newLine, oldLineTrimmed)) {\n       return { matchIndex: i, isPerfectMatch: true, newLine };",
        "comment_created_at": "2025-03-18T20:11:09+00:00",
        "comment_author": "owtaylor",
        "comment_body": "I think this probably should be oldLines[i] not newLine? The goal here should be that when we return `same` - we actually have the old line, not a version that differs in trailing whitespace. First try to make a test case that fails, then change this.",
        "pr_file_module": null
      },
      {
        "comment_id": "2002373822",
        "repo_full_name": "continuedev/continue",
        "pr_number": 4687,
        "pr_file": "core/diff/util.ts",
        "discussion_id": "2001910310",
        "commented_code": "@@ -62,24 +62,27 @@ export function matchLine(\n   const isEndBracket = END_BRACKETS.includes(newLine.trim());\n \n   for (let i = 0; i < oldLines.length; i++) {\n+    // trims trailing whitespaces from the old line before comparison\n+    //this ensures trailing spaces don't affect matching.\n+    const oldLineTrimmed = oldLines[i].trimEnd();\n     // Don't match end bracket lines if too far away\n     if (i > 4 && isEndBracket) {\n       return { matchIndex: -1, isPerfectMatch: false, newLine };\n     }\n \n-    if (linesMatchPerfectly(newLine, oldLines[i])) {\n+    if (linesMatchPerfectly(newLine, oldLineTrimmed)) {\n       return { matchIndex: i, isPerfectMatch: true, newLine };",
        "comment_created_at": "2025-03-19T04:05:47+00:00",
        "comment_author": "panyamkeerthana",
        "comment_body": "The test cases I ran for this scenario passed. In streamDiff():\r\n\r\n```\r\ncase \"same\":\r\n    yield { type, line: oldLinesCopy.shift()! };\r\n    break;\r\n```\r\nSo, regardless of what matchLine() returns for newLine, the line that is actually output is the one removed from oldLinesCopy (which is the original old line with the trailing whitespaces). But I can change it to oldLine[i] to maintain logic and uniformity",
        "pr_file_module": null
      },
      {
        "comment_id": "2006288136",
        "repo_full_name": "continuedev/continue",
        "pr_number": 4687,
        "pr_file": "core/diff/util.ts",
        "discussion_id": "2001910310",
        "commented_code": "@@ -62,24 +62,27 @@ export function matchLine(\n   const isEndBracket = END_BRACKETS.includes(newLine.trim());\n \n   for (let i = 0; i < oldLines.length; i++) {\n+    // trims trailing whitespaces from the old line before comparison\n+    //this ensures trailing spaces don't affect matching.\n+    const oldLineTrimmed = oldLines[i].trimEnd();\n     // Don't match end bracket lines if too far away\n     if (i > 4 && isEndBracket) {\n       return { matchIndex: -1, isPerfectMatch: false, newLine };\n     }\n \n-    if (linesMatchPerfectly(newLine, oldLines[i])) {\n+    if (linesMatchPerfectly(newLine, oldLineTrimmed)) {\n       return { matchIndex: i, isPerfectMatch: true, newLine };",
        "comment_created_at": "2025-03-20T19:09:10+00:00",
        "comment_author": "owtaylor",
        "comment_body": "Turned out that this very much needed to be newLine - the calling code relies on this only being different from the passed in newline when the leading indentation changed. Sorry for the confusion!",
        "pr_file_module": null
      },
      {
        "comment_id": "2006319211",
        "repo_full_name": "continuedev/continue",
        "pr_number": 4687,
        "pr_file": "core/diff/util.ts",
        "discussion_id": "2001910310",
        "commented_code": "@@ -62,24 +62,27 @@ export function matchLine(\n   const isEndBracket = END_BRACKETS.includes(newLine.trim());\n \n   for (let i = 0; i < oldLines.length; i++) {\n+    // trims trailing whitespaces from the old line before comparison\n+    //this ensures trailing spaces don't affect matching.\n+    const oldLineTrimmed = oldLines[i].trimEnd();\n     // Don't match end bracket lines if too far away\n     if (i > 4 && isEndBracket) {\n       return { matchIndex: -1, isPerfectMatch: false, newLine };\n     }\n \n-    if (linesMatchPerfectly(newLine, oldLines[i])) {\n+    if (linesMatchPerfectly(newLine, oldLineTrimmed)) {\n       return { matchIndex: i, isPerfectMatch: true, newLine };",
        "comment_created_at": "2025-03-20T19:29:46+00:00",
        "comment_author": "panyamkeerthana",
        "comment_body": "All this testing has only made the whitespace and indentation handling more robust! ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2179729948",
    "pr_number": 6395,
    "pr_file": "gui/src/redux/util/index.ts",
    "created_at": "2025-07-02T10:42:17+00:00",
    "commented_code": "export function findCurrentToolCall(\n   chatHistory: RootState[\"session\"][\"history\"],\n ): ToolCallState | undefined {\n-  return chatHistory[chatHistory.length - 1]?.toolCallState;\n+  for (let i = chatHistory.length - 1; i >= 0; i--) {\n+    const item = chatHistory[i];\n+    if (item.message.role !== \"assistant\") {",
    "repo_full_name": "continuedev/continue",
    "discussion_comments": [
      {
        "comment_id": "2179729948",
        "repo_full_name": "continuedev/continue",
        "pr_number": 6395,
        "pr_file": "gui/src/redux/util/index.ts",
        "discussion_id": "2179729948",
        "commented_code": "@@ -7,7 +7,15 @@ import { RootState } from \"../store\";\n export function findCurrentToolCall(\n   chatHistory: RootState[\"session\"][\"history\"],\n ): ToolCallState | undefined {\n-  return chatHistory[chatHistory.length - 1]?.toolCallState;\n+  for (let i = chatHistory.length - 1; i >= 0; i--) {\n+    const item = chatHistory[i];\n+    if (item.message.role !== \"assistant\") {",
        "comment_created_at": "2025-07-02T10:42:17+00:00",
        "comment_author": "cubic-dev-ai[bot]",
        "comment_body": "<!-- metadata:{\"confidence\":9,\"steps\":[]} -->\nThis check will break the loop on the first non-assistant message, which may skip over valid toolCallState entries in earlier assistant messages. This could cause the function to miss the most recent tool call if there are interleaved user or tool messages. Consider continuing the loop instead of breaking.\n\n```suggestion\n    if (item.message.role !== \"assistant\") {\n      continue;\n    }\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2182233686",
    "pr_number": 6429,
    "pr_file": "gui/src/components/mainInput/TipTapEditor/utils/resolveEditorContent.ts",
    "created_at": "2025-07-03T08:51:24+00:00",
    "commented_code": "if (\n         !acc.some(\n           (i) =>\n-            (i.id.providerTitle === item.id.providerTitle &&\n-              i.id.itemId === item.id.itemId) ||\n-            (i.uri &&\n-              item.uri &&\n-              i.uri.type === item.uri.type &&\n-              i.uri.value === item.uri.value),\n+            i.id.providerTitle === item.id.providerTitle &&",
    "repo_full_name": "continuedev/continue",
    "discussion_comments": [
      {
        "comment_id": "2182233686",
        "repo_full_name": "continuedev/continue",
        "pr_number": 6429,
        "pr_file": "gui/src/components/mainInput/TipTapEditor/utils/resolveEditorContent.ts",
        "discussion_id": "2182233686",
        "commented_code": "@@ -201,12 +201,12 @@ async function gatherContextItems({\n       if (\n         !acc.some(\n           (i) =>\n-            (i.id.providerTitle === item.id.providerTitle &&\n-              i.id.itemId === item.id.itemId) ||\n-            (i.uri &&\n-              item.uri &&\n-              i.uri.type === item.uri.type &&\n-              i.uri.value === item.uri.value),\n+            i.id.providerTitle === item.id.providerTitle &&",
        "comment_created_at": "2025-07-03T08:51:24+00:00",
        "comment_author": "RomneyDa",
        "comment_body": "Requested changes for this line\r\nIt changes deduplication to be for _exactly_ the same context item but breaks it for the original goal which is e.g. openFiles and currentFile adds the same file twice, or @diff is mentioned three times in nested prompts, or @openFiles in a prompt matches a @file mention in the editor, etc.",
        "pr_file_module": null
      },
      {
        "comment_id": "2182259439",
        "repo_full_name": "continuedev/continue",
        "pr_number": 6429,
        "pr_file": "gui/src/components/mainInput/TipTapEditor/utils/resolveEditorContent.ts",
        "discussion_id": "2182233686",
        "commented_code": "@@ -201,12 +201,12 @@ async function gatherContextItems({\n       if (\n         !acc.some(\n           (i) =>\n-            (i.id.providerTitle === item.id.providerTitle &&\n-              i.id.itemId === item.id.itemId) ||\n-            (i.uri &&\n-              item.uri &&\n-              i.uri.type === item.uri.type &&\n-              i.uri.value === item.uri.value),\n+            i.id.providerTitle === item.id.providerTitle &&",
        "comment_created_at": "2025-07-03T09:04:29+00:00",
        "comment_author": "RomneyDa",
        "comment_body": "But I realized deduplication logic had another flaw which is that you can have multiple context items with the same file URI and different content\r\n\r\nMaybe the solution is as simple as\r\n```\r\n   i.content === item.content\r\n```",
        "pr_file_module": null
      }
    ]
  }
]