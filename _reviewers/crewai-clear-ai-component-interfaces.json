[
  {
    "discussion_id": "2066658346",
    "pr_number": 2636,
    "pr_file": "docs/concepts/tasks.mdx",
    "created_at": "2025-04-29T14:18:12+00:00",
    "commented_code": ")\n ```\n \n+#### Leverage a no-code approach for validation\n+\n+```python Code\n+from crewai import Task\n+\n+task = Task(\n+    description=\"Generate JSON data\",\n+    expected_output=\"Valid JSON object\",\n+    guardrail=\"Ensure the response is a valid JSON object\"\n+)\n+```\n+\n+#### Using YAML\n+\n+```yaml\n+research_task:\n+  ...\n+  guardrail: make sure each bullet contains a minimum of 100 words\n+  ...\n+```\n+\n+```python Code\n+@CrewBase\n+class InternalCrew:\n+    agents_config = \"config/agents.yaml\"\n+    tasks_config = \"config/tasks.yaml\"\n+\n+    ...\n+    @task\n+    def research_task(self):\n+        return Task(config=self.tasks_config[\"research_task\"])  # type: ignore[index]\n+    ...\n+```\n+\n+\n+#### Use custom models for code generation\n+\n+```python Code\n+from crewai import Task\n+from crewai.llm import LLM\n+\n+task = Task(\n+    description=\"Generate JSON data\",\n+    expected_output=\"Valid JSON object\",\n+    guardrail=TaskGuardrail(",
    "repo_full_name": "crewAIInc/crewAI",
    "discussion_comments": [
      {
        "comment_id": "2066658346",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2636,
        "pr_file": "docs/concepts/tasks.mdx",
        "discussion_id": "2066658346",
        "commented_code": "@@ -769,6 +775,57 @@ task = Task(\n )\n ```\n \n+#### Leverage a no-code approach for validation\n+\n+```python Code\n+from crewai import Task\n+\n+task = Task(\n+    description=\"Generate JSON data\",\n+    expected_output=\"Valid JSON object\",\n+    guardrail=\"Ensure the response is a valid JSON object\"\n+)\n+```\n+\n+#### Using YAML\n+\n+```yaml\n+research_task:\n+  ...\n+  guardrail: make sure each bullet contains a minimum of 100 words\n+  ...\n+```\n+\n+```python Code\n+@CrewBase\n+class InternalCrew:\n+    agents_config = \"config/agents.yaml\"\n+    tasks_config = \"config/tasks.yaml\"\n+\n+    ...\n+    @task\n+    def research_task(self):\n+        return Task(config=self.tasks_config[\"research_task\"])  # type: ignore[index]\n+    ...\n+```\n+\n+\n+#### Use custom models for code generation\n+\n+```python Code\n+from crewai import Task\n+from crewai.llm import LLM\n+\n+task = Task(\n+    description=\"Generate JSON data\",\n+    expected_output=\"Valid JSON object\",\n+    guardrail=TaskGuardrail(",
        "comment_created_at": "2025-04-29T14:18:12+00:00",
        "comment_author": "gvieira",
        "comment_body": "I wonder if we shouldn't make it more specific, like `LLMGuardrail`. Naming is hard ™️. I'll summon @greysonlalonde again.",
        "pr_file_module": null
      },
      {
        "comment_id": "2067008659",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2636,
        "pr_file": "docs/concepts/tasks.mdx",
        "discussion_id": "2066658346",
        "commented_code": "@@ -769,6 +775,57 @@ task = Task(\n )\n ```\n \n+#### Leverage a no-code approach for validation\n+\n+```python Code\n+from crewai import Task\n+\n+task = Task(\n+    description=\"Generate JSON data\",\n+    expected_output=\"Valid JSON object\",\n+    guardrail=\"Ensure the response is a valid JSON object\"\n+)\n+```\n+\n+#### Using YAML\n+\n+```yaml\n+research_task:\n+  ...\n+  guardrail: make sure each bullet contains a minimum of 100 words\n+  ...\n+```\n+\n+```python Code\n+@CrewBase\n+class InternalCrew:\n+    agents_config = \"config/agents.yaml\"\n+    tasks_config = \"config/tasks.yaml\"\n+\n+    ...\n+    @task\n+    def research_task(self):\n+        return Task(config=self.tasks_config[\"research_task\"])  # type: ignore[index]\n+    ...\n+```\n+\n+\n+#### Use custom models for code generation\n+\n+```python Code\n+from crewai import Task\n+from crewai.llm import LLM\n+\n+task = Task(\n+    description=\"Generate JSON data\",\n+    expected_output=\"Valid JSON object\",\n+    guardrail=TaskGuardrail(",
        "comment_created_at": "2025-04-29T17:21:00+00:00",
        "comment_author": "lucasgomide",
        "comment_body": "What about `LLMOutputValidator`\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2068945182",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2636,
        "pr_file": "docs/concepts/tasks.mdx",
        "discussion_id": "2066658346",
        "commented_code": "@@ -769,6 +775,57 @@ task = Task(\n )\n ```\n \n+#### Leverage a no-code approach for validation\n+\n+```python Code\n+from crewai import Task\n+\n+task = Task(\n+    description=\"Generate JSON data\",\n+    expected_output=\"Valid JSON object\",\n+    guardrail=\"Ensure the response is a valid JSON object\"\n+)\n+```\n+\n+#### Using YAML\n+\n+```yaml\n+research_task:\n+  ...\n+  guardrail: make sure each bullet contains a minimum of 100 words\n+  ...\n+```\n+\n+```python Code\n+@CrewBase\n+class InternalCrew:\n+    agents_config = \"config/agents.yaml\"\n+    tasks_config = \"config/tasks.yaml\"\n+\n+    ...\n+    @task\n+    def research_task(self):\n+        return Task(config=self.tasks_config[\"research_task\"])  # type: ignore[index]\n+    ...\n+```\n+\n+\n+#### Use custom models for code generation\n+\n+```python Code\n+from crewai import Task\n+from crewai.llm import LLM\n+\n+task = Task(\n+    description=\"Generate JSON data\",\n+    expected_output=\"Valid JSON object\",\n+    guardrail=TaskGuardrail(",
        "comment_created_at": "2025-04-30T15:39:25+00:00",
        "comment_author": "greysonlalonde",
        "comment_body": "Missed this mention - I think `LLMGuardrail` is a good alternative, though. Usage of terms like validator start to feel a little pydantic-y",
        "pr_file_module": null
      },
      {
        "comment_id": "2069110373",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2636,
        "pr_file": "docs/concepts/tasks.mdx",
        "discussion_id": "2066658346",
        "commented_code": "@@ -769,6 +775,57 @@ task = Task(\n )\n ```\n \n+#### Leverage a no-code approach for validation\n+\n+```python Code\n+from crewai import Task\n+\n+task = Task(\n+    description=\"Generate JSON data\",\n+    expected_output=\"Valid JSON object\",\n+    guardrail=\"Ensure the response is a valid JSON object\"\n+)\n+```\n+\n+#### Using YAML\n+\n+```yaml\n+research_task:\n+  ...\n+  guardrail: make sure each bullet contains a minimum of 100 words\n+  ...\n+```\n+\n+```python Code\n+@CrewBase\n+class InternalCrew:\n+    agents_config = \"config/agents.yaml\"\n+    tasks_config = \"config/tasks.yaml\"\n+\n+    ...\n+    @task\n+    def research_task(self):\n+        return Task(config=self.tasks_config[\"research_task\"])  # type: ignore[index]\n+    ...\n+```\n+\n+\n+#### Use custom models for code generation\n+\n+```python Code\n+from crewai import Task\n+from crewai.llm import LLM\n+\n+task = Task(\n+    description=\"Generate JSON data\",\n+    expected_output=\"Valid JSON object\",\n+    guardrail=TaskGuardrail(",
        "comment_created_at": "2025-04-30T16:58:25+00:00",
        "comment_author": "lucasgomide",
        "comment_body": "@greysonlalonde I forgot to resolve this conversation before merging. I'm heading to renaming it right now",
        "pr_file_module": null
      },
      {
        "comment_id": "2069119454",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2636,
        "pr_file": "docs/concepts/tasks.mdx",
        "discussion_id": "2066658346",
        "commented_code": "@@ -769,6 +775,57 @@ task = Task(\n )\n ```\n \n+#### Leverage a no-code approach for validation\n+\n+```python Code\n+from crewai import Task\n+\n+task = Task(\n+    description=\"Generate JSON data\",\n+    expected_output=\"Valid JSON object\",\n+    guardrail=\"Ensure the response is a valid JSON object\"\n+)\n+```\n+\n+#### Using YAML\n+\n+```yaml\n+research_task:\n+  ...\n+  guardrail: make sure each bullet contains a minimum of 100 words\n+  ...\n+```\n+\n+```python Code\n+@CrewBase\n+class InternalCrew:\n+    agents_config = \"config/agents.yaml\"\n+    tasks_config = \"config/tasks.yaml\"\n+\n+    ...\n+    @task\n+    def research_task(self):\n+        return Task(config=self.tasks_config[\"research_task\"])  # type: ignore[index]\n+    ...\n+```\n+\n+\n+#### Use custom models for code generation\n+\n+```python Code\n+from crewai import Task\n+from crewai.llm import LLM\n+\n+task = Task(\n+    description=\"Generate JSON data\",\n+    expected_output=\"Valid JSON object\",\n+    guardrail=TaskGuardrail(",
        "comment_created_at": "2025-04-30T17:03:55+00:00",
        "comment_author": "lucasgomide",
        "comment_body": "@gvieira @greysonlalonde \r\nhttps://github.com/crewAIInc/crewAI/pull/2731",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1978863688",
    "pr_number": 2254,
    "pr_file": "docs/tools/apifyactorstool.mdx",
    "created_at": "2025-03-04T08:18:52+00:00",
    "commented_code": "+---\n+title: Apify Actors\n+description: The `ApifyActorsTool` seamlessly integrates Apify Actors into CrewAI workflows for web scraping, data extraction, and automation.\n+icon: toolbox\n+---\n+\n+# `ApifyActorsTool`\n+\n+## Description\n+\n+The `ApifyActorsTool` seamlessly integrates [Apify Actors](https://apify.com/) - cloud-based web scraping and automation programs—into your CrewAI workflows. Whether you need to extract data, crawl websites, or automate tasks, this tool simplifies the process without requiring infrastructure management.\n+\n+Key features:\n+- **Run Actors Directly**: Execute Actors like the [RAG Web Browser](https://apify.com/apify/rag-web-browser) within CrewAI agents.\n+- **Real-Time Data**: Ideal for tasks requiring up-to-date web data or automation.\n+- **Explore More**: Discover additional Actors in the [Apify Store](https://apify.com/store).\n+\n+For detailed integration guidance, see the [Apify CrewAI documentation](https://docs.apify.com/platform/integrations/crewai).\n+\n+## Installation\n+\n+To use `ApifyActorsTool`, install the required packages and configure your Apify API token. You’ll need an API token from Apify - see the [Apify API documentation](https://docs.apify.com/platform/integrations/api) for instructions.\n+\n+### Steps\n+1. **Install Dependencies**\n+   Use pip to install `crewai[tools]` and `langchain-apify`:\n+   ```bash\n+   pip install 'crewai[tools]' langchain-apify\n+   ```\n+   Alternatively, with `uv`:\n+   ```bash\n+   uv pip install 'crewai[tools]' langchain-apify\n+   ```\n+\n+2. **Set Your API Token**\n+   Export the token as an environment variable:\n+   - On Linux/macOS:\n+     ```bash\n+     export APIFY_API_TOKEN='your-api-token-here'\n+     ```\n+   - On Windows (Command Prompt):\n+     ```cmd\n+     set APIFY_API_TOKEN=your-api-token-here\n+     ```\n+   - Or add it to your `.env` file and load it with a library like `python-dotenv`.\n+\n+## Usage example\n+\n+Here’s how to use the `ApifyActorsTool` to run the [RAG Web Browser Actor](https://apify.com/apify/rag-web-browser) for web searching within a CrewAI workflow:\n+\n+```python\n+from crewai_tools import ApifyActorsTool\n+\n+# Initialize the tool with an Apify Actor\n+tool = ApifyActorsTool(actor_name=\"apify/rag-web-browser\")\n+\n+# Run the tool with input parameters\n+results = tool.run(run_input={\"query\": \"What is CrewAI?\", \"maxResults\": 5})\n+\n+# Process the results\n+for result in results:\n+    print(f\"URL: {result['metadata']['url']}\")\n+    print(f\"Content: {result.get('markdown', 'N/A')[:100]}...\")\n+```\n+\n+### Expected output\n+\n+```text\n+URL: https://www.example.com/crewai-intro\n+Content: CrewAI is a framework for building AI-powered workflows...\n+URL: https://docs.crewai.com/\n+Content: Official documentation for CrewAI...\n+```\n+\n+For a more comprehensive example with tool-agent, see [CrewAI Apify Actor template](https://apify.com/templates/python-crewai).\n+\n+Try other Actors from the [Apify Store](https://apify.com/store) by adjusting `actor_name` and `run_input` based on the Actor’s input schema.\n+\n+## Configuration\n+\n+The `ApifyActorsTool` requires specific inputs to operate:\n+\n+- **`actor_name` (str, required)**\n+  The ID of the Apify Actor to run (e.g., `\"apify/rag-web-browser\"`). Find Actors in the [Apify Store](https://apify.com/store).\n+- **`run_input` (dict, required at runtime)**\n+  A dictionary of input parameters for the Actor. Examples:\n+  - For `apify/rag-web-browser`: `{\"query\": \"search term\", \"maxResults\": 5}`\n+  - Check each Actor’s [input schema](https://apify.com/apify/rag-web-browser/input-schema) for details.\n+\n+The tool adapts dynamically to the chosen [Actor](https://docs.apify.com/platform/actors).\n+\n+## Steps to Get Started\n+\n+<Steps>\n+    <Step title=\"Install Dependencies\">\n+        Install `crewai[tools]` and `langchain-apify` using pip: `pip install 'crewai[tools]' langchain-apify`.\n+    </Step>\n+    <Step title=\"Obtain an API Token\">\n+        Sign up at [Apify](https://apify.com/) and retrieve your API token from the [Apify API documentation](https://docs.apify.com/platform/integrations/api).\n+    </Step>\n+    <Step title=\"Configure Environment\">\n+        Set your API token as an environment variable (`APIFY_API_TOKEN`) to enable the tool’s functionality.\n+    </Step>\n+    <Step title=\"Verify Setup\">\n+        Run `python -c \"import langchain_apify; print('Setup complete')\"` to confirm the installation.\n+    </Step>\n+</Steps>\n+\n+## Resources",
    "repo_full_name": "crewAIInc/crewAI",
    "discussion_comments": [
      {
        "comment_id": "1978863688",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2254,
        "pr_file": "docs/tools/apifyactorstool.mdx",
        "discussion_id": "1978863688",
        "commented_code": "@@ -0,0 +1,118 @@\n+---\n+title: Apify Actors\n+description: The `ApifyActorsTool` seamlessly integrates Apify Actors into CrewAI workflows for web scraping, data extraction, and automation.\n+icon: toolbox\n+---\n+\n+# `ApifyActorsTool`\n+\n+## Description\n+\n+The `ApifyActorsTool` seamlessly integrates [Apify Actors](https://apify.com/) - cloud-based web scraping and automation programs—into your CrewAI workflows. Whether you need to extract data, crawl websites, or automate tasks, this tool simplifies the process without requiring infrastructure management.\n+\n+Key features:\n+- **Run Actors Directly**: Execute Actors like the [RAG Web Browser](https://apify.com/apify/rag-web-browser) within CrewAI agents.\n+- **Real-Time Data**: Ideal for tasks requiring up-to-date web data or automation.\n+- **Explore More**: Discover additional Actors in the [Apify Store](https://apify.com/store).\n+\n+For detailed integration guidance, see the [Apify CrewAI documentation](https://docs.apify.com/platform/integrations/crewai).\n+\n+## Installation\n+\n+To use `ApifyActorsTool`, install the required packages and configure your Apify API token. You’ll need an API token from Apify - see the [Apify API documentation](https://docs.apify.com/platform/integrations/api) for instructions.\n+\n+### Steps\n+1. **Install Dependencies**\n+   Use pip to install `crewai[tools]` and `langchain-apify`:\n+   ```bash\n+   pip install 'crewai[tools]' langchain-apify\n+   ```\n+   Alternatively, with `uv`:\n+   ```bash\n+   uv pip install 'crewai[tools]' langchain-apify\n+   ```\n+\n+2. **Set Your API Token**\n+   Export the token as an environment variable:\n+   - On Linux/macOS:\n+     ```bash\n+     export APIFY_API_TOKEN='your-api-token-here'\n+     ```\n+   - On Windows (Command Prompt):\n+     ```cmd\n+     set APIFY_API_TOKEN=your-api-token-here\n+     ```\n+   - Or add it to your `.env` file and load it with a library like `python-dotenv`.\n+\n+## Usage example\n+\n+Here’s how to use the `ApifyActorsTool` to run the [RAG Web Browser Actor](https://apify.com/apify/rag-web-browser) for web searching within a CrewAI workflow:\n+\n+```python\n+from crewai_tools import ApifyActorsTool\n+\n+# Initialize the tool with an Apify Actor\n+tool = ApifyActorsTool(actor_name=\"apify/rag-web-browser\")\n+\n+# Run the tool with input parameters\n+results = tool.run(run_input={\"query\": \"What is CrewAI?\", \"maxResults\": 5})\n+\n+# Process the results\n+for result in results:\n+    print(f\"URL: {result['metadata']['url']}\")\n+    print(f\"Content: {result.get('markdown', 'N/A')[:100]}...\")\n+```\n+\n+### Expected output\n+\n+```text\n+URL: https://www.example.com/crewai-intro\n+Content: CrewAI is a framework for building AI-powered workflows...\n+URL: https://docs.crewai.com/\n+Content: Official documentation for CrewAI...\n+```\n+\n+For a more comprehensive example with tool-agent, see [CrewAI Apify Actor template](https://apify.com/templates/python-crewai).\n+\n+Try other Actors from the [Apify Store](https://apify.com/store) by adjusting `actor_name` and `run_input` based on the Actor’s input schema.\n+\n+## Configuration\n+\n+The `ApifyActorsTool` requires specific inputs to operate:\n+\n+- **`actor_name` (str, required)**\n+  The ID of the Apify Actor to run (e.g., `\"apify/rag-web-browser\"`). Find Actors in the [Apify Store](https://apify.com/store).\n+- **`run_input` (dict, required at runtime)**\n+  A dictionary of input parameters for the Actor. Examples:\n+  - For `apify/rag-web-browser`: `{\"query\": \"search term\", \"maxResults\": 5}`\n+  - Check each Actor’s [input schema](https://apify.com/apify/rag-web-browser/input-schema) for details.\n+\n+The tool adapts dynamically to the chosen [Actor](https://docs.apify.com/platform/actors).\n+\n+## Steps to Get Started\n+\n+<Steps>\n+    <Step title=\"Install Dependencies\">\n+        Install `crewai[tools]` and `langchain-apify` using pip: `pip install 'crewai[tools]' langchain-apify`.\n+    </Step>\n+    <Step title=\"Obtain an API Token\">\n+        Sign up at [Apify](https://apify.com/) and retrieve your API token from the [Apify API documentation](https://docs.apify.com/platform/integrations/api).\n+    </Step>\n+    <Step title=\"Configure Environment\">\n+        Set your API token as an environment variable (`APIFY_API_TOKEN`) to enable the tool’s functionality.\n+    </Step>\n+    <Step title=\"Verify Setup\">\n+        Run `python -c \"import langchain_apify; print('Setup complete')\"` to confirm the installation.\n+    </Step>\n+</Steps>\n+\n+## Resources",
        "comment_created_at": "2025-03-04T08:18:52+00:00",
        "comment_author": "jirispilka",
        "comment_body": "can we add agent use case, e.g.: https://docs.crewai.com/tools/bravesearchtool\r\n\r\nThis makes me wondering how a generic `ApifyActorTool` will work in Agent? How will LLM infer input arguments and tool functionality?",
        "pr_file_module": null
      },
      {
        "comment_id": "1980983861",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2254,
        "pr_file": "docs/tools/apifyactorstool.mdx",
        "discussion_id": "1978863688",
        "commented_code": "@@ -0,0 +1,118 @@\n+---\n+title: Apify Actors\n+description: The `ApifyActorsTool` seamlessly integrates Apify Actors into CrewAI workflows for web scraping, data extraction, and automation.\n+icon: toolbox\n+---\n+\n+# `ApifyActorsTool`\n+\n+## Description\n+\n+The `ApifyActorsTool` seamlessly integrates [Apify Actors](https://apify.com/) - cloud-based web scraping and automation programs—into your CrewAI workflows. Whether you need to extract data, crawl websites, or automate tasks, this tool simplifies the process without requiring infrastructure management.\n+\n+Key features:\n+- **Run Actors Directly**: Execute Actors like the [RAG Web Browser](https://apify.com/apify/rag-web-browser) within CrewAI agents.\n+- **Real-Time Data**: Ideal for tasks requiring up-to-date web data or automation.\n+- **Explore More**: Discover additional Actors in the [Apify Store](https://apify.com/store).\n+\n+For detailed integration guidance, see the [Apify CrewAI documentation](https://docs.apify.com/platform/integrations/crewai).\n+\n+## Installation\n+\n+To use `ApifyActorsTool`, install the required packages and configure your Apify API token. You’ll need an API token from Apify - see the [Apify API documentation](https://docs.apify.com/platform/integrations/api) for instructions.\n+\n+### Steps\n+1. **Install Dependencies**\n+   Use pip to install `crewai[tools]` and `langchain-apify`:\n+   ```bash\n+   pip install 'crewai[tools]' langchain-apify\n+   ```\n+   Alternatively, with `uv`:\n+   ```bash\n+   uv pip install 'crewai[tools]' langchain-apify\n+   ```\n+\n+2. **Set Your API Token**\n+   Export the token as an environment variable:\n+   - On Linux/macOS:\n+     ```bash\n+     export APIFY_API_TOKEN='your-api-token-here'\n+     ```\n+   - On Windows (Command Prompt):\n+     ```cmd\n+     set APIFY_API_TOKEN=your-api-token-here\n+     ```\n+   - Or add it to your `.env` file and load it with a library like `python-dotenv`.\n+\n+## Usage example\n+\n+Here’s how to use the `ApifyActorsTool` to run the [RAG Web Browser Actor](https://apify.com/apify/rag-web-browser) for web searching within a CrewAI workflow:\n+\n+```python\n+from crewai_tools import ApifyActorsTool\n+\n+# Initialize the tool with an Apify Actor\n+tool = ApifyActorsTool(actor_name=\"apify/rag-web-browser\")\n+\n+# Run the tool with input parameters\n+results = tool.run(run_input={\"query\": \"What is CrewAI?\", \"maxResults\": 5})\n+\n+# Process the results\n+for result in results:\n+    print(f\"URL: {result['metadata']['url']}\")\n+    print(f\"Content: {result.get('markdown', 'N/A')[:100]}...\")\n+```\n+\n+### Expected output\n+\n+```text\n+URL: https://www.example.com/crewai-intro\n+Content: CrewAI is a framework for building AI-powered workflows...\n+URL: https://docs.crewai.com/\n+Content: Official documentation for CrewAI...\n+```\n+\n+For a more comprehensive example with tool-agent, see [CrewAI Apify Actor template](https://apify.com/templates/python-crewai).\n+\n+Try other Actors from the [Apify Store](https://apify.com/store) by adjusting `actor_name` and `run_input` based on the Actor’s input schema.\n+\n+## Configuration\n+\n+The `ApifyActorsTool` requires specific inputs to operate:\n+\n+- **`actor_name` (str, required)**\n+  The ID of the Apify Actor to run (e.g., `\"apify/rag-web-browser\"`). Find Actors in the [Apify Store](https://apify.com/store).\n+- **`run_input` (dict, required at runtime)**\n+  A dictionary of input parameters for the Actor. Examples:\n+  - For `apify/rag-web-browser`: `{\"query\": \"search term\", \"maxResults\": 5}`\n+  - Check each Actor’s [input schema](https://apify.com/apify/rag-web-browser/input-schema) for details.\n+\n+The tool adapts dynamically to the chosen [Actor](https://docs.apify.com/platform/actors).\n+\n+## Steps to Get Started\n+\n+<Steps>\n+    <Step title=\"Install Dependencies\">\n+        Install `crewai[tools]` and `langchain-apify` using pip: `pip install 'crewai[tools]' langchain-apify`.\n+    </Step>\n+    <Step title=\"Obtain an API Token\">\n+        Sign up at [Apify](https://apify.com/) and retrieve your API token from the [Apify API documentation](https://docs.apify.com/platform/integrations/api).\n+    </Step>\n+    <Step title=\"Configure Environment\">\n+        Set your API token as an environment variable (`APIFY_API_TOKEN`) to enable the tool’s functionality.\n+    </Step>\n+    <Step title=\"Verify Setup\">\n+        Run `python -c \"import langchain_apify; print('Setup complete')\"` to confirm the installation.\n+    </Step>\n+</Steps>\n+\n+## Resources",
        "comment_created_at": "2025-03-05T09:07:19+00:00",
        "comment_author": "MQ37",
        "comment_body": "added the agent use example and explained that the tool fetches the schema and description automatically :+1: ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1861160086",
    "pr_number": 1664,
    "pr_file": "docs/concepts/langchain-tools.mdx",
    "created_at": "2024-11-27T19:28:42+00:00",
    "commented_code": "## Using LangChain Tools\n \n <Info>\n-    CrewAI seamlessly integrates with LangChain’s comprehensive [list of tools](https://python.langchain.com/docs/integrations/tools/), all of which can be used with CrewAI.\n+    CrewAI seamlessly integrates with LangChain's comprehensive [list of tools](https://python.langchain.com/docs/integrations/tools/), all of which can be used with CrewAI.\n </Info>\n \n ```python Code\n import os\n-from crewai import Agent\n-from langchain.agents import Tool\n-from langchain.utilities import GoogleSerperAPIWrapper\n+from dotenv import load_dotenv\n+from crewai import Agent, Task, Crew\n+from crewai.tools import BaseTool\n+from pydantic import Field\n+from langchain_community.utilities import GoogleSerperAPIWrapper\n \n-# Setup API keys\n-os.environ[\"SERPER_API_KEY\"] = \"Your Key\"\n+# Set up your SERPER_API_KEY key in an .env file, eg:\n+# SERPER_API_KEY=<your api key>\n+load_dotenv()\n \n search = GoogleSerperAPIWrapper()\n \n-# Create and assign the search tool to an agent\n-serper_tool = Tool(\n-  name=\"Intermediate Answer\",\n-  func=search.run,\n-  description=\"Useful for search-based queries\",\n-)\n-\n-agent = Agent(\n-  role='Research Analyst',\n-  goal='Provide up-to-date market analysis',\n-  backstory='An expert analyst with a keen eye for market trends.',\n-  tools=[serper_tool]\n+class SearchTool(BaseTool):",
    "repo_full_name": "crewAIInc/crewAI",
    "discussion_comments": [
      {
        "comment_id": "1861160086",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 1664,
        "pr_file": "docs/concepts/langchain-tools.mdx",
        "discussion_id": "1861160086",
        "commented_code": "@@ -7,39 +7,52 @@ icon: link\n ## Using LangChain Tools\n \n <Info>\n-    CrewAI seamlessly integrates with LangChain’s comprehensive [list of tools](https://python.langchain.com/docs/integrations/tools/), all of which can be used with CrewAI.\n+    CrewAI seamlessly integrates with LangChain's comprehensive [list of tools](https://python.langchain.com/docs/integrations/tools/), all of which can be used with CrewAI.\n </Info>\n \n ```python Code\n import os\n-from crewai import Agent\n-from langchain.agents import Tool\n-from langchain.utilities import GoogleSerperAPIWrapper\n+from dotenv import load_dotenv\n+from crewai import Agent, Task, Crew\n+from crewai.tools import BaseTool\n+from pydantic import Field\n+from langchain_community.utilities import GoogleSerperAPIWrapper\n \n-# Setup API keys\n-os.environ[\"SERPER_API_KEY\"] = \"Your Key\"\n+# Set up your SERPER_API_KEY key in an .env file, eg:\n+# SERPER_API_KEY=<your api key>\n+load_dotenv()\n \n search = GoogleSerperAPIWrapper()\n \n-# Create and assign the search tool to an agent\n-serper_tool = Tool(\n-  name=\"Intermediate Answer\",\n-  func=search.run,\n-  description=\"Useful for search-based queries\",\n-)\n-\n-agent = Agent(\n-  role='Research Analyst',\n-  goal='Provide up-to-date market analysis',\n-  backstory='An expert analyst with a keen eye for market trends.',\n-  tools=[serper_tool]\n+class SearchTool(BaseTool):",
        "comment_created_at": "2024-11-27T19:28:42+00:00",
        "comment_author": "bhancockio",
        "comment_body": "Instead of creating a `BaseTool`, you could also just use langchain's tool like this:\r\n\r\n```\r\nfrom crewai import Agent, Crew, Process, Task\r\nfrom langchain.agents import Tool\r\nfrom langchain_community.utilities import GoogleSerperAPIWrapper\r\n\r\nsearch = GoogleSerperAPIWrapper()\r\n\r\n# Create and assign the search tool to an agent\r\nserper_tool = Tool(\r\n    name=\"Intermediate Answer\",\r\n    func=search.run,\r\n    description=\"Useful for search-based queries\",\r\n)\r\n\r\nresearch_analyst = Agent(\r\n    role=\"Research Analyst\",\r\n    goal=\"Provide up-to-date market analysis\",\r\n    backstory=\"An expert analyst with a keen eye for market trends.\",\r\n    tools=[serper_tool],\r\n)\r\n```\r\n\r\nIt looks a little more cleaner and fully showcases using a LangChain Tool.\r\n\r\nIf you could update the example to use `from langchain.agents import Tool`, we can merge this in!",
        "pr_file_module": null
      },
      {
        "comment_id": "1861184087",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 1664,
        "pr_file": "docs/concepts/langchain-tools.mdx",
        "discussion_id": "1861160086",
        "commented_code": "@@ -7,39 +7,52 @@ icon: link\n ## Using LangChain Tools\n \n <Info>\n-    CrewAI seamlessly integrates with LangChain’s comprehensive [list of tools](https://python.langchain.com/docs/integrations/tools/), all of which can be used with CrewAI.\n+    CrewAI seamlessly integrates with LangChain's comprehensive [list of tools](https://python.langchain.com/docs/integrations/tools/), all of which can be used with CrewAI.\n </Info>\n \n ```python Code\n import os\n-from crewai import Agent\n-from langchain.agents import Tool\n-from langchain.utilities import GoogleSerperAPIWrapper\n+from dotenv import load_dotenv\n+from crewai import Agent, Task, Crew\n+from crewai.tools import BaseTool\n+from pydantic import Field\n+from langchain_community.utilities import GoogleSerperAPIWrapper\n \n-# Setup API keys\n-os.environ[\"SERPER_API_KEY\"] = \"Your Key\"\n+# Set up your SERPER_API_KEY key in an .env file, eg:\n+# SERPER_API_KEY=<your api key>\n+load_dotenv()\n \n search = GoogleSerperAPIWrapper()\n \n-# Create and assign the search tool to an agent\n-serper_tool = Tool(\n-  name=\"Intermediate Answer\",\n-  func=search.run,\n-  description=\"Useful for search-based queries\",\n-)\n-\n-agent = Agent(\n-  role='Research Analyst',\n-  goal='Provide up-to-date market analysis',\n-  backstory='An expert analyst with a keen eye for market trends.',\n-  tools=[serper_tool]\n+class SearchTool(BaseTool):",
        "comment_created_at": "2024-11-27T19:54:40+00:00",
        "comment_author": "olaservo",
        "comment_body": "I might be missing something, I think that's what is already in the example?  When I looked at the source code it seemed like I needed to wrap it this way since I got an error otherwise.",
        "pr_file_module": null
      }
    ]
  }
]