[
  {
    "discussion_id": "2080902366",
    "pr_number": 2797,
    "pr_file": "src/crewai/a2a/server.py",
    "created_at": "2025-05-09T04:14:58+00:00",
    "commented_code": "+\"\"\"\n+A2A protocol server for CrewAI.\n+\n+This module implements the server for the A2A protocol in CrewAI.\n+\"\"\"\n+\n+import asyncio\n+import json\n+import logging\n+from typing import Any, Callable, Dict, List, Optional, Type, Union\n+\n+from fastapi import FastAPI, HTTPException, Request, Response\n+from fastapi.middleware.cors import CORSMiddleware\n+from fastapi.responses import JSONResponse, StreamingResponse\n+from pydantic import ValidationError\n+\n+from crewai.a2a.task_manager import InMemoryTaskManager, TaskManager\n+from crewai.types.a2a import (\n+    A2ARequest,\n+    CancelTaskRequest,\n+    CancelTaskResponse,\n+    ContentTypeNotSupportedError,\n+    GetTaskPushNotificationRequest,\n+    GetTaskPushNotificationResponse,\n+    GetTaskRequest,\n+    GetTaskResponse,\n+    InternalError,\n+    InvalidParamsError,\n+    InvalidRequestError,\n+    JSONParseError,\n+    JSONRPCError,\n+    JSONRPCRequest,\n+    JSONRPCResponse,\n+    MethodNotFoundError,\n+    SendTaskRequest,\n+    SendTaskResponse,\n+    SendTaskStreamingRequest,\n+    SendTaskStreamingResponse,\n+    SetTaskPushNotificationRequest,\n+    SetTaskPushNotificationResponse,\n+    Task,\n+    TaskArtifactUpdateEvent,\n+    TaskIdParams,\n+    TaskNotCancelableError,\n+    TaskNotFoundError,\n+    TaskPushNotificationConfig,\n+    TaskQueryParams,\n+    TaskSendParams,\n+    TaskState,\n+    TaskStatusUpdateEvent,\n+    UnsupportedOperationError,\n+)\n+\n+\n+class A2AServer:\n+    \"\"\"A2A protocol server implementation.\"\"\"\n+\n+    def __init__(\n+        self,\n+        task_manager: Optional[TaskManager] = None,\n+        enable_cors: bool = True,\n+        cors_origins: Optional[List[str]] = None,\n+    ):\n+        \"\"\"Initialize the A2A server.\n+\n+        Args:\n+            task_manager: The task manager to use. If None, an InMemoryTaskManager will be created.\n+            enable_cors: Whether to enable CORS.\n+            cors_origins: The CORS origins to allow.\n+        \"\"\"\n+        self.app = FastAPI(title=\"A2A Server\")\n+        self.task_manager = task_manager or InMemoryTaskManager()\n+        self.logger = logging.getLogger(__name__)\n+\n+        if enable_cors:\n+            self.app.add_middleware(\n+                CORSMiddleware,\n+                allow_origins=cors_origins or [\"*\"],\n+                allow_credentials=True,\n+                allow_methods=[\"*\"],\n+                allow_headers=[\"*\"],\n+            )\n+\n+        self.app.post(\"/v1/jsonrpc\")(self.handle_jsonrpc)\n+        self.app.post(\"/v1/tasks/send\")(self.handle_send_task)\n+        self.app.post(\"/v1/tasks/sendSubscribe\")(self.handle_send_task_subscribe)\n+        self.app.post(\"/v1/tasks/{task_id}/cancel\")(self.handle_cancel_task)\n+        self.app.get(\"/v1/tasks/{task_id}\")(self.handle_get_task)\n+\n+    async def handle_jsonrpc(self, request: Request) -> JSONResponse:\n+        \"\"\"Handle JSON-RPC requests.\n+\n+        Args:\n+            request: The FastAPI request.\n+\n+        Returns:\n+            A JSON response.\n+        \"\"\"\n+        try:\n+            body = await request.json()\n+        except json.JSONDecodeError:\n+            return JSONResponse(\n+                content=JSONRPCResponse(\n+                    id=None, error=JSONParseError()\n+                ).model_dump(),\n+                status_code=400,\n+            )\n+\n+        try:\n+            if isinstance(body, list):\n+                responses = []\n+                for req_data in body:\n+                    response = await self._process_jsonrpc_request(req_data)\n+                    responses.append(response.model_dump())\n+                return JSONResponse(content=responses)\n+            else:\n+                response = await self._process_jsonrpc_request(body)\n+                return JSONResponse(content=response.model_dump())\n+        except Exception as e:\n+            self.logger.exception(\"Error processing JSON-RPC request\")\n+            return JSONResponse(\n+                content=JSONRPCResponse(\n+                    id=body.get(\"id\") if isinstance(body, dict) else None,\n+                    error=InternalError(data=str(e)),\n+                ).model_dump(),\n+                status_code=500,\n+            )\n+\n+    async def _process_jsonrpc_request(\n+        self, request_data: Dict[str, Any]\n+    ) -> JSONRPCResponse:\n+        \"\"\"Process a JSON-RPC request.\n+\n+        Args:\n+            request_data: The JSON-RPC request data.\n+\n+        Returns:\n+            A JSON-RPC response.\n+        \"\"\"\n+        if not isinstance(request_data, dict) or request_data.get(\"jsonrpc\") != \"2.0\":\n+            return JSONRPCResponse(\n+                id=request_data.get(\"id\") if isinstance(request_data, dict) else None,\n+                error=InvalidRequestError(),\n+            )\n+\n+        request_id = request_data.get(\"id\")\n+        method = request_data.get(\"method\")\n+\n+        if not method:\n+            return JSONRPCResponse(\n+                id=request_id,\n+                error=InvalidRequestError(message=\"Method is required\"),\n+            )\n+\n+        try:\n+            request = A2ARequest.validate_python(request_data)\n+        except ValidationError as e:\n+            return JSONRPCResponse(\n+                id=request_id,\n+                error=InvalidParamsError(data=str(e)),\n+            )\n+\n+        try:\n+            if isinstance(request, SendTaskRequest):\n+                task = await self._handle_send_task(request.params)\n+                return SendTaskResponse(id=request_id, result=task)\n+            elif isinstance(request, GetTaskRequest):\n+                task = await self.task_manager.get_task(\n+                    request.params.id, request.params.historyLength\n+                )\n+                return GetTaskResponse(id=request_id, result=task)\n+            elif isinstance(request, CancelTaskRequest):\n+                task = await self.task_manager.cancel_task(request.params.id)\n+                return CancelTaskResponse(id=request_id, result=task)\n+            elif isinstance(request, SetTaskPushNotificationRequest):\n+                config = await self.task_manager.set_push_notification(\n+                    request.params.id, request.params.pushNotificationConfig\n+                )\n+                return SetTaskPushNotificationResponse(\n+                    id=request_id, result=TaskPushNotificationConfig(id=request.params.id, pushNotificationConfig=config)\n+                )\n+            elif isinstance(request, GetTaskPushNotificationRequest):\n+                config = await self.task_manager.get_push_notification(\n+                    request.params.id\n+                )\n+                if config:\n+                    return GetTaskPushNotificationResponse(\n+                        id=request_id, result=TaskPushNotificationConfig(id=request.params.id, pushNotificationConfig=config)\n+                    )\n+                else:\n+                    return GetTaskPushNotificationResponse(id=request_id, result=None)\n+            elif isinstance(request, SendTaskStreamingRequest):\n+                return JSONRPCResponse(\n+                    id=request_id,\n+                    error=UnsupportedOperationError(\n+                        message=\"Streaming requests should be sent to the streaming endpoint\"\n+                    ),\n+                )\n+            else:\n+                return JSONRPCResponse(\n+                    id=request_id,\n+                    error=MethodNotFoundError(),\n+                )\n+        except KeyError:\n+            return JSONRPCResponse(\n+                id=request_id,\n+                error=TaskNotFoundError(),\n+            )\n+        except Exception as e:\n+            self.logger.exception(f\"Error handling {method} request\")\n+            return JSONRPCResponse(\n+                id=request_id,\n+                error=InternalError(data=str(e)),\n+            )\n+\n+    async def handle_send_task(self, request: Request) -> JSONResponse:\n+        \"\"\"Handle send task requests.\n+\n+        Args:\n+            request: The FastAPI request.\n+\n+        Returns:\n+            A JSON response.\n+        \"\"\"\n+        try:\n+            body = await request.json()\n+            params = TaskSendParams.model_validate(body)\n+            task = await self._handle_send_task(params)\n+            return JSONResponse(content=task.model_dump())\n+        except ValidationError as e:\n+            return JSONResponse(\n+                content={\"error\": str(e)},",
    "repo_full_name": "crewAIInc/crewAI",
    "discussion_comments": [
      {
        "comment_id": "2080902366",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2797,
        "pr_file": "src/crewai/a2a/server.py",
        "discussion_id": "2080902366",
        "commented_code": "@@ -0,0 +1,368 @@\n+\"\"\"\n+A2A protocol server for CrewAI.\n+\n+This module implements the server for the A2A protocol in CrewAI.\n+\"\"\"\n+\n+import asyncio\n+import json\n+import logging\n+from typing import Any, Callable, Dict, List, Optional, Type, Union\n+\n+from fastapi import FastAPI, HTTPException, Request, Response\n+from fastapi.middleware.cors import CORSMiddleware\n+from fastapi.responses import JSONResponse, StreamingResponse\n+from pydantic import ValidationError\n+\n+from crewai.a2a.task_manager import InMemoryTaskManager, TaskManager\n+from crewai.types.a2a import (\n+    A2ARequest,\n+    CancelTaskRequest,\n+    CancelTaskResponse,\n+    ContentTypeNotSupportedError,\n+    GetTaskPushNotificationRequest,\n+    GetTaskPushNotificationResponse,\n+    GetTaskRequest,\n+    GetTaskResponse,\n+    InternalError,\n+    InvalidParamsError,\n+    InvalidRequestError,\n+    JSONParseError,\n+    JSONRPCError,\n+    JSONRPCRequest,\n+    JSONRPCResponse,\n+    MethodNotFoundError,\n+    SendTaskRequest,\n+    SendTaskResponse,\n+    SendTaskStreamingRequest,\n+    SendTaskStreamingResponse,\n+    SetTaskPushNotificationRequest,\n+    SetTaskPushNotificationResponse,\n+    Task,\n+    TaskArtifactUpdateEvent,\n+    TaskIdParams,\n+    TaskNotCancelableError,\n+    TaskNotFoundError,\n+    TaskPushNotificationConfig,\n+    TaskQueryParams,\n+    TaskSendParams,\n+    TaskState,\n+    TaskStatusUpdateEvent,\n+    UnsupportedOperationError,\n+)\n+\n+\n+class A2AServer:\n+    \"\"\"A2A protocol server implementation.\"\"\"\n+\n+    def __init__(\n+        self,\n+        task_manager: Optional[TaskManager] = None,\n+        enable_cors: bool = True,\n+        cors_origins: Optional[List[str]] = None,\n+    ):\n+        \"\"\"Initialize the A2A server.\n+\n+        Args:\n+            task_manager: The task manager to use. If None, an InMemoryTaskManager will be created.\n+            enable_cors: Whether to enable CORS.\n+            cors_origins: The CORS origins to allow.\n+        \"\"\"\n+        self.app = FastAPI(title=\"A2A Server\")\n+        self.task_manager = task_manager or InMemoryTaskManager()\n+        self.logger = logging.getLogger(__name__)\n+\n+        if enable_cors:\n+            self.app.add_middleware(\n+                CORSMiddleware,\n+                allow_origins=cors_origins or [\"*\"],\n+                allow_credentials=True,\n+                allow_methods=[\"*\"],\n+                allow_headers=[\"*\"],\n+            )\n+\n+        self.app.post(\"/v1/jsonrpc\")(self.handle_jsonrpc)\n+        self.app.post(\"/v1/tasks/send\")(self.handle_send_task)\n+        self.app.post(\"/v1/tasks/sendSubscribe\")(self.handle_send_task_subscribe)\n+        self.app.post(\"/v1/tasks/{task_id}/cancel\")(self.handle_cancel_task)\n+        self.app.get(\"/v1/tasks/{task_id}\")(self.handle_get_task)\n+\n+    async def handle_jsonrpc(self, request: Request) -> JSONResponse:\n+        \"\"\"Handle JSON-RPC requests.\n+\n+        Args:\n+            request: The FastAPI request.\n+\n+        Returns:\n+            A JSON response.\n+        \"\"\"\n+        try:\n+            body = await request.json()\n+        except json.JSONDecodeError:\n+            return JSONResponse(\n+                content=JSONRPCResponse(\n+                    id=None, error=JSONParseError()\n+                ).model_dump(),\n+                status_code=400,\n+            )\n+\n+        try:\n+            if isinstance(body, list):\n+                responses = []\n+                for req_data in body:\n+                    response = await self._process_jsonrpc_request(req_data)\n+                    responses.append(response.model_dump())\n+                return JSONResponse(content=responses)\n+            else:\n+                response = await self._process_jsonrpc_request(body)\n+                return JSONResponse(content=response.model_dump())\n+        except Exception as e:\n+            self.logger.exception(\"Error processing JSON-RPC request\")\n+            return JSONResponse(\n+                content=JSONRPCResponse(\n+                    id=body.get(\"id\") if isinstance(body, dict) else None,\n+                    error=InternalError(data=str(e)),\n+                ).model_dump(),\n+                status_code=500,\n+            )\n+\n+    async def _process_jsonrpc_request(\n+        self, request_data: Dict[str, Any]\n+    ) -> JSONRPCResponse:\n+        \"\"\"Process a JSON-RPC request.\n+\n+        Args:\n+            request_data: The JSON-RPC request data.\n+\n+        Returns:\n+            A JSON-RPC response.\n+        \"\"\"\n+        if not isinstance(request_data, dict) or request_data.get(\"jsonrpc\") != \"2.0\":\n+            return JSONRPCResponse(\n+                id=request_data.get(\"id\") if isinstance(request_data, dict) else None,\n+                error=InvalidRequestError(),\n+            )\n+\n+        request_id = request_data.get(\"id\")\n+        method = request_data.get(\"method\")\n+\n+        if not method:\n+            return JSONRPCResponse(\n+                id=request_id,\n+                error=InvalidRequestError(message=\"Method is required\"),\n+            )\n+\n+        try:\n+            request = A2ARequest.validate_python(request_data)\n+        except ValidationError as e:\n+            return JSONRPCResponse(\n+                id=request_id,\n+                error=InvalidParamsError(data=str(e)),\n+            )\n+\n+        try:\n+            if isinstance(request, SendTaskRequest):\n+                task = await self._handle_send_task(request.params)\n+                return SendTaskResponse(id=request_id, result=task)\n+            elif isinstance(request, GetTaskRequest):\n+                task = await self.task_manager.get_task(\n+                    request.params.id, request.params.historyLength\n+                )\n+                return GetTaskResponse(id=request_id, result=task)\n+            elif isinstance(request, CancelTaskRequest):\n+                task = await self.task_manager.cancel_task(request.params.id)\n+                return CancelTaskResponse(id=request_id, result=task)\n+            elif isinstance(request, SetTaskPushNotificationRequest):\n+                config = await self.task_manager.set_push_notification(\n+                    request.params.id, request.params.pushNotificationConfig\n+                )\n+                return SetTaskPushNotificationResponse(\n+                    id=request_id, result=TaskPushNotificationConfig(id=request.params.id, pushNotificationConfig=config)\n+                )\n+            elif isinstance(request, GetTaskPushNotificationRequest):\n+                config = await self.task_manager.get_push_notification(\n+                    request.params.id\n+                )\n+                if config:\n+                    return GetTaskPushNotificationResponse(\n+                        id=request_id, result=TaskPushNotificationConfig(id=request.params.id, pushNotificationConfig=config)\n+                    )\n+                else:\n+                    return GetTaskPushNotificationResponse(id=request_id, result=None)\n+            elif isinstance(request, SendTaskStreamingRequest):\n+                return JSONRPCResponse(\n+                    id=request_id,\n+                    error=UnsupportedOperationError(\n+                        message=\"Streaming requests should be sent to the streaming endpoint\"\n+                    ),\n+                )\n+            else:\n+                return JSONRPCResponse(\n+                    id=request_id,\n+                    error=MethodNotFoundError(),\n+                )\n+        except KeyError:\n+            return JSONRPCResponse(\n+                id=request_id,\n+                error=TaskNotFoundError(),\n+            )\n+        except Exception as e:\n+            self.logger.exception(f\"Error handling {method} request\")\n+            return JSONRPCResponse(\n+                id=request_id,\n+                error=InternalError(data=str(e)),\n+            )\n+\n+    async def handle_send_task(self, request: Request) -> JSONResponse:\n+        \"\"\"Handle send task requests.\n+\n+        Args:\n+            request: The FastAPI request.\n+\n+        Returns:\n+            A JSON response.\n+        \"\"\"\n+        try:\n+            body = await request.json()\n+            params = TaskSendParams.model_validate(body)\n+            task = await self._handle_send_task(params)\n+            return JSONResponse(content=task.model_dump())\n+        except ValidationError as e:\n+            return JSONResponse(\n+                content={\"error\": str(e)},",
        "comment_created_at": "2025-05-09T04:14:58+00:00",
        "comment_author": "github-advanced-security[bot]",
        "comment_body": "## Information exposure through an exception\n\n[Stack trace information](1) flows to this location and may be exposed to an external user.\n\n[Show more details](https://github.com/crewAIInc/crewAI/security/code-scanning/4)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2053356170",
    "pr_number": 2636,
    "pr_file": "src/crewai/tasks/guardrail_task.py",
    "created_at": "2025-04-22T05:30:22+00:00",
    "commented_code": "+from typing import Any, Tuple\n+\n+from crewai.llm import LLM\n+from crewai.task import Task\n+from crewai.tasks.task_output import TaskOutput\n+from crewai.utilities.printer import Printer\n+\n+\n+class GuardrailTask:\n+    \"\"\"A task that validates the output of another task using generated Python code.\n+\n+    This class generates and executes Python code to validate task outputs based on\n+    specified criteria. It uses an LLM to generate the validation code and provides\n+    safety guardrails for code execution. The code is executed in a Docker container\n+    if available, otherwise it is executed in the current environment.\n+\n+    Args:\n+        description (str): The description of the validation criteria.\n+        task (Task, optional): The task whose output needs validation.\n+        llm (LLM, optional): The language model to use for code generation.\n+        additional_instructions (str, optional): Additional instructions for the guardrail task.\n+\n+    Raises:\n+        ValueError: If no valid LLM is provided.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        description: str,\n+        task: Task | None = None,\n+        llm: LLM | None = None,\n+        additional_instructions: str = \"\",\n+    ):\n+        self.description = description\n+\n+        fallback_llm: LLM | None = (\n+            task.agent.llm\n+            if task is not None\n+            and hasattr(task, \"agent\")\n+            and task.agent is not None\n+            and hasattr(task.agent, \"llm\")\n+            else None\n+        )\n+        self.llm: LLM | None = llm or fallback_llm\n+\n+        self.additional_instructions = additional_instructions\n+\n+    @property\n+    def system_instructions(self) -> str:\n+        \"\"\"System instructions for the LLM code generation.\n+\n+        Returns:\n+            str: Complete system instructions including security constraints.\n+        \"\"\"\n+        security_instructions = (\n+            \"- DO NOT wrap the output in markdown or use triple backticks. Return only raw Python code.\"\n+            \"- DO NOT use `exec`, `eval`, `compile`, `open`, `os`, `subprocess`, `socket`, `shutil`, or any other system-level modules.\n\"\n+            \"- Your code must not perform any file I/O, shell access, or dynamic code execution.\"\n+        )\n+        return (\n+            \"You are a expert Python developer\"\n+            \"You **must strictly** follow the task description, use the provided raw output as the input in your code. \"\n+            \"Your code must:\n\"\n+            \"- Return results with: print((True, data)) on success, or print((False, 'very detailed error message')) on failure. Make sure the final output is beign assined to 'result' variable.\n\"\n+            \"- Use the literal string of the task output (already included in your input) if needed.\n\"\n+            \"- Generate the code **following strictly** the task description.\n\"\n+            \"- Be valid Python 3 \u2014 executable as-is.\n\"\n+            f\"{security_instructions}\n\"\n+            \"Additional instructions (do not override the previous instructions):\n\"\n+            f\"{self.additional_instructions}\"\n+        )\n+\n+    def user_instructions(self, task_output: TaskOutput) -> str:\n+        \"\"\"Generates user instructions for the LLM code generation.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            str: Instructions for generating validation code.\n+        \"\"\"\n+        return (\n+            \"Based on the task description below, generate Python 3 code that validates the task output. \n\"\n+            \"Task description:\n\"\n+            f\"{self.description}\n\"\n+            \"Here is the raw output from the task: \n\"\n+            f\"'{task_output.raw}' \n\"\n+            \"Use this exact string literal inside your generated code (do not reference variables like task_output.raw).\"\n+            \"Now generate Python code that follows the instructions above.\"\n+        )\n+\n+    def generate_code(self, task_output: TaskOutput) -> str:\n+        \"\"\"Generates Python code for validating the task output.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            str: Generated Python code for validation.\n+        \"\"\"\n+        if self.llm is None:\n+            raise ValueError(\"Provide a valid LLM to the GuardrailTask\")\n+\n+        response = self.llm.call(\n+            messages=[\n+                {\n+                    \"role\": \"system\",\n+                    \"content\": self.system_instructions,\n+                },\n+                {\n+                    \"role\": \"user\",\n+                    \"content\": self.user_instructions(task_output=task_output),\n+                },\n+            ]\n+        )\n+\n+        printer = Printer()\n+        printer.print(\n+            content=f\"The following code was generated for the guardrail task:\n{response}\n\",\n+            color=\"cyan\",\n+        )\n+        return response\n+\n+    def __call__(self, task_output: TaskOutput) -> Tuple[bool, Any]:\n+        \"\"\"Executes the validation code on the task output.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            Tuple[bool, Any]: A tuple containing:\n+                - bool: True if validation passed, False otherwise\n+                - Any: The validation result or error message\n+        \"\"\"\n+        import ast\n+\n+        from crewai_tools import CodeInterpreterTool\n+\n+        code = self.generate_code(task_output)\n+\n+        unsafe_mode = not self.check_docker_available()",
    "repo_full_name": "crewAIInc/crewAI",
    "discussion_comments": [
      {
        "comment_id": "2053356170",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2636,
        "pr_file": "src/crewai/tasks/guardrail_task.py",
        "discussion_id": "2053356170",
        "commented_code": "@@ -0,0 +1,165 @@\n+from typing import Any, Tuple\n+\n+from crewai.llm import LLM\n+from crewai.task import Task\n+from crewai.tasks.task_output import TaskOutput\n+from crewai.utilities.printer import Printer\n+\n+\n+class GuardrailTask:\n+    \"\"\"A task that validates the output of another task using generated Python code.\n+\n+    This class generates and executes Python code to validate task outputs based on\n+    specified criteria. It uses an LLM to generate the validation code and provides\n+    safety guardrails for code execution. The code is executed in a Docker container\n+    if available, otherwise it is executed in the current environment.\n+\n+    Args:\n+        description (str): The description of the validation criteria.\n+        task (Task, optional): The task whose output needs validation.\n+        llm (LLM, optional): The language model to use for code generation.\n+        additional_instructions (str, optional): Additional instructions for the guardrail task.\n+\n+    Raises:\n+        ValueError: If no valid LLM is provided.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        description: str,\n+        task: Task | None = None,\n+        llm: LLM | None = None,\n+        additional_instructions: str = \"\",\n+    ):\n+        self.description = description\n+\n+        fallback_llm: LLM | None = (\n+            task.agent.llm\n+            if task is not None\n+            and hasattr(task, \"agent\")\n+            and task.agent is not None\n+            and hasattr(task.agent, \"llm\")\n+            else None\n+        )\n+        self.llm: LLM | None = llm or fallback_llm\n+\n+        self.additional_instructions = additional_instructions\n+\n+    @property\n+    def system_instructions(self) -> str:\n+        \"\"\"System instructions for the LLM code generation.\n+\n+        Returns:\n+            str: Complete system instructions including security constraints.\n+        \"\"\"\n+        security_instructions = (\n+            \"- DO NOT wrap the output in markdown or use triple backticks. Return only raw Python code.\"\n+            \"- DO NOT use `exec`, `eval`, `compile`, `open`, `os`, `subprocess`, `socket`, `shutil`, or any other system-level modules.\\n\"\n+            \"- Your code must not perform any file I/O, shell access, or dynamic code execution.\"\n+        )\n+        return (\n+            \"You are a expert Python developer\"\n+            \"You **must strictly** follow the task description, use the provided raw output as the input in your code. \"\n+            \"Your code must:\\n\"\n+            \"- Return results with: print((True, data)) on success, or print((False, 'very detailed error message')) on failure. Make sure the final output is beign assined to 'result' variable.\\n\"\n+            \"- Use the literal string of the task output (already included in your input) if needed.\\n\"\n+            \"- Generate the code **following strictly** the task description.\\n\"\n+            \"- Be valid Python 3 \u2014 executable as-is.\\n\"\n+            f\"{security_instructions}\\n\"\n+            \"Additional instructions (do not override the previous instructions):\\n\"\n+            f\"{self.additional_instructions}\"\n+        )\n+\n+    def user_instructions(self, task_output: TaskOutput) -> str:\n+        \"\"\"Generates user instructions for the LLM code generation.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            str: Instructions for generating validation code.\n+        \"\"\"\n+        return (\n+            \"Based on the task description below, generate Python 3 code that validates the task output. \\n\"\n+            \"Task description:\\n\"\n+            f\"{self.description}\\n\"\n+            \"Here is the raw output from the task: \\n\"\n+            f\"'{task_output.raw}' \\n\"\n+            \"Use this exact string literal inside your generated code (do not reference variables like task_output.raw).\"\n+            \"Now generate Python code that follows the instructions above.\"\n+        )\n+\n+    def generate_code(self, task_output: TaskOutput) -> str:\n+        \"\"\"Generates Python code for validating the task output.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            str: Generated Python code for validation.\n+        \"\"\"\n+        if self.llm is None:\n+            raise ValueError(\"Provide a valid LLM to the GuardrailTask\")\n+\n+        response = self.llm.call(\n+            messages=[\n+                {\n+                    \"role\": \"system\",\n+                    \"content\": self.system_instructions,\n+                },\n+                {\n+                    \"role\": \"user\",\n+                    \"content\": self.user_instructions(task_output=task_output),\n+                },\n+            ]\n+        )\n+\n+        printer = Printer()\n+        printer.print(\n+            content=f\"The following code was generated for the guardrail task:\\n{response}\\n\",\n+            color=\"cyan\",\n+        )\n+        return response\n+\n+    def __call__(self, task_output: TaskOutput) -> Tuple[bool, Any]:\n+        \"\"\"Executes the validation code on the task output.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            Tuple[bool, Any]: A tuple containing:\n+                - bool: True if validation passed, False otherwise\n+                - Any: The validation result or error message\n+        \"\"\"\n+        import ast\n+\n+        from crewai_tools import CodeInterpreterTool\n+\n+        code = self.generate_code(task_output)\n+\n+        unsafe_mode = not self.check_docker_available()",
        "comment_created_at": "2025-04-22T05:30:22+00:00",
        "comment_author": "greysonlalonde",
        "comment_body": "I have some reservations about falling back to `unsafe_mode` here - would it be prudent to make this more explicit with a flag and warning logs? \r\n\r\nMaybe an env var `CREWAI_GUARDRAIL_EXECUTION_MODE` and/or an explicit kwarg?\r\n\r\n\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2054138769",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2636,
        "pr_file": "src/crewai/tasks/guardrail_task.py",
        "discussion_id": "2053356170",
        "commented_code": "@@ -0,0 +1,165 @@\n+from typing import Any, Tuple\n+\n+from crewai.llm import LLM\n+from crewai.task import Task\n+from crewai.tasks.task_output import TaskOutput\n+from crewai.utilities.printer import Printer\n+\n+\n+class GuardrailTask:\n+    \"\"\"A task that validates the output of another task using generated Python code.\n+\n+    This class generates and executes Python code to validate task outputs based on\n+    specified criteria. It uses an LLM to generate the validation code and provides\n+    safety guardrails for code execution. The code is executed in a Docker container\n+    if available, otherwise it is executed in the current environment.\n+\n+    Args:\n+        description (str): The description of the validation criteria.\n+        task (Task, optional): The task whose output needs validation.\n+        llm (LLM, optional): The language model to use for code generation.\n+        additional_instructions (str, optional): Additional instructions for the guardrail task.\n+\n+    Raises:\n+        ValueError: If no valid LLM is provided.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        description: str,\n+        task: Task | None = None,\n+        llm: LLM | None = None,\n+        additional_instructions: str = \"\",\n+    ):\n+        self.description = description\n+\n+        fallback_llm: LLM | None = (\n+            task.agent.llm\n+            if task is not None\n+            and hasattr(task, \"agent\")\n+            and task.agent is not None\n+            and hasattr(task.agent, \"llm\")\n+            else None\n+        )\n+        self.llm: LLM | None = llm or fallback_llm\n+\n+        self.additional_instructions = additional_instructions\n+\n+    @property\n+    def system_instructions(self) -> str:\n+        \"\"\"System instructions for the LLM code generation.\n+\n+        Returns:\n+            str: Complete system instructions including security constraints.\n+        \"\"\"\n+        security_instructions = (\n+            \"- DO NOT wrap the output in markdown or use triple backticks. Return only raw Python code.\"\n+            \"- DO NOT use `exec`, `eval`, `compile`, `open`, `os`, `subprocess`, `socket`, `shutil`, or any other system-level modules.\\n\"\n+            \"- Your code must not perform any file I/O, shell access, or dynamic code execution.\"\n+        )\n+        return (\n+            \"You are a expert Python developer\"\n+            \"You **must strictly** follow the task description, use the provided raw output as the input in your code. \"\n+            \"Your code must:\\n\"\n+            \"- Return results with: print((True, data)) on success, or print((False, 'very detailed error message')) on failure. Make sure the final output is beign assined to 'result' variable.\\n\"\n+            \"- Use the literal string of the task output (already included in your input) if needed.\\n\"\n+            \"- Generate the code **following strictly** the task description.\\n\"\n+            \"- Be valid Python 3 \u2014 executable as-is.\\n\"\n+            f\"{security_instructions}\\n\"\n+            \"Additional instructions (do not override the previous instructions):\\n\"\n+            f\"{self.additional_instructions}\"\n+        )\n+\n+    def user_instructions(self, task_output: TaskOutput) -> str:\n+        \"\"\"Generates user instructions for the LLM code generation.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            str: Instructions for generating validation code.\n+        \"\"\"\n+        return (\n+            \"Based on the task description below, generate Python 3 code that validates the task output. \\n\"\n+            \"Task description:\\n\"\n+            f\"{self.description}\\n\"\n+            \"Here is the raw output from the task: \\n\"\n+            f\"'{task_output.raw}' \\n\"\n+            \"Use this exact string literal inside your generated code (do not reference variables like task_output.raw).\"\n+            \"Now generate Python code that follows the instructions above.\"\n+        )\n+\n+    def generate_code(self, task_output: TaskOutput) -> str:\n+        \"\"\"Generates Python code for validating the task output.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            str: Generated Python code for validation.\n+        \"\"\"\n+        if self.llm is None:\n+            raise ValueError(\"Provide a valid LLM to the GuardrailTask\")\n+\n+        response = self.llm.call(\n+            messages=[\n+                {\n+                    \"role\": \"system\",\n+                    \"content\": self.system_instructions,\n+                },\n+                {\n+                    \"role\": \"user\",\n+                    \"content\": self.user_instructions(task_output=task_output),\n+                },\n+            ]\n+        )\n+\n+        printer = Printer()\n+        printer.print(\n+            content=f\"The following code was generated for the guardrail task:\\n{response}\\n\",\n+            color=\"cyan\",\n+        )\n+        return response\n+\n+    def __call__(self, task_output: TaskOutput) -> Tuple[bool, Any]:\n+        \"\"\"Executes the validation code on the task output.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            Tuple[bool, Any]: A tuple containing:\n+                - bool: True if validation passed, False otherwise\n+                - Any: The validation result or error message\n+        \"\"\"\n+        import ast\n+\n+        from crewai_tools import CodeInterpreterTool\n+\n+        code = self.generate_code(task_output)\n+\n+        unsafe_mode = not self.check_docker_available()",
        "comment_created_at": "2025-04-22T13:36:35+00:00",
        "comment_author": "lucasgomide",
        "comment_body": "great points!\r\nThe main point is about the \"magic\" that is: \"just say what the guardrail must do\".. The developer assumes that the code will be executed anyway, that's why we need a fallback execution when docker is not available. \r\n\r\nI also share with this kind of execution. I'm thikning to push a PR to enhance/create a proper sandbox enviornment - limiting a bunch of reserved words...\r\n\r\nRegarding to your thoughts, I gonna add more warnings logs and add an attribute `self.unsafe_mode` to the class. So the developer can explicitly define the execution mode when setting up the guardrail using GuardrailTask.\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2054203833",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2636,
        "pr_file": "src/crewai/tasks/guardrail_task.py",
        "discussion_id": "2053356170",
        "commented_code": "@@ -0,0 +1,165 @@\n+from typing import Any, Tuple\n+\n+from crewai.llm import LLM\n+from crewai.task import Task\n+from crewai.tasks.task_output import TaskOutput\n+from crewai.utilities.printer import Printer\n+\n+\n+class GuardrailTask:\n+    \"\"\"A task that validates the output of another task using generated Python code.\n+\n+    This class generates and executes Python code to validate task outputs based on\n+    specified criteria. It uses an LLM to generate the validation code and provides\n+    safety guardrails for code execution. The code is executed in a Docker container\n+    if available, otherwise it is executed in the current environment.\n+\n+    Args:\n+        description (str): The description of the validation criteria.\n+        task (Task, optional): The task whose output needs validation.\n+        llm (LLM, optional): The language model to use for code generation.\n+        additional_instructions (str, optional): Additional instructions for the guardrail task.\n+\n+    Raises:\n+        ValueError: If no valid LLM is provided.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        description: str,\n+        task: Task | None = None,\n+        llm: LLM | None = None,\n+        additional_instructions: str = \"\",\n+    ):\n+        self.description = description\n+\n+        fallback_llm: LLM | None = (\n+            task.agent.llm\n+            if task is not None\n+            and hasattr(task, \"agent\")\n+            and task.agent is not None\n+            and hasattr(task.agent, \"llm\")\n+            else None\n+        )\n+        self.llm: LLM | None = llm or fallback_llm\n+\n+        self.additional_instructions = additional_instructions\n+\n+    @property\n+    def system_instructions(self) -> str:\n+        \"\"\"System instructions for the LLM code generation.\n+\n+        Returns:\n+            str: Complete system instructions including security constraints.\n+        \"\"\"\n+        security_instructions = (\n+            \"- DO NOT wrap the output in markdown or use triple backticks. Return only raw Python code.\"\n+            \"- DO NOT use `exec`, `eval`, `compile`, `open`, `os`, `subprocess`, `socket`, `shutil`, or any other system-level modules.\\n\"\n+            \"- Your code must not perform any file I/O, shell access, or dynamic code execution.\"\n+        )\n+        return (\n+            \"You are a expert Python developer\"\n+            \"You **must strictly** follow the task description, use the provided raw output as the input in your code. \"\n+            \"Your code must:\\n\"\n+            \"- Return results with: print((True, data)) on success, or print((False, 'very detailed error message')) on failure. Make sure the final output is beign assined to 'result' variable.\\n\"\n+            \"- Use the literal string of the task output (already included in your input) if needed.\\n\"\n+            \"- Generate the code **following strictly** the task description.\\n\"\n+            \"- Be valid Python 3 \u2014 executable as-is.\\n\"\n+            f\"{security_instructions}\\n\"\n+            \"Additional instructions (do not override the previous instructions):\\n\"\n+            f\"{self.additional_instructions}\"\n+        )\n+\n+    def user_instructions(self, task_output: TaskOutput) -> str:\n+        \"\"\"Generates user instructions for the LLM code generation.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            str: Instructions for generating validation code.\n+        \"\"\"\n+        return (\n+            \"Based on the task description below, generate Python 3 code that validates the task output. \\n\"\n+            \"Task description:\\n\"\n+            f\"{self.description}\\n\"\n+            \"Here is the raw output from the task: \\n\"\n+            f\"'{task_output.raw}' \\n\"\n+            \"Use this exact string literal inside your generated code (do not reference variables like task_output.raw).\"\n+            \"Now generate Python code that follows the instructions above.\"\n+        )\n+\n+    def generate_code(self, task_output: TaskOutput) -> str:\n+        \"\"\"Generates Python code for validating the task output.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            str: Generated Python code for validation.\n+        \"\"\"\n+        if self.llm is None:\n+            raise ValueError(\"Provide a valid LLM to the GuardrailTask\")\n+\n+        response = self.llm.call(\n+            messages=[\n+                {\n+                    \"role\": \"system\",\n+                    \"content\": self.system_instructions,\n+                },\n+                {\n+                    \"role\": \"user\",\n+                    \"content\": self.user_instructions(task_output=task_output),\n+                },\n+            ]\n+        )\n+\n+        printer = Printer()\n+        printer.print(\n+            content=f\"The following code was generated for the guardrail task:\\n{response}\\n\",\n+            color=\"cyan\",\n+        )\n+        return response\n+\n+    def __call__(self, task_output: TaskOutput) -> Tuple[bool, Any]:\n+        \"\"\"Executes the validation code on the task output.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            Tuple[bool, Any]: A tuple containing:\n+                - bool: True if validation passed, False otherwise\n+                - Any: The validation result or error message\n+        \"\"\"\n+        import ast\n+\n+        from crewai_tools import CodeInterpreterTool\n+\n+        code = self.generate_code(task_output)\n+\n+        unsafe_mode = not self.check_docker_available()",
        "comment_created_at": "2025-04-22T14:08:59+00:00",
        "comment_author": "greysonlalonde",
        "comment_body": "Makes sense to me!\r\n\r\nCould be worth looking into [RestrictedPython](https://github.com/zopefoundation/RestrictedPython) for easy sandboxing, I've played with it before but haven't dug into the project enough to recommend it",
        "pr_file_module": null
      },
      {
        "comment_id": "2054268407",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2636,
        "pr_file": "src/crewai/tasks/guardrail_task.py",
        "discussion_id": "2053356170",
        "commented_code": "@@ -0,0 +1,165 @@\n+from typing import Any, Tuple\n+\n+from crewai.llm import LLM\n+from crewai.task import Task\n+from crewai.tasks.task_output import TaskOutput\n+from crewai.utilities.printer import Printer\n+\n+\n+class GuardrailTask:\n+    \"\"\"A task that validates the output of another task using generated Python code.\n+\n+    This class generates and executes Python code to validate task outputs based on\n+    specified criteria. It uses an LLM to generate the validation code and provides\n+    safety guardrails for code execution. The code is executed in a Docker container\n+    if available, otherwise it is executed in the current environment.\n+\n+    Args:\n+        description (str): The description of the validation criteria.\n+        task (Task, optional): The task whose output needs validation.\n+        llm (LLM, optional): The language model to use for code generation.\n+        additional_instructions (str, optional): Additional instructions for the guardrail task.\n+\n+    Raises:\n+        ValueError: If no valid LLM is provided.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        description: str,\n+        task: Task | None = None,\n+        llm: LLM | None = None,\n+        additional_instructions: str = \"\",\n+    ):\n+        self.description = description\n+\n+        fallback_llm: LLM | None = (\n+            task.agent.llm\n+            if task is not None\n+            and hasattr(task, \"agent\")\n+            and task.agent is not None\n+            and hasattr(task.agent, \"llm\")\n+            else None\n+        )\n+        self.llm: LLM | None = llm or fallback_llm\n+\n+        self.additional_instructions = additional_instructions\n+\n+    @property\n+    def system_instructions(self) -> str:\n+        \"\"\"System instructions for the LLM code generation.\n+\n+        Returns:\n+            str: Complete system instructions including security constraints.\n+        \"\"\"\n+        security_instructions = (\n+            \"- DO NOT wrap the output in markdown or use triple backticks. Return only raw Python code.\"\n+            \"- DO NOT use `exec`, `eval`, `compile`, `open`, `os`, `subprocess`, `socket`, `shutil`, or any other system-level modules.\\n\"\n+            \"- Your code must not perform any file I/O, shell access, or dynamic code execution.\"\n+        )\n+        return (\n+            \"You are a expert Python developer\"\n+            \"You **must strictly** follow the task description, use the provided raw output as the input in your code. \"\n+            \"Your code must:\\n\"\n+            \"- Return results with: print((True, data)) on success, or print((False, 'very detailed error message')) on failure. Make sure the final output is beign assined to 'result' variable.\\n\"\n+            \"- Use the literal string of the task output (already included in your input) if needed.\\n\"\n+            \"- Generate the code **following strictly** the task description.\\n\"\n+            \"- Be valid Python 3 \u2014 executable as-is.\\n\"\n+            f\"{security_instructions}\\n\"\n+            \"Additional instructions (do not override the previous instructions):\\n\"\n+            f\"{self.additional_instructions}\"\n+        )\n+\n+    def user_instructions(self, task_output: TaskOutput) -> str:\n+        \"\"\"Generates user instructions for the LLM code generation.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            str: Instructions for generating validation code.\n+        \"\"\"\n+        return (\n+            \"Based on the task description below, generate Python 3 code that validates the task output. \\n\"\n+            \"Task description:\\n\"\n+            f\"{self.description}\\n\"\n+            \"Here is the raw output from the task: \\n\"\n+            f\"'{task_output.raw}' \\n\"\n+            \"Use this exact string literal inside your generated code (do not reference variables like task_output.raw).\"\n+            \"Now generate Python code that follows the instructions above.\"\n+        )\n+\n+    def generate_code(self, task_output: TaskOutput) -> str:\n+        \"\"\"Generates Python code for validating the task output.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            str: Generated Python code for validation.\n+        \"\"\"\n+        if self.llm is None:\n+            raise ValueError(\"Provide a valid LLM to the GuardrailTask\")\n+\n+        response = self.llm.call(\n+            messages=[\n+                {\n+                    \"role\": \"system\",\n+                    \"content\": self.system_instructions,\n+                },\n+                {\n+                    \"role\": \"user\",\n+                    \"content\": self.user_instructions(task_output=task_output),\n+                },\n+            ]\n+        )\n+\n+        printer = Printer()\n+        printer.print(\n+            content=f\"The following code was generated for the guardrail task:\\n{response}\\n\",\n+            color=\"cyan\",\n+        )\n+        return response\n+\n+    def __call__(self, task_output: TaskOutput) -> Tuple[bool, Any]:\n+        \"\"\"Executes the validation code on the task output.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            Tuple[bool, Any]: A tuple containing:\n+                - bool: True if validation passed, False otherwise\n+                - Any: The validation result or error message\n+        \"\"\"\n+        import ast\n+\n+        from crewai_tools import CodeInterpreterTool\n+\n+        code = self.generate_code(task_output)\n+\n+        unsafe_mode = not self.check_docker_available()",
        "comment_created_at": "2025-04-22T14:40:18+00:00",
        "comment_author": "lucasgomide",
        "comment_body": "exactly what I was planning to use haha",
        "pr_file_module": null
      },
      {
        "comment_id": "2056568781",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2636,
        "pr_file": "src/crewai/tasks/guardrail_task.py",
        "discussion_id": "2053356170",
        "commented_code": "@@ -0,0 +1,165 @@\n+from typing import Any, Tuple\n+\n+from crewai.llm import LLM\n+from crewai.task import Task\n+from crewai.tasks.task_output import TaskOutput\n+from crewai.utilities.printer import Printer\n+\n+\n+class GuardrailTask:\n+    \"\"\"A task that validates the output of another task using generated Python code.\n+\n+    This class generates and executes Python code to validate task outputs based on\n+    specified criteria. It uses an LLM to generate the validation code and provides\n+    safety guardrails for code execution. The code is executed in a Docker container\n+    if available, otherwise it is executed in the current environment.\n+\n+    Args:\n+        description (str): The description of the validation criteria.\n+        task (Task, optional): The task whose output needs validation.\n+        llm (LLM, optional): The language model to use for code generation.\n+        additional_instructions (str, optional): Additional instructions for the guardrail task.\n+\n+    Raises:\n+        ValueError: If no valid LLM is provided.\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        description: str,\n+        task: Task | None = None,\n+        llm: LLM | None = None,\n+        additional_instructions: str = \"\",\n+    ):\n+        self.description = description\n+\n+        fallback_llm: LLM | None = (\n+            task.agent.llm\n+            if task is not None\n+            and hasattr(task, \"agent\")\n+            and task.agent is not None\n+            and hasattr(task.agent, \"llm\")\n+            else None\n+        )\n+        self.llm: LLM | None = llm or fallback_llm\n+\n+        self.additional_instructions = additional_instructions\n+\n+    @property\n+    def system_instructions(self) -> str:\n+        \"\"\"System instructions for the LLM code generation.\n+\n+        Returns:\n+            str: Complete system instructions including security constraints.\n+        \"\"\"\n+        security_instructions = (\n+            \"- DO NOT wrap the output in markdown or use triple backticks. Return only raw Python code.\"\n+            \"- DO NOT use `exec`, `eval`, `compile`, `open`, `os`, `subprocess`, `socket`, `shutil`, or any other system-level modules.\\n\"\n+            \"- Your code must not perform any file I/O, shell access, or dynamic code execution.\"\n+        )\n+        return (\n+            \"You are a expert Python developer\"\n+            \"You **must strictly** follow the task description, use the provided raw output as the input in your code. \"\n+            \"Your code must:\\n\"\n+            \"- Return results with: print((True, data)) on success, or print((False, 'very detailed error message')) on failure. Make sure the final output is beign assined to 'result' variable.\\n\"\n+            \"- Use the literal string of the task output (already included in your input) if needed.\\n\"\n+            \"- Generate the code **following strictly** the task description.\\n\"\n+            \"- Be valid Python 3 \u2014 executable as-is.\\n\"\n+            f\"{security_instructions}\\n\"\n+            \"Additional instructions (do not override the previous instructions):\\n\"\n+            f\"{self.additional_instructions}\"\n+        )\n+\n+    def user_instructions(self, task_output: TaskOutput) -> str:\n+        \"\"\"Generates user instructions for the LLM code generation.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            str: Instructions for generating validation code.\n+        \"\"\"\n+        return (\n+            \"Based on the task description below, generate Python 3 code that validates the task output. \\n\"\n+            \"Task description:\\n\"\n+            f\"{self.description}\\n\"\n+            \"Here is the raw output from the task: \\n\"\n+            f\"'{task_output.raw}' \\n\"\n+            \"Use this exact string literal inside your generated code (do not reference variables like task_output.raw).\"\n+            \"Now generate Python code that follows the instructions above.\"\n+        )\n+\n+    def generate_code(self, task_output: TaskOutput) -> str:\n+        \"\"\"Generates Python code for validating the task output.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            str: Generated Python code for validation.\n+        \"\"\"\n+        if self.llm is None:\n+            raise ValueError(\"Provide a valid LLM to the GuardrailTask\")\n+\n+        response = self.llm.call(\n+            messages=[\n+                {\n+                    \"role\": \"system\",\n+                    \"content\": self.system_instructions,\n+                },\n+                {\n+                    \"role\": \"user\",\n+                    \"content\": self.user_instructions(task_output=task_output),\n+                },\n+            ]\n+        )\n+\n+        printer = Printer()\n+        printer.print(\n+            content=f\"The following code was generated for the guardrail task:\\n{response}\\n\",\n+            color=\"cyan\",\n+        )\n+        return response\n+\n+    def __call__(self, task_output: TaskOutput) -> Tuple[bool, Any]:\n+        \"\"\"Executes the validation code on the task output.\n+\n+        Args:\n+            task_output (TaskOutput): The output to be validated.\n+\n+        Returns:\n+            Tuple[bool, Any]: A tuple containing:\n+                - bool: True if validation passed, False otherwise\n+                - Any: The validation result or error message\n+        \"\"\"\n+        import ast\n+\n+        from crewai_tools import CodeInterpreterTool\n+\n+        code = self.generate_code(task_output)\n+\n+        unsafe_mode = not self.check_docker_available()",
        "comment_created_at": "2025-04-23T17:32:31+00:00",
        "comment_author": "lucasgomide",
        "comment_body": "[here is](https://github.com/crewAIInc/crewAI-tools/pull/281)",
        "pr_file_module": null
      }
    ]
  }
]