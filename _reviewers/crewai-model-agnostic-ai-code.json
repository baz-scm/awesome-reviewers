[
  {
    "discussion_id": "2135661254",
    "pr_number": 2852,
    "pr_file": "src/crewai/agents/agent_adapters/foundry_agents/foundry_adapter.py",
    "created_at": "2025-06-09T12:49:19+00:00",
    "commented_code": "+from typing import Any, List, Optional\n+import os\n+import time\n+import json\n+from pydantic import Field, PrivateAttr\n+\n+from crewai.agents.agent_adapters.base_agent_adapter import BaseAgentAdapter\n+from crewai.agents.agent_adapters.foundry_agents.structured_output_converter import (\n+    FoundryConverterAdapter,\n+)\n+from crewai.agents.agent_builder.base_agent import BaseAgent\n+from crewai.tools import BaseTool\n+from crewai.tools.agent_tools.agent_tools import AgentTools\n+from crewai.utilities import Logger\n+from crewai.utilities.events import crewai_event_bus\n+from crewai.utilities.events.agent_events import (\n+    AgentExecutionCompletedEvent,\n+    AgentExecutionErrorEvent,\n+    AgentExecutionStartedEvent,\n+)\n+\n+try:\n+    from azure.ai.projects import AIProjectClient as FoundryClient\n+    from azure.ai.projects.models import MessageTextContent\n+    from azure.identity import DefaultAzureCredential\n+    from azure.ai.projects.models import FunctionTool\n+\n+\n+    from .foundry_agent_tool_adapter import FoundryAgentToolAdapter\n+\n+    FOUNDRY_AVAILABLE = True\n+except ImportError:\n+    FOUNDRY_AVAILABLE = False\n+\n+\n+class FoundryAgentAdapter(BaseAgentAdapter):\n+    \"\"\"Adapter for Foundry Assistants\"\"\"\n+\n+    model_config = {\"arbitrary_types_allowed\": True}\n+\n+    _foundry_client: \"FoundryClient\" = PrivateAttr()\n+    _logger: Logger = PrivateAttr(default_factory=lambda: Logger())\n+    _active_thread_id: Optional[str] = PrivateAttr(default=None)\n+    function_calling_llm: Any = Field(default=None)\n+    step_callback: Any = Field(default=None)\n+    _tool_adapter: \"FoundryAgentToolAdapter\" = PrivateAttr()\n+    _converter_adapter: FoundryConverterAdapter = PrivateAttr()\n+    _converted_tools: Optional[FunctionTool] = PrivateAttr(default=None)\n+\n+    def __init__(\n+        self,\n+        model: str = \"gpt-4.1-mini\",\n+        tools: Optional[List[BaseTool]] = None,\n+        agent_config: Optional[dict] = None,\n+        **kwargs,\n+    ):\n+        if not FOUNDRY_AVAILABLE:\n+            raise ImportError(\n+                \"Foundry Agent Dependencies are not installed. Please install it using `uv pip install azure-ai-projects azure-identity`\"\n+            )\n+        else:\n+            role = kwargs.pop(\"role\", None)\n+            goal = kwargs.pop(\"goal\", None)\n+            backstory = kwargs.pop(\"backstory\", None)\n+            super().__init__(\n+                role=role,\n+                goal=goal,\n+                backstory=backstory,\n+                tools=tools,\n+                agent_config=agent_config,\n+                **kwargs,\n+            )\n+            self._tool_adapter = FoundryAgentToolAdapter(tools=tools)\n+            self.llm = model",
    "repo_full_name": "crewAIInc/crewAI",
    "discussion_comments": [
      {
        "comment_id": "2135661254",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2852,
        "pr_file": "src/crewai/agents/agent_adapters/foundry_agents/foundry_adapter.py",
        "discussion_id": "2135661254",
        "commented_code": "@@ -0,0 +1,184 @@\n+from typing import Any, List, Optional\n+import os\n+import time\n+import json\n+from pydantic import Field, PrivateAttr\n+\n+from crewai.agents.agent_adapters.base_agent_adapter import BaseAgentAdapter\n+from crewai.agents.agent_adapters.foundry_agents.structured_output_converter import (\n+    FoundryConverterAdapter,\n+)\n+from crewai.agents.agent_builder.base_agent import BaseAgent\n+from crewai.tools import BaseTool\n+from crewai.tools.agent_tools.agent_tools import AgentTools\n+from crewai.utilities import Logger\n+from crewai.utilities.events import crewai_event_bus\n+from crewai.utilities.events.agent_events import (\n+    AgentExecutionCompletedEvent,\n+    AgentExecutionErrorEvent,\n+    AgentExecutionStartedEvent,\n+)\n+\n+try:\n+    from azure.ai.projects import AIProjectClient as FoundryClient\n+    from azure.ai.projects.models import MessageTextContent\n+    from azure.identity import DefaultAzureCredential\n+    from azure.ai.projects.models import FunctionTool\n+\n+\n+    from .foundry_agent_tool_adapter import FoundryAgentToolAdapter\n+\n+    FOUNDRY_AVAILABLE = True\n+except ImportError:\n+    FOUNDRY_AVAILABLE = False\n+\n+\n+class FoundryAgentAdapter(BaseAgentAdapter):\n+    \"\"\"Adapter for Foundry Assistants\"\"\"\n+\n+    model_config = {\"arbitrary_types_allowed\": True}\n+\n+    _foundry_client: \"FoundryClient\" = PrivateAttr()\n+    _logger: Logger = PrivateAttr(default_factory=lambda: Logger())\n+    _active_thread_id: Optional[str] = PrivateAttr(default=None)\n+    function_calling_llm: Any = Field(default=None)\n+    step_callback: Any = Field(default=None)\n+    _tool_adapter: \"FoundryAgentToolAdapter\" = PrivateAttr()\n+    _converter_adapter: FoundryConverterAdapter = PrivateAttr()\n+    _converted_tools: Optional[FunctionTool] = PrivateAttr(default=None)\n+\n+    def __init__(\n+        self,\n+        model: str = \"gpt-4.1-mini\",\n+        tools: Optional[List[BaseTool]] = None,\n+        agent_config: Optional[dict] = None,\n+        **kwargs,\n+    ):\n+        if not FOUNDRY_AVAILABLE:\n+            raise ImportError(\n+                \"Foundry Agent Dependencies are not installed. Please install it using `uv pip install azure-ai-projects azure-identity`\"\n+            )\n+        else:\n+            role = kwargs.pop(\"role\", None)\n+            goal = kwargs.pop(\"goal\", None)\n+            backstory = kwargs.pop(\"backstory\", None)\n+            super().__init__(\n+                role=role,\n+                goal=goal,\n+                backstory=backstory,\n+                tools=tools,\n+                agent_config=agent_config,\n+                **kwargs,\n+            )\n+            self._tool_adapter = FoundryAgentToolAdapter(tools=tools)\n+            self.llm = model",
        "comment_created_at": "2025-06-09T12:49:19+00:00",
        "comment_author": "lucasgomide",
        "comment_body": "Following the `langgraph_adapter.py` as a reference, you could define the LLM during initialization like this: llm = llm or self.model",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2040075572",
    "pr_number": 2580,
    "pr_file": "src/crewai/utilities/converter.py",
    "created_at": "2025-04-11T18:16:02+00:00",
    "commented_code": "if self.llm.supports_function_calling():\n                 result = self._create_instructor().to_pydantic()\n             else:\n-                response = self.llm.call(\n-                    [\n-                        {\"role\": \"system\", \"content\": self.instructions},\n-                        {\"role\": \"user\", \"content\": self.text},\n-                    ]\n-                )\n+                if self.llm._is_mistral_model():\n+                    # Mistral models require a different approach\n+                    response = self.llm.call(\n+                        [\n+                            {\"role\": \"user\", \"content\": self.instructions + \"/n\" + self.text}\n+                        ]\n+                    )",
    "repo_full_name": "crewAIInc/crewAI",
    "discussion_comments": [
      {
        "comment_id": "2040075572",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2580,
        "pr_file": "src/crewai/utilities/converter.py",
        "discussion_id": "2040075572",
        "commented_code": "@@ -26,12 +26,20 @@ def to_pydantic(self, current_attempt=1) -> BaseModel:\n             if self.llm.supports_function_calling():\n                 result = self._create_instructor().to_pydantic()\n             else:\n-                response = self.llm.call(\n-                    [\n-                        {\"role\": \"system\", \"content\": self.instructions},\n-                        {\"role\": \"user\", \"content\": self.text},\n-                    ]\n-                )\n+                if self.llm._is_mistral_model():\n+                    # Mistral models require a different approach\n+                    response = self.llm.call(\n+                        [\n+                            {\"role\": \"user\", \"content\": self.instructions + \"/n\" + self.text}\n+                        ]\n+                    )",
        "comment_created_at": "2025-04-11T18:16:02+00:00",
        "comment_author": "lucasgomide",
        "comment_body": "since we are converting all system message to assistant, do you need to touch at this point?\r\ndo you have any docs reference about that?",
        "pr_file_module": null
      },
      {
        "comment_id": "2040121347",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2580,
        "pr_file": "src/crewai/utilities/converter.py",
        "discussion_id": "2040075572",
        "commented_code": "@@ -26,12 +26,20 @@ def to_pydantic(self, current_attempt=1) -> BaseModel:\n             if self.llm.supports_function_calling():\n                 result = self._create_instructor().to_pydantic()\n             else:\n-                response = self.llm.call(\n-                    [\n-                        {\"role\": \"system\", \"content\": self.instructions},\n-                        {\"role\": \"user\", \"content\": self.text},\n-                    ]\n-                )\n+                if self.llm._is_mistral_model():\n+                    # Mistral models require a different approach\n+                    response = self.llm.call(\n+                        [\n+                            {\"role\": \"user\", \"content\": self.instructions + \"/n\" + self.text}\n+                        ]\n+                    )",
        "comment_created_at": "2025-04-11T18:49:56+00:00",
        "comment_author": "Vidit-Ostwal",
        "comment_body": "Exactly, this is need actually, if we don't do this. \r\nwhat will happen is the first role in the message would be `system` and that would be converted to `assistant`, by the later logic.\r\nThe mistral wants a `user` role, as the first message role.\r\n\r\nCheck this out.\r\nhttps://docs.mistral.ai/capabilities/guardrailing/#conversational-endpoint",
        "pr_file_module": null
      },
      {
        "comment_id": "2040136055",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 2580,
        "pr_file": "src/crewai/utilities/converter.py",
        "discussion_id": "2040075572",
        "commented_code": "@@ -26,12 +26,20 @@ def to_pydantic(self, current_attempt=1) -> BaseModel:\n             if self.llm.supports_function_calling():\n                 result = self._create_instructor().to_pydantic()\n             else:\n-                response = self.llm.call(\n-                    [\n-                        {\"role\": \"system\", \"content\": self.instructions},\n-                        {\"role\": \"user\", \"content\": self.text},\n-                    ]\n-                )\n+                if self.llm._is_mistral_model():\n+                    # Mistral models require a different approach\n+                    response = self.llm.call(\n+                        [\n+                            {\"role\": \"user\", \"content\": self.instructions + \"/n\" + self.text}\n+                        ]\n+                    )",
        "comment_created_at": "2025-04-11T18:58:02+00:00",
        "comment_author": "Vidit-Ostwal",
        "comment_body": "the system to assistant conversion, is just an additional check I am making at this moment.\r\n\r\nI think I should remove that check. \r\nIt should better fail, so that we can come back and fix, let me know what you think.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1656376280",
    "pr_number": 785,
    "pr_file": "src/crewai/task.py",
    "created_at": "2024-06-27T04:08:47+00:00",
    "commented_code": "agent=agent,\n                 context=context,\n                 tools=tools,\n+                rci = self.rci, # adding rci in function call\n+                rci_depth=self.rci_depth\n             )\n             return result\n \n-    def _execute(self, agent, task, context, tools):\n+    # Create new methods that will verify the output of the agent using RCI - Recursive Criticism and Iteration\n+    def critique(self, agent, task, output, llm):\n+\n+        critic_prompt_template = \"\"\"\n+        {agent_backstory}. + You are a great critic who has keen eyes for errors. \n+        A task is assigned to a LLM model which provides an output based on the task description. \n+        Identify errors in the output provided by the model, if any. \n+        Strictly avoid grammatical rephrasing or paraphrasing, point out only the logical or factual inaccuracies. \n+        Do not reproduce your own version of the output, just provide only the critique.\n+        I repeat do not give your own rewritten version of the output. Only point out the errors.\n+\n+        Provided Task: {task_description}\n+        Output: {output}\n+        \"\"\"\n+\n+        critic_prompt = PromptTemplate(\n+            input_variables=[\"task_description\", \"result\"],\n+            template=critic_prompt_template\n+        )\n+\n+        critic_chain = critic_prompt | llm | StrOutputParser()\n+        \n+        critic_response = critic_chain.invoke({\n+            \"agent_backstory\": agent.backstory,\n+            \"task_description\": task.description,\n+            \"output\": output\n+        })\n+\n+        print(\"Critic Response:\n\", critic_response)\n+\n+        return critic_response\n+\n+    \n+    def validate(self, task, critique, output, llm):\n+\n+        validate_prompt_template = \"\"\"\n+        You are a context analyzer and your job is to identify if the critique to a task provided and its corresponding output, states \"significant changes are required in the output\" or synonymous phrases of that significance order.\n+        If there are significant changes stated in the critique, without any preamble or additional explanation, just print \"True\" else just print \"False\". \n+        Avoid minor inaccuracies or minor adjustments. \n+        If the critique says the overall output matches the task description with minor changes required, print 'False'.\n+        Unless and until the output change provided by the critique is tangential, print 'False', if it is tagential print 'True'. \n+        Make sure the output provided by you should be only one word that is either 'True' or 'False'.\n+\n+        Provided Task: {task_description}\n+        Output: {output}\n+        Critique: {critique}\n+        \"\"\"\n+\n+        validate_prompt = PromptTemplate(\n+            input_variables=[\"task_description\", \"output\", \"critique\"],\n+            template=validate_prompt_template\n+        )\n+\n+        validate_chain = validate_prompt | llm | StrOutputParser()\n+\n+        validate_response = validate_chain.invoke({\n+            \"task_description\": task.description,\n+            \"output\": output,\n+            \"critique\": critique\n+        })\n+\n+        print(\"Validate Response:\n\", validate_response)\n+        return validate_response\n+    \n+    def improve(self, task, output, critique, llm):\n+    \n+        improve_prompt_template = \"\"\"\n+        You are a helpful assistant who can skillfully analyze the critique provided to a task based on its output. \n+        Your job is completely understand the task, its corresponding output and the critique provided and rewrite the output based on the critique. \n+        Avoid writing \"Here is my modificication\" or any synoymous phrases at the start or at the end.\n+        No need for premable or explanations from your side, just rewrite the output based on the critique. \n+        Make sure you maintain the format if mentioned in the task description.\n+\n+        Provided Task: {task_description}\n+        Output: {output}\n+        Critique: {critique}\n+        \"\"\"\n+\n+        improve_prompt = PromptTemplate(\n+            input_variables=[\"task_description\", \"output\", \"critique\"],\n+            template=improve_prompt_template\n+        )\n+\n+        improve_chain = improve_prompt | llm | StrOutputParser()\n+        \n+        improve_response = improve_chain.invoke({\n+            \"task_description\": task.description,\n+            \"output\": output,\n+            \"critique\": critique\n+        })\n+\n+        print(\"Improvised Response:\n\", improve_response)\n+\n+        return improve_response\n+\n+    def _execute(self, agent, task, context, tools, rci=True, rci_depth=1):\n         result = agent.execute_task(\n             task=task,\n             context=context,\n             tools=tools,\n         )\n \n+        # To perform RCI if rci is set to True\n+        llm = ChatOllama(model=\"llama3\")",
    "repo_full_name": "crewAIInc/crewAI",
    "discussion_comments": [
      {
        "comment_id": "1656376280",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 785,
        "pr_file": "src/crewai/task.py",
        "discussion_id": "1656376280",
        "commented_code": "@@ -189,16 +205,126 @@ def execute(  # type: ignore # Missing return statement\n                 agent=agent,\n                 context=context,\n                 tools=tools,\n+                rci = self.rci, # adding rci in function call\n+                rci_depth=self.rci_depth\n             )\n             return result\n \n-    def _execute(self, agent, task, context, tools):\n+    # Create new methods that will verify the output of the agent using RCI - Recursive Criticism and Iteration\n+    def critique(self, agent, task, output, llm):\n+\n+        critic_prompt_template = \"\"\"\n+        {agent_backstory}. + You are a great critic who has keen eyes for errors. \n+        A task is assigned to a LLM model which provides an output based on the task description. \n+        Identify errors in the output provided by the model, if any. \n+        Strictly avoid grammatical rephrasing or paraphrasing, point out only the logical or factual inaccuracies. \n+        Do not reproduce your own version of the output, just provide only the critique.\n+        I repeat do not give your own rewritten version of the output. Only point out the errors.\n+\n+        Provided Task: {task_description}\n+        Output: {output}\n+        \"\"\"\n+\n+        critic_prompt = PromptTemplate(\n+            input_variables=[\"task_description\", \"result\"],\n+            template=critic_prompt_template\n+        )\n+\n+        critic_chain = critic_prompt | llm | StrOutputParser()\n+        \n+        critic_response = critic_chain.invoke({\n+            \"agent_backstory\": agent.backstory,\n+            \"task_description\": task.description,\n+            \"output\": output\n+        })\n+\n+        print(\"Critic Response:\\n\", critic_response)\n+\n+        return critic_response\n+\n+    \n+    def validate(self, task, critique, output, llm):\n+\n+        validate_prompt_template = \"\"\"\n+        You are a context analyzer and your job is to identify if the critique to a task provided and its corresponding output, states \"significant changes are required in the output\" or synonymous phrases of that significance order.\n+        If there are significant changes stated in the critique, without any preamble or additional explanation, just print \"True\" else just print \"False\". \n+        Avoid minor inaccuracies or minor adjustments. \n+        If the critique says the overall output matches the task description with minor changes required, print 'False'.\n+        Unless and until the output change provided by the critique is tangential, print 'False', if it is tagential print 'True'. \n+        Make sure the output provided by you should be only one word that is either 'True' or 'False'.\n+\n+        Provided Task: {task_description}\n+        Output: {output}\n+        Critique: {critique}\n+        \"\"\"\n+\n+        validate_prompt = PromptTemplate(\n+            input_variables=[\"task_description\", \"output\", \"critique\"],\n+            template=validate_prompt_template\n+        )\n+\n+        validate_chain = validate_prompt | llm | StrOutputParser()\n+\n+        validate_response = validate_chain.invoke({\n+            \"task_description\": task.description,\n+            \"output\": output,\n+            \"critique\": critique\n+        })\n+\n+        print(\"Validate Response:\\n\", validate_response)\n+        return validate_response\n+    \n+    def improve(self, task, output, critique, llm):\n+    \n+        improve_prompt_template = \"\"\"\n+        You are a helpful assistant who can skillfully analyze the critique provided to a task based on its output. \n+        Your job is completely understand the task, its corresponding output and the critique provided and rewrite the output based on the critique. \n+        Avoid writing \"Here is my modificication\" or any synoymous phrases at the start or at the end.\n+        No need for premable or explanations from your side, just rewrite the output based on the critique. \n+        Make sure you maintain the format if mentioned in the task description.\n+\n+        Provided Task: {task_description}\n+        Output: {output}\n+        Critique: {critique}\n+        \"\"\"\n+\n+        improve_prompt = PromptTemplate(\n+            input_variables=[\"task_description\", \"output\", \"critique\"],\n+            template=improve_prompt_template\n+        )\n+\n+        improve_chain = improve_prompt | llm | StrOutputParser()\n+        \n+        improve_response = improve_chain.invoke({\n+            \"task_description\": task.description,\n+            \"output\": output,\n+            \"critique\": critique\n+        })\n+\n+        print(\"Improvised Response:\\n\", improve_response)\n+\n+        return improve_response\n+\n+    def _execute(self, agent, task, context, tools, rci=True, rci_depth=1):\n         result = agent.execute_task(\n             task=task,\n             context=context,\n             tools=tools,\n         )\n \n+        # To perform RCI if rci is set to True\n+        llm = ChatOllama(model=\"llama3\")",
        "comment_created_at": "2024-06-27T04:08:47+00:00",
        "comment_author": "mbarnathan",
        "comment_body": "I'm really glad to see this capability coming to CrewAI! This will probably need to be more generic; I doubt a hardcoded dependency on Ollama will get approved since the library doesn't have one anywhere else.",
        "pr_file_module": null
      },
      {
        "comment_id": "1656393788",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 785,
        "pr_file": "src/crewai/task.py",
        "discussion_id": "1656376280",
        "commented_code": "@@ -189,16 +205,126 @@ def execute(  # type: ignore # Missing return statement\n                 agent=agent,\n                 context=context,\n                 tools=tools,\n+                rci = self.rci, # adding rci in function call\n+                rci_depth=self.rci_depth\n             )\n             return result\n \n-    def _execute(self, agent, task, context, tools):\n+    # Create new methods that will verify the output of the agent using RCI - Recursive Criticism and Iteration\n+    def critique(self, agent, task, output, llm):\n+\n+        critic_prompt_template = \"\"\"\n+        {agent_backstory}. + You are a great critic who has keen eyes for errors. \n+        A task is assigned to a LLM model which provides an output based on the task description. \n+        Identify errors in the output provided by the model, if any. \n+        Strictly avoid grammatical rephrasing or paraphrasing, point out only the logical or factual inaccuracies. \n+        Do not reproduce your own version of the output, just provide only the critique.\n+        I repeat do not give your own rewritten version of the output. Only point out the errors.\n+\n+        Provided Task: {task_description}\n+        Output: {output}\n+        \"\"\"\n+\n+        critic_prompt = PromptTemplate(\n+            input_variables=[\"task_description\", \"result\"],\n+            template=critic_prompt_template\n+        )\n+\n+        critic_chain = critic_prompt | llm | StrOutputParser()\n+        \n+        critic_response = critic_chain.invoke({\n+            \"agent_backstory\": agent.backstory,\n+            \"task_description\": task.description,\n+            \"output\": output\n+        })\n+\n+        print(\"Critic Response:\\n\", critic_response)\n+\n+        return critic_response\n+\n+    \n+    def validate(self, task, critique, output, llm):\n+\n+        validate_prompt_template = \"\"\"\n+        You are a context analyzer and your job is to identify if the critique to a task provided and its corresponding output, states \"significant changes are required in the output\" or synonymous phrases of that significance order.\n+        If there are significant changes stated in the critique, without any preamble or additional explanation, just print \"True\" else just print \"False\". \n+        Avoid minor inaccuracies or minor adjustments. \n+        If the critique says the overall output matches the task description with minor changes required, print 'False'.\n+        Unless and until the output change provided by the critique is tangential, print 'False', if it is tagential print 'True'. \n+        Make sure the output provided by you should be only one word that is either 'True' or 'False'.\n+\n+        Provided Task: {task_description}\n+        Output: {output}\n+        Critique: {critique}\n+        \"\"\"\n+\n+        validate_prompt = PromptTemplate(\n+            input_variables=[\"task_description\", \"output\", \"critique\"],\n+            template=validate_prompt_template\n+        )\n+\n+        validate_chain = validate_prompt | llm | StrOutputParser()\n+\n+        validate_response = validate_chain.invoke({\n+            \"task_description\": task.description,\n+            \"output\": output,\n+            \"critique\": critique\n+        })\n+\n+        print(\"Validate Response:\\n\", validate_response)\n+        return validate_response\n+    \n+    def improve(self, task, output, critique, llm):\n+    \n+        improve_prompt_template = \"\"\"\n+        You are a helpful assistant who can skillfully analyze the critique provided to a task based on its output. \n+        Your job is completely understand the task, its corresponding output and the critique provided and rewrite the output based on the critique. \n+        Avoid writing \"Here is my modificication\" or any synoymous phrases at the start or at the end.\n+        No need for premable or explanations from your side, just rewrite the output based on the critique. \n+        Make sure you maintain the format if mentioned in the task description.\n+\n+        Provided Task: {task_description}\n+        Output: {output}\n+        Critique: {critique}\n+        \"\"\"\n+\n+        improve_prompt = PromptTemplate(\n+            input_variables=[\"task_description\", \"output\", \"critique\"],\n+            template=improve_prompt_template\n+        )\n+\n+        improve_chain = improve_prompt | llm | StrOutputParser()\n+        \n+        improve_response = improve_chain.invoke({\n+            \"task_description\": task.description,\n+            \"output\": output,\n+            \"critique\": critique\n+        })\n+\n+        print(\"Improvised Response:\\n\", improve_response)\n+\n+        return improve_response\n+\n+    def _execute(self, agent, task, context, tools, rci=True, rci_depth=1):\n         result = agent.execute_task(\n             task=task,\n             context=context,\n             tools=tools,\n         )\n \n+        # To perform RCI if rci is set to True\n+        llm = ChatOllama(model=\"llama3\")",
        "comment_created_at": "2024-06-27T04:31:01+00:00",
        "comment_author": "chandrakanth137",
        "comment_body": "I will try making it more generic. I only had access to local LLMs, so that piece of code ended up there. I will modify it to use the user preferred LLM and make the code more generic. Thanks for the review !",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1842981225",
    "pr_number": 1567,
    "pr_file": "src/crewai/knowledge/embedder/ollama.py",
    "created_at": "2024-11-14T22:49:20+00:00",
    "commented_code": "+import os",
    "repo_full_name": "crewAIInc/crewAI",
    "discussion_comments": [
      {
        "comment_id": "1842981225",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 1567,
        "pr_file": "src/crewai/knowledge/embedder/ollama.py",
        "discussion_id": "1842981225",
        "commented_code": "@@ -0,0 +1,82 @@\n+import os",
        "comment_created_at": "2024-11-14T22:49:20+00:00",
        "comment_author": "lorenzejay",
        "comment_body": "i'd drop the ollama version. support openai, then let anyone bring their own embedder function (super easy) then have the knowledge_config setup like embedder_config setup for our rag storage",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1656531929",
    "pr_number": 776,
    "pr_file": "src/crewai/agents/agent_builder/base_agent.py",
    "created_at": "2024-06-27T06:29:30+00:00",
    "commented_code": "+from copy import deepcopy\n+import uuid\n+from typing import Any, Dict, List, Optional\n+from abc import ABC, abstractmethod\n+from pydantic import (\n+    UUID4,\n+    BaseModel,\n+    Field,\n+    InstanceOf,\n+    field_validator,\n+    model_validator,\n+    ConfigDict,\n+    PrivateAttr,\n+)\n+from pydantic_core import PydanticCustomError\n+\n+from crewai.utilities import I18N, RPMController, Logger\n+from crewai.agents import CacheHandler, ToolsHandler\n+from crewai.utilities.token_counter_callback import TokenProcess\n+\n+\n+class BaseAgent(ABC, BaseModel):\n+    \"\"\"Abstract Base Class for all third party agents compatible with CrewAI.\n+\n+    Attributes:\n+        id (UUID4): Unique identifier for the agent.\n+        role (str): Role of the agent.\n+        goal (str): Objective of the agent.\n+        backstory (str): Backstory of the agent.\n+        cache (bool): Whether the agent should use a cache for tool usage.\n+        config (Optional[Dict[str, Any]]): Configuration for the agent.\n+        verbose (bool): Verbose mode for the Agent Execution.\n+        max_rpm (Optional[int]): Maximum number of requests per minute for the agent execution.\n+        allow_delegation (bool): Allow delegation of tasks to agents.\n+        tools (Optional[List[Any]]): Tools at the agent's disposal.\n+        max_iter (Optional[int]): Maximum iterations for an agent to execute a task.\n+        agent_executor (InstanceOf): An instance of the CrewAgentExecutor class.\n+        llm (Any): Language model that will run the agent.\n+        crew (Any): Crew to which the agent belongs.\n+        i18n (I18N): Internationalization settings.\n+        cache_handler (InstanceOf[CacheHandler]): An instance of the CacheHandler class.\n+        tools_handler (InstanceOf[ToolsHandler]): An instance of the ToolsHandler class.\n+\n+\n+    Methods:\n+        execute_task(task: Any, context: Optional[str] = None, tools: Optional[List[Any]] = None) -> str:\n+            Abstract method to execute a task.\n+        create_agent_executor(tools=None) -> None:\n+            Abstract method to create an agent executor.\n+        _parse_tools(tools: List[Any]) -> List[Any]:\n+            Abstract method to parse tools.\n+        get_delegation_tools(agents: List[\"BaseAgent\"]):\n+            Abstract method to set the agents task tools for handling delegation and question asking to other agents in crew.\n+        get_output_converter(llm, model, instructions):\n+            Abstract method to get the converter class for the agent to create json/pydantic outputs.\n+        interpolate_inputs(inputs: Dict[str, Any]) -> None:\n+            Interpolate inputs into the agent description and backstory.\n+        set_cache_handler(cache_handler: CacheHandler) -> None:\n+            Set the cache handler for the agent.\n+        increment_formatting_errors() -> None:\n+            Increment formatting errors.\n+        copy() -> \"BaseAgent\":\n+            Create a copy of the agent.\n+        set_rpm_controller(rpm_controller: RPMController) -> None:\n+            Set the rpm controller for the agent.\n+        set_private_attrs() -> \"BaseAgent\":\n+            Set private attributes.\n+    \"\"\"\n+\n+    __hash__ = object.__hash__  # type: ignore\n+    _logger: Logger = PrivateAttr()\n+    _rpm_controller: RPMController = PrivateAttr(default=None)\n+    _request_within_rpm_limit: Any = PrivateAttr(default=None)\n+    formatting_errors: int = 0\n+    model_config = ConfigDict(arbitrary_types_allowed=True)\n+    id: UUID4 = Field(default_factory=uuid.uuid4, frozen=True)\n+    role: str = Field(description=\"Role of the agent\")\n+    goal: str = Field(description=\"Objective of the agent\")\n+    backstory: str = Field(description=\"Backstory of the agent\")\n+    cache: bool = Field(\n+        default=True, description=\"Whether the agent should use a cache for tool usage.\"\n+    )\n+    config: Optional[Dict[str, Any]] = Field(\n+        description=\"Configuration for the agent\", default=None\n+    )\n+    verbose: bool = Field(\n+        default=False, description=\"Verbose mode for the Agent Execution\"\n+    )\n+    max_rpm: Optional[int] = Field(\n+        default=None,\n+        description=\"Maximum number of requests per minute for the agent execution to be respected.\",\n+    )\n+    allow_delegation: bool = Field(\n+        default=True, description=\"Allow delegation of tasks to agents\"\n+    )\n+    tools: Optional[List[Any]] = Field(\n+        default_factory=list, description=\"Tools at agents' disposal\"\n+    )\n+    max_iter: Optional[int] = Field(\n+        default=25, description=\"Maximum iterations for an agent to execute a task\"\n+    )\n+    agent_executor: InstanceOf = Field(\n+        default=None, description=\"An instance of the CrewAgentExecutor class.\"\n+    )\n+    llm: Any = Field(\n+        default=None, description=\"Language model that will run the agent.\"\n+    )\n+    crew: Any = Field(default=None, description=\"Crew to which the agent belongs.\")\n+    i18n: I18N = Field(default=I18N(), description=\"Internationalization settings.\")\n+    cache_handler: InstanceOf[CacheHandler] = Field(\n+        default=None, description=\"An instance of the CacheHandler class.\"\n+    )\n+    tools_handler: InstanceOf[ToolsHandler] = Field(\n+        default=None, description=\"An instance of the ToolsHandler class.\"\n+    )\n+\n+    _original_role: str | None = None\n+    _original_goal: str | None = None\n+    _original_backstory: str | None = None\n+    _token_process: TokenProcess = TokenProcess()\n+\n+    def __init__(__pydantic_self__, **data):\n+        config = data.pop(\"config\", {})\n+        super().__init__(**config, **data)\n+",
    "repo_full_name": "crewAIInc/crewAI",
    "discussion_comments": [
      {
        "comment_id": "1656531929",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 776,
        "pr_file": "src/crewai/agents/agent_builder/base_agent.py",
        "discussion_id": "1656531929",
        "commented_code": "@@ -0,0 +1,255 @@\n+from copy import deepcopy\n+import uuid\n+from typing import Any, Dict, List, Optional\n+from abc import ABC, abstractmethod\n+from pydantic import (\n+    UUID4,\n+    BaseModel,\n+    Field,\n+    InstanceOf,\n+    field_validator,\n+    model_validator,\n+    ConfigDict,\n+    PrivateAttr,\n+)\n+from pydantic_core import PydanticCustomError\n+\n+from crewai.utilities import I18N, RPMController, Logger\n+from crewai.agents import CacheHandler, ToolsHandler\n+from crewai.utilities.token_counter_callback import TokenProcess\n+\n+\n+class BaseAgent(ABC, BaseModel):\n+    \"\"\"Abstract Base Class for all third party agents compatible with CrewAI.\n+\n+    Attributes:\n+        id (UUID4): Unique identifier for the agent.\n+        role (str): Role of the agent.\n+        goal (str): Objective of the agent.\n+        backstory (str): Backstory of the agent.\n+        cache (bool): Whether the agent should use a cache for tool usage.\n+        config (Optional[Dict[str, Any]]): Configuration for the agent.\n+        verbose (bool): Verbose mode for the Agent Execution.\n+        max_rpm (Optional[int]): Maximum number of requests per minute for the agent execution.\n+        allow_delegation (bool): Allow delegation of tasks to agents.\n+        tools (Optional[List[Any]]): Tools at the agent's disposal.\n+        max_iter (Optional[int]): Maximum iterations for an agent to execute a task.\n+        agent_executor (InstanceOf): An instance of the CrewAgentExecutor class.\n+        llm (Any): Language model that will run the agent.\n+        crew (Any): Crew to which the agent belongs.\n+        i18n (I18N): Internationalization settings.\n+        cache_handler (InstanceOf[CacheHandler]): An instance of the CacheHandler class.\n+        tools_handler (InstanceOf[ToolsHandler]): An instance of the ToolsHandler class.\n+\n+\n+    Methods:\n+        execute_task(task: Any, context: Optional[str] = None, tools: Optional[List[Any]] = None) -> str:\n+            Abstract method to execute a task.\n+        create_agent_executor(tools=None) -> None:\n+            Abstract method to create an agent executor.\n+        _parse_tools(tools: List[Any]) -> List[Any]:\n+            Abstract method to parse tools.\n+        get_delegation_tools(agents: List[\"BaseAgent\"]):\n+            Abstract method to set the agents task tools for handling delegation and question asking to other agents in crew.\n+        get_output_converter(llm, model, instructions):\n+            Abstract method to get the converter class for the agent to create json/pydantic outputs.\n+        interpolate_inputs(inputs: Dict[str, Any]) -> None:\n+            Interpolate inputs into the agent description and backstory.\n+        set_cache_handler(cache_handler: CacheHandler) -> None:\n+            Set the cache handler for the agent.\n+        increment_formatting_errors() -> None:\n+            Increment formatting errors.\n+        copy() -> \"BaseAgent\":\n+            Create a copy of the agent.\n+        set_rpm_controller(rpm_controller: RPMController) -> None:\n+            Set the rpm controller for the agent.\n+        set_private_attrs() -> \"BaseAgent\":\n+            Set private attributes.\n+    \"\"\"\n+\n+    __hash__ = object.__hash__  # type: ignore\n+    _logger: Logger = PrivateAttr()\n+    _rpm_controller: RPMController = PrivateAttr(default=None)\n+    _request_within_rpm_limit: Any = PrivateAttr(default=None)\n+    formatting_errors: int = 0\n+    model_config = ConfigDict(arbitrary_types_allowed=True)\n+    id: UUID4 = Field(default_factory=uuid.uuid4, frozen=True)\n+    role: str = Field(description=\"Role of the agent\")\n+    goal: str = Field(description=\"Objective of the agent\")\n+    backstory: str = Field(description=\"Backstory of the agent\")\n+    cache: bool = Field(\n+        default=True, description=\"Whether the agent should use a cache for tool usage.\"\n+    )\n+    config: Optional[Dict[str, Any]] = Field(\n+        description=\"Configuration for the agent\", default=None\n+    )\n+    verbose: bool = Field(\n+        default=False, description=\"Verbose mode for the Agent Execution\"\n+    )\n+    max_rpm: Optional[int] = Field(\n+        default=None,\n+        description=\"Maximum number of requests per minute for the agent execution to be respected.\",\n+    )\n+    allow_delegation: bool = Field(\n+        default=True, description=\"Allow delegation of tasks to agents\"\n+    )\n+    tools: Optional[List[Any]] = Field(\n+        default_factory=list, description=\"Tools at agents' disposal\"\n+    )\n+    max_iter: Optional[int] = Field(\n+        default=25, description=\"Maximum iterations for an agent to execute a task\"\n+    )\n+    agent_executor: InstanceOf = Field(\n+        default=None, description=\"An instance of the CrewAgentExecutor class.\"\n+    )\n+    llm: Any = Field(\n+        default=None, description=\"Language model that will run the agent.\"\n+    )\n+    crew: Any = Field(default=None, description=\"Crew to which the agent belongs.\")\n+    i18n: I18N = Field(default=I18N(), description=\"Internationalization settings.\")\n+    cache_handler: InstanceOf[CacheHandler] = Field(\n+        default=None, description=\"An instance of the CacheHandler class.\"\n+    )\n+    tools_handler: InstanceOf[ToolsHandler] = Field(\n+        default=None, description=\"An instance of the ToolsHandler class.\"\n+    )\n+\n+    _original_role: str | None = None\n+    _original_goal: str | None = None\n+    _original_backstory: str | None = None\n+    _token_process: TokenProcess = TokenProcess()\n+\n+    def __init__(__pydantic_self__, **data):\n+        config = data.pop(\"config\", {})\n+        super().__init__(**config, **data)\n+",
        "comment_created_at": "2024-06-27T06:29:30+00:00",
        "comment_author": "bhancockio",
        "comment_body": "If we aren't going to make gpt-4o the default llm for everything. We need to add a model_validator that checks to make sure the agent has an LLM and isn't none.",
        "pr_file_module": null
      },
      {
        "comment_id": "1656633687",
        "repo_full_name": "crewAIInc/crewAI",
        "pr_number": 776,
        "pr_file": "src/crewai/agents/agent_builder/base_agent.py",
        "discussion_id": "1656531929",
        "commented_code": "@@ -0,0 +1,255 @@\n+from copy import deepcopy\n+import uuid\n+from typing import Any, Dict, List, Optional\n+from abc import ABC, abstractmethod\n+from pydantic import (\n+    UUID4,\n+    BaseModel,\n+    Field,\n+    InstanceOf,\n+    field_validator,\n+    model_validator,\n+    ConfigDict,\n+    PrivateAttr,\n+)\n+from pydantic_core import PydanticCustomError\n+\n+from crewai.utilities import I18N, RPMController, Logger\n+from crewai.agents import CacheHandler, ToolsHandler\n+from crewai.utilities.token_counter_callback import TokenProcess\n+\n+\n+class BaseAgent(ABC, BaseModel):\n+    \"\"\"Abstract Base Class for all third party agents compatible with CrewAI.\n+\n+    Attributes:\n+        id (UUID4): Unique identifier for the agent.\n+        role (str): Role of the agent.\n+        goal (str): Objective of the agent.\n+        backstory (str): Backstory of the agent.\n+        cache (bool): Whether the agent should use a cache for tool usage.\n+        config (Optional[Dict[str, Any]]): Configuration for the agent.\n+        verbose (bool): Verbose mode for the Agent Execution.\n+        max_rpm (Optional[int]): Maximum number of requests per minute for the agent execution.\n+        allow_delegation (bool): Allow delegation of tasks to agents.\n+        tools (Optional[List[Any]]): Tools at the agent's disposal.\n+        max_iter (Optional[int]): Maximum iterations for an agent to execute a task.\n+        agent_executor (InstanceOf): An instance of the CrewAgentExecutor class.\n+        llm (Any): Language model that will run the agent.\n+        crew (Any): Crew to which the agent belongs.\n+        i18n (I18N): Internationalization settings.\n+        cache_handler (InstanceOf[CacheHandler]): An instance of the CacheHandler class.\n+        tools_handler (InstanceOf[ToolsHandler]): An instance of the ToolsHandler class.\n+\n+\n+    Methods:\n+        execute_task(task: Any, context: Optional[str] = None, tools: Optional[List[Any]] = None) -> str:\n+            Abstract method to execute a task.\n+        create_agent_executor(tools=None) -> None:\n+            Abstract method to create an agent executor.\n+        _parse_tools(tools: List[Any]) -> List[Any]:\n+            Abstract method to parse tools.\n+        get_delegation_tools(agents: List[\"BaseAgent\"]):\n+            Abstract method to set the agents task tools for handling delegation and question asking to other agents in crew.\n+        get_output_converter(llm, model, instructions):\n+            Abstract method to get the converter class for the agent to create json/pydantic outputs.\n+        interpolate_inputs(inputs: Dict[str, Any]) -> None:\n+            Interpolate inputs into the agent description and backstory.\n+        set_cache_handler(cache_handler: CacheHandler) -> None:\n+            Set the cache handler for the agent.\n+        increment_formatting_errors() -> None:\n+            Increment formatting errors.\n+        copy() -> \"BaseAgent\":\n+            Create a copy of the agent.\n+        set_rpm_controller(rpm_controller: RPMController) -> None:\n+            Set the rpm controller for the agent.\n+        set_private_attrs() -> \"BaseAgent\":\n+            Set private attributes.\n+    \"\"\"\n+\n+    __hash__ = object.__hash__  # type: ignore\n+    _logger: Logger = PrivateAttr()\n+    _rpm_controller: RPMController = PrivateAttr(default=None)\n+    _request_within_rpm_limit: Any = PrivateAttr(default=None)\n+    formatting_errors: int = 0\n+    model_config = ConfigDict(arbitrary_types_allowed=True)\n+    id: UUID4 = Field(default_factory=uuid.uuid4, frozen=True)\n+    role: str = Field(description=\"Role of the agent\")\n+    goal: str = Field(description=\"Objective of the agent\")\n+    backstory: str = Field(description=\"Backstory of the agent\")\n+    cache: bool = Field(\n+        default=True, description=\"Whether the agent should use a cache for tool usage.\"\n+    )\n+    config: Optional[Dict[str, Any]] = Field(\n+        description=\"Configuration for the agent\", default=None\n+    )\n+    verbose: bool = Field(\n+        default=False, description=\"Verbose mode for the Agent Execution\"\n+    )\n+    max_rpm: Optional[int] = Field(\n+        default=None,\n+        description=\"Maximum number of requests per minute for the agent execution to be respected.\",\n+    )\n+    allow_delegation: bool = Field(\n+        default=True, description=\"Allow delegation of tasks to agents\"\n+    )\n+    tools: Optional[List[Any]] = Field(\n+        default_factory=list, description=\"Tools at agents' disposal\"\n+    )\n+    max_iter: Optional[int] = Field(\n+        default=25, description=\"Maximum iterations for an agent to execute a task\"\n+    )\n+    agent_executor: InstanceOf = Field(\n+        default=None, description=\"An instance of the CrewAgentExecutor class.\"\n+    )\n+    llm: Any = Field(\n+        default=None, description=\"Language model that will run the agent.\"\n+    )\n+    crew: Any = Field(default=None, description=\"Crew to which the agent belongs.\")\n+    i18n: I18N = Field(default=I18N(), description=\"Internationalization settings.\")\n+    cache_handler: InstanceOf[CacheHandler] = Field(\n+        default=None, description=\"An instance of the CacheHandler class.\"\n+    )\n+    tools_handler: InstanceOf[ToolsHandler] = Field(\n+        default=None, description=\"An instance of the ToolsHandler class.\"\n+    )\n+\n+    _original_role: str | None = None\n+    _original_goal: str | None = None\n+    _original_backstory: str | None = None\n+    _token_process: TokenProcess = TokenProcess()\n+\n+    def __init__(__pydantic_self__, **data):\n+        config = data.pop(\"config\", {})\n+        super().__init__(**config, **data)\n+",
        "comment_created_at": "2024-06-27T07:45:43+00:00",
        "comment_author": "lorenzejay",
        "comment_body": "I agree. Other agents may not be supporting 4o yet. but I do think a validator for llm not being none is best.",
        "pr_file_module": null
      }
    ]
  }
]