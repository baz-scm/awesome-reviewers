[
  {
    "discussion_id": "1139357296",
    "pr_number": 9936,
    "pr_file": "platform-tests/src/test/java/org/eclipse/deeplearning4j/nd4j/linalg/blas/BlasTests.java",
    "created_at": "2023-03-16T21:04:25+00:00",
    "commented_code": "}\n \n \n+    @ParameterizedTest\n+    @MethodSource(\"org.nd4j.linalg.BaseNd4jTestWithBackends#configs\")\n+    public void pcaTest(Nd4jBackend backend) {\n+        double[][] inputArray = { { 1.0, 2.0, 3.0 }, { 11.0, 12.0, 13.0 }, { 21.0, 22.0, 23.0 }, { 31.0, 32.0, 33.0 } };\n+        double[][] assertion = new double[][]{\n+                {-0.55332, -0.72606, 0.40825},\n+                {      -0.57703 ,-0.01936 ,-0.81650},\n+                {-0.60073, 0.68735, 0.40825 }\n+        };\n+        INDArray assertArr = Nd4j.create(assertion);\n+        INDArray inputMatrix = Nd4j.create( inputArray );",
    "repo_full_name": "deeplearning4j/deeplearning4j",
    "discussion_comments": [
      {
        "comment_id": "1139357296",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 9936,
        "pr_file": "platform-tests/src/test/java/org/eclipse/deeplearning4j/nd4j/linalg/blas/BlasTests.java",
        "discussion_id": "1139357296",
        "commented_code": "@@ -65,6 +64,25 @@ public void pcaTest(Nd4jBackend backend) {\n     }\n \n \n+    @ParameterizedTest\n+    @MethodSource(\"org.nd4j.linalg.BaseNd4jTestWithBackends#configs\")\n+    public void pcaTest(Nd4jBackend backend) {\n+        double[][] inputArray = { { 1.0, 2.0, 3.0 }, { 11.0, 12.0, 13.0 }, { 21.0, 22.0, 23.0 }, { 31.0, 32.0, 33.0 } };\n+        double[][] assertion = new double[][]{\n+                {-0.55332, -0.72606, 0.40825},\n+                {      -0.57703 ,-0.01936 ,-0.81650},\n+                {-0.60073, 0.68735, 0.40825 }\n+        };\n+        INDArray assertArr = Nd4j.create(assertion);\n+        INDArray inputMatrix = Nd4j.create( inputArray );",
        "comment_created_at": "2023-03-16T21:04:25+00:00",
        "comment_author": "dpetronijevic",
        "comment_body": "In order to verify that PCA.pca_factor does not modify inputMatrix  it would be good to add to test the following:\r\n`INDArray duplicateInput = inputMatrix.dup();`\r\nbefore the calls to PCA.pca_factor and PCA.pca and then assert after the calls:\r\n`assertEquals(duplicateInput, inputMatrix);`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "628227730",
    "pr_number": 9295,
    "pr_file": "deeplearning4j/deeplearning4j-core/src/test/java/org/deeplearning4j/gradientcheck/CNN1DGradientCheckTest.java",
    "created_at": "2021-05-07T13:52:29+00:00",
    "commented_code": "labels.putScalar(new int[] { i, i % finalNOut, j }, 1.0);\n                         }\n                     }\n-                    MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder().dataType(DataType.DOUBLE).updater(new NoOp()).dist(new NormalDistribution(0, 1)).convolutionMode(ConvolutionMode.Same).list().layer(new Convolution1DLayer.Builder().activation(afn).kernelSize(kernel).stride(stride).padding(padding).nIn(convNIn).nOut(convNOut1).rnnDataFormat(RNNFormat.NCW).build()).layer(new LocallyConnected1D.Builder().activation(afn).kernelSize(kernel).stride(stride).padding(padding).nIn(convNOut1).nOut(convNOut2).hasBias(false).build()).layer(new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nOut(finalNOut).build()).setInputType(InputType.recurrent(convNIn, length)).build();\n+                    MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder().seed(2021).dataType(DataType.DOUBLE).updater(new NoOp()).dist(new NormalDistribution(0, 1)).convolutionMode(ConvolutionMode.Same).list().layer(new Convolution1DLayer.Builder().activation(afn).kernelSize(kernel).stride(stride).padding(padding).nIn(convNIn).nOut(convNOut1).rnnDataFormat(RNNFormat.NCW).build()).layer(new LocallyConnected1D.Builder().activation(afn).kernelSize(kernel).stride(stride).padding(padding).nIn(convNOut1).nOut(convNOut2).hasBias(false).build()).layer(new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nOut(finalNOut).build()).setInputType(InputType.recurrent(convNIn, length)).build();",
    "repo_full_name": "deeplearning4j/deeplearning4j",
    "discussion_comments": [
      {
        "comment_id": "628227730",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 9295,
        "pr_file": "deeplearning4j/deeplearning4j-core/src/test/java/org/deeplearning4j/gradientcheck/CNN1DGradientCheckTest.java",
        "discussion_id": "628227730",
        "commented_code": "@@ -105,7 +104,7 @@ void testCnn1DWithLocallyConnected1D() {\n                             labels.putScalar(new int[] { i, i % finalNOut, j }, 1.0);\n                         }\n                     }\n-                    MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder().dataType(DataType.DOUBLE).updater(new NoOp()).dist(new NormalDistribution(0, 1)).convolutionMode(ConvolutionMode.Same).list().layer(new Convolution1DLayer.Builder().activation(afn).kernelSize(kernel).stride(stride).padding(padding).nIn(convNIn).nOut(convNOut1).rnnDataFormat(RNNFormat.NCW).build()).layer(new LocallyConnected1D.Builder().activation(afn).kernelSize(kernel).stride(stride).padding(padding).nIn(convNOut1).nOut(convNOut2).hasBias(false).build()).layer(new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nOut(finalNOut).build()).setInputType(InputType.recurrent(convNIn, length)).build();\n+                    MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder().seed(2021).dataType(DataType.DOUBLE).updater(new NoOp()).dist(new NormalDistribution(0, 1)).convolutionMode(ConvolutionMode.Same).list().layer(new Convolution1DLayer.Builder().activation(afn).kernelSize(kernel).stride(stride).padding(padding).nIn(convNIn).nOut(convNOut1).rnnDataFormat(RNNFormat.NCW).build()).layer(new LocallyConnected1D.Builder().activation(afn).kernelSize(kernel).stride(stride).padding(padding).nIn(convNOut1).nOut(convNOut2).hasBias(false).build()).layer(new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nOut(finalNOut).build()).setInputType(InputType.recurrent(convNIn, length)).build();",
        "comment_created_at": "2021-05-07T13:52:29+00:00",
        "comment_author": "agibsonccc",
        "comment_body": "Mind adding some comments about how important the seed is here? A log of issues we ran in to with certain tests is handy.",
        "pr_file_module": null
      },
      {
        "comment_id": "628280349",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 9295,
        "pr_file": "deeplearning4j/deeplearning4j-core/src/test/java/org/deeplearning4j/gradientcheck/CNN1DGradientCheckTest.java",
        "discussion_id": "628227730",
        "commented_code": "@@ -105,7 +104,7 @@ void testCnn1DWithLocallyConnected1D() {\n                             labels.putScalar(new int[] { i, i % finalNOut, j }, 1.0);\n                         }\n                     }\n-                    MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder().dataType(DataType.DOUBLE).updater(new NoOp()).dist(new NormalDistribution(0, 1)).convolutionMode(ConvolutionMode.Same).list().layer(new Convolution1DLayer.Builder().activation(afn).kernelSize(kernel).stride(stride).padding(padding).nIn(convNIn).nOut(convNOut1).rnnDataFormat(RNNFormat.NCW).build()).layer(new LocallyConnected1D.Builder().activation(afn).kernelSize(kernel).stride(stride).padding(padding).nIn(convNOut1).nOut(convNOut2).hasBias(false).build()).layer(new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nOut(finalNOut).build()).setInputType(InputType.recurrent(convNIn, length)).build();\n+                    MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder().seed(2021).dataType(DataType.DOUBLE).updater(new NoOp()).dist(new NormalDistribution(0, 1)).convolutionMode(ConvolutionMode.Same).list().layer(new Convolution1DLayer.Builder().activation(afn).kernelSize(kernel).stride(stride).padding(padding).nIn(convNIn).nOut(convNOut1).rnnDataFormat(RNNFormat.NCW).build()).layer(new LocallyConnected1D.Builder().activation(afn).kernelSize(kernel).stride(stride).padding(padding).nIn(convNOut1).nOut(convNOut2).hasBias(false).build()).layer(new RnnOutputLayer.Builder(LossFunctions.LossFunction.MCXENT).activation(Activation.SOFTMAX).nOut(finalNOut).build()).setInputType(InputType.recurrent(convNIn, length)).build();",
        "comment_created_at": "2021-05-07T15:01:56+00:00",
        "comment_author": "quickwritereader",
        "comment_body": "refactored all calls into one method and added the comment",
        "pr_file_module": null
      }
    ]
  }
]