[
  {
    "discussion_id": "198542123",
    "pr_number": 5725,
    "pr_file": "libnd4j/include/loops/cpu/type_conversions.cpp",
    "created_at": "2018-06-27T15:34:36+00:00",
    "commented_code": "}\n     }\n \n+    /**\n+ * This is cpu version, so leave it here as inline, to avoid templates instantiation\n+ *\n+ * @tparam S source type\n+ * @tparam T target type\n+ * @tparam T intermediate type\n+ * @param dx\n+ * @param N\n+ * @param dz\n+ */\n+    template<typename S, typename T>\n+    void TypeCast::convertDirectGeneric(Nd4jPointer * extras, void *dx, Nd4jLong N, void *dz) {\n+        auto x = reinterpret_cast<S *>(dx);\n+        auto z = reinterpret_cast<T *>(dz);\n+\n+        if (N < nd4j::Environment::getInstance()->elementwiseThreshold()) {\n+#pragma omp simd\n+            for (int i = 0; i < N; i++) {\n+                z[i] = static_cast<T>(x[i]);\n+            }\n+        } else {\n+\n+#pragma omp parallel for\n+            for (int i = 0; i < N; i++) {\n+                z[i] = static_cast<T>(x[i]);\n+            }\n+        }\n+    };\n+\n     /**\n      * This is cpu version, so leave it here as inline, to avoid templates instantiation\n      *\n-     * @tparam S\n-     * @tparam T\n+     * @tparam S source type\n+     * @tparam T target type\n+     * @tparam T intermediate type\n      * @param dx\n      * @param N\n      * @param dz\n      */\n-    template<typename S, typename T>\n+    template<typename S, typename T, typename I>\n     void TypeCast::convertGeneric(Nd4jPointer * extras, void *dx, Nd4jLong N, void *dz) {\n         auto x = reinterpret_cast<S *>(dx);\n         auto z = reinterpret_cast<T *>(dz);\n \n         if (N < nd4j::Environment::getInstance()->elementwiseThreshold()) {\n #pragma omp simd\n             for (int i = 0; i < N; i++) {\n-                // FIXME: get rid of through-float though\n-                z[i] = static_cast<T>(static_cast<float>(x[i]));\n+                // FIXME: get rid of through-I though\n+                z[i] = static_cast<T>(static_cast<I>(x[i]));\n             }\n         } else {\n \n #pragma omp parallel for\n             for (int i = 0; i < N; i++) {\n-                // FIXME: get rid of through-float though\n-                z[i] = static_cast<T>(static_cast<float>(x[i]));\n+                // FIXME: get rid of through-I though",
    "repo_full_name": "deeplearning4j/deeplearning4j",
    "discussion_comments": [
      {
        "comment_id": "198542123",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 5725,
        "pr_file": "libnd4j/include/loops/cpu/type_conversions.cpp",
        "discussion_id": "198542123",
        "commented_code": "@@ -88,36 +88,96 @@ namespace nd4j {\n         }\n     }\n \n+    /**\n+ * This is cpu version, so leave it here as inline, to avoid templates instantiation\n+ *\n+ * @tparam S source type\n+ * @tparam T target type\n+ * @tparam T intermediate type\n+ * @param dx\n+ * @param N\n+ * @param dz\n+ */\n+    template<typename S, typename T>\n+    void TypeCast::convertDirectGeneric(Nd4jPointer * extras, void *dx, Nd4jLong N, void *dz) {\n+        auto x = reinterpret_cast<S *>(dx);\n+        auto z = reinterpret_cast<T *>(dz);\n+\n+        if (N < nd4j::Environment::getInstance()->elementwiseThreshold()) {\n+#pragma omp simd\n+            for (int i = 0; i < N; i++) {\n+                z[i] = static_cast<T>(x[i]);\n+            }\n+        } else {\n+\n+#pragma omp parallel for\n+            for (int i = 0; i < N; i++) {\n+                z[i] = static_cast<T>(x[i]);\n+            }\n+        }\n+    };\n+\n     /**\n      * This is cpu version, so leave it here as inline, to avoid templates instantiation\n      *\n-     * @tparam S\n-     * @tparam T\n+     * @tparam S source type\n+     * @tparam T target type\n+     * @tparam T intermediate type\n      * @param dx\n      * @param N\n      * @param dz\n      */\n-    template<typename S, typename T>\n+    template<typename S, typename T, typename I>\n     void TypeCast::convertGeneric(Nd4jPointer * extras, void *dx, Nd4jLong N, void *dz) {\n         auto x = reinterpret_cast<S *>(dx);\n         auto z = reinterpret_cast<T *>(dz);\n \n         if (N < nd4j::Environment::getInstance()->elementwiseThreshold()) {\n #pragma omp simd\n             for (int i = 0; i < N; i++) {\n-                // FIXME: get rid of through-float though\n-                z[i] = static_cast<T>(static_cast<float>(x[i]));\n+                // FIXME: get rid of through-I though\n+                z[i] = static_cast<T>(static_cast<I>(x[i]));\n             }\n         } else {\n \n #pragma omp parallel for\n             for (int i = 0; i < N; i++) {\n-                // FIXME: get rid of through-float though\n-                z[i] = static_cast<T>(static_cast<float>(x[i]));\n+                // FIXME: get rid of through-I though",
        "comment_created_at": "2018-06-27T15:34:36+00:00",
        "comment_author": "raver119",
        "comment_body": "All this stuff is NOT need. \r\nReason of that FIXME message isn't related to precision.",
        "pr_file_module": null
      },
      {
        "comment_id": "198543293",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 5725,
        "pr_file": "libnd4j/include/loops/cpu/type_conversions.cpp",
        "discussion_id": "198542123",
        "commented_code": "@@ -88,36 +88,96 @@ namespace nd4j {\n         }\n     }\n \n+    /**\n+ * This is cpu version, so leave it here as inline, to avoid templates instantiation\n+ *\n+ * @tparam S source type\n+ * @tparam T target type\n+ * @tparam T intermediate type\n+ * @param dx\n+ * @param N\n+ * @param dz\n+ */\n+    template<typename S, typename T>\n+    void TypeCast::convertDirectGeneric(Nd4jPointer * extras, void *dx, Nd4jLong N, void *dz) {\n+        auto x = reinterpret_cast<S *>(dx);\n+        auto z = reinterpret_cast<T *>(dz);\n+\n+        if (N < nd4j::Environment::getInstance()->elementwiseThreshold()) {\n+#pragma omp simd\n+            for (int i = 0; i < N; i++) {\n+                z[i] = static_cast<T>(x[i]);\n+            }\n+        } else {\n+\n+#pragma omp parallel for\n+            for (int i = 0; i < N; i++) {\n+                z[i] = static_cast<T>(x[i]);\n+            }\n+        }\n+    };\n+\n     /**\n      * This is cpu version, so leave it here as inline, to avoid templates instantiation\n      *\n-     * @tparam S\n-     * @tparam T\n+     * @tparam S source type\n+     * @tparam T target type\n+     * @tparam T intermediate type\n      * @param dx\n      * @param N\n      * @param dz\n      */\n-    template<typename S, typename T>\n+    template<typename S, typename T, typename I>\n     void TypeCast::convertGeneric(Nd4jPointer * extras, void *dx, Nd4jLong N, void *dz) {\n         auto x = reinterpret_cast<S *>(dx);\n         auto z = reinterpret_cast<T *>(dz);\n \n         if (N < nd4j::Environment::getInstance()->elementwiseThreshold()) {\n #pragma omp simd\n             for (int i = 0; i < N; i++) {\n-                // FIXME: get rid of through-float though\n-                z[i] = static_cast<T>(static_cast<float>(x[i]));\n+                // FIXME: get rid of through-I though\n+                z[i] = static_cast<T>(static_cast<I>(x[i]));\n             }\n         } else {\n \n #pragma omp parallel for\n             for (int i = 0; i < N; i++) {\n-                // FIXME: get rid of through-float though\n-                z[i] = static_cast<T>(static_cast<float>(x[i]));\n+                // FIXME: get rid of through-I though",
        "comment_created_at": "2018-06-27T15:37:54+00:00",
        "comment_author": "raver119",
        "comment_body": "In ideal world we should just add proper conversions between values, plus something for overflow handling. But definitely not a third template argument.",
        "pr_file_module": null
      },
      {
        "comment_id": "198547168",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 5725,
        "pr_file": "libnd4j/include/loops/cpu/type_conversions.cpp",
        "discussion_id": "198542123",
        "commented_code": "@@ -88,36 +88,96 @@ namespace nd4j {\n         }\n     }\n \n+    /**\n+ * This is cpu version, so leave it here as inline, to avoid templates instantiation\n+ *\n+ * @tparam S source type\n+ * @tparam T target type\n+ * @tparam T intermediate type\n+ * @param dx\n+ * @param N\n+ * @param dz\n+ */\n+    template<typename S, typename T>\n+    void TypeCast::convertDirectGeneric(Nd4jPointer * extras, void *dx, Nd4jLong N, void *dz) {\n+        auto x = reinterpret_cast<S *>(dx);\n+        auto z = reinterpret_cast<T *>(dz);\n+\n+        if (N < nd4j::Environment::getInstance()->elementwiseThreshold()) {\n+#pragma omp simd\n+            for (int i = 0; i < N; i++) {\n+                z[i] = static_cast<T>(x[i]);\n+            }\n+        } else {\n+\n+#pragma omp parallel for\n+            for (int i = 0; i < N; i++) {\n+                z[i] = static_cast<T>(x[i]);\n+            }\n+        }\n+    };\n+\n     /**\n      * This is cpu version, so leave it here as inline, to avoid templates instantiation\n      *\n-     * @tparam S\n-     * @tparam T\n+     * @tparam S source type\n+     * @tparam T target type\n+     * @tparam T intermediate type\n      * @param dx\n      * @param N\n      * @param dz\n      */\n-    template<typename S, typename T>\n+    template<typename S, typename T, typename I>\n     void TypeCast::convertGeneric(Nd4jPointer * extras, void *dx, Nd4jLong N, void *dz) {\n         auto x = reinterpret_cast<S *>(dx);\n         auto z = reinterpret_cast<T *>(dz);\n \n         if (N < nd4j::Environment::getInstance()->elementwiseThreshold()) {\n #pragma omp simd\n             for (int i = 0; i < N; i++) {\n-                // FIXME: get rid of through-float though\n-                z[i] = static_cast<T>(static_cast<float>(x[i]));\n+                // FIXME: get rid of through-I though\n+                z[i] = static_cast<T>(static_cast<I>(x[i]));\n             }\n         } else {\n \n #pragma omp parallel for\n             for (int i = 0; i < N; i++) {\n-                // FIXME: get rid of through-float though\n-                z[i] = static_cast<T>(static_cast<float>(x[i]));\n+                // FIXME: get rid of through-I though",
        "comment_created_at": "2018-06-27T15:48:30+00:00",
        "comment_author": "raver119",
        "comment_body": "So, each of defined additional dtype should have conversion operator defined for all other additional dtypes. That's proper solution we want long-term.",
        "pr_file_module": null
      },
      {
        "comment_id": "198551308",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 5725,
        "pr_file": "libnd4j/include/loops/cpu/type_conversions.cpp",
        "discussion_id": "198542123",
        "commented_code": "@@ -88,36 +88,96 @@ namespace nd4j {\n         }\n     }\n \n+    /**\n+ * This is cpu version, so leave it here as inline, to avoid templates instantiation\n+ *\n+ * @tparam S source type\n+ * @tparam T target type\n+ * @tparam T intermediate type\n+ * @param dx\n+ * @param N\n+ * @param dz\n+ */\n+    template<typename S, typename T>\n+    void TypeCast::convertDirectGeneric(Nd4jPointer * extras, void *dx, Nd4jLong N, void *dz) {\n+        auto x = reinterpret_cast<S *>(dx);\n+        auto z = reinterpret_cast<T *>(dz);\n+\n+        if (N < nd4j::Environment::getInstance()->elementwiseThreshold()) {\n+#pragma omp simd\n+            for (int i = 0; i < N; i++) {\n+                z[i] = static_cast<T>(x[i]);\n+            }\n+        } else {\n+\n+#pragma omp parallel for\n+            for (int i = 0; i < N; i++) {\n+                z[i] = static_cast<T>(x[i]);\n+            }\n+        }\n+    };\n+\n     /**\n      * This is cpu version, so leave it here as inline, to avoid templates instantiation\n      *\n-     * @tparam S\n-     * @tparam T\n+     * @tparam S source type\n+     * @tparam T target type\n+     * @tparam T intermediate type\n      * @param dx\n      * @param N\n      * @param dz\n      */\n-    template<typename S, typename T>\n+    template<typename S, typename T, typename I>\n     void TypeCast::convertGeneric(Nd4jPointer * extras, void *dx, Nd4jLong N, void *dz) {\n         auto x = reinterpret_cast<S *>(dx);\n         auto z = reinterpret_cast<T *>(dz);\n \n         if (N < nd4j::Environment::getInstance()->elementwiseThreshold()) {\n #pragma omp simd\n             for (int i = 0; i < N; i++) {\n-                // FIXME: get rid of through-float though\n-                z[i] = static_cast<T>(static_cast<float>(x[i]));\n+                // FIXME: get rid of through-I though\n+                z[i] = static_cast<T>(static_cast<I>(x[i]));\n             }\n         } else {\n \n #pragma omp parallel for\n             for (int i = 0; i < N; i++) {\n-                // FIXME: get rid of through-float though\n-                z[i] = static_cast<T>(static_cast<float>(x[i]));\n+                // FIXME: get rid of through-I though",
        "comment_created_at": "2018-06-27T16:02:23+00:00",
        "comment_author": "emillynge",
        "comment_body": "Ok, I think I understand.\r\n\r\nSo if I understand you correctly \r\n`z[i] = static_cast<T>(static_cast<float>(x[i]));` does not result in a downcast even if `x[i]` is a double and `z[i]` is a long long int.\r\n\r\nAlso, can you tell me whether the compiler takes care of optimizing \r\n`static_cast<float>(static_cast<float>(x[i]))` ? Or maybe we simply do not care.\r\n\r\n\r\nIf we were to get rid of the cast-through dtype, that would require implementing more conversion operators in:\r\n```\r\nfloat8.cpp\r\nfloat16.cpp\r\nint8.cpp\r\nint16.cpp\r\nuint8.cpp\r\nuint16.cpp\r\n```\r\nright?\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "198564260",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 5725,
        "pr_file": "libnd4j/include/loops/cpu/type_conversions.cpp",
        "discussion_id": "198542123",
        "commented_code": "@@ -88,36 +88,96 @@ namespace nd4j {\n         }\n     }\n \n+    /**\n+ * This is cpu version, so leave it here as inline, to avoid templates instantiation\n+ *\n+ * @tparam S source type\n+ * @tparam T target type\n+ * @tparam T intermediate type\n+ * @param dx\n+ * @param N\n+ * @param dz\n+ */\n+    template<typename S, typename T>\n+    void TypeCast::convertDirectGeneric(Nd4jPointer * extras, void *dx, Nd4jLong N, void *dz) {\n+        auto x = reinterpret_cast<S *>(dx);\n+        auto z = reinterpret_cast<T *>(dz);\n+\n+        if (N < nd4j::Environment::getInstance()->elementwiseThreshold()) {\n+#pragma omp simd\n+            for (int i = 0; i < N; i++) {\n+                z[i] = static_cast<T>(x[i]);\n+            }\n+        } else {\n+\n+#pragma omp parallel for\n+            for (int i = 0; i < N; i++) {\n+                z[i] = static_cast<T>(x[i]);\n+            }\n+        }\n+    };\n+\n     /**\n      * This is cpu version, so leave it here as inline, to avoid templates instantiation\n      *\n-     * @tparam S\n-     * @tparam T\n+     * @tparam S source type\n+     * @tparam T target type\n+     * @tparam T intermediate type\n      * @param dx\n      * @param N\n      * @param dz\n      */\n-    template<typename S, typename T>\n+    template<typename S, typename T, typename I>\n     void TypeCast::convertGeneric(Nd4jPointer * extras, void *dx, Nd4jLong N, void *dz) {\n         auto x = reinterpret_cast<S *>(dx);\n         auto z = reinterpret_cast<T *>(dz);\n \n         if (N < nd4j::Environment::getInstance()->elementwiseThreshold()) {\n #pragma omp simd\n             for (int i = 0; i < N; i++) {\n-                // FIXME: get rid of through-float though\n-                z[i] = static_cast<T>(static_cast<float>(x[i]));\n+                // FIXME: get rid of through-I though\n+                z[i] = static_cast<T>(static_cast<I>(x[i]));\n             }\n         } else {\n \n #pragma omp parallel for\n             for (int i = 0; i < N; i++) {\n-                // FIXME: get rid of through-float though\n-                z[i] = static_cast<T>(static_cast<float>(x[i]));\n+                // FIXME: get rid of through-I though",
        "comment_created_at": "2018-06-27T16:45:17+00:00",
        "comment_author": "raver119",
        "comment_body": "re: methods. Yes, exactly. those classes.\r\n\r\nre: cast-through. problem is precision, not a capacity. i.e. you cast from **int** to **long** via **float**. In this case due to how floating point works, you'll get inaccurate conversions above some threshold. \r\n\r\naccuracy isn't any issue for int -> short, or int -> byte. But it is an issue for int -> long when it comes to relatively big values.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "189971816",
    "pr_number": 5293,
    "pr_file": "libnd4j/include/ops/declarable/generic/helpers/impl/convolutions.cpp",
    "created_at": "2018-05-22T16:39:48+00:00",
    "commented_code": "const int oD = output.sizeAt(2);\n     const int oH = output.sizeAt(3);\n     const int oW = output.sizeAt(4);    \n-\n-    int k;\n-\n-#pragma omp parallel for private(k)\n-    for (k = 0; k < iC; k++) {\n     \n-        /* loop over output */\n-        int i, j, ti;\n-        for (ti = 0; ti < oD; ti++) {\n-            for (i = 0; i < oH; i++) {\n-                for (j = 0; j < oW; j++){\n+    const int iStride2 = iH * iW;\n+    const int oStride2 = oH * oW;\n+    const int iStride1 = iD * iStride2;\n+    const int oStride1 = oD * oStride2;\n+    const int iStride0 = iC * iStride1;",
    "repo_full_name": "deeplearning4j/deeplearning4j",
    "discussion_comments": [
      {
        "comment_id": "189971816",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 5293,
        "pr_file": "libnd4j/include/ops/declarable/generic/helpers/impl/convolutions.cpp",
        "discussion_id": "189971816",
        "commented_code": "@@ -737,56 +768,62 @@ void ConvolutionUtils<T>::maxPool3dFrame(NDArray<T>& input, NDArray<T>& output,\n     const int oD = output.sizeAt(2);\n     const int oH = output.sizeAt(3);\n     const int oW = output.sizeAt(4);    \n-\n-    int k;\n-\n-#pragma omp parallel for private(k)\n-    for (k = 0; k < iC; k++) {\n     \n-        /* loop over output */\n-        int i, j, ti;\n-        for (ti = 0; ti < oD; ti++) {\n-            for (i = 0; i < oH; i++) {\n-                for (j = 0; j < oW; j++){\n+    const int iStride2 = iH * iW;\n+    const int oStride2 = oH * oW;\n+    const int iStride1 = iD * iStride2;\n+    const int oStride1 = oD * oStride2;\n+    const int iStride0 = iC * iStride1;",
        "comment_created_at": "2018-05-22T16:39:48+00:00",
        "comment_author": "raver119",
        "comment_body": "use auto or Nd4jLong here please. Convolution stuff was the reason behind int -> long migration, exactly due to possibility of getting strides > MAX_INT. ",
        "pr_file_module": null
      },
      {
        "comment_id": "189984047",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 5293,
        "pr_file": "libnd4j/include/ops/declarable/generic/helpers/impl/convolutions.cpp",
        "discussion_id": "189971816",
        "commented_code": "@@ -737,56 +768,62 @@ void ConvolutionUtils<T>::maxPool3dFrame(NDArray<T>& input, NDArray<T>& output,\n     const int oD = output.sizeAt(2);\n     const int oH = output.sizeAt(3);\n     const int oW = output.sizeAt(4);    \n-\n-    int k;\n-\n-#pragma omp parallel for private(k)\n-    for (k = 0; k < iC; k++) {\n     \n-        /* loop over output */\n-        int i, j, ti;\n-        for (ti = 0; ti < oD; ti++) {\n-            for (i = 0; i < oH; i++) {\n-                for (j = 0; j < oW; j++){\n+    const int iStride2 = iH * iW;\n+    const int oStride2 = oH * oW;\n+    const int iStride1 = iD * iStride2;\n+    const int oStride1 = oD * oStride2;\n+    const int iStride0 = iC * iStride1;",
        "comment_created_at": "2018-05-22T17:17:56+00:00",
        "comment_author": "shyrma",
        "comment_body": "done",
        "pr_file_module": null
      }
    ]
  }
]