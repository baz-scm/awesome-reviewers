[
  {
    "discussion_id": "672985933",
    "pr_number": 9395,
    "pr_file": "python4j/python4j-numpy/src/main/java/org/nd4j/python4j/NumpyArray.java",
    "created_at": "2021-07-20T10:04:04+00:00",
    "commented_code": "// PyArray_Type() call causes jvm crash in linux cpu if GIL is acquired by non main thread.\n         // Using Interpreter for now:\n \n-//        try(PythonContextManager.Context context = new PythonContextManager.Context(\"__np_array_converter\")){\n-//            log.info(\"Stringing exec...\");\n-//            String code = \"import ctypes\nimport numpy as np\n\" +\n-//                    \"cArr = (ctypes.\" + ctype + \"*\" + indArray.length() + \")\"+\n-//                    \".from_address(\" + indArray.data().pointer().address() + \")\n\"+\n-//                    \"npArr = np.frombuffer(cArr, dtype=\" + ((numpyType == NPY_HALF) ? \"'half'\" : \"ctypes.\" + ctype)+\n-//                    \").reshape(\" + Arrays.toString(indArray.shape()) + \")\";\n-//            PythonExecutioner.exec(code);\n-//            log.info(\"exec done.\");\n-//            PythonObject ret = PythonExecutioner.getVariable(\"npArr\");\n-//            Py_IncRef(ret.getNativePythonObject());\n-//            return ret;\n-//\n-//        }\n-        log.info(\"NUMPY: PyArray_Type()\");\n-        PyTypeObject pyTypeObject = PyArray_Type();\n-\n-\n-        log.info(\"NUMPY: PyArray_New()\");\n-        PyObject npArr = PyArray_New(pyTypeObject, shape.length, new SizeTPointer(shape),\n-                numpyType, null,\n-                inputArray.data().addressPointer(),\n-                0, NPY_ARRAY_CARRAY, null);\n-        log.info(\"Done.\");\n-        return new PythonObject(npArr);\n+        //likely embedded in python, always use this method instead\n+        if(!PythonConstants.releaseGilAutomatically() || PythonConstants.createNpyViaPython()) {\n+            try(PythonContextManager.Context context = new PythonContextManager.Context(\"__np_array_converter\")){\n+                log.info(\"Stringing exec...\");\n+                String code = \"import ctypes\nimport numpy as np\n\" +\n+                        \"cArr = (ctypes.\" + ctype + \"*\" + indArray.length() + \")\"+\n+                        \".from_address(\" + indArray.data().pointer().address() + \")\n\"+\n+                        \"npArr = np.frombuffer(cArr, dtype=\" + ((numpyType == NPY_HALF) ? \"'half'\" : \"ctypes.\" + ctype)+\n+                        \").reshape(\" + Arrays.toString(indArray.shape()) + \")\";\n+                PythonExecutioner.exec(code);\n+                log.info(\"exec done.\");",
    "repo_full_name": "deeplearning4j/deeplearning4j",
    "discussion_comments": [
      {
        "comment_id": "672985933",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 9395,
        "pr_file": "python4j/python4j-numpy/src/main/java/org/nd4j/python4j/NumpyArray.java",
        "discussion_id": "672985933",
        "commented_code": "@@ -282,31 +282,37 @@ public PythonObject toPython(INDArray indArray) {\n         // PyArray_Type() call causes jvm crash in linux cpu if GIL is acquired by non main thread.\n         // Using Interpreter for now:\n \n-//        try(PythonContextManager.Context context = new PythonContextManager.Context(\"__np_array_converter\")){\n-//            log.info(\"Stringing exec...\");\n-//            String code = \"import ctypes\\nimport numpy as np\\n\" +\n-//                    \"cArr = (ctypes.\" + ctype + \"*\" + indArray.length() + \")\"+\n-//                    \".from_address(\" + indArray.data().pointer().address() + \")\\n\"+\n-//                    \"npArr = np.frombuffer(cArr, dtype=\" + ((numpyType == NPY_HALF) ? \"'half'\" : \"ctypes.\" + ctype)+\n-//                    \").reshape(\" + Arrays.toString(indArray.shape()) + \")\";\n-//            PythonExecutioner.exec(code);\n-//            log.info(\"exec done.\");\n-//            PythonObject ret = PythonExecutioner.getVariable(\"npArr\");\n-//            Py_IncRef(ret.getNativePythonObject());\n-//            return ret;\n-//\n-//        }\n-        log.info(\"NUMPY: PyArray_Type()\");\n-        PyTypeObject pyTypeObject = PyArray_Type();\n-\n-\n-        log.info(\"NUMPY: PyArray_New()\");\n-        PyObject npArr = PyArray_New(pyTypeObject, shape.length, new SizeTPointer(shape),\n-                numpyType, null,\n-                inputArray.data().addressPointer(),\n-                0, NPY_ARRAY_CARRAY, null);\n-        log.info(\"Done.\");\n-        return new PythonObject(npArr);\n+        //likely embedded in python, always use this method instead\n+        if(!PythonConstants.releaseGilAutomatically() || PythonConstants.createNpyViaPython()) {\n+            try(PythonContextManager.Context context = new PythonContextManager.Context(\"__np_array_converter\")){\n+                log.info(\"Stringing exec...\");\n+                String code = \"import ctypes\\nimport numpy as np\\n\" +\n+                        \"cArr = (ctypes.\" + ctype + \"*\" + indArray.length() + \")\"+\n+                        \".from_address(\" + indArray.data().pointer().address() + \")\\n\"+\n+                        \"npArr = np.frombuffer(cArr, dtype=\" + ((numpyType == NPY_HALF) ? \"'half'\" : \"ctypes.\" + ctype)+\n+                        \").reshape(\" + Arrays.toString(indArray.shape()) + \")\";\n+                PythonExecutioner.exec(code);\n+                log.info(\"exec done.\");",
        "comment_created_at": "2021-07-20T10:04:04+00:00",
        "comment_author": "treo",
        "comment_body": "Does it make sense to keep this at info log level? or should this maybe move to the debug log level, as you did with the logging in the other branch?",
        "pr_file_module": null
      },
      {
        "comment_id": "673008751",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 9395,
        "pr_file": "python4j/python4j-numpy/src/main/java/org/nd4j/python4j/NumpyArray.java",
        "discussion_id": "672985933",
        "commented_code": "@@ -282,31 +282,37 @@ public PythonObject toPython(INDArray indArray) {\n         // PyArray_Type() call causes jvm crash in linux cpu if GIL is acquired by non main thread.\n         // Using Interpreter for now:\n \n-//        try(PythonContextManager.Context context = new PythonContextManager.Context(\"__np_array_converter\")){\n-//            log.info(\"Stringing exec...\");\n-//            String code = \"import ctypes\\nimport numpy as np\\n\" +\n-//                    \"cArr = (ctypes.\" + ctype + \"*\" + indArray.length() + \")\"+\n-//                    \".from_address(\" + indArray.data().pointer().address() + \")\\n\"+\n-//                    \"npArr = np.frombuffer(cArr, dtype=\" + ((numpyType == NPY_HALF) ? \"'half'\" : \"ctypes.\" + ctype)+\n-//                    \").reshape(\" + Arrays.toString(indArray.shape()) + \")\";\n-//            PythonExecutioner.exec(code);\n-//            log.info(\"exec done.\");\n-//            PythonObject ret = PythonExecutioner.getVariable(\"npArr\");\n-//            Py_IncRef(ret.getNativePythonObject());\n-//            return ret;\n-//\n-//        }\n-        log.info(\"NUMPY: PyArray_Type()\");\n-        PyTypeObject pyTypeObject = PyArray_Type();\n-\n-\n-        log.info(\"NUMPY: PyArray_New()\");\n-        PyObject npArr = PyArray_New(pyTypeObject, shape.length, new SizeTPointer(shape),\n-                numpyType, null,\n-                inputArray.data().addressPointer(),\n-                0, NPY_ARRAY_CARRAY, null);\n-        log.info(\"Done.\");\n-        return new PythonObject(npArr);\n+        //likely embedded in python, always use this method instead\n+        if(!PythonConstants.releaseGilAutomatically() || PythonConstants.createNpyViaPython()) {\n+            try(PythonContextManager.Context context = new PythonContextManager.Context(\"__np_array_converter\")){\n+                log.info(\"Stringing exec...\");\n+                String code = \"import ctypes\\nimport numpy as np\\n\" +\n+                        \"cArr = (ctypes.\" + ctype + \"*\" + indArray.length() + \")\"+\n+                        \".from_address(\" + indArray.data().pointer().address() + \")\\n\"+\n+                        \"npArr = np.frombuffer(cArr, dtype=\" + ((numpyType == NPY_HALF) ? \"'half'\" : \"ctypes.\" + ctype)+\n+                        \").reshape(\" + Arrays.toString(indArray.shape()) + \")\";\n+                PythonExecutioner.exec(code);\n+                log.info(\"exec done.\");",
        "comment_created_at": "2021-07-20T10:40:29+00:00",
        "comment_author": "agibsonccc",
        "comment_body": "Fixed log levels.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "412986257",
    "pr_number": 8856,
    "pr_file": "deeplearning4j/deeplearning4j-ui-parent/deeplearning4j-vertx/src/test/java/org/deeplearning4j/ui/TestVertxUIMultiSession.java",
    "created_at": "2020-04-22T13:33:36+00:00",
    "commented_code": "*/\n @Ignore\n public class TestVertxUIMultiSession extends BaseDL4JTest {\n+    private static final Logger log = LoggerFactory.getLogger(TestVertxUIMultiSession.class);",
    "repo_full_name": "deeplearning4j/deeplearning4j",
    "discussion_comments": [
      {
        "comment_id": "412986257",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 8856,
        "pr_file": "deeplearning4j/deeplearning4j-ui-parent/deeplearning4j-vertx/src/test/java/org/deeplearning4j/ui/TestVertxUIMultiSession.java",
        "discussion_id": "412986257",
        "commented_code": "@@ -54,19 +57,25 @@\n  */\n @Ignore\n public class TestVertxUIMultiSession extends BaseDL4JTest {\n+    private static final Logger log = LoggerFactory.getLogger(TestVertxUIMultiSession.class);",
        "comment_created_at": "2020-04-22T13:33:36+00:00",
        "comment_author": "AlexDBlack",
        "comment_body": "Not a big deal - but we can use Lombok `@Slf4j` annotation on the class to get the same thing",
        "pr_file_module": null
      },
      {
        "comment_id": "413142057",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 8856,
        "pr_file": "deeplearning4j/deeplearning4j-ui-parent/deeplearning4j-vertx/src/test/java/org/deeplearning4j/ui/TestVertxUIMultiSession.java",
        "discussion_id": "412986257",
        "commented_code": "@@ -54,19 +57,25 @@\n  */\n @Ignore\n public class TestVertxUIMultiSession extends BaseDL4JTest {\n+    private static final Logger log = LoggerFactory.getLogger(TestVertxUIMultiSession.class);",
        "comment_created_at": "2020-04-22T16:43:31+00:00",
        "comment_author": "printomi",
        "comment_body": "Now using Lombok `@Slf4j` annotation.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "309012772",
    "pr_number": 8050,
    "pr_file": "rl4j/rl4j-core/src/main/java/org/deeplearning4j/rl4j/util/DataManagerSyncTrainingListener.java",
    "created_at": "2019-07-31T02:02:45+00:00",
    "commented_code": "+package org.deeplearning4j.rl4j.util;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.deeplearning4j.rl4j.learning.sync.listener.SyncTrainingEpochEndEvent;\n+import org.deeplearning4j.rl4j.learning.sync.listener.SyncTrainingEvent;\n+import org.deeplearning4j.rl4j.learning.sync.listener.SyncTrainingListener;\n+\n+@Slf4j\n+public class DataManagerSyncTrainingListener implements SyncTrainingListener {\n+    private final IDataManager dataManager;\n+    private final int saveFrequency;\n+    private final int monitorFrequency;\n+\n+    private int lastSave;\n+    private int lastMonitor;\n+\n+    private DataManagerSyncTrainingListener(Builder builder) {\n+        this.dataManager = builder.dataManager;\n+\n+        this.saveFrequency = builder.saveFrequency;\n+        this.lastSave = -builder.saveFrequency;\n+\n+        this.monitorFrequency = builder.monitorFrequency;\n+        this.lastMonitor = -builder.monitorFrequency;\n+    }\n+\n+    @Override\n+    public void onTrainingStart(SyncTrainingEvent event) {\n+        try {\n+            dataManager.writeInfo(event.getLearning());\n+        } catch (Exception e) {\n+            log.error(\"Training failed.\", e);\n+            e.printStackTrace();",
    "repo_full_name": "deeplearning4j/deeplearning4j",
    "discussion_comments": [
      {
        "comment_id": "309012772",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 8050,
        "pr_file": "rl4j/rl4j-core/src/main/java/org/deeplearning4j/rl4j/util/DataManagerSyncTrainingListener.java",
        "discussion_id": "309012772",
        "commented_code": "@@ -0,0 +1,105 @@\n+package org.deeplearning4j.rl4j.util;\n+\n+import lombok.extern.slf4j.Slf4j;\n+import org.deeplearning4j.rl4j.learning.sync.listener.SyncTrainingEpochEndEvent;\n+import org.deeplearning4j.rl4j.learning.sync.listener.SyncTrainingEvent;\n+import org.deeplearning4j.rl4j.learning.sync.listener.SyncTrainingListener;\n+\n+@Slf4j\n+public class DataManagerSyncTrainingListener implements SyncTrainingListener {\n+    private final IDataManager dataManager;\n+    private final int saveFrequency;\n+    private final int monitorFrequency;\n+\n+    private int lastSave;\n+    private int lastMonitor;\n+\n+    private DataManagerSyncTrainingListener(Builder builder) {\n+        this.dataManager = builder.dataManager;\n+\n+        this.saveFrequency = builder.saveFrequency;\n+        this.lastSave = -builder.saveFrequency;\n+\n+        this.monitorFrequency = builder.monitorFrequency;\n+        this.lastMonitor = -builder.monitorFrequency;\n+    }\n+\n+    @Override\n+    public void onTrainingStart(SyncTrainingEvent event) {\n+        try {\n+            dataManager.writeInfo(event.getLearning());\n+        } catch (Exception e) {\n+            log.error(\"Training failed.\", e);\n+            e.printStackTrace();",
        "comment_created_at": "2019-07-31T02:02:45+00:00",
        "comment_author": "AlexDBlack",
        "comment_body": "Don't also print stack trace, log.error will already print it.\r\nAlso other instances below.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "255435277",
    "pr_number": 7141,
    "pr_file": "deeplearning4j/deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/text/tokenization/tokenizer/BertWordPieceStreamTokenizer.java",
    "created_at": "2019-02-11T09:51:58+00:00",
    "commented_code": "+/*******************************************************************************\n+ * Copyright (c) 2015-2018 Skymind, Inc.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Apache License, Version 2.0 which is available at\n+ * https://www.apache.org/licenses/LICENSE-2.0.\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ ******************************************************************************/\n+\n+package org.deeplearning4j.text.tokenization.tokenizer;\n+\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.*;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.NavigableMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * A tokenizer that works with a vocab from a published bert model and tokenizes a token at a time from a stream\n+ * @author Paul Dubs\n+ */\n+public class BertWordPieceStreamTokenizer implements Tokenizer {\n+\n+    private final Pattern splitPattern = Pattern.compile(\"(\\\\p{javaWhitespace}|((?<=\\\\p{Punct})|(?=\\\\p{Punct})))+\");\n+    private final NavigableMap<String, Integer> vocab;\n+    private final Reader reader;\n+    private boolean more = true;\n+    private String buffer = \"\";\n+    private int longestToken = 0;\n+    private String prevRest = null;\n+    private boolean noSplit = false;\n+\n+    private TokenPreProcess tokenPreProcess;\n+    private List<String> tokens = new ArrayList<>();\n+    private AtomicInteger position = new AtomicInteger(0);\n+\n+    protected static final Logger log = LoggerFactory.getLogger(BertWordPieceStreamTokenizer.class);",
    "repo_full_name": "deeplearning4j/deeplearning4j",
    "discussion_comments": [
      {
        "comment_id": "255435277",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 7141,
        "pr_file": "deeplearning4j/deeplearning4j-nlp-parent/deeplearning4j-nlp/src/main/java/org/deeplearning4j/text/tokenization/tokenizer/BertWordPieceStreamTokenizer.java",
        "discussion_id": "255435277",
        "commented_code": "@@ -0,0 +1,182 @@\n+/*******************************************************************************\n+ * Copyright (c) 2015-2018 Skymind, Inc.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Apache License, Version 2.0 which is available at\n+ * https://www.apache.org/licenses/LICENSE-2.0.\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ ******************************************************************************/\n+\n+package org.deeplearning4j.text.tokenization.tokenizer;\n+\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.*;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.NavigableMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * A tokenizer that works with a vocab from a published bert model and tokenizes a token at a time from a stream\n+ * @author Paul Dubs\n+ */\n+public class BertWordPieceStreamTokenizer implements Tokenizer {\n+\n+    private final Pattern splitPattern = Pattern.compile(\"(\\\\p{javaWhitespace}|((?<=\\\\p{Punct})|(?=\\\\p{Punct})))+\");\n+    private final NavigableMap<String, Integer> vocab;\n+    private final Reader reader;\n+    private boolean more = true;\n+    private String buffer = \"\";\n+    private int longestToken = 0;\n+    private String prevRest = null;\n+    private boolean noSplit = false;\n+\n+    private TokenPreProcess tokenPreProcess;\n+    private List<String> tokens = new ArrayList<>();\n+    private AtomicInteger position = new AtomicInteger(0);\n+\n+    protected static final Logger log = LoggerFactory.getLogger(BertWordPieceStreamTokenizer.class);",
        "comment_created_at": "2019-02-11T09:51:58+00:00",
        "comment_author": "AlexDBlack",
        "comment_body": "I'm being picky here - can use ```@Slf4j``` annotation instead.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "214577745",
    "pr_number": 6115,
    "pr_file": "nd4j/nd4j-parameter-server-parent/nd4j-parameter-server-node/src/main/java/org/nd4j/parameterserver/distributed/v2/transport/impl/BaseTransport.java",
    "created_at": "2018-09-03T05:19:57+00:00",
    "commented_code": "+/*******************************************************************************\n+ * Copyright (c) 2015-2018 Skymind, Inc.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Apache License, Version 2.0 which is available at\n+ * https://www.apache.org/licenses/LICENSE-2.0.\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ ******************************************************************************/\n+\n+package org.nd4j.parameterserver.distributed.v2.transport.impl;\n+\n+import io.reactivex.Flowable;\n+import io.reactivex.functions.Consumer;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.jetbrains.annotations.NotNull;\n+import org.nd4j.linalg.exception.ND4JIllegalStateException;\n+import org.nd4j.linalg.primitives.Atomic;\n+import org.nd4j.linalg.primitives.AtomicBoolean;\n+import org.nd4j.linalg.primitives.Optional;\n+import org.nd4j.parameterserver.distributed.conf.VoidConfiguration;\n+import org.nd4j.parameterserver.distributed.v2.enums.MeshBuildMode;\n+import org.nd4j.parameterserver.distributed.v2.chunks.VoidChunk;\n+import org.nd4j.parameterserver.distributed.v2.enums.PropagationMode;\n+import org.nd4j.parameterserver.distributed.v2.messages.*;\n+import org.nd4j.parameterserver.distributed.v2.messages.history.HashHistoryHolder;\n+import org.nd4j.parameterserver.distributed.v2.messages.impl.MeshUpdateMessage;\n+import org.nd4j.parameterserver.distributed.v2.messages.pairs.handshake.HandshakeRequest;\n+import org.nd4j.parameterserver.distributed.v2.messages.pairs.handshake.HandshakeResponse;\n+import org.nd4j.parameterserver.distributed.v2.messages.pairs.ping.PingMessage;\n+import org.nd4j.parameterserver.distributed.v2.messages.pairs.ping.PongMessage;\n+import org.nd4j.parameterserver.distributed.v2.messages.MessagesHistoryHolder;\n+import org.nd4j.parameterserver.distributed.v2.transport.RestartCallback;\n+import org.nd4j.parameterserver.distributed.v2.transport.Transport;\n+import org.nd4j.parameterserver.distributed.v2.util.MeshOrganizer;\n+import org.nd4j.parameterserver.distributed.v2.util.MessageSplitter;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.*;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ *\n+ * @author raver119@gmail.com\n+ */\n+@Slf4j\n+public abstract  class BaseTransport  implements Transport {\n+    // this stream is for delivering messages from this host to other hosts in the network\n+    protected final MessageFlow<VoidMessage> outgoingFlow = new MessageFlow<>();\n+\n+    // this stream is for receiving INDArray messages from the network\n+    protected final MessageFlow<INDArrayMessage> incomingFlow = new MessageFlow<>();\n+\n+    // here we're storing reference to mesh\n+    protected final Atomic<MeshOrganizer> mesh = new Atomic<>();\n+\n+    // this is Id of this Transport instance\n+    protected String id;\n+\n+    // id of the root node is used for initial communication\n+    protected String rootId;\n+\n+    protected boolean masterMode = false;\n+\n+    // this is simple storage for replies\n+    protected final Map<String, ResponseMessage> replies = new ConcurrentHashMap<>();\n+\n+    // dedicated callback for restart messages\n+    protected RestartCallback restartCallback;\n+\n+    // collection of callbacks for connection with ParameterServer implementation\n+    protected Map<String, Consumer> consumers = new HashMap<>();\n+\n+    // just configuration bean\n+    protected final VoidConfiguration voidConfiguration;\n+\n+    protected final MeshBuildMode meshBuildMode = MeshBuildMode.MESH;\n+\n+    // exactly what name says\n+    protected final AtomicInteger numerOfNodes = new AtomicInteger(0);\n+\n+    // this queue handles all incoming messages\n+    protected final TransferQueue<VoidMessage> messageQueue = new LinkedTransferQueue<>();\n+\n+    // MessageSplitter instance that'll be used in this transport\n+    protected MessageSplitter splitter;\n+\n+    // we're keeping Ids of last 2k INDArrayMessages, just to avoid double spending/retransmission\n+    protected MessagesHistoryHolder<String> historyHolder = new HashHistoryHolder<String>(2048);\n+\n+    protected final ThreadPoolExecutor executorService = (ThreadPoolExecutor) Executors.newFixedThreadPool(Math.max(2, Runtime.getRuntime().availableProcessors()), new ThreadFactory() {\n+        @Override\n+        public Thread newThread(@NotNull Runnable r) {\n+            val t = Executors.defaultThreadFactory().newThread(r);\n+            t.setDaemon(true);\n+            return t;\n+        }\n+    });\n+\n+\n+\n+    protected BaseTransport() {\n+        this(java.util.UUID.randomUUID().toString());\n+    }\n+\n+    protected BaseTransport(@NonNull String rootId) {\n+        this(rootId, VoidConfiguration.builder().build());\n+    }\n+\n+    protected BaseTransport(@NonNull String rootId, @NonNull VoidConfiguration voidConfiguration) {\n+        this.mesh.set(new MeshOrganizer(voidConfiguration.getMeshBuildMode()));\n+        this.rootId = rootId;\n+        this.voidConfiguration = voidConfiguration;\n+    }\n+\n+    protected BaseTransport(@NonNull String ownId, @NonNull String rootId, @NonNull VoidConfiguration voidConfiguration) {\n+        this.mesh.set(new MeshOrganizer(voidConfiguration.getMeshBuildMode()));\n+        this.id = ownId;\n+        this.rootId = rootId;\n+        this.voidConfiguration = voidConfiguration;\n+\n+        masterMode = ownId.equalsIgnoreCase(rootId);\n+        if (masterMode) {\n+            this.mesh.get().getRootNode().setId(rootId);\n+        }\n+    }\n+\n+    @Override\n+    public Consumer<VoidMessage> outgoingConsumer() {\n+        return outgoingFlow;\n+    }\n+\n+    @Override\n+    public Publisher<INDArrayMessage> incomingPublisher() {\n+        return incomingFlow;\n+    }\n+\n+    @Override\n+    public String getUpstreamId() {\n+        if (mesh.get().getRootNode().getId().equals(this.id()))\n+            return this.id();\n+\n+        return mesh.get().getNodeById(this.id()).getUpstreamNode().getId();\n+    }\n+\n+    @Override\n+    public synchronized void launch() {\n+        // master mode assumes heartbeat thread, so we'll need one more thread to run there\n+        int lim = masterMode ? 1 : 0;\n+        // we're launching threads for messages processing\n+        for (int e = 0; e< executorService.getMaximumPoolSize() - lim; e++) {\n+            executorService.submit(new Runnable() {\n+                @Override\n+                public void run() {\n+                    while (true) {\n+                        try {\n+                            val message = messageQueue.take();\n+                            if (message != null)\n+                                internalProcessMessage(message);\n+                        } catch (InterruptedException e) {\n+                            break;\n+                        } catch (Exception e) {\n+                            e.printStackTrace();\n+                        }\n+                    }\n+                }\n+            });\n+        }\n+\n+\n+        // this flow gets converted to VoidChunks and sent to upstream and downstreams\n+        val d = Flowable.fromPublisher(outgoingFlow).subscribe(voidMessage -> {\n+            if (mesh.get() == null) {\n+                log.warn(\"Mesh wasn't received yet!\");\n+                return;\n+            }\n+\n+            // we're tagging this message as originated locally\n+            voidMessage.setOriginatorId(id);\n+\n+            // and propagating message across mesh network\n+            propagateMessage(voidMessage, PropagationMode.BOTH_WAYS);\n+        });\n+\n+        // now we're going for Handshake with master\n+        if (!masterMode) {\n+            try {\n+                sendMessageBlocking(new HandshakeRequest(), rootId);\n+            } catch (Exception e) {\n+                throw new ND4JIllegalStateException(\"Can't proceed with handshake from [\" + this.id() + \"] to [\" + rootId + \"]\", e);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public synchronized void launchAsMaster() {\n+        if (mesh.get() == null)\n+            mesh.set(new MeshOrganizer(meshBuildMode));\n+\n+        masterMode = true;\n+        mesh.get().getRootNode().setId(this.id());\n+\n+        // launching heartbeat thread, that will monitor offline nodes\n+        executorService.submit(new HeartbeatThread(120000, this, mesh));\n+\n+        this.launch();\n+    }\n+\n+    @Override\n+    public synchronized void shutdown() {\n+        // shuttng down\n+        executorService.shutdown();\n+    }\n+\n+    protected void propagateArrayMessage(INDArrayMessage message, PropagationMode mode) throws IOException  {\n+        val node = mesh.get().getNodeById(id);\n+\n+        val root = mesh.get().getRootNode();\n+        val upstream = node.getUpstreamNode();\n+        val downstreams = node.getDownstreamNodes();\n+\n+        // TODO: make chunk size configurable\n+        val chunks = splitter.split(message, voidConfiguration.getMaxChunkSize());\n+        // send chunks to the upstream\n+        if (!node.isRootNode() && (PropagationMode.BOTH_WAYS == mode || PropagationMode.ONLY_UP == mode))\n+            chunks.forEach(c -> sendMessage(c, upstream.getId()));\n+\n+        // and send chunks to all downstreams\n+        if (PropagationMode.BOTH_WAYS == mode || PropagationMode.ONLY_DOWN == mode)\n+            downstreams.parallelStream().forEach(n -> {\n+                chunks.forEach(c -> sendMessage(c, n.getId()));\n+            });\n+    }\n+\n+    @Override\n+    public void propagateMessage(@NonNull VoidMessage voidMessage, PropagationMode mode) throws IOException {\n+        val node = mesh.get().getNodeById(id);\n+\n+        //if (voidMessage.getOriginatorId() != null && id != null && voidMessage.getOriginatorId().equals(id))\n+         //   return;\n+\n+        // it's possible situation to have master as regular node. i.e. spark localhost mode\n+        if (mesh.get().totalNodes() == 1) {\n+            internalProcessMessage(voidMessage);\n+            return;\n+        }\n+\n+        val root = mesh.get().getRootNode();\n+        val upstream = node.getUpstreamNode();\n+        val downstreams = node.getDownstreamNodes();\n+\n+        // setting on first one\n+        //if (voidMessage.getOriginatorId() == null)\n+            //voidMessage.setOriginatorId(this.id());\n+\n+        if (voidMessage instanceof BroadcastableMessage) {\n+            ((BroadcastableMessage) voidMessage).setRelayId(id);\n+        }\n+\n+        // if this is INDArrayMessage we'll split it into chunks\n+        if (voidMessage instanceof INDArrayMessage) {\n+            propagateArrayMessage((INDArrayMessage) voidMessage, mode);\n+        } else {\n+            // send message to the upstream\n+            if (!node.isRootNode() && (PropagationMode.BOTH_WAYS == mode || PropagationMode.ONLY_UP == mode))\n+                sendMessage(voidMessage, upstream.getId());\n+\n+            // and send message for all downstreams\n+            if (PropagationMode.BOTH_WAYS == mode || PropagationMode.ONLY_DOWN == mode)\n+                downstreams.forEach(n -> sendMessage(voidMessage, n.getId()));\n+        }\n+    }\n+\n+    protected void propagateBroadcastableMessage(@NonNull BroadcastableMessage voidMessage, PropagationMode mode) {\n+        // we never broadcast MeshUpdates, master will send everyone copy anyway\n+        if (voidMessage instanceof MeshUpdateMessage)\n+           return;\n+\n+        // if this message is already a known one - just skip it\n+        if (historyHolder.storeIfUnknownMessageId(voidMessage.getMessageId()))\n+            return;\n+\n+        val node = mesh.get().getNodeById(id);\n+\n+        if (voidMessage.getOriginatorId() != null && id != null && voidMessage.getOriginatorId().equals(id))\n+            return;\n+\n+        val root = mesh.get().getRootNode();\n+        val upstream = node.getUpstreamNode();\n+        val downstreams = node.getDownstreamNodes();\n+\n+        val ownId = id();\n+        val upstreamId = node.isRootNode() ? null : upstream.getId();\n+        val originatorId = voidMessage.getOriginatorId();\n+        val relayId = voidMessage.getRelayId();\n+        voidMessage.setRelayId(id());\n+\n+        // we never propagate upstream if we're on root node\n+        // we never send to the latest node\n+        // we never send to the original node\n+        if (!node.isRootNode() && (PropagationMode.BOTH_WAYS == mode || PropagationMode.ONLY_UP == mode) && !isLoopedNode(upstream, originatorId, relayId)) {\n+            if (!isLoopedNode(upstream, originatorId, relayId)) {\n+                sendMessage(voidMessage, upstreamId);\n+            }\n+        }\n+\n+        // now we're sending message down\n+        if (PropagationMode.BOTH_WAYS == mode || PropagationMode.ONLY_DOWN == mode) {\n+            downstreams.forEach(n -> {\n+                if (!isLoopedNode(n, originatorId, relayId)) {\n+                    sendMessage(voidMessage, n.getId());\n+                }\n+            });\n+        }\n+    }\n+\n+    protected boolean isLoopedNode(@NonNull MeshOrganizer.Node node, @NonNull String originatorId, @NonNull String relayId) {\n+        return node.getId().equals(originatorId) || node.getId().equals(relayId);\n+    }\n+\n+    /**\n+     * This method puts INDArray to the flow read by parameter server\n+     * @param message\n+     */\n+    private void forwardToParameterServer(INDArrayMessage message) {\n+        try {\n+            incomingFlow.accept(message);\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    protected void internalProcessMessage(VoidMessage message) {\n+        /**\n+         * TODO: we need better isolation here\n+         */\n+        if (message instanceof PingMessage) {\n+\n+            val msg = new PongMessage();\n+            msg.setRequestId(((PingMessage) message).getRequestId());\n+            sendMessage(msg, message.getOriginatorId());\n+        } if (message instanceof PongMessage) {\n+\n+            // do nothing\n+        }  else if (message instanceof VoidChunk) {\n+            // we merge chunks to get full INDArrayMessage\n+            Optional<INDArrayMessage> opt = splitter.merge((VoidChunk) message, voidConfiguration.getChunksBufferSize());\n+\n+            // if this chunk was the last message, we'll forward it to parameter server for actual use\n+            if (opt.isPresent())\n+                this.processMessage(opt.get());\n+        } else if (message instanceof INDArrayMessage) {\n+            // just forward message, but ONLY if it's not a Response message, since it's probably processed separately\n+            if (!(message instanceof ResponseMessage)) {\n+                if (!historyHolder.isKnownMessageId(message.getMessageId())) {// we're not applying the same message twice\n+                    forwardToParameterServer((INDArrayMessage) message);\n+                }\n+            } else {\n+                // in this case we store message to the map, to be fetched later\n+                val reply = (ResponseMessage) message;\n+                replies.putIfAbsent(reply.getRequestId(), reply);\n+            }\n+        } else if (message instanceof HandshakeRequest) {\n+            synchronized (mesh) {\n+                if (!mesh.get().isKnownNode(this.id())) {\n+                    mesh.get().getRootNode().setId(this.id);\n+                }\n+            }\n+\n+            // our response\n+            val response = HandshakeResponse.builder()\n+                    .build();\n+\n+            synchronized (mesh) {\n+                if (mesh.get().isKnownNode(message.getOriginatorId())) {\n+                    mesh.get().remapNodeAndDownstreams(message.getOriginatorId());\n+                    // we say that this model has restarted\n+                    response.setRestart(true);\n+                } else {\n+                    // first we add new node to the mesh\n+                    mesh.get().addNode(message.getOriginatorId());\n+                }\n+\n+                response.setMesh(mesh.get().clone());\n+            }\n+\n+            response.setRequestId(((HandshakeRequest) message).getRequestId());\n+            sendMessage(response, message.getOriginatorId());\n+\n+            // update all other nodes with new mesh\n+            try {\n+                propagateMessageDirect(new MeshUpdateMessage(mesh.get()));\n+            } catch (Exception e) {\n+                log.error(\"Wasn't able to propagate message from [{}]\", id());\n+                e.printStackTrace();",
    "repo_full_name": "deeplearning4j/deeplearning4j",
    "discussion_comments": [
      {
        "comment_id": "214577745",
        "repo_full_name": "deeplearning4j/deeplearning4j",
        "pr_number": 6115,
        "pr_file": "nd4j/nd4j-parameter-server-parent/nd4j-parameter-server-node/src/main/java/org/nd4j/parameterserver/distributed/v2/transport/impl/BaseTransport.java",
        "discussion_id": "214577745",
        "commented_code": "@@ -0,0 +1,670 @@\n+/*******************************************************************************\n+ * Copyright (c) 2015-2018 Skymind, Inc.\n+ *\n+ * This program and the accompanying materials are made available under the\n+ * terms of the Apache License, Version 2.0 which is available at\n+ * https://www.apache.org/licenses/LICENSE-2.0.\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ * SPDX-License-Identifier: Apache-2.0\n+ ******************************************************************************/\n+\n+package org.nd4j.parameterserver.distributed.v2.transport.impl;\n+\n+import io.reactivex.Flowable;\n+import io.reactivex.functions.Consumer;\n+import lombok.NonNull;\n+import lombok.extern.slf4j.Slf4j;\n+import lombok.val;\n+import org.jetbrains.annotations.NotNull;\n+import org.nd4j.linalg.exception.ND4JIllegalStateException;\n+import org.nd4j.linalg.primitives.Atomic;\n+import org.nd4j.linalg.primitives.AtomicBoolean;\n+import org.nd4j.linalg.primitives.Optional;\n+import org.nd4j.parameterserver.distributed.conf.VoidConfiguration;\n+import org.nd4j.parameterserver.distributed.v2.enums.MeshBuildMode;\n+import org.nd4j.parameterserver.distributed.v2.chunks.VoidChunk;\n+import org.nd4j.parameterserver.distributed.v2.enums.PropagationMode;\n+import org.nd4j.parameterserver.distributed.v2.messages.*;\n+import org.nd4j.parameterserver.distributed.v2.messages.history.HashHistoryHolder;\n+import org.nd4j.parameterserver.distributed.v2.messages.impl.MeshUpdateMessage;\n+import org.nd4j.parameterserver.distributed.v2.messages.pairs.handshake.HandshakeRequest;\n+import org.nd4j.parameterserver.distributed.v2.messages.pairs.handshake.HandshakeResponse;\n+import org.nd4j.parameterserver.distributed.v2.messages.pairs.ping.PingMessage;\n+import org.nd4j.parameterserver.distributed.v2.messages.pairs.ping.PongMessage;\n+import org.nd4j.parameterserver.distributed.v2.messages.MessagesHistoryHolder;\n+import org.nd4j.parameterserver.distributed.v2.transport.RestartCallback;\n+import org.nd4j.parameterserver.distributed.v2.transport.Transport;\n+import org.nd4j.parameterserver.distributed.v2.util.MeshOrganizer;\n+import org.nd4j.parameterserver.distributed.v2.util.MessageSplitter;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.*;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.locks.LockSupport;\n+\n+/**\n+ *\n+ * @author raver119@gmail.com\n+ */\n+@Slf4j\n+public abstract  class BaseTransport  implements Transport {\n+    // this stream is for delivering messages from this host to other hosts in the network\n+    protected final MessageFlow<VoidMessage> outgoingFlow = new MessageFlow<>();\n+\n+    // this stream is for receiving INDArray messages from the network\n+    protected final MessageFlow<INDArrayMessage> incomingFlow = new MessageFlow<>();\n+\n+    // here we're storing reference to mesh\n+    protected final Atomic<MeshOrganizer> mesh = new Atomic<>();\n+\n+    // this is Id of this Transport instance\n+    protected String id;\n+\n+    // id of the root node is used for initial communication\n+    protected String rootId;\n+\n+    protected boolean masterMode = false;\n+\n+    // this is simple storage for replies\n+    protected final Map<String, ResponseMessage> replies = new ConcurrentHashMap<>();\n+\n+    // dedicated callback for restart messages\n+    protected RestartCallback restartCallback;\n+\n+    // collection of callbacks for connection with ParameterServer implementation\n+    protected Map<String, Consumer> consumers = new HashMap<>();\n+\n+    // just configuration bean\n+    protected final VoidConfiguration voidConfiguration;\n+\n+    protected final MeshBuildMode meshBuildMode = MeshBuildMode.MESH;\n+\n+    // exactly what name says\n+    protected final AtomicInteger numerOfNodes = new AtomicInteger(0);\n+\n+    // this queue handles all incoming messages\n+    protected final TransferQueue<VoidMessage> messageQueue = new LinkedTransferQueue<>();\n+\n+    // MessageSplitter instance that'll be used in this transport\n+    protected MessageSplitter splitter;\n+\n+    // we're keeping Ids of last 2k INDArrayMessages, just to avoid double spending/retransmission\n+    protected MessagesHistoryHolder<String> historyHolder = new HashHistoryHolder<String>(2048);\n+\n+    protected final ThreadPoolExecutor executorService = (ThreadPoolExecutor) Executors.newFixedThreadPool(Math.max(2, Runtime.getRuntime().availableProcessors()), new ThreadFactory() {\n+        @Override\n+        public Thread newThread(@NotNull Runnable r) {\n+            val t = Executors.defaultThreadFactory().newThread(r);\n+            t.setDaemon(true);\n+            return t;\n+        }\n+    });\n+\n+\n+\n+    protected BaseTransport() {\n+        this(java.util.UUID.randomUUID().toString());\n+    }\n+\n+    protected BaseTransport(@NonNull String rootId) {\n+        this(rootId, VoidConfiguration.builder().build());\n+    }\n+\n+    protected BaseTransport(@NonNull String rootId, @NonNull VoidConfiguration voidConfiguration) {\n+        this.mesh.set(new MeshOrganizer(voidConfiguration.getMeshBuildMode()));\n+        this.rootId = rootId;\n+        this.voidConfiguration = voidConfiguration;\n+    }\n+\n+    protected BaseTransport(@NonNull String ownId, @NonNull String rootId, @NonNull VoidConfiguration voidConfiguration) {\n+        this.mesh.set(new MeshOrganizer(voidConfiguration.getMeshBuildMode()));\n+        this.id = ownId;\n+        this.rootId = rootId;\n+        this.voidConfiguration = voidConfiguration;\n+\n+        masterMode = ownId.equalsIgnoreCase(rootId);\n+        if (masterMode) {\n+            this.mesh.get().getRootNode().setId(rootId);\n+        }\n+    }\n+\n+    @Override\n+    public Consumer<VoidMessage> outgoingConsumer() {\n+        return outgoingFlow;\n+    }\n+\n+    @Override\n+    public Publisher<INDArrayMessage> incomingPublisher() {\n+        return incomingFlow;\n+    }\n+\n+    @Override\n+    public String getUpstreamId() {\n+        if (mesh.get().getRootNode().getId().equals(this.id()))\n+            return this.id();\n+\n+        return mesh.get().getNodeById(this.id()).getUpstreamNode().getId();\n+    }\n+\n+    @Override\n+    public synchronized void launch() {\n+        // master mode assumes heartbeat thread, so we'll need one more thread to run there\n+        int lim = masterMode ? 1 : 0;\n+        // we're launching threads for messages processing\n+        for (int e = 0; e< executorService.getMaximumPoolSize() - lim; e++) {\n+            executorService.submit(new Runnable() {\n+                @Override\n+                public void run() {\n+                    while (true) {\n+                        try {\n+                            val message = messageQueue.take();\n+                            if (message != null)\n+                                internalProcessMessage(message);\n+                        } catch (InterruptedException e) {\n+                            break;\n+                        } catch (Exception e) {\n+                            e.printStackTrace();\n+                        }\n+                    }\n+                }\n+            });\n+        }\n+\n+\n+        // this flow gets converted to VoidChunks and sent to upstream and downstreams\n+        val d = Flowable.fromPublisher(outgoingFlow).subscribe(voidMessage -> {\n+            if (mesh.get() == null) {\n+                log.warn(\"Mesh wasn't received yet!\");\n+                return;\n+            }\n+\n+            // we're tagging this message as originated locally\n+            voidMessage.setOriginatorId(id);\n+\n+            // and propagating message across mesh network\n+            propagateMessage(voidMessage, PropagationMode.BOTH_WAYS);\n+        });\n+\n+        // now we're going for Handshake with master\n+        if (!masterMode) {\n+            try {\n+                sendMessageBlocking(new HandshakeRequest(), rootId);\n+            } catch (Exception e) {\n+                throw new ND4JIllegalStateException(\"Can't proceed with handshake from [\" + this.id() + \"] to [\" + rootId + \"]\", e);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public synchronized void launchAsMaster() {\n+        if (mesh.get() == null)\n+            mesh.set(new MeshOrganizer(meshBuildMode));\n+\n+        masterMode = true;\n+        mesh.get().getRootNode().setId(this.id());\n+\n+        // launching heartbeat thread, that will monitor offline nodes\n+        executorService.submit(new HeartbeatThread(120000, this, mesh));\n+\n+        this.launch();\n+    }\n+\n+    @Override\n+    public synchronized void shutdown() {\n+        // shuttng down\n+        executorService.shutdown();\n+    }\n+\n+    protected void propagateArrayMessage(INDArrayMessage message, PropagationMode mode) throws IOException  {\n+        val node = mesh.get().getNodeById(id);\n+\n+        val root = mesh.get().getRootNode();\n+        val upstream = node.getUpstreamNode();\n+        val downstreams = node.getDownstreamNodes();\n+\n+        // TODO: make chunk size configurable\n+        val chunks = splitter.split(message, voidConfiguration.getMaxChunkSize());\n+        // send chunks to the upstream\n+        if (!node.isRootNode() && (PropagationMode.BOTH_WAYS == mode || PropagationMode.ONLY_UP == mode))\n+            chunks.forEach(c -> sendMessage(c, upstream.getId()));\n+\n+        // and send chunks to all downstreams\n+        if (PropagationMode.BOTH_WAYS == mode || PropagationMode.ONLY_DOWN == mode)\n+            downstreams.parallelStream().forEach(n -> {\n+                chunks.forEach(c -> sendMessage(c, n.getId()));\n+            });\n+    }\n+\n+    @Override\n+    public void propagateMessage(@NonNull VoidMessage voidMessage, PropagationMode mode) throws IOException {\n+        val node = mesh.get().getNodeById(id);\n+\n+        //if (voidMessage.getOriginatorId() != null && id != null && voidMessage.getOriginatorId().equals(id))\n+         //   return;\n+\n+        // it's possible situation to have master as regular node. i.e. spark localhost mode\n+        if (mesh.get().totalNodes() == 1) {\n+            internalProcessMessage(voidMessage);\n+            return;\n+        }\n+\n+        val root = mesh.get().getRootNode();\n+        val upstream = node.getUpstreamNode();\n+        val downstreams = node.getDownstreamNodes();\n+\n+        // setting on first one\n+        //if (voidMessage.getOriginatorId() == null)\n+            //voidMessage.setOriginatorId(this.id());\n+\n+        if (voidMessage instanceof BroadcastableMessage) {\n+            ((BroadcastableMessage) voidMessage).setRelayId(id);\n+        }\n+\n+        // if this is INDArrayMessage we'll split it into chunks\n+        if (voidMessage instanceof INDArrayMessage) {\n+            propagateArrayMessage((INDArrayMessage) voidMessage, mode);\n+        } else {\n+            // send message to the upstream\n+            if (!node.isRootNode() && (PropagationMode.BOTH_WAYS == mode || PropagationMode.ONLY_UP == mode))\n+                sendMessage(voidMessage, upstream.getId());\n+\n+            // and send message for all downstreams\n+            if (PropagationMode.BOTH_WAYS == mode || PropagationMode.ONLY_DOWN == mode)\n+                downstreams.forEach(n -> sendMessage(voidMessage, n.getId()));\n+        }\n+    }\n+\n+    protected void propagateBroadcastableMessage(@NonNull BroadcastableMessage voidMessage, PropagationMode mode) {\n+        // we never broadcast MeshUpdates, master will send everyone copy anyway\n+        if (voidMessage instanceof MeshUpdateMessage)\n+           return;\n+\n+        // if this message is already a known one - just skip it\n+        if (historyHolder.storeIfUnknownMessageId(voidMessage.getMessageId()))\n+            return;\n+\n+        val node = mesh.get().getNodeById(id);\n+\n+        if (voidMessage.getOriginatorId() != null && id != null && voidMessage.getOriginatorId().equals(id))\n+            return;\n+\n+        val root = mesh.get().getRootNode();\n+        val upstream = node.getUpstreamNode();\n+        val downstreams = node.getDownstreamNodes();\n+\n+        val ownId = id();\n+        val upstreamId = node.isRootNode() ? null : upstream.getId();\n+        val originatorId = voidMessage.getOriginatorId();\n+        val relayId = voidMessage.getRelayId();\n+        voidMessage.setRelayId(id());\n+\n+        // we never propagate upstream if we're on root node\n+        // we never send to the latest node\n+        // we never send to the original node\n+        if (!node.isRootNode() && (PropagationMode.BOTH_WAYS == mode || PropagationMode.ONLY_UP == mode) && !isLoopedNode(upstream, originatorId, relayId)) {\n+            if (!isLoopedNode(upstream, originatorId, relayId)) {\n+                sendMessage(voidMessage, upstreamId);\n+            }\n+        }\n+\n+        // now we're sending message down\n+        if (PropagationMode.BOTH_WAYS == mode || PropagationMode.ONLY_DOWN == mode) {\n+            downstreams.forEach(n -> {\n+                if (!isLoopedNode(n, originatorId, relayId)) {\n+                    sendMessage(voidMessage, n.getId());\n+                }\n+            });\n+        }\n+    }\n+\n+    protected boolean isLoopedNode(@NonNull MeshOrganizer.Node node, @NonNull String originatorId, @NonNull String relayId) {\n+        return node.getId().equals(originatorId) || node.getId().equals(relayId);\n+    }\n+\n+    /**\n+     * This method puts INDArray to the flow read by parameter server\n+     * @param message\n+     */\n+    private void forwardToParameterServer(INDArrayMessage message) {\n+        try {\n+            incomingFlow.accept(message);\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    protected void internalProcessMessage(VoidMessage message) {\n+        /**\n+         * TODO: we need better isolation here\n+         */\n+        if (message instanceof PingMessage) {\n+\n+            val msg = new PongMessage();\n+            msg.setRequestId(((PingMessage) message).getRequestId());\n+            sendMessage(msg, message.getOriginatorId());\n+        } if (message instanceof PongMessage) {\n+\n+            // do nothing\n+        }  else if (message instanceof VoidChunk) {\n+            // we merge chunks to get full INDArrayMessage\n+            Optional<INDArrayMessage> opt = splitter.merge((VoidChunk) message, voidConfiguration.getChunksBufferSize());\n+\n+            // if this chunk was the last message, we'll forward it to parameter server for actual use\n+            if (opt.isPresent())\n+                this.processMessage(opt.get());\n+        } else if (message instanceof INDArrayMessage) {\n+            // just forward message, but ONLY if it's not a Response message, since it's probably processed separately\n+            if (!(message instanceof ResponseMessage)) {\n+                if (!historyHolder.isKnownMessageId(message.getMessageId())) {// we're not applying the same message twice\n+                    forwardToParameterServer((INDArrayMessage) message);\n+                }\n+            } else {\n+                // in this case we store message to the map, to be fetched later\n+                val reply = (ResponseMessage) message;\n+                replies.putIfAbsent(reply.getRequestId(), reply);\n+            }\n+        } else if (message instanceof HandshakeRequest) {\n+            synchronized (mesh) {\n+                if (!mesh.get().isKnownNode(this.id())) {\n+                    mesh.get().getRootNode().setId(this.id);\n+                }\n+            }\n+\n+            // our response\n+            val response = HandshakeResponse.builder()\n+                    .build();\n+\n+            synchronized (mesh) {\n+                if (mesh.get().isKnownNode(message.getOriginatorId())) {\n+                    mesh.get().remapNodeAndDownstreams(message.getOriginatorId());\n+                    // we say that this model has restarted\n+                    response.setRestart(true);\n+                } else {\n+                    // first we add new node to the mesh\n+                    mesh.get().addNode(message.getOriginatorId());\n+                }\n+\n+                response.setMesh(mesh.get().clone());\n+            }\n+\n+            response.setRequestId(((HandshakeRequest) message).getRequestId());\n+            sendMessage(response, message.getOriginatorId());\n+\n+            // update all other nodes with new mesh\n+            try {\n+                propagateMessageDirect(new MeshUpdateMessage(mesh.get()));\n+            } catch (Exception e) {\n+                log.error(\"Wasn't able to propagate message from [{}]\", id());\n+                e.printStackTrace();",
        "comment_created_at": "2018-09-03T05:19:57+00:00",
        "comment_author": "AlexDBlack",
        "comment_body": "Put exception as log.error arg",
        "pr_file_module": null
      }
    ]
  }
]