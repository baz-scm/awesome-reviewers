[
  {
    "discussion_id": "2193622267",
    "pr_number": 30029,
    "pr_file": "ext/net/tunnel.rs",
    "created_at": "2025-07-08T23:30:38+00:00",
    "commented_code": "use deno_tls::TlsKeys;\n use deno_tls::create_client_config;\n use deno_tls::rustls::RootCertStore;\n+pub use quinn;\n use quinn::ConnectionError;",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "2193622267",
        "repo_full_name": "denoland/deno",
        "pr_number": 30029,
        "pr_file": "ext/net/tunnel.rs",
        "discussion_id": "2193622267",
        "commented_code": "@@ -21,6 +21,7 @@ use deno_tls::SocketUse;\n use deno_tls::TlsKeys;\n use deno_tls::create_client_config;\n use deno_tls::rustls::RootCertStore;\n+pub use quinn;\n use quinn::ConnectionError;",
        "comment_created_at": "2025-07-08T23:30:38+00:00",
        "comment_author": "dsherret",
        "comment_body": "Nitpick: Maybe just reexport `quinn::ConnectionError` to not leak this detail to the rest of the code?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2155719746",
    "pr_number": 29811,
    "pr_file": "ext/node/ops/require.rs",
    "created_at": "2025-06-18T23:35:36+00:00",
    "commented_code": "Ok(canonicalized_path.to_string_lossy().into_owned())\n }\n \n+#[op2]\n+#[string]\n+pub fn op_require_fallback_resolve<\n+  TInNpmPackageChecker: InNpmPackageChecker + 'static,\n+  TNpmPackageFolderResolver: NpmPackageFolderResolver + 'static,\n+  TSys: ExtNodeSys + 'static,\n+>(\n+  state: &mut OpState,\n+  #[string] request: String,\n+  #[string] parent_filename: Option<String>,\n+) -> Result<String, RequireError> {\n+  let resolver = state.borrow::<crate::DenoResolverRc<\n+    TInNpmPackageChecker,\n+    TNpmPackageFolderResolver,\n+    TSys,\n+  >>();\n+  let graph_container = state.borrow::<crate::GraphContainerWrapper>();",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "2155719746",
        "repo_full_name": "denoland/deno",
        "pr_number": 29811,
        "pr_file": "ext/node/ops/require.rs",
        "discussion_id": "2155719746",
        "commented_code": "@@ -401,6 +402,53 @@ pub fn op_require_real_path<\n   Ok(canonicalized_path.to_string_lossy().into_owned())\n }\n \n+#[op2]\n+#[string]\n+pub fn op_require_fallback_resolve<\n+  TInNpmPackageChecker: InNpmPackageChecker + 'static,\n+  TNpmPackageFolderResolver: NpmPackageFolderResolver + 'static,\n+  TSys: ExtNodeSys + 'static,\n+>(\n+  state: &mut OpState,\n+  #[string] request: String,\n+  #[string] parent_filename: Option<String>,\n+) -> Result<String, RequireError> {\n+  let resolver = state.borrow::<crate::DenoResolverRc<\n+    TInNpmPackageChecker,\n+    TNpmPackageFolderResolver,\n+    TSys,\n+  >>();\n+  let graph_container = state.borrow::<crate::GraphContainerWrapper>();",
        "comment_created_at": "2025-06-18T23:35:36+00:00",
        "comment_author": "dsherret",
        "comment_body": "It's probably too much to expose all the way down here and also it creates a dependency on deno_graph for Deploy as well as `deno compile`. Probably we should have a trait that gets passed down here and then the CLI and deno compile can implement this separately (maybe just put it as a method on `NodeRequireLoader`)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1342192944",
    "pr_number": 20695,
    "pr_file": "cli/tools/repl/session.rs",
    "created_at": "2023-10-01T21:52:46+00:00",
    "commented_code": "}\n   }\n }\n+\n+fn parse_source_as(\n+  source: String,\n+  media_type: deno_ast::MediaType,\n+) -> Result<deno_ast::ParsedSource, AnyError> {\n+  let specifier = if media_type == deno_ast::MediaType::Tsx {\n+    \"repl.tsx\"\n+  } else {\n+    \"repl.ts\"\n+  };\n+\n+  let parsed = deno_ast::parse_module(deno_ast::ParseParams {\n+    specifier: specifier.to_string(),\n+    text_info: deno_ast::SourceTextInfo::from_string(source),\n+    media_type,\n+    capture_tokens: true,\n+    maybe_syntax: None,\n+    scope_analysis: false,\n+  })?;\n+\n+  Ok(parsed)\n+}\n+\n+/// Matches the `@jsxImportSource` pragma.\n+static JSX_IMPORT_SOURCE_RE: Lazy<Regex> =",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "1342192944",
        "repo_full_name": "denoland/deno",
        "pr_number": 20695,
        "pr_file": "cli/tools/repl/session.rs",
        "discussion_id": "1342192944",
        "commented_code": "@@ -626,3 +733,120 @@ impl Visit for ImportCollector {\n     }\n   }\n }\n+\n+fn parse_source_as(\n+  source: String,\n+  media_type: deno_ast::MediaType,\n+) -> Result<deno_ast::ParsedSource, AnyError> {\n+  let specifier = if media_type == deno_ast::MediaType::Tsx {\n+    \"repl.tsx\"\n+  } else {\n+    \"repl.ts\"\n+  };\n+\n+  let parsed = deno_ast::parse_module(deno_ast::ParseParams {\n+    specifier: specifier.to_string(),\n+    text_info: deno_ast::SourceTextInfo::from_string(source),\n+    media_type,\n+    capture_tokens: true,\n+    maybe_syntax: None,\n+    scope_analysis: false,\n+  })?;\n+\n+  Ok(parsed)\n+}\n+\n+/// Matches the `@jsxImportSource` pragma.\n+static JSX_IMPORT_SOURCE_RE: Lazy<Regex> =",
        "comment_created_at": "2023-10-01T21:52:46+00:00",
        "comment_author": "dsherret",
        "comment_body": "Before we merge this, we should open a PR in deno_graph to expose these and then add a todo here to remove this code.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2129104760",
    "pr_number": 29622,
    "pr_file": "resolvers/node/resolution.rs",
    "created_at": "2025-06-05T15:17:30+00:00",
    "commented_code": "&[Cow::Borrowed(\"require\"), Cow::Borrowed(\"node\")];\n static TYPES_ONLY_CONDITIONS: &[Cow<'static, str>] = &[Cow::Borrowed(\"types\")];\n \n-#[derive(Debug, Clone)]\n-pub struct ConditionResolverOptions {\n+#[derive(Debug, Default, Clone)]\n+pub struct ConditionOptions {\n   pub conditions: Vec<Cow<'static, str>>,\n-  pub default_import_conditions: Vec<Cow<'static, str>>,\n-  pub default_require_conditions: Vec<Cow<'static, str>>,\n-}\n-\n-impl Default for ConditionResolverOptions {\n-  fn default() -> Self {\n-    Self {\n-      conditions: Vec::new(),\n-      default_import_conditions: DEFAULT_CONDITIONS.to_vec(),\n-      default_require_conditions: REQUIRE_CONDITIONS.to_vec(),\n-    }\n-  }\n+  /// Provide a value to override the default import conditions.\n+  ///\n+  /// Defaults to `[\"deno\", \"node\", \"import\"]`\n+  pub import_conditions_override: Option<Vec<Cow<'static, str>>>,\n+  /// Provide a value to override the default require conditions.\n+  ///\n+  /// Defaults to `[\"require\", \"node\"]`\n+  pub require_conditions_override: Option<Vec<Cow<'static, str>>>,\n }\n \n #[derive(Debug, Clone)]\n-pub struct ConditionResolver {\n-  import_conditions: Vec<Cow<'static, str>>,\n-  require_conditions: Vec<Cow<'static, str>>,\n-}\n-\n-impl Default for ConditionResolver {\n-  fn default() -> Self {\n-    Self::new(Default::default())\n-  }\n+struct ConditionResolver {",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "2129104760",
        "repo_full_name": "denoland/deno",
        "pr_number": 29622,
        "pr_file": "resolvers/node/resolution.rs",
        "discussion_id": "2129104760",
        "commented_code": "@@ -70,57 +70,62 @@ pub static REQUIRE_CONDITIONS: &[Cow<'static, str>] =\n   &[Cow::Borrowed(\"require\"), Cow::Borrowed(\"node\")];\n static TYPES_ONLY_CONDITIONS: &[Cow<'static, str>] = &[Cow::Borrowed(\"types\")];\n \n-#[derive(Debug, Clone)]\n-pub struct ConditionResolverOptions {\n+#[derive(Debug, Default, Clone)]\n+pub struct ConditionOptions {\n   pub conditions: Vec<Cow<'static, str>>,\n-  pub default_import_conditions: Vec<Cow<'static, str>>,\n-  pub default_require_conditions: Vec<Cow<'static, str>>,\n-}\n-\n-impl Default for ConditionResolverOptions {\n-  fn default() -> Self {\n-    Self {\n-      conditions: Vec::new(),\n-      default_import_conditions: DEFAULT_CONDITIONS.to_vec(),\n-      default_require_conditions: REQUIRE_CONDITIONS.to_vec(),\n-    }\n-  }\n+  /// Provide a value to override the default import conditions.\n+  ///\n+  /// Defaults to `[\"deno\", \"node\", \"import\"]`\n+  pub import_conditions_override: Option<Vec<Cow<'static, str>>>,\n+  /// Provide a value to override the default require conditions.\n+  ///\n+  /// Defaults to `[\"require\", \"node\"]`\n+  pub require_conditions_override: Option<Vec<Cow<'static, str>>>,\n }\n \n #[derive(Debug, Clone)]\n-pub struct ConditionResolver {\n-  import_conditions: Vec<Cow<'static, str>>,\n-  require_conditions: Vec<Cow<'static, str>>,\n-}\n-\n-impl Default for ConditionResolver {\n-  fn default() -> Self {\n-    Self::new(Default::default())\n-  }\n+struct ConditionResolver {",
        "comment_created_at": "2025-06-05T15:17:30+00:00",
        "comment_author": "dsherret",
        "comment_body": "I noticed we don't need to expose this and only need to expose the options. Saves having to import one extra type in the caller.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2067382080",
    "pr_number": 28424,
    "pr_file": "cli/tools/clean.rs",
    "created_at": "2025-04-29T20:32:40+00:00",
    "commented_code": "Ok(())\n }\n \n+#[derive(Clone, Debug, Default)]\n+struct PathNode {\n+  exact: bool,\n+  children: BTreeMap<OsString, usize>,\n+}\n+#[derive(Debug)]\n+struct PathTrie {\n+  root: usize,\n+  nodes: Vec<PathNode>,\n+  rewrites: Vec<(PathBuf, PathBuf)>,\n+}\n+\n+#[derive(Clone, Copy, PartialEq, Eq, Debug)]\n+enum Found {\n+  Match,\n+  Prefix,\n+}\n+\n+impl PathTrie {\n+  fn new() -> Self {\n+    Self {\n+      root: 0,\n+      nodes: vec![PathNode {\n+        exact: false,\n+        children: Default::default(),\n+      }],\n+      rewrites: vec![],\n+    }\n+  }\n+  fn add_rewrite(&mut self, from: PathBuf, to: PathBuf) {\n+    self.rewrites.push((from, to));\n+  }\n+  fn rewrite(&self, s: &Path) -> PathBuf {\n+    let normalized = deno_path_util::normalize_path(s);\n+    for (from, to) in &self.rewrites {\n+      if normalized.starts_with(from) {\n+        return to.join(normalized.strip_prefix(from).unwrap());\n+      }\n+    }\n+    normalized\n+  }\n+  fn insert(&mut self, s: &Path) {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        let id = self.nodes.len();\n+        self.nodes.push(PathNode::default());\n+        self.nodes[node]\n+          .children\n+          .insert(component.to_os_string(), id);\n+        node = id;\n+      }\n+    }\n+\n+    self.nodes[node].exact = true;\n+  }\n+\n+  fn find(&self, s: &Path) -> Option<Found> {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        return None;\n+      }\n+    }\n+\n+    Some(if self.nodes[node].exact {\n+      Found::Match\n+    } else {\n+      Found::Prefix\n+    })\n+  }\n+}\n+\n+fn try_get_canonicalized_root_dir<Sys: FsCanonicalize + FsCreateDirAll>(\n+  sys: &Sys,\n+  root_dir: &Path,\n+) -> Result<PathBuf, std::io::Error> {\n+  match sys.fs_canonicalize(root_dir) {\n+    Ok(path) => Ok(path),\n+    Err(err) if err.kind() == std::io::ErrorKind::NotFound => {\n+      sys.fs_create_dir_all(root_dir)?;\n+      sys.fs_canonicalize(root_dir)\n+    }\n+    Err(err) => Err(err),\n+  }\n+}\n+\n+async fn clean_except(\n+  flags: Arc<Flags>,\n+  entrypoints: &[String],\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut state = CleanState::default();\n+\n+  let factory = CliFactory::from_flags(flags.clone());\n+  let sys = factory.sys();\n+  let options = factory.cli_options()?;\n+  let main_graph_container = factory.main_module_graph_container().await?;\n+  let roots = main_graph_container.collect_specifiers(entrypoints)?;\n+  let http_cache = factory.global_http_cache()?;\n+  let local_or_global_http_cache = factory.http_cache()?.clone();\n+  let deno_dir = factory.deno_dir()?.clone();\n+  let deno_dir_root_canonical =\n+    try_get_canonicalized_root_dir(&sys, &deno_dir.root)\n+      .unwrap_or(deno_dir.root.clone());\n+\n+  let mut permit = main_graph_container.acquire_update_permit().await;\n+  let graph = permit.graph_mut();\n+  graph.packages = PackageSpecifiers::default();\n+  let graph_builder = factory.module_graph_builder().await?;\n+  graph_builder\n+    .build_graph_with_npm_resolution(\n+      graph,\n+      CreateGraphOptions {\n+        // loader: Some(&mut NoLoader),\n+        loader: None,\n+        graph_kind: graph.graph_kind(),\n+        is_dynamic: false,\n+        roots: roots.clone(),\n+        npm_caching: crate::graph_util::NpmCachingStrategy::Manual,\n+      },\n+    )\n+    .await?;\n+\n+  let npm_resolver = factory.npm_resolver().await?;\n+\n+  let mut keep = HashSet::new();\n+  let mut npm_reqs = Vec::new();\n+\n+  let mut keep_paths_trie = PathTrie::new();\n+  if deno_dir_root_canonical != deno_dir.root {\n+    keep_paths_trie\n+      .add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical.clone());\n+  }\n+  for (_, entry) in graph.walk(\n+    roots.iter(),\n+    deno_graph::WalkOptions {\n+      check_js: deno_graph::CheckJsOption::False,\n+      follow_dynamic: true,\n+      kind: graph.graph_kind(),\n+      prefer_fast_check_graph: false,\n+    },\n+  ) {\n+    match entry {\n+      deno_graph::ModuleEntryRef::Module(module) => match module {\n+        deno_graph::Module::Js(js_module) => {\n+          keep.insert(&js_module.specifier);\n+        }\n+        deno_graph::Module::Json(json_module) => {\n+          keep.insert(&json_module.specifier);\n+        }\n+        deno_graph::Module::Wasm(wasm_module) => {\n+          keep.insert(&wasm_module.specifier);\n+        }\n+        deno_graph::Module::Npm(npm_module) => {\n+          if let Some(managed) = npm_resolver.as_managed() {\n+            let id = managed\n+              .resolution()\n+              .resolve_pkg_id_from_deno_module(npm_module.nv_reference.nv())\n+              .unwrap();\n+            npm_reqs\n+              .extend(managed.resolution().resolve_pkg_reqs_from_pkg_id(&id));\n+          }\n+        }\n+        deno_graph::Module::Node(_) => {}\n+        deno_graph::Module::External(_) => {}\n+      },\n+      deno_graph::ModuleEntryRef::Err(_) => {}\n+      deno_graph::ModuleEntryRef::Redirect(_) => {}\n+    }\n+  }\n+\n+  for url in &keep {\n+    if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+      if let Ok(path) = http_cache.local_path_for_url(url) {\n+        keep_paths_trie.insert(&path);\n+      }\n+    }\n+    if let Some(path) = deno_dir\n+      .gen_cache\n+      .get_cache_filename_with_extension(url, \"js\")\n+    {\n+      let path = deno_dir.gen_cache.location.join(path);\n+      keep_paths_trie.insert(&path);\n+    }\n+  }\n+\n+  let npm_cache = factory.npm_cache()?;\n+  let snap = npm_resolver.as_managed().unwrap().resolution().snapshot();\n+  // TODO(nathanwhit): remove once we don't need packuments for creating the snapshot from lockfile\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    keep_paths_trie.insert(\n+      &npm_cache\n+        .package_name_folder(&package.id.nv.name)\n+        .join(\"registry.json\"),\n+    );\n+  }\n+  let snap = snap.subset(&npm_reqs);\n+  let node_modules_path = npm_resolver.root_node_modules_path();\n+  let mut node_modules_keep = HashSet::new();\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    if node_modules_path.is_some() {\n+      node_modules_keep.insert(package.get_package_cache_folder_id());\n+    }\n+    keep_paths_trie.insert(&npm_cache.package_folder_for_id(\n+      &deno_npm::NpmPackageCacheFolderId {\n+        nv: package.id.nv.clone(),\n+        copy_index: package.copy_index,\n+      },\n+    ));\n+  }\n+\n+  let jsr_url = crate::args::jsr_url();\n+  add_jsr_meta_paths(graph, &mut keep_paths_trie, jsr_url, &|url| {\n+    http_cache.local_path_for_url(url).map_err(Into::into)\n+  })?;\n+  walk_removing(\n+    &mut state,\n+    walkdir::WalkDir::new(&deno_dir.root)\n+      .contents_first(false)\n+      .min_depth(2),\n+    &keep_paths_trie,\n+    &deno_dir.root,\n+    dry_run,\n+  )?;\n+  let mut node_modules_cleaned = CleanState::default();\n+\n+  if let Some(dir) = node_modules_path {\n+    // let npm_installer = factory.npm_installer_if_managed().await?.unwrap();\n+    // npm_installer.\n+    // let npm_installer = npm_installer.as_local().unwrap();\n+    clean_node_modules(\n+      &mut node_modules_cleaned,\n+      &node_modules_keep,\n+      dir,\n+      dry_run,\n+    )?;\n+  }\n+\n+  let mut vendor_cleaned = CleanState::default();\n+  if let Some(vendor_dir) = options.vendor_dir_path() {\n+    if let GlobalOrLocalHttpCache::Local(cache) = local_or_global_http_cache {\n+      let mut trie = PathTrie::new();\n+      if deno_dir_root_canonical != deno_dir.root {\n+        trie.add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical);\n+      }\n+      let cache = cache.clone();\n+      add_jsr_meta_paths(graph, &mut trie, jsr_url, &|_url| {\n+        if let Ok(Some(path)) = cache.local_path_for_url(_url) {\n+          Ok(path)\n+        } else {\n+          panic!(\"should not happen\")\n+        }\n+      })?;\n+      for url in keep {\n+        if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+          if let Ok(Some(path)) = cache.local_path_for_url(url) {\n+            trie.insert(&path);\n+          } else {\n+            panic!(\"should not happen\")\n+          }\n+        }\n+      }\n+\n+      walk_removing(\n+        &mut vendor_cleaned,\n+        WalkDir::new(vendor_dir).contents_first(false),\n+        &trie,\n+        vendor_dir,\n+        dry_run,\n+      )?;\n+    }\n+  }\n+\n+  if !dry_run {\n+    log_stats(&state, &deno_dir.root);\n+\n+    if let Some(dir) = node_modules_path {\n+      log_stats(&node_modules_cleaned, dir);\n+    }\n+    if let Some(dir) = options.vendor_dir_path() {\n+      log_stats(&vendor_cleaned, dir);\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn log_stats(state: &CleanState, dir: &Path) {\n+  if state.bytes_removed == 0\n+    && state.dirs_removed == 0\n+    && state.files_removed == 0\n+  {\n+    return;\n+  }\n+  log::info!(\n+    \"{} {}\",\n+    colors::green(\"Removed\"),\n+    colors::gray(&format!(\n+      \"{} files, {} from {}\",\n+      state.files_removed + state.dirs_removed,\n+      display::human_size(state.bytes_removed as f64),\n+      dir.display()\n+    ))\n+  );\n+}\n+\n+fn add_jsr_meta_paths(\n+  graph: &ModuleGraph,\n+  path_trie: &mut PathTrie,\n+  jsr_url: &Url,\n+  url_to_path: &dyn Fn(&Url) -> Result<PathBuf, AnyError>,\n+) -> Result<(), AnyError> {\n+  for package in graph.packages.mappings().values() {\n+    let Ok(base_url) = jsr_url.join(&format!(\"{}/\", &package.name)) else {\n+      continue;\n+    };\n+    let keep = url_to_path(&base_url.join(\"meta.json\").unwrap())?;\n+    path_trie.insert(&keep);\n+    let keep = url_to_path(\n+      &base_url\n+        .join(&format!(\"{}_meta.json\", package.version))\n+        .unwrap(),\n+    )?;\n+    path_trie.insert(&keep);\n+  }\n+  Ok(())\n+}\n+\n+fn walk_removing(\n+  state: &mut CleanState,\n+  walker: WalkDir,\n+  trie: &PathTrie,\n+  base: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut walker = walker.into_iter();\n+  while let Some(entry) = walker.next() {\n+    let entry = entry?;\n+    if let Some(found) = trie.find(entry.path()) {\n+      if entry.file_type().is_dir() && matches!(found, Found::Match) {\n+        walker.skip_current_dir();\n+        continue;\n+      }\n+      continue;\n+    }\n+    if !entry.path().starts_with(base) {\n+      panic!(\"VERY BAD\");\n+    }\n+    if entry.file_type().is_dir() {\n+      if dry_run {\n+        #[allow(clippy::print_stderr)]\n+        {\n+          eprintln!(\"would remove dir: {}\", entry.path().display());\n+        }\n+      } else {\n+        rm_rf(state, entry.path())?;\n+      }\n+      walker.skip_current_dir();\n+    } else if dry_run {\n+      #[allow(clippy::print_stderr)]\n+      {\n+        eprintln!(\"would remove file: {}\", entry.path().display());\n+      }\n+    } else {\n+      remove_file(state, entry.path(), Some(entry.metadata()?))?;\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn clean_node_modules(\n+  state: &mut CleanState,\n+  keep_pkgs: &HashSet<deno_npm::NpmPackageCacheFolderId>,\n+  dir: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  if !dir.ends_with(\"node_modules\") || !dir.is_dir() {\n+    bail!(\"not a node_modules directory\");\n+  }\n+  let base = dir.join(\".deno\");\n+  if !base.exists() {\n+    return Ok(());\n+  }\n+\n+  let keep_names = keep_pkgs\n+    .iter()\n+    .map(deno_resolver::npm::get_package_folder_id_folder_name)\n+    .collect::<HashSet<_>>();\n+\n+  // TODO(nathanwhit): this probably shouldn't reach directly into this code",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "2067382080",
        "repo_full_name": "denoland/deno",
        "pr_number": 28424,
        "pr_file": "cli/tools/clean.rs",
        "discussion_id": "2067382080",
        "commented_code": "@@ -69,6 +92,502 @@ pub fn clean(flags: Arc<Flags>) -> Result<(), AnyError> {\n   Ok(())\n }\n \n+#[derive(Clone, Debug, Default)]\n+struct PathNode {\n+  exact: bool,\n+  children: BTreeMap<OsString, usize>,\n+}\n+#[derive(Debug)]\n+struct PathTrie {\n+  root: usize,\n+  nodes: Vec<PathNode>,\n+  rewrites: Vec<(PathBuf, PathBuf)>,\n+}\n+\n+#[derive(Clone, Copy, PartialEq, Eq, Debug)]\n+enum Found {\n+  Match,\n+  Prefix,\n+}\n+\n+impl PathTrie {\n+  fn new() -> Self {\n+    Self {\n+      root: 0,\n+      nodes: vec![PathNode {\n+        exact: false,\n+        children: Default::default(),\n+      }],\n+      rewrites: vec![],\n+    }\n+  }\n+  fn add_rewrite(&mut self, from: PathBuf, to: PathBuf) {\n+    self.rewrites.push((from, to));\n+  }\n+  fn rewrite(&self, s: &Path) -> PathBuf {\n+    let normalized = deno_path_util::normalize_path(s);\n+    for (from, to) in &self.rewrites {\n+      if normalized.starts_with(from) {\n+        return to.join(normalized.strip_prefix(from).unwrap());\n+      }\n+    }\n+    normalized\n+  }\n+  fn insert(&mut self, s: &Path) {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        let id = self.nodes.len();\n+        self.nodes.push(PathNode::default());\n+        self.nodes[node]\n+          .children\n+          .insert(component.to_os_string(), id);\n+        node = id;\n+      }\n+    }\n+\n+    self.nodes[node].exact = true;\n+  }\n+\n+  fn find(&self, s: &Path) -> Option<Found> {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        return None;\n+      }\n+    }\n+\n+    Some(if self.nodes[node].exact {\n+      Found::Match\n+    } else {\n+      Found::Prefix\n+    })\n+  }\n+}\n+\n+fn try_get_canonicalized_root_dir<Sys: FsCanonicalize + FsCreateDirAll>(\n+  sys: &Sys,\n+  root_dir: &Path,\n+) -> Result<PathBuf, std::io::Error> {\n+  match sys.fs_canonicalize(root_dir) {\n+    Ok(path) => Ok(path),\n+    Err(err) if err.kind() == std::io::ErrorKind::NotFound => {\n+      sys.fs_create_dir_all(root_dir)?;\n+      sys.fs_canonicalize(root_dir)\n+    }\n+    Err(err) => Err(err),\n+  }\n+}\n+\n+async fn clean_except(\n+  flags: Arc<Flags>,\n+  entrypoints: &[String],\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut state = CleanState::default();\n+\n+  let factory = CliFactory::from_flags(flags.clone());\n+  let sys = factory.sys();\n+  let options = factory.cli_options()?;\n+  let main_graph_container = factory.main_module_graph_container().await?;\n+  let roots = main_graph_container.collect_specifiers(entrypoints)?;\n+  let http_cache = factory.global_http_cache()?;\n+  let local_or_global_http_cache = factory.http_cache()?.clone();\n+  let deno_dir = factory.deno_dir()?.clone();\n+  let deno_dir_root_canonical =\n+    try_get_canonicalized_root_dir(&sys, &deno_dir.root)\n+      .unwrap_or(deno_dir.root.clone());\n+\n+  let mut permit = main_graph_container.acquire_update_permit().await;\n+  let graph = permit.graph_mut();\n+  graph.packages = PackageSpecifiers::default();\n+  let graph_builder = factory.module_graph_builder().await?;\n+  graph_builder\n+    .build_graph_with_npm_resolution(\n+      graph,\n+      CreateGraphOptions {\n+        // loader: Some(&mut NoLoader),\n+        loader: None,\n+        graph_kind: graph.graph_kind(),\n+        is_dynamic: false,\n+        roots: roots.clone(),\n+        npm_caching: crate::graph_util::NpmCachingStrategy::Manual,\n+      },\n+    )\n+    .await?;\n+\n+  let npm_resolver = factory.npm_resolver().await?;\n+\n+  let mut keep = HashSet::new();\n+  let mut npm_reqs = Vec::new();\n+\n+  let mut keep_paths_trie = PathTrie::new();\n+  if deno_dir_root_canonical != deno_dir.root {\n+    keep_paths_trie\n+      .add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical.clone());\n+  }\n+  for (_, entry) in graph.walk(\n+    roots.iter(),\n+    deno_graph::WalkOptions {\n+      check_js: deno_graph::CheckJsOption::False,\n+      follow_dynamic: true,\n+      kind: graph.graph_kind(),\n+      prefer_fast_check_graph: false,\n+    },\n+  ) {\n+    match entry {\n+      deno_graph::ModuleEntryRef::Module(module) => match module {\n+        deno_graph::Module::Js(js_module) => {\n+          keep.insert(&js_module.specifier);\n+        }\n+        deno_graph::Module::Json(json_module) => {\n+          keep.insert(&json_module.specifier);\n+        }\n+        deno_graph::Module::Wasm(wasm_module) => {\n+          keep.insert(&wasm_module.specifier);\n+        }\n+        deno_graph::Module::Npm(npm_module) => {\n+          if let Some(managed) = npm_resolver.as_managed() {\n+            let id = managed\n+              .resolution()\n+              .resolve_pkg_id_from_deno_module(npm_module.nv_reference.nv())\n+              .unwrap();\n+            npm_reqs\n+              .extend(managed.resolution().resolve_pkg_reqs_from_pkg_id(&id));\n+          }\n+        }\n+        deno_graph::Module::Node(_) => {}\n+        deno_graph::Module::External(_) => {}\n+      },\n+      deno_graph::ModuleEntryRef::Err(_) => {}\n+      deno_graph::ModuleEntryRef::Redirect(_) => {}\n+    }\n+  }\n+\n+  for url in &keep {\n+    if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+      if let Ok(path) = http_cache.local_path_for_url(url) {\n+        keep_paths_trie.insert(&path);\n+      }\n+    }\n+    if let Some(path) = deno_dir\n+      .gen_cache\n+      .get_cache_filename_with_extension(url, \"js\")\n+    {\n+      let path = deno_dir.gen_cache.location.join(path);\n+      keep_paths_trie.insert(&path);\n+    }\n+  }\n+\n+  let npm_cache = factory.npm_cache()?;\n+  let snap = npm_resolver.as_managed().unwrap().resolution().snapshot();\n+  // TODO(nathanwhit): remove once we don't need packuments for creating the snapshot from lockfile\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    keep_paths_trie.insert(\n+      &npm_cache\n+        .package_name_folder(&package.id.nv.name)\n+        .join(\"registry.json\"),\n+    );\n+  }\n+  let snap = snap.subset(&npm_reqs);\n+  let node_modules_path = npm_resolver.root_node_modules_path();\n+  let mut node_modules_keep = HashSet::new();\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    if node_modules_path.is_some() {\n+      node_modules_keep.insert(package.get_package_cache_folder_id());\n+    }\n+    keep_paths_trie.insert(&npm_cache.package_folder_for_id(\n+      &deno_npm::NpmPackageCacheFolderId {\n+        nv: package.id.nv.clone(),\n+        copy_index: package.copy_index,\n+      },\n+    ));\n+  }\n+\n+  let jsr_url = crate::args::jsr_url();\n+  add_jsr_meta_paths(graph, &mut keep_paths_trie, jsr_url, &|url| {\n+    http_cache.local_path_for_url(url).map_err(Into::into)\n+  })?;\n+  walk_removing(\n+    &mut state,\n+    walkdir::WalkDir::new(&deno_dir.root)\n+      .contents_first(false)\n+      .min_depth(2),\n+    &keep_paths_trie,\n+    &deno_dir.root,\n+    dry_run,\n+  )?;\n+  let mut node_modules_cleaned = CleanState::default();\n+\n+  if let Some(dir) = node_modules_path {\n+    // let npm_installer = factory.npm_installer_if_managed().await?.unwrap();\n+    // npm_installer.\n+    // let npm_installer = npm_installer.as_local().unwrap();\n+    clean_node_modules(\n+      &mut node_modules_cleaned,\n+      &node_modules_keep,\n+      dir,\n+      dry_run,\n+    )?;\n+  }\n+\n+  let mut vendor_cleaned = CleanState::default();\n+  if let Some(vendor_dir) = options.vendor_dir_path() {\n+    if let GlobalOrLocalHttpCache::Local(cache) = local_or_global_http_cache {\n+      let mut trie = PathTrie::new();\n+      if deno_dir_root_canonical != deno_dir.root {\n+        trie.add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical);\n+      }\n+      let cache = cache.clone();\n+      add_jsr_meta_paths(graph, &mut trie, jsr_url, &|_url| {\n+        if let Ok(Some(path)) = cache.local_path_for_url(_url) {\n+          Ok(path)\n+        } else {\n+          panic!(\"should not happen\")\n+        }\n+      })?;\n+      for url in keep {\n+        if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+          if let Ok(Some(path)) = cache.local_path_for_url(url) {\n+            trie.insert(&path);\n+          } else {\n+            panic!(\"should not happen\")\n+          }\n+        }\n+      }\n+\n+      walk_removing(\n+        &mut vendor_cleaned,\n+        WalkDir::new(vendor_dir).contents_first(false),\n+        &trie,\n+        vendor_dir,\n+        dry_run,\n+      )?;\n+    }\n+  }\n+\n+  if !dry_run {\n+    log_stats(&state, &deno_dir.root);\n+\n+    if let Some(dir) = node_modules_path {\n+      log_stats(&node_modules_cleaned, dir);\n+    }\n+    if let Some(dir) = options.vendor_dir_path() {\n+      log_stats(&vendor_cleaned, dir);\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn log_stats(state: &CleanState, dir: &Path) {\n+  if state.bytes_removed == 0\n+    && state.dirs_removed == 0\n+    && state.files_removed == 0\n+  {\n+    return;\n+  }\n+  log::info!(\n+    \"{} {}\",\n+    colors::green(\"Removed\"),\n+    colors::gray(&format!(\n+      \"{} files, {} from {}\",\n+      state.files_removed + state.dirs_removed,\n+      display::human_size(state.bytes_removed as f64),\n+      dir.display()\n+    ))\n+  );\n+}\n+\n+fn add_jsr_meta_paths(\n+  graph: &ModuleGraph,\n+  path_trie: &mut PathTrie,\n+  jsr_url: &Url,\n+  url_to_path: &dyn Fn(&Url) -> Result<PathBuf, AnyError>,\n+) -> Result<(), AnyError> {\n+  for package in graph.packages.mappings().values() {\n+    let Ok(base_url) = jsr_url.join(&format!(\"{}/\", &package.name)) else {\n+      continue;\n+    };\n+    let keep = url_to_path(&base_url.join(\"meta.json\").unwrap())?;\n+    path_trie.insert(&keep);\n+    let keep = url_to_path(\n+      &base_url\n+        .join(&format!(\"{}_meta.json\", package.version))\n+        .unwrap(),\n+    )?;\n+    path_trie.insert(&keep);\n+  }\n+  Ok(())\n+}\n+\n+fn walk_removing(\n+  state: &mut CleanState,\n+  walker: WalkDir,\n+  trie: &PathTrie,\n+  base: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut walker = walker.into_iter();\n+  while let Some(entry) = walker.next() {\n+    let entry = entry?;\n+    if let Some(found) = trie.find(entry.path()) {\n+      if entry.file_type().is_dir() && matches!(found, Found::Match) {\n+        walker.skip_current_dir();\n+        continue;\n+      }\n+      continue;\n+    }\n+    if !entry.path().starts_with(base) {\n+      panic!(\"VERY BAD\");\n+    }\n+    if entry.file_type().is_dir() {\n+      if dry_run {\n+        #[allow(clippy::print_stderr)]\n+        {\n+          eprintln!(\"would remove dir: {}\", entry.path().display());\n+        }\n+      } else {\n+        rm_rf(state, entry.path())?;\n+      }\n+      walker.skip_current_dir();\n+    } else if dry_run {\n+      #[allow(clippy::print_stderr)]\n+      {\n+        eprintln!(\"would remove file: {}\", entry.path().display());\n+      }\n+    } else {\n+      remove_file(state, entry.path(), Some(entry.metadata()?))?;\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn clean_node_modules(\n+  state: &mut CleanState,\n+  keep_pkgs: &HashSet<deno_npm::NpmPackageCacheFolderId>,\n+  dir: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  if !dir.ends_with(\"node_modules\") || !dir.is_dir() {\n+    bail!(\"not a node_modules directory\");\n+  }\n+  let base = dir.join(\".deno\");\n+  if !base.exists() {\n+    return Ok(());\n+  }\n+\n+  let keep_names = keep_pkgs\n+    .iter()\n+    .map(deno_resolver::npm::get_package_folder_id_folder_name)\n+    .collect::<HashSet<_>>();\n+\n+  // TODO(nathanwhit): this probably shouldn't reach directly into this code",
        "comment_created_at": "2025-04-29T20:32:40+00:00",
        "comment_author": "bartlomieju",
        "comment_body": "I'm not sure I understand what's the problem here - is this touching some internal implementation details?",
        "pr_file_module": null
      },
      {
        "comment_id": "2067390713",
        "repo_full_name": "denoland/deno",
        "pr_number": 28424,
        "pr_file": "cli/tools/clean.rs",
        "discussion_id": "2067382080",
        "commented_code": "@@ -69,6 +92,502 @@ pub fn clean(flags: Arc<Flags>) -> Result<(), AnyError> {\n   Ok(())\n }\n \n+#[derive(Clone, Debug, Default)]\n+struct PathNode {\n+  exact: bool,\n+  children: BTreeMap<OsString, usize>,\n+}\n+#[derive(Debug)]\n+struct PathTrie {\n+  root: usize,\n+  nodes: Vec<PathNode>,\n+  rewrites: Vec<(PathBuf, PathBuf)>,\n+}\n+\n+#[derive(Clone, Copy, PartialEq, Eq, Debug)]\n+enum Found {\n+  Match,\n+  Prefix,\n+}\n+\n+impl PathTrie {\n+  fn new() -> Self {\n+    Self {\n+      root: 0,\n+      nodes: vec![PathNode {\n+        exact: false,\n+        children: Default::default(),\n+      }],\n+      rewrites: vec![],\n+    }\n+  }\n+  fn add_rewrite(&mut self, from: PathBuf, to: PathBuf) {\n+    self.rewrites.push((from, to));\n+  }\n+  fn rewrite(&self, s: &Path) -> PathBuf {\n+    let normalized = deno_path_util::normalize_path(s);\n+    for (from, to) in &self.rewrites {\n+      if normalized.starts_with(from) {\n+        return to.join(normalized.strip_prefix(from).unwrap());\n+      }\n+    }\n+    normalized\n+  }\n+  fn insert(&mut self, s: &Path) {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        let id = self.nodes.len();\n+        self.nodes.push(PathNode::default());\n+        self.nodes[node]\n+          .children\n+          .insert(component.to_os_string(), id);\n+        node = id;\n+      }\n+    }\n+\n+    self.nodes[node].exact = true;\n+  }\n+\n+  fn find(&self, s: &Path) -> Option<Found> {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        return None;\n+      }\n+    }\n+\n+    Some(if self.nodes[node].exact {\n+      Found::Match\n+    } else {\n+      Found::Prefix\n+    })\n+  }\n+}\n+\n+fn try_get_canonicalized_root_dir<Sys: FsCanonicalize + FsCreateDirAll>(\n+  sys: &Sys,\n+  root_dir: &Path,\n+) -> Result<PathBuf, std::io::Error> {\n+  match sys.fs_canonicalize(root_dir) {\n+    Ok(path) => Ok(path),\n+    Err(err) if err.kind() == std::io::ErrorKind::NotFound => {\n+      sys.fs_create_dir_all(root_dir)?;\n+      sys.fs_canonicalize(root_dir)\n+    }\n+    Err(err) => Err(err),\n+  }\n+}\n+\n+async fn clean_except(\n+  flags: Arc<Flags>,\n+  entrypoints: &[String],\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut state = CleanState::default();\n+\n+  let factory = CliFactory::from_flags(flags.clone());\n+  let sys = factory.sys();\n+  let options = factory.cli_options()?;\n+  let main_graph_container = factory.main_module_graph_container().await?;\n+  let roots = main_graph_container.collect_specifiers(entrypoints)?;\n+  let http_cache = factory.global_http_cache()?;\n+  let local_or_global_http_cache = factory.http_cache()?.clone();\n+  let deno_dir = factory.deno_dir()?.clone();\n+  let deno_dir_root_canonical =\n+    try_get_canonicalized_root_dir(&sys, &deno_dir.root)\n+      .unwrap_or(deno_dir.root.clone());\n+\n+  let mut permit = main_graph_container.acquire_update_permit().await;\n+  let graph = permit.graph_mut();\n+  graph.packages = PackageSpecifiers::default();\n+  let graph_builder = factory.module_graph_builder().await?;\n+  graph_builder\n+    .build_graph_with_npm_resolution(\n+      graph,\n+      CreateGraphOptions {\n+        // loader: Some(&mut NoLoader),\n+        loader: None,\n+        graph_kind: graph.graph_kind(),\n+        is_dynamic: false,\n+        roots: roots.clone(),\n+        npm_caching: crate::graph_util::NpmCachingStrategy::Manual,\n+      },\n+    )\n+    .await?;\n+\n+  let npm_resolver = factory.npm_resolver().await?;\n+\n+  let mut keep = HashSet::new();\n+  let mut npm_reqs = Vec::new();\n+\n+  let mut keep_paths_trie = PathTrie::new();\n+  if deno_dir_root_canonical != deno_dir.root {\n+    keep_paths_trie\n+      .add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical.clone());\n+  }\n+  for (_, entry) in graph.walk(\n+    roots.iter(),\n+    deno_graph::WalkOptions {\n+      check_js: deno_graph::CheckJsOption::False,\n+      follow_dynamic: true,\n+      kind: graph.graph_kind(),\n+      prefer_fast_check_graph: false,\n+    },\n+  ) {\n+    match entry {\n+      deno_graph::ModuleEntryRef::Module(module) => match module {\n+        deno_graph::Module::Js(js_module) => {\n+          keep.insert(&js_module.specifier);\n+        }\n+        deno_graph::Module::Json(json_module) => {\n+          keep.insert(&json_module.specifier);\n+        }\n+        deno_graph::Module::Wasm(wasm_module) => {\n+          keep.insert(&wasm_module.specifier);\n+        }\n+        deno_graph::Module::Npm(npm_module) => {\n+          if let Some(managed) = npm_resolver.as_managed() {\n+            let id = managed\n+              .resolution()\n+              .resolve_pkg_id_from_deno_module(npm_module.nv_reference.nv())\n+              .unwrap();\n+            npm_reqs\n+              .extend(managed.resolution().resolve_pkg_reqs_from_pkg_id(&id));\n+          }\n+        }\n+        deno_graph::Module::Node(_) => {}\n+        deno_graph::Module::External(_) => {}\n+      },\n+      deno_graph::ModuleEntryRef::Err(_) => {}\n+      deno_graph::ModuleEntryRef::Redirect(_) => {}\n+    }\n+  }\n+\n+  for url in &keep {\n+    if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+      if let Ok(path) = http_cache.local_path_for_url(url) {\n+        keep_paths_trie.insert(&path);\n+      }\n+    }\n+    if let Some(path) = deno_dir\n+      .gen_cache\n+      .get_cache_filename_with_extension(url, \"js\")\n+    {\n+      let path = deno_dir.gen_cache.location.join(path);\n+      keep_paths_trie.insert(&path);\n+    }\n+  }\n+\n+  let npm_cache = factory.npm_cache()?;\n+  let snap = npm_resolver.as_managed().unwrap().resolution().snapshot();\n+  // TODO(nathanwhit): remove once we don't need packuments for creating the snapshot from lockfile\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    keep_paths_trie.insert(\n+      &npm_cache\n+        .package_name_folder(&package.id.nv.name)\n+        .join(\"registry.json\"),\n+    );\n+  }\n+  let snap = snap.subset(&npm_reqs);\n+  let node_modules_path = npm_resolver.root_node_modules_path();\n+  let mut node_modules_keep = HashSet::new();\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    if node_modules_path.is_some() {\n+      node_modules_keep.insert(package.get_package_cache_folder_id());\n+    }\n+    keep_paths_trie.insert(&npm_cache.package_folder_for_id(\n+      &deno_npm::NpmPackageCacheFolderId {\n+        nv: package.id.nv.clone(),\n+        copy_index: package.copy_index,\n+      },\n+    ));\n+  }\n+\n+  let jsr_url = crate::args::jsr_url();\n+  add_jsr_meta_paths(graph, &mut keep_paths_trie, jsr_url, &|url| {\n+    http_cache.local_path_for_url(url).map_err(Into::into)\n+  })?;\n+  walk_removing(\n+    &mut state,\n+    walkdir::WalkDir::new(&deno_dir.root)\n+      .contents_first(false)\n+      .min_depth(2),\n+    &keep_paths_trie,\n+    &deno_dir.root,\n+    dry_run,\n+  )?;\n+  let mut node_modules_cleaned = CleanState::default();\n+\n+  if let Some(dir) = node_modules_path {\n+    // let npm_installer = factory.npm_installer_if_managed().await?.unwrap();\n+    // npm_installer.\n+    // let npm_installer = npm_installer.as_local().unwrap();\n+    clean_node_modules(\n+      &mut node_modules_cleaned,\n+      &node_modules_keep,\n+      dir,\n+      dry_run,\n+    )?;\n+  }\n+\n+  let mut vendor_cleaned = CleanState::default();\n+  if let Some(vendor_dir) = options.vendor_dir_path() {\n+    if let GlobalOrLocalHttpCache::Local(cache) = local_or_global_http_cache {\n+      let mut trie = PathTrie::new();\n+      if deno_dir_root_canonical != deno_dir.root {\n+        trie.add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical);\n+      }\n+      let cache = cache.clone();\n+      add_jsr_meta_paths(graph, &mut trie, jsr_url, &|_url| {\n+        if let Ok(Some(path)) = cache.local_path_for_url(_url) {\n+          Ok(path)\n+        } else {\n+          panic!(\"should not happen\")\n+        }\n+      })?;\n+      for url in keep {\n+        if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+          if let Ok(Some(path)) = cache.local_path_for_url(url) {\n+            trie.insert(&path);\n+          } else {\n+            panic!(\"should not happen\")\n+          }\n+        }\n+      }\n+\n+      walk_removing(\n+        &mut vendor_cleaned,\n+        WalkDir::new(vendor_dir).contents_first(false),\n+        &trie,\n+        vendor_dir,\n+        dry_run,\n+      )?;\n+    }\n+  }\n+\n+  if !dry_run {\n+    log_stats(&state, &deno_dir.root);\n+\n+    if let Some(dir) = node_modules_path {\n+      log_stats(&node_modules_cleaned, dir);\n+    }\n+    if let Some(dir) = options.vendor_dir_path() {\n+      log_stats(&vendor_cleaned, dir);\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn log_stats(state: &CleanState, dir: &Path) {\n+  if state.bytes_removed == 0\n+    && state.dirs_removed == 0\n+    && state.files_removed == 0\n+  {\n+    return;\n+  }\n+  log::info!(\n+    \"{} {}\",\n+    colors::green(\"Removed\"),\n+    colors::gray(&format!(\n+      \"{} files, {} from {}\",\n+      state.files_removed + state.dirs_removed,\n+      display::human_size(state.bytes_removed as f64),\n+      dir.display()\n+    ))\n+  );\n+}\n+\n+fn add_jsr_meta_paths(\n+  graph: &ModuleGraph,\n+  path_trie: &mut PathTrie,\n+  jsr_url: &Url,\n+  url_to_path: &dyn Fn(&Url) -> Result<PathBuf, AnyError>,\n+) -> Result<(), AnyError> {\n+  for package in graph.packages.mappings().values() {\n+    let Ok(base_url) = jsr_url.join(&format!(\"{}/\", &package.name)) else {\n+      continue;\n+    };\n+    let keep = url_to_path(&base_url.join(\"meta.json\").unwrap())?;\n+    path_trie.insert(&keep);\n+    let keep = url_to_path(\n+      &base_url\n+        .join(&format!(\"{}_meta.json\", package.version))\n+        .unwrap(),\n+    )?;\n+    path_trie.insert(&keep);\n+  }\n+  Ok(())\n+}\n+\n+fn walk_removing(\n+  state: &mut CleanState,\n+  walker: WalkDir,\n+  trie: &PathTrie,\n+  base: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut walker = walker.into_iter();\n+  while let Some(entry) = walker.next() {\n+    let entry = entry?;\n+    if let Some(found) = trie.find(entry.path()) {\n+      if entry.file_type().is_dir() && matches!(found, Found::Match) {\n+        walker.skip_current_dir();\n+        continue;\n+      }\n+      continue;\n+    }\n+    if !entry.path().starts_with(base) {\n+      panic!(\"VERY BAD\");\n+    }\n+    if entry.file_type().is_dir() {\n+      if dry_run {\n+        #[allow(clippy::print_stderr)]\n+        {\n+          eprintln!(\"would remove dir: {}\", entry.path().display());\n+        }\n+      } else {\n+        rm_rf(state, entry.path())?;\n+      }\n+      walker.skip_current_dir();\n+    } else if dry_run {\n+      #[allow(clippy::print_stderr)]\n+      {\n+        eprintln!(\"would remove file: {}\", entry.path().display());\n+      }\n+    } else {\n+      remove_file(state, entry.path(), Some(entry.metadata()?))?;\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn clean_node_modules(\n+  state: &mut CleanState,\n+  keep_pkgs: &HashSet<deno_npm::NpmPackageCacheFolderId>,\n+  dir: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  if !dir.ends_with(\"node_modules\") || !dir.is_dir() {\n+    bail!(\"not a node_modules directory\");\n+  }\n+  let base = dir.join(\".deno\");\n+  if !base.exists() {\n+    return Ok(());\n+  }\n+\n+  let keep_names = keep_pkgs\n+    .iter()\n+    .map(deno_resolver::npm::get_package_folder_id_folder_name)\n+    .collect::<HashSet<_>>();\n+\n+  // TODO(nathanwhit): this probably shouldn't reach directly into this code",
        "comment_created_at": "2025-04-29T20:36:30+00:00",
        "comment_author": "nathanwhit",
        "comment_body": "sort of. it's just everywhere else in the code we expose more generic methods on e.g. `NpmInstaller`. This just uses some of the code from the local installer directly. It's not incorrect, but it feels sort of wrong to me.",
        "pr_file_module": null
      },
      {
        "comment_id": "2067398316",
        "repo_full_name": "denoland/deno",
        "pr_number": 28424,
        "pr_file": "cli/tools/clean.rs",
        "discussion_id": "2067382080",
        "commented_code": "@@ -69,6 +92,502 @@ pub fn clean(flags: Arc<Flags>) -> Result<(), AnyError> {\n   Ok(())\n }\n \n+#[derive(Clone, Debug, Default)]\n+struct PathNode {\n+  exact: bool,\n+  children: BTreeMap<OsString, usize>,\n+}\n+#[derive(Debug)]\n+struct PathTrie {\n+  root: usize,\n+  nodes: Vec<PathNode>,\n+  rewrites: Vec<(PathBuf, PathBuf)>,\n+}\n+\n+#[derive(Clone, Copy, PartialEq, Eq, Debug)]\n+enum Found {\n+  Match,\n+  Prefix,\n+}\n+\n+impl PathTrie {\n+  fn new() -> Self {\n+    Self {\n+      root: 0,\n+      nodes: vec![PathNode {\n+        exact: false,\n+        children: Default::default(),\n+      }],\n+      rewrites: vec![],\n+    }\n+  }\n+  fn add_rewrite(&mut self, from: PathBuf, to: PathBuf) {\n+    self.rewrites.push((from, to));\n+  }\n+  fn rewrite(&self, s: &Path) -> PathBuf {\n+    let normalized = deno_path_util::normalize_path(s);\n+    for (from, to) in &self.rewrites {\n+      if normalized.starts_with(from) {\n+        return to.join(normalized.strip_prefix(from).unwrap());\n+      }\n+    }\n+    normalized\n+  }\n+  fn insert(&mut self, s: &Path) {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        let id = self.nodes.len();\n+        self.nodes.push(PathNode::default());\n+        self.nodes[node]\n+          .children\n+          .insert(component.to_os_string(), id);\n+        node = id;\n+      }\n+    }\n+\n+    self.nodes[node].exact = true;\n+  }\n+\n+  fn find(&self, s: &Path) -> Option<Found> {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        return None;\n+      }\n+    }\n+\n+    Some(if self.nodes[node].exact {\n+      Found::Match\n+    } else {\n+      Found::Prefix\n+    })\n+  }\n+}\n+\n+fn try_get_canonicalized_root_dir<Sys: FsCanonicalize + FsCreateDirAll>(\n+  sys: &Sys,\n+  root_dir: &Path,\n+) -> Result<PathBuf, std::io::Error> {\n+  match sys.fs_canonicalize(root_dir) {\n+    Ok(path) => Ok(path),\n+    Err(err) if err.kind() == std::io::ErrorKind::NotFound => {\n+      sys.fs_create_dir_all(root_dir)?;\n+      sys.fs_canonicalize(root_dir)\n+    }\n+    Err(err) => Err(err),\n+  }\n+}\n+\n+async fn clean_except(\n+  flags: Arc<Flags>,\n+  entrypoints: &[String],\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut state = CleanState::default();\n+\n+  let factory = CliFactory::from_flags(flags.clone());\n+  let sys = factory.sys();\n+  let options = factory.cli_options()?;\n+  let main_graph_container = factory.main_module_graph_container().await?;\n+  let roots = main_graph_container.collect_specifiers(entrypoints)?;\n+  let http_cache = factory.global_http_cache()?;\n+  let local_or_global_http_cache = factory.http_cache()?.clone();\n+  let deno_dir = factory.deno_dir()?.clone();\n+  let deno_dir_root_canonical =\n+    try_get_canonicalized_root_dir(&sys, &deno_dir.root)\n+      .unwrap_or(deno_dir.root.clone());\n+\n+  let mut permit = main_graph_container.acquire_update_permit().await;\n+  let graph = permit.graph_mut();\n+  graph.packages = PackageSpecifiers::default();\n+  let graph_builder = factory.module_graph_builder().await?;\n+  graph_builder\n+    .build_graph_with_npm_resolution(\n+      graph,\n+      CreateGraphOptions {\n+        // loader: Some(&mut NoLoader),\n+        loader: None,\n+        graph_kind: graph.graph_kind(),\n+        is_dynamic: false,\n+        roots: roots.clone(),\n+        npm_caching: crate::graph_util::NpmCachingStrategy::Manual,\n+      },\n+    )\n+    .await?;\n+\n+  let npm_resolver = factory.npm_resolver().await?;\n+\n+  let mut keep = HashSet::new();\n+  let mut npm_reqs = Vec::new();\n+\n+  let mut keep_paths_trie = PathTrie::new();\n+  if deno_dir_root_canonical != deno_dir.root {\n+    keep_paths_trie\n+      .add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical.clone());\n+  }\n+  for (_, entry) in graph.walk(\n+    roots.iter(),\n+    deno_graph::WalkOptions {\n+      check_js: deno_graph::CheckJsOption::False,\n+      follow_dynamic: true,\n+      kind: graph.graph_kind(),\n+      prefer_fast_check_graph: false,\n+    },\n+  ) {\n+    match entry {\n+      deno_graph::ModuleEntryRef::Module(module) => match module {\n+        deno_graph::Module::Js(js_module) => {\n+          keep.insert(&js_module.specifier);\n+        }\n+        deno_graph::Module::Json(json_module) => {\n+          keep.insert(&json_module.specifier);\n+        }\n+        deno_graph::Module::Wasm(wasm_module) => {\n+          keep.insert(&wasm_module.specifier);\n+        }\n+        deno_graph::Module::Npm(npm_module) => {\n+          if let Some(managed) = npm_resolver.as_managed() {\n+            let id = managed\n+              .resolution()\n+              .resolve_pkg_id_from_deno_module(npm_module.nv_reference.nv())\n+              .unwrap();\n+            npm_reqs\n+              .extend(managed.resolution().resolve_pkg_reqs_from_pkg_id(&id));\n+          }\n+        }\n+        deno_graph::Module::Node(_) => {}\n+        deno_graph::Module::External(_) => {}\n+      },\n+      deno_graph::ModuleEntryRef::Err(_) => {}\n+      deno_graph::ModuleEntryRef::Redirect(_) => {}\n+    }\n+  }\n+\n+  for url in &keep {\n+    if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+      if let Ok(path) = http_cache.local_path_for_url(url) {\n+        keep_paths_trie.insert(&path);\n+      }\n+    }\n+    if let Some(path) = deno_dir\n+      .gen_cache\n+      .get_cache_filename_with_extension(url, \"js\")\n+    {\n+      let path = deno_dir.gen_cache.location.join(path);\n+      keep_paths_trie.insert(&path);\n+    }\n+  }\n+\n+  let npm_cache = factory.npm_cache()?;\n+  let snap = npm_resolver.as_managed().unwrap().resolution().snapshot();\n+  // TODO(nathanwhit): remove once we don't need packuments for creating the snapshot from lockfile\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    keep_paths_trie.insert(\n+      &npm_cache\n+        .package_name_folder(&package.id.nv.name)\n+        .join(\"registry.json\"),\n+    );\n+  }\n+  let snap = snap.subset(&npm_reqs);\n+  let node_modules_path = npm_resolver.root_node_modules_path();\n+  let mut node_modules_keep = HashSet::new();\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    if node_modules_path.is_some() {\n+      node_modules_keep.insert(package.get_package_cache_folder_id());\n+    }\n+    keep_paths_trie.insert(&npm_cache.package_folder_for_id(\n+      &deno_npm::NpmPackageCacheFolderId {\n+        nv: package.id.nv.clone(),\n+        copy_index: package.copy_index,\n+      },\n+    ));\n+  }\n+\n+  let jsr_url = crate::args::jsr_url();\n+  add_jsr_meta_paths(graph, &mut keep_paths_trie, jsr_url, &|url| {\n+    http_cache.local_path_for_url(url).map_err(Into::into)\n+  })?;\n+  walk_removing(\n+    &mut state,\n+    walkdir::WalkDir::new(&deno_dir.root)\n+      .contents_first(false)\n+      .min_depth(2),\n+    &keep_paths_trie,\n+    &deno_dir.root,\n+    dry_run,\n+  )?;\n+  let mut node_modules_cleaned = CleanState::default();\n+\n+  if let Some(dir) = node_modules_path {\n+    // let npm_installer = factory.npm_installer_if_managed().await?.unwrap();\n+    // npm_installer.\n+    // let npm_installer = npm_installer.as_local().unwrap();\n+    clean_node_modules(\n+      &mut node_modules_cleaned,\n+      &node_modules_keep,\n+      dir,\n+      dry_run,\n+    )?;\n+  }\n+\n+  let mut vendor_cleaned = CleanState::default();\n+  if let Some(vendor_dir) = options.vendor_dir_path() {\n+    if let GlobalOrLocalHttpCache::Local(cache) = local_or_global_http_cache {\n+      let mut trie = PathTrie::new();\n+      if deno_dir_root_canonical != deno_dir.root {\n+        trie.add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical);\n+      }\n+      let cache = cache.clone();\n+      add_jsr_meta_paths(graph, &mut trie, jsr_url, &|_url| {\n+        if let Ok(Some(path)) = cache.local_path_for_url(_url) {\n+          Ok(path)\n+        } else {\n+          panic!(\"should not happen\")\n+        }\n+      })?;\n+      for url in keep {\n+        if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+          if let Ok(Some(path)) = cache.local_path_for_url(url) {\n+            trie.insert(&path);\n+          } else {\n+            panic!(\"should not happen\")\n+          }\n+        }\n+      }\n+\n+      walk_removing(\n+        &mut vendor_cleaned,\n+        WalkDir::new(vendor_dir).contents_first(false),\n+        &trie,\n+        vendor_dir,\n+        dry_run,\n+      )?;\n+    }\n+  }\n+\n+  if !dry_run {\n+    log_stats(&state, &deno_dir.root);\n+\n+    if let Some(dir) = node_modules_path {\n+      log_stats(&node_modules_cleaned, dir);\n+    }\n+    if let Some(dir) = options.vendor_dir_path() {\n+      log_stats(&vendor_cleaned, dir);\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn log_stats(state: &CleanState, dir: &Path) {\n+  if state.bytes_removed == 0\n+    && state.dirs_removed == 0\n+    && state.files_removed == 0\n+  {\n+    return;\n+  }\n+  log::info!(\n+    \"{} {}\",\n+    colors::green(\"Removed\"),\n+    colors::gray(&format!(\n+      \"{} files, {} from {}\",\n+      state.files_removed + state.dirs_removed,\n+      display::human_size(state.bytes_removed as f64),\n+      dir.display()\n+    ))\n+  );\n+}\n+\n+fn add_jsr_meta_paths(\n+  graph: &ModuleGraph,\n+  path_trie: &mut PathTrie,\n+  jsr_url: &Url,\n+  url_to_path: &dyn Fn(&Url) -> Result<PathBuf, AnyError>,\n+) -> Result<(), AnyError> {\n+  for package in graph.packages.mappings().values() {\n+    let Ok(base_url) = jsr_url.join(&format!(\"{}/\", &package.name)) else {\n+      continue;\n+    };\n+    let keep = url_to_path(&base_url.join(\"meta.json\").unwrap())?;\n+    path_trie.insert(&keep);\n+    let keep = url_to_path(\n+      &base_url\n+        .join(&format!(\"{}_meta.json\", package.version))\n+        .unwrap(),\n+    )?;\n+    path_trie.insert(&keep);\n+  }\n+  Ok(())\n+}\n+\n+fn walk_removing(\n+  state: &mut CleanState,\n+  walker: WalkDir,\n+  trie: &PathTrie,\n+  base: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut walker = walker.into_iter();\n+  while let Some(entry) = walker.next() {\n+    let entry = entry?;\n+    if let Some(found) = trie.find(entry.path()) {\n+      if entry.file_type().is_dir() && matches!(found, Found::Match) {\n+        walker.skip_current_dir();\n+        continue;\n+      }\n+      continue;\n+    }\n+    if !entry.path().starts_with(base) {\n+      panic!(\"VERY BAD\");\n+    }\n+    if entry.file_type().is_dir() {\n+      if dry_run {\n+        #[allow(clippy::print_stderr)]\n+        {\n+          eprintln!(\"would remove dir: {}\", entry.path().display());\n+        }\n+      } else {\n+        rm_rf(state, entry.path())?;\n+      }\n+      walker.skip_current_dir();\n+    } else if dry_run {\n+      #[allow(clippy::print_stderr)]\n+      {\n+        eprintln!(\"would remove file: {}\", entry.path().display());\n+      }\n+    } else {\n+      remove_file(state, entry.path(), Some(entry.metadata()?))?;\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn clean_node_modules(\n+  state: &mut CleanState,\n+  keep_pkgs: &HashSet<deno_npm::NpmPackageCacheFolderId>,\n+  dir: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  if !dir.ends_with(\"node_modules\") || !dir.is_dir() {\n+    bail!(\"not a node_modules directory\");\n+  }\n+  let base = dir.join(\".deno\");\n+  if !base.exists() {\n+    return Ok(());\n+  }\n+\n+  let keep_names = keep_pkgs\n+    .iter()\n+    .map(deno_resolver::npm::get_package_folder_id_folder_name)\n+    .collect::<HashSet<_>>();\n+\n+  // TODO(nathanwhit): this probably shouldn't reach directly into this code",
        "comment_created_at": "2025-04-29T20:39:36+00:00",
        "comment_author": "bartlomieju",
        "comment_body": "We could expose it as a public API down the road?",
        "pr_file_module": null
      },
      {
        "comment_id": "2067411256",
        "repo_full_name": "denoland/deno",
        "pr_number": 28424,
        "pr_file": "cli/tools/clean.rs",
        "discussion_id": "2067382080",
        "commented_code": "@@ -69,6 +92,502 @@ pub fn clean(flags: Arc<Flags>) -> Result<(), AnyError> {\n   Ok(())\n }\n \n+#[derive(Clone, Debug, Default)]\n+struct PathNode {\n+  exact: bool,\n+  children: BTreeMap<OsString, usize>,\n+}\n+#[derive(Debug)]\n+struct PathTrie {\n+  root: usize,\n+  nodes: Vec<PathNode>,\n+  rewrites: Vec<(PathBuf, PathBuf)>,\n+}\n+\n+#[derive(Clone, Copy, PartialEq, Eq, Debug)]\n+enum Found {\n+  Match,\n+  Prefix,\n+}\n+\n+impl PathTrie {\n+  fn new() -> Self {\n+    Self {\n+      root: 0,\n+      nodes: vec![PathNode {\n+        exact: false,\n+        children: Default::default(),\n+      }],\n+      rewrites: vec![],\n+    }\n+  }\n+  fn add_rewrite(&mut self, from: PathBuf, to: PathBuf) {\n+    self.rewrites.push((from, to));\n+  }\n+  fn rewrite(&self, s: &Path) -> PathBuf {\n+    let normalized = deno_path_util::normalize_path(s);\n+    for (from, to) in &self.rewrites {\n+      if normalized.starts_with(from) {\n+        return to.join(normalized.strip_prefix(from).unwrap());\n+      }\n+    }\n+    normalized\n+  }\n+  fn insert(&mut self, s: &Path) {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        let id = self.nodes.len();\n+        self.nodes.push(PathNode::default());\n+        self.nodes[node]\n+          .children\n+          .insert(component.to_os_string(), id);\n+        node = id;\n+      }\n+    }\n+\n+    self.nodes[node].exact = true;\n+  }\n+\n+  fn find(&self, s: &Path) -> Option<Found> {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        return None;\n+      }\n+    }\n+\n+    Some(if self.nodes[node].exact {\n+      Found::Match\n+    } else {\n+      Found::Prefix\n+    })\n+  }\n+}\n+\n+fn try_get_canonicalized_root_dir<Sys: FsCanonicalize + FsCreateDirAll>(\n+  sys: &Sys,\n+  root_dir: &Path,\n+) -> Result<PathBuf, std::io::Error> {\n+  match sys.fs_canonicalize(root_dir) {\n+    Ok(path) => Ok(path),\n+    Err(err) if err.kind() == std::io::ErrorKind::NotFound => {\n+      sys.fs_create_dir_all(root_dir)?;\n+      sys.fs_canonicalize(root_dir)\n+    }\n+    Err(err) => Err(err),\n+  }\n+}\n+\n+async fn clean_except(\n+  flags: Arc<Flags>,\n+  entrypoints: &[String],\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut state = CleanState::default();\n+\n+  let factory = CliFactory::from_flags(flags.clone());\n+  let sys = factory.sys();\n+  let options = factory.cli_options()?;\n+  let main_graph_container = factory.main_module_graph_container().await?;\n+  let roots = main_graph_container.collect_specifiers(entrypoints)?;\n+  let http_cache = factory.global_http_cache()?;\n+  let local_or_global_http_cache = factory.http_cache()?.clone();\n+  let deno_dir = factory.deno_dir()?.clone();\n+  let deno_dir_root_canonical =\n+    try_get_canonicalized_root_dir(&sys, &deno_dir.root)\n+      .unwrap_or(deno_dir.root.clone());\n+\n+  let mut permit = main_graph_container.acquire_update_permit().await;\n+  let graph = permit.graph_mut();\n+  graph.packages = PackageSpecifiers::default();\n+  let graph_builder = factory.module_graph_builder().await?;\n+  graph_builder\n+    .build_graph_with_npm_resolution(\n+      graph,\n+      CreateGraphOptions {\n+        // loader: Some(&mut NoLoader),\n+        loader: None,\n+        graph_kind: graph.graph_kind(),\n+        is_dynamic: false,\n+        roots: roots.clone(),\n+        npm_caching: crate::graph_util::NpmCachingStrategy::Manual,\n+      },\n+    )\n+    .await?;\n+\n+  let npm_resolver = factory.npm_resolver().await?;\n+\n+  let mut keep = HashSet::new();\n+  let mut npm_reqs = Vec::new();\n+\n+  let mut keep_paths_trie = PathTrie::new();\n+  if deno_dir_root_canonical != deno_dir.root {\n+    keep_paths_trie\n+      .add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical.clone());\n+  }\n+  for (_, entry) in graph.walk(\n+    roots.iter(),\n+    deno_graph::WalkOptions {\n+      check_js: deno_graph::CheckJsOption::False,\n+      follow_dynamic: true,\n+      kind: graph.graph_kind(),\n+      prefer_fast_check_graph: false,\n+    },\n+  ) {\n+    match entry {\n+      deno_graph::ModuleEntryRef::Module(module) => match module {\n+        deno_graph::Module::Js(js_module) => {\n+          keep.insert(&js_module.specifier);\n+        }\n+        deno_graph::Module::Json(json_module) => {\n+          keep.insert(&json_module.specifier);\n+        }\n+        deno_graph::Module::Wasm(wasm_module) => {\n+          keep.insert(&wasm_module.specifier);\n+        }\n+        deno_graph::Module::Npm(npm_module) => {\n+          if let Some(managed) = npm_resolver.as_managed() {\n+            let id = managed\n+              .resolution()\n+              .resolve_pkg_id_from_deno_module(npm_module.nv_reference.nv())\n+              .unwrap();\n+            npm_reqs\n+              .extend(managed.resolution().resolve_pkg_reqs_from_pkg_id(&id));\n+          }\n+        }\n+        deno_graph::Module::Node(_) => {}\n+        deno_graph::Module::External(_) => {}\n+      },\n+      deno_graph::ModuleEntryRef::Err(_) => {}\n+      deno_graph::ModuleEntryRef::Redirect(_) => {}\n+    }\n+  }\n+\n+  for url in &keep {\n+    if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+      if let Ok(path) = http_cache.local_path_for_url(url) {\n+        keep_paths_trie.insert(&path);\n+      }\n+    }\n+    if let Some(path) = deno_dir\n+      .gen_cache\n+      .get_cache_filename_with_extension(url, \"js\")\n+    {\n+      let path = deno_dir.gen_cache.location.join(path);\n+      keep_paths_trie.insert(&path);\n+    }\n+  }\n+\n+  let npm_cache = factory.npm_cache()?;\n+  let snap = npm_resolver.as_managed().unwrap().resolution().snapshot();\n+  // TODO(nathanwhit): remove once we don't need packuments for creating the snapshot from lockfile\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    keep_paths_trie.insert(\n+      &npm_cache\n+        .package_name_folder(&package.id.nv.name)\n+        .join(\"registry.json\"),\n+    );\n+  }\n+  let snap = snap.subset(&npm_reqs);\n+  let node_modules_path = npm_resolver.root_node_modules_path();\n+  let mut node_modules_keep = HashSet::new();\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    if node_modules_path.is_some() {\n+      node_modules_keep.insert(package.get_package_cache_folder_id());\n+    }\n+    keep_paths_trie.insert(&npm_cache.package_folder_for_id(\n+      &deno_npm::NpmPackageCacheFolderId {\n+        nv: package.id.nv.clone(),\n+        copy_index: package.copy_index,\n+      },\n+    ));\n+  }\n+\n+  let jsr_url = crate::args::jsr_url();\n+  add_jsr_meta_paths(graph, &mut keep_paths_trie, jsr_url, &|url| {\n+    http_cache.local_path_for_url(url).map_err(Into::into)\n+  })?;\n+  walk_removing(\n+    &mut state,\n+    walkdir::WalkDir::new(&deno_dir.root)\n+      .contents_first(false)\n+      .min_depth(2),\n+    &keep_paths_trie,\n+    &deno_dir.root,\n+    dry_run,\n+  )?;\n+  let mut node_modules_cleaned = CleanState::default();\n+\n+  if let Some(dir) = node_modules_path {\n+    // let npm_installer = factory.npm_installer_if_managed().await?.unwrap();\n+    // npm_installer.\n+    // let npm_installer = npm_installer.as_local().unwrap();\n+    clean_node_modules(\n+      &mut node_modules_cleaned,\n+      &node_modules_keep,\n+      dir,\n+      dry_run,\n+    )?;\n+  }\n+\n+  let mut vendor_cleaned = CleanState::default();\n+  if let Some(vendor_dir) = options.vendor_dir_path() {\n+    if let GlobalOrLocalHttpCache::Local(cache) = local_or_global_http_cache {\n+      let mut trie = PathTrie::new();\n+      if deno_dir_root_canonical != deno_dir.root {\n+        trie.add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical);\n+      }\n+      let cache = cache.clone();\n+      add_jsr_meta_paths(graph, &mut trie, jsr_url, &|_url| {\n+        if let Ok(Some(path)) = cache.local_path_for_url(_url) {\n+          Ok(path)\n+        } else {\n+          panic!(\"should not happen\")\n+        }\n+      })?;\n+      for url in keep {\n+        if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+          if let Ok(Some(path)) = cache.local_path_for_url(url) {\n+            trie.insert(&path);\n+          } else {\n+            panic!(\"should not happen\")\n+          }\n+        }\n+      }\n+\n+      walk_removing(\n+        &mut vendor_cleaned,\n+        WalkDir::new(vendor_dir).contents_first(false),\n+        &trie,\n+        vendor_dir,\n+        dry_run,\n+      )?;\n+    }\n+  }\n+\n+  if !dry_run {\n+    log_stats(&state, &deno_dir.root);\n+\n+    if let Some(dir) = node_modules_path {\n+      log_stats(&node_modules_cleaned, dir);\n+    }\n+    if let Some(dir) = options.vendor_dir_path() {\n+      log_stats(&vendor_cleaned, dir);\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn log_stats(state: &CleanState, dir: &Path) {\n+  if state.bytes_removed == 0\n+    && state.dirs_removed == 0\n+    && state.files_removed == 0\n+  {\n+    return;\n+  }\n+  log::info!(\n+    \"{} {}\",\n+    colors::green(\"Removed\"),\n+    colors::gray(&format!(\n+      \"{} files, {} from {}\",\n+      state.files_removed + state.dirs_removed,\n+      display::human_size(state.bytes_removed as f64),\n+      dir.display()\n+    ))\n+  );\n+}\n+\n+fn add_jsr_meta_paths(\n+  graph: &ModuleGraph,\n+  path_trie: &mut PathTrie,\n+  jsr_url: &Url,\n+  url_to_path: &dyn Fn(&Url) -> Result<PathBuf, AnyError>,\n+) -> Result<(), AnyError> {\n+  for package in graph.packages.mappings().values() {\n+    let Ok(base_url) = jsr_url.join(&format!(\"{}/\", &package.name)) else {\n+      continue;\n+    };\n+    let keep = url_to_path(&base_url.join(\"meta.json\").unwrap())?;\n+    path_trie.insert(&keep);\n+    let keep = url_to_path(\n+      &base_url\n+        .join(&format!(\"{}_meta.json\", package.version))\n+        .unwrap(),\n+    )?;\n+    path_trie.insert(&keep);\n+  }\n+  Ok(())\n+}\n+\n+fn walk_removing(\n+  state: &mut CleanState,\n+  walker: WalkDir,\n+  trie: &PathTrie,\n+  base: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut walker = walker.into_iter();\n+  while let Some(entry) = walker.next() {\n+    let entry = entry?;\n+    if let Some(found) = trie.find(entry.path()) {\n+      if entry.file_type().is_dir() && matches!(found, Found::Match) {\n+        walker.skip_current_dir();\n+        continue;\n+      }\n+      continue;\n+    }\n+    if !entry.path().starts_with(base) {\n+      panic!(\"VERY BAD\");\n+    }\n+    if entry.file_type().is_dir() {\n+      if dry_run {\n+        #[allow(clippy::print_stderr)]\n+        {\n+          eprintln!(\"would remove dir: {}\", entry.path().display());\n+        }\n+      } else {\n+        rm_rf(state, entry.path())?;\n+      }\n+      walker.skip_current_dir();\n+    } else if dry_run {\n+      #[allow(clippy::print_stderr)]\n+      {\n+        eprintln!(\"would remove file: {}\", entry.path().display());\n+      }\n+    } else {\n+      remove_file(state, entry.path(), Some(entry.metadata()?))?;\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn clean_node_modules(\n+  state: &mut CleanState,\n+  keep_pkgs: &HashSet<deno_npm::NpmPackageCacheFolderId>,\n+  dir: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  if !dir.ends_with(\"node_modules\") || !dir.is_dir() {\n+    bail!(\"not a node_modules directory\");\n+  }\n+  let base = dir.join(\".deno\");\n+  if !base.exists() {\n+    return Ok(());\n+  }\n+\n+  let keep_names = keep_pkgs\n+    .iter()\n+    .map(deno_resolver::npm::get_package_folder_id_folder_name)\n+    .collect::<HashSet<_>>();\n+\n+  // TODO(nathanwhit): this probably shouldn't reach directly into this code",
        "comment_created_at": "2025-04-29T20:50:09+00:00",
        "comment_author": "nathanwhit",
        "comment_body": "yeah that's pretty much what the todo is, just to make/use a more public api",
        "pr_file_module": null
      }
    ]
  }
]