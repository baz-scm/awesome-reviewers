[
  {
    "discussion_id": "2169395416",
    "pr_number": 29843,
    "pr_file": "libs/resolver/deno_json.rs",
    "created_at": "2025-06-26T15:55:56+00:00",
    "commented_code": "&self,\n   ) -> Result<&TranspileAndEmitOptionsRc, CompilerOptionsParseError> {\n     self.memoized.transpile_options.get_or_try_init(|| {\n-      let compiler_options = self.emit_compiler_options()?;\n+      let compiler_options = self.compiler_options_for_emit()?;\n       compiler_options_to_transpile_and_emit_options(\n         compiler_options.as_ref().clone(),\n       )\n       .map(new_rc)\n       .map_err(|source| CompilerOptionsParseError {\n-        specifier: self\n-          .dir\n-          .maybe_deno_json()\n-          .map(|d| d.specifier.clone())\n-          .unwrap_or_else(|| {\n-            // will never happen because each dir should have a\n-            // deno.json if we got here\n-            debug_assert!(false);\n-            self.dir.dir_url().as_ref().clone()\n-          }),\n+        specifier: self.sources.last().map(|s| s.specifier.clone()).expect(\n+          \"Compiler options parse errors must come from a user source.\",\n+        ),\n         source,\n       })\n     })\n   }\n+\n+  pub fn compiler_options_types(&self) -> &CompilerOptionsTypesRc {\n+    self.memoized.compiler_options_types.get_or_init(|| {\n+      let types = self\n+        .sources\n+        .iter()\n+        .filter_map(|s| {\n+          let types = s\n+            .compiler_options\n+            .as_ref()?\n+            .0\n+            .as_object()?\n+            .get(\"types\")?\n+            .as_array()?\n+            .iter()\n+            .filter_map(|v| Some(v.as_str()?.to_string()))\n+            .collect();\n+          Some((s.specifier.clone(), types))\n+        })\n+        .collect();\n+      new_rc(types)\n+    })\n+  }\n+\n+  pub fn jsx_import_source_config(\n+    &self,\n+  ) -> Result<Option<&JsxImportSourceConfigRc>, ToMaybeJsxImportSourceConfigError>\n+  {\n+    self.memoized.jsx_import_source_config.get_or_try_init(|| {\n+      let jsx = self.sources.iter().rev().find_map(|s| Some((s.compiler_options.as_ref()?.0.as_object()?.get(\"jsx\")?.as_str()?, &s.specifier)));\n+      let is_jsx_automatic = matches!(\n+        jsx,\n+        Some((\"react-jsx\" | \"preserve\" | \"react-jsxdev\" | \"precompile\", _)),\n+      );\n+      let import_source = self.sources.iter().rev().find_map(|s| {\n+        Some(JsxImportSourceSpecifierConfig {\n+          specifier: s.compiler_options.as_ref()?.0.as_object()?.get(\"jsxImportSource\")?.as_str()?.to_string(),\n+          base: s.specifier.clone()\n+        })\n+      }).or_else(|| {\n+        if !is_jsx_automatic {\n+          return None;\n+        }\n+        Some(JsxImportSourceSpecifierConfig {\n+          base: self.sources.last()?.specifier.clone(),\n+          specifier: \"react\".to_string()\n+        })\n+      });\n+      let import_source_types = self.sources.iter().rev().find_map(|s| {\n+        Some(JsxImportSourceSpecifierConfig {\n+          specifier: s.compiler_options.as_ref()?.0.as_object()?.get(\"jsxImportSourceTypes\")?.as_str()?.to_string(),\n+          base: s.specifier.clone()\n+        })\n+      }).or_else(|| import_source.clone());\n+      let module = match jsx {\n+        Some((\"react-jsx\" | \"preserve\", _)) => \"jsx-runtime\".to_string(),\n+        Some((\"react-jsxdev\", _)) => \"jsx-dev-runtime\".to_string(),\n+        Some((\"react\", _)) | None => {\n+          if let Some(import_source) = &import_source {\n+            return Err(\n+              ToMaybeJsxImportSourceConfigError::InvalidJsxImportSourceValue(\n+                import_source.base.clone(),\n+              ),\n+            );\n+          }\n+          if let Some(import_source_types) = &import_source_types {\n+            return Err(\n+              ToMaybeJsxImportSourceConfigError::InvalidJsxImportSourceTypesValue(\n+                import_source_types.base.clone(),\n+              ),\n+            );\n+          }\n+          return Ok(None);\n+        }\n+        Some((\"precompile\", _)) => \"jsx-runtime\".to_string(),\n+        Some((setting, setting_source)) => {\n+          return Err(\n+            ToMaybeJsxImportSourceConfigError::InvalidJsxCompilerOption {\n+              value: setting.to_string(),\n+              specifier: setting_source.clone(),\n+            },\n+          )\n+        }\n+      };\n+      Ok(Some(new_rc(JsxImportSourceConfig {\n+        module,\n+        import_source,\n+        import_source_types,\n+      })))\n+    }).map(|c| c.as_ref())\n+  }\n+\n+  pub fn check_js(&self) -> bool {\n+    *self.memoized.check_js.get_or_init(|| {\n+      self\n+        .sources\n+        .iter()\n+        .rev()\n+        .find_map(|s| {\n+          s.compiler_options\n+            .as_ref()?\n+            .0\n+            .as_object()?\n+            .get(\"checkJs\")?\n+            .as_bool()\n+        })\n+        .unwrap_or(false)\n+    })\n+  }\n+}\n+\n+// A resolved element of the `files` array in a tsconfig.\n+#[derive(Debug, Clone)]\n+pub struct TsConfigFile {\n+  pub relative_specifier: String,\n+  pub absolute_path: PathBuf,\n+}\n+\n+impl TsConfigFile {\n+  fn from_raw(raw: &str, dir_path: impl AsRef<Path>) -> Self {\n+    let relative_specifier = if raw.starts_with(\"./\")\n+      || raw.starts_with(\"../\")\n+      || raw.starts_with('/')\n+    {\n+      raw.to_string()\n+    } else {\n+      format!(\"./{raw}\")\n+    };\n+    let path = Path::new(raw);\n+    let absolute_path = if path.is_absolute() {\n+      normalize_path(path)\n+    } else {\n+      normalize_path(dir_path.as_ref().join(path))\n+    };\n+    Self {\n+      relative_specifier,\n+      absolute_path,\n+    }\n+  }\n }\n \n #[derive(Debug)]\n-pub struct TsConfigResolver<TSys: FsRead> {\n-  map: FolderScopedMap<TsConfigFolderInfo<TSys>>,\n+struct TsConfigFileFilter {\n+  // Note that `files`, `include` and `exclude` are overwritten, not merged,\n+  // when using `extends`. So we only need to store one referrer for `files`.\n+  // See: https://www.typescriptlang.org/tsconfig/#extends.\n+  files: Option<(Url, Vec<TsConfigFile>)>,\n+  include: Option<PathOrPatternSet>,\n+  exclude: Option<PathOrPatternSet>,\n+  dir_path: PathBuf,\n }\n \n-impl<TSys: FsRead + Clone> TsConfigResolver<TSys> {\n-  pub fn from_workspace(sys: &TSys, workspace: &WorkspaceRc) -> Self {\n-    // separate the workspace into directories that have compiler options\n-    let root_dir = workspace.resolve_member_dir(workspace.root_dir());\n-    let logged_warnings = new_rc(LoggedWarnings::default());\n-    let mut map = FolderScopedMap::new(TsConfigFolderInfo {\n-      dir: root_dir,\n-      logged_warnings: logged_warnings.clone(),\n-      memoized: Default::default(),\n-      sys: sys.clone(),\n-    });\n-    for (url, folder) in workspace.config_folders() {\n-      let folder_has_compiler_options = folder\n-        .deno_json\n-        .as_ref()\n-        .map(|d| d.json.compiler_options.is_some())\n-        .unwrap_or(false);\n-      if url != workspace.root_dir() && folder_has_compiler_options {\n-        let dir = workspace.resolve_member_dir(url);\n-        map.insert(\n-          url.clone(),\n-          TsConfigFolderInfo {\n-            dir,\n-            logged_warnings: logged_warnings.clone(),\n-            memoized: Default::default(),\n-            sys: sys.clone(),\n-          },\n-        );\n+impl TsConfigFileFilter {\n+  fn includes_path(&self, path: impl AsRef<Path>) -> bool {\n+    let path = path.as_ref();\n+    if let Some((_, files)) = &self.files {\n+      if files.iter().any(|f| f.absolute_path == path) {\n+        return true;\n+      }\n+    }\n+    if let Some(exclude) = &self.exclude {\n+      if exclude.matches_path(path) {\n+        return false;\n+      }\n+    }\n+    if let Some(include) = &self.include {\n+      if include.matches_path(path) {\n+        return true;\n       }\n+    } else if path.starts_with(&self.dir_path) {\n+      return true;\n     }\n-    Self { map }\n+    false\n   }\n }\n \n-impl<TSys: FsRead> TsConfigResolver<TSys> {\n-  pub fn check_js_for_specifier(&self, specifier: &Url) -> bool {\n-    self.folder_for_specifier(specifier).dir.check_js()\n+#[allow(clippy::disallowed_types)]\n+type TsConfigFileFilterRc = crate::sync::MaybeArc<TsConfigFileFilter>;\n+\n+#[derive(Debug)]\n+pub struct TsConfigData {\n+  pub compiler_options: CompilerOptionsData,\n+  filter: TsConfigFileFilterRc,\n+  references: Vec<String>,\n+}\n+\n+impl TsConfigData {\n+  pub fn files(&self) -> Option<(&Url, &Vec<TsConfigFile>)> {\n+    let (referrer, files) = self.filter.files.as_ref()?;\n+    Some((referrer, files))\n   }\n \n-  #[cfg(feature = \"deno_ast\")]\n-  pub fn transpile_and_emit_options(\n-    &self,\n-    specifier: &Url,\n-  ) -> Result<&TranspileAndEmitOptionsRc, CompilerOptionsParseError> {\n-    let value = self.map.get_for_specifier(specifier);\n-    value.transpile_options()\n+  fn specifier(&self) -> &Url {\n+    &self\n+      .compiler_options\n+      .sources\n+      .last()\n+      .expect(\"Tsconfigs should always have at least one source.\")\n+      .specifier\n   }\n+}\n \n-  pub fn folder_for_specifier(\n-    &self,\n-    specifier: &Url,\n-  ) -> &TsConfigFolderInfo<TSys> {\n-    self.folder_for_specifier_str(specifier.as_str())\n+fn is_maybe_directory_error(err: &std::io::Error) -> bool {\n+  let kind = err.kind();\n+  kind == ErrorKind::IsADirectory\n+    // This happens on Windows for some reason.\n+    || cfg!(windows) && kind == ErrorKind::PermissionDenied\n+}\n+\n+type TsConfigNodeResolver<TSys> = NodeResolver<\n+  DenoInNpmPackageChecker,\n+  DenoIsBuiltInNodeModuleChecker,\n+  NpmResolver<TSys>,\n+  TSys,\n+>;\n+\n+#[derive(Debug)]\n+struct TsConfigCollector<'a, TSys: FsRead, NSys: NpmResolverSys> {\n+  roots: BTreeSet<PathBuf>,\n+  collected: IndexMap<Url, Rc<TsConfigData>>,\n+  read_cache: HashMap<PathBuf, Result<Rc<TsConfigData>, Rc<std::io::Error>>>,\n+  currently_reading: IndexSet<PathBuf>,\n+  sys: &'a TSys,\n+  node_resolver: &'a TsConfigNodeResolver<NSys>,\n+  logged_warnings: &'a LoggedWarningsRc,\n+}\n+\n+impl<'a, TSys: FsRead, NSys: NpmResolverSys> TsConfigCollector<'a, TSys, NSys> {\n+  fn new(\n+    sys: &'a TSys,\n+    node_resolver: &'a TsConfigNodeResolver<NSys>,\n+    logged_warnings: &'a LoggedWarningsRc,\n+  ) -> Self {\n+    Self {\n+      roots: Default::default(),\n+      collected: Default::default(),\n+      read_cache: Default::default(),\n+      currently_reading: Default::default(),\n+      sys,\n+      node_resolver,\n+      logged_warnings,\n+    }\n   }\n \n-  pub fn folder_for_specifier_str(\n-    &self,\n-    specifier: &str,\n-  ) -> &TsConfigFolderInfo<TSys> {\n-    self.map.get_for_specifier_str(specifier)\n+  fn add_root(&mut self, path: PathBuf) {\n+    self.roots.insert(path);\n+  }\n+\n+  fn collect(mut self) -> Vec<TsConfigData> {\n+    for root in std::mem::take(&mut self.roots) {\n+      let Ok(ts_config) = self.read_ts_config_with_cache(root) else {\n+        continue;\n+      };\n+      self.visit_reference(ts_config);\n+    }\n+    let Self { collected, .. } = { self };\n+    collected\n+      .into_values()\n+      .map(|t| {\n+        Rc::try_unwrap(t).expect(\n+          \"No other references should be held since the read cache is dropped.\",\n+        )\n+      })\n+      .collect()\n+  }\n+\n+  fn visit_reference(&mut self, ts_config: Rc<TsConfigData>) {\n+    let specifier = ts_config.specifier();\n+    if self.collected.contains_key(specifier) {\n+      return;\n+    }\n+    let Some(dir_path) = url_to_file_path(specifier)\n+      .ok()\n+      .and_then(|p| Some(p.parent()?.to_path_buf()))\n+    else {\n+      return;\n+    };\n+    for reference in &ts_config.references {\n+      let reference_path = Path::new(reference);\n+      let reference_path = if reference_path.is_absolute() {\n+        Cow::Borrowed(reference_path)\n+      } else {\n+        Cow::Owned(dir_path.join(reference_path))\n+      };\n+      match self.read_ts_config_with_cache(&reference_path) {\n+        Ok(ts_config) => self.visit_reference(ts_config),\n+        Err(err) if is_maybe_directory_error(&err) => {\n+          if let Ok(ts_config) =\n+            self.read_ts_config_with_cache(reference_path.join(\"tsconfig.json\"))\n+          {\n+            self.visit_reference(ts_config)\n+          }\n+        }\n+        _ => {}\n+      }\n+    }\n+    self.collected.insert(specifier.clone(), ts_config);\n+  }\n+\n+  fn read_ts_config_with_cache(\n+    &mut self,\n+    path: impl AsRef<Path>,\n+  ) -> Result<Rc<TsConfigData>, Rc<std::io::Error>> {\n+    let path = normalize_path(path.as_ref());\n+    self.read_cache.get(&path).cloned().unwrap_or_else(|| {\n+      if !self.currently_reading.insert(path.clone()) {\n+        return Err(Rc::new(std::io::Error::new(\n+          ErrorKind::Other,\n+          \"Cycle detected while following `extends`.\",\n+        )));\n+      }\n+      let result = self.read_ts_config(&path).map(Rc::new).map_err(Rc::new);\n+      self.currently_reading.pop();\n+      self.read_cache.insert(path, result.clone());\n+      result\n+    })\n+  }\n+\n+  fn read_ts_config(\n+    &mut self,\n+    path: impl AsRef<Path>,\n+  ) -> Result<TsConfigData, std::io::Error> {\n+    let path = path.as_ref();\n+    let warn = |err: &dyn std::fmt::Display| {\n+      log::warn!(\"Failed reading {}: {}\", path.display(), err);\n+    };\n+    let specifier = url_from_file_path(path)\n+      .inspect_err(|e| warn(e))\n+      .map_err(|err| std::io::Error::new(ErrorKind::InvalidInput, err))?;\n+    let text = self.sys.fs_read_to_string(path).inspect_err(|e| {\n+      if e.kind() != ErrorKind::NotFound && !is_maybe_directory_error(e) {\n+        warn(e)\n+      }\n+    })?;",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "2169395416",
        "repo_full_name": "denoland/deno",
        "pr_number": 29843,
        "pr_file": "libs/resolver/deno_json.rs",
        "discussion_id": "2169395416",
        "commented_code": "@@ -111,109 +171,601 @@ impl<TSys: FsRead> TsConfigFolderInfo<TSys> {\n     &self,\n   ) -> Result<&TranspileAndEmitOptionsRc, CompilerOptionsParseError> {\n     self.memoized.transpile_options.get_or_try_init(|| {\n-      let compiler_options = self.emit_compiler_options()?;\n+      let compiler_options = self.compiler_options_for_emit()?;\n       compiler_options_to_transpile_and_emit_options(\n         compiler_options.as_ref().clone(),\n       )\n       .map(new_rc)\n       .map_err(|source| CompilerOptionsParseError {\n-        specifier: self\n-          .dir\n-          .maybe_deno_json()\n-          .map(|d| d.specifier.clone())\n-          .unwrap_or_else(|| {\n-            // will never happen because each dir should have a\n-            // deno.json if we got here\n-            debug_assert!(false);\n-            self.dir.dir_url().as_ref().clone()\n-          }),\n+        specifier: self.sources.last().map(|s| s.specifier.clone()).expect(\n+          \"Compiler options parse errors must come from a user source.\",\n+        ),\n         source,\n       })\n     })\n   }\n+\n+  pub fn compiler_options_types(&self) -> &CompilerOptionsTypesRc {\n+    self.memoized.compiler_options_types.get_or_init(|| {\n+      let types = self\n+        .sources\n+        .iter()\n+        .filter_map(|s| {\n+          let types = s\n+            .compiler_options\n+            .as_ref()?\n+            .0\n+            .as_object()?\n+            .get(\"types\")?\n+            .as_array()?\n+            .iter()\n+            .filter_map(|v| Some(v.as_str()?.to_string()))\n+            .collect();\n+          Some((s.specifier.clone(), types))\n+        })\n+        .collect();\n+      new_rc(types)\n+    })\n+  }\n+\n+  pub fn jsx_import_source_config(\n+    &self,\n+  ) -> Result<Option<&JsxImportSourceConfigRc>, ToMaybeJsxImportSourceConfigError>\n+  {\n+    self.memoized.jsx_import_source_config.get_or_try_init(|| {\n+      let jsx = self.sources.iter().rev().find_map(|s| Some((s.compiler_options.as_ref()?.0.as_object()?.get(\"jsx\")?.as_str()?, &s.specifier)));\n+      let is_jsx_automatic = matches!(\n+        jsx,\n+        Some((\"react-jsx\" | \"preserve\" | \"react-jsxdev\" | \"precompile\", _)),\n+      );\n+      let import_source = self.sources.iter().rev().find_map(|s| {\n+        Some(JsxImportSourceSpecifierConfig {\n+          specifier: s.compiler_options.as_ref()?.0.as_object()?.get(\"jsxImportSource\")?.as_str()?.to_string(),\n+          base: s.specifier.clone()\n+        })\n+      }).or_else(|| {\n+        if !is_jsx_automatic {\n+          return None;\n+        }\n+        Some(JsxImportSourceSpecifierConfig {\n+          base: self.sources.last()?.specifier.clone(),\n+          specifier: \"react\".to_string()\n+        })\n+      });\n+      let import_source_types = self.sources.iter().rev().find_map(|s| {\n+        Some(JsxImportSourceSpecifierConfig {\n+          specifier: s.compiler_options.as_ref()?.0.as_object()?.get(\"jsxImportSourceTypes\")?.as_str()?.to_string(),\n+          base: s.specifier.clone()\n+        })\n+      }).or_else(|| import_source.clone());\n+      let module = match jsx {\n+        Some((\"react-jsx\" | \"preserve\", _)) => \"jsx-runtime\".to_string(),\n+        Some((\"react-jsxdev\", _)) => \"jsx-dev-runtime\".to_string(),\n+        Some((\"react\", _)) | None => {\n+          if let Some(import_source) = &import_source {\n+            return Err(\n+              ToMaybeJsxImportSourceConfigError::InvalidJsxImportSourceValue(\n+                import_source.base.clone(),\n+              ),\n+            );\n+          }\n+          if let Some(import_source_types) = &import_source_types {\n+            return Err(\n+              ToMaybeJsxImportSourceConfigError::InvalidJsxImportSourceTypesValue(\n+                import_source_types.base.clone(),\n+              ),\n+            );\n+          }\n+          return Ok(None);\n+        }\n+        Some((\"precompile\", _)) => \"jsx-runtime\".to_string(),\n+        Some((setting, setting_source)) => {\n+          return Err(\n+            ToMaybeJsxImportSourceConfigError::InvalidJsxCompilerOption {\n+              value: setting.to_string(),\n+              specifier: setting_source.clone(),\n+            },\n+          )\n+        }\n+      };\n+      Ok(Some(new_rc(JsxImportSourceConfig {\n+        module,\n+        import_source,\n+        import_source_types,\n+      })))\n+    }).map(|c| c.as_ref())\n+  }\n+\n+  pub fn check_js(&self) -> bool {\n+    *self.memoized.check_js.get_or_init(|| {\n+      self\n+        .sources\n+        .iter()\n+        .rev()\n+        .find_map(|s| {\n+          s.compiler_options\n+            .as_ref()?\n+            .0\n+            .as_object()?\n+            .get(\"checkJs\")?\n+            .as_bool()\n+        })\n+        .unwrap_or(false)\n+    })\n+  }\n+}\n+\n+// A resolved element of the `files` array in a tsconfig.\n+#[derive(Debug, Clone)]\n+pub struct TsConfigFile {\n+  pub relative_specifier: String,\n+  pub absolute_path: PathBuf,\n+}\n+\n+impl TsConfigFile {\n+  fn from_raw(raw: &str, dir_path: impl AsRef<Path>) -> Self {\n+    let relative_specifier = if raw.starts_with(\"./\")\n+      || raw.starts_with(\"../\")\n+      || raw.starts_with('/')\n+    {\n+      raw.to_string()\n+    } else {\n+      format!(\"./{raw}\")\n+    };\n+    let path = Path::new(raw);\n+    let absolute_path = if path.is_absolute() {\n+      normalize_path(path)\n+    } else {\n+      normalize_path(dir_path.as_ref().join(path))\n+    };\n+    Self {\n+      relative_specifier,\n+      absolute_path,\n+    }\n+  }\n }\n \n #[derive(Debug)]\n-pub struct TsConfigResolver<TSys: FsRead> {\n-  map: FolderScopedMap<TsConfigFolderInfo<TSys>>,\n+struct TsConfigFileFilter {\n+  // Note that `files`, `include` and `exclude` are overwritten, not merged,\n+  // when using `extends`. So we only need to store one referrer for `files`.\n+  // See: https://www.typescriptlang.org/tsconfig/#extends.\n+  files: Option<(Url, Vec<TsConfigFile>)>,\n+  include: Option<PathOrPatternSet>,\n+  exclude: Option<PathOrPatternSet>,\n+  dir_path: PathBuf,\n }\n \n-impl<TSys: FsRead + Clone> TsConfigResolver<TSys> {\n-  pub fn from_workspace(sys: &TSys, workspace: &WorkspaceRc) -> Self {\n-    // separate the workspace into directories that have compiler options\n-    let root_dir = workspace.resolve_member_dir(workspace.root_dir());\n-    let logged_warnings = new_rc(LoggedWarnings::default());\n-    let mut map = FolderScopedMap::new(TsConfigFolderInfo {\n-      dir: root_dir,\n-      logged_warnings: logged_warnings.clone(),\n-      memoized: Default::default(),\n-      sys: sys.clone(),\n-    });\n-    for (url, folder) in workspace.config_folders() {\n-      let folder_has_compiler_options = folder\n-        .deno_json\n-        .as_ref()\n-        .map(|d| d.json.compiler_options.is_some())\n-        .unwrap_or(false);\n-      if url != workspace.root_dir() && folder_has_compiler_options {\n-        let dir = workspace.resolve_member_dir(url);\n-        map.insert(\n-          url.clone(),\n-          TsConfigFolderInfo {\n-            dir,\n-            logged_warnings: logged_warnings.clone(),\n-            memoized: Default::default(),\n-            sys: sys.clone(),\n-          },\n-        );\n+impl TsConfigFileFilter {\n+  fn includes_path(&self, path: impl AsRef<Path>) -> bool {\n+    let path = path.as_ref();\n+    if let Some((_, files)) = &self.files {\n+      if files.iter().any(|f| f.absolute_path == path) {\n+        return true;\n+      }\n+    }\n+    if let Some(exclude) = &self.exclude {\n+      if exclude.matches_path(path) {\n+        return false;\n+      }\n+    }\n+    if let Some(include) = &self.include {\n+      if include.matches_path(path) {\n+        return true;\n       }\n+    } else if path.starts_with(&self.dir_path) {\n+      return true;\n     }\n-    Self { map }\n+    false\n   }\n }\n \n-impl<TSys: FsRead> TsConfigResolver<TSys> {\n-  pub fn check_js_for_specifier(&self, specifier: &Url) -> bool {\n-    self.folder_for_specifier(specifier).dir.check_js()\n+#[allow(clippy::disallowed_types)]\n+type TsConfigFileFilterRc = crate::sync::MaybeArc<TsConfigFileFilter>;\n+\n+#[derive(Debug)]\n+pub struct TsConfigData {\n+  pub compiler_options: CompilerOptionsData,\n+  filter: TsConfigFileFilterRc,\n+  references: Vec<String>,\n+}\n+\n+impl TsConfigData {\n+  pub fn files(&self) -> Option<(&Url, &Vec<TsConfigFile>)> {\n+    let (referrer, files) = self.filter.files.as_ref()?;\n+    Some((referrer, files))\n   }\n \n-  #[cfg(feature = \"deno_ast\")]\n-  pub fn transpile_and_emit_options(\n-    &self,\n-    specifier: &Url,\n-  ) -> Result<&TranspileAndEmitOptionsRc, CompilerOptionsParseError> {\n-    let value = self.map.get_for_specifier(specifier);\n-    value.transpile_options()\n+  fn specifier(&self) -> &Url {\n+    &self\n+      .compiler_options\n+      .sources\n+      .last()\n+      .expect(\"Tsconfigs should always have at least one source.\")\n+      .specifier\n   }\n+}\n \n-  pub fn folder_for_specifier(\n-    &self,\n-    specifier: &Url,\n-  ) -> &TsConfigFolderInfo<TSys> {\n-    self.folder_for_specifier_str(specifier.as_str())\n+fn is_maybe_directory_error(err: &std::io::Error) -> bool {\n+  let kind = err.kind();\n+  kind == ErrorKind::IsADirectory\n+    // This happens on Windows for some reason.\n+    || cfg!(windows) && kind == ErrorKind::PermissionDenied\n+}\n+\n+type TsConfigNodeResolver<TSys> = NodeResolver<\n+  DenoInNpmPackageChecker,\n+  DenoIsBuiltInNodeModuleChecker,\n+  NpmResolver<TSys>,\n+  TSys,\n+>;\n+\n+#[derive(Debug)]\n+struct TsConfigCollector<'a, TSys: FsRead, NSys: NpmResolverSys> {\n+  roots: BTreeSet<PathBuf>,\n+  collected: IndexMap<Url, Rc<TsConfigData>>,\n+  read_cache: HashMap<PathBuf, Result<Rc<TsConfigData>, Rc<std::io::Error>>>,\n+  currently_reading: IndexSet<PathBuf>,\n+  sys: &'a TSys,\n+  node_resolver: &'a TsConfigNodeResolver<NSys>,\n+  logged_warnings: &'a LoggedWarningsRc,\n+}\n+\n+impl<'a, TSys: FsRead, NSys: NpmResolverSys> TsConfigCollector<'a, TSys, NSys> {\n+  fn new(\n+    sys: &'a TSys,\n+    node_resolver: &'a TsConfigNodeResolver<NSys>,\n+    logged_warnings: &'a LoggedWarningsRc,\n+  ) -> Self {\n+    Self {\n+      roots: Default::default(),\n+      collected: Default::default(),\n+      read_cache: Default::default(),\n+      currently_reading: Default::default(),\n+      sys,\n+      node_resolver,\n+      logged_warnings,\n+    }\n   }\n \n-  pub fn folder_for_specifier_str(\n-    &self,\n-    specifier: &str,\n-  ) -> &TsConfigFolderInfo<TSys> {\n-    self.map.get_for_specifier_str(specifier)\n+  fn add_root(&mut self, path: PathBuf) {\n+    self.roots.insert(path);\n+  }\n+\n+  fn collect(mut self) -> Vec<TsConfigData> {\n+    for root in std::mem::take(&mut self.roots) {\n+      let Ok(ts_config) = self.read_ts_config_with_cache(root) else {\n+        continue;\n+      };\n+      self.visit_reference(ts_config);\n+    }\n+    let Self { collected, .. } = { self };\n+    collected\n+      .into_values()\n+      .map(|t| {\n+        Rc::try_unwrap(t).expect(\n+          \"No other references should be held since the read cache is dropped.\",\n+        )\n+      })\n+      .collect()\n+  }\n+\n+  fn visit_reference(&mut self, ts_config: Rc<TsConfigData>) {\n+    let specifier = ts_config.specifier();\n+    if self.collected.contains_key(specifier) {\n+      return;\n+    }\n+    let Some(dir_path) = url_to_file_path(specifier)\n+      .ok()\n+      .and_then(|p| Some(p.parent()?.to_path_buf()))\n+    else {\n+      return;\n+    };\n+    for reference in &ts_config.references {\n+      let reference_path = Path::new(reference);\n+      let reference_path = if reference_path.is_absolute() {\n+        Cow::Borrowed(reference_path)\n+      } else {\n+        Cow::Owned(dir_path.join(reference_path))\n+      };\n+      match self.read_ts_config_with_cache(&reference_path) {\n+        Ok(ts_config) => self.visit_reference(ts_config),\n+        Err(err) if is_maybe_directory_error(&err) => {\n+          if let Ok(ts_config) =\n+            self.read_ts_config_with_cache(reference_path.join(\"tsconfig.json\"))\n+          {\n+            self.visit_reference(ts_config)\n+          }\n+        }\n+        _ => {}\n+      }\n+    }\n+    self.collected.insert(specifier.clone(), ts_config);\n+  }\n+\n+  fn read_ts_config_with_cache(\n+    &mut self,\n+    path: impl AsRef<Path>,\n+  ) -> Result<Rc<TsConfigData>, Rc<std::io::Error>> {\n+    let path = normalize_path(path.as_ref());\n+    self.read_cache.get(&path).cloned().unwrap_or_else(|| {\n+      if !self.currently_reading.insert(path.clone()) {\n+        return Err(Rc::new(std::io::Error::new(\n+          ErrorKind::Other,\n+          \"Cycle detected while following `extends`.\",\n+        )));\n+      }\n+      let result = self.read_ts_config(&path).map(Rc::new).map_err(Rc::new);\n+      self.currently_reading.pop();\n+      self.read_cache.insert(path, result.clone());\n+      result\n+    })\n+  }\n+\n+  fn read_ts_config(\n+    &mut self,\n+    path: impl AsRef<Path>,\n+  ) -> Result<TsConfigData, std::io::Error> {\n+    let path = path.as_ref();\n+    let warn = |err: &dyn std::fmt::Display| {\n+      log::warn!(\"Failed reading {}: {}\", path.display(), err);\n+    };\n+    let specifier = url_from_file_path(path)\n+      .inspect_err(|e| warn(e))\n+      .map_err(|err| std::io::Error::new(ErrorKind::InvalidInput, err))?;\n+    let text = self.sys.fs_read_to_string(path).inspect_err(|e| {\n+      if e.kind() != ErrorKind::NotFound && !is_maybe_directory_error(e) {\n+        warn(e)\n+      }\n+    })?;",
        "comment_created_at": "2025-06-26T15:55:56+00:00",
        "comment_author": "dsherret",
        "comment_body": "Why are these warning and returning the error?",
        "pr_file_module": null
      },
      {
        "comment_id": "2169440760",
        "repo_full_name": "denoland/deno",
        "pr_number": 29843,
        "pr_file": "libs/resolver/deno_json.rs",
        "discussion_id": "2169395416",
        "commented_code": "@@ -111,109 +171,601 @@ impl<TSys: FsRead> TsConfigFolderInfo<TSys> {\n     &self,\n   ) -> Result<&TranspileAndEmitOptionsRc, CompilerOptionsParseError> {\n     self.memoized.transpile_options.get_or_try_init(|| {\n-      let compiler_options = self.emit_compiler_options()?;\n+      let compiler_options = self.compiler_options_for_emit()?;\n       compiler_options_to_transpile_and_emit_options(\n         compiler_options.as_ref().clone(),\n       )\n       .map(new_rc)\n       .map_err(|source| CompilerOptionsParseError {\n-        specifier: self\n-          .dir\n-          .maybe_deno_json()\n-          .map(|d| d.specifier.clone())\n-          .unwrap_or_else(|| {\n-            // will never happen because each dir should have a\n-            // deno.json if we got here\n-            debug_assert!(false);\n-            self.dir.dir_url().as_ref().clone()\n-          }),\n+        specifier: self.sources.last().map(|s| s.specifier.clone()).expect(\n+          \"Compiler options parse errors must come from a user source.\",\n+        ),\n         source,\n       })\n     })\n   }\n+\n+  pub fn compiler_options_types(&self) -> &CompilerOptionsTypesRc {\n+    self.memoized.compiler_options_types.get_or_init(|| {\n+      let types = self\n+        .sources\n+        .iter()\n+        .filter_map(|s| {\n+          let types = s\n+            .compiler_options\n+            .as_ref()?\n+            .0\n+            .as_object()?\n+            .get(\"types\")?\n+            .as_array()?\n+            .iter()\n+            .filter_map(|v| Some(v.as_str()?.to_string()))\n+            .collect();\n+          Some((s.specifier.clone(), types))\n+        })\n+        .collect();\n+      new_rc(types)\n+    })\n+  }\n+\n+  pub fn jsx_import_source_config(\n+    &self,\n+  ) -> Result<Option<&JsxImportSourceConfigRc>, ToMaybeJsxImportSourceConfigError>\n+  {\n+    self.memoized.jsx_import_source_config.get_or_try_init(|| {\n+      let jsx = self.sources.iter().rev().find_map(|s| Some((s.compiler_options.as_ref()?.0.as_object()?.get(\"jsx\")?.as_str()?, &s.specifier)));\n+      let is_jsx_automatic = matches!(\n+        jsx,\n+        Some((\"react-jsx\" | \"preserve\" | \"react-jsxdev\" | \"precompile\", _)),\n+      );\n+      let import_source = self.sources.iter().rev().find_map(|s| {\n+        Some(JsxImportSourceSpecifierConfig {\n+          specifier: s.compiler_options.as_ref()?.0.as_object()?.get(\"jsxImportSource\")?.as_str()?.to_string(),\n+          base: s.specifier.clone()\n+        })\n+      }).or_else(|| {\n+        if !is_jsx_automatic {\n+          return None;\n+        }\n+        Some(JsxImportSourceSpecifierConfig {\n+          base: self.sources.last()?.specifier.clone(),\n+          specifier: \"react\".to_string()\n+        })\n+      });\n+      let import_source_types = self.sources.iter().rev().find_map(|s| {\n+        Some(JsxImportSourceSpecifierConfig {\n+          specifier: s.compiler_options.as_ref()?.0.as_object()?.get(\"jsxImportSourceTypes\")?.as_str()?.to_string(),\n+          base: s.specifier.clone()\n+        })\n+      }).or_else(|| import_source.clone());\n+      let module = match jsx {\n+        Some((\"react-jsx\" | \"preserve\", _)) => \"jsx-runtime\".to_string(),\n+        Some((\"react-jsxdev\", _)) => \"jsx-dev-runtime\".to_string(),\n+        Some((\"react\", _)) | None => {\n+          if let Some(import_source) = &import_source {\n+            return Err(\n+              ToMaybeJsxImportSourceConfigError::InvalidJsxImportSourceValue(\n+                import_source.base.clone(),\n+              ),\n+            );\n+          }\n+          if let Some(import_source_types) = &import_source_types {\n+            return Err(\n+              ToMaybeJsxImportSourceConfigError::InvalidJsxImportSourceTypesValue(\n+                import_source_types.base.clone(),\n+              ),\n+            );\n+          }\n+          return Ok(None);\n+        }\n+        Some((\"precompile\", _)) => \"jsx-runtime\".to_string(),\n+        Some((setting, setting_source)) => {\n+          return Err(\n+            ToMaybeJsxImportSourceConfigError::InvalidJsxCompilerOption {\n+              value: setting.to_string(),\n+              specifier: setting_source.clone(),\n+            },\n+          )\n+        }\n+      };\n+      Ok(Some(new_rc(JsxImportSourceConfig {\n+        module,\n+        import_source,\n+        import_source_types,\n+      })))\n+    }).map(|c| c.as_ref())\n+  }\n+\n+  pub fn check_js(&self) -> bool {\n+    *self.memoized.check_js.get_or_init(|| {\n+      self\n+        .sources\n+        .iter()\n+        .rev()\n+        .find_map(|s| {\n+          s.compiler_options\n+            .as_ref()?\n+            .0\n+            .as_object()?\n+            .get(\"checkJs\")?\n+            .as_bool()\n+        })\n+        .unwrap_or(false)\n+    })\n+  }\n+}\n+\n+// A resolved element of the `files` array in a tsconfig.\n+#[derive(Debug, Clone)]\n+pub struct TsConfigFile {\n+  pub relative_specifier: String,\n+  pub absolute_path: PathBuf,\n+}\n+\n+impl TsConfigFile {\n+  fn from_raw(raw: &str, dir_path: impl AsRef<Path>) -> Self {\n+    let relative_specifier = if raw.starts_with(\"./\")\n+      || raw.starts_with(\"../\")\n+      || raw.starts_with('/')\n+    {\n+      raw.to_string()\n+    } else {\n+      format!(\"./{raw}\")\n+    };\n+    let path = Path::new(raw);\n+    let absolute_path = if path.is_absolute() {\n+      normalize_path(path)\n+    } else {\n+      normalize_path(dir_path.as_ref().join(path))\n+    };\n+    Self {\n+      relative_specifier,\n+      absolute_path,\n+    }\n+  }\n }\n \n #[derive(Debug)]\n-pub struct TsConfigResolver<TSys: FsRead> {\n-  map: FolderScopedMap<TsConfigFolderInfo<TSys>>,\n+struct TsConfigFileFilter {\n+  // Note that `files`, `include` and `exclude` are overwritten, not merged,\n+  // when using `extends`. So we only need to store one referrer for `files`.\n+  // See: https://www.typescriptlang.org/tsconfig/#extends.\n+  files: Option<(Url, Vec<TsConfigFile>)>,\n+  include: Option<PathOrPatternSet>,\n+  exclude: Option<PathOrPatternSet>,\n+  dir_path: PathBuf,\n }\n \n-impl<TSys: FsRead + Clone> TsConfigResolver<TSys> {\n-  pub fn from_workspace(sys: &TSys, workspace: &WorkspaceRc) -> Self {\n-    // separate the workspace into directories that have compiler options\n-    let root_dir = workspace.resolve_member_dir(workspace.root_dir());\n-    let logged_warnings = new_rc(LoggedWarnings::default());\n-    let mut map = FolderScopedMap::new(TsConfigFolderInfo {\n-      dir: root_dir,\n-      logged_warnings: logged_warnings.clone(),\n-      memoized: Default::default(),\n-      sys: sys.clone(),\n-    });\n-    for (url, folder) in workspace.config_folders() {\n-      let folder_has_compiler_options = folder\n-        .deno_json\n-        .as_ref()\n-        .map(|d| d.json.compiler_options.is_some())\n-        .unwrap_or(false);\n-      if url != workspace.root_dir() && folder_has_compiler_options {\n-        let dir = workspace.resolve_member_dir(url);\n-        map.insert(\n-          url.clone(),\n-          TsConfigFolderInfo {\n-            dir,\n-            logged_warnings: logged_warnings.clone(),\n-            memoized: Default::default(),\n-            sys: sys.clone(),\n-          },\n-        );\n+impl TsConfigFileFilter {\n+  fn includes_path(&self, path: impl AsRef<Path>) -> bool {\n+    let path = path.as_ref();\n+    if let Some((_, files)) = &self.files {\n+      if files.iter().any(|f| f.absolute_path == path) {\n+        return true;\n+      }\n+    }\n+    if let Some(exclude) = &self.exclude {\n+      if exclude.matches_path(path) {\n+        return false;\n+      }\n+    }\n+    if let Some(include) = &self.include {\n+      if include.matches_path(path) {\n+        return true;\n       }\n+    } else if path.starts_with(&self.dir_path) {\n+      return true;\n     }\n-    Self { map }\n+    false\n   }\n }\n \n-impl<TSys: FsRead> TsConfigResolver<TSys> {\n-  pub fn check_js_for_specifier(&self, specifier: &Url) -> bool {\n-    self.folder_for_specifier(specifier).dir.check_js()\n+#[allow(clippy::disallowed_types)]\n+type TsConfigFileFilterRc = crate::sync::MaybeArc<TsConfigFileFilter>;\n+\n+#[derive(Debug)]\n+pub struct TsConfigData {\n+  pub compiler_options: CompilerOptionsData,\n+  filter: TsConfigFileFilterRc,\n+  references: Vec<String>,\n+}\n+\n+impl TsConfigData {\n+  pub fn files(&self) -> Option<(&Url, &Vec<TsConfigFile>)> {\n+    let (referrer, files) = self.filter.files.as_ref()?;\n+    Some((referrer, files))\n   }\n \n-  #[cfg(feature = \"deno_ast\")]\n-  pub fn transpile_and_emit_options(\n-    &self,\n-    specifier: &Url,\n-  ) -> Result<&TranspileAndEmitOptionsRc, CompilerOptionsParseError> {\n-    let value = self.map.get_for_specifier(specifier);\n-    value.transpile_options()\n+  fn specifier(&self) -> &Url {\n+    &self\n+      .compiler_options\n+      .sources\n+      .last()\n+      .expect(\"Tsconfigs should always have at least one source.\")\n+      .specifier\n   }\n+}\n \n-  pub fn folder_for_specifier(\n-    &self,\n-    specifier: &Url,\n-  ) -> &TsConfigFolderInfo<TSys> {\n-    self.folder_for_specifier_str(specifier.as_str())\n+fn is_maybe_directory_error(err: &std::io::Error) -> bool {\n+  let kind = err.kind();\n+  kind == ErrorKind::IsADirectory\n+    // This happens on Windows for some reason.\n+    || cfg!(windows) && kind == ErrorKind::PermissionDenied\n+}\n+\n+type TsConfigNodeResolver<TSys> = NodeResolver<\n+  DenoInNpmPackageChecker,\n+  DenoIsBuiltInNodeModuleChecker,\n+  NpmResolver<TSys>,\n+  TSys,\n+>;\n+\n+#[derive(Debug)]\n+struct TsConfigCollector<'a, TSys: FsRead, NSys: NpmResolverSys> {\n+  roots: BTreeSet<PathBuf>,\n+  collected: IndexMap<Url, Rc<TsConfigData>>,\n+  read_cache: HashMap<PathBuf, Result<Rc<TsConfigData>, Rc<std::io::Error>>>,\n+  currently_reading: IndexSet<PathBuf>,\n+  sys: &'a TSys,\n+  node_resolver: &'a TsConfigNodeResolver<NSys>,\n+  logged_warnings: &'a LoggedWarningsRc,\n+}\n+\n+impl<'a, TSys: FsRead, NSys: NpmResolverSys> TsConfigCollector<'a, TSys, NSys> {\n+  fn new(\n+    sys: &'a TSys,\n+    node_resolver: &'a TsConfigNodeResolver<NSys>,\n+    logged_warnings: &'a LoggedWarningsRc,\n+  ) -> Self {\n+    Self {\n+      roots: Default::default(),\n+      collected: Default::default(),\n+      read_cache: Default::default(),\n+      currently_reading: Default::default(),\n+      sys,\n+      node_resolver,\n+      logged_warnings,\n+    }\n   }\n \n-  pub fn folder_for_specifier_str(\n-    &self,\n-    specifier: &str,\n-  ) -> &TsConfigFolderInfo<TSys> {\n-    self.map.get_for_specifier_str(specifier)\n+  fn add_root(&mut self, path: PathBuf) {\n+    self.roots.insert(path);\n+  }\n+\n+  fn collect(mut self) -> Vec<TsConfigData> {\n+    for root in std::mem::take(&mut self.roots) {\n+      let Ok(ts_config) = self.read_ts_config_with_cache(root) else {\n+        continue;\n+      };\n+      self.visit_reference(ts_config);\n+    }\n+    let Self { collected, .. } = { self };\n+    collected\n+      .into_values()\n+      .map(|t| {\n+        Rc::try_unwrap(t).expect(\n+          \"No other references should be held since the read cache is dropped.\",\n+        )\n+      })\n+      .collect()\n+  }\n+\n+  fn visit_reference(&mut self, ts_config: Rc<TsConfigData>) {\n+    let specifier = ts_config.specifier();\n+    if self.collected.contains_key(specifier) {\n+      return;\n+    }\n+    let Some(dir_path) = url_to_file_path(specifier)\n+      .ok()\n+      .and_then(|p| Some(p.parent()?.to_path_buf()))\n+    else {\n+      return;\n+    };\n+    for reference in &ts_config.references {\n+      let reference_path = Path::new(reference);\n+      let reference_path = if reference_path.is_absolute() {\n+        Cow::Borrowed(reference_path)\n+      } else {\n+        Cow::Owned(dir_path.join(reference_path))\n+      };\n+      match self.read_ts_config_with_cache(&reference_path) {\n+        Ok(ts_config) => self.visit_reference(ts_config),\n+        Err(err) if is_maybe_directory_error(&err) => {\n+          if let Ok(ts_config) =\n+            self.read_ts_config_with_cache(reference_path.join(\"tsconfig.json\"))\n+          {\n+            self.visit_reference(ts_config)\n+          }\n+        }\n+        _ => {}\n+      }\n+    }\n+    self.collected.insert(specifier.clone(), ts_config);\n+  }\n+\n+  fn read_ts_config_with_cache(\n+    &mut self,\n+    path: impl AsRef<Path>,\n+  ) -> Result<Rc<TsConfigData>, Rc<std::io::Error>> {\n+    let path = normalize_path(path.as_ref());\n+    self.read_cache.get(&path).cloned().unwrap_or_else(|| {\n+      if !self.currently_reading.insert(path.clone()) {\n+        return Err(Rc::new(std::io::Error::new(\n+          ErrorKind::Other,\n+          \"Cycle detected while following `extends`.\",\n+        )));\n+      }\n+      let result = self.read_ts_config(&path).map(Rc::new).map_err(Rc::new);\n+      self.currently_reading.pop();\n+      self.read_cache.insert(path, result.clone());\n+      result\n+    })\n+  }\n+\n+  fn read_ts_config(\n+    &mut self,\n+    path: impl AsRef<Path>,\n+  ) -> Result<TsConfigData, std::io::Error> {\n+    let path = path.as_ref();\n+    let warn = |err: &dyn std::fmt::Display| {\n+      log::warn!(\"Failed reading {}: {}\", path.display(), err);\n+    };\n+    let specifier = url_from_file_path(path)\n+      .inspect_err(|e| warn(e))\n+      .map_err(|err| std::io::Error::new(ErrorKind::InvalidInput, err))?;\n+    let text = self.sys.fs_read_to_string(path).inspect_err(|e| {\n+      if e.kind() != ErrorKind::NotFound && !is_maybe_directory_error(e) {\n+        warn(e)\n+      }\n+    })?;",
        "comment_created_at": "2025-06-26T16:22:17+00:00",
        "comment_author": "nayeemrmn",
        "comment_body": "It warns for unexpected errors (other than 'not found' and 'is a directory'), returns it regardless so the result can be cached but the rest is handled silently.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2008361144",
    "pr_number": 28575,
    "pr_file": "cli/tools/run/mod.rs",
    "created_at": "2025-03-21T21:36:47+00:00",
    "commented_code": "use crate::npm::installer::PackageCaching;\n use crate::util;\n use crate::util::file_watcher::WatcherRestartMode;\n+use deno_core::anyhow::bail;\n+use deno_path_util::url_to_file_path;\n \n pub mod hmr;\n \n+/// Heuristically determine if the provided npm binary entrypoint should be\n+/// executed as a Node/JS script within the Deno runtime or spawned as an\n+/// external process. Returns `Ok(true)` if the binary appears to be a JS file.\n+/// At minimum, this checks known script extensions as well as a shebang with\n+/// `node` in its path. Binaries that don't match this heuristic are assumed to\n+/// be non-JS executables (for example, compiled binaries or shell scripts).\n+fn is_node_cli_like(path: &std::path::Path) -> std::io::Result<bool> {\n+  let ext = path.extension().and_then(|p| p.to_str()).unwrap_or(\"\");\n+  // if we have a known JS/TS extension, assume it's a script.\n+  if matches!(ext, \"js\" | \"cjs\" | \"mjs\" | \"ts\" | \"cts\" | \"mts\") {\n+    return Ok(true);\n+  }\n+  // Otherwise try to read the first line to look for a node shebang.\n+  let file = std::fs::File::open(path)?;\n+  let mut reader = std::io::BufReader::new(file);\n+  let mut first_line = String::new();\n+  if reader.read_line(&mut first_line)? == 0 {",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "2008361144",
        "repo_full_name": "denoland/deno",
        "pr_number": 28575,
        "pr_file": "cli/tools/run/mod.rs",
        "discussion_id": "2008361144",
        "commented_code": "@@ -21,9 +22,36 @@ use crate::factory::CliFactory;\n use crate::npm::installer::PackageCaching;\n use crate::util;\n use crate::util::file_watcher::WatcherRestartMode;\n+use deno_core::anyhow::bail;\n+use deno_path_util::url_to_file_path;\n \n pub mod hmr;\n \n+/// Heuristically determine if the provided npm binary entrypoint should be\n+/// executed as a Node/JS script within the Deno runtime or spawned as an\n+/// external process. Returns `Ok(true)` if the binary appears to be a JS file.\n+/// At minimum, this checks known script extensions as well as a shebang with\n+/// `node` in its path. Binaries that don't match this heuristic are assumed to\n+/// be non-JS executables (for example, compiled binaries or shell scripts).\n+fn is_node_cli_like(path: &std::path::Path) -> std::io::Result<bool> {\n+  let ext = path.extension().and_then(|p| p.to_str()).unwrap_or(\"\");\n+  // if we have a known JS/TS extension, assume it's a script.\n+  if matches!(ext, \"js\" | \"cjs\" | \"mjs\" | \"ts\" | \"cts\" | \"mts\") {\n+    return Ok(true);\n+  }\n+  // Otherwise try to read the first line to look for a node shebang.\n+  let file = std::fs::File::open(path)?;\n+  let mut reader = std::io::BufReader::new(file);\n+  let mut first_line = String::new();\n+  if reader.read_line(&mut first_line)? == 0 {",
        "comment_created_at": "2025-03-21T21:36:47+00:00",
        "comment_author": "nathanwhit",
        "comment_body": "I believe this will fail on binaries, because it won't be a utf8 string or have any \"lines\" to read.\r\n\r\nI think if this fails we just have to assume it's a binary and return false",
        "pr_file_module": null
      },
      {
        "comment_id": "2011413198",
        "repo_full_name": "denoland/deno",
        "pr_number": 28575,
        "pr_file": "cli/tools/run/mod.rs",
        "discussion_id": "2008361144",
        "commented_code": "@@ -21,9 +22,36 @@ use crate::factory::CliFactory;\n use crate::npm::installer::PackageCaching;\n use crate::util;\n use crate::util::file_watcher::WatcherRestartMode;\n+use deno_core::anyhow::bail;\n+use deno_path_util::url_to_file_path;\n \n pub mod hmr;\n \n+/// Heuristically determine if the provided npm binary entrypoint should be\n+/// executed as a Node/JS script within the Deno runtime or spawned as an\n+/// external process. Returns `Ok(true)` if the binary appears to be a JS file.\n+/// At minimum, this checks known script extensions as well as a shebang with\n+/// `node` in its path. Binaries that don't match this heuristic are assumed to\n+/// be non-JS executables (for example, compiled binaries or shell scripts).\n+fn is_node_cli_like(path: &std::path::Path) -> std::io::Result<bool> {\n+  let ext = path.extension().and_then(|p| p.to_str()).unwrap_or(\"\");\n+  // if we have a known JS/TS extension, assume it's a script.\n+  if matches!(ext, \"js\" | \"cjs\" | \"mjs\" | \"ts\" | \"cts\" | \"mts\") {\n+    return Ok(true);\n+  }\n+  // Otherwise try to read the first line to look for a node shebang.\n+  let file = std::fs::File::open(path)?;\n+  let mut reader = std::io::BufReader::new(file);\n+  let mut first_line = String::new();\n+  if reader.read_line(&mut first_line)? == 0 {",
        "comment_created_at": "2025-03-25T06:36:50+00:00",
        "comment_author": "gopoto",
        "comment_body": "Good catch. Updated `is_node_cli_like` to guard against `InvalidData` from reading a binary and treat that as `false`.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1970689122",
    "pr_number": 28260,
    "pr_file": "cli/tools/coverage/reporter.rs",
    "created_at": "2025-02-25T23:37:19+00:00",
    "commented_code": "}\n }\n \n-struct LcovCoverageReporter {}\n+pub struct LcovCoverageReporter {}\n \n impl CoverageReporter for LcovCoverageReporter {\n   fn done(\n-    &mut self,\n+    &self,\n     _coverage_root: &Path,\n     file_reports: &[(CoverageReport, String)],\n   ) {\n     file_reports.iter().for_each(|(report, file_text)| {\n       self.report(report, file_text).unwrap();\n     });\n+    if let Some((report, _)) = file_reports.first() {\n+      if let Some(ref output) = report.output {\n+        let path = output.canonicalize().unwrap().to_string_lossy().to_string();",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "1970689122",
        "repo_full_name": "denoland/deno",
        "pr_number": 28260,
        "pr_file": "cli/tools/coverage/reporter.rs",
        "discussion_id": "1970689122",
        "commented_code": "@@ -206,17 +206,24 @@ impl CoverageReporter for SummaryCoverageReporter {\n   }\n }\n \n-struct LcovCoverageReporter {}\n+pub struct LcovCoverageReporter {}\n \n impl CoverageReporter for LcovCoverageReporter {\n   fn done(\n-    &mut self,\n+    &self,\n     _coverage_root: &Path,\n     file_reports: &[(CoverageReport, String)],\n   ) {\n     file_reports.iter().for_each(|(report, file_text)| {\n       self.report(report, file_text).unwrap();\n     });\n+    if let Some((report, _)) = file_reports.first() {\n+      if let Some(ref output) = report.output {\n+        let path = output.canonicalize().unwrap().to_string_lossy().to_string();",
        "comment_created_at": "2025-02-25T23:37:19+00:00",
        "comment_author": "bartlomieju",
        "comment_body": "This unwrap is sus here \ud83d\ude2c maybe consider failing gracefully with an error message? Also you don't need to do the conversion to string first - `Url::from_file_path` will accept a `PathBuf`",
        "pr_file_module": null
      },
      {
        "comment_id": "1971168948",
        "repo_full_name": "denoland/deno",
        "pr_number": 28260,
        "pr_file": "cli/tools/coverage/reporter.rs",
        "discussion_id": "1970689122",
        "commented_code": "@@ -206,17 +206,24 @@ impl CoverageReporter for SummaryCoverageReporter {\n   }\n }\n \n-struct LcovCoverageReporter {}\n+pub struct LcovCoverageReporter {}\n \n impl CoverageReporter for LcovCoverageReporter {\n   fn done(\n-    &mut self,\n+    &self,\n     _coverage_root: &Path,\n     file_reports: &[(CoverageReport, String)],\n   ) {\n     file_reports.iter().for_each(|(report, file_text)| {\n       self.report(report, file_text).unwrap();\n     });\n+    if let Some((report, _)) = file_reports.first() {\n+      if let Some(ref output) = report.output {\n+        let path = output.canonicalize().unwrap().to_string_lossy().to_string();",
        "comment_created_at": "2025-02-26T08:45:20+00:00",
        "comment_author": "kt3k",
        "comment_body": "Updated. Now it prints error message when `.canonicalize` failed",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1842479810",
    "pr_number": 26590,
    "pr_file": "cli/tools/coverage/mod.rs",
    "created_at": "2024-11-14T16:01:11+00:00",
    "commented_code": "output: Option<PathBuf>,\n }\n \n+struct GenerateCoverageReportOptions<'a> {\n+  cli_options: &'a CliOptions,\n+  script_module_specifier: Url,\n+  script_media_type: MediaType,\n+  script_coverage: &'a cdp::ScriptCoverage,\n+  script_original_source: String,\n+  script_runtime_source: String,\n+  maybe_source_map: &'a Option<Vec<u8>>,\n+  output: &'a Option<PathBuf>,\n+}\n+\n fn generate_coverage_report(\n-  script_coverage: &cdp::ScriptCoverage,\n-  script_source: String,\n-  maybe_source_map: &Option<Vec<u8>>,\n-  output: &Option<PathBuf>,\n+  options: GenerateCoverageReportOptions,\n ) -> CoverageReport {\n-  let maybe_source_map = maybe_source_map\n+  let parsed_source = parse_program(\n+    options.script_module_specifier,\n+    options.script_media_type,\n+    &options.script_original_source,\n+  )\n+  .expect(\"invalid source code\");",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "1842479810",
        "repo_full_name": "denoland/deno",
        "pr_number": 26590,
        "pr_file": "cli/tools/coverage/mod.rs",
        "discussion_id": "1842479810",
        "commented_code": "@@ -194,41 +201,89 @@ pub struct CoverageReport {\n   output: Option<PathBuf>,\n }\n \n+struct GenerateCoverageReportOptions<'a> {\n+  cli_options: &'a CliOptions,\n+  script_module_specifier: Url,\n+  script_media_type: MediaType,\n+  script_coverage: &'a cdp::ScriptCoverage,\n+  script_original_source: String,\n+  script_runtime_source: String,\n+  maybe_source_map: &'a Option<Vec<u8>>,\n+  output: &'a Option<PathBuf>,\n+}\n+\n fn generate_coverage_report(\n-  script_coverage: &cdp::ScriptCoverage,\n-  script_source: String,\n-  maybe_source_map: &Option<Vec<u8>>,\n-  output: &Option<PathBuf>,\n+  options: GenerateCoverageReportOptions,\n ) -> CoverageReport {\n-  let maybe_source_map = maybe_source_map\n+  let parsed_source = parse_program(\n+    options.script_module_specifier,\n+    options.script_media_type,\n+    &options.script_original_source,\n+  )\n+  .expect(\"invalid source code\");",
        "comment_created_at": "2024-11-14T16:01:11+00:00",
        "comment_author": "bartlomieju",
        "comment_body": "We shouldn't use `expect` here - we're gonna find all sorts of strange or broken files that are included by mistake - we should error out or print a warning in this case instead of panicking.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2007629162",
    "pr_number": 28578,
    "pr_file": "cli/graph_util.rs",
    "created_at": "2025-03-21T13:55:01+00:00",
    "commented_code": ".unwrap_or_else(|| format_deno_graph_error(error))\n     }\n   };\n-\n-  if let Some(range) = error.maybe_range() {\n-    if mode == EnhanceGraphErrorMode::ShowRange\n-      && !range.specifier.as_str().contains(\"/$deno$eval\")\n-    {\n-      message.push_str(\"\n    at \");\n-      message.push_str(&format_range_with_colors(range));\n+  // attempt to provide some context for the error if we have a range.\n+  // For resolution errors in Wasm modules the specifier range is often\n+  // missing, but we can fall back to the referrer range if available.\n+  if mode == EnhanceGraphErrorMode::ShowRange {\n+    // first attempt to use the error's specifier range\n+    let mut maybe_range = error.maybe_range();\n+    if maybe_range.is_none() {\n+      // fallback: for resolution errors use the referrer's range\n+      if let ModuleGraphError::ResolutionError(resolution_error) = error {\n+        // resolution errors always have a referrer range on the variant itself\n+        // which points to the location in the importing module.\n+        // When the specifier range is missing (ex. wasm binary), fall back to this.\n+        use deno_graph::ResolutionError;\n+        maybe_range = match resolution_error {\n+          ResolutionError::InvalidSpecifier { range, .. } => Some(range),\n+          ResolutionError::ResolverError { range, .. } => Some(range),\n+          _ => None,\n+        };",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "2007629162",
        "repo_full_name": "denoland/deno",
        "pr_number": 28578,
        "pr_file": "cli/graph_util.rs",
        "discussion_id": "2007629162",
        "commented_code": "@@ -330,13 +330,31 @@ pub fn enhance_graph_error(\n         .unwrap_or_else(|| format_deno_graph_error(error))\n     }\n   };\n-\n-  if let Some(range) = error.maybe_range() {\n-    if mode == EnhanceGraphErrorMode::ShowRange\n-      && !range.specifier.as_str().contains(\"/$deno$eval\")\n-    {\n-      message.push_str(\"\\n    at \");\n-      message.push_str(&format_range_with_colors(range));\n+  // attempt to provide some context for the error if we have a range.\n+  // For resolution errors in Wasm modules the specifier range is often\n+  // missing, but we can fall back to the referrer range if available.\n+  if mode == EnhanceGraphErrorMode::ShowRange {\n+    // first attempt to use the error's specifier range\n+    let mut maybe_range = error.maybe_range();\n+    if maybe_range.is_none() {\n+      // fallback: for resolution errors use the referrer's range\n+      if let ModuleGraphError::ResolutionError(resolution_error) = error {\n+        // resolution errors always have a referrer range on the variant itself\n+        // which points to the location in the importing module.\n+        // When the specifier range is missing (ex. wasm binary), fall back to this.\n+        use deno_graph::ResolutionError;\n+        maybe_range = match resolution_error {\n+          ResolutionError::InvalidSpecifier { range, .. } => Some(range),\n+          ResolutionError::ResolverError { range, .. } => Some(range),\n+          _ => None,\n+        };",
        "comment_created_at": "2025-03-21T13:55:01+00:00",
        "comment_author": "dsherret",
        "comment_body": "I think this is doing what `error.maybe_range()` does internally? https://github.com/denoland/deno_graph/blob/961df5f16a0bb28a530612172b2f58e4482f287e/src/graph.rs#L426C14-L426C24",
        "pr_file_module": null
      },
      {
        "comment_id": "2011411029",
        "repo_full_name": "denoland/deno",
        "pr_number": 28578,
        "pr_file": "cli/graph_util.rs",
        "discussion_id": "2007629162",
        "commented_code": "@@ -330,13 +330,31 @@ pub fn enhance_graph_error(\n         .unwrap_or_else(|| format_deno_graph_error(error))\n     }\n   };\n-\n-  if let Some(range) = error.maybe_range() {\n-    if mode == EnhanceGraphErrorMode::ShowRange\n-      && !range.specifier.as_str().contains(\"/$deno$eval\")\n-    {\n-      message.push_str(\"\\n    at \");\n-      message.push_str(&format_range_with_colors(range));\n+  // attempt to provide some context for the error if we have a range.\n+  // For resolution errors in Wasm modules the specifier range is often\n+  // missing, but we can fall back to the referrer range if available.\n+  if mode == EnhanceGraphErrorMode::ShowRange {\n+    // first attempt to use the error's specifier range\n+    let mut maybe_range = error.maybe_range();\n+    if maybe_range.is_none() {\n+      // fallback: for resolution errors use the referrer's range\n+      if let ModuleGraphError::ResolutionError(resolution_error) = error {\n+        // resolution errors always have a referrer range on the variant itself\n+        // which points to the location in the importing module.\n+        // When the specifier range is missing (ex. wasm binary), fall back to this.\n+        use deno_graph::ResolutionError;\n+        maybe_range = match resolution_error {\n+          ResolutionError::InvalidSpecifier { range, .. } => Some(range),\n+          ResolutionError::ResolverError { range, .. } => Some(range),\n+          _ => None,\n+        };",
        "comment_created_at": "2025-03-25T06:34:49+00:00",
        "comment_author": "gopoto",
        "comment_body": "Good point \u2013 `maybe_range()` already walks the error variants, so I dropped the extra match arm.",
        "pr_file_module": null
      }
    ]
  }
]