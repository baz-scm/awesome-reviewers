[
  {
    "discussion_id": "2067452632",
    "pr_number": 28424,
    "pr_file": "cli/tools/clean.rs",
    "created_at": "2025-04-29T21:25:10+00:00",
    "commented_code": "Ok(())\n }\n \n+#[derive(Clone, Debug, Default)]\n+struct PathNode {\n+  exact: bool,\n+  children: BTreeMap<OsString, usize>,\n+}\n+#[derive(Debug)]\n+struct PathTrie {\n+  root: usize,\n+  nodes: Vec<PathNode>,\n+  rewrites: Vec<(PathBuf, PathBuf)>,\n+}\n+\n+#[derive(Clone, Copy, PartialEq, Eq, Debug)]\n+enum Found {\n+  Match,\n+  Prefix,\n+}\n+\n+impl PathTrie {\n+  fn new() -> Self {\n+    Self {\n+      root: 0,\n+      nodes: vec![PathNode {\n+        exact: false,\n+        children: Default::default(),\n+      }],\n+      rewrites: vec![],\n+    }\n+  }\n+\n+  fn add_rewrite(&mut self, from: PathBuf, to: PathBuf) {\n+    self.rewrites.push((from, to));\n+  }\n+\n+  fn rewrite(&self, s: &Path) -> PathBuf {\n+    let normalized = deno_path_util::normalize_path(s);\n+    for (from, to) in &self.rewrites {\n+      if normalized.starts_with(from) {\n+        return to.join(normalized.strip_prefix(from).unwrap());\n+      }\n+    }\n+    normalized\n+  }\n+\n+  fn insert(&mut self, s: &Path) {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        let id = self.nodes.len();\n+        self.nodes.push(PathNode::default());\n+        self.nodes[node]\n+          .children\n+          .insert(component.to_os_string(), id);\n+        node = id;\n+      }\n+    }\n+\n+    self.nodes[node].exact = true;\n+  }\n+\n+  fn find(&self, s: &Path) -> Option<Found> {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        return None;\n+      }\n+    }\n+\n+    Some(if self.nodes[node].exact {\n+      Found::Match\n+    } else {\n+      Found::Prefix\n+    })\n+  }\n+}\n+\n+fn try_get_canonicalized_root_dir<Sys: FsCanonicalize + FsCreateDirAll>(\n+  sys: &Sys,\n+  root_dir: &Path,\n+) -> Result<PathBuf, std::io::Error> {\n+  match sys.fs_canonicalize(root_dir) {\n+    Ok(path) => Ok(path),\n+    Err(err) if err.kind() == std::io::ErrorKind::NotFound => {\n+      sys.fs_create_dir_all(root_dir)?;\n+      sys.fs_canonicalize(root_dir)\n+    }\n+    Err(err) => Err(err),\n+  }\n+}\n+\n+async fn clean_except(\n+  flags: Arc<Flags>,\n+  entrypoints: &[String],\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut state = CleanState::default();\n+\n+  let factory = CliFactory::from_flags(flags.clone());\n+  let sys = factory.sys();\n+  let options = factory.cli_options()?;\n+  let main_graph_container = factory.main_module_graph_container().await?;\n+  let roots = main_graph_container.collect_specifiers(entrypoints)?;\n+  let http_cache = factory.global_http_cache()?;\n+  let local_or_global_http_cache = factory.http_cache()?.clone();\n+  let deno_dir = factory.deno_dir()?.clone();\n+  let deno_dir_root_canonical =\n+    try_get_canonicalized_root_dir(&sys, &deno_dir.root)\n+      .unwrap_or(deno_dir.root.clone());\n+\n+  let mut permit = main_graph_container.acquire_update_permit().await;\n+  let graph = permit.graph_mut();\n+  graph.packages = PackageSpecifiers::default();\n+  let graph_builder = factory.module_graph_builder().await?;\n+  graph_builder\n+    .build_graph_with_npm_resolution(\n+      graph,\n+      CreateGraphOptions {\n+        // loader: Some(&mut NoLoader),\n+        loader: None,\n+        graph_kind: graph.graph_kind(),\n+        is_dynamic: false,\n+        roots: roots.clone(),\n+        npm_caching: crate::graph_util::NpmCachingStrategy::Manual,\n+      },\n+    )\n+    .await?;\n+\n+  let npm_resolver = factory.npm_resolver().await?;\n+\n+  let mut keep = HashSet::new();\n+  let mut npm_reqs = Vec::new();\n+\n+  let mut keep_paths_trie = PathTrie::new();\n+  if deno_dir_root_canonical != deno_dir.root {\n+    keep_paths_trie\n+      .add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical.clone());\n+  }\n+  for (_, entry) in graph.walk(\n+    roots.iter(),\n+    deno_graph::WalkOptions {\n+      check_js: deno_graph::CheckJsOption::False,\n+      follow_dynamic: true,\n+      kind: graph.graph_kind(),\n+      prefer_fast_check_graph: false,\n+    },\n+  ) {\n+    match entry {\n+      deno_graph::ModuleEntryRef::Module(module) => match module {\n+        deno_graph::Module::Js(js_module) => {\n+          keep.insert(&js_module.specifier);\n+        }\n+        deno_graph::Module::Json(json_module) => {\n+          keep.insert(&json_module.specifier);\n+        }\n+        deno_graph::Module::Wasm(wasm_module) => {\n+          keep.insert(&wasm_module.specifier);\n+        }\n+        deno_graph::Module::Npm(npm_module) => {\n+          if let Some(managed) = npm_resolver.as_managed() {\n+            let id = managed\n+              .resolution()\n+              .resolve_pkg_id_from_deno_module(npm_module.nv_reference.nv())\n+              .unwrap();\n+            npm_reqs\n+              .extend(managed.resolution().resolve_pkg_reqs_from_pkg_id(&id));\n+          }\n+        }\n+        deno_graph::Module::Node(_) => {}\n+        deno_graph::Module::External(_) => {}\n+      },\n+      deno_graph::ModuleEntryRef::Err(_) => {}\n+      deno_graph::ModuleEntryRef::Redirect(_) => {}\n+    }\n+  }\n+\n+  for url in &keep {\n+    if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+      if let Ok(path) = http_cache.local_path_for_url(url) {\n+        keep_paths_trie.insert(&path);\n+      }\n+    }\n+    if let Some(path) = deno_dir\n+      .gen_cache\n+      .get_cache_filename_with_extension(url, \"js\")\n+    {\n+      let path = deno_dir.gen_cache.location.join(path);\n+      keep_paths_trie.insert(&path);\n+    }\n+  }\n+\n+  let npm_cache = factory.npm_cache()?;\n+  let snap = npm_resolver.as_managed().unwrap().resolution().snapshot();\n+  // TODO(nathanwhit): remove once we don't need packuments for creating the snapshot from lockfile\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    keep_paths_trie.insert(\n+      &npm_cache\n+        .package_name_folder(&package.id.nv.name)\n+        .join(\"registry.json\"),\n+    );\n+  }\n+  let snap = snap.subset(&npm_reqs);\n+  let node_modules_path = npm_resolver.root_node_modules_path();\n+  let mut node_modules_keep = HashSet::new();\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    if node_modules_path.is_some() {\n+      node_modules_keep.insert(package.get_package_cache_folder_id());\n+    }\n+    keep_paths_trie.insert(&npm_cache.package_folder_for_id(\n+      &deno_npm::NpmPackageCacheFolderId {\n+        nv: package.id.nv.clone(),\n+        copy_index: package.copy_index,\n+      },\n+    ));\n+  }\n+\n+  let jsr_url = crate::args::jsr_url();\n+  add_jsr_meta_paths(graph, &mut keep_paths_trie, jsr_url, &|url| {\n+    http_cache.local_path_for_url(url).map_err(Into::into)\n+  })?;\n+  walk_removing(\n+    &mut state,\n+    walkdir::WalkDir::new(&deno_dir.root)\n+      .contents_first(false)\n+      .min_depth(2),\n+    &keep_paths_trie,\n+    &deno_dir.root,\n+    dry_run,\n+  )?;\n+  let mut node_modules_cleaned = CleanState::default();\n+\n+  if let Some(dir) = node_modules_path {\n+    // let npm_installer = factory.npm_installer_if_managed().await?.unwrap();\n+    // npm_installer.\n+    // let npm_installer = npm_installer.as_local().unwrap();\n+    clean_node_modules(\n+      &mut node_modules_cleaned,\n+      &node_modules_keep,\n+      dir,\n+      dry_run,\n+    )?;\n+  }\n+\n+  let mut vendor_cleaned = CleanState::default();\n+  if let Some(vendor_dir) = options.vendor_dir_path() {\n+    if let GlobalOrLocalHttpCache::Local(cache) = local_or_global_http_cache {\n+      let mut trie = PathTrie::new();\n+      if deno_dir_root_canonical != deno_dir.root {\n+        trie.add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical);\n+      }\n+      let cache = cache.clone();\n+      add_jsr_meta_paths(graph, &mut trie, jsr_url, &|_url| {\n+        if let Ok(Some(path)) = cache.local_path_for_url(_url) {\n+          Ok(path)\n+        } else {\n+          panic!(\"should not happen\")\n+        }\n+      })?;\n+      for url in keep {\n+        if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+          if let Ok(Some(path)) = cache.local_path_for_url(url) {\n+            trie.insert(&path);\n+          } else {\n+            panic!(\"should not happen\")\n+          }\n+        }\n+      }\n+\n+      walk_removing(\n+        &mut vendor_cleaned,\n+        WalkDir::new(vendor_dir).contents_first(false),\n+        &trie,\n+        vendor_dir,\n+        dry_run,\n+      )?;\n+    }\n+  }\n+\n+  if !dry_run {\n+    log_stats(&state, &deno_dir.root);\n+\n+    if let Some(dir) = node_modules_path {\n+      log_stats(&node_modules_cleaned, dir);\n+    }\n+    if let Some(dir) = options.vendor_dir_path() {\n+      log_stats(&vendor_cleaned, dir);\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn log_stats(state: &CleanState, dir: &Path) {\n+  if state.bytes_removed == 0\n+    && state.dirs_removed == 0\n+    && state.files_removed == 0\n+  {\n+    return;\n+  }\n+  log::info!(\n+    \"{} {}\",\n+    colors::green(\"Removed\"),\n+    colors::gray(&format!(\n+      \"{} files, {} from {}\",\n+      state.files_removed + state.dirs_removed,\n+      display::human_size(state.bytes_removed as f64),\n+      dir.display()\n+    ))\n+  );\n+}\n+\n+fn add_jsr_meta_paths(\n+  graph: &ModuleGraph,\n+  path_trie: &mut PathTrie,\n+  jsr_url: &Url,\n+  url_to_path: &dyn Fn(&Url) -> Result<PathBuf, AnyError>,\n+) -> Result<(), AnyError> {\n+  for package in graph.packages.mappings().values() {\n+    let Ok(base_url) = jsr_url.join(&format!(\"{}/\", &package.name)) else {\n+      continue;\n+    };\n+    let keep = url_to_path(&base_url.join(\"meta.json\").unwrap())?;\n+    path_trie.insert(&keep);\n+    let keep = url_to_path(\n+      &base_url\n+        .join(&format!(\"{}_meta.json\", package.version))\n+        .unwrap(),\n+    )?;\n+    path_trie.insert(&keep);\n+  }\n+  Ok(())\n+}\n+\n+fn walk_removing(\n+  state: &mut CleanState,\n+  walker: WalkDir,\n+  trie: &PathTrie,\n+  base: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut walker = walker.into_iter();\n+  while let Some(entry) = walker.next() {\n+    let entry = entry?;\n+    if let Some(found) = trie.find(entry.path()) {\n+      if entry.file_type().is_dir() && matches!(found, Found::Match) {\n+        walker.skip_current_dir();\n+        continue;\n+      }\n+      continue;\n+    }\n+    if !entry.path().starts_with(base) {\n+      panic!(\"VERY BAD\");\n+    }\n+    if entry.file_type().is_dir() {\n+      if dry_run {\n+        #[allow(clippy::print_stderr)]\n+        {\n+          eprintln!(\"would remove dir: {}\", entry.path().display());\n+        }\n+      } else {\n+        rm_rf(state, entry.path())?;\n+      }\n+      walker.skip_current_dir();\n+    } else if dry_run {\n+      #[allow(clippy::print_stderr)]\n+      {\n+        eprintln!(\"would remove file: {}\", entry.path().display());\n+      }\n+    } else {\n+      remove_file(state, entry.path(), Some(entry.metadata()?))?;\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn clean_node_modules(\n+  state: &mut CleanState,\n+  keep_pkgs: &HashSet<deno_npm::NpmPackageCacheFolderId>,\n+  dir: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  if !dir.ends_with(\"node_modules\") || !dir.is_dir() {\n+    bail!(\"not a node_modules directory\");\n+  }\n+  let base = dir.join(\".deno\");\n+  if !base.exists() {\n+    return Ok(());\n+  }\n+\n+  let keep_names = keep_pkgs\n+    .iter()\n+    .map(deno_resolver::npm::get_package_folder_id_folder_name)\n+    .collect::<HashSet<_>>();\n+\n+  // TODO(nathanwhit): this probably shouldn't reach directly into this code\n+  let mut setup_cache =\n+    crate::npm::installer::SetupCache::load(base.join(\".setup-cache.bin\"));\n+\n+  // remove the actual packages from node_modules/.deno\n+  let entries = std::fs::read_dir(&base)?;\n+  for entry in entries {\n+    let entry = entry?;\n+    if !entry.file_type()?.is_dir() {\n+      continue;\n+    }\n+    let file_name = entry.file_name();\n+    let file_name = file_name.to_string_lossy();\n+    if keep_names.contains(file_name.as_ref()) || file_name == \"node_modules\" {\n+      continue;\n+    } else if dry_run {\n+      #[allow(clippy::print_stderr)]\n+      {\n+        eprintln!(\n+          \"would remove dir from node modules: {}\",\n+          entry.path().display()\n+        );\n+      }\n+    } else {\n+      rm_rf(state, &entry.path())?;\n+    }",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "2067452632",
        "repo_full_name": "denoland/deno",
        "pr_number": 28424,
        "pr_file": "cli/tools/clean.rs",
        "discussion_id": "2067452632",
        "commented_code": "@@ -69,6 +92,505 @@ pub fn clean(flags: Arc<Flags>) -> Result<(), AnyError> {\n   Ok(())\n }\n \n+#[derive(Clone, Debug, Default)]\n+struct PathNode {\n+  exact: bool,\n+  children: BTreeMap<OsString, usize>,\n+}\n+#[derive(Debug)]\n+struct PathTrie {\n+  root: usize,\n+  nodes: Vec<PathNode>,\n+  rewrites: Vec<(PathBuf, PathBuf)>,\n+}\n+\n+#[derive(Clone, Copy, PartialEq, Eq, Debug)]\n+enum Found {\n+  Match,\n+  Prefix,\n+}\n+\n+impl PathTrie {\n+  fn new() -> Self {\n+    Self {\n+      root: 0,\n+      nodes: vec![PathNode {\n+        exact: false,\n+        children: Default::default(),\n+      }],\n+      rewrites: vec![],\n+    }\n+  }\n+\n+  fn add_rewrite(&mut self, from: PathBuf, to: PathBuf) {\n+    self.rewrites.push((from, to));\n+  }\n+\n+  fn rewrite(&self, s: &Path) -> PathBuf {\n+    let normalized = deno_path_util::normalize_path(s);\n+    for (from, to) in &self.rewrites {\n+      if normalized.starts_with(from) {\n+        return to.join(normalized.strip_prefix(from).unwrap());\n+      }\n+    }\n+    normalized\n+  }\n+\n+  fn insert(&mut self, s: &Path) {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        let id = self.nodes.len();\n+        self.nodes.push(PathNode::default());\n+        self.nodes[node]\n+          .children\n+          .insert(component.to_os_string(), id);\n+        node = id;\n+      }\n+    }\n+\n+    self.nodes[node].exact = true;\n+  }\n+\n+  fn find(&self, s: &Path) -> Option<Found> {\n+    let normalized = self.rewrite(s);\n+    let components = normalized.components().map(|c| c.as_os_str());\n+    let mut node = self.root;\n+\n+    for component in components {\n+      if let Some(nd) = self.nodes[node].children.get(component).copied() {\n+        node = nd;\n+      } else {\n+        return None;\n+      }\n+    }\n+\n+    Some(if self.nodes[node].exact {\n+      Found::Match\n+    } else {\n+      Found::Prefix\n+    })\n+  }\n+}\n+\n+fn try_get_canonicalized_root_dir<Sys: FsCanonicalize + FsCreateDirAll>(\n+  sys: &Sys,\n+  root_dir: &Path,\n+) -> Result<PathBuf, std::io::Error> {\n+  match sys.fs_canonicalize(root_dir) {\n+    Ok(path) => Ok(path),\n+    Err(err) if err.kind() == std::io::ErrorKind::NotFound => {\n+      sys.fs_create_dir_all(root_dir)?;\n+      sys.fs_canonicalize(root_dir)\n+    }\n+    Err(err) => Err(err),\n+  }\n+}\n+\n+async fn clean_except(\n+  flags: Arc<Flags>,\n+  entrypoints: &[String],\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut state = CleanState::default();\n+\n+  let factory = CliFactory::from_flags(flags.clone());\n+  let sys = factory.sys();\n+  let options = factory.cli_options()?;\n+  let main_graph_container = factory.main_module_graph_container().await?;\n+  let roots = main_graph_container.collect_specifiers(entrypoints)?;\n+  let http_cache = factory.global_http_cache()?;\n+  let local_or_global_http_cache = factory.http_cache()?.clone();\n+  let deno_dir = factory.deno_dir()?.clone();\n+  let deno_dir_root_canonical =\n+    try_get_canonicalized_root_dir(&sys, &deno_dir.root)\n+      .unwrap_or(deno_dir.root.clone());\n+\n+  let mut permit = main_graph_container.acquire_update_permit().await;\n+  let graph = permit.graph_mut();\n+  graph.packages = PackageSpecifiers::default();\n+  let graph_builder = factory.module_graph_builder().await?;\n+  graph_builder\n+    .build_graph_with_npm_resolution(\n+      graph,\n+      CreateGraphOptions {\n+        // loader: Some(&mut NoLoader),\n+        loader: None,\n+        graph_kind: graph.graph_kind(),\n+        is_dynamic: false,\n+        roots: roots.clone(),\n+        npm_caching: crate::graph_util::NpmCachingStrategy::Manual,\n+      },\n+    )\n+    .await?;\n+\n+  let npm_resolver = factory.npm_resolver().await?;\n+\n+  let mut keep = HashSet::new();\n+  let mut npm_reqs = Vec::new();\n+\n+  let mut keep_paths_trie = PathTrie::new();\n+  if deno_dir_root_canonical != deno_dir.root {\n+    keep_paths_trie\n+      .add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical.clone());\n+  }\n+  for (_, entry) in graph.walk(\n+    roots.iter(),\n+    deno_graph::WalkOptions {\n+      check_js: deno_graph::CheckJsOption::False,\n+      follow_dynamic: true,\n+      kind: graph.graph_kind(),\n+      prefer_fast_check_graph: false,\n+    },\n+  ) {\n+    match entry {\n+      deno_graph::ModuleEntryRef::Module(module) => match module {\n+        deno_graph::Module::Js(js_module) => {\n+          keep.insert(&js_module.specifier);\n+        }\n+        deno_graph::Module::Json(json_module) => {\n+          keep.insert(&json_module.specifier);\n+        }\n+        deno_graph::Module::Wasm(wasm_module) => {\n+          keep.insert(&wasm_module.specifier);\n+        }\n+        deno_graph::Module::Npm(npm_module) => {\n+          if let Some(managed) = npm_resolver.as_managed() {\n+            let id = managed\n+              .resolution()\n+              .resolve_pkg_id_from_deno_module(npm_module.nv_reference.nv())\n+              .unwrap();\n+            npm_reqs\n+              .extend(managed.resolution().resolve_pkg_reqs_from_pkg_id(&id));\n+          }\n+        }\n+        deno_graph::Module::Node(_) => {}\n+        deno_graph::Module::External(_) => {}\n+      },\n+      deno_graph::ModuleEntryRef::Err(_) => {}\n+      deno_graph::ModuleEntryRef::Redirect(_) => {}\n+    }\n+  }\n+\n+  for url in &keep {\n+    if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+      if let Ok(path) = http_cache.local_path_for_url(url) {\n+        keep_paths_trie.insert(&path);\n+      }\n+    }\n+    if let Some(path) = deno_dir\n+      .gen_cache\n+      .get_cache_filename_with_extension(url, \"js\")\n+    {\n+      let path = deno_dir.gen_cache.location.join(path);\n+      keep_paths_trie.insert(&path);\n+    }\n+  }\n+\n+  let npm_cache = factory.npm_cache()?;\n+  let snap = npm_resolver.as_managed().unwrap().resolution().snapshot();\n+  // TODO(nathanwhit): remove once we don't need packuments for creating the snapshot from lockfile\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    keep_paths_trie.insert(\n+      &npm_cache\n+        .package_name_folder(&package.id.nv.name)\n+        .join(\"registry.json\"),\n+    );\n+  }\n+  let snap = snap.subset(&npm_reqs);\n+  let node_modules_path = npm_resolver.root_node_modules_path();\n+  let mut node_modules_keep = HashSet::new();\n+  for package in snap.all_system_packages(&options.npm_system_info()) {\n+    if node_modules_path.is_some() {\n+      node_modules_keep.insert(package.get_package_cache_folder_id());\n+    }\n+    keep_paths_trie.insert(&npm_cache.package_folder_for_id(\n+      &deno_npm::NpmPackageCacheFolderId {\n+        nv: package.id.nv.clone(),\n+        copy_index: package.copy_index,\n+      },\n+    ));\n+  }\n+\n+  let jsr_url = crate::args::jsr_url();\n+  add_jsr_meta_paths(graph, &mut keep_paths_trie, jsr_url, &|url| {\n+    http_cache.local_path_for_url(url).map_err(Into::into)\n+  })?;\n+  walk_removing(\n+    &mut state,\n+    walkdir::WalkDir::new(&deno_dir.root)\n+      .contents_first(false)\n+      .min_depth(2),\n+    &keep_paths_trie,\n+    &deno_dir.root,\n+    dry_run,\n+  )?;\n+  let mut node_modules_cleaned = CleanState::default();\n+\n+  if let Some(dir) = node_modules_path {\n+    // let npm_installer = factory.npm_installer_if_managed().await?.unwrap();\n+    // npm_installer.\n+    // let npm_installer = npm_installer.as_local().unwrap();\n+    clean_node_modules(\n+      &mut node_modules_cleaned,\n+      &node_modules_keep,\n+      dir,\n+      dry_run,\n+    )?;\n+  }\n+\n+  let mut vendor_cleaned = CleanState::default();\n+  if let Some(vendor_dir) = options.vendor_dir_path() {\n+    if let GlobalOrLocalHttpCache::Local(cache) = local_or_global_http_cache {\n+      let mut trie = PathTrie::new();\n+      if deno_dir_root_canonical != deno_dir.root {\n+        trie.add_rewrite(deno_dir.root.clone(), deno_dir_root_canonical);\n+      }\n+      let cache = cache.clone();\n+      add_jsr_meta_paths(graph, &mut trie, jsr_url, &|_url| {\n+        if let Ok(Some(path)) = cache.local_path_for_url(_url) {\n+          Ok(path)\n+        } else {\n+          panic!(\"should not happen\")\n+        }\n+      })?;\n+      for url in keep {\n+        if url.scheme() == \"http\" || url.scheme() == \"https\" {\n+          if let Ok(Some(path)) = cache.local_path_for_url(url) {\n+            trie.insert(&path);\n+          } else {\n+            panic!(\"should not happen\")\n+          }\n+        }\n+      }\n+\n+      walk_removing(\n+        &mut vendor_cleaned,\n+        WalkDir::new(vendor_dir).contents_first(false),\n+        &trie,\n+        vendor_dir,\n+        dry_run,\n+      )?;\n+    }\n+  }\n+\n+  if !dry_run {\n+    log_stats(&state, &deno_dir.root);\n+\n+    if let Some(dir) = node_modules_path {\n+      log_stats(&node_modules_cleaned, dir);\n+    }\n+    if let Some(dir) = options.vendor_dir_path() {\n+      log_stats(&vendor_cleaned, dir);\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn log_stats(state: &CleanState, dir: &Path) {\n+  if state.bytes_removed == 0\n+    && state.dirs_removed == 0\n+    && state.files_removed == 0\n+  {\n+    return;\n+  }\n+  log::info!(\n+    \"{} {}\",\n+    colors::green(\"Removed\"),\n+    colors::gray(&format!(\n+      \"{} files, {} from {}\",\n+      state.files_removed + state.dirs_removed,\n+      display::human_size(state.bytes_removed as f64),\n+      dir.display()\n+    ))\n+  );\n+}\n+\n+fn add_jsr_meta_paths(\n+  graph: &ModuleGraph,\n+  path_trie: &mut PathTrie,\n+  jsr_url: &Url,\n+  url_to_path: &dyn Fn(&Url) -> Result<PathBuf, AnyError>,\n+) -> Result<(), AnyError> {\n+  for package in graph.packages.mappings().values() {\n+    let Ok(base_url) = jsr_url.join(&format!(\"{}/\", &package.name)) else {\n+      continue;\n+    };\n+    let keep = url_to_path(&base_url.join(\"meta.json\").unwrap())?;\n+    path_trie.insert(&keep);\n+    let keep = url_to_path(\n+      &base_url\n+        .join(&format!(\"{}_meta.json\", package.version))\n+        .unwrap(),\n+    )?;\n+    path_trie.insert(&keep);\n+  }\n+  Ok(())\n+}\n+\n+fn walk_removing(\n+  state: &mut CleanState,\n+  walker: WalkDir,\n+  trie: &PathTrie,\n+  base: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  let mut walker = walker.into_iter();\n+  while let Some(entry) = walker.next() {\n+    let entry = entry?;\n+    if let Some(found) = trie.find(entry.path()) {\n+      if entry.file_type().is_dir() && matches!(found, Found::Match) {\n+        walker.skip_current_dir();\n+        continue;\n+      }\n+      continue;\n+    }\n+    if !entry.path().starts_with(base) {\n+      panic!(\"VERY BAD\");\n+    }\n+    if entry.file_type().is_dir() {\n+      if dry_run {\n+        #[allow(clippy::print_stderr)]\n+        {\n+          eprintln!(\"would remove dir: {}\", entry.path().display());\n+        }\n+      } else {\n+        rm_rf(state, entry.path())?;\n+      }\n+      walker.skip_current_dir();\n+    } else if dry_run {\n+      #[allow(clippy::print_stderr)]\n+      {\n+        eprintln!(\"would remove file: {}\", entry.path().display());\n+      }\n+    } else {\n+      remove_file(state, entry.path(), Some(entry.metadata()?))?;\n+    }\n+  }\n+\n+  Ok(())\n+}\n+\n+fn clean_node_modules(\n+  state: &mut CleanState,\n+  keep_pkgs: &HashSet<deno_npm::NpmPackageCacheFolderId>,\n+  dir: &Path,\n+  dry_run: bool,\n+) -> Result<(), AnyError> {\n+  if !dir.ends_with(\"node_modules\") || !dir.is_dir() {\n+    bail!(\"not a node_modules directory\");\n+  }\n+  let base = dir.join(\".deno\");\n+  if !base.exists() {\n+    return Ok(());\n+  }\n+\n+  let keep_names = keep_pkgs\n+    .iter()\n+    .map(deno_resolver::npm::get_package_folder_id_folder_name)\n+    .collect::<HashSet<_>>();\n+\n+  // TODO(nathanwhit): this probably shouldn't reach directly into this code\n+  let mut setup_cache =\n+    crate::npm::installer::SetupCache::load(base.join(\".setup-cache.bin\"));\n+\n+  // remove the actual packages from node_modules/.deno\n+  let entries = std::fs::read_dir(&base)?;\n+  for entry in entries {\n+    let entry = entry?;\n+    if !entry.file_type()?.is_dir() {\n+      continue;\n+    }\n+    let file_name = entry.file_name();\n+    let file_name = file_name.to_string_lossy();\n+    if keep_names.contains(file_name.as_ref()) || file_name == \"node_modules\" {\n+      continue;\n+    } else if dry_run {\n+      #[allow(clippy::print_stderr)]\n+      {\n+        eprintln!(\n+          \"would remove dir from node modules: {}\",\n+          entry.path().display()\n+        );\n+      }\n+    } else {\n+      rm_rf(state, &entry.path())?;\n+    }",
        "comment_created_at": "2025-04-29T21:25:10+00:00",
        "comment_author": "dsherret",
        "comment_body": "Could use strategy pattern here in the future (reporting strategy and remove strategy).",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1842555924",
    "pr_number": 26590,
    "pr_file": "cli/tools/coverage/ast_parser.rs",
    "created_at": "2024-11-14T16:36:20+00:00",
    "commented_code": "+// Copyright 2018-2024 the Deno authors. All rights reserved. MIT license.\n+\n+use deno_ast::get_syntax;\n+use deno_ast::MediaType;\n+use deno_ast::ModuleSpecifier;\n+use deno_ast::ParseDiagnostic;\n+use deno_ast::ParsedSource;\n+\n+pub(crate) fn parse_program(",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "1842555924",
        "repo_full_name": "denoland/deno",
        "pr_number": 26590,
        "pr_file": "cli/tools/coverage/ast_parser.rs",
        "discussion_id": "1842555924",
        "commented_code": "@@ -0,0 +1,23 @@\n+// Copyright 2018-2024 the Deno authors. All rights reserved. MIT license.\n+\n+use deno_ast::get_syntax;\n+use deno_ast::MediaType;\n+use deno_ast::ModuleSpecifier;\n+use deno_ast::ParseDiagnostic;\n+use deno_ast::ParsedSource;\n+\n+pub(crate) fn parse_program(",
        "comment_created_at": "2024-11-14T16:36:20+00:00",
        "comment_author": "dsherret",
        "comment_body": "Why do we need to parse an AST now? It seems we really only need the comments which the lexer provides?",
        "pr_file_module": null
      },
      {
        "comment_id": "1855207469",
        "repo_full_name": "denoland/deno",
        "pr_number": 26590,
        "pr_file": "cli/tools/coverage/ast_parser.rs",
        "discussion_id": "1842555924",
        "commented_code": "@@ -0,0 +1,23 @@\n+// Copyright 2018-2024 the Deno authors. All rights reserved. MIT license.\n+\n+use deno_ast::get_syntax;\n+use deno_ast::MediaType;\n+use deno_ast::ModuleSpecifier;\n+use deno_ast::ParseDiagnostic;\n+use deno_ast::ParsedSource;\n+\n+pub(crate) fn parse_program(",
        "comment_created_at": "2024-11-23T14:56:45+00:00",
        "comment_author": "bcheidemann",
        "comment_body": "For the current implementation, there's no need to parse the AST if we can get comments from the Lexer. The current implementation parses the AST because it was largely copied/adapted from the [implementation in `deno_lint`](https://github.com/denoland/deno_lint/blob/f2a2aab27c3825403b538faeecb15f65f6179d9a/src/ignore_directives.rs), which does the same.\r\n\r\nThat said, I didn't consider using the lexer for comments in part because I had [syntax aware coverage ignore directives](https://github.com/denoland/deno/issues/26722) in mind while working on this. Since these require access to the AST, it didn't make sense to optimise away the AST parsing.\r\n\r\nI'm happy to refactor to use the lexer if you prefer.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1938149639",
    "pr_number": 27812,
    "pr_file": "cli/tools/registry/pm/outdated/interactive.rs",
    "created_at": "2025-02-01T01:44:43+00:00",
    "commented_code": "+// Copyright 2018-2025 the Deno authors. MIT license.\n+\n+use std::collections::HashSet;\n+use std::io;\n+use std::io::Write;\n+\n+use crossterm::cursor;\n+use crossterm::event::KeyCode;\n+use crossterm::event::KeyEvent;\n+use crossterm::event::KeyEventKind;\n+use crossterm::event::KeyModifiers;\n+use crossterm::style;\n+use crossterm::style::Stylize;\n+use crossterm::terminal;\n+use crossterm::ExecutableCommand;\n+use crossterm::QueueableCommand;\n+use deno_core::anyhow;\n+use deno_core::anyhow::Context;\n+\n+use crate::tools::registry::pm::deps::DepKind;\n+\n+#[derive(Debug)]\n+pub struct PackageInfo {\n+  pub current_version: String,\n+  pub new_version: String,\n+  pub name: String,\n+  pub kind: DepKind,\n+}\n+\n+#[derive(Debug)]\n+struct State {\n+  packages: Vec<PackageInfo>,\n+  currently_selected: usize,\n+  checked: HashSet<usize>,\n+\n+  name_width: usize,\n+  current_width: usize,\n+  start_row: u16,\n+}\n+\n+impl State {\n+  fn new(packages: Vec<PackageInfo>) -> anyhow::Result<Self> {\n+    let name_width = packages\n+      .iter()\n+      .map(|p| p.name.len() + p.kind.scheme().len() + 1)\n+      .max()\n+      .unwrap_or_default();\n+    let current_width = packages\n+      .iter()\n+      .map(|p| p.current_version.len())\n+      .max()\n+      .unwrap_or_default();\n+\n+    Ok(Self {\n+      packages,\n+      currently_selected: 0,\n+      checked: HashSet::new(),\n+\n+      name_width,\n+      current_width,\n+      start_row: cursor::position()?.1,\n+    })\n+  }\n+\n+  fn render<W: std::io::Write>(&self, out: &mut W) -> anyhow::Result<()> {\n+    use cursor::MoveTo;\n+    use style::Print;\n+    use style::PrintStyledContent;\n+\n+    crossterm::queue!(\n+      out,\n+      MoveTo(0, self.start_row),\n+      terminal::Clear(terminal::ClearType::FromCursorDown),\n+      PrintStyledContent(\"?\".blue()),\n+      Print(\" Select which packages to update (<space> to select, \u2191/\u2193/j/k to navigate, enter to accept, <Ctrl-c> to cancel)\")\n+    )?;\n+\n+    let base = self.start_row + 1;\n+\n+    for (i, package) in self.packages.iter().enumerate() {\n+      if self.currently_selected == i {\n+        crossterm::queue!(\n+          out,\n+          MoveTo(0, base + (self.currently_selected as u16)),\n+          PrintStyledContent(\"\u276f\".blue()),\n+          Print(' '),\n+        )?;\n+      }\n+      let checked = self.checked.contains(&i);\n+      let selector = if checked { \"\u25cf\" } else { \"\u25cb\" };\n+      crossterm::queue!(\n+        out,\n+        MoveTo(2, base + (i as u16)),\n+        Print(selector),\n+        Print(\" \"),\n+      )?;\n+\n+      if self.currently_selected == i {\n+        out.queue(style::SetStyle(\n+          style::ContentStyle::new().on_black().white().bold(),\n+        ))?;\n+      }\n+      let want = &package.new_version;\n+      let new_version_highlight =\n+        highlight_new_version(&package.current_version, want)?;\n+      let formatted_name = format!(\n+        \"{}{}\",\n+        deno_terminal::colors::gray(format!(\"{}:\", package.kind.scheme())),\n+        package.name\n+      );\n+      let name_pad = \" \".repeat(self.name_width + 2 - (package.name.len() + 4));\n+\n+      crossterm::queue!(\n+        out,\n+        Print(format!(\n+          \"{formatted_name}{name_pad} {:<current_width$} -> {}\",\n+          package.current_version,\n+          new_version_highlight,\n+          current_width = self.current_width\n+        )),\n+      )?;\n+      if self.currently_selected == i {\n+        out.queue(style::ResetColor)?;\n+      }\n+    }\n+\n+    out.queue(MoveTo(0, base + self.packages.len() as u16))?;\n+\n+    out.flush()?;\n+\n+    Ok(())\n+  }\n+}\n+\n+enum VersionDifference {\n+  Major,\n+  Minor,\n+  Patch,\n+}\n+\n+struct VersionParts {\n+  major: u64,\n+  minor: u64,\n+  patch: u64,\n+  pre: Option<String>,",
    "repo_full_name": "denoland/deno",
    "discussion_comments": [
      {
        "comment_id": "1938149639",
        "repo_full_name": "denoland/deno",
        "pr_number": 27812,
        "pr_file": "cli/tools/registry/pm/outdated/interactive.rs",
        "discussion_id": "1938149639",
        "commented_code": "@@ -0,0 +1,333 @@\n+// Copyright 2018-2025 the Deno authors. MIT license.\n+\n+use std::collections::HashSet;\n+use std::io;\n+use std::io::Write;\n+\n+use crossterm::cursor;\n+use crossterm::event::KeyCode;\n+use crossterm::event::KeyEvent;\n+use crossterm::event::KeyEventKind;\n+use crossterm::event::KeyModifiers;\n+use crossterm::style;\n+use crossterm::style::Stylize;\n+use crossterm::terminal;\n+use crossterm::ExecutableCommand;\n+use crossterm::QueueableCommand;\n+use deno_core::anyhow;\n+use deno_core::anyhow::Context;\n+\n+use crate::tools::registry::pm::deps::DepKind;\n+\n+#[derive(Debug)]\n+pub struct PackageInfo {\n+  pub current_version: String,\n+  pub new_version: String,\n+  pub name: String,\n+  pub kind: DepKind,\n+}\n+\n+#[derive(Debug)]\n+struct State {\n+  packages: Vec<PackageInfo>,\n+  currently_selected: usize,\n+  checked: HashSet<usize>,\n+\n+  name_width: usize,\n+  current_width: usize,\n+  start_row: u16,\n+}\n+\n+impl State {\n+  fn new(packages: Vec<PackageInfo>) -> anyhow::Result<Self> {\n+    let name_width = packages\n+      .iter()\n+      .map(|p| p.name.len() + p.kind.scheme().len() + 1)\n+      .max()\n+      .unwrap_or_default();\n+    let current_width = packages\n+      .iter()\n+      .map(|p| p.current_version.len())\n+      .max()\n+      .unwrap_or_default();\n+\n+    Ok(Self {\n+      packages,\n+      currently_selected: 0,\n+      checked: HashSet::new(),\n+\n+      name_width,\n+      current_width,\n+      start_row: cursor::position()?.1,\n+    })\n+  }\n+\n+  fn render<W: std::io::Write>(&self, out: &mut W) -> anyhow::Result<()> {\n+    use cursor::MoveTo;\n+    use style::Print;\n+    use style::PrintStyledContent;\n+\n+    crossterm::queue!(\n+      out,\n+      MoveTo(0, self.start_row),\n+      terminal::Clear(terminal::ClearType::FromCursorDown),\n+      PrintStyledContent(\"?\".blue()),\n+      Print(\" Select which packages to update (<space> to select, \u2191/\u2193/j/k to navigate, enter to accept, <Ctrl-c> to cancel)\")\n+    )?;\n+\n+    let base = self.start_row + 1;\n+\n+    for (i, package) in self.packages.iter().enumerate() {\n+      if self.currently_selected == i {\n+        crossterm::queue!(\n+          out,\n+          MoveTo(0, base + (self.currently_selected as u16)),\n+          PrintStyledContent(\"\u276f\".blue()),\n+          Print(' '),\n+        )?;\n+      }\n+      let checked = self.checked.contains(&i);\n+      let selector = if checked { \"\u25cf\" } else { \"\u25cb\" };\n+      crossterm::queue!(\n+        out,\n+        MoveTo(2, base + (i as u16)),\n+        Print(selector),\n+        Print(\" \"),\n+      )?;\n+\n+      if self.currently_selected == i {\n+        out.queue(style::SetStyle(\n+          style::ContentStyle::new().on_black().white().bold(),\n+        ))?;\n+      }\n+      let want = &package.new_version;\n+      let new_version_highlight =\n+        highlight_new_version(&package.current_version, want)?;\n+      let formatted_name = format!(\n+        \"{}{}\",\n+        deno_terminal::colors::gray(format!(\"{}:\", package.kind.scheme())),\n+        package.name\n+      );\n+      let name_pad = \" \".repeat(self.name_width + 2 - (package.name.len() + 4));\n+\n+      crossterm::queue!(\n+        out,\n+        Print(format!(\n+          \"{formatted_name}{name_pad} {:<current_width$} -> {}\",\n+          package.current_version,\n+          new_version_highlight,\n+          current_width = self.current_width\n+        )),\n+      )?;\n+      if self.currently_selected == i {\n+        out.queue(style::ResetColor)?;\n+      }\n+    }\n+\n+    out.queue(MoveTo(0, base + self.packages.len() as u16))?;\n+\n+    out.flush()?;\n+\n+    Ok(())\n+  }\n+}\n+\n+enum VersionDifference {\n+  Major,\n+  Minor,\n+  Patch,\n+}\n+\n+struct VersionParts {\n+  major: u64,\n+  minor: u64,\n+  patch: u64,\n+  pre: Option<String>,",
        "comment_created_at": "2025-02-01T01:44:43+00:00",
        "comment_author": "dsherret",
        "comment_body": "Should we be using `deno_semver::Version` here? https://docs.rs/deno_semver/0.7.1/deno_semver/struct.Version.html",
        "pr_file_module": null
      }
    ]
  }
]