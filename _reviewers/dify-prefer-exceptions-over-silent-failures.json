[
  {
    "discussion_id": "2313967964",
    "pr_number": 24428,
    "pr_file": "api/services/schedule_service.py",
    "created_at": "2025-09-01T13:29:24+00:00",
    "commented_code": "+import json\n+import logging\n+from datetime import UTC, datetime\n+from typing import Optional\n+\n+import pytz\n+from croniter import croniter\n+from sqlalchemy import select\n+from sqlalchemy.orm import Session\n+\n+from core.workflow.nodes import NodeType\n+from models.account import Account, TenantAccountJoin\n+from models.workflow import Workflow, WorkflowSchedulePlan\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class ScheduleService:\n+    @staticmethod\n+    def calculate_next_run_at(\n+        cron_expression: str,\n+        timezone: str,\n+        base_time: Optional[datetime] = None,\n+    ) -> Optional[datetime]:\n+        try:\n+            tz = pytz.timezone(timezone)\n+            if base_time is None:\n+                base_time = datetime.now(UTC)\n+            base_time_tz = base_time.astimezone(tz)\n+            cron = croniter(cron_expression, base_time_tz)\n+            next_run_tz = cron.get_next(datetime)\n+            next_run_utc = next_run_tz.astimezone(UTC)\n+            return next_run_utc\n+        except Exception:\n+            logger.exception(\"Error calculating next run time\")\n+            return None\n+\n+    @staticmethod\n+    def create_schedule(\n+        session: Session,\n+        tenant_id: str,\n+        app_id: str,\n+        node_id: str,\n+        cron_expression: str,\n+        timezone: str,\n+    ) -> WorkflowSchedulePlan:\n+        # Pre-calculate next_run_at to ensure the schedule is valid before persisting\n+        next_run_at = ScheduleService.calculate_next_run_at(\n+            cron_expression,\n+            timezone,\n+        )\n+\n+        schedule = WorkflowSchedulePlan(\n+            tenant_id=tenant_id,\n+            app_id=app_id,\n+            node_id=node_id,\n+            cron_expression=cron_expression,\n+            timezone=timezone,\n+            next_run_at=next_run_at,\n+        )\n+\n+        session.add(schedule)\n+        session.flush()\n+\n+        return schedule\n+\n+    @staticmethod\n+    def update_schedule(\n+        session: Session,\n+        schedule_id: str,\n+        updates: dict,\n+    ) -> Optional[WorkflowSchedulePlan]:\n+        schedule = session.get(WorkflowSchedulePlan, schedule_id)\n+        if not schedule:\n+            return None",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2313967964",
        "repo_full_name": "langgenius/dify",
        "pr_number": 24428,
        "pr_file": "api/services/schedule_service.py",
        "discussion_id": "2313967964",
        "commented_code": "@@ -0,0 +1,313 @@\n+import json\n+import logging\n+from datetime import UTC, datetime\n+from typing import Optional\n+\n+import pytz\n+from croniter import croniter\n+from sqlalchemy import select\n+from sqlalchemy.orm import Session\n+\n+from core.workflow.nodes import NodeType\n+from models.account import Account, TenantAccountJoin\n+from models.workflow import Workflow, WorkflowSchedulePlan\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class ScheduleService:\n+    @staticmethod\n+    def calculate_next_run_at(\n+        cron_expression: str,\n+        timezone: str,\n+        base_time: Optional[datetime] = None,\n+    ) -> Optional[datetime]:\n+        try:\n+            tz = pytz.timezone(timezone)\n+            if base_time is None:\n+                base_time = datetime.now(UTC)\n+            base_time_tz = base_time.astimezone(tz)\n+            cron = croniter(cron_expression, base_time_tz)\n+            next_run_tz = cron.get_next(datetime)\n+            next_run_utc = next_run_tz.astimezone(UTC)\n+            return next_run_utc\n+        except Exception:\n+            logger.exception(\"Error calculating next run time\")\n+            return None\n+\n+    @staticmethod\n+    def create_schedule(\n+        session: Session,\n+        tenant_id: str,\n+        app_id: str,\n+        node_id: str,\n+        cron_expression: str,\n+        timezone: str,\n+    ) -> WorkflowSchedulePlan:\n+        # Pre-calculate next_run_at to ensure the schedule is valid before persisting\n+        next_run_at = ScheduleService.calculate_next_run_at(\n+            cron_expression,\n+            timezone,\n+        )\n+\n+        schedule = WorkflowSchedulePlan(\n+            tenant_id=tenant_id,\n+            app_id=app_id,\n+            node_id=node_id,\n+            cron_expression=cron_expression,\n+            timezone=timezone,\n+            next_run_at=next_run_at,\n+        )\n+\n+        session.add(schedule)\n+        session.flush()\n+\n+        return schedule\n+\n+    @staticmethod\n+    def update_schedule(\n+        session: Session,\n+        schedule_id: str,\n+        updates: dict,\n+    ) -> Optional[WorkflowSchedulePlan]:\n+        schedule = session.get(WorkflowSchedulePlan, schedule_id)\n+        if not schedule:\n+            return None",
        "comment_created_at": "2025-09-01T13:29:24+00:00",
        "comment_author": "Yeuoly",
        "comment_body": "We should raise exception here I think, return None is confused to contributors, what's more, it means any calling to this method should check nullable result like error handing Golang\r\n```\r\nif _, err := foo(); err != nil {\r\n//TODO\r\n}\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2313970835",
    "pr_number": 24428,
    "pr_file": "api/services/schedule_service.py",
    "created_at": "2025-09-01T13:30:37+00:00",
    "commented_code": "+import json\n+import logging\n+from datetime import UTC, datetime\n+from typing import Optional\n+\n+import pytz\n+from croniter import croniter\n+from sqlalchemy import select\n+from sqlalchemy.orm import Session\n+\n+from core.workflow.nodes import NodeType\n+from models.account import Account, TenantAccountJoin\n+from models.workflow import Workflow, WorkflowSchedulePlan\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class ScheduleService:\n+    @staticmethod\n+    def calculate_next_run_at(\n+        cron_expression: str,\n+        timezone: str,\n+        base_time: Optional[datetime] = None,\n+    ) -> Optional[datetime]:\n+        try:\n+            tz = pytz.timezone(timezone)\n+            if base_time is None:\n+                base_time = datetime.now(UTC)\n+            base_time_tz = base_time.astimezone(tz)\n+            cron = croniter(cron_expression, base_time_tz)\n+            next_run_tz = cron.get_next(datetime)\n+            next_run_utc = next_run_tz.astimezone(UTC)\n+            return next_run_utc\n+        except Exception:\n+            logger.exception(\"Error calculating next run time\")\n+            return None\n+\n+    @staticmethod\n+    def create_schedule(\n+        session: Session,\n+        tenant_id: str,\n+        app_id: str,\n+        node_id: str,\n+        cron_expression: str,\n+        timezone: str,\n+    ) -> WorkflowSchedulePlan:\n+        # Pre-calculate next_run_at to ensure the schedule is valid before persisting\n+        next_run_at = ScheduleService.calculate_next_run_at(\n+            cron_expression,\n+            timezone,\n+        )\n+\n+        schedule = WorkflowSchedulePlan(\n+            tenant_id=tenant_id,\n+            app_id=app_id,\n+            node_id=node_id,\n+            cron_expression=cron_expression,\n+            timezone=timezone,\n+            next_run_at=next_run_at,\n+        )\n+\n+        session.add(schedule)\n+        session.flush()\n+\n+        return schedule\n+\n+    @staticmethod\n+    def update_schedule(\n+        session: Session,\n+        schedule_id: str,\n+        updates: dict,\n+    ) -> Optional[WorkflowSchedulePlan]:\n+        schedule = session.get(WorkflowSchedulePlan, schedule_id)\n+        if not schedule:\n+            return None\n+\n+        for field, value in updates.items():\n+            if hasattr(schedule, field):\n+                setattr(schedule, field, value)\n+\n+        # Ensure next_run_at stays accurate when schedule timing changes\n+        if any(field in updates for field in [\"cron_expression\", \"timezone\"]):\n+            next_run_at = ScheduleService.calculate_next_run_at(\n+                schedule.cron_expression,\n+                schedule.timezone,\n+            )\n+            schedule.next_run_at = next_run_at\n+\n+        session.flush()\n+        return schedule\n+\n+    @staticmethod\n+    def delete_schedule(\n+        session: Session,\n+        schedule_id: str,\n+    ) -> bool:\n+        schedule = session.get(WorkflowSchedulePlan, schedule_id)\n+        if not schedule:\n+            return False",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2313970835",
        "repo_full_name": "langgenius/dify",
        "pr_number": 24428,
        "pr_file": "api/services/schedule_service.py",
        "discussion_id": "2313970835",
        "commented_code": "@@ -0,0 +1,313 @@\n+import json\n+import logging\n+from datetime import UTC, datetime\n+from typing import Optional\n+\n+import pytz\n+from croniter import croniter\n+from sqlalchemy import select\n+from sqlalchemy.orm import Session\n+\n+from core.workflow.nodes import NodeType\n+from models.account import Account, TenantAccountJoin\n+from models.workflow import Workflow, WorkflowSchedulePlan\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class ScheduleService:\n+    @staticmethod\n+    def calculate_next_run_at(\n+        cron_expression: str,\n+        timezone: str,\n+        base_time: Optional[datetime] = None,\n+    ) -> Optional[datetime]:\n+        try:\n+            tz = pytz.timezone(timezone)\n+            if base_time is None:\n+                base_time = datetime.now(UTC)\n+            base_time_tz = base_time.astimezone(tz)\n+            cron = croniter(cron_expression, base_time_tz)\n+            next_run_tz = cron.get_next(datetime)\n+            next_run_utc = next_run_tz.astimezone(UTC)\n+            return next_run_utc\n+        except Exception:\n+            logger.exception(\"Error calculating next run time\")\n+            return None\n+\n+    @staticmethod\n+    def create_schedule(\n+        session: Session,\n+        tenant_id: str,\n+        app_id: str,\n+        node_id: str,\n+        cron_expression: str,\n+        timezone: str,\n+    ) -> WorkflowSchedulePlan:\n+        # Pre-calculate next_run_at to ensure the schedule is valid before persisting\n+        next_run_at = ScheduleService.calculate_next_run_at(\n+            cron_expression,\n+            timezone,\n+        )\n+\n+        schedule = WorkflowSchedulePlan(\n+            tenant_id=tenant_id,\n+            app_id=app_id,\n+            node_id=node_id,\n+            cron_expression=cron_expression,\n+            timezone=timezone,\n+            next_run_at=next_run_at,\n+        )\n+\n+        session.add(schedule)\n+        session.flush()\n+\n+        return schedule\n+\n+    @staticmethod\n+    def update_schedule(\n+        session: Session,\n+        schedule_id: str,\n+        updates: dict,\n+    ) -> Optional[WorkflowSchedulePlan]:\n+        schedule = session.get(WorkflowSchedulePlan, schedule_id)\n+        if not schedule:\n+            return None\n+\n+        for field, value in updates.items():\n+            if hasattr(schedule, field):\n+                setattr(schedule, field, value)\n+\n+        # Ensure next_run_at stays accurate when schedule timing changes\n+        if any(field in updates for field in [\"cron_expression\", \"timezone\"]):\n+            next_run_at = ScheduleService.calculate_next_run_at(\n+                schedule.cron_expression,\n+                schedule.timezone,\n+            )\n+            schedule.next_run_at = next_run_at\n+\n+        session.flush()\n+        return schedule\n+\n+    @staticmethod\n+    def delete_schedule(\n+        session: Session,\n+        schedule_id: str,\n+    ) -> bool:\n+        schedule = session.get(WorkflowSchedulePlan, schedule_id)\n+        if not schedule:\n+            return False",
        "comment_created_at": "2025-09-01T13:30:37+00:00",
        "comment_author": "Yeuoly",
        "comment_body": "Also, for non-exists WorkflowSchedulePlan, we should raise exception.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2313979342",
    "pr_number": 24428,
    "pr_file": "api/services/schedule_service.py",
    "created_at": "2025-09-01T13:33:56+00:00",
    "commented_code": "+import json\n+import logging\n+from datetime import UTC, datetime\n+from typing import Optional\n+\n+import pytz\n+from croniter import croniter\n+from sqlalchemy import select\n+from sqlalchemy.orm import Session\n+\n+from core.workflow.nodes import NodeType\n+from models.account import Account, TenantAccountJoin\n+from models.workflow import Workflow, WorkflowSchedulePlan\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class ScheduleService:\n+    @staticmethod\n+    def calculate_next_run_at(\n+        cron_expression: str,\n+        timezone: str,\n+        base_time: Optional[datetime] = None,\n+    ) -> Optional[datetime]:\n+        try:\n+            tz = pytz.timezone(timezone)\n+            if base_time is None:\n+                base_time = datetime.now(UTC)\n+            base_time_tz = base_time.astimezone(tz)\n+            cron = croniter(cron_expression, base_time_tz)\n+            next_run_tz = cron.get_next(datetime)\n+            next_run_utc = next_run_tz.astimezone(UTC)\n+            return next_run_utc\n+        except Exception:\n+            logger.exception(\"Error calculating next run time\")\n+            return None\n+\n+    @staticmethod\n+    def create_schedule(\n+        session: Session,\n+        tenant_id: str,\n+        app_id: str,\n+        node_id: str,\n+        cron_expression: str,\n+        timezone: str,\n+    ) -> WorkflowSchedulePlan:\n+        # Pre-calculate next_run_at to ensure the schedule is valid before persisting\n+        next_run_at = ScheduleService.calculate_next_run_at(\n+            cron_expression,\n+            timezone,\n+        )\n+\n+        schedule = WorkflowSchedulePlan(\n+            tenant_id=tenant_id,\n+            app_id=app_id,\n+            node_id=node_id,\n+            cron_expression=cron_expression,\n+            timezone=timezone,\n+            next_run_at=next_run_at,\n+        )\n+\n+        session.add(schedule)\n+        session.flush()\n+\n+        return schedule\n+\n+    @staticmethod\n+    def update_schedule(\n+        session: Session,\n+        schedule_id: str,\n+        updates: dict,\n+    ) -> Optional[WorkflowSchedulePlan]:\n+        schedule = session.get(WorkflowSchedulePlan, schedule_id)\n+        if not schedule:\n+            return None\n+\n+        for field, value in updates.items():\n+            if hasattr(schedule, field):\n+                setattr(schedule, field, value)\n+\n+        # Ensure next_run_at stays accurate when schedule timing changes\n+        if any(field in updates for field in [\"cron_expression\", \"timezone\"]):\n+            next_run_at = ScheduleService.calculate_next_run_at(\n+                schedule.cron_expression,\n+                schedule.timezone,\n+            )\n+            schedule.next_run_at = next_run_at\n+\n+        session.flush()\n+        return schedule\n+\n+    @staticmethod\n+    def delete_schedule(\n+        session: Session,\n+        schedule_id: str,\n+    ) -> bool:\n+        schedule = session.get(WorkflowSchedulePlan, schedule_id)\n+        if not schedule:\n+            return False\n+\n+        session.delete(schedule)\n+        session.flush()\n+        return True\n+\n+    @staticmethod\n+    def get_tenant_owner(session: Session, tenant_id: str) -> Optional[Account]:\n+        \"\"\"\n+        Returns an account to execute scheduled workflows on behalf of the tenant.\n+        Prioritizes owner over admin to ensure proper authorization hierarchy.\n+        \"\"\"\n+        result = session.execute(\n+            select(TenantAccountJoin)\n+            .where(TenantAccountJoin.tenant_id == tenant_id, TenantAccountJoin.role == \"owner\")\n+            .limit(1)\n+        ).scalar_one_or_none()\n+\n+        if not result:\n+            # Owner may not exist in some tenant configurations, fallback to admin\n+            result = session.execute(\n+                select(TenantAccountJoin)\n+                .where(TenantAccountJoin.tenant_id == tenant_id, TenantAccountJoin.role == \"admin\")\n+                .limit(1)\n+            ).scalar_one_or_none()\n+\n+        if result:\n+            return session.get(Account, result.account_id)\n+\n+        return None\n+\n+    @staticmethod\n+    def update_next_run_at(\n+        session: Session,\n+        schedule_id: str,\n+    ) -> Optional[datetime]:\n+        \"\"\"\n+        Advances the schedule to its next execution time after a successful trigger.\n+        Uses current time as base to prevent missing executions during delays.\n+        \"\"\"\n+        schedule = session.get(WorkflowSchedulePlan, schedule_id)\n+        if not schedule:\n+            return None\n+\n+        # Base on current time to handle execution delays gracefully\n+        next_run_at = ScheduleService.calculate_next_run_at(\n+            schedule.cron_expression,\n+            schedule.timezone,\n+        )\n+\n+        schedule.next_run_at = next_run_at\n+        session.flush()\n+        return next_run_at\n+\n+    @staticmethod\n+    def extract_schedule_config(workflow: Workflow) -> Optional[dict]:\n+        \"\"\"\n+        Extracts schedule configuration from workflow graph for synchronization.\n+        Normalizes both visual and cron modes into a unified cron expression format.\n+        \"\"\"\n+        try:\n+            graph_data = workflow.graph_dict\n+        except (json.JSONDecodeError, TypeError, AttributeError):\n+            return None\n+\n+        if not graph_data:\n+            return None\n+\n+        for node in graph_data.get(\"nodes\", []):\n+            node_data = node.get(\"data\", {})\n+            if node_data.get(\"type\") == NodeType.TRIGGER_SCHEDULE.value:\n+                mode = node_data.get(\"mode\", \"visual\")\n+                timezone = node_data.get(\"timezone\", \"UTC\")\n+                node_id = node.get(\"id\", \"start\")\n+\n+                # Normalize both modes to cron expression for consistent storage\n+                cron_expression = None\n+                if mode == \"cron\":\n+                    cron_expression = node_data.get(\"cron_expression\")\n+                elif mode == \"visual\":\n+                    cron_expression = ScheduleService.visual_to_cron(\n+                        node_data.get(\"frequency\"), node_data.get(\"visual_config\", {})\n+                    )\n+\n+                if cron_expression:\n+                    return {\n+                        \"node_id\": node_id,\n+                        \"cron_expression\": cron_expression,\n+                        \"timezone\": timezone,\n+                    }\n+                else:\n+                    logger.warning(\"Invalid schedule configuration in node %s\", node_id)",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2313979342",
        "repo_full_name": "langgenius/dify",
        "pr_number": 24428,
        "pr_file": "api/services/schedule_service.py",
        "discussion_id": "2313979342",
        "commented_code": "@@ -0,0 +1,313 @@\n+import json\n+import logging\n+from datetime import UTC, datetime\n+from typing import Optional\n+\n+import pytz\n+from croniter import croniter\n+from sqlalchemy import select\n+from sqlalchemy.orm import Session\n+\n+from core.workflow.nodes import NodeType\n+from models.account import Account, TenantAccountJoin\n+from models.workflow import Workflow, WorkflowSchedulePlan\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class ScheduleService:\n+    @staticmethod\n+    def calculate_next_run_at(\n+        cron_expression: str,\n+        timezone: str,\n+        base_time: Optional[datetime] = None,\n+    ) -> Optional[datetime]:\n+        try:\n+            tz = pytz.timezone(timezone)\n+            if base_time is None:\n+                base_time = datetime.now(UTC)\n+            base_time_tz = base_time.astimezone(tz)\n+            cron = croniter(cron_expression, base_time_tz)\n+            next_run_tz = cron.get_next(datetime)\n+            next_run_utc = next_run_tz.astimezone(UTC)\n+            return next_run_utc\n+        except Exception:\n+            logger.exception(\"Error calculating next run time\")\n+            return None\n+\n+    @staticmethod\n+    def create_schedule(\n+        session: Session,\n+        tenant_id: str,\n+        app_id: str,\n+        node_id: str,\n+        cron_expression: str,\n+        timezone: str,\n+    ) -> WorkflowSchedulePlan:\n+        # Pre-calculate next_run_at to ensure the schedule is valid before persisting\n+        next_run_at = ScheduleService.calculate_next_run_at(\n+            cron_expression,\n+            timezone,\n+        )\n+\n+        schedule = WorkflowSchedulePlan(\n+            tenant_id=tenant_id,\n+            app_id=app_id,\n+            node_id=node_id,\n+            cron_expression=cron_expression,\n+            timezone=timezone,\n+            next_run_at=next_run_at,\n+        )\n+\n+        session.add(schedule)\n+        session.flush()\n+\n+        return schedule\n+\n+    @staticmethod\n+    def update_schedule(\n+        session: Session,\n+        schedule_id: str,\n+        updates: dict,\n+    ) -> Optional[WorkflowSchedulePlan]:\n+        schedule = session.get(WorkflowSchedulePlan, schedule_id)\n+        if not schedule:\n+            return None\n+\n+        for field, value in updates.items():\n+            if hasattr(schedule, field):\n+                setattr(schedule, field, value)\n+\n+        # Ensure next_run_at stays accurate when schedule timing changes\n+        if any(field in updates for field in [\"cron_expression\", \"timezone\"]):\n+            next_run_at = ScheduleService.calculate_next_run_at(\n+                schedule.cron_expression,\n+                schedule.timezone,\n+            )\n+            schedule.next_run_at = next_run_at\n+\n+        session.flush()\n+        return schedule\n+\n+    @staticmethod\n+    def delete_schedule(\n+        session: Session,\n+        schedule_id: str,\n+    ) -> bool:\n+        schedule = session.get(WorkflowSchedulePlan, schedule_id)\n+        if not schedule:\n+            return False\n+\n+        session.delete(schedule)\n+        session.flush()\n+        return True\n+\n+    @staticmethod\n+    def get_tenant_owner(session: Session, tenant_id: str) -> Optional[Account]:\n+        \"\"\"\n+        Returns an account to execute scheduled workflows on behalf of the tenant.\n+        Prioritizes owner over admin to ensure proper authorization hierarchy.\n+        \"\"\"\n+        result = session.execute(\n+            select(TenantAccountJoin)\n+            .where(TenantAccountJoin.tenant_id == tenant_id, TenantAccountJoin.role == \"owner\")\n+            .limit(1)\n+        ).scalar_one_or_none()\n+\n+        if not result:\n+            # Owner may not exist in some tenant configurations, fallback to admin\n+            result = session.execute(\n+                select(TenantAccountJoin)\n+                .where(TenantAccountJoin.tenant_id == tenant_id, TenantAccountJoin.role == \"admin\")\n+                .limit(1)\n+            ).scalar_one_or_none()\n+\n+        if result:\n+            return session.get(Account, result.account_id)\n+\n+        return None\n+\n+    @staticmethod\n+    def update_next_run_at(\n+        session: Session,\n+        schedule_id: str,\n+    ) -> Optional[datetime]:\n+        \"\"\"\n+        Advances the schedule to its next execution time after a successful trigger.\n+        Uses current time as base to prevent missing executions during delays.\n+        \"\"\"\n+        schedule = session.get(WorkflowSchedulePlan, schedule_id)\n+        if not schedule:\n+            return None\n+\n+        # Base on current time to handle execution delays gracefully\n+        next_run_at = ScheduleService.calculate_next_run_at(\n+            schedule.cron_expression,\n+            schedule.timezone,\n+        )\n+\n+        schedule.next_run_at = next_run_at\n+        session.flush()\n+        return next_run_at\n+\n+    @staticmethod\n+    def extract_schedule_config(workflow: Workflow) -> Optional[dict]:\n+        \"\"\"\n+        Extracts schedule configuration from workflow graph for synchronization.\n+        Normalizes both visual and cron modes into a unified cron expression format.\n+        \"\"\"\n+        try:\n+            graph_data = workflow.graph_dict\n+        except (json.JSONDecodeError, TypeError, AttributeError):\n+            return None\n+\n+        if not graph_data:\n+            return None\n+\n+        for node in graph_data.get(\"nodes\", []):\n+            node_data = node.get(\"data\", {})\n+            if node_data.get(\"type\") == NodeType.TRIGGER_SCHEDULE.value:\n+                mode = node_data.get(\"mode\", \"visual\")\n+                timezone = node_data.get(\"timezone\", \"UTC\")\n+                node_id = node.get(\"id\", \"start\")\n+\n+                # Normalize both modes to cron expression for consistent storage\n+                cron_expression = None\n+                if mode == \"cron\":\n+                    cron_expression = node_data.get(\"cron_expression\")\n+                elif mode == \"visual\":\n+                    cron_expression = ScheduleService.visual_to_cron(\n+                        node_data.get(\"frequency\"), node_data.get(\"visual_config\", {})\n+                    )\n+\n+                if cron_expression:\n+                    return {\n+                        \"node_id\": node_id,\n+                        \"cron_expression\": cron_expression,\n+                        \"timezone\": timezone,\n+                    }\n+                else:\n+                    logger.warning(\"Invalid schedule configuration in node %s\", node_id)",
        "comment_created_at": "2025-09-01T13:33:56+00:00",
        "comment_author": "Yeuoly",
        "comment_body": "We should not log the message here, raising exception instead.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2234035359",
    "pr_number": 22975,
    "pr_file": "api/core/tools/utils/parser.py",
    "created_at": "2025-07-28T02:54:12+00:00",
    "commented_code": "# overwrite the content\n                             interface[\"operation\"][\"requestBody\"][\"content\"][content_type][\"schema\"] = root\n \n+                            # handle allOf reference in schema properties\n+                            for prop_dict in root.get(\"properties\", {}).values():\n+                                for item in prop_dict.get(\"allOf\", []):\n+                                    if \"$ref\" in item:\n+                                        ref_schema = openapi\n+                                        reference = item[\"$ref\"].split(\"/\")[1:]\n+                                        for ref in reference:\n+                                            ref_schema = ref_schema[ref]\n+                                    else:\n+                                        ref_schema = item\n+                                    for key, value in ref_schema.items():\n+                                        if isinstance(value, list):\n+                                            if key not in prop_dict:\n+                                                prop_dict[key] = []\n+                                            # extends list field\n+                                            if isinstance(prop_dict[key], list):\n+                                                prop_dict[key].extend(value)",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2234492201",
        "repo_full_name": "langgenius/dify",
        "pr_number": 22975,
        "pr_file": "api/core/tools/utils/parser.py",
        "discussion_id": "2234035359",
        "commented_code": "@@ -105,6 +105,29 @@ def parse_openapi_to_tool_bundle(\n                             # overwrite the content\n                             interface[\"operation\"][\"requestBody\"][\"content\"][content_type][\"schema\"] = root\n \n+                            # handle allOf reference in schema properties\n+                            for prop_dict in root.get(\"properties\", {}).values():\n+                                for item in prop_dict.get(\"allOf\", []):\n+                                    if \"$ref\" in item:\n+                                        ref_schema = openapi\n+                                        reference = item[\"$ref\"].split(\"/\")[1:]\n+                                        for ref in reference:\n+                                            ref_schema = ref_schema[ref]\n+                                    else:\n+                                        ref_schema = item\n+                                    for key, value in ref_schema.items():\n+                                        if isinstance(value, list):\n+                                            if key not in prop_dict:\n+                                                prop_dict[key] = []\n+                                            # extends list field\n+                                            if isinstance(prop_dict[key], list):\n+                                                prop_dict[key].extend(value)",
        "comment_created_at": "2025-07-28T02:54:12+00:00",
        "comment_author": "mike1936",
        "comment_body": "This line is actually for skip merging list if the original field of the property is not a list.\r\n\r\nFor strict validation, better raise an error here",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2224470210",
    "pr_number": 22803,
    "pr_file": "api/core/workflow/nodes/list_operator/node.py",
    "created_at": "2025-07-23T05:59:13+00:00",
    "commented_code": "if len(variable.value) > int(value):\n             result = variable.value[value]\n         else:\n-            result = \"\"\n+            result = None",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2224470210",
        "repo_full_name": "langgenius/dify",
        "pr_number": 22803,
        "pr_file": "api/core/workflow/nodes/list_operator/node.py",
        "discussion_id": "2224470210",
        "commented_code": "@@ -188,7 +188,7 @@ def _extract_slice(\n         if len(variable.value) > int(value):\n             result = variable.value[value]\n         else:\n-            result = \"\"\n+            result = None",
        "comment_created_at": "2025-07-23T05:59:13+00:00",
        "comment_author": "Nov1c444",
        "comment_body": "In my opinion, we just need to do the same as Python - throw this error when the list index out of range\r\n```python\r\nelse:\r\n            raise InvalidKeyError(f\"Invalid serial index: must be < {len(variable.value)}, got {value}\")\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2225021272",
        "repo_full_name": "langgenius/dify",
        "pr_number": 22803,
        "pr_file": "api/core/workflow/nodes/list_operator/node.py",
        "discussion_id": "2224470210",
        "commented_code": "@@ -188,7 +188,7 @@ def _extract_slice(\n         if len(variable.value) > int(value):\n             result = variable.value[value]\n         else:\n-            result = \"\"\n+            result = None",
        "comment_created_at": "2025-07-23T09:53:21+00:00",
        "comment_author": "leslie2046",
        "comment_body": "In my opinion,it should return empty File list.",
        "pr_file_module": null
      },
      {
        "comment_id": "2227217834",
        "repo_full_name": "langgenius/dify",
        "pr_number": 22803,
        "pr_file": "api/core/workflow/nodes/list_operator/node.py",
        "discussion_id": "2224470210",
        "commented_code": "@@ -188,7 +188,7 @@ def _extract_slice(\n         if len(variable.value) > int(value):\n             result = variable.value[value]\n         else:\n-            result = \"\"\n+            result = None",
        "comment_created_at": "2025-07-24T03:04:06+00:00",
        "comment_author": "crazywoola",
        "comment_body": "> In my opinion, we just need to do the same as Python - throw this error when the list index out of range\r\n> \r\n> ```python\r\n> else:\r\n>             raise InvalidKeyError(f\"Invalid serial index: must be < {len(variable.value)}, got {value}\")\r\n> ```\r\n\r\n+1",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1796743900",
    "pr_number": 8984,
    "pr_file": "api/core/app/entities/app_invoke_entities.py",
    "created_at": "2024-10-11T10:12:59+00:00",
    "commented_code": "model_config = ConfigDict(protected_namespaces=())\n \n \n-class ChatAppGenerateEntity(EasyUIBasedAppGenerateEntity):\n+class ConversationAppGenerateEntity(AppGenerateEntity):\n     \"\"\"\n-    Chat Application Generate Entity.\n+    Base entity for conversation-based app generation.\n     \"\"\"\n \n     conversation_id: Optional[str] = None\n-    parent_message_id: Optional[str] = None\n+    parent_message_id: Optional[str] = Field(\n+        default=None,\n+        description=(\n+            \"Starting from v0.9.0, parent_message_id is used to support message regeneration \"\n+            \"for internal chat API. For service API, we need to ensure its forward compatibility, \"\n+            \"so passing in the parent_message_id as request arg is not supported for now. \"\n+            \"It will be set to UUID_NIL so that the subsequent processing will treat it as legacy messages.\"\n+        ),\n+    )\n+\n+    @field_validator(\"parent_message_id\")\n+    @classmethod\n+    def validate_parent_message_id(cls, v, info: ValidationInfo):\n+        if info.data.get(\"invoke_from\") == InvokeFrom.SERVICE_API:\n+            return UUID_NIL",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "1796743900",
        "repo_full_name": "langgenius/dify",
        "pr_number": 8984,
        "pr_file": "api/core/app/entities/app_invoke_entities.py",
        "discussion_id": "1796743900",
        "commented_code": "@@ -116,13 +117,36 @@ class EasyUIBasedAppGenerateEntity(AppGenerateEntity):\n     model_config = ConfigDict(protected_namespaces=())\n \n \n-class ChatAppGenerateEntity(EasyUIBasedAppGenerateEntity):\n+class ConversationAppGenerateEntity(AppGenerateEntity):\n     \"\"\"\n-    Chat Application Generate Entity.\n+    Base entity for conversation-based app generation.\n     \"\"\"\n \n     conversation_id: Optional[str] = None\n-    parent_message_id: Optional[str] = None\n+    parent_message_id: Optional[str] = Field(\n+        default=None,\n+        description=(\n+            \"Starting from v0.9.0, parent_message_id is used to support message regeneration \"\n+            \"for internal chat API. For service API, we need to ensure its forward compatibility, \"\n+            \"so passing in the parent_message_id as request arg is not supported for now. \"\n+            \"It will be set to UUID_NIL so that the subsequent processing will treat it as legacy messages.\"\n+        ),\n+    )\n+\n+    @field_validator(\"parent_message_id\")\n+    @classmethod\n+    def validate_parent_message_id(cls, v, info: ValidationInfo):\n+        if info.data.get(\"invoke_from\") == InvokeFrom.SERVICE_API:\n+            return UUID_NIL",
        "comment_created_at": "2024-10-11T10:12:59+00:00",
        "comment_author": "laipz8200",
        "comment_body": "Modifying the input value within the validator is not an ideal approach. I recommend throwing an exception when v != UUID_NIL, and the user should ensure the accuracy of the input data.",
        "pr_file_module": null
      }
    ]
  }
]