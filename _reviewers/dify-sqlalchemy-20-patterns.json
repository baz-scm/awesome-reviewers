[
  {
    "discussion_id": "2312551659",
    "pr_number": 23827,
    "pr_file": "api/services/workflow_alias_service.py",
    "created_at": "2025-08-31T17:08:47+00:00",
    "commented_code": "+import logging\n+import re\n+from typing import TYPE_CHECKING, Optional, Union\n+from uuid import uuid4\n+\n+from pydantic import BaseModel, Field\n+from sqlalchemy import and_, func, select\n+from sqlalchemy.orm import Session\n+\n+if TYPE_CHECKING:\n+    from sqlalchemy.orm import scoped_session\n+\n+from models import Workflow, WorkflowAlias\n+from models.workflow_alias import AliasType\n+\n+\n+class CreateOrUpdateAliasRequest(BaseModel):\n+    \"\"\"\n+    Pydantic model for create or update alias request parameters.\n+    \"\"\"\n+\n+    tenant_id: str = Field(..., description=\"Tenant ID\")\n+    app_id: str = Field(..., description=\"App ID\")\n+    workflow_id: str = Field(..., description=\"Workflow ID\")\n+    alias_name: str = Field(..., description=\"Alias name\", max_length=255)\n+    alias_type: str = Field(default=AliasType.CUSTOM, description=\"Alias type\")\n+    created_by: Optional[str] = Field(default=None, description=\"User ID who created the alias\")\n+\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class WorkflowAliasService:\n+    def create_or_update_alias(\n+        self,\n+        session: Union[Session, \"scoped_session\"],\n+        request: CreateOrUpdateAliasRequest,\n+    ) -> WorkflowAlias:\n+        self._validate_alias_name(request.alias_name)\n+\n+        workflow = session.get(Workflow, request.workflow_id)\n+        if not workflow:\n+            raise ValueError(f\"Workflow {request.workflow_id} not found\")\n+\n+        if workflow.version == Workflow.VERSION_DRAFT:\n+            raise ValueError(\"Cannot create or transfer aliases for draft workflows\")\n+\n+        existing_alias = session.execute(\n+            select(WorkflowAlias).where(\n+                and_(WorkflowAlias.app_id == request.app_id, WorkflowAlias.alias_name == request.alias_name)\n+            )\n+        ).scalar_one_or_none()",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2312551659",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23827,
        "pr_file": "api/services/workflow_alias_service.py",
        "discussion_id": "2312551659",
        "commented_code": "@@ -0,0 +1,149 @@\n+import logging\n+import re\n+from typing import TYPE_CHECKING, Optional, Union\n+from uuid import uuid4\n+\n+from pydantic import BaseModel, Field\n+from sqlalchemy import and_, func, select\n+from sqlalchemy.orm import Session\n+\n+if TYPE_CHECKING:\n+    from sqlalchemy.orm import scoped_session\n+\n+from models import Workflow, WorkflowAlias\n+from models.workflow_alias import AliasType\n+\n+\n+class CreateOrUpdateAliasRequest(BaseModel):\n+    \"\"\"\n+    Pydantic model for create or update alias request parameters.\n+    \"\"\"\n+\n+    tenant_id: str = Field(..., description=\"Tenant ID\")\n+    app_id: str = Field(..., description=\"App ID\")\n+    workflow_id: str = Field(..., description=\"Workflow ID\")\n+    alias_name: str = Field(..., description=\"Alias name\", max_length=255)\n+    alias_type: str = Field(default=AliasType.CUSTOM, description=\"Alias type\")\n+    created_by: Optional[str] = Field(default=None, description=\"User ID who created the alias\")\n+\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+class WorkflowAliasService:\n+    def create_or_update_alias(\n+        self,\n+        session: Union[Session, \"scoped_session\"],\n+        request: CreateOrUpdateAliasRequest,\n+    ) -> WorkflowAlias:\n+        self._validate_alias_name(request.alias_name)\n+\n+        workflow = session.get(Workflow, request.workflow_id)\n+        if not workflow:\n+            raise ValueError(f\"Workflow {request.workflow_id} not found\")\n+\n+        if workflow.version == Workflow.VERSION_DRAFT:\n+            raise ValueError(\"Cannot create or transfer aliases for draft workflows\")\n+\n+        existing_alias = session.execute(\n+            select(WorkflowAlias).where(\n+                and_(WorkflowAlias.app_id == request.app_id, WorkflowAlias.alias_name == request.alias_name)\n+            )\n+        ).scalar_one_or_none()",
        "comment_created_at": "2025-08-31T17:08:47+00:00",
        "comment_author": "laipz8200",
        "comment_body": "Using `session.scalar` would be better.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2310722364",
    "pr_number": 24801,
    "pr_file": "api/core/tools/tool_manager.py",
    "created_at": "2025-08-29T17:28:43+00:00",
    "commented_code": "# get db api providers\n             if \"api\" in filters:\n-                db_api_providers: list[ApiToolProvider] = (\n-                    db.session.query(ApiToolProvider).where(ApiToolProvider.tenant_id == tenant_id).all()\n-                )\n+                db_api_providers: list[ApiToolProvider] = db.session.scalars(",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2310722364",
        "repo_full_name": "langgenius/dify",
        "pr_number": 24801,
        "pr_file": "api/core/tools/tool_manager.py",
        "discussion_id": "2310722364",
        "commented_code": "@@ -667,9 +668,9 @@ def list_providers_from_api(\n \n             # get db api providers\n             if \"api\" in filters:\n-                db_api_providers: list[ApiToolProvider] = (\n-                    db.session.query(ApiToolProvider).where(ApiToolProvider.tenant_id == tenant_id).all()\n-                )\n+                db_api_providers: list[ApiToolProvider] = db.session.scalars(",
        "comment_created_at": "2025-08-29T17:28:43+00:00",
        "comment_author": "asukaminato0721",
        "comment_body": "```suggestion\r\n                db_api_providers = db.session.scalars(\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2261968774",
    "pr_number": 23224,
    "pr_file": "api/core/agent/base_agent_runner.py",
    "created_at": "2025-08-08T05:29:06+00:00",
    "commented_code": "\"\"\"\n         Save agent thought\n         \"\"\"\n-        agent_thought = db.session.query(MessageAgentThought).where(MessageAgentThought.id == agent_thought_id).first()\n+        stmt = select(MessageAgentThought).where(MessageAgentThought.id == agent_thought_id)\n+        agent_thought = db.session.execute(stmt).scalars().first()",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2261968774",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/agent/base_agent_runner.py",
        "discussion_id": "2261968774",
        "commented_code": "@@ -334,7 +334,8 @@ def save_agent_thought(\n         \"\"\"\n         Save agent thought\n         \"\"\"\n-        agent_thought = db.session.query(MessageAgentThought).where(MessageAgentThought.id == agent_thought_id).first()\n+        stmt = select(MessageAgentThought).where(MessageAgentThought.id == agent_thought_id)\n+        agent_thought = db.session.execute(stmt).scalars().first()",
        "comment_created_at": "2025-08-08T05:29:06+00:00",
        "comment_author": "asukaminato0721",
        "comment_body": "I guess?\r\n\r\n```suggestion\r\n        agent_thought = db.session.scalar(stmt)\r\n```\r\n\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2265298146",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/agent/base_agent_runner.py",
        "discussion_id": "2261968774",
        "commented_code": "@@ -334,7 +334,8 @@ def save_agent_thought(\n         \"\"\"\n         Save agent thought\n         \"\"\"\n-        agent_thought = db.session.query(MessageAgentThought).where(MessageAgentThought.id == agent_thought_id).first()\n+        stmt = select(MessageAgentThought).where(MessageAgentThought.id == agent_thought_id)\n+        agent_thought = db.session.execute(stmt).scalars().first()",
        "comment_created_at": "2025-08-10T13:58:03+00:00",
        "comment_author": "hyongtao-code",
        "comment_body": "Thanks for your review. Your suggestion is correct and concise. I\u2019ve made the changes in this commit [04e168e](https://github.com/langgenius/dify/pull/23224/commits/04e168ebf5f0ff6558f9ab4c9b9213b9a5036273).\r\nBelow is the replacement script I used `python replace_script.py api\\core\\ --write`, which is also based on libcst and was written by ChatGPT.\r\n<details>\r\n<summary>python script </summary>\r\n\r\n``` python\r\n#!/usr/bin/env python3\r\n\"\"\"\r\nBatch-rewrite:\r\n    *.session.execute(stmt).scalars().first()\r\nto:\r\n    *.session.scalar(stmt)\r\n\r\n- Preserves formatting/comments via LibCST.\r\n- Default: dry-run (preview unified diff with colors).\r\n- Use --write to apply changes.\r\n\r\npip install libcst\r\n\"\"\"\r\n\r\nimport argparse\r\nimport difflib\r\nimport os\r\nfrom pathlib import Path\r\nimport libcst as cst\r\n\r\n\r\nclass ExecScalarsFirstToScalar(cst.CSTTransformer):\r\n    \"\"\"\r\n    Match chain:  <ANY>.session.execute(args...).scalars().first()\r\n    Replace with: <ANY>.session.scalar(args...)\r\n    \"\"\"\r\n\r\n    def leave_Call(self, original_node: cst.Call, updated_node: cst.Call) -> cst.BaseExpression:\r\n        # must be .first() with no args\r\n        if not isinstance(updated_node.func, cst.Attribute):\r\n            return updated_node\r\n        attr_first = updated_node.func\r\n        if not isinstance(attr_first.attr, cst.Name) or attr_first.attr.value != \"first\":\r\n            return updated_node\r\n        if len(updated_node.args) != 0:\r\n            return updated_node\r\n\r\n        # its receiver must be scalars() with no args\r\n        scalars_call = attr_first.value\r\n        if not isinstance(scalars_call, cst.Call):\r\n            return updated_node\r\n        if not (isinstance(scalars_call.func, cst.Attribute)\r\n                and isinstance(scalars_call.func.attr, cst.Name)\r\n                and scalars_call.func.attr.value == \"scalars\"):\r\n            return updated_node\r\n        if len(scalars_call.args) != 0:\r\n            return updated_node\r\n\r\n        # whose receiver must be execute(...)\r\n        execute_call = scalars_call.func.value\r\n        if not isinstance(execute_call, cst.Call):\r\n            return updated_node\r\n        if not (isinstance(execute_call.func, cst.Attribute)\r\n                and isinstance(execute_call.func.attr, cst.Name)\r\n                and execute_call.func.attr.value == \"execute\"):\r\n            return updated_node\r\n\r\n        # and that execute(...) must be on *.session\r\n        session_attr = execute_call.func.value\r\n        if not (isinstance(session_attr, cst.Attribute)\r\n                and isinstance(session_attr.attr, cst.Name)\r\n                and session_attr.attr.value == \"session\"):\r\n            return updated_node\r\n\r\n        # Build: *.session.scalar(<execute args...>)\r\n        new_func = cst.Attribute(value=session_attr, attr=cst.Name(\"scalar\"))\r\n        new_call = cst.Call(func=new_func, args=execute_call.args)\r\n\r\n        # Keep parentheses from the outer call if present\r\n        if original_node.lpar or original_node.rpar:\r\n            new_call = new_call.with_changes(lpar=original_node.lpar, rpar=original_node.rpar)\r\n\r\n        return new_call\r\n\r\n\r\ndef rewrite_source(code: str) -> str:\r\n    mod = cst.parse_module(code)\r\n    new_mod = mod.visit(ExecScalarsFirstToScalar())\r\n    return new_mod.code\r\n\r\n\r\ndef color_diff(diff_lines):\r\n    for line in diff_lines:\r\n        if line.startswith(\"-\"):\r\n            yield f\"\\033[31m{line}\\033[0m\"  # \u7ea2\u8272\r\n        elif line.startswith(\"+\"):\r\n            yield f\"\\033[32m{line}\\033[0m\"  # \u7eff\u8272\r\n        else:\r\n            yield line\r\n\r\n\r\ndef process_file(fp: Path, write: bool) -> bool:\r\n    try:\r\n        src = fp.read_text(encoding=\"utf-8\")\r\n    except Exception:\r\n        return False\r\n\r\n    try:\r\n        new_src = rewrite_source(src)\r\n    except Exception:\r\n        # skip files that fail to parse\r\n        return False\r\n\r\n    if src == new_src:\r\n        return False\r\n\r\n    if write:\r\n        fp.write_text(new_src, encoding=\"utf-8\")\r\n        print(f\"Updated: {fp}\")\r\n    else:\r\n        print(f\"DRY-RUN (would update): {fp}\")\r\n        diff = difflib.unified_diff(\r\n            src.splitlines(keepends=True),\r\n            new_src.splitlines(keepends=True),\r\n            fromfile=str(fp),\r\n            tofile=f\"{fp} (rewritten)\",\r\n            n=3,\r\n        )\r\n        for i, line in enumerate(color_diff(diff)):\r\n            if i > 200:\r\n                print(\"... (diff truncated)\")\r\n                break\r\n            print(line, end=\"\")\r\n    return True\r\n\r\n\r\ndef iter_py_files(root: Path):\r\n    if root.is_file() and root.suffix == \".py\":\r\n        yield root\r\n        return\r\n    EXCLUDES = {\".git\", \".hg\", \".svn\", \".idea\", \".vscode\", \"node_modules\", \"dist\", \"build\", \"__pycache__\", \".venv\", \"venv\"}\r\n    for dirpath, dirnames, filenames in os.walk(root):\r\n        dirnames[:] = [d for d in dirnames if d not in EXCLUDES]\r\n        for name in filenames:\r\n            if name.endswith(\".py\"):\r\n                yield Path(dirpath) / name\r\n\r\n\r\ndef main():\r\n    ap = argparse.ArgumentParser(\r\n        description=\"Rewrite *.session.execute(...).scalars().first() -> *.session.scalar(...) using LibCST\"\r\n    )\r\n    ap.add_argument(\"path\", help=\"Project root directory or a single .py file\")\r\n    ap.add_argument(\"--write\", action=\"store_true\", help=\"Apply changes (default: dry-run preview)\")\r\n    args = ap.parse_args()\r\n\r\n    root = Path(args.path).resolve()\r\n    if not root.exists():\r\n        raise SystemExit(f\"Path not found: {root}\")\r\n\r\n    changed = 0\r\n    for fp in iter_py_files(root):\r\n        if process_file(fp, write=args.write):\r\n            changed += 1\r\n\r\n    if args.write:\r\n        print(f\"Done. Files updated: {changed}\")\r\n    else:\r\n        print(f\"Dry-run complete. Files that would change: {changed}\")\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n\r\n```\r\n</details> ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2265616628",
    "pr_number": 23224,
    "pr_file": "api/core/agent/base_agent_runner.py",
    "created_at": "2025-08-11T03:48:11+00:00",
    "commented_code": "return result\n \n     def organize_agent_user_prompt(self, message: Message) -> UserPromptMessage:\n-        files = db.session.query(MessageFile).where(MessageFile.message_id == message.id).all()\n+        stmt = select(MessageFile).where(MessageFile.message_id == message.id)\n+        files = db.session.execute(stmt).scalars().all()",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2265616628",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/agent/base_agent_runner.py",
        "discussion_id": "2265616628",
        "commented_code": "@@ -492,7 +493,8 @@ def organize_agent_history(self, prompt_messages: list[PromptMessage]) -> list[P\n         return result\n \n     def organize_agent_user_prompt(self, message: Message) -> UserPromptMessage:\n-        files = db.session.query(MessageFile).where(MessageFile.message_id == message.id).all()\n+        stmt = select(MessageFile).where(MessageFile.message_id == message.id)\n+        files = db.session.execute(stmt).scalars().all()",
        "comment_created_at": "2025-08-11T03:48:11+00:00",
        "comment_author": "asukaminato0721",
        "comment_body": "I guess\r\n\r\n```suggestion\r\n        files = db.session.scalars(stmt).all()\r\n```\r\n\r\nref https://docs.sqlalchemy.org/en/20/orm/queryguide/select.html#selecting-orm-entities",
        "pr_file_module": null
      },
      {
        "comment_id": "2265808035",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/agent/base_agent_runner.py",
        "discussion_id": "2265616628",
        "commented_code": "@@ -492,7 +493,8 @@ def organize_agent_history(self, prompt_messages: list[PromptMessage]) -> list[P\n         return result\n \n     def organize_agent_user_prompt(self, message: Message) -> UserPromptMessage:\n-        files = db.session.query(MessageFile).where(MessageFile.message_id == message.id).all()\n+        stmt = select(MessageFile).where(MessageFile.message_id == message.id)\n+        files = db.session.execute(stmt).scalars().all()",
        "comment_created_at": "2025-08-11T06:35:00+00:00",
        "comment_author": "hyongtao-code",
        "comment_body": "Thanks for your suggestion \u2014 this way is both concise and correct.\r\nRef: 531008d",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2265699642",
    "pr_number": 23224,
    "pr_file": "api/core/rag/extractor/notion_extractor.py",
    "created_at": "2025-08-11T05:01:53+00:00",
    "commented_code": "@classmethod\n     def _get_access_token(cls, tenant_id: str, notion_workspace_id: str) -> str:\n-        data_source_binding = (\n-            db.session.query(DataSourceOauthBinding)\n-            .where(\n-                db.and_(\n-                    DataSourceOauthBinding.tenant_id == tenant_id,\n-                    DataSourceOauthBinding.provider == \"notion\",\n-                    DataSourceOauthBinding.disabled == False,\n-                    DataSourceOauthBinding.source_info[\"workspace_id\"] == f'\"{notion_workspace_id}\"',\n-                )\n+        stmt = select(DataSourceOauthBinding).where(\n+            db.and_(",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2265699642",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/rag/extractor/notion_extractor.py",
        "discussion_id": "2265699642",
        "commented_code": "@@ -367,18 +368,15 @@ def get_notion_last_edited_time(self) -> str:\n \n     @classmethod\n     def _get_access_token(cls, tenant_id: str, notion_workspace_id: str) -> str:\n-        data_source_binding = (\n-            db.session.query(DataSourceOauthBinding)\n-            .where(\n-                db.and_(\n-                    DataSourceOauthBinding.tenant_id == tenant_id,\n-                    DataSourceOauthBinding.provider == \"notion\",\n-                    DataSourceOauthBinding.disabled == False,\n-                    DataSourceOauthBinding.source_info[\"workspace_id\"] == f'\"{notion_workspace_id}\"',\n-                )\n+        stmt = select(DataSourceOauthBinding).where(\n+            db.and_(",
        "comment_created_at": "2025-08-11T05:01:53+00:00",
        "comment_author": "asukaminato0721",
        "comment_body": "by default is and, so can delete it\r\n\r\n```suggestion\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2265810081",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/rag/extractor/notion_extractor.py",
        "discussion_id": "2265699642",
        "commented_code": "@@ -367,18 +368,15 @@ def get_notion_last_edited_time(self) -> str:\n \n     @classmethod\n     def _get_access_token(cls, tenant_id: str, notion_workspace_id: str) -> str:\n-        data_source_binding = (\n-            db.session.query(DataSourceOauthBinding)\n-            .where(\n-                db.and_(\n-                    DataSourceOauthBinding.tenant_id == tenant_id,\n-                    DataSourceOauthBinding.provider == \"notion\",\n-                    DataSourceOauthBinding.disabled == False,\n-                    DataSourceOauthBinding.source_info[\"workspace_id\"] == f'\"{notion_workspace_id}\"',\n-                )\n+        stmt = select(DataSourceOauthBinding).where(\n+            db.and_(",
        "comment_created_at": "2025-08-11T06:36:25+00:00",
        "comment_author": "hyongtao-code",
        "comment_body": "Done at commit 587ef58",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2265872048",
    "pr_number": 23224,
    "pr_file": "api/core/indexing_runner.py",
    "created_at": "2025-08-11T07:14:35+00:00",
    "commented_code": "if dataset_document.data_source_type == \"upload_file\":\n             if not data_source_info or \"upload_file_id\" not in data_source_info:\n                 raise ValueError(\"no upload file found\")\n-\n-            file_detail = (\n-                db.session.query(UploadFile).where(UploadFile.id == data_source_info[\"upload_file_id\"]).one_or_none()\n-            )\n+            stmt = select(UploadFile).where(UploadFile.id == data_source_info[\"upload_file_id\"])\n+            file_detail = db.session.execute(stmt).scalars().one_or_none()",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2265872048",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/indexing_runner.py",
        "discussion_id": "2265872048",
        "commented_code": "@@ -345,10 +338,8 @@ def _extract(\n         if dataset_document.data_source_type == \"upload_file\":\n             if not data_source_info or \"upload_file_id\" not in data_source_info:\n                 raise ValueError(\"no upload file found\")\n-\n-            file_detail = (\n-                db.session.query(UploadFile).where(UploadFile.id == data_source_info[\"upload_file_id\"]).one_or_none()\n-            )\n+            stmt = select(UploadFile).where(UploadFile.id == data_source_info[\"upload_file_id\"])\n+            file_detail = db.session.execute(stmt).scalars().one_or_none()",
        "comment_created_at": "2025-08-11T07:14:35+00:00",
        "comment_author": "asukaminato0721",
        "comment_body": "I wonder whether here can also be the same.",
        "pr_file_module": null
      },
      {
        "comment_id": "2265874785",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/indexing_runner.py",
        "discussion_id": "2265872048",
        "commented_code": "@@ -345,10 +338,8 @@ def _extract(\n         if dataset_document.data_source_type == \"upload_file\":\n             if not data_source_info or \"upload_file_id\" not in data_source_info:\n                 raise ValueError(\"no upload file found\")\n-\n-            file_detail = (\n-                db.session.query(UploadFile).where(UploadFile.id == data_source_info[\"upload_file_id\"]).one_or_none()\n-            )\n+            stmt = select(UploadFile).where(UploadFile.id == data_source_info[\"upload_file_id\"])\n+            file_detail = db.session.execute(stmt).scalars().one_or_none()",
        "comment_created_at": "2025-08-11T07:16:14+00:00",
        "comment_author": "hyongtao-code",
        "comment_body": "OK, pls let me have a check.",
        "pr_file_module": null
      },
      {
        "comment_id": "2265920766",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/indexing_runner.py",
        "discussion_id": "2265872048",
        "commented_code": "@@ -345,10 +338,8 @@ def _extract(\n         if dataset_document.data_source_type == \"upload_file\":\n             if not data_source_info or \"upload_file_id\" not in data_source_info:\n                 raise ValueError(\"no upload file found\")\n-\n-            file_detail = (\n-                db.session.query(UploadFile).where(UploadFile.id == data_source_info[\"upload_file_id\"]).one_or_none()\n-            )\n+            stmt = select(UploadFile).where(UploadFile.id == data_source_info[\"upload_file_id\"])\n+            file_detail = db.session.execute(stmt).scalars().one_or_none()",
        "comment_created_at": "2025-08-11T07:40:52+00:00",
        "comment_author": "hyongtao-code",
        "comment_body": "`one_or_none()` can also be written following the previous pattern.\n**Code**:\n``` python\nengine = create_engine(DATABASE_URL, echo=True)\nSession = sessionmaker(bind=engine)\nsession = Session()\n\nprint(\"+-----------------------------------------------------+\")\nstmt = select(User).where(User.id==1)\nu2 = session.execute(stmt).scalars().one_or_none()\nprint(\"1-----------------------------------------------------+\")\nprint(u2)\nprint(type(u2))\n\nu3 = session.scalars(stmt).one_or_none()\nprint(\"2-----------------------------------------------------+\")\nprint(u3)\nprint(type(u3))\n\nstmt2 = select(User).where(User.id==-99999)\nu4 = session.execute(stmt2).scalars().one_or_none()\nprint(\"3-----------------------------------------------------+\")\nprint(u4)\nprint(type(u4))\n\nu5 = session.scalars(stmt2).one_or_none()\nprint(\"4-----------------------------------------------------+\")\nprint(u5)\nprint(type(u5))\n\nsession.close()\n```\n**Result**:\n```bash\n+-----------------------------------------------------+\n1-----------------------------------------------------+\n<User(id=1, name='Alice', email='alice@example.com')>\n<class '__main__.User'>\n2-----------------------------------------------------+\n<User(id=1, name='Alice', email='alice@example.com')>\n<class '__main__.User'>\n3-----------------------------------------------------+\nNone\n<class 'NoneType'>\n4-----------------------------------------------------+\nNone\n<class 'NoneType'>\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2266043469",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/indexing_runner.py",
        "discussion_id": "2265872048",
        "commented_code": "@@ -345,10 +338,8 @@ def _extract(\n         if dataset_document.data_source_type == \"upload_file\":\n             if not data_source_info or \"upload_file_id\" not in data_source_info:\n                 raise ValueError(\"no upload file found\")\n-\n-            file_detail = (\n-                db.session.query(UploadFile).where(UploadFile.id == data_source_info[\"upload_file_id\"]).one_or_none()\n-            )\n+            stmt = select(UploadFile).where(UploadFile.id == data_source_info[\"upload_file_id\"])\n+            file_detail = db.session.execute(stmt).scalars().one_or_none()",
        "comment_created_at": "2025-08-11T08:45:28+00:00",
        "comment_author": "hyongtao-code",
        "comment_body": "Done at commit 9fb221a",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2265884331",
    "pr_number": 23224,
    "pr_file": "api/core/ops/arize_phoenix_trace/arize_phoenix_trace.py",
    "created_at": "2025-08-11T07:21:30+00:00",
    "commented_code": "def _get_workflow_nodes(self, workflow_run_id: str):\n         \"\"\"Helper method to get workflow nodes\"\"\"\n-        workflow_nodes = (\n-            db.session.query(\n-                WorkflowNodeExecutionModel.id,\n-                WorkflowNodeExecutionModel.tenant_id,\n-                WorkflowNodeExecutionModel.app_id,\n-                WorkflowNodeExecutionModel.title,\n-                WorkflowNodeExecutionModel.node_type,\n-                WorkflowNodeExecutionModel.status,\n-                WorkflowNodeExecutionModel.inputs,\n-                WorkflowNodeExecutionModel.outputs,\n-                WorkflowNodeExecutionModel.created_at,\n-                WorkflowNodeExecutionModel.elapsed_time,\n-                WorkflowNodeExecutionModel.process_data,\n-                WorkflowNodeExecutionModel.execution_metadata,\n-            )\n-            .where(WorkflowNodeExecutionModel.workflow_run_id == workflow_run_id)\n-            .all()\n-        )\n+        stmt = select(\n+            WorkflowNodeExecutionModel.id,\n+            WorkflowNodeExecutionModel.tenant_id,\n+            WorkflowNodeExecutionModel.app_id,\n+            WorkflowNodeExecutionModel.title,\n+            WorkflowNodeExecutionModel.node_type,\n+            WorkflowNodeExecutionModel.status,\n+            WorkflowNodeExecutionModel.inputs,\n+            WorkflowNodeExecutionModel.outputs,\n+            WorkflowNodeExecutionModel.created_at,\n+            WorkflowNodeExecutionModel.elapsed_time,\n+            WorkflowNodeExecutionModel.process_data,\n+            WorkflowNodeExecutionModel.execution_metadata,\n+        ).where(WorkflowNodeExecutionModel.workflow_run_id == workflow_run_id)\n+        workflow_nodes = db.session.scalars(stmt).all()",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2265884331",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/ops/arize_phoenix_trace/arize_phoenix_trace.py",
        "discussion_id": "2265884331",
        "commented_code": "@@ -699,24 +700,21 @@ def get_project_url(self):\n \n     def _get_workflow_nodes(self, workflow_run_id: str):\n         \"\"\"Helper method to get workflow nodes\"\"\"\n-        workflow_nodes = (\n-            db.session.query(\n-                WorkflowNodeExecutionModel.id,\n-                WorkflowNodeExecutionModel.tenant_id,\n-                WorkflowNodeExecutionModel.app_id,\n-                WorkflowNodeExecutionModel.title,\n-                WorkflowNodeExecutionModel.node_type,\n-                WorkflowNodeExecutionModel.status,\n-                WorkflowNodeExecutionModel.inputs,\n-                WorkflowNodeExecutionModel.outputs,\n-                WorkflowNodeExecutionModel.created_at,\n-                WorkflowNodeExecutionModel.elapsed_time,\n-                WorkflowNodeExecutionModel.process_data,\n-                WorkflowNodeExecutionModel.execution_metadata,\n-            )\n-            .where(WorkflowNodeExecutionModel.workflow_run_id == workflow_run_id)\n-            .all()\n-        )\n+        stmt = select(\n+            WorkflowNodeExecutionModel.id,\n+            WorkflowNodeExecutionModel.tenant_id,\n+            WorkflowNodeExecutionModel.app_id,\n+            WorkflowNodeExecutionModel.title,\n+            WorkflowNodeExecutionModel.node_type,\n+            WorkflowNodeExecutionModel.status,\n+            WorkflowNodeExecutionModel.inputs,\n+            WorkflowNodeExecutionModel.outputs,\n+            WorkflowNodeExecutionModel.created_at,\n+            WorkflowNodeExecutionModel.elapsed_time,\n+            WorkflowNodeExecutionModel.process_data,\n+            WorkflowNodeExecutionModel.execution_metadata,\n+        ).where(WorkflowNodeExecutionModel.workflow_run_id == workflow_run_id)\n+        workflow_nodes = db.session.scalars(stmt).all()",
        "comment_created_at": "2025-08-11T07:21:30+00:00",
        "comment_author": "asukaminato0721",
        "comment_body": "aa\uff0csorry\uff0cin this case we need original version.\r\nRef https://stackoverflow.com/questions/72790215/sqlalchemy-2-x-with-specific-columns-makes-scalars-return-non-orm-objects",
        "pr_file_module": null
      },
      {
        "comment_id": "2265924065",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/ops/arize_phoenix_trace/arize_phoenix_trace.py",
        "discussion_id": "2265884331",
        "commented_code": "@@ -699,24 +700,21 @@ def get_project_url(self):\n \n     def _get_workflow_nodes(self, workflow_run_id: str):\n         \"\"\"Helper method to get workflow nodes\"\"\"\n-        workflow_nodes = (\n-            db.session.query(\n-                WorkflowNodeExecutionModel.id,\n-                WorkflowNodeExecutionModel.tenant_id,\n-                WorkflowNodeExecutionModel.app_id,\n-                WorkflowNodeExecutionModel.title,\n-                WorkflowNodeExecutionModel.node_type,\n-                WorkflowNodeExecutionModel.status,\n-                WorkflowNodeExecutionModel.inputs,\n-                WorkflowNodeExecutionModel.outputs,\n-                WorkflowNodeExecutionModel.created_at,\n-                WorkflowNodeExecutionModel.elapsed_time,\n-                WorkflowNodeExecutionModel.process_data,\n-                WorkflowNodeExecutionModel.execution_metadata,\n-            )\n-            .where(WorkflowNodeExecutionModel.workflow_run_id == workflow_run_id)\n-            .all()\n-        )\n+        stmt = select(\n+            WorkflowNodeExecutionModel.id,\n+            WorkflowNodeExecutionModel.tenant_id,\n+            WorkflowNodeExecutionModel.app_id,\n+            WorkflowNodeExecutionModel.title,\n+            WorkflowNodeExecutionModel.node_type,\n+            WorkflowNodeExecutionModel.status,\n+            WorkflowNodeExecutionModel.inputs,\n+            WorkflowNodeExecutionModel.outputs,\n+            WorkflowNodeExecutionModel.created_at,\n+            WorkflowNodeExecutionModel.elapsed_time,\n+            WorkflowNodeExecutionModel.process_data,\n+            WorkflowNodeExecutionModel.execution_metadata,\n+        ).where(WorkflowNodeExecutionModel.workflow_run_id == workflow_run_id)\n+        workflow_nodes = db.session.scalars(stmt).all()",
        "comment_created_at": "2025-08-11T07:42:44+00:00",
        "comment_author": "hyongtao-code",
        "comment_body": "Thanks for the reminder. No worries, please let me double-check.",
        "pr_file_module": null
      },
      {
        "comment_id": "2265967284",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/ops/arize_phoenix_trace/arize_phoenix_trace.py",
        "discussion_id": "2265884331",
        "commented_code": "@@ -699,24 +700,21 @@ def get_project_url(self):\n \n     def _get_workflow_nodes(self, workflow_run_id: str):\n         \"\"\"Helper method to get workflow nodes\"\"\"\n-        workflow_nodes = (\n-            db.session.query(\n-                WorkflowNodeExecutionModel.id,\n-                WorkflowNodeExecutionModel.tenant_id,\n-                WorkflowNodeExecutionModel.app_id,\n-                WorkflowNodeExecutionModel.title,\n-                WorkflowNodeExecutionModel.node_type,\n-                WorkflowNodeExecutionModel.status,\n-                WorkflowNodeExecutionModel.inputs,\n-                WorkflowNodeExecutionModel.outputs,\n-                WorkflowNodeExecutionModel.created_at,\n-                WorkflowNodeExecutionModel.elapsed_time,\n-                WorkflowNodeExecutionModel.process_data,\n-                WorkflowNodeExecutionModel.execution_metadata,\n-            )\n-            .where(WorkflowNodeExecutionModel.workflow_run_id == workflow_run_id)\n-            .all()\n-        )\n+        stmt = select(\n+            WorkflowNodeExecutionModel.id,\n+            WorkflowNodeExecutionModel.tenant_id,\n+            WorkflowNodeExecutionModel.app_id,\n+            WorkflowNodeExecutionModel.title,\n+            WorkflowNodeExecutionModel.node_type,\n+            WorkflowNodeExecutionModel.status,\n+            WorkflowNodeExecutionModel.inputs,\n+            WorkflowNodeExecutionModel.outputs,\n+            WorkflowNodeExecutionModel.created_at,\n+            WorkflowNodeExecutionModel.elapsed_time,\n+            WorkflowNodeExecutionModel.process_data,\n+            WorkflowNodeExecutionModel.execution_metadata,\n+        ).where(WorkflowNodeExecutionModel.workflow_run_id == workflow_run_id)\n+        workflow_nodes = db.session.scalars(stmt).all()",
        "comment_created_at": "2025-08-11T08:05:08+00:00",
        "comment_author": "hyongtao-code",
        "comment_body": "Good catch.\n**Demo code:**\n```python\nengine = create_engine(DATABASE_URL, echo=True)\nSession = sessionmaker(bind=engine)\nsession = Session()\n\nprint(\"+-----------------------------------------------------+\")\nstmt = select(User)\nu2 = session.execute(stmt).scalars().all()\nprint(\"1-----------------------------------------------------+\")\nprint(u2)\nprint(type(u2))\n\nu3 = session.scalars(stmt).all()\nprint(\"2-----------------------------------------------------+\")\nprint(u3)\nprint(type(u3))\n\nstmt2 = select(User.id, User.name, User.email)\nu4 = session.execute(stmt2).scalars().all()\nprint(\"3-----------------------------------------------------+\")\nprint(u4)\nprint(type(u4))\n\nu5 = session.scalars(stmt2).all()\nprint(\"4-----------------------------------------------------+\")\nprint(u5)\nprint(type(u5))\n\nsession.close()\n\n```\n**Result:**\n```bash\n1-----------------------------------------------------+\n[<User(id=1, name='Alice', email='alice@example.com')>, <User(id=2, name='Bob', email='bob@example.com')>, <User(id=3, name='Charlie', email='charlie@example.com')>]\n<class 'list'>\n2-----------------------------------------------------+\n[<User(id=1, name='Alice', email='alice@example.com')>, <User(id=2, name='Bob', email='bob@example.com')>, <User(id=3, name='Charlie', email='charlie@example.com')>]\n<class 'list'>\n3-----------------------------------------------------+\n[1, 2, 3] -------------------!!! This is not as expected.\n<class 'list'>\n4-----------------------------------------------------+\n[1, 2, 3] -------------------!!! This is not as expected.\n<class 'list'>\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2266044287",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/ops/arize_phoenix_trace/arize_phoenix_trace.py",
        "discussion_id": "2265884331",
        "commented_code": "@@ -699,24 +700,21 @@ def get_project_url(self):\n \n     def _get_workflow_nodes(self, workflow_run_id: str):\n         \"\"\"Helper method to get workflow nodes\"\"\"\n-        workflow_nodes = (\n-            db.session.query(\n-                WorkflowNodeExecutionModel.id,\n-                WorkflowNodeExecutionModel.tenant_id,\n-                WorkflowNodeExecutionModel.app_id,\n-                WorkflowNodeExecutionModel.title,\n-                WorkflowNodeExecutionModel.node_type,\n-                WorkflowNodeExecutionModel.status,\n-                WorkflowNodeExecutionModel.inputs,\n-                WorkflowNodeExecutionModel.outputs,\n-                WorkflowNodeExecutionModel.created_at,\n-                WorkflowNodeExecutionModel.elapsed_time,\n-                WorkflowNodeExecutionModel.process_data,\n-                WorkflowNodeExecutionModel.execution_metadata,\n-            )\n-            .where(WorkflowNodeExecutionModel.workflow_run_id == workflow_run_id)\n-            .all()\n-        )\n+        stmt = select(\n+            WorkflowNodeExecutionModel.id,\n+            WorkflowNodeExecutionModel.tenant_id,\n+            WorkflowNodeExecutionModel.app_id,\n+            WorkflowNodeExecutionModel.title,\n+            WorkflowNodeExecutionModel.node_type,\n+            WorkflowNodeExecutionModel.status,\n+            WorkflowNodeExecutionModel.inputs,\n+            WorkflowNodeExecutionModel.outputs,\n+            WorkflowNodeExecutionModel.created_at,\n+            WorkflowNodeExecutionModel.elapsed_time,\n+            WorkflowNodeExecutionModel.process_data,\n+            WorkflowNodeExecutionModel.execution_metadata,\n+        ).where(WorkflowNodeExecutionModel.workflow_run_id == workflow_run_id)\n+        workflow_nodes = db.session.scalars(stmt).all()",
        "comment_created_at": "2025-08-11T08:45:53+00:00",
        "comment_author": "hyongtao-code",
        "comment_body": "Done at commit 95bb455",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2299989050",
    "pr_number": 23224,
    "pr_file": "api/core/entities/provider_configuration.py",
    "created_at": "2025-08-26T06:59:34+00:00",
    "commented_code": "ProviderModel.model_name == model,\n             ProviderModel.model_type == model_type.to_origin_model_type(),\n         )\n+        provider_model_record = db.session.scalar(stmt)\n \n         return session.execute(stmt).scalar_one_or_none()",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2299989050",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/entities/provider_configuration.py",
        "discussion_id": "2299989050",
        "commented_code": "@@ -638,6 +638,7 @@ def _get_custom_model_record(\n             ProviderModel.model_name == model,\n             ProviderModel.model_type == model_type.to_origin_model_type(),\n         )\n+        provider_model_record = db.session.scalar(stmt)\n \n         return session.execute(stmt).scalar_one_or_none()",
        "comment_created_at": "2025-08-26T06:59:34+00:00",
        "comment_author": "laipz8200",
        "comment_body": "Please also update the return statement",
        "pr_file_module": null
      },
      {
        "comment_id": "2300632792",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/entities/provider_configuration.py",
        "discussion_id": "2299989050",
        "commented_code": "@@ -638,6 +638,7 @@ def _get_custom_model_record(\n             ProviderModel.model_name == model,\n             ProviderModel.model_type == model_type.to_origin_model_type(),\n         )\n+        provider_model_record = db.session.scalar(stmt)\n \n         return session.execute(stmt).scalar_one_or_none()",
        "comment_created_at": "2025-08-26T11:07:17+00:00",
        "comment_author": "hyongtao-code",
        "comment_body": "\r\nThis part is tricky to make a code change.\r\nIf the query returns multiple rows, `scalar(stmt)` will silently return the first one,\r\nwhereas `execute(stmt).scalar_one_or_none()` will raise an error.\r\nFor this reason, I kept the current implementation. Please see the example below. \r\n``` python\r\nprint(\"+-----------------------------------------------------+\")\r\nstmt = select(User)\r\nu2 = session.scalar(stmt)\r\nprint(\"1-----------------------------------------------------+\")\r\nprint(u2) # <User(id=1, name='Alice', email='alice@example.com')>\r\nprint(type(u2)) # <class '__main__.User'>\r\n\r\nprint(\"+-----------------------------------------------------+\")\r\nstmt = select(User)\r\nu1 = session.execute(stmt).scalar_one_or_none() # sqlalchemy.exc.MultipleResultsFound: Multiple rows were found when one or none was required\r\nprint(\"2-----------------------------------------------------+\")\r\nprint(u1)\r\nprint(type(u1))\r\n```\r\nResult:\r\n``` bash\r\n1-----------------------------------------------------+\r\n<User(id=1, name='Alice', email='alice@example.com')>\r\n<class '__main__.User'>\r\n+-----------------------------------------------------+\r\nTraceback (most recent call last):\r\n\r\nsqlalchemy.exc.MultipleResultsFound: Multiple rows were found when one or none was required\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2299992016",
    "pr_number": 23224,
    "pr_file": "api/core/ops/aliyun_trace/aliyun_trace.py",
    "created_at": "2025-08-26T07:00:41+00:00",
    "commented_code": "app_id = trace_info.metadata.get(\"app_id\")\n             if not app_id:\n                 raise ValueError(\"No app_id found in trace_info metadata\")\n-\n-            app = session.query(App).where(App.id == app_id).first()\n+            app_stmt = select(App).where(App.id == app_id)\n+            app = db.session.scalar(app_stmt)\n             if not app:\n                 raise ValueError(f\"App with id {app_id} not found\")\n \n             if not app.created_by:\n                 raise ValueError(f\"App with id {app_id} has no creator (created_by is None)\")\n-\n-            service_account = session.query(Account).where(Account.id == app.created_by).first()\n+            account_stmt = select(Account).where(Account.id == app.created_by)\n+            service_account = db.session.scalar(account_stmt)",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2299992016",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/ops/aliyun_trace/aliyun_trace.py",
        "discussion_id": "2299992016",
        "commented_code": "@@ -263,15 +264,15 @@ def get_workflow_node_executions(self, trace_info: WorkflowTraceInfo) -> Sequenc\n             app_id = trace_info.metadata.get(\"app_id\")\n             if not app_id:\n                 raise ValueError(\"No app_id found in trace_info metadata\")\n-\n-            app = session.query(App).where(App.id == app_id).first()\n+            app_stmt = select(App).where(App.id == app_id)\n+            app = db.session.scalar(app_stmt)\n             if not app:\n                 raise ValueError(f\"App with id {app_id} not found\")\n \n             if not app.created_by:\n                 raise ValueError(f\"App with id {app_id} has no creator (created_by is None)\")\n-\n-            service_account = session.query(Account).where(Account.id == app.created_by).first()\n+            account_stmt = select(Account).where(Account.id == app.created_by)\n+            service_account = db.session.scalar(account_stmt)",
        "comment_created_at": "2025-08-26T07:00:41+00:00",
        "comment_author": "laipz8200",
        "comment_body": "Use `session` here",
        "pr_file_module": null
      },
      {
        "comment_id": "2300654590",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/ops/aliyun_trace/aliyun_trace.py",
        "discussion_id": "2299992016",
        "commented_code": "@@ -263,15 +264,15 @@ def get_workflow_node_executions(self, trace_info: WorkflowTraceInfo) -> Sequenc\n             app_id = trace_info.metadata.get(\"app_id\")\n             if not app_id:\n                 raise ValueError(\"No app_id found in trace_info metadata\")\n-\n-            app = session.query(App).where(App.id == app_id).first()\n+            app_stmt = select(App).where(App.id == app_id)\n+            app = db.session.scalar(app_stmt)\n             if not app:\n                 raise ValueError(f\"App with id {app_id} not found\")\n \n             if not app.created_by:\n                 raise ValueError(f\"App with id {app_id} has no creator (created_by is None)\")\n-\n-            service_account = session.query(Account).where(Account.id == app.created_by).first()\n+            account_stmt = select(Account).where(Account.id == app.created_by)\n+            service_account = db.session.scalar(account_stmt)",
        "comment_created_at": "2025-08-26T11:17:03+00:00",
        "comment_author": "hyongtao-code",
        "comment_body": "Done at [94a6965](https://github.com/langgenius/dify/pull/23224/commits/94a6965d6dfe11f3e310b88e6265d97bd705c113)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2299996918",
    "pr_number": 23224,
    "pr_file": "api/core/rag/docstore/dataset_docstore.py",
    "created_at": "2025-08-26T07:03:01+00:00",
    "commented_code": "@property\n     def docs(self) -> dict[str, Document]:\n-        document_segments = (\n-            db.session.query(DocumentSegment).where(DocumentSegment.dataset_id == self._dataset.id).all()\n-        )\n+        stmt = select(DocumentSegment).where(DocumentSegment.dataset_id == self._dataset.id)\n+        document_segments = db.session.scalars(stmt).all()",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2299996918",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/rag/docstore/dataset_docstore.py",
        "discussion_id": "2299996918",
        "commented_code": "@@ -41,9 +41,8 @@ def user_id(self) -> Any:\n \n     @property\n     def docs(self) -> dict[str, Document]:\n-        document_segments = (\n-            db.session.query(DocumentSegment).where(DocumentSegment.dataset_id == self._dataset.id).all()\n-        )\n+        stmt = select(DocumentSegment).where(DocumentSegment.dataset_id == self._dataset.id)\n+        document_segments = db.session.scalars(stmt).all()",
        "comment_created_at": "2025-08-26T07:03:01+00:00",
        "comment_author": "laipz8200",
        "comment_body": "`.all()` is unnecessary",
        "pr_file_module": null
      },
      {
        "comment_id": "2300543687",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/rag/docstore/dataset_docstore.py",
        "discussion_id": "2299996918",
        "commented_code": "@@ -41,9 +41,8 @@ def user_id(self) -> Any:\n \n     @property\n     def docs(self) -> dict[str, Document]:\n-        document_segments = (\n-            db.session.query(DocumentSegment).where(DocumentSegment.dataset_id == self._dataset.id).all()\n-        )\n+        stmt = select(DocumentSegment).where(DocumentSegment.dataset_id == self._dataset.id)\n+        document_segments = db.session.scalars(stmt).all()",
        "comment_created_at": "2025-08-26T10:27:49+00:00",
        "comment_author": "hyongtao-code",
        "comment_body": "`.scalars()` returns a `ScalarResult` object, which is a lazy iterator.\r\n`.scalars().all()` evaluates that iterator immediately and returns a Python `list`.\r\n\r\nHere is an example:\r\n``` python\r\nprint(\"+-----------------------------------------------------+\")\r\nstmt = select(User)\r\nu1 = session.execute(stmt).scalars().all()\r\nprint(\"1-----------------------------------------------------+\")\r\nprint(u1)\r\nprint(type(u1))\r\nprint(\"+-----------------------------------------------------+\")\r\nstmt = select(User)\r\nu2 = session.execute(stmt).scalars()\r\nprint(\"2-----------------------------------------------------+\")\r\nprint(u2)\r\nprint(type(u2))\r\n```\r\n\r\nthe script result is shown as below:\r\n``` bash\r\n1-----------------------------------------------------+\r\n[<User(id=1, name='Alice', email='alice@example.com')>, <User(id=2, name='Bob', email='bob@example.com')>, <User(id=3, name='Charlie', email='charlie@example.com')>]\r\n<class 'list'>\r\n+-----------------------------------------------------+\r\n2-----------------------------------------------------+\r\n<sqlalchemy.engine.result.ScalarResult object at 0x00000182FA05AEE0>\r\n<class 'sqlalchemy.engine.result.ScalarResult'>\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2299999095",
    "pr_number": 23224,
    "pr_file": "api/core/rag/retrieval/dataset_retrieval.py",
    "created_at": "2025-08-26T07:03:57+00:00",
    "commented_code": "self, dataset_ids: list, query: str, tenant_id: str, user_id: str, metadata_model_config: ModelConfig\n     ) -> Optional[list[dict[str, Any]]]:\n         # get all metadata field\n-        metadata_fields = db.session.query(DatasetMetadata).where(DatasetMetadata.dataset_id.in_(dataset_ids)).all()\n+        metadata_stmt = select(DatasetMetadata).where(DatasetMetadata.dataset_id.in_(dataset_ids))\n+        metadata_fields = db.session.scalars(metadata_stmt).all()",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2299999095",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/rag/retrieval/dataset_retrieval.py",
        "discussion_id": "2299999095",
        "commented_code": "@@ -958,7 +955,8 @@ def _automatic_metadata_filter_func(\n         self, dataset_ids: list, query: str, tenant_id: str, user_id: str, metadata_model_config: ModelConfig\n     ) -> Optional[list[dict[str, Any]]]:\n         # get all metadata field\n-        metadata_fields = db.session.query(DatasetMetadata).where(DatasetMetadata.dataset_id.in_(dataset_ids)).all()\n+        metadata_stmt = select(DatasetMetadata).where(DatasetMetadata.dataset_id.in_(dataset_ids))\n+        metadata_fields = db.session.scalars(metadata_stmt).all()",
        "comment_created_at": "2025-08-26T07:03:57+00:00",
        "comment_author": "laipz8200",
        "comment_body": "`.all()` is unnecessary",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2300003310",
    "pr_number": 23224,
    "pr_file": "api/core/tools/tool_label_manager.py",
    "created_at": "2025-08-26T07:05:50+00:00",
    "commented_code": "return controller.tool_labels\n         else:\n             raise ValueError(\"Unsupported tool type\")\n-\n-        labels = (\n-            db.session.query(ToolLabelBinding.label_name)\n-            .where(\n-                ToolLabelBinding.tool_id == provider_id,\n-                ToolLabelBinding.tool_type == controller.provider_type.value,\n-            )\n-            .all()\n+        stmt = select(ToolLabelBinding.label_name).where(\n+            ToolLabelBinding.tool_id == provider_id,\n+            ToolLabelBinding.tool_type == controller.provider_type.value,\n         )\n+        labels = db.session.scalars(stmt).all()",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2300003310",
        "repo_full_name": "langgenius/dify",
        "pr_number": 23224,
        "pr_file": "api/core/tools/tool_label_manager.py",
        "discussion_id": "2300003310",
        "commented_code": "@@ -54,17 +56,13 @@ def get_tool_labels(cls, controller: ToolProviderController) -> list[str]:\n             return controller.tool_labels\n         else:\n             raise ValueError(\"Unsupported tool type\")\n-\n-        labels = (\n-            db.session.query(ToolLabelBinding.label_name)\n-            .where(\n-                ToolLabelBinding.tool_id == provider_id,\n-                ToolLabelBinding.tool_type == controller.provider_type.value,\n-            )\n-            .all()\n+        stmt = select(ToolLabelBinding.label_name).where(\n+            ToolLabelBinding.tool_id == provider_id,\n+            ToolLabelBinding.tool_type == controller.provider_type.value,\n         )\n+        labels = db.session.scalars(stmt).all()",
        "comment_created_at": "2025-08-26T07:05:50+00:00",
        "comment_author": "laipz8200",
        "comment_body": "`.all()` is unnecessary",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2224355508",
    "pr_number": 22801,
    "pr_file": "api/controllers/web/passport.py",
    "created_at": "2025-07-23T05:04:28+00:00",
    "commented_code": "raise WebAppAuthRequiredError()\n \n         # get site from db and check if it is normal\n-        site = db.session.query(Site).filter(Site.code == app_code, Site.status == \"normal\").first()\n+        site = db.session.scalar(select(Site).filter(Site.code == app_code, Site.status == \"normal\"))",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2224355508",
        "repo_full_name": "langgenius/dify",
        "pr_number": 22801,
        "pr_file": "api/controllers/web/passport.py",
        "discussion_id": "2224355508",
        "commented_code": "@@ -42,17 +43,17 @@ def get(self):\n                 raise WebAppAuthRequiredError()\n \n         # get site from db and check if it is normal\n-        site = db.session.query(Site).filter(Site.code == app_code, Site.status == \"normal\").first()\n+        site = db.session.scalar(select(Site).filter(Site.code == app_code, Site.status == \"normal\"))",
        "comment_created_at": "2025-07-23T05:04:28+00:00",
        "comment_author": "laipz8200",
        "comment_body": "```suggestion\n        site = db.session.scalar(select(Site).where(Site.code == app_code, Site.status == \"normal\"))\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2224359388",
    "pr_number": 22801,
    "pr_file": "api/libs/oauth_data_source.py",
    "created_at": "2025-07-23T05:07:50+00:00",
    "commented_code": "def sync_data_source(self, binding_id: str):\n         # save data source binding\n-        data_source_binding = (\n-            db.session.query(DataSourceOauthBinding)\n-            .filter(\n-                db.and_(\n+        data_source_binding = db.session.scalar(\n+            select(DataSourceOauthBinding).filter(",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2224359388",
        "repo_full_name": "langgenius/dify",
        "pr_number": 22801,
        "pr_file": "api/libs/oauth_data_source.py",
        "discussion_id": "2224359388",
        "commented_code": "@@ -129,17 +126,15 @@ def save_internal_access_token(self, access_token: str):\n \n     def sync_data_source(self, binding_id: str):\n         # save data source binding\n-        data_source_binding = (\n-            db.session.query(DataSourceOauthBinding)\n-            .filter(\n-                db.and_(\n+        data_source_binding = db.session.scalar(\n+            select(DataSourceOauthBinding).filter(",
        "comment_created_at": "2025-07-23T05:07:50+00:00",
        "comment_author": "laipz8200",
        "comment_body": "```suggestion\n            select(DataSourceOauthBinding).where(\n                DataSourceOauthBinding.tenant_id == current_user.current_tenant_id,\n                DataSourceOauthBinding.provider == \"notion\",\n                DataSourceOauthBinding.id == binding_id,\n                DataSourceOauthBinding.disabled == False,\n            )\n```",
        "pr_file_module": null
      }
    ]
  }
]