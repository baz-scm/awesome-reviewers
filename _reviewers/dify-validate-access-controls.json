[
  {
    "discussion_id": "2200242164",
    "pr_number": 22213,
    "pr_file": "api/controllers/console/workspace/account.py",
    "created_at": "2025-07-11T09:43:20+00:00",
    "commented_code": "return BillingService.EducationIdentity.autocomplete(args[\"keywords\"], args[\"page\"], args[\"limit\"])\n \n \n+class ChangeEmailSendEmailApi(Resource):\n+    @enable_change_email\n+    @setup_required\n+    @login_required\n+    @account_initialization_required\n+    def post(self):\n+        parser = reqparse.RequestParser()\n+        parser.add_argument(\"email\", type=email, required=True, location=\"json\")\n+        parser.add_argument(\"language\", type=str, required=False, location=\"json\")\n+        parser.add_argument(\"phase\", type=str, required=False, location=\"json\")\n+        parser.add_argument(\"token\", type=str, required=False, location=\"json\")\n+        args = parser.parse_args()\n+\n+        ip_address = extract_remote_ip(request)\n+        if AccountService.is_email_send_ip_limit(ip_address):\n+            raise EmailSendIpLimitError()\n+\n+        if args[\"language\"] is not None and args[\"language\"] == \"zh-Hans\":\n+            language = \"zh-Hans\"\n+        else:\n+            language = \"en-US\"\n+        account = None\n+        user_email = args[\"email\"]\n+        if args[\"phase\"] is not None and args[\"phase\"] == \"new_email\":\n+            if args[\"token\"] is None:\n+                raise InvalidTokenError()\n+\n+            reset_data = AccountService.get_change_email_data(args[\"token\"])\n+            if reset_data is None:\n+                raise InvalidTokenError()\n+            user_email = reset_data.get(\"email\", \"\")\n+\n+            if user_email == current_user.email:\n+                raise InvalidEmailError()\n+        else:\n+            with Session(db.engine) as session:\n+                account = session.execute(select(Account).filter_by(email=args[\"email\"])).scalar_one_or_none()\n+            if account is None:\n+                raise AccountNotFound()\n+\n+        token = AccountService.send_change_email_email(\n+            account=account, email=args[\"email\"], old_email=user_email, language=language, phase=args[\"phase\"]\n+        )\n+        return {\"result\": \"success\", \"data\": token}\n+\n+\n+class ChangeEmailCheckApi(Resource):\n+    @enable_change_email\n+    @setup_required\n+    @login_required\n+    @account_initialization_required\n+    def post(self):\n+        parser = reqparse.RequestParser()\n+        parser.add_argument(\"email\", type=email, required=True, location=\"json\")\n+        parser.add_argument(\"code\", type=str, required=True, location=\"json\")\n+        parser.add_argument(\"token\", type=str, required=True, nullable=False, location=\"json\")\n+        args = parser.parse_args()\n+\n+        user_email = args[\"email\"]\n+\n+        is_change_email_error_rate_limit = AccountService.is_change_email_error_rate_limit(args[\"email\"])\n+        if is_change_email_error_rate_limit:\n+            raise EmailChangeLimitError()\n+\n+        token_data = AccountService.get_change_email_data(args[\"token\"])\n+        if token_data is None:\n+            raise InvalidTokenError()\n+\n+        if user_email != token_data.get(\"email\"):\n+            raise InvalidEmailError()\n+\n+        if args[\"code\"] != token_data.get(\"code\"):\n+            AccountService.add_change_email_error_rate_limit(args[\"email\"])\n+            raise EmailCodeError()\n+\n+        # Verified, revoke the first token\n+        AccountService.revoke_change_email_token(args[\"token\"])\n+\n+        # Refresh token data by generating a new token\n+        _, new_token = AccountService.generate_change_email_token(\n+            user_email, code=args[\"code\"], old_email=token_data.get(\"old_email\"), additional_data={}\n+        )\n+\n+        AccountService.reset_change_email_error_rate_limit(args[\"email\"])\n+        return {\"is_valid\": True, \"email\": token_data.get(\"email\"), \"token\": new_token}\n+\n+\n+class ChangeEmailResetApi(Resource):\n+    @enable_change_email\n+    @setup_required\n+    @login_required\n+    @account_initialization_required\n+    @marshal_with(account_fields)\n+    def post(self):\n+        parser = reqparse.RequestParser()\n+        parser.add_argument(\"new_email\", type=email, required=True, location=\"json\")\n+        parser.add_argument(\"token\", type=str, required=True, nullable=False, location=\"json\")\n+        args = parser.parse_args()\n+\n+        reset_data = AccountService.get_change_email_data(args[\"token\"])\n+        if not reset_data:\n+            raise InvalidTokenError()\n+        # Must use token in reset phase\n+        if reset_data.get(\"phase\", \"\") != \"change_email\":\n+            raise InvalidTokenError()\n+\n+        AccountService.revoke_change_email_token(args[\"token\"])\n+\n+        old_email = reset_data.get(\"old_email\", \"\")\n+        if current_user.email != old_email:\n+            raise AccountNotFound()\n+\n+        updated_account = AccountService.update_account(current_user, email=args[\"new_email\"])",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2200242164",
        "repo_full_name": "langgenius/dify",
        "pr_number": 22213,
        "pr_file": "api/controllers/console/workspace/account.py",
        "discussion_id": "2200242164",
        "commented_code": "@@ -369,6 +381,137 @@ def get(self):\n         return BillingService.EducationIdentity.autocomplete(args[\"keywords\"], args[\"page\"], args[\"limit\"])\n \n \n+class ChangeEmailSendEmailApi(Resource):\n+    @enable_change_email\n+    @setup_required\n+    @login_required\n+    @account_initialization_required\n+    def post(self):\n+        parser = reqparse.RequestParser()\n+        parser.add_argument(\"email\", type=email, required=True, location=\"json\")\n+        parser.add_argument(\"language\", type=str, required=False, location=\"json\")\n+        parser.add_argument(\"phase\", type=str, required=False, location=\"json\")\n+        parser.add_argument(\"token\", type=str, required=False, location=\"json\")\n+        args = parser.parse_args()\n+\n+        ip_address = extract_remote_ip(request)\n+        if AccountService.is_email_send_ip_limit(ip_address):\n+            raise EmailSendIpLimitError()\n+\n+        if args[\"language\"] is not None and args[\"language\"] == \"zh-Hans\":\n+            language = \"zh-Hans\"\n+        else:\n+            language = \"en-US\"\n+        account = None\n+        user_email = args[\"email\"]\n+        if args[\"phase\"] is not None and args[\"phase\"] == \"new_email\":\n+            if args[\"token\"] is None:\n+                raise InvalidTokenError()\n+\n+            reset_data = AccountService.get_change_email_data(args[\"token\"])\n+            if reset_data is None:\n+                raise InvalidTokenError()\n+            user_email = reset_data.get(\"email\", \"\")\n+\n+            if user_email == current_user.email:\n+                raise InvalidEmailError()\n+        else:\n+            with Session(db.engine) as session:\n+                account = session.execute(select(Account).filter_by(email=args[\"email\"])).scalar_one_or_none()\n+            if account is None:\n+                raise AccountNotFound()\n+\n+        token = AccountService.send_change_email_email(\n+            account=account, email=args[\"email\"], old_email=user_email, language=language, phase=args[\"phase\"]\n+        )\n+        return {\"result\": \"success\", \"data\": token}\n+\n+\n+class ChangeEmailCheckApi(Resource):\n+    @enable_change_email\n+    @setup_required\n+    @login_required\n+    @account_initialization_required\n+    def post(self):\n+        parser = reqparse.RequestParser()\n+        parser.add_argument(\"email\", type=email, required=True, location=\"json\")\n+        parser.add_argument(\"code\", type=str, required=True, location=\"json\")\n+        parser.add_argument(\"token\", type=str, required=True, nullable=False, location=\"json\")\n+        args = parser.parse_args()\n+\n+        user_email = args[\"email\"]\n+\n+        is_change_email_error_rate_limit = AccountService.is_change_email_error_rate_limit(args[\"email\"])\n+        if is_change_email_error_rate_limit:\n+            raise EmailChangeLimitError()\n+\n+        token_data = AccountService.get_change_email_data(args[\"token\"])\n+        if token_data is None:\n+            raise InvalidTokenError()\n+\n+        if user_email != token_data.get(\"email\"):\n+            raise InvalidEmailError()\n+\n+        if args[\"code\"] != token_data.get(\"code\"):\n+            AccountService.add_change_email_error_rate_limit(args[\"email\"])\n+            raise EmailCodeError()\n+\n+        # Verified, revoke the first token\n+        AccountService.revoke_change_email_token(args[\"token\"])\n+\n+        # Refresh token data by generating a new token\n+        _, new_token = AccountService.generate_change_email_token(\n+            user_email, code=args[\"code\"], old_email=token_data.get(\"old_email\"), additional_data={}\n+        )\n+\n+        AccountService.reset_change_email_error_rate_limit(args[\"email\"])\n+        return {\"is_valid\": True, \"email\": token_data.get(\"email\"), \"token\": new_token}\n+\n+\n+class ChangeEmailResetApi(Resource):\n+    @enable_change_email\n+    @setup_required\n+    @login_required\n+    @account_initialization_required\n+    @marshal_with(account_fields)\n+    def post(self):\n+        parser = reqparse.RequestParser()\n+        parser.add_argument(\"new_email\", type=email, required=True, location=\"json\")\n+        parser.add_argument(\"token\", type=str, required=True, nullable=False, location=\"json\")\n+        args = parser.parse_args()\n+\n+        reset_data = AccountService.get_change_email_data(args[\"token\"])\n+        if not reset_data:\n+            raise InvalidTokenError()\n+        # Must use token in reset phase\n+        if reset_data.get(\"phase\", \"\") != \"change_email\":\n+            raise InvalidTokenError()\n+\n+        AccountService.revoke_change_email_token(args[\"token\"])\n+\n+        old_email = reset_data.get(\"old_email\", \"\")\n+        if current_user.email != old_email:\n+            raise AccountNotFound()\n+\n+        updated_account = AccountService.update_account(current_user, email=args[\"new_email\"])",
        "comment_created_at": "2025-07-11T09:43:20+00:00",
        "comment_author": "GareArc",
        "comment_body": "Please add validation to verify email uniqueness here. It's possible for users to bypass this restriction through direct API calls.",
        "pr_file_module": null
      },
      {
        "comment_id": "2203685935",
        "repo_full_name": "langgenius/dify",
        "pr_number": 22213,
        "pr_file": "api/controllers/console/workspace/account.py",
        "discussion_id": "2200242164",
        "commented_code": "@@ -369,6 +381,137 @@ def get(self):\n         return BillingService.EducationIdentity.autocomplete(args[\"keywords\"], args[\"page\"], args[\"limit\"])\n \n \n+class ChangeEmailSendEmailApi(Resource):\n+    @enable_change_email\n+    @setup_required\n+    @login_required\n+    @account_initialization_required\n+    def post(self):\n+        parser = reqparse.RequestParser()\n+        parser.add_argument(\"email\", type=email, required=True, location=\"json\")\n+        parser.add_argument(\"language\", type=str, required=False, location=\"json\")\n+        parser.add_argument(\"phase\", type=str, required=False, location=\"json\")\n+        parser.add_argument(\"token\", type=str, required=False, location=\"json\")\n+        args = parser.parse_args()\n+\n+        ip_address = extract_remote_ip(request)\n+        if AccountService.is_email_send_ip_limit(ip_address):\n+            raise EmailSendIpLimitError()\n+\n+        if args[\"language\"] is not None and args[\"language\"] == \"zh-Hans\":\n+            language = \"zh-Hans\"\n+        else:\n+            language = \"en-US\"\n+        account = None\n+        user_email = args[\"email\"]\n+        if args[\"phase\"] is not None and args[\"phase\"] == \"new_email\":\n+            if args[\"token\"] is None:\n+                raise InvalidTokenError()\n+\n+            reset_data = AccountService.get_change_email_data(args[\"token\"])\n+            if reset_data is None:\n+                raise InvalidTokenError()\n+            user_email = reset_data.get(\"email\", \"\")\n+\n+            if user_email == current_user.email:\n+                raise InvalidEmailError()\n+        else:\n+            with Session(db.engine) as session:\n+                account = session.execute(select(Account).filter_by(email=args[\"email\"])).scalar_one_or_none()\n+            if account is None:\n+                raise AccountNotFound()\n+\n+        token = AccountService.send_change_email_email(\n+            account=account, email=args[\"email\"], old_email=user_email, language=language, phase=args[\"phase\"]\n+        )\n+        return {\"result\": \"success\", \"data\": token}\n+\n+\n+class ChangeEmailCheckApi(Resource):\n+    @enable_change_email\n+    @setup_required\n+    @login_required\n+    @account_initialization_required\n+    def post(self):\n+        parser = reqparse.RequestParser()\n+        parser.add_argument(\"email\", type=email, required=True, location=\"json\")\n+        parser.add_argument(\"code\", type=str, required=True, location=\"json\")\n+        parser.add_argument(\"token\", type=str, required=True, nullable=False, location=\"json\")\n+        args = parser.parse_args()\n+\n+        user_email = args[\"email\"]\n+\n+        is_change_email_error_rate_limit = AccountService.is_change_email_error_rate_limit(args[\"email\"])\n+        if is_change_email_error_rate_limit:\n+            raise EmailChangeLimitError()\n+\n+        token_data = AccountService.get_change_email_data(args[\"token\"])\n+        if token_data is None:\n+            raise InvalidTokenError()\n+\n+        if user_email != token_data.get(\"email\"):\n+            raise InvalidEmailError()\n+\n+        if args[\"code\"] != token_data.get(\"code\"):\n+            AccountService.add_change_email_error_rate_limit(args[\"email\"])\n+            raise EmailCodeError()\n+\n+        # Verified, revoke the first token\n+        AccountService.revoke_change_email_token(args[\"token\"])\n+\n+        # Refresh token data by generating a new token\n+        _, new_token = AccountService.generate_change_email_token(\n+            user_email, code=args[\"code\"], old_email=token_data.get(\"old_email\"), additional_data={}\n+        )\n+\n+        AccountService.reset_change_email_error_rate_limit(args[\"email\"])\n+        return {\"is_valid\": True, \"email\": token_data.get(\"email\"), \"token\": new_token}\n+\n+\n+class ChangeEmailResetApi(Resource):\n+    @enable_change_email\n+    @setup_required\n+    @login_required\n+    @account_initialization_required\n+    @marshal_with(account_fields)\n+    def post(self):\n+        parser = reqparse.RequestParser()\n+        parser.add_argument(\"new_email\", type=email, required=True, location=\"json\")\n+        parser.add_argument(\"token\", type=str, required=True, nullable=False, location=\"json\")\n+        args = parser.parse_args()\n+\n+        reset_data = AccountService.get_change_email_data(args[\"token\"])\n+        if not reset_data:\n+            raise InvalidTokenError()\n+        # Must use token in reset phase\n+        if reset_data.get(\"phase\", \"\") != \"change_email\":\n+            raise InvalidTokenError()\n+\n+        AccountService.revoke_change_email_token(args[\"token\"])\n+\n+        old_email = reset_data.get(\"old_email\", \"\")\n+        if current_user.email != old_email:\n+            raise AccountNotFound()\n+\n+        updated_account = AccountService.update_account(current_user, email=args[\"new_email\"])",
        "comment_created_at": "2025-07-14T01:39:55+00:00",
        "comment_author": "zyssyz123",
        "comment_body": "ooops, I forgot this part, thanks for reminding me",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2194602462",
    "pr_number": 21458,
    "pr_file": "api/repositories/api_workflow_node_execution_repository.py",
    "created_at": "2025-07-09T10:00:46+00:00",
    "commented_code": "+\"\"\"\n+Service-layer repository protocol for WorkflowNodeExecutionModel operations.\n+\n+This module provides a protocol interface for service-layer operations on WorkflowNodeExecutionModel\n+that abstracts database queries currently done directly in service classes. This repository is\n+specifically designed for service-layer needs and is separate from the core domain repository.\n+\n+The service repository handles operations that require access to database-specific fields like\n+tenant_id, app_id, triggered_from, etc., which are not part of the core domain model.\n+\"\"\"\n+\n+from abc import abstractmethod\n+from collections.abc import Sequence\n+from datetime import datetime\n+from typing import Optional, Protocol\n+\n+from models.workflow import WorkflowNodeExecutionModel\n+\n+\n+class DifyAPIWorkflowNodeExecutionRepository(Protocol):\n+    \"\"\"\n+    Protocol for service-layer operations on WorkflowNodeExecutionModel.\n+\n+    This repository provides database access patterns specifically needed by service classes,\n+    handling queries that involve database-specific fields and multi-tenancy concerns.\n+\n+    Key responsibilities:\n+    - Manages database operations for workflow node executions\n+    - Handles multi-tenant data isolation\n+    - Provides batch processing capabilities\n+    - Supports execution lifecycle management\n+\n+    Implementation notes:\n+    - Returns database models directly (WorkflowNodeExecutionModel)\n+    - Handles tenant/app filtering automatically\n+    - Provides service-specific query patterns\n+    - Focuses on database operations without domain logic\n+    - Supports cleanup and maintenance operations\n+    \"\"\"\n+\n+    @abstractmethod\n+    def get_node_last_execution(\n+        self,\n+        tenant_id: str,\n+        app_id: str,\n+        workflow_id: str,\n+        node_id: str,\n+    ) -> Optional[WorkflowNodeExecutionModel]:\n+        \"\"\"\n+        Get the most recent execution for a specific node.\n+\n+        This method finds the latest execution of a specific node within a workflow,\n+        ordered by creation time. Used primarily for debugging and inspection purposes.\n+\n+        Args:\n+            tenant_id: The tenant identifier\n+            app_id: The application identifier\n+            workflow_id: The workflow identifier\n+            node_id: The node identifier\n+\n+        Returns:\n+            The most recent WorkflowNodeExecutionModel for the node, or None if not found\n+        \"\"\"\n+        ...\n+\n+    @abstractmethod\n+    def get_executions_by_workflow_run(\n+        self,\n+        tenant_id: str,\n+        app_id: str,\n+        workflow_run_id: str,\n+    ) -> Sequence[WorkflowNodeExecutionModel]:\n+        \"\"\"\n+        Get all node executions for a specific workflow run.\n+\n+        This method retrieves all node executions that belong to a specific workflow run,\n+        ordered by index in descending order for proper trace visualization.\n+\n+        Args:\n+            tenant_id: The tenant identifier\n+            app_id: The application identifier\n+            workflow_run_id: The workflow run identifier\n+\n+        Returns:\n+            A sequence of WorkflowNodeExecutionModel instances ordered by index (desc)\n+        \"\"\"\n+        ...\n+\n+    @abstractmethod\n+    def get_execution_by_id(\n+        self,\n+        execution_id: str,\n+        tenant_id: Optional[str] = None,\n+    ) -> Optional[WorkflowNodeExecutionModel]:\n+        \"\"\"\n+        Get a workflow node execution by its ID.\n+\n+        This method retrieves a specific execution by its unique identifier.\n+        Tenant filtering is optional for cases where the execution ID is globally unique.",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2194602462",
        "repo_full_name": "langgenius/dify",
        "pr_number": 21458,
        "pr_file": "api/repositories/api_workflow_node_execution_repository.py",
        "discussion_id": "2194602462",
        "commented_code": "@@ -0,0 +1,196 @@\n+\"\"\"\n+Service-layer repository protocol for WorkflowNodeExecutionModel operations.\n+\n+This module provides a protocol interface for service-layer operations on WorkflowNodeExecutionModel\n+that abstracts database queries currently done directly in service classes. This repository is\n+specifically designed for service-layer needs and is separate from the core domain repository.\n+\n+The service repository handles operations that require access to database-specific fields like\n+tenant_id, app_id, triggered_from, etc., which are not part of the core domain model.\n+\"\"\"\n+\n+from abc import abstractmethod\n+from collections.abc import Sequence\n+from datetime import datetime\n+from typing import Optional, Protocol\n+\n+from models.workflow import WorkflowNodeExecutionModel\n+\n+\n+class DifyAPIWorkflowNodeExecutionRepository(Protocol):\n+    \"\"\"\n+    Protocol for service-layer operations on WorkflowNodeExecutionModel.\n+\n+    This repository provides database access patterns specifically needed by service classes,\n+    handling queries that involve database-specific fields and multi-tenancy concerns.\n+\n+    Key responsibilities:\n+    - Manages database operations for workflow node executions\n+    - Handles multi-tenant data isolation\n+    - Provides batch processing capabilities\n+    - Supports execution lifecycle management\n+\n+    Implementation notes:\n+    - Returns database models directly (WorkflowNodeExecutionModel)\n+    - Handles tenant/app filtering automatically\n+    - Provides service-specific query patterns\n+    - Focuses on database operations without domain logic\n+    - Supports cleanup and maintenance operations\n+    \"\"\"\n+\n+    @abstractmethod\n+    def get_node_last_execution(\n+        self,\n+        tenant_id: str,\n+        app_id: str,\n+        workflow_id: str,\n+        node_id: str,\n+    ) -> Optional[WorkflowNodeExecutionModel]:\n+        \"\"\"\n+        Get the most recent execution for a specific node.\n+\n+        This method finds the latest execution of a specific node within a workflow,\n+        ordered by creation time. Used primarily for debugging and inspection purposes.\n+\n+        Args:\n+            tenant_id: The tenant identifier\n+            app_id: The application identifier\n+            workflow_id: The workflow identifier\n+            node_id: The node identifier\n+\n+        Returns:\n+            The most recent WorkflowNodeExecutionModel for the node, or None if not found\n+        \"\"\"\n+        ...\n+\n+    @abstractmethod\n+    def get_executions_by_workflow_run(\n+        self,\n+        tenant_id: str,\n+        app_id: str,\n+        workflow_run_id: str,\n+    ) -> Sequence[WorkflowNodeExecutionModel]:\n+        \"\"\"\n+        Get all node executions for a specific workflow run.\n+\n+        This method retrieves all node executions that belong to a specific workflow run,\n+        ordered by index in descending order for proper trace visualization.\n+\n+        Args:\n+            tenant_id: The tenant identifier\n+            app_id: The application identifier\n+            workflow_run_id: The workflow run identifier\n+\n+        Returns:\n+            A sequence of WorkflowNodeExecutionModel instances ordered by index (desc)\n+        \"\"\"\n+        ...\n+\n+    @abstractmethod\n+    def get_execution_by_id(\n+        self,\n+        execution_id: str,\n+        tenant_id: Optional[str] = None,\n+    ) -> Optional[WorkflowNodeExecutionModel]:\n+        \"\"\"\n+        Get a workflow node execution by its ID.\n+\n+        This method retrieves a specific execution by its unique identifier.\n+        Tenant filtering is optional for cases where the execution ID is globally unique.",
        "comment_created_at": "2025-07-09T10:00:46+00:00",
        "comment_author": "QuantumGhost",
        "comment_body": "I recommend adding the following comment about the optional `tenant_id`:\n\n```python\n# When `tenant_id` is None, it's the caller's responsibility to ensure proper data isolation between tenants.\n# If the `execution_id` comes from untrusted sources (e.g., retrieved from an API request), the caller should \n# set `tenant_id` to prevent horizontal privilege escalation.\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2108037891",
    "pr_number": 20242,
    "pr_file": "api/services/dataset_service.py",
    "created_at": "2025-05-27T05:34:35+00:00",
    "commented_code": "if dataset.permission == DatasetPermissionEnum.ONLY_ME and dataset.created_by != user.id:\n                 logging.debug(f\"User {user.id} does not have permission to access dataset {dataset.id}\")\n                 raise NoPermissionError(\"You do not have permission to access this dataset.\")\n-            if dataset.permission == \"partial_members\":\n-                user_permission = (\n-                    db.session.query(DatasetPermission).filter_by(dataset_id=dataset.id, account_id=user.id).first()\n-                )\n-                if (\n-                    not user_permission\n-                    and dataset.tenant_id != user.current_tenant_id\n-                    and dataset.created_by != user.id\n-                ):\n-                    logging.debug(f\"User {user.id} does not have permission to access dataset {dataset.id}\")\n-                    raise NoPermissionError(\"You do not have permission to access this dataset.\")\n+            if dataset.permission == DatasetPermissionEnum.PARTIAL_TEAM:",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2108212004",
        "repo_full_name": "langgenius/dify",
        "pr_number": 20242,
        "pr_file": "api/services/dataset_service.py",
        "discussion_id": "2108037891",
        "commented_code": "@@ -477,17 +477,15 @@ def check_dataset_permission(dataset, user):\n             if dataset.permission == DatasetPermissionEnum.ONLY_ME and dataset.created_by != user.id:\n                 logging.debug(f\"User {user.id} does not have permission to access dataset {dataset.id}\")\n                 raise NoPermissionError(\"You do not have permission to access this dataset.\")\n-            if dataset.permission == \"partial_members\":\n-                user_permission = (\n-                    db.session.query(DatasetPermission).filter_by(dataset_id=dataset.id, account_id=user.id).first()\n-                )\n-                if (\n-                    not user_permission\n-                    and dataset.tenant_id != user.current_tenant_id\n-                    and dataset.created_by != user.id\n-                ):\n-                    logging.debug(f\"User {user.id} does not have permission to access dataset {dataset.id}\")\n-                    raise NoPermissionError(\"You do not have permission to access this dataset.\")\n+            if dataset.permission == DatasetPermissionEnum.PARTIAL_TEAM:",
        "comment_created_at": "2025-05-27T05:34:35+00:00",
        "comment_author": "mio-inamijima",
        "comment_body": "The tenant ID validation is actually performed earlier in the method at line 473-475, where we check if dataset.tenant_id != user.current_tenant_id before any permission-specific logic. This ensures that users can only access datasets within their own tenant, regardless of the permission type.\r\n\r\nThe removal of the redundant tenant ID check from the PARTIAL_TEAM section was intentional because:\r\n\r\n1. Early validation: The tenant check at the method start (line 473) already ensures cross-tenant access is blocked\r\n2. Cleaner logic: The PARTIAL_TEAM permission logic now focuses solely on checking if the user is the creator or has explicit permission via the DatasetPermission table  \r\n3. Consistency: This aligns the PARTIAL_TEAM logic with how other permission types work - they rely on the early tenant validation rather than duplicating the check\r\n\r\nThe security boundary is maintained while simplifying the permission logic.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2050323652",
    "pr_number": 18363,
    "pr_file": "api/controllers/console/wraps.py",
    "created_at": "2025-04-18T08:18:15+00:00",
    "commented_code": "return view(*args, **kwargs)\n \n     return decorated\n+\n+\n+def email_password_login_enabled(view):\n+    @wraps(view)\n+    def decorated(*args, **kwargs):\n+        features = FeatureService.get_system_features()\n+        if features.enable_email_password_login:\n+            return view(*args, **kwargs)\n+\n+        # otherwise, return 404\n+        abort(404)",
    "repo_full_name": "langgenius/dify",
    "discussion_comments": [
      {
        "comment_id": "2050323652",
        "repo_full_name": "langgenius/dify",
        "pr_number": 18363,
        "pr_file": "api/controllers/console/wraps.py",
        "discussion_id": "2050323652",
        "commented_code": "@@ -210,3 +210,16 @@ def decorated(*args, **kwargs):\n         return view(*args, **kwargs)\n \n     return decorated\n+\n+\n+def email_password_login_enabled(view):\n+    @wraps(view)\n+    def decorated(*args, **kwargs):\n+        features = FeatureService.get_system_features()\n+        if features.enable_email_password_login:\n+            return view(*args, **kwargs)\n+\n+        # otherwise, return 404\n+        abort(404)",
        "comment_created_at": "2025-04-18T08:18:15+00:00",
        "comment_author": "laipz8200",
        "comment_body": "```suggestion\r\n        abort(403)\r\n```",
        "pr_file_module": null
      }
    ]
  }
]