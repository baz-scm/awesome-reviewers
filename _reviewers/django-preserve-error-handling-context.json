[
  {
    "discussion_id": "1829277919",
    "pr_number": 18627,
    "pr_file": "django/tasks/utils.py",
    "created_at": "2024-11-05T12:35:02+00:00",
    "commented_code": "+import inspect\n+import json\n+import time\n+from functools import wraps\n+from traceback import format_exception\n+\n+from django.utils.module_loading import import_string\n+\n+\n+def is_module_level_function(func):\n+    if not inspect.isfunction(func) or inspect.isbuiltin(func):\n+        return False\n+\n+    if \"<locals>\" in func.__qualname__:\n+        return False\n+\n+    return True\n+\n+\n+def json_normalize(obj):\n+    \"\"\"\n+    Round-trip encode object as JSON to normalize types.\n+    \"\"\"\n+    return json.loads(json.dumps(obj))\n+\n+\n+def retry(*, retries=3, backoff_delay=0.1):\n+    \"\"\"\n+    Retry the given code `retries` times, raising the final error.\n+\n+    `backoff_delay` can be used to add a delay between attempts.\n+    \"\"\"\n+\n+    def wrapper(f):\n+        @wraps(f)\n+        def inner_wrapper(*args, **kwargs):\n+            for attempt in range(1, retries + 1):\n+                try:\n+                    return f(*args, **kwargs)\n+                except KeyboardInterrupt:\n+                    # Let the user ctrl-C out of the program without a retry\n+                    raise\n+                except BaseException:\n+                    if attempt == retries:\n+                        raise\n+                    time.sleep(backoff_delay)\n+\n+        return inner_wrapper\n+\n+    return wrapper\n+\n+\n+def get_module_path(val):\n+    return f\"{val.__module__}.{val.__qualname__}\"\n+\n+\n+def exception_to_dict(exc):\n+    return {\n+        \"exc_type\": get_module_path(type(exc)),\n+        \"exc_args\": json_normalize(exc.args),",
    "repo_full_name": "django/django",
    "discussion_comments": [
      {
        "comment_id": "1829277919",
        "repo_full_name": "django/django",
        "pr_number": 18627,
        "pr_file": "django/tasks/utils.py",
        "discussion_id": "1829277919",
        "commented_code": "@@ -0,0 +1,71 @@\n+import inspect\n+import json\n+import time\n+from functools import wraps\n+from traceback import format_exception\n+\n+from django.utils.module_loading import import_string\n+\n+\n+def is_module_level_function(func):\n+    if not inspect.isfunction(func) or inspect.isbuiltin(func):\n+        return False\n+\n+    if \"<locals>\" in func.__qualname__:\n+        return False\n+\n+    return True\n+\n+\n+def json_normalize(obj):\n+    \"\"\"\n+    Round-trip encode object as JSON to normalize types.\n+    \"\"\"\n+    return json.loads(json.dumps(obj))\n+\n+\n+def retry(*, retries=3, backoff_delay=0.1):\n+    \"\"\"\n+    Retry the given code `retries` times, raising the final error.\n+\n+    `backoff_delay` can be used to add a delay between attempts.\n+    \"\"\"\n+\n+    def wrapper(f):\n+        @wraps(f)\n+        def inner_wrapper(*args, **kwargs):\n+            for attempt in range(1, retries + 1):\n+                try:\n+                    return f(*args, **kwargs)\n+                except KeyboardInterrupt:\n+                    # Let the user ctrl-C out of the program without a retry\n+                    raise\n+                except BaseException:\n+                    if attempt == retries:\n+                        raise\n+                    time.sleep(backoff_delay)\n+\n+        return inner_wrapper\n+\n+    return wrapper\n+\n+\n+def get_module_path(val):\n+    return f\"{val.__module__}.{val.__qualname__}\"\n+\n+\n+def exception_to_dict(exc):\n+    return {\n+        \"exc_type\": get_module_path(type(exc)),\n+        \"exc_args\": json_normalize(exc.args),",
        "comment_created_at": "2024-11-05T12:35:02+00:00",
        "comment_author": "rtpg",
        "comment_body": "Having exception serialization fail due to an arg not being json serializable feels like losing a lot of debugging info for the sake of deserializing on the other end.",
        "pr_file_module": null
      },
      {
        "comment_id": "1850643158",
        "repo_full_name": "django/django",
        "pr_number": 18627,
        "pr_file": "django/tasks/utils.py",
        "discussion_id": "1829277919",
        "commented_code": "@@ -0,0 +1,71 @@\n+import inspect\n+import json\n+import time\n+from functools import wraps\n+from traceback import format_exception\n+\n+from django.utils.module_loading import import_string\n+\n+\n+def is_module_level_function(func):\n+    if not inspect.isfunction(func) or inspect.isbuiltin(func):\n+        return False\n+\n+    if \"<locals>\" in func.__qualname__:\n+        return False\n+\n+    return True\n+\n+\n+def json_normalize(obj):\n+    \"\"\"\n+    Round-trip encode object as JSON to normalize types.\n+    \"\"\"\n+    return json.loads(json.dumps(obj))\n+\n+\n+def retry(*, retries=3, backoff_delay=0.1):\n+    \"\"\"\n+    Retry the given code `retries` times, raising the final error.\n+\n+    `backoff_delay` can be used to add a delay between attempts.\n+    \"\"\"\n+\n+    def wrapper(f):\n+        @wraps(f)\n+        def inner_wrapper(*args, **kwargs):\n+            for attempt in range(1, retries + 1):\n+                try:\n+                    return f(*args, **kwargs)\n+                except KeyboardInterrupt:\n+                    # Let the user ctrl-C out of the program without a retry\n+                    raise\n+                except BaseException:\n+                    if attempt == retries:\n+                        raise\n+                    time.sleep(backoff_delay)\n+\n+        return inner_wrapper\n+\n+    return wrapper\n+\n+\n+def get_module_path(val):\n+    return f\"{val.__module__}.{val.__qualname__}\"\n+\n+\n+def exception_to_dict(exc):\n+    return {\n+        \"exc_type\": get_module_path(type(exc)),\n+        \"exc_args\": json_normalize(exc.args),",
        "comment_created_at": "2024-11-20T16:35:54+00:00",
        "comment_author": "RealOrangeOne",
        "comment_body": "Is there an alternative? Avoiding serialization entirely has the same issues.",
        "pr_file_module": null
      },
      {
        "comment_id": "1850958473",
        "repo_full_name": "django/django",
        "pr_number": 18627,
        "pr_file": "django/tasks/utils.py",
        "discussion_id": "1829277919",
        "commented_code": "@@ -0,0 +1,71 @@\n+import inspect\n+import json\n+import time\n+from functools import wraps\n+from traceback import format_exception\n+\n+from django.utils.module_loading import import_string\n+\n+\n+def is_module_level_function(func):\n+    if not inspect.isfunction(func) or inspect.isbuiltin(func):\n+        return False\n+\n+    if \"<locals>\" in func.__qualname__:\n+        return False\n+\n+    return True\n+\n+\n+def json_normalize(obj):\n+    \"\"\"\n+    Round-trip encode object as JSON to normalize types.\n+    \"\"\"\n+    return json.loads(json.dumps(obj))\n+\n+\n+def retry(*, retries=3, backoff_delay=0.1):\n+    \"\"\"\n+    Retry the given code `retries` times, raising the final error.\n+\n+    `backoff_delay` can be used to add a delay between attempts.\n+    \"\"\"\n+\n+    def wrapper(f):\n+        @wraps(f)\n+        def inner_wrapper(*args, **kwargs):\n+            for attempt in range(1, retries + 1):\n+                try:\n+                    return f(*args, **kwargs)\n+                except KeyboardInterrupt:\n+                    # Let the user ctrl-C out of the program without a retry\n+                    raise\n+                except BaseException:\n+                    if attempt == retries:\n+                        raise\n+                    time.sleep(backoff_delay)\n+\n+        return inner_wrapper\n+\n+    return wrapper\n+\n+\n+def get_module_path(val):\n+    return f\"{val.__module__}.{val.__qualname__}\"\n+\n+\n+def exception_to_dict(exc):\n+    return {\n+        \"exc_type\": get_module_path(type(exc)),\n+        \"exc_args\": json_normalize(exc.args),",
        "comment_created_at": "2024-11-20T20:44:33+00:00",
        "comment_author": "rtpg",
        "comment_body": "Stringification works more or less universally.\n\nYou cannot roundtrip that, but I believe the roundtripping of the exception to be a feature that should be removed.\n\nHaving results be required to be JSON-serializable makes sense because we know what results are.\n\nExceptions are often downstream of outright mistakes, or other unknown operational errors. Having the errors be caught and recorded is good, but I think in those scenarios we have to try really hard to record the error. Dropping information is, IMO, a worse thing than not being able to deserialize the exception. \n\nEspecially given that people will often (in my experience at least) be looking at the exception by hand, not through automated processes.",
        "pr_file_module": null
      },
      {
        "comment_id": "1852048471",
        "repo_full_name": "django/django",
        "pr_number": 18627,
        "pr_file": "django/tasks/utils.py",
        "discussion_id": "1829277919",
        "commented_code": "@@ -0,0 +1,71 @@\n+import inspect\n+import json\n+import time\n+from functools import wraps\n+from traceback import format_exception\n+\n+from django.utils.module_loading import import_string\n+\n+\n+def is_module_level_function(func):\n+    if not inspect.isfunction(func) or inspect.isbuiltin(func):\n+        return False\n+\n+    if \"<locals>\" in func.__qualname__:\n+        return False\n+\n+    return True\n+\n+\n+def json_normalize(obj):\n+    \"\"\"\n+    Round-trip encode object as JSON to normalize types.\n+    \"\"\"\n+    return json.loads(json.dumps(obj))\n+\n+\n+def retry(*, retries=3, backoff_delay=0.1):\n+    \"\"\"\n+    Retry the given code `retries` times, raising the final error.\n+\n+    `backoff_delay` can be used to add a delay between attempts.\n+    \"\"\"\n+\n+    def wrapper(f):\n+        @wraps(f)\n+        def inner_wrapper(*args, **kwargs):\n+            for attempt in range(1, retries + 1):\n+                try:\n+                    return f(*args, **kwargs)\n+                except KeyboardInterrupt:\n+                    # Let the user ctrl-C out of the program without a retry\n+                    raise\n+                except BaseException:\n+                    if attempt == retries:\n+                        raise\n+                    time.sleep(backoff_delay)\n+\n+        return inner_wrapper\n+\n+    return wrapper\n+\n+\n+def get_module_path(val):\n+    return f\"{val.__module__}.{val.__qualname__}\"\n+\n+\n+def exception_to_dict(exc):\n+    return {\n+        \"exc_type\": get_module_path(type(exc)),\n+        \"exc_args\": json_normalize(exc.args),",
        "comment_created_at": "2024-11-21T13:18:53+00:00",
        "comment_author": "RealOrangeOne",
        "comment_body": "That's sort of what's here though. The traceback is available as a string, but the exception instance itself is also available if needed for automation reasons.",
        "pr_file_module": null
      },
      {
        "comment_id": "1853157735",
        "repo_full_name": "django/django",
        "pr_number": 18627,
        "pr_file": "django/tasks/utils.py",
        "discussion_id": "1829277919",
        "commented_code": "@@ -0,0 +1,71 @@\n+import inspect\n+import json\n+import time\n+from functools import wraps\n+from traceback import format_exception\n+\n+from django.utils.module_loading import import_string\n+\n+\n+def is_module_level_function(func):\n+    if not inspect.isfunction(func) or inspect.isbuiltin(func):\n+        return False\n+\n+    if \"<locals>\" in func.__qualname__:\n+        return False\n+\n+    return True\n+\n+\n+def json_normalize(obj):\n+    \"\"\"\n+    Round-trip encode object as JSON to normalize types.\n+    \"\"\"\n+    return json.loads(json.dumps(obj))\n+\n+\n+def retry(*, retries=3, backoff_delay=0.1):\n+    \"\"\"\n+    Retry the given code `retries` times, raising the final error.\n+\n+    `backoff_delay` can be used to add a delay between attempts.\n+    \"\"\"\n+\n+    def wrapper(f):\n+        @wraps(f)\n+        def inner_wrapper(*args, **kwargs):\n+            for attempt in range(1, retries + 1):\n+                try:\n+                    return f(*args, **kwargs)\n+                except KeyboardInterrupt:\n+                    # Let the user ctrl-C out of the program without a retry\n+                    raise\n+                except BaseException:\n+                    if attempt == retries:\n+                        raise\n+                    time.sleep(backoff_delay)\n+\n+        return inner_wrapper\n+\n+    return wrapper\n+\n+\n+def get_module_path(val):\n+    return f\"{val.__module__}.{val.__qualname__}\"\n+\n+\n+def exception_to_dict(exc):\n+    return {\n+        \"exc_type\": get_module_path(type(exc)),\n+        \"exc_args\": json_normalize(exc.args),",
        "comment_created_at": "2024-11-22T01:24:10+00:00",
        "comment_author": "rtpg",
        "comment_body": "Here is a very simple example of accidentally using the wrong data type to key into a structure. This turns into a `KeyError` of a `datetime.date`. The resulting exception fails to be serializable with `exception_to_dict`, so in the result handling code the exception data would be lost entirely.\r\n\r\n```\r\nIn [11]: t = datetime.date.today()\r\nIn [12]: data = {\"2024-11-22\": \"foo\"}\r\nIn [13]: try:\r\n    ...:     data[t]\r\n    ...:     print(\"No error!\")\r\n    ...: except Exception as e:\r\n    ...:     print(\"Hit exception1\", exception_to_dict(e))\r\n    ...: \r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\nCell In[13], line 2\r\n      1 try:\r\n----> 2     data[t]\r\n      3     print(\"No error!\")\r\n\r\nKeyError: datetime.date(2024, 11, 22)\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\nCell In[13], line 5\r\n      3     print(\"No error!\")\r\n      4 except Exception as e:\r\n----> 5     print(\"Hit exception1\", exception_to_dict(e))\r\n\r\n(snipped out stack trace)\r\n\r\nTypeError: Object of type date is not JSON serializable\r\n```\r\n\r\nThis is an extremely common kind of failure in Python, right? So it's not an edge case to say \"maybe the arguments to an exception are not JSON serializable\".\r\n\r\nOne resolution strategy here would be to have some fallback exception representation if JSON serialization fails. I think that should be built into `exception_to_dict`, so that when a result tries to record that there was an exception, it will _always_ be able to capture _some_ information.\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "1854153598",
        "repo_full_name": "django/django",
        "pr_number": 18627,
        "pr_file": "django/tasks/utils.py",
        "discussion_id": "1829277919",
        "commented_code": "@@ -0,0 +1,71 @@\n+import inspect\n+import json\n+import time\n+from functools import wraps\n+from traceback import format_exception\n+\n+from django.utils.module_loading import import_string\n+\n+\n+def is_module_level_function(func):\n+    if not inspect.isfunction(func) or inspect.isbuiltin(func):\n+        return False\n+\n+    if \"<locals>\" in func.__qualname__:\n+        return False\n+\n+    return True\n+\n+\n+def json_normalize(obj):\n+    \"\"\"\n+    Round-trip encode object as JSON to normalize types.\n+    \"\"\"\n+    return json.loads(json.dumps(obj))\n+\n+\n+def retry(*, retries=3, backoff_delay=0.1):\n+    \"\"\"\n+    Retry the given code `retries` times, raising the final error.\n+\n+    `backoff_delay` can be used to add a delay between attempts.\n+    \"\"\"\n+\n+    def wrapper(f):\n+        @wraps(f)\n+        def inner_wrapper(*args, **kwargs):\n+            for attempt in range(1, retries + 1):\n+                try:\n+                    return f(*args, **kwargs)\n+                except KeyboardInterrupt:\n+                    # Let the user ctrl-C out of the program without a retry\n+                    raise\n+                except BaseException:\n+                    if attempt == retries:\n+                        raise\n+                    time.sleep(backoff_delay)\n+\n+        return inner_wrapper\n+\n+    return wrapper\n+\n+\n+def get_module_path(val):\n+    return f\"{val.__module__}.{val.__qualname__}\"\n+\n+\n+def exception_to_dict(exc):\n+    return {\n+        \"exc_type\": get_module_path(type(exc)),\n+        \"exc_args\": json_normalize(exc.args),",
        "comment_created_at": "2024-11-22T15:48:09+00:00",
        "comment_author": "RealOrangeOne",
        "comment_body": "Ah of course, I'd forgotten about the internal arguments :sob:  I think you're right - something much simpler is going to be necessary.\r\n\r\nA string traceback, plus just the exception class is probably the best compromise",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1939305161",
    "pr_number": 18627,
    "pr_file": "django/tasks/task.py",
    "created_at": "2025-02-03T12:34:32+00:00",
    "commented_code": "+from dataclasses import dataclass, field, replace\n+from datetime import datetime\n+from inspect import iscoroutinefunction\n+from typing import Any, Callable, Dict, Optional, Type\n+\n+from asgiref.sync import async_to_sync, sync_to_async\n+\n+from django.db.models.enums import TextChoices\n+from django.utils.translation import gettext_lazy as _\n+\n+from .exceptions import ResultDoesNotExist\n+from .utils import get_module_path, json_normalize\n+\n+DEFAULT_TASK_BACKEND_ALIAS = \"default\"\n+DEFAULT_QUEUE_NAME = \"default\"\n+MIN_PRIORITY = -100\n+MAX_PRIORITY = 100\n+DEFAULT_PRIORITY = 0\n+\n+TASK_REFRESH_ATTRS = {\n+    \"_exception_class\",\n+    \"_traceback\",\n+    \"_return_value\",\n+    \"finished_at\",\n+    \"started_at\",\n+    \"status\",\n+    \"enqueued_at\",\n+}\n+\n+\n+class ResultStatus(TextChoices):\n+    NEW = (\"NEW\", _(\"New\"))\n+    RUNNING = (\"RUNNING\", _(\"Running\"))\n+    FAILED = (\"FAILED\", _(\"Failed\"))\n+    SUCCEEDED = (\"SUCCEEDED\", _(\"Succeeded\"))\n+\n+\n+@dataclass(frozen=True)\n+class Task:\n+    priority: int\n+    \"\"\"The priority of the task\"\"\"\n+\n+    func: Callable\n+    \"\"\"The task function\"\"\"\n+\n+    backend: str\n+    \"\"\"The name of the backend the task will run on\"\"\"\n+\n+    queue_name: str = DEFAULT_QUEUE_NAME\n+    \"\"\"The name of the queue the task will run on\"\"\"\n+\n+    run_after: Optional[datetime] = None\n+    \"\"\"The earliest this task will run\"\"\"\n+\n+    enqueue_on_commit: Optional[bool] = None\n+    \"\"\"\n+    Whether the task will be enqueued when the current transaction commits,\n+    immediately, or whatever the backend decides\n+    \"\"\"\n+\n+    def __post_init__(self):\n+        self.get_backend().validate_task(self)\n+\n+    @property\n+    def name(self):\n+        \"\"\"\n+        An identifier for the task\n+        \"\"\"\n+        return self.func.__name__\n+\n+    def using(\n+        self,\n+        *,\n+        priority=None,\n+        queue_name=None,\n+        run_after=None,\n+        backend=None,\n+    ):\n+        \"\"\"\n+        Create a new task with modified defaults\n+        \"\"\"\n+\n+        changes = {}\n+\n+        if priority is not None:\n+            changes[\"priority\"] = priority\n+        if queue_name is not None:\n+            changes[\"queue_name\"] = queue_name\n+        if run_after is not None:\n+            changes[\"run_after\"] = run_after\n+        if backend is not None:\n+            changes[\"backend\"] = backend\n+\n+        return replace(self, **changes)\n+\n+    def enqueue(self, *args, **kwargs):\n+        \"\"\"\n+        Queue up the task to be executed\n+        \"\"\"\n+        return self.get_backend().enqueue(\n+            self, json_normalize(args), json_normalize(kwargs)",
    "repo_full_name": "django/django",
    "discussion_comments": [
      {
        "comment_id": "1939305161",
        "repo_full_name": "django/django",
        "pr_number": 18627,
        "pr_file": "django/tasks/task.py",
        "discussion_id": "1939305161",
        "commented_code": "@@ -0,0 +1,271 @@\n+from dataclasses import dataclass, field, replace\n+from datetime import datetime\n+from inspect import iscoroutinefunction\n+from typing import Any, Callable, Dict, Optional, Type\n+\n+from asgiref.sync import async_to_sync, sync_to_async\n+\n+from django.db.models.enums import TextChoices\n+from django.utils.translation import gettext_lazy as _\n+\n+from .exceptions import ResultDoesNotExist\n+from .utils import get_module_path, json_normalize\n+\n+DEFAULT_TASK_BACKEND_ALIAS = \"default\"\n+DEFAULT_QUEUE_NAME = \"default\"\n+MIN_PRIORITY = -100\n+MAX_PRIORITY = 100\n+DEFAULT_PRIORITY = 0\n+\n+TASK_REFRESH_ATTRS = {\n+    \"_exception_class\",\n+    \"_traceback\",\n+    \"_return_value\",\n+    \"finished_at\",\n+    \"started_at\",\n+    \"status\",\n+    \"enqueued_at\",\n+}\n+\n+\n+class ResultStatus(TextChoices):\n+    NEW = (\"NEW\", _(\"New\"))\n+    RUNNING = (\"RUNNING\", _(\"Running\"))\n+    FAILED = (\"FAILED\", _(\"Failed\"))\n+    SUCCEEDED = (\"SUCCEEDED\", _(\"Succeeded\"))\n+\n+\n+@dataclass(frozen=True)\n+class Task:\n+    priority: int\n+    \"\"\"The priority of the task\"\"\"\n+\n+    func: Callable\n+    \"\"\"The task function\"\"\"\n+\n+    backend: str\n+    \"\"\"The name of the backend the task will run on\"\"\"\n+\n+    queue_name: str = DEFAULT_QUEUE_NAME\n+    \"\"\"The name of the queue the task will run on\"\"\"\n+\n+    run_after: Optional[datetime] = None\n+    \"\"\"The earliest this task will run\"\"\"\n+\n+    enqueue_on_commit: Optional[bool] = None\n+    \"\"\"\n+    Whether the task will be enqueued when the current transaction commits,\n+    immediately, or whatever the backend decides\n+    \"\"\"\n+\n+    def __post_init__(self):\n+        self.get_backend().validate_task(self)\n+\n+    @property\n+    def name(self):\n+        \"\"\"\n+        An identifier for the task\n+        \"\"\"\n+        return self.func.__name__\n+\n+    def using(\n+        self,\n+        *,\n+        priority=None,\n+        queue_name=None,\n+        run_after=None,\n+        backend=None,\n+    ):\n+        \"\"\"\n+        Create a new task with modified defaults\n+        \"\"\"\n+\n+        changes = {}\n+\n+        if priority is not None:\n+            changes[\"priority\"] = priority\n+        if queue_name is not None:\n+            changes[\"queue_name\"] = queue_name\n+        if run_after is not None:\n+            changes[\"run_after\"] = run_after\n+        if backend is not None:\n+            changes[\"backend\"] = backend\n+\n+        return replace(self, **changes)\n+\n+    def enqueue(self, *args, **kwargs):\n+        \"\"\"\n+        Queue up the task to be executed\n+        \"\"\"\n+        return self.get_backend().enqueue(\n+            self, json_normalize(args), json_normalize(kwargs)",
        "comment_created_at": "2025-02-03T12:34:32+00:00",
        "comment_author": "bluetech",
        "comment_body": "It would be nice to wrap the `json_normalize` in try/except and raise a clear Django error that the input needs to be JSON-serializable. Not everyone will read the documentation note, and some TypeError exception would be confusing for beginners I imagine.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1169653778",
    "pr_number": 16775,
    "pr_file": "django/contrib/staticfiles/storage.py",
    "created_at": "2023-04-18T08:06:26+00:00",
    "commented_code": "if re.match(r\"^[a-z]+:\", url):\n                 return matched\n \n-            # Ignore absolute URLs that don't point to a static file (dynamic\n-            # CSS / JS?). Note that STATIC_URL cannot be empty.\n-            if url.startswith(\"/\") and not url.startswith(settings.STATIC_URL):\n-                return matched\n-\n             # Strip off the fragment so a path-like fragment won't interfere.\n             url_path, fragment = urldefrag(url)\n \n             # Ignore URLs without a path\n             if not url_path:\n                 return matched\n \n+            absolute_url_without_static_url = False\n             if url_path.startswith(\"/\"):\n-                # Otherwise the condition above would have returned prematurely.\n-                assert url_path.startswith(settings.STATIC_URL)\n-                target_name = url_path.removeprefix(settings.STATIC_URL)\n+                if url_path.startswith(settings.STATIC_URL):\n+                    target_name = url_path[len(settings.STATIC_URL) :]\n+                else:\n+                    target_name = url_path[1:]\n+                    absolute_url_without_static_url = True\n             else:\n                 # We're using the posixpath module to mix paths and URLs conveniently.\n                 source_name = name if os.sep == \"/\" else name.replace(os.sep, \"/\")\n                 target_name = posixpath.join(posixpath.dirname(source_name), url_path)\n \n-            # Determine the hashed name of the target file with the storage backend.\n-            hashed_url = self._url(\n-                self._stored_name,\n-                unquote(target_name),\n-                force=True,\n-                hashed_files=hashed_files,\n-            )\n+            try:\n+                # Determine the hashed name of the target file with the storage backend.\n+                hashed_url = self._url(\n+                    self._stored_name,\n+                    unquote(target_name),\n+                    force=True,\n+                    hashed_files=hashed_files,\n+                )\n+            except (ValueError, SuspiciousFileOperation):",
    "repo_full_name": "django/django",
    "discussion_comments": [
      {
        "comment_id": "1169653778",
        "repo_full_name": "django/django",
        "pr_number": 16775,
        "pr_file": "django/contrib/staticfiles/storage.py",
        "discussion_id": "1169653778",
        "commented_code": "@@ -224,39 +224,49 @@ def converter(matchobj):\n             if re.match(r\"^[a-z]+:\", url):\n                 return matched\n \n-            # Ignore absolute URLs that don't point to a static file (dynamic\n-            # CSS / JS?). Note that STATIC_URL cannot be empty.\n-            if url.startswith(\"/\") and not url.startswith(settings.STATIC_URL):\n-                return matched\n-\n             # Strip off the fragment so a path-like fragment won't interfere.\n             url_path, fragment = urldefrag(url)\n \n             # Ignore URLs without a path\n             if not url_path:\n                 return matched\n \n+            absolute_url_without_static_url = False\n             if url_path.startswith(\"/\"):\n-                # Otherwise the condition above would have returned prematurely.\n-                assert url_path.startswith(settings.STATIC_URL)\n-                target_name = url_path.removeprefix(settings.STATIC_URL)\n+                if url_path.startswith(settings.STATIC_URL):\n+                    target_name = url_path[len(settings.STATIC_URL) :]\n+                else:\n+                    target_name = url_path[1:]\n+                    absolute_url_without_static_url = True\n             else:\n                 # We're using the posixpath module to mix paths and URLs conveniently.\n                 source_name = name if os.sep == \"/\" else name.replace(os.sep, \"/\")\n                 target_name = posixpath.join(posixpath.dirname(source_name), url_path)\n \n-            # Determine the hashed name of the target file with the storage backend.\n-            hashed_url = self._url(\n-                self._stored_name,\n-                unquote(target_name),\n-                force=True,\n-                hashed_files=hashed_files,\n-            )\n+            try:\n+                # Determine the hashed name of the target file with the storage backend.\n+                hashed_url = self._url(\n+                    self._stored_name,\n+                    unquote(target_name),\n+                    force=True,\n+                    hashed_files=hashed_files,\n+                )\n+            except (ValueError, SuspiciousFileOperation):",
        "comment_created_at": "2023-04-18T08:06:26+00:00",
        "comment_author": "felixxm",
        "comment_body": "Do we have a test for `ValueError`? I don't see any failures in `staticfiles_tests` when I remove it.",
        "pr_file_module": null
      },
      {
        "comment_id": "1170210924",
        "repo_full_name": "django/django",
        "pr_number": 16775,
        "pr_file": "django/contrib/staticfiles/storage.py",
        "discussion_id": "1169653778",
        "commented_code": "@@ -224,39 +224,49 @@ def converter(matchobj):\n             if re.match(r\"^[a-z]+:\", url):\n                 return matched\n \n-            # Ignore absolute URLs that don't point to a static file (dynamic\n-            # CSS / JS?). Note that STATIC_URL cannot be empty.\n-            if url.startswith(\"/\") and not url.startswith(settings.STATIC_URL):\n-                return matched\n-\n             # Strip off the fragment so a path-like fragment won't interfere.\n             url_path, fragment = urldefrag(url)\n \n             # Ignore URLs without a path\n             if not url_path:\n                 return matched\n \n+            absolute_url_without_static_url = False\n             if url_path.startswith(\"/\"):\n-                # Otherwise the condition above would have returned prematurely.\n-                assert url_path.startswith(settings.STATIC_URL)\n-                target_name = url_path.removeprefix(settings.STATIC_URL)\n+                if url_path.startswith(settings.STATIC_URL):\n+                    target_name = url_path[len(settings.STATIC_URL) :]\n+                else:\n+                    target_name = url_path[1:]\n+                    absolute_url_without_static_url = True\n             else:\n                 # We're using the posixpath module to mix paths and URLs conveniently.\n                 source_name = name if os.sep == \"/\" else name.replace(os.sep, \"/\")\n                 target_name = posixpath.join(posixpath.dirname(source_name), url_path)\n \n-            # Determine the hashed name of the target file with the storage backend.\n-            hashed_url = self._url(\n-                self._stored_name,\n-                unquote(target_name),\n-                force=True,\n-                hashed_files=hashed_files,\n-            )\n+            try:\n+                # Determine the hashed name of the target file with the storage backend.\n+                hashed_url = self._url(\n+                    self._stored_name,\n+                    unquote(target_name),\n+                    force=True,\n+                    hashed_files=hashed_files,\n+                )\n+            except (ValueError, SuspiciousFileOperation):",
        "comment_created_at": "2023-04-18T15:27:59+00:00",
        "comment_author": "hwalinga",
        "comment_body": "This block of code has some redundancy. ValueError is only raised when the URL does not start with a '/' and thus is always reraised, and SuspiciousFileOperation is always raised when it does start with a '/'. Removing all redundant code would result in:\r\n\r\n```\r\nexcept SuspiciousFileOperation:\r\n    # Ignore absolute URLs that don't point to a static file (dynamic\r\n    # CSS / JS?). Note that STATIC_URL cannot be empty.\r\n    if not url.startswith(settings.STATIC_URL):\r\n        return matched\r\n    else:\r\n        raise\r\n```\r\n\r\nAnd it would be all fine. \r\n\r\nHowever, I prefer to have some redundancy as I am just not 100% relying on the code this comes from. The exception originates in django/utils/_os.py and although the docstring claims it should raise a ValueError the code actually raises a SuspiciousFileOperation. ",
        "pr_file_module": null
      },
      {
        "comment_id": "1171243373",
        "repo_full_name": "django/django",
        "pr_number": 16775,
        "pr_file": "django/contrib/staticfiles/storage.py",
        "discussion_id": "1169653778",
        "commented_code": "@@ -224,39 +224,49 @@ def converter(matchobj):\n             if re.match(r\"^[a-z]+:\", url):\n                 return matched\n \n-            # Ignore absolute URLs that don't point to a static file (dynamic\n-            # CSS / JS?). Note that STATIC_URL cannot be empty.\n-            if url.startswith(\"/\") and not url.startswith(settings.STATIC_URL):\n-                return matched\n-\n             # Strip off the fragment so a path-like fragment won't interfere.\n             url_path, fragment = urldefrag(url)\n \n             # Ignore URLs without a path\n             if not url_path:\n                 return matched\n \n+            absolute_url_without_static_url = False\n             if url_path.startswith(\"/\"):\n-                # Otherwise the condition above would have returned prematurely.\n-                assert url_path.startswith(settings.STATIC_URL)\n-                target_name = url_path.removeprefix(settings.STATIC_URL)\n+                if url_path.startswith(settings.STATIC_URL):\n+                    target_name = url_path[len(settings.STATIC_URL) :]\n+                else:\n+                    target_name = url_path[1:]\n+                    absolute_url_without_static_url = True\n             else:\n                 # We're using the posixpath module to mix paths and URLs conveniently.\n                 source_name = name if os.sep == \"/\" else name.replace(os.sep, \"/\")\n                 target_name = posixpath.join(posixpath.dirname(source_name), url_path)\n \n-            # Determine the hashed name of the target file with the storage backend.\n-            hashed_url = self._url(\n-                self._stored_name,\n-                unquote(target_name),\n-                force=True,\n-                hashed_files=hashed_files,\n-            )\n+            try:\n+                # Determine the hashed name of the target file with the storage backend.\n+                hashed_url = self._url(\n+                    self._stored_name,\n+                    unquote(target_name),\n+                    force=True,\n+                    hashed_files=hashed_files,\n+                )\n+            except (ValueError, SuspiciousFileOperation):",
        "comment_created_at": "2023-04-19T12:08:39+00:00",
        "comment_author": "shangxiao",
        "comment_body": "I think it should be fine to remove `ValueError`. If you look a very early commit eg f6e86c4286 then you can see the function did actually raise a `ValueError`. When it was changed to `SuspiciousFileOperation` the docstring wasn't updated \ud83e\udd37\u200d\u2642\ufe0f",
        "pr_file_module": null
      },
      {
        "comment_id": "1171245288",
        "repo_full_name": "django/django",
        "pr_number": 16775,
        "pr_file": "django/contrib/staticfiles/storage.py",
        "discussion_id": "1169653778",
        "commented_code": "@@ -224,39 +224,49 @@ def converter(matchobj):\n             if re.match(r\"^[a-z]+:\", url):\n                 return matched\n \n-            # Ignore absolute URLs that don't point to a static file (dynamic\n-            # CSS / JS?). Note that STATIC_URL cannot be empty.\n-            if url.startswith(\"/\") and not url.startswith(settings.STATIC_URL):\n-                return matched\n-\n             # Strip off the fragment so a path-like fragment won't interfere.\n             url_path, fragment = urldefrag(url)\n \n             # Ignore URLs without a path\n             if not url_path:\n                 return matched\n \n+            absolute_url_without_static_url = False\n             if url_path.startswith(\"/\"):\n-                # Otherwise the condition above would have returned prematurely.\n-                assert url_path.startswith(settings.STATIC_URL)\n-                target_name = url_path.removeprefix(settings.STATIC_URL)\n+                if url_path.startswith(settings.STATIC_URL):\n+                    target_name = url_path[len(settings.STATIC_URL) :]\n+                else:\n+                    target_name = url_path[1:]\n+                    absolute_url_without_static_url = True\n             else:\n                 # We're using the posixpath module to mix paths and URLs conveniently.\n                 source_name = name if os.sep == \"/\" else name.replace(os.sep, \"/\")\n                 target_name = posixpath.join(posixpath.dirname(source_name), url_path)\n \n-            # Determine the hashed name of the target file with the storage backend.\n-            hashed_url = self._url(\n-                self._stored_name,\n-                unquote(target_name),\n-                force=True,\n-                hashed_files=hashed_files,\n-            )\n+            try:\n+                # Determine the hashed name of the target file with the storage backend.\n+                hashed_url = self._url(\n+                    self._stored_name,\n+                    unquote(target_name),\n+                    force=True,\n+                    hashed_files=hashed_files,\n+                )\n+            except (ValueError, SuspiciousFileOperation):",
        "comment_created_at": "2023-04-19T12:10:31+00:00",
        "comment_author": "shangxiao",
        "comment_body": "ah confirmed: b8ba73cd0cb6a3dbdaeb3df65936970956829de3\r\n\r\n/me looks at aaugustin \ud83d\ude01",
        "pr_file_module": null
      },
      {
        "comment_id": "1171250116",
        "repo_full_name": "django/django",
        "pr_number": 16775,
        "pr_file": "django/contrib/staticfiles/storage.py",
        "discussion_id": "1169653778",
        "commented_code": "@@ -224,39 +224,49 @@ def converter(matchobj):\n             if re.match(r\"^[a-z]+:\", url):\n                 return matched\n \n-            # Ignore absolute URLs that don't point to a static file (dynamic\n-            # CSS / JS?). Note that STATIC_URL cannot be empty.\n-            if url.startswith(\"/\") and not url.startswith(settings.STATIC_URL):\n-                return matched\n-\n             # Strip off the fragment so a path-like fragment won't interfere.\n             url_path, fragment = urldefrag(url)\n \n             # Ignore URLs without a path\n             if not url_path:\n                 return matched\n \n+            absolute_url_without_static_url = False\n             if url_path.startswith(\"/\"):\n-                # Otherwise the condition above would have returned prematurely.\n-                assert url_path.startswith(settings.STATIC_URL)\n-                target_name = url_path.removeprefix(settings.STATIC_URL)\n+                if url_path.startswith(settings.STATIC_URL):\n+                    target_name = url_path[len(settings.STATIC_URL) :]\n+                else:\n+                    target_name = url_path[1:]\n+                    absolute_url_without_static_url = True\n             else:\n                 # We're using the posixpath module to mix paths and URLs conveniently.\n                 source_name = name if os.sep == \"/\" else name.replace(os.sep, \"/\")\n                 target_name = posixpath.join(posixpath.dirname(source_name), url_path)\n \n-            # Determine the hashed name of the target file with the storage backend.\n-            hashed_url = self._url(\n-                self._stored_name,\n-                unquote(target_name),\n-                force=True,\n-                hashed_files=hashed_files,\n-            )\n+            try:\n+                # Determine the hashed name of the target file with the storage backend.\n+                hashed_url = self._url(\n+                    self._stored_name,\n+                    unquote(target_name),\n+                    force=True,\n+                    hashed_files=hashed_files,\n+                )\n+            except (ValueError, SuspiciousFileOperation):",
        "comment_created_at": "2023-04-19T12:15:10+00:00",
        "comment_author": "felixxm",
        "comment_body": "IMO, `ValueError` is still needed, e.g.\r\n```diff\r\ndiff --git a/tests/staticfiles_tests/project/documents/cached/source_map.js b/tests/staticfiles_tests/project/documents/cached/source_map.js\r\nindex 9d417868a0..10391168df 100644\r\n--- a/tests/staticfiles_tests/project/documents/cached/source_map.js\r\n+++ b/tests/staticfiles_tests/project/documents/cached/source_map.js\r\n@@ -1,2 +1,3 @@\r\n //# sourceMappingURL=source_map.js.map\r\n+//# sourceMappingURL=/source_map.js.map\r\n let a_variable = 1;\r\n```\r\ncrashes with:\r\n```\r\nValueError: The file 'source_map.js.map' could not be found with <django.contrib.staticfiles.storage.ManifestStaticFilesStorage object at 0x7fab98dd2fe0>.\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1172559475",
        "repo_full_name": "django/django",
        "pr_number": 16775,
        "pr_file": "django/contrib/staticfiles/storage.py",
        "discussion_id": "1169653778",
        "commented_code": "@@ -224,39 +224,49 @@ def converter(matchobj):\n             if re.match(r\"^[a-z]+:\", url):\n                 return matched\n \n-            # Ignore absolute URLs that don't point to a static file (dynamic\n-            # CSS / JS?). Note that STATIC_URL cannot be empty.\n-            if url.startswith(\"/\") and not url.startswith(settings.STATIC_URL):\n-                return matched\n-\n             # Strip off the fragment so a path-like fragment won't interfere.\n             url_path, fragment = urldefrag(url)\n \n             # Ignore URLs without a path\n             if not url_path:\n                 return matched\n \n+            absolute_url_without_static_url = False\n             if url_path.startswith(\"/\"):\n-                # Otherwise the condition above would have returned prematurely.\n-                assert url_path.startswith(settings.STATIC_URL)\n-                target_name = url_path.removeprefix(settings.STATIC_URL)\n+                if url_path.startswith(settings.STATIC_URL):\n+                    target_name = url_path[len(settings.STATIC_URL) :]\n+                else:\n+                    target_name = url_path[1:]\n+                    absolute_url_without_static_url = True\n             else:\n                 # We're using the posixpath module to mix paths and URLs conveniently.\n                 source_name = name if os.sep == \"/\" else name.replace(os.sep, \"/\")\n                 target_name = posixpath.join(posixpath.dirname(source_name), url_path)\n \n-            # Determine the hashed name of the target file with the storage backend.\n-            hashed_url = self._url(\n-                self._stored_name,\n-                unquote(target_name),\n-                force=True,\n-                hashed_files=hashed_files,\n-            )\n+            try:\n+                # Determine the hashed name of the target file with the storage backend.\n+                hashed_url = self._url(\n+                    self._stored_name,\n+                    unquote(target_name),\n+                    force=True,\n+                    hashed_files=hashed_files,\n+                )\n+            except (ValueError, SuspiciousFileOperation):",
        "comment_created_at": "2023-04-20T13:05:21+00:00",
        "comment_author": "hwalinga",
        "comment_body": "Good one. Yes, there seemed to be missing a test that tests the behavior of \"Ignore absolute URLs that don't point to a static file\". Now pushed. \r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1213354741",
    "pr_number": 16851,
    "pr_file": "django/db/models/fields/related.py",
    "created_at": "2023-06-01T15:44:48+00:00",
    "commented_code": "else []\n         )\n \n+    def _has_related_models_with_db_cascading(self, model):\n+        \"\"\"\n+        If the foreignkey parent has DB cascading and the Current model has non\n+        db cascading return true\n+        \"\"\"\n+        if not hasattr(model, \"_meta\"):\n+            return False\n+\n+        on_delete = getattr(self.remote_field, \"on_delete\", None)\n+        related_models = [\n+            rel.related_model\n+            for rel in model._meta.get_fields()\n+            if rel.related_model and not rel.auto_created\n+        ]\n+        has_related_cascade_db = any(\n+            any(\n+                (\n+                    isinstance(rel, ForeignKey)\n+                    and hasattr(rel.remote_field, \"on_delete\")\n+                    and rel.remote_field.on_delete in [DB_CASCADE, DB_SET_NULL]\n+                    and on_delete in [CASCADE, SET_NULL]\n+                )\n+                for rel in model._meta.get_fields()",
    "repo_full_name": "django/django",
    "discussion_comments": [
      {
        "comment_id": "1213354741",
        "repo_full_name": "django/django",
        "pr_number": 16851,
        "pr_file": "django/db/models/fields/related.py",
        "discussion_id": "1213354741",
        "commented_code": "@@ -1051,6 +1108,35 @@ def _check_unique(self, **kwargs):\n             else []\n         )\n \n+    def _has_related_models_with_db_cascading(self, model):\n+        \"\"\"\n+        If the foreignkey parent has DB cascading and the Current model has non\n+        db cascading return true\n+        \"\"\"\n+        if not hasattr(model, \"_meta\"):\n+            return False\n+\n+        on_delete = getattr(self.remote_field, \"on_delete\", None)\n+        related_models = [\n+            rel.related_model\n+            for rel in model._meta.get_fields()\n+            if rel.related_model and not rel.auto_created\n+        ]\n+        has_related_cascade_db = any(\n+            any(\n+                (\n+                    isinstance(rel, ForeignKey)\n+                    and hasattr(rel.remote_field, \"on_delete\")\n+                    and rel.remote_field.on_delete in [DB_CASCADE, DB_SET_NULL]\n+                    and on_delete in [CASCADE, SET_NULL]\n+                )\n+                for rel in model._meta.get_fields()",
        "comment_created_at": "2023-06-01T15:44:48+00:00",
        "comment_author": "LilyAcorn",
        "comment_body": "I wonder if the we can make the error message more useful by explicitly calling out which `rel` is incompatible.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2111941291",
    "pr_number": 19508,
    "pr_file": "django/utils/log.py",
    "created_at": "2025-05-28T13:34:42+00:00",
    "commented_code": "\"level\": \"INFO\",\n             \"propagate\": False,\n         },\n+        \"django.db.backends\": {\n+            \"handlers\": [\"debug_queries\"],\n+            \"level\": \"ERROR\",\n+            \"propagate\": False,\n+        },",
    "repo_full_name": "django/django",
    "discussion_comments": [
      {
        "comment_id": "2111941291",
        "repo_full_name": "django/django",
        "pr_number": 19508,
        "pr_file": "django/utils/log.py",
        "discussion_id": "2111941291",
        "commented_code": "@@ -60,6 +72,11 @@\n             \"level\": \"INFO\",\n             \"propagate\": False,\n         },\n+        \"django.db.backends\": {\n+            \"handlers\": [\"debug_queries\"],\n+            \"level\": \"ERROR\",\n+            \"propagate\": False,\n+        },",
        "comment_created_at": "2025-05-28T13:34:42+00:00",
        "comment_author": "jacobtylerwalls",
        "comment_body": "This is a light touch change, but it does cause one behavior change: now `on_commit(robust=True)` calls will have [exceptions logged](https://docs.djangoproject.com/en/5.2/topics/db/transactions/#django.db.transaction.on_commit) by default. This might be worth documenting (don't want to surprise users who consider exceptions sensitive, etc.)\r\n\r\nShould we consider raising this to `CRITICAL`?",
        "pr_file_module": null
      },
      {
        "comment_id": "2112156104",
        "repo_full_name": "django/django",
        "pr_number": 19508,
        "pr_file": "django/utils/log.py",
        "discussion_id": "2111941291",
        "commented_code": "@@ -60,6 +72,11 @@\n             \"level\": \"INFO\",\n             \"propagate\": False,\n         },\n+        \"django.db.backends\": {\n+            \"handlers\": [\"debug_queries\"],\n+            \"level\": \"ERROR\",\n+            \"propagate\": False,\n+        },",
        "comment_created_at": "2025-05-28T15:09:55+00:00",
        "comment_author": "nessita",
        "comment_body": "Either that or plugin in the formatter to `django.db.backends.utils` and use that in `django/db/backends/utils.py`?",
        "pr_file_module": null
      }
    ]
  }
]