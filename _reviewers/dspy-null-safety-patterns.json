[
  {
    "discussion_id": "2049100206",
    "pr_number": 8077,
    "pr_file": "dspy/adapters/utils.py",
    "created_at": "2025-04-17T14:35:46+00:00",
    "commented_code": "raise ValueError(f\"{identifier} is not a valid name or value for the enum {enum.__name__}\")\n \n+def _strip_optional(ann):\n+    \"\"\"If ann is Union[..., NoneType] return the non\u2011None part, else ann.\"\"\"\n+    if get_origin(ann) is Union and NoneType in get_args(ann):\n+        # keep the first non\u2011None member (there will be only one in Optional[T])\n+        return next(a for a in get_args(ann) if a is not NoneType)\n+    return ann\n \n def parse_value(value, annotation):\n+    annotation = _strip_optional(annotation)",
    "repo_full_name": "stanfordnlp/dspy",
    "discussion_comments": [
      {
        "comment_id": "2049100206",
        "repo_full_name": "stanfordnlp/dspy",
        "pr_number": 8077,
        "pr_file": "dspy/adapters/utils.py",
        "discussion_id": "2049100206",
        "commented_code": "@@ -130,8 +131,19 @@ def find_enum_member(enum, identifier):\n \n     raise ValueError(f\"{identifier} is not a valid name or value for the enum {enum.__name__}\")\n \n+def _strip_optional(ann):\n+    \"\"\"If ann is Union[..., NoneType] return the non\u2011None part, else ann.\"\"\"\n+    if get_origin(ann) is Union and NoneType in get_args(ann):\n+        # keep the first non\u2011None member (there will be only one in Optional[T])\n+        return next(a for a in get_args(ann) if a is not NoneType)\n+    return ann\n \n def parse_value(value, annotation):\n+    annotation = _strip_optional(annotation)",
        "comment_created_at": "2025-04-17T14:35:46+00:00",
        "comment_author": "klopsahlong",
        "comment_body": "This is to allow support for Optional fields (i.e. where a field could be None, or str), which is the case for KIE and was throwing errors before.",
        "pr_file_module": null
      },
      {
        "comment_id": "2316540253",
        "repo_full_name": "stanfordnlp/dspy",
        "pr_number": 8077,
        "pr_file": "dspy/adapters/utils.py",
        "discussion_id": "2049100206",
        "commented_code": "@@ -130,8 +131,19 @@ def find_enum_member(enum, identifier):\n \n     raise ValueError(f\"{identifier} is not a valid name or value for the enum {enum.__name__}\")\n \n+def _strip_optional(ann):\n+    \"\"\"If ann is Union[..., NoneType] return the non\u2011None part, else ann.\"\"\"\n+    if get_origin(ann) is Union and NoneType in get_args(ann):\n+        # keep the first non\u2011None member (there will be only one in Optional[T])\n+        return next(a for a in get_args(ann) if a is not NoneType)\n+    return ann\n \n def parse_value(value, annotation):\n+    annotation = _strip_optional(annotation)",
        "comment_created_at": "2025-09-02T16:02:01+00:00",
        "comment_author": "klopsahlong",
        "comment_body": "More info on the failure case this fixes:\r\n\r\nPreviously, this was failing for fields of Union(str, None) with values of type 'str' that could also be parsed as ints. Ex: \"9812750\". \r\n\r\nThe problem is in this sequence:\r\nvalue = \"9812750\" (string)\r\nannotation = typing.Optional[str]\r\ncandidate = json_repair.loads(\"9812750\") \u2192 9812750 (parses as integer, not str)\r\nTypeAdapter(typing.Optional[str]).validate_python(9812750) \u2192 Fails with pydantic.ValidationError since the value is neither a str nor None\r\nException handler is triggered: except pydantic.ValidationError as e:\r\nThen we hit this line : issubclass(annotation, Type), which throws the error `issubclass() arg 1 must be a class` because `typing.Optional[str]` is not a class, since it's a type annotation/Union.\r\n\r\nThis fix involves first parsing the Optional field to get the expected non-Null type, and parse the value according to this. Now pydantic handles the type coercion correctly from str -> str instead of int-> int when the non-null annotation type is 'str'",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2312136846",
    "pr_number": 8737,
    "pr_file": "dspy/teleprompt/gepa/gepa_utils.py",
    "created_at": "2025-08-30T22:36:13+00:00",
    "commented_code": "self.num_threads = num_threads\n         self.add_format_failure_as_feedback = add_format_failure_as_feedback\n         self.rng = rng or random.Random(0)\n+        self.reflection_lm = reflection_lm\n+        self.custom_instruction_proposer = custom_instruction_proposer\n+\n+        if self.custom_instruction_proposer is not None:",
    "repo_full_name": "stanfordnlp/dspy",
    "discussion_comments": [
      {
        "comment_id": "2312136846",
        "repo_full_name": "stanfordnlp/dspy",
        "pr_number": 8737,
        "pr_file": "dspy/teleprompt/gepa/gepa_utils.py",
        "discussion_id": "2312136846",
        "commented_code": "@@ -66,6 +73,35 @@ def __init__(\n         self.num_threads = num_threads\n         self.add_format_failure_as_feedback = add_format_failure_as_feedback\n         self.rng = rng or random.Random(0)\n+        self.reflection_lm = reflection_lm\n+        self.custom_instruction_proposer = custom_instruction_proposer\n+\n+        if self.custom_instruction_proposer is not None:",
        "comment_created_at": "2025-08-30T22:36:13+00:00",
        "comment_author": "LakshyAAAgrawal",
        "comment_body": "There should be an assert here, that ensures whenever `self.custom_instruction_proposer is not None`, then `assert self.reflection_lm is not None` as well.",
        "pr_file_module": null
      },
      {
        "comment_id": "2314642335",
        "repo_full_name": "stanfordnlp/dspy",
        "pr_number": 8737,
        "pr_file": "dspy/teleprompt/gepa/gepa_utils.py",
        "discussion_id": "2312136846",
        "commented_code": "@@ -66,6 +73,35 @@ def __init__(\n         self.num_threads = num_threads\n         self.add_format_failure_as_feedback = add_format_failure_as_feedback\n         self.rng = rng or random.Random(0)\n+        self.reflection_lm = reflection_lm\n+        self.custom_instruction_proposer = custom_instruction_proposer\n+\n+        if self.custom_instruction_proposer is not None:",
        "comment_created_at": "2025-09-01T23:16:49+00:00",
        "comment_author": "andressrg",
        "comment_body": "good point. Added \ud83d\udc4d ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2317184406",
    "pr_number": 8737,
    "pr_file": "dspy/teleprompt/gepa/gepa.py",
    "created_at": "2025-09-02T21:11:21+00:00",
    "commented_code": "self.max_full_evals = max_full_evals\n         self.max_metric_calls = max_metric_calls\n \n-        # Reflection based configuration\n+        # Reflection configuration\n         self.reflection_minibatch_size = reflection_minibatch_size\n         self.candidate_selection_strategy = candidate_selection_strategy\n-        # self.reflection_lm = reflection_lm\n         assert reflection_lm is not None, \"GEPA requires a reflection language model to be provided. Typically, you can use `dspy.LM(model='gpt-5', temperature=1.0, max_tokens=32000)` to get a good reflection model. Reflection LM is used by GEPA to reflect on the behavior of the program and propose new instructions, and will benefit from a strong model.\"",
    "repo_full_name": "stanfordnlp/dspy",
    "discussion_comments": [
      {
        "comment_id": "2317184406",
        "repo_full_name": "stanfordnlp/dspy",
        "pr_number": 8737,
        "pr_file": "dspy/teleprompt/gepa/gepa.py",
        "discussion_id": "2317184406",
        "commented_code": "@@ -309,11 +317,11 @@ def __init__(\n         self.max_full_evals = max_full_evals\n         self.max_metric_calls = max_metric_calls\n \n-        # Reflection based configuration\n+        # Reflection configuration\n         self.reflection_minibatch_size = reflection_minibatch_size\n         self.candidate_selection_strategy = candidate_selection_strategy\n-        # self.reflection_lm = reflection_lm\n         assert reflection_lm is not None, \"GEPA requires a reflection language model to be provided. Typically, you can use `dspy.LM(model='gpt-5', temperature=1.0, max_tokens=32000)` to get a good reflection model. Reflection LM is used by GEPA to reflect on the behavior of the program and propose new instructions, and will benefit from a strong model.\"",
        "comment_created_at": "2025-09-02T21:11:21+00:00",
        "comment_author": "LakshyAAAgrawal",
        "comment_body": "This should be modified to say \"assert custom_proposer is not None or reflection_lm is not None\"",
        "pr_file_module": null
      },
      {
        "comment_id": "2317582523",
        "repo_full_name": "stanfordnlp/dspy",
        "pr_number": 8737,
        "pr_file": "dspy/teleprompt/gepa/gepa.py",
        "discussion_id": "2317184406",
        "commented_code": "@@ -309,11 +317,11 @@ def __init__(\n         self.max_full_evals = max_full_evals\n         self.max_metric_calls = max_metric_calls\n \n-        # Reflection based configuration\n+        # Reflection configuration\n         self.reflection_minibatch_size = reflection_minibatch_size\n         self.candidate_selection_strategy = candidate_selection_strategy\n-        # self.reflection_lm = reflection_lm\n         assert reflection_lm is not None, \"GEPA requires a reflection language model to be provided. Typically, you can use `dspy.LM(model='gpt-5', temperature=1.0, max_tokens=32000)` to get a good reflection model. Reflection LM is used by GEPA to reflect on the behavior of the program and propose new instructions, and will benefit from a strong model.\"",
        "comment_created_at": "2025-09-03T02:09:03+00:00",
        "comment_author": "andressrg",
        "comment_body": "sure. Done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2131697848",
    "pr_number": 8334,
    "pr_file": "dspy/predict/react.py",
    "created_at": "2025-06-06T07:50:11+00:00",
    "commented_code": "logger = logging.getLogger(__name__)\n \n+if TYPE_CHECKING:\n+    from dspy.signatures.signature import Signature\n+\n \n class ReAct(Module):\n-    def __init__(self, signature, tools: list[Callable], max_iters=5):\n+    def __init__(self, signature: Type[\"Signature\"], tools: list[Callable], max_iters: Optional[int] = 5):",
    "repo_full_name": "stanfordnlp/dspy",
    "discussion_comments": [
      {
        "comment_id": "2131697848",
        "repo_full_name": "stanfordnlp/dspy",
        "pr_number": 8334,
        "pr_file": "dspy/predict/react.py",
        "discussion_id": "2131697848",
        "commented_code": "@@ -10,11 +10,44 @@\n \n logger = logging.getLogger(__name__)\n \n+if TYPE_CHECKING:\n+    from dspy.signatures.signature import Signature\n+\n \n class ReAct(Module):\n-    def __init__(self, signature, tools: list[Callable], max_iters=5):\n+    def __init__(self, signature: Type[\"Signature\"], tools: list[Callable], max_iters: Optional[int] = 5):",
        "comment_created_at": "2025-06-06T07:50:11+00:00",
        "comment_author": "TomeHirata",
        "comment_body": "nit: no need to make the type of max_iters Optional since it has default value.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2125040011",
    "pr_number": 8296,
    "pr_file": "dspy/predict/code_act.py",
    "created_at": "2025-06-03T22:24:01+00:00",
    "commented_code": "self.codeact = dspy.Predict(codeact_signature)\n         self.extractor = dspy.ChainOfThought(extract_signature)\n         # It will raises exception when dspy cannot find available deno instance by now.\n-        self.interpreter = PythonInterpreter()\n-\n+        self.interpreter = interpreter if interpreter is not None else PythonInterpreter()",
    "repo_full_name": "stanfordnlp/dspy",
    "discussion_comments": [
      {
        "comment_id": "2125040011",
        "repo_full_name": "stanfordnlp/dspy",
        "pr_number": 8296,
        "pr_file": "dspy/predict/code_act.py",
        "discussion_id": "2125040011",
        "commented_code": "@@ -67,8 +67,7 @@ def factorial(n):\n         self.codeact = dspy.Predict(codeact_signature)\n         self.extractor = dspy.ChainOfThought(extract_signature)\n         # It will raises exception when dspy cannot find available deno instance by now.\n-        self.interpreter = PythonInterpreter()\n-\n+        self.interpreter = interpreter if interpreter is not None else PythonInterpreter()",
        "comment_created_at": "2025-06-03T22:24:01+00:00",
        "comment_author": "chenmoneygithub",
        "comment_body": "you can do:\r\n\r\n```\r\nself.interpreter = interpreter or PythonInterpreter()\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1518322348",
    "pr_number": 567,
    "pr_file": "dspy/backends/base.py",
    "created_at": "2024-03-08T21:32:06+00:00",
    "commented_code": "from abc import ABC, abstractmethod\n-import typing as t\n \n-from pydantic import BaseModel\n-from dspy.primitives.prediction import Completions\n-from dspy.primitives.example import Example\n+from pydantic import BaseModel, Field\n \n from dspy.signatures.signature import Signature, ensure_signature\n-\n-\n-class Completion:\n-    def __init__(self, example: Example, complete: bool):\n-        self.example = example\n-        self.complete = complete\n-\n-    def __len__(self) -> int:\n-        return len(self.example.keys())\n-\n-\n-def convert_to_completion(signature: Signature, example: Example) -> Completion:\n-    complete = True\n-    for field in signature.output_fields:\n-        if field not in example:\n-            complete = False\n-\n-    return Completion(example=example, complete=complete)\n-\n-\n-BackendEvent = t.TypeVar(\"BackendEvent\", bound=dict[str, t.Any])\n+from dspy.primitives.prediction import Completions\n \n \n class BaseBackend(BaseModel, ABC):\n     \"\"\"A backend takes a signature, its params, and returns a list of structured predictions.\"\"\"\n \n-    _history: t.List[BackendEvent] = []\n+    history: list[Completions] = Field(default=[])",
    "repo_full_name": "stanfordnlp/dspy",
    "discussion_comments": [
      {
        "comment_id": "1518322348",
        "repo_full_name": "stanfordnlp/dspy",
        "pr_number": 567,
        "pr_file": "dspy/backends/base.py",
        "discussion_id": "1518322348",
        "commented_code": "@@ -1,76 +1,42 @@\n from abc import ABC, abstractmethod\n-import typing as t\n \n-from pydantic import BaseModel\n-from dspy.primitives.prediction import Completions\n-from dspy.primitives.example import Example\n+from pydantic import BaseModel, Field\n \n from dspy.signatures.signature import Signature, ensure_signature\n-\n-\n-class Completion:\n-    def __init__(self, example: Example, complete: bool):\n-        self.example = example\n-        self.complete = complete\n-\n-    def __len__(self) -> int:\n-        return len(self.example.keys())\n-\n-\n-def convert_to_completion(signature: Signature, example: Example) -> Completion:\n-    complete = True\n-    for field in signature.output_fields:\n-        if field not in example:\n-            complete = False\n-\n-    return Completion(example=example, complete=complete)\n-\n-\n-BackendEvent = t.TypeVar(\"BackendEvent\", bound=dict[str, t.Any])\n+from dspy.primitives.prediction import Completions\n \n \n class BaseBackend(BaseModel, ABC):\n     \"\"\"A backend takes a signature, its params, and returns a list of structured predictions.\"\"\"\n \n-    _history: t.List[BackendEvent] = []\n+    history: list[Completions] = Field(default=[])",
        "comment_created_at": "2024-03-08T21:32:06+00:00",
        "comment_author": "CyrusNuevoDia",
        "comment_body": "Little bug here \u2014\u00a0you wanna do \r\n\r\n`Field(default_factory=list)`\r\n\r\nOtherwise it's the same mutable list being used as a default for all instantiated backends",
        "pr_file_module": null
      }
    ]
  }
]