[
  {
    "discussion_id": "2140299528",
    "pr_number": 16581,
    "pr_file": "test/sql/ordinality/ordinality_readcsv.test_slow",
    "created_at": "2025-06-11T14:09:36+00:00",
    "commented_code": "+# name: test/sql/ordinality/ordinality_readcsv.test_slow\n+# description: Test read_csv function for multiple chunks\n+# group: [ordinality]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+\n+query III\n+SELECT * FROM read_csv('test/sql/ordinality/a1.csv') WITH ORDINALITY ORDER BY Numbers,Chars,ordinality;\n+----\n+7800 values hashing to d86e8a5e8df33cec28e0ed7b6c386419",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2140299528",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 16581,
        "pr_file": "test/sql/ordinality/ordinality_readcsv.test_slow",
        "discussion_id": "2140299528",
        "commented_code": "@@ -0,0 +1,18 @@\n+# name: test/sql/ordinality/ordinality_readcsv.test_slow\n+# description: Test read_csv function for multiple chunks\n+# group: [ordinality]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+\n+query III\n+SELECT * FROM read_csv('test/sql/ordinality/a1.csv') WITH ORDINALITY ORDER BY Numbers,Chars,ordinality;\n+----\n+7800 values hashing to d86e8a5e8df33cec28e0ed7b6c386419",
        "comment_created_at": "2025-06-11T14:09:36+00:00",
        "comment_author": "Mytherin",
        "comment_body": "In general we prefer to avoid using the hash comparison feature - we can verify two results are the same using the labeled results, we can use that to verify results instead, e.g.:\r\n\r\n```sql\r\nquery III nosort read_csv_result\r\nSELECT * FROM read_csv('test/sql/ordinality/a1.csv') WITH ORDINALITY ORDER BY Numbers,Chars,ordinality;\r\n\r\nquery III nosort read_csv_result\r\nSELECT *, row_number() OVER () AS ordinality FROM read_csv('test/sql/ordinality/a1.csv') ORDER BY Numbers,Chars,ordinality;\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2218868175",
    "pr_number": 18327,
    "pr_file": "test/optimizer/unused_columns/deliver_child_columns.test",
    "created_at": "2025-07-21T11:10:09+00:00",
    "commented_code": "+# name: test/optimizer/unused_columns/deliver_child_columns.test\n+# description: deliver child columns in RemoveUnusedColumns optimizer\n+# group: [unused_columns]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+create table t (s struct(c1 varchar, c2 integer));\n+\n+statement ok\n+insert into t values(('c1', 1));\n+\n+statement ok\n+create or replace view test as select * from t;\n+\n+query II\n+explain select s.c1 from test;\n+----\n+physical_plan\t<REGEX>:.*SEQ_SCAN.*Projections: s.c1.*",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2218868175",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18327,
        "pr_file": "test/optimizer/unused_columns/deliver_child_columns.test",
        "discussion_id": "2218868175",
        "commented_code": "@@ -0,0 +1,20 @@\n+# name: test/optimizer/unused_columns/deliver_child_columns.test\n+# description: deliver child columns in RemoveUnusedColumns optimizer\n+# group: [unused_columns]\n+\n+statement ok\n+PRAGMA enable_verification\n+\n+statement ok\n+create table t (s struct(c1 varchar, c2 integer));\n+\n+statement ok\n+insert into t values(('c1', 1));\n+\n+statement ok\n+create or replace view test as select * from t;\n+\n+query II\n+explain select s.c1 from test;\n+----\n+physical_plan\t<REGEX>:.*SEQ_SCAN.*Projections: s.c1.*",
        "comment_created_at": "2025-07-21T11:10:09+00:00",
        "comment_author": "Mytherin",
        "comment_body": "We should execute the query here - not just check the plan. \r\n\r\nWe should add more tests here:\r\n\r\nWhat if the view already has references to subsets of columns?\r\n\r\n```sql\r\ncreate or replace view test as select s.c1, s.c2, s from t;\r\nselect s1.c2, s2.c1 from test;\r\n```\r\n\r\nWhat if the view contains the same reference multiple times?\r\n\r\n```sql\r\ncreate or replace view test as select s s1, s s2 from t;\r\nselect s1.c2, s2.c1 from test;\r\n```\r\n\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2198258432",
    "pr_number": 18203,
    "pr_file": "test/sql/storage/compression/dict_fsst/test_dict_fsst_with_smaller_block_size.test",
    "created_at": "2025-07-10T17:03:31+00:00",
    "commented_code": "+# name: test/sql/storage/compression/dict_fsst/test_dict_fsst_with_smaller_block_size.test\n+# description: Test storage with dictionary compression and a smaller block size.\n+# group: [dict_fsst]\n+\n+statement ok\n+SET storage_compatibility_version='latest';\n+\n+statement ok\n+ATTACH '__TEST_DIR__/partial_manager.db' AS db (BLOCK_SIZE 16384);\n+\n+statement ok",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2198258432",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18203,
        "pr_file": "test/sql/storage/compression/dict_fsst/test_dict_fsst_with_smaller_block_size.test",
        "discussion_id": "2198258432",
        "commented_code": "@@ -0,0 +1,12 @@\n+# name: test/sql/storage/compression/dict_fsst/test_dict_fsst_with_smaller_block_size.test\n+# description: Test storage with dictionary compression and a smaller block size.\n+# group: [dict_fsst]\n+\n+statement ok\n+SET storage_compatibility_version='latest';\n+\n+statement ok\n+ATTACH '__TEST_DIR__/partial_manager.db' AS db (BLOCK_SIZE 16384);\n+\n+statement ok",
        "comment_created_at": "2025-07-10T17:03:31+00:00",
        "comment_author": "Tishj",
        "comment_body": "Does this contain nulls?\r\nDon't we need a \"restart\" to verify correctness on reload?\r\n\r\n~~This test also doesnt have a `load` so it's not actually testing any storage~~",
        "pr_file_module": null
      },
      {
        "comment_id": "2199859069",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18203,
        "pr_file": "test/sql/storage/compression/dict_fsst/test_dict_fsst_with_smaller_block_size.test",
        "discussion_id": "2198258432",
        "commented_code": "@@ -0,0 +1,12 @@\n+# name: test/sql/storage/compression/dict_fsst/test_dict_fsst_with_smaller_block_size.test\n+# description: Test storage with dictionary compression and a smaller block size.\n+# group: [dict_fsst]\n+\n+statement ok\n+SET storage_compatibility_version='latest';\n+\n+statement ok\n+ATTACH '__TEST_DIR__/partial_manager.db' AS db (BLOCK_SIZE 16384);\n+\n+statement ok",
        "comment_created_at": "2025-07-11T07:15:05+00:00",
        "comment_author": "taniabogatsch",
        "comment_body": "It auto-checkpoints the attached database during the `CREATE TABLE`, which is where the serialization is tipped off (with the new assertion triggering on writing empty partial blocks instead of only when reading them later).\r\n\r\nI can add a `DETACH`, but it should not matter, as the assertion fails before getting there.",
        "pr_file_module": null
      },
      {
        "comment_id": "2199904383",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18203,
        "pr_file": "test/sql/storage/compression/dict_fsst/test_dict_fsst_with_smaller_block_size.test",
        "discussion_id": "2198258432",
        "commented_code": "@@ -0,0 +1,12 @@\n+# name: test/sql/storage/compression/dict_fsst/test_dict_fsst_with_smaller_block_size.test\n+# description: Test storage with dictionary compression and a smaller block size.\n+# group: [dict_fsst]\n+\n+statement ok\n+SET storage_compatibility_version='latest';\n+\n+statement ok\n+ATTACH '__TEST_DIR__/partial_manager.db' AS db (BLOCK_SIZE 16384);\n+\n+statement ok",
        "comment_created_at": "2025-07-11T07:31:11+00:00",
        "comment_author": "Tishj",
        "comment_body": "Can we verify that the created table contains nulls and non-nulls?\r\n\r\nAlso scan the table, as that might otherwise hide a bug that is only triggered when the segments are read",
        "pr_file_module": null
      },
      {
        "comment_id": "2199908933",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18203,
        "pr_file": "test/sql/storage/compression/dict_fsst/test_dict_fsst_with_smaller_block_size.test",
        "discussion_id": "2198258432",
        "commented_code": "@@ -0,0 +1,12 @@\n+# name: test/sql/storage/compression/dict_fsst/test_dict_fsst_with_smaller_block_size.test\n+# description: Test storage with dictionary compression and a smaller block size.\n+# group: [dict_fsst]\n+\n+statement ok\n+SET storage_compatibility_version='latest';\n+\n+statement ok\n+ATTACH '__TEST_DIR__/partial_manager.db' AS db (BLOCK_SIZE 16384);\n+\n+statement ok",
        "comment_created_at": "2025-07-11T07:32:51+00:00",
        "comment_author": "Tishj",
        "comment_body": "Also, doesn't it only auto-checkpoint if the WAL threshold is reached?",
        "pr_file_module": null
      },
      {
        "comment_id": "2199946781",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18203,
        "pr_file": "test/sql/storage/compression/dict_fsst/test_dict_fsst_with_smaller_block_size.test",
        "discussion_id": "2198258432",
        "commented_code": "@@ -0,0 +1,12 @@\n+# name: test/sql/storage/compression/dict_fsst/test_dict_fsst_with_smaller_block_size.test\n+# description: Test storage with dictionary compression and a smaller block size.\n+# group: [dict_fsst]\n+\n+statement ok\n+SET storage_compatibility_version='latest';\n+\n+statement ok\n+ATTACH '__TEST_DIR__/partial_manager.db' AS db (BLOCK_SIZE 16384);\n+\n+statement ok",
        "comment_created_at": "2025-07-11T07:49:41+00:00",
        "comment_author": "taniabogatsch",
        "comment_body": "> Can we verify that the created table contains nulls and non-nulls?\r\n> Also scan the table, as that might otherwise hide a bug that is only triggered when the segments are read\r\n\r\nGood call, will do \ud83d\udc4d \r\n\r\n> Also, doesn't it only auto-checkpoint if the WAL threshold is reached?\r\n\r\nHmm, it was checkpointing on my breakpoint, I didn't dive to deep into the why. \ud83d\ude05 But yes, it auto-checkpoints, if the WAL threshold is exceeded. Anyways, I'll just add a `DETACH` and `reATTACH` to be sure. ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2039130456",
    "pr_number": 17045,
    "pr_file": "test/optimizer/pushdown/issue_17042.test",
    "created_at": "2025-04-11T09:04:26+00:00",
    "commented_code": "+# name: test/optimizer/pushdown/issue_17042.test\n+# description: Test left join filter lost in filter pushdown\n+# group: [pushdown]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE  TABLE  t2(c1 INTEGER);\n+\n+statement ok\n+CREATE  TABLE  t0(c1 DOUBLE);\n+\n+statement ok\n+INSERT INTO t0(c1) VALUES (0.1);\n+\n+statement ok\n+INSERT INTO t2(c1) VALUES (2);\n+\n+query II\n+SELECT * FROM t2 LEFT JOIN t0 ON true WHERE ((t0.c1<t2.c1) IS NULL);",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2039130456",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 17045,
        "pr_file": "test/optimizer/pushdown/issue_17042.test",
        "discussion_id": "2039130456",
        "commented_code": "@@ -0,0 +1,22 @@\n+# name: test/optimizer/pushdown/issue_17042.test\n+# description: Test left join filter lost in filter pushdown\n+# group: [pushdown]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE  TABLE  t2(c1 INTEGER);\n+\n+statement ok\n+CREATE  TABLE  t0(c1 DOUBLE);\n+\n+statement ok\n+INSERT INTO t0(c1) VALUES (0.1);\n+\n+statement ok\n+INSERT INTO t2(c1) VALUES (2);\n+\n+query II\n+SELECT * FROM t2 LEFT JOIN t0 ON true WHERE ((t0.c1<t2.c1) IS NULL);",
        "comment_created_at": "2025-04-11T09:04:26+00:00",
        "comment_author": "Tmonster",
        "comment_body": "Can you also add a test case where there is expected data?\r\n\r\nAnd another one where the join is turned into an inner join because another filter does remove NULLS? And then check that both filters are present in the plan? Something like below should work,\r\n\r\n```\r\nINSERT INTO t2(c1) VALUES (2), (4), (8), (9), (10), (NULL);\r\nexplain SELECT * FROM t2 LEFT JOIN t0 ON true WHERE (t0.c1 is distinct from t2.c1) and (t2.c1 > t0.c1);\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2039249293",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 17045,
        "pr_file": "test/optimizer/pushdown/issue_17042.test",
        "discussion_id": "2039130456",
        "commented_code": "@@ -0,0 +1,22 @@\n+# name: test/optimizer/pushdown/issue_17042.test\n+# description: Test left join filter lost in filter pushdown\n+# group: [pushdown]\n+\n+statement ok\n+pragma enable_verification\n+\n+statement ok\n+CREATE  TABLE  t2(c1 INTEGER);\n+\n+statement ok\n+CREATE  TABLE  t0(c1 DOUBLE);\n+\n+statement ok\n+INSERT INTO t0(c1) VALUES (0.1);\n+\n+statement ok\n+INSERT INTO t2(c1) VALUES (2);\n+\n+query II\n+SELECT * FROM t2 LEFT JOIN t0 ON true WHERE ((t0.c1<t2.c1) IS NULL);",
        "comment_created_at": "2025-04-11T10:15:29+00:00",
        "comment_author": "Damon07",
        "comment_body": "Done.",
        "pr_file_module": null
      }
    ]
  }
]