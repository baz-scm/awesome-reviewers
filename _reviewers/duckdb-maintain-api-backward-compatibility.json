[
  {
    "discussion_id": "2048292614",
    "pr_number": 17081,
    "pr_file": "src/include/duckdb.h",
    "created_at": "2025-04-17T06:03:43+00:00",
    "commented_code": "DUCKDB_C_API duckdb_vector duckdb_array_vector_get_child(duckdb_vector vector);\n \n /*!\n-Slice a vector with a selection vector.\n+Creates a dictionary vector from a vector and a selection mask, the resulting vector will have length `len`.\n \n-The max value in the selection vector must be less than the length of the vector\n-\n-The resulting vector happens to be a dictionary vector.\n-\n-* @param vector The vector which is to become a dictionary\n+* @param dict_size The size of the `dict_values`\n * @param selection The selection vector\n * @param len The length of the selection vector\n */\n-DUCKDB_C_API void duckdb_slice_vector(duckdb_vector vector, duckdb_selection_vector selection, idx_t len);\n+DUCKDB_C_API void duckdb_slice_vector(duckdb_vector vector, idx_t dict_size, duckdb_selection_vector selection,",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2048292614",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 17081,
        "pr_file": "src/include/duckdb.h",
        "discussion_id": "2048292614",
        "commented_code": "@@ -3060,17 +3060,14 @@ The resulting vector has the size of the parent vector multiplied by the array s\n DUCKDB_C_API duckdb_vector duckdb_array_vector_get_child(duckdb_vector vector);\n \n /*!\n-Slice a vector with a selection vector.\n+Creates a dictionary vector from a vector and a selection mask, the resulting vector will have length `len`.\n \n-The max value in the selection vector must be less than the length of the vector\n-\n-The resulting vector happens to be a dictionary vector.\n-\n-* @param vector The vector which is to become a dictionary\n+* @param dict_size The size of the `dict_values`\n * @param selection The selection vector\n * @param len The length of the selection vector\n */\n-DUCKDB_C_API void duckdb_slice_vector(duckdb_vector vector, duckdb_selection_vector selection, idx_t len);\n+DUCKDB_C_API void duckdb_slice_vector(duckdb_vector vector, idx_t dict_size, duckdb_selection_vector selection,",
        "comment_created_at": "2025-04-17T06:03:43+00:00",
        "comment_author": "Mytherin",
        "comment_body": "Instead of modifying `duckdb_slice_vector`, maybe we can add a separate method `duckdb_vector_slice_dictionary` that does this?",
        "pr_file_module": null
      },
      {
        "comment_id": "2048981730",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 17081,
        "pr_file": "src/include/duckdb.h",
        "discussion_id": "2048292614",
        "commented_code": "@@ -3060,17 +3060,14 @@ The resulting vector has the size of the parent vector multiplied by the array s\n DUCKDB_C_API duckdb_vector duckdb_array_vector_get_child(duckdb_vector vector);\n \n /*!\n-Slice a vector with a selection vector.\n+Creates a dictionary vector from a vector and a selection mask, the resulting vector will have length `len`.\n \n-The max value in the selection vector must be less than the length of the vector\n-\n-The resulting vector happens to be a dictionary vector.\n-\n-* @param vector The vector which is to become a dictionary\n+* @param dict_size The size of the `dict_values`\n * @param selection The selection vector\n * @param len The length of the selection vector\n */\n-DUCKDB_C_API void duckdb_slice_vector(duckdb_vector vector, duckdb_selection_vector selection, idx_t len);\n+DUCKDB_C_API void duckdb_slice_vector(duckdb_vector vector, idx_t dict_size, duckdb_selection_vector selection,",
        "comment_created_at": "2025-04-17T13:41:01+00:00",
        "comment_author": "joseph-isaacs",
        "comment_body": "sure",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2241987404",
    "pr_number": 18438,
    "pr_file": "extension/parquet/include/thrift_tools.hpp",
    "created_at": "2025-07-30T08:59:00+00:00",
    "commented_code": "if (read_head.GetEnd() > file_handle.GetFileSize()) {\n \t\t\t\tthrow std::runtime_error(\"Prefetch registered requested for bytes outside file\");\n \t\t\t}\n-\t\t\tread_head.buffer_handle = file_handle.Read(read_head.buffer_ptr, read_head.size, read_head.location);\n+\t\t\tread_head.buffer_handle =\n+\t\t\t    file_handle.Read(QueryContext(), read_head.buffer_ptr, read_head.size, read_head.location);",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2241987404",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18438,
        "pr_file": "extension/parquet/include/thrift_tools.hpp",
        "discussion_id": "2241987404",
        "commented_code": "@@ -118,7 +118,8 @@ struct ReadAheadBuffer {\n \t\t\tif (read_head.GetEnd() > file_handle.GetFileSize()) {\n \t\t\t\tthrow std::runtime_error(\"Prefetch registered requested for bytes outside file\");\n \t\t\t}\n-\t\t\tread_head.buffer_handle = file_handle.Read(read_head.buffer_ptr, read_head.size, read_head.location);\n+\t\t\tread_head.buffer_handle =\n+\t\t\t    file_handle.Read(QueryContext(), read_head.buffer_ptr, read_head.size, read_head.location);",
        "comment_created_at": "2025-07-30T08:59:00+00:00",
        "comment_author": "taniabogatsch",
        "comment_body": "Should we consider two functions for `FileHandle::Read`? One with, and one without the `QueryContext`? That way, we avoid breaking extensions.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2212616659",
    "pr_number": 18246,
    "pr_file": "src/include/duckdb.h",
    "created_at": "2025-07-17T08:04:40+00:00",
    "commented_code": "// Arrow Interface\n //===--------------------------------------------------------------------===//\n \n+/*!\n+Transforms a DuckDB Schema into an Arrow Schema\n+\n+* @param client_properties The client properties to extract the arrow settings from.\n+* @param types The DuckDB Logical Types for each column in the schema.\n+* @param names The names for each column in the schema.\n+* @param column_count The number of columns that exist in the schema.\n+* @param out_schema The resulting arrow schema. Must be destroyed with `out_schema->release(out_schema)`.\n+* @return The error data.\n+*/\n+DUCKDB_C_API duckdb_error_data duckdb_to_arrow_schema(duckdb_client_properties client_properties,\n+                                                      duckdb_logical_type *types, char **names, idx_t column_count,\n+                                                      struct ArrowSchema *out_schema);\n+\n+/*!\n+Transforms a DuckDB data chunk into an Arrow array.\n+\n+* @param client_properties The client properties to extract the Arrow settings from.\n+* @param chunk The DuckDB data chunk to convert.\n+* @param out_arrow_array The output Arrow structure that will hold the converted data. Must be released with\n+`out_arrow_array->release(out_arrow_array)`\n+* @return The error data.\n+*/\n+DUCKDB_C_API duckdb_error_data duckdb_data_chunk_to_arrow(duckdb_client_properties client_properties,\n+                                                          duckdb_data_chunk chunk, struct ArrowArray *out_arrow_array);\n+\n+/*!\n+Transforms an Arrow Schema into a DuckDB Schema.\n+\n+* @param connection The connection to get the transformation settings from.\n+* @param schema The input Arrow schema. Must be released with `schema->release(schema)`.\n+* @param out_types The Arrow converted schema with extra information about the Arrow Types. Must be destroyed with\n+`duckdb_destroy_arrow_converted_schema`.\n+* @param out_names The resulting column names array. Must be appropriately deleted.",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2212616659",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18246,
        "pr_file": "src/include/duckdb.h",
        "discussion_id": "2212616659",
        "commented_code": "@@ -4485,6 +4528,69 @@ DUCKDB_C_API char *duckdb_table_description_get_column_name(duckdb_table_descrip\n // Arrow Interface\n //===--------------------------------------------------------------------===//\n \n+/*!\n+Transforms a DuckDB Schema into an Arrow Schema\n+\n+* @param client_properties The client properties to extract the arrow settings from.\n+* @param types The DuckDB Logical Types for each column in the schema.\n+* @param names The names for each column in the schema.\n+* @param column_count The number of columns that exist in the schema.\n+* @param out_schema The resulting arrow schema. Must be destroyed with `out_schema->release(out_schema)`.\n+* @return The error data.\n+*/\n+DUCKDB_C_API duckdb_error_data duckdb_to_arrow_schema(duckdb_client_properties client_properties,\n+                                                      duckdb_logical_type *types, char **names, idx_t column_count,\n+                                                      struct ArrowSchema *out_schema);\n+\n+/*!\n+Transforms a DuckDB data chunk into an Arrow array.\n+\n+* @param client_properties The client properties to extract the Arrow settings from.\n+* @param chunk The DuckDB data chunk to convert.\n+* @param out_arrow_array The output Arrow structure that will hold the converted data. Must be released with\n+`out_arrow_array->release(out_arrow_array)`\n+* @return The error data.\n+*/\n+DUCKDB_C_API duckdb_error_data duckdb_data_chunk_to_arrow(duckdb_client_properties client_properties,\n+                                                          duckdb_data_chunk chunk, struct ArrowArray *out_arrow_array);\n+\n+/*!\n+Transforms an Arrow Schema into a DuckDB Schema.\n+\n+* @param connection The connection to get the transformation settings from.\n+* @param schema The input Arrow schema. Must be released with `schema->release(schema)`.\n+* @param out_types The Arrow converted schema with extra information about the Arrow Types. Must be destroyed with\n+`duckdb_destroy_arrow_converted_schema`.\n+* @param out_names The resulting column names array. Must be appropriately deleted.",
        "comment_created_at": "2025-07-17T08:04:40+00:00",
        "comment_author": "Mytherin",
        "comment_body": "The `out_names` here is problematic for various reasons:\r\n\r\n* \"Must be appropriately deleted\" is unclear \r\n* It is not actually possible to appropriately delete - given that the out_names are allocated with `new` which has no equivalent in the C API. Anything that requires the user to delete it should be allocated with `duckdb_malloc` so it can be freed with `duckdb_free`\r\n* I wonder if the `out_names` and `out_column_count` are required to begin with? We are already emitting an opaque object (`duckdb_arrow_converted_schema`). Can we not store the names/column count in that opaque object and expose them using accessors?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2140456918",
    "pr_number": 17870,
    "pr_file": "src/include/duckdb/common/types/data_chunk.hpp",
    "created_at": "2025-06-11T15:12:01+00:00",
    "commented_code": "DUCKDB_API void Copy(DataChunk &other, const SelectionVector &sel, const idx_t source_count,\n \t                     const idx_t offset = 0) const;\n \n+\t//! Copies the data from this chunk to another chunk but only for the columns specified\n+\tDUCKDB_API void Copy(DataChunk &other, const SelectionVector &sel, const idx_t source_count, const idx_t offset,\n+\t                     const vector<column_t> &column_ids) const;\n+",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2140456918",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 17870,
        "pr_file": "src/include/duckdb/common/types/data_chunk.hpp",
        "discussion_id": "2140456918",
        "commented_code": "@@ -114,6 +114,10 @@ class DataChunk {\n \tDUCKDB_API void Copy(DataChunk &other, const SelectionVector &sel, const idx_t source_count,\n \t                     const idx_t offset = 0) const;\n \n+\t//! Copies the data from this chunk to another chunk but only for the columns specified\n+\tDUCKDB_API void Copy(DataChunk &other, const SelectionVector &sel, const idx_t source_count, const idx_t offset,\n+\t                     const vector<column_t> &column_ids) const;\n+",
        "comment_created_at": "2025-06-11T15:12:01+00:00",
        "comment_author": "taniabogatsch",
        "comment_body": "I'm unsure about exposing a helper function on the C++ / `DataChunk` side - could we instead expose `VectorOperations::Copy` in the C API? Together with `duckdb_data_chunk_get_vector`, we should then be able to achieve the same behaviour as this new helper function?",
        "pr_file_module": null
      },
      {
        "comment_id": "2140759090",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 17870,
        "pr_file": "src/include/duckdb/common/types/data_chunk.hpp",
        "discussion_id": "2140456918",
        "commented_code": "@@ -114,6 +114,10 @@ class DataChunk {\n \tDUCKDB_API void Copy(DataChunk &other, const SelectionVector &sel, const idx_t source_count,\n \t                     const idx_t offset = 0) const;\n \n+\t//! Copies the data from this chunk to another chunk but only for the columns specified\n+\tDUCKDB_API void Copy(DataChunk &other, const SelectionVector &sel, const idx_t source_count, const idx_t offset,\n+\t                     const vector<column_t> &column_ids) const;\n+",
        "comment_created_at": "2025-06-11T17:50:22+00:00",
        "comment_author": "abramk",
        "comment_body": "I was a bit apprehensive about the new C++ api myself - it seemed too specialized. Your idea is excellent. I've made the change.",
        "pr_file_module": null
      }
    ]
  }
]