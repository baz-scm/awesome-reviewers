[
  {
    "discussion_id": "1926969443",
    "pr_number": 15782,
    "pr_file": "src/main/capi/prepared-c.cpp",
    "created_at": "2025-01-23T13:20:58+00:00",
    "commented_code": "return nullptr;\n }\n \n+idx_t duckdb_prepared_column_count(duckdb_prepared_statement statement) {\n+\tauto wrapper = reinterpret_cast<PreparedStatementWrapper *>(statement);\n+\tif (!wrapper || !wrapper->statement || wrapper->statement->HasError()) {\n+\t\treturn 0;\n+\t}\n+\treturn wrapper->statement->ColumnCount();\n+}\n+\n+const char *duckdb_prepared_column_name(duckdb_prepared_statement statement, idx_t field_idx) {",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "1926969443",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 15782,
        "pr_file": "src/main/capi/prepared-c.cpp",
        "discussion_id": "1926969443",
        "commented_code": "@@ -159,6 +159,49 @@ duckdb_logical_type duckdb_param_logical_type(duckdb_prepared_statement prepared\n \treturn nullptr;\n }\n \n+idx_t duckdb_prepared_column_count(duckdb_prepared_statement statement) {\n+\tauto wrapper = reinterpret_cast<PreparedStatementWrapper *>(statement);\n+\tif (!wrapper || !wrapper->statement || wrapper->statement->HasError()) {\n+\t\treturn 0;\n+\t}\n+\treturn wrapper->statement->ColumnCount();\n+}\n+\n+const char *duckdb_prepared_column_name(duckdb_prepared_statement statement, idx_t field_idx) {",
        "comment_created_at": "2025-01-23T13:20:58+00:00",
        "comment_author": "taniabogatsch",
        "comment_body": "Nit: let's call this `column_idx` instead of `field_idx`. Same for the other functions.",
        "pr_file_module": null
      },
      {
        "comment_id": "1926998019",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 15782,
        "pr_file": "src/main/capi/prepared-c.cpp",
        "discussion_id": "1926969443",
        "commented_code": "@@ -159,6 +159,49 @@ duckdb_logical_type duckdb_param_logical_type(duckdb_prepared_statement prepared\n \treturn nullptr;\n }\n \n+idx_t duckdb_prepared_column_count(duckdb_prepared_statement statement) {\n+\tauto wrapper = reinterpret_cast<PreparedStatementWrapper *>(statement);\n+\tif (!wrapper || !wrapper->statement || wrapper->statement->HasError()) {\n+\t\treturn 0;\n+\t}\n+\treturn wrapper->statement->ColumnCount();\n+}\n+\n+const char *duckdb_prepared_column_name(duckdb_prepared_statement statement, idx_t field_idx) {",
        "comment_created_at": "2025-01-23T13:41:24+00:00",
        "comment_author": "fanyang01",
        "comment_body": "Thank you for pointing that out. I've updated the variable name to column_idx as suggested. The same change has been applied to the other functions.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2182910364",
    "pr_number": 18135,
    "pr_file": "src/execution/operator/persistent/physical_merge_into.cpp",
    "created_at": "2025-07-03T14:15:05+00:00",
    "commented_code": "+#include \"duckdb/execution/operator/persistent/physical_merge_into.hpp\"\n+#include \"duckdb/execution/expression_executor.hpp\"\n+#include \"duckdb/parser/statement/merge_into_statement.hpp\"\n+\n+namespace duckdb {\n+\n+PhysicalMergeInto::PhysicalMergeInto(PhysicalPlan &physical_plan, vector<LogicalType> types,\n+                                     map<MergeActionCondition, vector<unique_ptr<MergeIntoOperator>>> actions_p,\n+                                     idx_t row_id_index, optional_idx source_marker, bool parallel_p)\n+    : PhysicalOperator(physical_plan, PhysicalOperatorType::MERGE_INTO, std::move(types), 1),\n+      row_id_index(row_id_index), source_marker(source_marker), parallel(parallel_p) {\n+\n+\tmap<MergeActionCondition, MergeActionRange> ranges;\n+\tfor (auto &entry : actions_p) {\n+\t\tMergeActionRange range;\n+\t\trange.condition = entry.first;\n+\t\trange.start = actions.size();\n+\t\tfor (auto &action : entry.second) {\n+\t\t\tactions.push_back(std::move(action));\n+\t\t}\n+\t\trange.end = actions.size();\n+\t\tranges.emplace(entry.first, range);\n+\t}\n+\tmatch_actions = {MergeActionCondition::WHEN_MATCHED, MergeActionCondition::WHEN_NOT_MATCHED_BY_TARGET,\n+\t                 MergeActionCondition::WHEN_NOT_MATCHED_BY_SOURCE};\n+\tfor (idx_t i = 0; i < match_actions.size(); i++) {\n+\t\tauto entry = ranges.find(match_actions[i]);\n+\t\tMergeActionRange range;\n+\t\tif (entry != ranges.end()) {\n+\t\t\trange = entry->second;\n+\t\t}\n+\t\trange.condition = match_actions[i];\n+\t\taction_ranges.push_back(range);\n+\t}\n+}\n+\n+//===--------------------------------------------------------------------===//\n+// Sink\n+//===--------------------------------------------------------------------===//\n+struct MergeSinkState {\n+\tMergeSinkState() : selected_sel(STANDARD_VECTOR_SIZE), remaining_sel(STANDARD_VECTOR_SIZE) {\n+\t}\n+\n+\tbool computed_matches = false;\n+\tbool match_initialized = false;\n+\tidx_t match_idx = 0;\n+\tidx_t index_in_match = 0;\n+\tSelectionVector current_sel;\n+\tSelectionVector selected_sel;\n+\tSelectionVector remaining_sel;\n+\tidx_t current_count;\n+\tunique_ptr<DataChunk> sliced_chunk;\n+\toptional_ptr<DataChunk> input_chunk;\n+};\n+\n+struct MergeLocalExecutionState {\n+\tunique_ptr<LocalSinkState> local_state;\n+\tunique_ptr<ExpressionExecutor> condition_executor;\n+\tunique_ptr<ExpressionExecutor> insert_executor;\n+\tunique_ptr<DataChunk> insert_chunk;\n+};\n+\n+struct MatchResult {\n+\tMatchResult(ClientContext &context, const vector<LogicalType> &types) : sel(STANDARD_VECTOR_SIZE), count(0) {\n+\t\tchunk = make_uniq<DataChunk>();\n+\t\tchunk->Initialize(context, types);\n+\t}\n+\n+\tSelectionVector sel;\n+\tidx_t count;\n+\tunique_ptr<DataChunk> chunk;\n+};\n+\n+class MergeIntoLocalState : public LocalSinkState {\n+public:\n+\tMergeIntoLocalState(ExecutionContext &context, const PhysicalMergeInto &op) {\n+\t\tfor (auto &action : op.actions) {\n+\t\t\tMergeLocalExecutionState state;\n+\t\t\tif (action->op) {\n+\t\t\t\tstate.local_state = action->op->GetLocalSinkState(context);\n+\t\t\t}\n+\t\t\tif (action->condition) {\n+\t\t\t\tstate.condition_executor = make_uniq<ExpressionExecutor>(context.client, *action->condition);\n+\t\t\t}\n+\t\t\tif (!action->expressions.empty()) {\n+\t\t\t\tstate.insert_executor = make_uniq<ExpressionExecutor>(context.client, action->expressions);\n+\t\t\t\tvector<LogicalType> insert_types;\n+\t\t\t\tfor (auto &expr : action->expressions) {\n+\t\t\t\t\tinsert_types.push_back(expr->return_type);\n+\t\t\t\t}\n+\t\t\t\tstate.insert_chunk = make_uniq<DataChunk>();\n+\t\t\t\tstate.insert_chunk->Initialize(context.client, insert_types);\n+\t\t\t}\n+\n+\t\t\tstates.push_back(std::move(state));\n+\t\t}\n+\t\tfor (idx_t i = 0; i < 3; i++) {\n+\t\t\tmatch_results.emplace_back(context.client, op.children[0].get().types);\n+\t\t}\n+\t}\n+\n+\tMergeSinkState sink_state;\n+\tvector<MatchResult> match_results;\n+\tidx_t combine_idx = 0;\n+\tvector<MergeLocalExecutionState> states;\n+\tidx_t merged_count = 0;\n+};\n+\n+class MergeIntoGlobalState : public GlobalSinkState {\n+public:\n+\tMergeIntoGlobalState(ClientContext &context, const PhysicalMergeInto &op) : op(op) {\n+\t\tfor (auto &action : op.actions) {\n+\t\t\tsink_states.push_back(action->op ? action->op->GetGlobalSinkState(context) : nullptr);\n+\t\t}\n+\t\tmerged_count = 0;\n+\t}\n+\tconst PhysicalMergeInto &op;\n+\tidx_t finalize_idx = 0;\n+\tvector<unique_ptr<GlobalSinkState>> sink_states;\n+\tatomic<idx_t> merged_count;\n+\n+\toptional_ptr<DataChunk> ComputeActionInput(ClientContext &context, MergeIntoOperator &action, DataChunk &chunk,\n+\t                                           MergeIntoLocalState &local_state,\n+\t                                           MergeLocalExecutionState &local_action_state) {\n+\t\tauto &current_count = local_state.sink_state.current_count;\n+\t\tauto &current_sel = local_state.sink_state.current_sel;\n+\t\tauto &sliced_chunk = local_state.sink_state.sliced_chunk;\n+\t\tauto &selected_sel = local_state.sink_state.selected_sel;\n+\t\tauto &remaining_sel = local_state.sink_state.remaining_sel;\n+\t\tif (current_count == 0) {\n+\t\t\treturn nullptr;\n+\t\t}\n+\t\tif (!sliced_chunk) {\n+\t\t\tsliced_chunk = make_uniq<DataChunk>();\n+\t\t\tsliced_chunk->Initialize(context, chunk.GetTypes());\n+\t\t} else {\n+\t\t\tsliced_chunk->Reset();\n+\t\t}\n+\t\toptional_ptr<DataChunk> result;\n+\t\tif (action.condition) {\n+\t\t\t// if we have a condition we need to evaluate it\n+\t\t\tauto &executor = *local_action_state.condition_executor;\n+\t\t\tidx_t match_count =\n+\t\t\t    executor.SelectExpression(chunk, selected_sel, remaining_sel, current_sel, current_count);\n+\t\t\tif (match_count == 0) {\n+\t\t\t\t// no matches - move to next action\n+\t\t\t\treturn nullptr;\n+\t\t\t}\n+\t\t\t// slice the chunk for this action with the matching sel\n+\t\t\tsliced_chunk->Slice(chunk, selected_sel, match_count);\n+\t\t\tresult = sliced_chunk;\n+\n+\t\t\t// for the next chunk - update the matches\n+\t\t\tcurrent_count = current_count - match_count;\n+\t\t\tcurrent_sel.Initialize(remaining_sel);\n+\t\t} else if (current_count != chunk.size()) {\n+\t\t\t// if we have previously processed rows - remove them\n+\t\t\tsliced_chunk->Slice(chunk, current_sel, current_count);\n+\t\t\tresult = sliced_chunk;\n+\t\t} else {\n+\t\t\tresult = chunk;\n+\t\t}\n+\t\t// if we have any expressions - execute them to generate the new input chunk\n+\t\tif (!action.expressions.empty()) {\n+\t\t\tauto &insert_chunk = local_action_state.insert_chunk;\n+\t\t\tinsert_chunk->Reset();\n+\t\t\tlocal_action_state.insert_executor->Execute(*result, *insert_chunk);\n+\t\t\tresult = insert_chunk.get();\n+\t\t}\n+\t\tif (action.op) {\n+\t\t\tlocal_state.merged_count += result->size();\n+\t\t}\n+\t\treturn result;\n+\t}\n+\n+\tSinkResultType Sink(ExecutionContext &context, DataChunk &chunk, MergeIntoLocalState &local_state,\n+\t                    OperatorSinkInput &input, MergeActionRange range, idx_t &index_in_match) {\n+\t\tauto &input_chunk = local_state.sink_state.input_chunk;\n+\t\tfor (; range.start + index_in_match < range.end; index_in_match++) {\n+\t\t\tidx_t i = range.start + index_in_match;\n+\t\t\tauto &action = op.actions[i];\n+\t\t\tauto &local_action_state = local_state.states[i];\n+\t\t\tif (!input_chunk) {\n+\t\t\t\t// first time processing this action - compute the input chunk\n+\t\t\t\tinput_chunk = ComputeActionInput(context.client, *action, chunk, local_state, local_action_state);\n+\t\t\t\tif (!input_chunk) {\n+\t\t\t\t\t// no data for this action - move to next action\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\t// process the action\n+\t\t\tif (!action->op) {\n+\t\t\t\tif (action->action_type == MergeActionType::MERGE_ERROR) {\n+\t\t\t\t\t// abort - generate an error message\n+\t\t\t\t\tstring merge_condition;\n+\t\t\t\t\tmerge_condition += MergeIntoStatement::ActionConditionToString(range.condition);\n+\t\t\t\t\tif (action->condition) {\n+\t\t\t\t\t\tmerge_condition += \" AND \" + action->condition->ToString();\n+\t\t\t\t\t}\n+\t\t\t\t\tif (!action->expressions.empty()) {\n+\t\t\t\t\t\t// if there are any user-provided error messages: add the first error message encountered\n+\t\t\t\t\t\tmerge_condition += \": \" + input_chunk->data[0].GetValue(0).ToString();\n+\t\t\t\t\t}\n+\t\t\t\t\tthrow ConstraintException(\"Merge error condition %s\", merge_condition);\n+\t\t\t\t}\n+\t\t\t\tD_ASSERT(action->action_type == MergeActionType::MERGE_DO_NOTHING);\n+\t\t\t\tinput_chunk = nullptr;\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\t\t\tauto &gstate = sink_states[i];\n+\t\t\tauto &lstate = *local_action_state.local_state;\n+\t\t\tOperatorSinkInput sink_input {*gstate, lstate, input.interrupt_state};\n+\t\t\tauto result = action->op->Sink(context, *input_chunk, sink_input);\n+\t\t\tif (result == SinkResultType::BLOCKED) {\n+\t\t\t\treturn SinkResultType::BLOCKED;\n+\t\t\t}\n+\t\t\t// move to next action\n+\t\t\tinput_chunk = nullptr;\n+\t\t}\n+\t\treturn SinkResultType::NEED_MORE_INPUT;\n+\t}\n+\n+\tSinkCombineResultType Combine(ExecutionContext &context, MergeIntoLocalState &local_state,\n+\t                              OperatorSinkCombineInput &input) {\n+\t\tfor (; local_state.combine_idx < local_state.states.size(); ++local_state.combine_idx) {\n+\t\t\tauto &lstate = local_state.states[local_state.combine_idx];\n+\t\t\tauto &gstate = sink_states[local_state.combine_idx];\n+\t\t\tauto &action = op.actions[local_state.combine_idx];\n+\t\t\tif (!action->op) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\t\t\tOperatorSinkCombineInput combine_input {*gstate, *lstate.local_state, input.interrupt_state};\n+\t\t\tauto result = action->op->Combine(context, combine_input);\n+\t\t\tif (result == SinkCombineResultType::BLOCKED) {\n+\t\t\t\treturn SinkCombineResultType::BLOCKED;\n+\t\t\t}\n+\t\t}\n+\t\treturn SinkCombineResultType::FINISHED;\n+\t}\n+\n+\tSinkFinalizeType Finalize(Pipeline &pipeline, Event &event, ClientContext &context,\n+\t                          OperatorSinkFinalizeInput &input) {\n+\t\tfor (; finalize_idx < sink_states.size(); ++finalize_idx) {\n+\t\t\tauto &gstate = sink_states[finalize_idx];\n+\t\t\tauto &action = op.actions[finalize_idx];\n+\t\t\tif (!action->op) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\n+\t\t\tOperatorSinkFinalizeInput finalize_input {*gstate, input.interrupt_state};\n+\t\t\tauto result = action->op->Finalize(pipeline, event, context, finalize_input);\n+\t\t\tif (result == SinkFinalizeType::BLOCKED) {\n+\t\t\t\treturn SinkFinalizeType::BLOCKED;\n+\t\t\t}\n+\t\t}\n+\t\treturn SinkFinalizeType::READY;\n+\t}\n+};\n+\n+unique_ptr<GlobalSinkState> PhysicalMergeInto::GetGlobalSinkState(ClientContext &context) const {\n+\treturn make_uniq<MergeIntoGlobalState>(context, *this);\n+}\n+\n+unique_ptr<LocalSinkState> PhysicalMergeInto::GetLocalSinkState(ExecutionContext &context) const {\n+\treturn make_uniq<MergeIntoLocalState>(context, *this);\n+}\n+\n+idx_t PhysicalMergeInto::GetIndex(MergeActionCondition condition) const {\n+\tfor (idx_t i = 0; i < match_actions.size(); ++i) {\n+\t\tif (match_actions[i] == condition) {\n+\t\t\treturn i;\n+\t\t}\n+\t}\n+\tthrow InternalException(\"Unsupported match action condition\");\n+}\n+\n+void PhysicalMergeInto::ComputeMatches(MergeIntoLocalState &local_state, DataChunk &chunk) const {\n+\tauto &match_results = local_state.match_results;\n+\n+\t// for each row, figure out if we have generated a match or not\n+\tauto &matched = match_results[0];\n+\tauto &not_matched = match_results[1];\n+\tauto &not_matched_by_source = match_results[2];\n+\n+\tmatched.count = 0;\n+\tnot_matched.count = 0;\n+\tnot_matched_by_source.count = 0;\n+\n+\tUnifiedVectorFormat row_id_data;\n+\tchunk.data[row_id_index].ToUnifiedFormat(chunk.size(), row_id_data);\n+\tif (source_marker.IsValid()) {\n+\t\t// source marker - check both row id and source marker\n+\t\tUnifiedVectorFormat source_marker_data;\n+\t\tchunk.data[source_marker.GetIndex()].ToUnifiedFormat(chunk.size(), source_marker_data);\n+\t\tfor (idx_t i = 0; i < chunk.size(); i++) {\n+\t\t\tif (!source_marker_data.validity.RowIsValid(source_marker_data.sel->get_index(i))) {\n+\t\t\t\t// source marker is NULL - no source match\n+\t\t\t\tnot_matched_by_source.sel.set_index(not_matched_by_source.count++, i);\n+\t\t\t} else if (!row_id_data.validity.RowIsValid(row_id_data.sel->get_index(i))) {\n+\t\t\t\t// target marker is NULL - no target match\n+\t\t\t\tnot_matched.sel.set_index(not_matched.count++, i);\n+\t\t\t} else {\n+\t\t\t\t// match\n+\t\t\t\tmatched.sel.set_index(matched.count++, i);\n+\t\t\t}\n+\t\t}\n+\t} else {\n+\t\t// no source marker - only check row-ids\n+\t\tfor (idx_t i = 0; i < chunk.size(); i++) {\n+\t\t\tauto idx = row_id_data.sel->get_index(i);\n+\t\t\tif (row_id_data.validity.RowIsValid(idx)) {\n+\t\t\t\t// match\n+\t\t\t\tmatched.sel.set_index(matched.count++, i);\n+\t\t\t} else {\n+\t\t\t\t// no match\n+\t\t\t\tnot_matched.sel.set_index(not_matched.count++, i);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// reset and slice chunks\n+\tfor (auto &match : match_results) {\n+\t\tif (match.count == 0) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\tmatch.chunk->Reset();\n+\t\tmatch.chunk->Slice(chunk, match.sel, match.count);\n+\t}\n+}\n+\n+SinkResultType PhysicalMergeInto::Sink(ExecutionContext &context, DataChunk &chunk, OperatorSinkInput &input) const {\n+\tauto &global_state = input.global_state.Cast<MergeIntoGlobalState>();\n+\tauto &local_state = input.local_state.Cast<MergeIntoLocalState>();\n+\n+\tauto &match_results = local_state.match_results;\n+\tauto &computed_matches = local_state.sink_state.computed_matches;\n+\tauto &match_idx = local_state.sink_state.match_idx;\n+\tauto &index_in_match = local_state.sink_state.index_in_match;\n+\tauto &match_initialized = local_state.sink_state.match_initialized;\n+\tauto &current_sel = local_state.sink_state.current_sel;\n+\tauto &current_count = local_state.sink_state.current_count;\n+\tif (!computed_matches) {\n+\t\t// we haven't figured out which rows have which types of matches - compute them\n+\t\tComputeMatches(local_state, chunk);\n+\n+\t\t// set up the state so we can prepare sinking into the relevant operators\n+\t\tcomputed_matches = true;\n+\t\tmatch_idx = 0;\n+\t\tindex_in_match = 0;\n+\t\tmatch_initialized = false;\n+\t}\n+\t// now slice and call sink for each of the match conditions\n+\tfor (; match_idx < 3; match_idx++) {",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2182910364",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18135,
        "pr_file": "src/execution/operator/persistent/physical_merge_into.cpp",
        "discussion_id": "2182910364",
        "commented_code": "@@ -0,0 +1,411 @@\n+#include \"duckdb/execution/operator/persistent/physical_merge_into.hpp\"\n+#include \"duckdb/execution/expression_executor.hpp\"\n+#include \"duckdb/parser/statement/merge_into_statement.hpp\"\n+\n+namespace duckdb {\n+\n+PhysicalMergeInto::PhysicalMergeInto(PhysicalPlan &physical_plan, vector<LogicalType> types,\n+                                     map<MergeActionCondition, vector<unique_ptr<MergeIntoOperator>>> actions_p,\n+                                     idx_t row_id_index, optional_idx source_marker, bool parallel_p)\n+    : PhysicalOperator(physical_plan, PhysicalOperatorType::MERGE_INTO, std::move(types), 1),\n+      row_id_index(row_id_index), source_marker(source_marker), parallel(parallel_p) {\n+\n+\tmap<MergeActionCondition, MergeActionRange> ranges;\n+\tfor (auto &entry : actions_p) {\n+\t\tMergeActionRange range;\n+\t\trange.condition = entry.first;\n+\t\trange.start = actions.size();\n+\t\tfor (auto &action : entry.second) {\n+\t\t\tactions.push_back(std::move(action));\n+\t\t}\n+\t\trange.end = actions.size();\n+\t\tranges.emplace(entry.first, range);\n+\t}\n+\tmatch_actions = {MergeActionCondition::WHEN_MATCHED, MergeActionCondition::WHEN_NOT_MATCHED_BY_TARGET,\n+\t                 MergeActionCondition::WHEN_NOT_MATCHED_BY_SOURCE};\n+\tfor (idx_t i = 0; i < match_actions.size(); i++) {\n+\t\tauto entry = ranges.find(match_actions[i]);\n+\t\tMergeActionRange range;\n+\t\tif (entry != ranges.end()) {\n+\t\t\trange = entry->second;\n+\t\t}\n+\t\trange.condition = match_actions[i];\n+\t\taction_ranges.push_back(range);\n+\t}\n+}\n+\n+//===--------------------------------------------------------------------===//\n+// Sink\n+//===--------------------------------------------------------------------===//\n+struct MergeSinkState {\n+\tMergeSinkState() : selected_sel(STANDARD_VECTOR_SIZE), remaining_sel(STANDARD_VECTOR_SIZE) {\n+\t}\n+\n+\tbool computed_matches = false;\n+\tbool match_initialized = false;\n+\tidx_t match_idx = 0;\n+\tidx_t index_in_match = 0;\n+\tSelectionVector current_sel;\n+\tSelectionVector selected_sel;\n+\tSelectionVector remaining_sel;\n+\tidx_t current_count;\n+\tunique_ptr<DataChunk> sliced_chunk;\n+\toptional_ptr<DataChunk> input_chunk;\n+};\n+\n+struct MergeLocalExecutionState {\n+\tunique_ptr<LocalSinkState> local_state;\n+\tunique_ptr<ExpressionExecutor> condition_executor;\n+\tunique_ptr<ExpressionExecutor> insert_executor;\n+\tunique_ptr<DataChunk> insert_chunk;\n+};\n+\n+struct MatchResult {\n+\tMatchResult(ClientContext &context, const vector<LogicalType> &types) : sel(STANDARD_VECTOR_SIZE), count(0) {\n+\t\tchunk = make_uniq<DataChunk>();\n+\t\tchunk->Initialize(context, types);\n+\t}\n+\n+\tSelectionVector sel;\n+\tidx_t count;\n+\tunique_ptr<DataChunk> chunk;\n+};\n+\n+class MergeIntoLocalState : public LocalSinkState {\n+public:\n+\tMergeIntoLocalState(ExecutionContext &context, const PhysicalMergeInto &op) {\n+\t\tfor (auto &action : op.actions) {\n+\t\t\tMergeLocalExecutionState state;\n+\t\t\tif (action->op) {\n+\t\t\t\tstate.local_state = action->op->GetLocalSinkState(context);\n+\t\t\t}\n+\t\t\tif (action->condition) {\n+\t\t\t\tstate.condition_executor = make_uniq<ExpressionExecutor>(context.client, *action->condition);\n+\t\t\t}\n+\t\t\tif (!action->expressions.empty()) {\n+\t\t\t\tstate.insert_executor = make_uniq<ExpressionExecutor>(context.client, action->expressions);\n+\t\t\t\tvector<LogicalType> insert_types;\n+\t\t\t\tfor (auto &expr : action->expressions) {\n+\t\t\t\t\tinsert_types.push_back(expr->return_type);\n+\t\t\t\t}\n+\t\t\t\tstate.insert_chunk = make_uniq<DataChunk>();\n+\t\t\t\tstate.insert_chunk->Initialize(context.client, insert_types);\n+\t\t\t}\n+\n+\t\t\tstates.push_back(std::move(state));\n+\t\t}\n+\t\tfor (idx_t i = 0; i < 3; i++) {\n+\t\t\tmatch_results.emplace_back(context.client, op.children[0].get().types);\n+\t\t}\n+\t}\n+\n+\tMergeSinkState sink_state;\n+\tvector<MatchResult> match_results;\n+\tidx_t combine_idx = 0;\n+\tvector<MergeLocalExecutionState> states;\n+\tidx_t merged_count = 0;\n+};\n+\n+class MergeIntoGlobalState : public GlobalSinkState {\n+public:\n+\tMergeIntoGlobalState(ClientContext &context, const PhysicalMergeInto &op) : op(op) {\n+\t\tfor (auto &action : op.actions) {\n+\t\t\tsink_states.push_back(action->op ? action->op->GetGlobalSinkState(context) : nullptr);\n+\t\t}\n+\t\tmerged_count = 0;\n+\t}\n+\tconst PhysicalMergeInto &op;\n+\tidx_t finalize_idx = 0;\n+\tvector<unique_ptr<GlobalSinkState>> sink_states;\n+\tatomic<idx_t> merged_count;\n+\n+\toptional_ptr<DataChunk> ComputeActionInput(ClientContext &context, MergeIntoOperator &action, DataChunk &chunk,\n+\t                                           MergeIntoLocalState &local_state,\n+\t                                           MergeLocalExecutionState &local_action_state) {\n+\t\tauto &current_count = local_state.sink_state.current_count;\n+\t\tauto &current_sel = local_state.sink_state.current_sel;\n+\t\tauto &sliced_chunk = local_state.sink_state.sliced_chunk;\n+\t\tauto &selected_sel = local_state.sink_state.selected_sel;\n+\t\tauto &remaining_sel = local_state.sink_state.remaining_sel;\n+\t\tif (current_count == 0) {\n+\t\t\treturn nullptr;\n+\t\t}\n+\t\tif (!sliced_chunk) {\n+\t\t\tsliced_chunk = make_uniq<DataChunk>();\n+\t\t\tsliced_chunk->Initialize(context, chunk.GetTypes());\n+\t\t} else {\n+\t\t\tsliced_chunk->Reset();\n+\t\t}\n+\t\toptional_ptr<DataChunk> result;\n+\t\tif (action.condition) {\n+\t\t\t// if we have a condition we need to evaluate it\n+\t\t\tauto &executor = *local_action_state.condition_executor;\n+\t\t\tidx_t match_count =\n+\t\t\t    executor.SelectExpression(chunk, selected_sel, remaining_sel, current_sel, current_count);\n+\t\t\tif (match_count == 0) {\n+\t\t\t\t// no matches - move to next action\n+\t\t\t\treturn nullptr;\n+\t\t\t}\n+\t\t\t// slice the chunk for this action with the matching sel\n+\t\t\tsliced_chunk->Slice(chunk, selected_sel, match_count);\n+\t\t\tresult = sliced_chunk;\n+\n+\t\t\t// for the next chunk - update the matches\n+\t\t\tcurrent_count = current_count - match_count;\n+\t\t\tcurrent_sel.Initialize(remaining_sel);\n+\t\t} else if (current_count != chunk.size()) {\n+\t\t\t// if we have previously processed rows - remove them\n+\t\t\tsliced_chunk->Slice(chunk, current_sel, current_count);\n+\t\t\tresult = sliced_chunk;\n+\t\t} else {\n+\t\t\tresult = chunk;\n+\t\t}\n+\t\t// if we have any expressions - execute them to generate the new input chunk\n+\t\tif (!action.expressions.empty()) {\n+\t\t\tauto &insert_chunk = local_action_state.insert_chunk;\n+\t\t\tinsert_chunk->Reset();\n+\t\t\tlocal_action_state.insert_executor->Execute(*result, *insert_chunk);\n+\t\t\tresult = insert_chunk.get();\n+\t\t}\n+\t\tif (action.op) {\n+\t\t\tlocal_state.merged_count += result->size();\n+\t\t}\n+\t\treturn result;\n+\t}\n+\n+\tSinkResultType Sink(ExecutionContext &context, DataChunk &chunk, MergeIntoLocalState &local_state,\n+\t                    OperatorSinkInput &input, MergeActionRange range, idx_t &index_in_match) {\n+\t\tauto &input_chunk = local_state.sink_state.input_chunk;\n+\t\tfor (; range.start + index_in_match < range.end; index_in_match++) {\n+\t\t\tidx_t i = range.start + index_in_match;\n+\t\t\tauto &action = op.actions[i];\n+\t\t\tauto &local_action_state = local_state.states[i];\n+\t\t\tif (!input_chunk) {\n+\t\t\t\t// first time processing this action - compute the input chunk\n+\t\t\t\tinput_chunk = ComputeActionInput(context.client, *action, chunk, local_state, local_action_state);\n+\t\t\t\tif (!input_chunk) {\n+\t\t\t\t\t// no data for this action - move to next action\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\t// process the action\n+\t\t\tif (!action->op) {\n+\t\t\t\tif (action->action_type == MergeActionType::MERGE_ERROR) {\n+\t\t\t\t\t// abort - generate an error message\n+\t\t\t\t\tstring merge_condition;\n+\t\t\t\t\tmerge_condition += MergeIntoStatement::ActionConditionToString(range.condition);\n+\t\t\t\t\tif (action->condition) {\n+\t\t\t\t\t\tmerge_condition += \" AND \" + action->condition->ToString();\n+\t\t\t\t\t}\n+\t\t\t\t\tif (!action->expressions.empty()) {\n+\t\t\t\t\t\t// if there are any user-provided error messages: add the first error message encountered\n+\t\t\t\t\t\tmerge_condition += \": \" + input_chunk->data[0].GetValue(0).ToString();\n+\t\t\t\t\t}\n+\t\t\t\t\tthrow ConstraintException(\"Merge error condition %s\", merge_condition);\n+\t\t\t\t}\n+\t\t\t\tD_ASSERT(action->action_type == MergeActionType::MERGE_DO_NOTHING);\n+\t\t\t\tinput_chunk = nullptr;\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\t\t\tauto &gstate = sink_states[i];\n+\t\t\tauto &lstate = *local_action_state.local_state;\n+\t\t\tOperatorSinkInput sink_input {*gstate, lstate, input.interrupt_state};\n+\t\t\tauto result = action->op->Sink(context, *input_chunk, sink_input);\n+\t\t\tif (result == SinkResultType::BLOCKED) {\n+\t\t\t\treturn SinkResultType::BLOCKED;\n+\t\t\t}\n+\t\t\t// move to next action\n+\t\t\tinput_chunk = nullptr;\n+\t\t}\n+\t\treturn SinkResultType::NEED_MORE_INPUT;\n+\t}\n+\n+\tSinkCombineResultType Combine(ExecutionContext &context, MergeIntoLocalState &local_state,\n+\t                              OperatorSinkCombineInput &input) {\n+\t\tfor (; local_state.combine_idx < local_state.states.size(); ++local_state.combine_idx) {\n+\t\t\tauto &lstate = local_state.states[local_state.combine_idx];\n+\t\t\tauto &gstate = sink_states[local_state.combine_idx];\n+\t\t\tauto &action = op.actions[local_state.combine_idx];\n+\t\t\tif (!action->op) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\t\t\tOperatorSinkCombineInput combine_input {*gstate, *lstate.local_state, input.interrupt_state};\n+\t\t\tauto result = action->op->Combine(context, combine_input);\n+\t\t\tif (result == SinkCombineResultType::BLOCKED) {\n+\t\t\t\treturn SinkCombineResultType::BLOCKED;\n+\t\t\t}\n+\t\t}\n+\t\treturn SinkCombineResultType::FINISHED;\n+\t}\n+\n+\tSinkFinalizeType Finalize(Pipeline &pipeline, Event &event, ClientContext &context,\n+\t                          OperatorSinkFinalizeInput &input) {\n+\t\tfor (; finalize_idx < sink_states.size(); ++finalize_idx) {\n+\t\t\tauto &gstate = sink_states[finalize_idx];\n+\t\t\tauto &action = op.actions[finalize_idx];\n+\t\t\tif (!action->op) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\n+\t\t\tOperatorSinkFinalizeInput finalize_input {*gstate, input.interrupt_state};\n+\t\t\tauto result = action->op->Finalize(pipeline, event, context, finalize_input);\n+\t\t\tif (result == SinkFinalizeType::BLOCKED) {\n+\t\t\t\treturn SinkFinalizeType::BLOCKED;\n+\t\t\t}\n+\t\t}\n+\t\treturn SinkFinalizeType::READY;\n+\t}\n+};\n+\n+unique_ptr<GlobalSinkState> PhysicalMergeInto::GetGlobalSinkState(ClientContext &context) const {\n+\treturn make_uniq<MergeIntoGlobalState>(context, *this);\n+}\n+\n+unique_ptr<LocalSinkState> PhysicalMergeInto::GetLocalSinkState(ExecutionContext &context) const {\n+\treturn make_uniq<MergeIntoLocalState>(context, *this);\n+}\n+\n+idx_t PhysicalMergeInto::GetIndex(MergeActionCondition condition) const {\n+\tfor (idx_t i = 0; i < match_actions.size(); ++i) {\n+\t\tif (match_actions[i] == condition) {\n+\t\t\treturn i;\n+\t\t}\n+\t}\n+\tthrow InternalException(\"Unsupported match action condition\");\n+}\n+\n+void PhysicalMergeInto::ComputeMatches(MergeIntoLocalState &local_state, DataChunk &chunk) const {\n+\tauto &match_results = local_state.match_results;\n+\n+\t// for each row, figure out if we have generated a match or not\n+\tauto &matched = match_results[0];\n+\tauto &not_matched = match_results[1];\n+\tauto &not_matched_by_source = match_results[2];\n+\n+\tmatched.count = 0;\n+\tnot_matched.count = 0;\n+\tnot_matched_by_source.count = 0;\n+\n+\tUnifiedVectorFormat row_id_data;\n+\tchunk.data[row_id_index].ToUnifiedFormat(chunk.size(), row_id_data);\n+\tif (source_marker.IsValid()) {\n+\t\t// source marker - check both row id and source marker\n+\t\tUnifiedVectorFormat source_marker_data;\n+\t\tchunk.data[source_marker.GetIndex()].ToUnifiedFormat(chunk.size(), source_marker_data);\n+\t\tfor (idx_t i = 0; i < chunk.size(); i++) {\n+\t\t\tif (!source_marker_data.validity.RowIsValid(source_marker_data.sel->get_index(i))) {\n+\t\t\t\t// source marker is NULL - no source match\n+\t\t\t\tnot_matched_by_source.sel.set_index(not_matched_by_source.count++, i);\n+\t\t\t} else if (!row_id_data.validity.RowIsValid(row_id_data.sel->get_index(i))) {\n+\t\t\t\t// target marker is NULL - no target match\n+\t\t\t\tnot_matched.sel.set_index(not_matched.count++, i);\n+\t\t\t} else {\n+\t\t\t\t// match\n+\t\t\t\tmatched.sel.set_index(matched.count++, i);\n+\t\t\t}\n+\t\t}\n+\t} else {\n+\t\t// no source marker - only check row-ids\n+\t\tfor (idx_t i = 0; i < chunk.size(); i++) {\n+\t\t\tauto idx = row_id_data.sel->get_index(i);\n+\t\t\tif (row_id_data.validity.RowIsValid(idx)) {\n+\t\t\t\t// match\n+\t\t\t\tmatched.sel.set_index(matched.count++, i);\n+\t\t\t} else {\n+\t\t\t\t// no match\n+\t\t\t\tnot_matched.sel.set_index(not_matched.count++, i);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// reset and slice chunks\n+\tfor (auto &match : match_results) {\n+\t\tif (match.count == 0) {\n+\t\t\tcontinue;\n+\t\t}\n+\t\tmatch.chunk->Reset();\n+\t\tmatch.chunk->Slice(chunk, match.sel, match.count);\n+\t}\n+}\n+\n+SinkResultType PhysicalMergeInto::Sink(ExecutionContext &context, DataChunk &chunk, OperatorSinkInput &input) const {\n+\tauto &global_state = input.global_state.Cast<MergeIntoGlobalState>();\n+\tauto &local_state = input.local_state.Cast<MergeIntoLocalState>();\n+\n+\tauto &match_results = local_state.match_results;\n+\tauto &computed_matches = local_state.sink_state.computed_matches;\n+\tauto &match_idx = local_state.sink_state.match_idx;\n+\tauto &index_in_match = local_state.sink_state.index_in_match;\n+\tauto &match_initialized = local_state.sink_state.match_initialized;\n+\tauto &current_sel = local_state.sink_state.current_sel;\n+\tauto &current_count = local_state.sink_state.current_count;\n+\tif (!computed_matches) {\n+\t\t// we haven't figured out which rows have which types of matches - compute them\n+\t\tComputeMatches(local_state, chunk);\n+\n+\t\t// set up the state so we can prepare sinking into the relevant operators\n+\t\tcomputed_matches = true;\n+\t\tmatch_idx = 0;\n+\t\tindex_in_match = 0;\n+\t\tmatch_initialized = false;\n+\t}\n+\t// now slice and call sink for each of the match conditions\n+\tfor (; match_idx < 3; match_idx++) {",
        "comment_created_at": "2025-07-03T14:15:05+00:00",
        "comment_author": "Tishj",
        "comment_body": "What is with this magic number?\r\n~~I assume it's UPDATE, INSERT, DELETE ?~~\r\n\r\nSeems to be this:\r\n```c++\r\n\tmatch_actions = {MergeActionCondition::WHEN_MATCHED, MergeActionCondition::WHEN_NOT_MATCHED_BY_TARGET,\r\n\t                 MergeActionCondition::WHEN_NOT_MATCHED_BY_SOURCE};\r\n```\r\n\r\nSo we could just use `match_actions.size()` ?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2194678533",
    "pr_number": 18069,
    "pr_file": "src/execution/operator/aggregate/distinct_aggregate_data.cpp",
    "created_at": "2025-07-09T10:37:31+00:00",
    "commented_code": "}\n \n //! Persistent + shared (read-only) data for the distinct aggregates\n-DistinctAggregateData::DistinctAggregateData(const DistinctAggregateCollectionInfo &info)\n-    : DistinctAggregateData(info, {}, nullptr) {\n+DistinctAggregateData::DistinctAggregateData(const DistinctAggregateCollectionInfo &info, bool all_expr_inputs_valid)",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2194678533",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18069,
        "pr_file": "src/execution/operator/aggregate/distinct_aggregate_data.cpp",
        "discussion_id": "2194678533",
        "commented_code": "@@ -68,12 +68,13 @@ DistinctAggregateState::DistinctAggregateState(const DistinctAggregateData &data\n }\n \n //! Persistent + shared (read-only) data for the distinct aggregates\n-DistinctAggregateData::DistinctAggregateData(const DistinctAggregateCollectionInfo &info)\n-    : DistinctAggregateData(info, {}, nullptr) {\n+DistinctAggregateData::DistinctAggregateData(const DistinctAggregateCollectionInfo &info, bool all_expr_inputs_valid)",
        "comment_created_at": "2025-07-09T10:37:31+00:00",
        "comment_author": "Mytherin",
        "comment_body": "Maybe we can make this an enum, and this should perhaps be `all_inputs_valid`?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2207333733",
    "pr_number": 18168,
    "pr_file": "extension/core_functions/scalar/blob/encode.cpp",
    "created_at": "2025-07-15T12:22:41+00:00",
    "commented_code": "result.Reinterpret(args.data[0]);\n }\n \n-struct BlobDecodeOperator {\n+enum class DecodeErrorBehavior : uint8_t {\n+\tABORT = 1,  // raise error\n+\tSTRICT = 2, // return null\n+\tREPLACE = 3 // replace invalid characters with '?'\n+};\n+\n+bool TryGetDecodeErrorBehavior(const string &specifier_p, DecodeErrorBehavior &result) {\n+\tauto specifier = StringUtil::Lower(specifier_p);\n+\tif (specifier == \"abort\" || specifier == \"a\") {\n+\t\tresult = DecodeErrorBehavior::ABORT;\n+\t} else if (specifier == \"strict\" || specifier == \"s\") {",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2207333733",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18168,
        "pr_file": "extension/core_functions/scalar/blob/encode.cpp",
        "discussion_id": "2207333733",
        "commented_code": "@@ -12,7 +12,35 @@ void EncodeFunction(DataChunk &args, ExpressionState &state, Vector &result) {\n \tresult.Reinterpret(args.data[0]);\n }\n \n-struct BlobDecodeOperator {\n+enum class DecodeErrorBehavior : uint8_t {\n+\tABORT = 1,  // raise error\n+\tSTRICT = 2, // return null\n+\tREPLACE = 3 // replace invalid characters with '?'\n+};\n+\n+bool TryGetDecodeErrorBehavior(const string &specifier_p, DecodeErrorBehavior &result) {\n+\tauto specifier = StringUtil::Lower(specifier_p);\n+\tif (specifier == \"abort\" || specifier == \"a\") {\n+\t\tresult = DecodeErrorBehavior::ABORT;\n+\t} else if (specifier == \"strict\" || specifier == \"s\") {",
        "comment_created_at": "2025-07-15T12:22:41+00:00",
        "comment_author": "Mytherin",
        "comment_body": "Python does not allow the short-hands - I would follow them here and require this to be spelled out (i.e. `replace`, `strict`, etc)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2240141870",
    "pr_number": 18410,
    "pr_file": "extension/core_functions/aggregate/nested/list.cpp",
    "created_at": "2025-07-29T14:58:17+00:00",
    "commented_code": "} // namespace\n \n AggregateFunction ListFun::GetFunction() {\n-\tauto func =\n-\t    AggregateFunction({LogicalType::ANY}, LogicalTypeId::LIST, AggregateFunction::StateSize<ListAggState>,\n-\t                      AggregateFunction::StateInitialize<ListAggState, ListFunction>, ListUpdateFunction,\n-\t                      ListCombineFunction, ListFinalize, nullptr, ListBindFunction, nullptr, nullptr, nullptr);\n+\tauto func = AggregateFunction(\n+\t    {LogicalType::TEMPLATE()}, LogicalType::LIST(LogicalType::TEMPLATE()),",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2240141870",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18410,
        "pr_file": "extension/core_functions/aggregate/nested/list.cpp",
        "discussion_id": "2240141870",
        "commented_code": "@@ -198,10 +190,10 @@ unique_ptr<FunctionData> ListBindFunction(ClientContext &context, AggregateFunct\n } // namespace\n \n AggregateFunction ListFun::GetFunction() {\n-\tauto func =\n-\t    AggregateFunction({LogicalType::ANY}, LogicalTypeId::LIST, AggregateFunction::StateSize<ListAggState>,\n-\t                      AggregateFunction::StateInitialize<ListAggState, ListFunction>, ListUpdateFunction,\n-\t                      ListCombineFunction, ListFinalize, nullptr, ListBindFunction, nullptr, nullptr, nullptr);\n+\tauto func = AggregateFunction(\n+\t    {LogicalType::TEMPLATE()}, LogicalType::LIST(LogicalType::TEMPLATE()),",
        "comment_created_at": "2025-07-29T14:58:17+00:00",
        "comment_author": "taniabogatsch",
        "comment_body": "`TEMPLATE()` is still a bit confusing to me, and I am also not sure it's obvious that this is the same template as the other `TEMPLATE()`. Maybe we can make it more explicit? `DEFAULT_TEMPLATE()` (still not super happy). Or maybe even `TEMPLATE_T()` (if we give it the name `\"T\"` anyways)? Or we don't allow a constructor without any arguments (my preference), and passing \"T\" does not really take much extra space.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2166164847",
    "pr_number": 18054,
    "pr_file": "test/helpers/test_config.cpp",
    "created_at": "2025-06-25T08:44:27+00:00",
    "commented_code": "}\n }\n \n-string TestConfiguration::OnConnectCommand() {\n+TestConfiguration::ExtensionLoadingMode TestConfiguration::GetExtensionLoadingMode() {\n+\tstring res = StringUtil::Lower(GetOptionOrDefault(\"extension_loading\", string(\"none\")));\n+\tif (res == \"none\") {",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2166164847",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 18054,
        "pr_file": "test/helpers/test_config.cpp",
        "discussion_id": "2166164847",
        "commented_code": "@@ -160,10 +165,54 @@ void TestConfiguration::ParseOption(const string &name, const Value &value) {\n \t}\n }\n \n-string TestConfiguration::OnConnectCommand() {\n+TestConfiguration::ExtensionLoadingMode TestConfiguration::GetExtensionLoadingMode() {\n+\tstring res = StringUtil::Lower(GetOptionOrDefault(\"extension_loading\", string(\"none\")));\n+\tif (res == \"none\") {",
        "comment_created_at": "2025-06-25T08:44:27+00:00",
        "comment_author": "Mytherin",
        "comment_body": "The naming here is confusing to me.\r\n\r\nThis is the behavior as I understand it:\r\n\r\n* extension_loading = none -> we load extensions on `require` with `ExtensionHelper::LoadExtension`. This usually only loads statically linked extensions, but there are several paths to get this to load using `LOAD` (e.g. with defines `DUCKDB_TEST_REMOTE_INSTALL` and `DUCKDB_EXTENSIONS_TEST_WITH_LOADABLE`)\r\n* extension_loading = autoload -> we skip loading altogether during `require`, and instead enable autoloading so that we can autoload extensions\r\n* extension_loading = all -> we load extensions using `LOAD {extension_name}` in addition to `ExtensionHelper::LoadExtension`\r\n\r\nI think this naming is quite confusing. When `extension_loading = none` we load extensions, when `extension_loading = autoload` we don't. \r\n\r\nThere's also a bunch of other testing code (`TEST_REMOTE_INSTALL` / `TEST_WITH_LOADABLE_EXTENSION`) that heavily overlaps with these newly added options.\r\n\r\nI think it would be good to revisit this because as it stands this is piling more things onto something that is already very messy. Maybe we can give these things clear names, and remove the existing options for testing / replace them with the new options?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2144837387",
    "pr_number": 17875,
    "pr_file": "src/execution/index/art/art.cpp",
    "created_at": "2025-06-13T11:14:14+00:00",
    "commented_code": "}\n }\n \n-IndexStorageInfo ART::GetStorageInfo(const case_insensitive_map_t<Value> &options, const bool to_wal) {\n+IndexStorageInfo ART::GetStorageInfo(optional_ptr<ClientContext> context,",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2144837387",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 17875,
        "pr_file": "src/execution/index/art/art.cpp",
        "discussion_id": "2144837387",
        "commented_code": "@@ -1063,7 +1063,13 @@ void ART::TransformToDeprecated() {\n \t}\n }\n \n-IndexStorageInfo ART::GetStorageInfo(const case_insensitive_map_t<Value> &options, const bool to_wal) {\n+IndexStorageInfo ART::GetStorageInfo(optional_ptr<ClientContext> context,",
        "comment_created_at": "2025-06-13T11:14:14+00:00",
        "comment_author": "Mytherin",
        "comment_body": "Maybe this method should be renamed to `SerializeToDisk`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2140429124",
    "pr_number": 17819,
    "pr_file": "src/function/scalar/struct/struct_contains.cpp",
    "created_at": "2025-06-11T14:59:40+00:00",
    "commented_code": "+#include \"duckdb/common/string_util.hpp\"\n+#include \"duckdb/execution/expression_executor.hpp\"\n+#include \"duckdb/function/scalar/struct_functions.hpp\"\n+#include \"duckdb/function/scalar/list/contains_or_position.hpp\"\n+\n+namespace duckdb {\n+\n+template <class T, class RETURN_TYPE, bool FIND_NULLS>\n+static void TemplatedStructSearch(Vector &input_vector, vector<unique_ptr<Vector>> &members, Vector &target,\n+                                  const idx_t count, Vector &result) {\n+\t// If the return type is not a bool, return the position\n+\tconst auto return_pos = std::is_same<RETURN_TYPE, int32_t>::value;\n+\n+\tconst auto &target_type = target.GetType();\n+\n+\tUnifiedVectorFormat vector_format;\n+\tinput_vector.ToUnifiedFormat(count, vector_format);\n+\n+\tUnifiedVectorFormat target_format;\n+\ttarget.ToUnifiedFormat(count, target_format);\n+\tconst auto target_data = UnifiedVectorFormat::GetData<T>(target_format);\n+\n+\tvector<const T *> member_datas;\n+\tvector<UnifiedVectorFormat> member_vectors;\n+\tfor (const auto &member : members) {\n+\t\tif (member->GetType().InternalType() == target_type.InternalType()) {\n+\t\t\tUnifiedVectorFormat member_format;\n+\t\t\tmember->ToUnifiedFormat(count, member_format);\n+\t\t\tmember_datas.push_back(UnifiedVectorFormat::GetData<T>(member_format));\n+\t\t\tmember_vectors.push_back(std::move(member_format));\n+\t\t} else {\n+\t\t\tmember_datas.push_back(nullptr);\n+\t\t\tmember_vectors.push_back(UnifiedVectorFormat());\n+\t\t}\n+\t}\n+\n+\tresult.SetVectorType(VectorType::FLAT_VECTOR);\n+\tauto result_data = FlatVector::GetData<RETURN_TYPE>(result);\n+\tauto &result_validity = FlatVector::Validity(result);\n+\n+\tconst auto member_count = members.size();\n+\tfor (idx_t row = 0; row < count; row++) {\n+\t\tconst auto &member_row_idx = vector_format.sel->get_index(row);\n+\n+\t\tif (!vector_format.validity.RowIsValid(member_row_idx)) {\n+\t\t\tresult_validity.SetInvalid(row);\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\tconst auto &target_row_idx = target_format.sel->get_index(row);\n+\t\tconst bool target_valid = target_format.validity.RowIsValid(target_row_idx);\n+\n+\t\t// We are finished if we are not looking for NULL, and the target is NULL.\n+\t\tconst auto finished = !FIND_NULLS && !target_valid;\n+\t\t// We did not find the target (finished, or struct is empty).\n+\t\tif (finished) {\n+\t\t\tif (return_pos) {\n+\t\t\t\tresult_validity.SetInvalid(row);\n+\t\t\t} else {\n+\t\t\t\tresult_data[row] = false;\n+\t\t\t}\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\tbool found = false;\n+\n+\t\tfor (idx_t member_idx = 0; member_idx < member_count; member_idx++) {\n+\t\t\tauto &member_data = member_datas[member_idx];\n+\t\t\tif (!member_data) {\n+\t\t\t\tcontinue; // skip if member data is not compatible with the target type\n+\t\t\t}\n+\t\t\tconst auto &member_vector = member_vectors[member_idx];\n+\t\t\tconst auto member_data_idx = member_vector.sel->get_index(row);\n+\t\t\tconst auto col_valid = member_vector.validity.RowIsValid(member_data_idx);\n+\n+\t\t\tauto is_null = FIND_NULLS && !col_valid && !target_valid;\n+\t\t\tauto both_valid_and_match = col_valid && target_valid &&\n+\t\t\t                            Equals::Operation<T>(member_data[member_data_idx], target_data[target_row_idx]);\n+\n+\t\t\tif (is_null || both_valid_and_match) {\n+\t\t\t\tfound = true;\n+\t\t\t\tif (return_pos) {\n+\t\t\t\t\tresult_data[row] = UnsafeNumericCast<int32_t>(member_idx + 1);\n+\t\t\t\t} else {\n+\t\t\t\t\tresult_data[row] = true;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (!found) {\n+\t\t\tif (return_pos) {\n+\t\t\t\tresult_validity.SetInvalid(row);\n+\t\t\t} else {\n+\t\t\t\tresult_data[row] = false;\n+\t\t\t}\n+\t\t}\n+\t}\n+}\n+\n+template <class RETURN_TYPE, bool FIND_NULLS>\n+static void StructNestedOp(Vector &input_vector, vector<unique_ptr<Vector>> &members, Vector &target, const idx_t count,\n+                           Vector &result) {\n+\tconst OrderModifiers order_modifiers(OrderType::ASCENDING, OrderByNullType::NULLS_LAST);\n+\n+\t// Set up sort keys for nested types.\n+\tconst auto members_size = members.size();\n+\tvector<unique_ptr<Vector>> member_sort_key_vectors;\n+\tfor (idx_t i = 0; i < members_size; i++) {\n+\t\tVector member_sort_key_vec(LogicalType::BLOB, count);\n+\t\tCreateSortKeyHelpers::CreateSortKeyWithValidity(*members[i], member_sort_key_vec, order_modifiers, count);\n+\n+\t\tauto member_sort_key_ptr = make_uniq<Vector>(member_sort_key_vec);\n+\t\tmember_sort_key_vectors.push_back(std::move(member_sort_key_ptr));\n+\t}\n+\n+\tVector target_sort_key_vec(LogicalType::BLOB, count);\n+\tCreateSortKeyHelpers::CreateSortKeyWithValidity(target, target_sort_key_vec, order_modifiers, count);\n+\n+\tTemplatedStructSearch<string_t, RETURN_TYPE, FIND_NULLS>(input_vector, member_sort_key_vectors, target_sort_key_vec,\n+\t                                                         count, result);\n+}\n+\n+template <class RETURN_TYPE, bool FIND_NULLS>\n+static void StructSearchOp(Vector &input_vector, vector<unique_ptr<Vector>> &members, Vector &target, const idx_t count,\n+                           Vector &result) {\n+\tconst auto &target_type = target.GetType().InternalType();\n+\tswitch (target_type) {\n+\tcase PhysicalType::BOOL:\n+\tcase PhysicalType::INT8:\n+\t\treturn TemplatedStructSearch<int8_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::INT16:\n+\t\treturn TemplatedStructSearch<int16_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::INT32:\n+\t\treturn TemplatedStructSearch<int32_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::INT64:\n+\t\treturn TemplatedStructSearch<int64_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::INT128:\n+\t\treturn TemplatedStructSearch<hugeint_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::UINT8:\n+\t\treturn TemplatedStructSearch<uint8_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::UINT16:\n+\t\treturn TemplatedStructSearch<uint16_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::UINT32:\n+\t\treturn TemplatedStructSearch<uint32_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::UINT64:\n+\t\treturn TemplatedStructSearch<uint64_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::UINT128:\n+\t\treturn TemplatedStructSearch<uhugeint_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::FLOAT:\n+\t\treturn TemplatedStructSearch<float, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::DOUBLE:\n+\t\treturn TemplatedStructSearch<double, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::VARCHAR:\n+\t\treturn TemplatedStructSearch<string_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::INTERVAL:\n+\t\treturn TemplatedStructSearch<interval_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::STRUCT:\n+\tcase PhysicalType::LIST:\n+\tcase PhysicalType::ARRAY:\n+\t\treturn StructNestedOp<RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tdefault:\n+\t\tthrow NotImplementedException(\"This function has not been implemented for logical type %s\",\n+\t\t                              TypeIdToString(target_type));\n+\t}\n+}\n+\n+template <class RETURN_TYPE, bool FIND_NULLS = false>\n+static void StructSearchFunction(DataChunk &args, ExpressionState &state, Vector &result) {\n+\tif (result.GetType().id() == LogicalTypeId::SQLNULL) {\n+\t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t\tConstantVector::SetNull(result, true);\n+\t\treturn;\n+\t}\n+\n+\tconst auto count = args.size();\n+\tauto &input_vector = args.data[0];\n+\tauto &members = StructVector::GetEntries(input_vector);\n+\tauto &target = args.data[1];\n+\n+\tStructSearchOp<RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\n+\tif (count == 1) {\n+\t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t}\n+}\n+\n+static unique_ptr<FunctionData> StructContainsBind(ClientContext &context, ScalarFunction &bound_function,\n+                                                   vector<unique_ptr<Expression>> &arguments) {\n+\tD_ASSERT(bound_function.arguments.size() == 2);\n+\tauto &child_type = arguments[0]->return_type;\n+\tif (child_type.id() == LogicalTypeId::UNKNOWN) {\n+\t\tthrow ParameterNotResolvedException();\n+\t}\n+\n+\tif (child_type.id() == LogicalTypeId::SQLNULL) {\n+\t\tbound_function.arguments[0] = LogicalTypeId::UNKNOWN;\n+\t\tbound_function.arguments[1] = LogicalTypeId::UNKNOWN;\n+\t\tbound_function.return_type = LogicalType::SQLNULL;\n+\t\treturn nullptr;\n+\t}\n+\n+\tauto &struct_children = StructType::GetChildTypes(arguments[0]->return_type);\n+\tif (struct_children.empty()) {\n+\t\tthrow InternalException(\"Can't check for containment in an empty struct\");\n+\t}\n+\tif (!StructType::IsUnnamed(child_type)) {\n+\t\tthrow BinderException(\"%s can only be used on unnamed structs\", bound_function.name);\n+\t}\n+\tbound_function.arguments[0] = child_type;\n+\n+\t// the value type must match one of the struct's children\n+\tLogicalType max_child_type = arguments[1]->return_type;\n+\tvector<LogicalType> new_child_types;\n+\tbool has_match = false;\n+\tfor (auto &child : struct_children) {\n+\t\tif (!LogicalType::TryGetMaxLogicalType(context, child.second, max_child_type, max_child_type)) {\n+\t\t\tnew_child_types.push_back(child.second);\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\thas_match = true;\n+\t\tnew_child_types.push_back(max_child_type);\n+\t\tbound_function.arguments[1] = max_child_type;\n+\t}\n+\n+\tchild_list_t<LogicalType> matching_children;\n+\tfor (idx_t i = 0; i < new_child_types.size(); i++) {\n+\t\tmatching_children.push_back(make_pair(struct_children[i].first, new_child_types[i]));\n+\t}",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2140429124",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 17819,
        "pr_file": "src/function/scalar/struct/struct_contains.cpp",
        "discussion_id": "2140429124",
        "commented_code": "@@ -0,0 +1,252 @@\n+#include \"duckdb/common/string_util.hpp\"\n+#include \"duckdb/execution/expression_executor.hpp\"\n+#include \"duckdb/function/scalar/struct_functions.hpp\"\n+#include \"duckdb/function/scalar/list/contains_or_position.hpp\"\n+\n+namespace duckdb {\n+\n+template <class T, class RETURN_TYPE, bool FIND_NULLS>\n+static void TemplatedStructSearch(Vector &input_vector, vector<unique_ptr<Vector>> &members, Vector &target,\n+                                  const idx_t count, Vector &result) {\n+\t// If the return type is not a bool, return the position\n+\tconst auto return_pos = std::is_same<RETURN_TYPE, int32_t>::value;\n+\n+\tconst auto &target_type = target.GetType();\n+\n+\tUnifiedVectorFormat vector_format;\n+\tinput_vector.ToUnifiedFormat(count, vector_format);\n+\n+\tUnifiedVectorFormat target_format;\n+\ttarget.ToUnifiedFormat(count, target_format);\n+\tconst auto target_data = UnifiedVectorFormat::GetData<T>(target_format);\n+\n+\tvector<const T *> member_datas;\n+\tvector<UnifiedVectorFormat> member_vectors;\n+\tfor (const auto &member : members) {\n+\t\tif (member->GetType().InternalType() == target_type.InternalType()) {\n+\t\t\tUnifiedVectorFormat member_format;\n+\t\t\tmember->ToUnifiedFormat(count, member_format);\n+\t\t\tmember_datas.push_back(UnifiedVectorFormat::GetData<T>(member_format));\n+\t\t\tmember_vectors.push_back(std::move(member_format));\n+\t\t} else {\n+\t\t\tmember_datas.push_back(nullptr);\n+\t\t\tmember_vectors.push_back(UnifiedVectorFormat());\n+\t\t}\n+\t}\n+\n+\tresult.SetVectorType(VectorType::FLAT_VECTOR);\n+\tauto result_data = FlatVector::GetData<RETURN_TYPE>(result);\n+\tauto &result_validity = FlatVector::Validity(result);\n+\n+\tconst auto member_count = members.size();\n+\tfor (idx_t row = 0; row < count; row++) {\n+\t\tconst auto &member_row_idx = vector_format.sel->get_index(row);\n+\n+\t\tif (!vector_format.validity.RowIsValid(member_row_idx)) {\n+\t\t\tresult_validity.SetInvalid(row);\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\tconst auto &target_row_idx = target_format.sel->get_index(row);\n+\t\tconst bool target_valid = target_format.validity.RowIsValid(target_row_idx);\n+\n+\t\t// We are finished if we are not looking for NULL, and the target is NULL.\n+\t\tconst auto finished = !FIND_NULLS && !target_valid;\n+\t\t// We did not find the target (finished, or struct is empty).\n+\t\tif (finished) {\n+\t\t\tif (return_pos) {\n+\t\t\t\tresult_validity.SetInvalid(row);\n+\t\t\t} else {\n+\t\t\t\tresult_data[row] = false;\n+\t\t\t}\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\tbool found = false;\n+\n+\t\tfor (idx_t member_idx = 0; member_idx < member_count; member_idx++) {\n+\t\t\tauto &member_data = member_datas[member_idx];\n+\t\t\tif (!member_data) {\n+\t\t\t\tcontinue; // skip if member data is not compatible with the target type\n+\t\t\t}\n+\t\t\tconst auto &member_vector = member_vectors[member_idx];\n+\t\t\tconst auto member_data_idx = member_vector.sel->get_index(row);\n+\t\t\tconst auto col_valid = member_vector.validity.RowIsValid(member_data_idx);\n+\n+\t\t\tauto is_null = FIND_NULLS && !col_valid && !target_valid;\n+\t\t\tauto both_valid_and_match = col_valid && target_valid &&\n+\t\t\t                            Equals::Operation<T>(member_data[member_data_idx], target_data[target_row_idx]);\n+\n+\t\t\tif (is_null || both_valid_and_match) {\n+\t\t\t\tfound = true;\n+\t\t\t\tif (return_pos) {\n+\t\t\t\t\tresult_data[row] = UnsafeNumericCast<int32_t>(member_idx + 1);\n+\t\t\t\t} else {\n+\t\t\t\t\tresult_data[row] = true;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (!found) {\n+\t\t\tif (return_pos) {\n+\t\t\t\tresult_validity.SetInvalid(row);\n+\t\t\t} else {\n+\t\t\t\tresult_data[row] = false;\n+\t\t\t}\n+\t\t}\n+\t}\n+}\n+\n+template <class RETURN_TYPE, bool FIND_NULLS>\n+static void StructNestedOp(Vector &input_vector, vector<unique_ptr<Vector>> &members, Vector &target, const idx_t count,\n+                           Vector &result) {\n+\tconst OrderModifiers order_modifiers(OrderType::ASCENDING, OrderByNullType::NULLS_LAST);\n+\n+\t// Set up sort keys for nested types.\n+\tconst auto members_size = members.size();\n+\tvector<unique_ptr<Vector>> member_sort_key_vectors;\n+\tfor (idx_t i = 0; i < members_size; i++) {\n+\t\tVector member_sort_key_vec(LogicalType::BLOB, count);\n+\t\tCreateSortKeyHelpers::CreateSortKeyWithValidity(*members[i], member_sort_key_vec, order_modifiers, count);\n+\n+\t\tauto member_sort_key_ptr = make_uniq<Vector>(member_sort_key_vec);\n+\t\tmember_sort_key_vectors.push_back(std::move(member_sort_key_ptr));\n+\t}\n+\n+\tVector target_sort_key_vec(LogicalType::BLOB, count);\n+\tCreateSortKeyHelpers::CreateSortKeyWithValidity(target, target_sort_key_vec, order_modifiers, count);\n+\n+\tTemplatedStructSearch<string_t, RETURN_TYPE, FIND_NULLS>(input_vector, member_sort_key_vectors, target_sort_key_vec,\n+\t                                                         count, result);\n+}\n+\n+template <class RETURN_TYPE, bool FIND_NULLS>\n+static void StructSearchOp(Vector &input_vector, vector<unique_ptr<Vector>> &members, Vector &target, const idx_t count,\n+                           Vector &result) {\n+\tconst auto &target_type = target.GetType().InternalType();\n+\tswitch (target_type) {\n+\tcase PhysicalType::BOOL:\n+\tcase PhysicalType::INT8:\n+\t\treturn TemplatedStructSearch<int8_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::INT16:\n+\t\treturn TemplatedStructSearch<int16_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::INT32:\n+\t\treturn TemplatedStructSearch<int32_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::INT64:\n+\t\treturn TemplatedStructSearch<int64_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::INT128:\n+\t\treturn TemplatedStructSearch<hugeint_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::UINT8:\n+\t\treturn TemplatedStructSearch<uint8_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::UINT16:\n+\t\treturn TemplatedStructSearch<uint16_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::UINT32:\n+\t\treturn TemplatedStructSearch<uint32_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::UINT64:\n+\t\treturn TemplatedStructSearch<uint64_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::UINT128:\n+\t\treturn TemplatedStructSearch<uhugeint_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::FLOAT:\n+\t\treturn TemplatedStructSearch<float, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::DOUBLE:\n+\t\treturn TemplatedStructSearch<double, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::VARCHAR:\n+\t\treturn TemplatedStructSearch<string_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::INTERVAL:\n+\t\treturn TemplatedStructSearch<interval_t, RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tcase PhysicalType::STRUCT:\n+\tcase PhysicalType::LIST:\n+\tcase PhysicalType::ARRAY:\n+\t\treturn StructNestedOp<RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\tdefault:\n+\t\tthrow NotImplementedException(\"This function has not been implemented for logical type %s\",\n+\t\t                              TypeIdToString(target_type));\n+\t}\n+}\n+\n+template <class RETURN_TYPE, bool FIND_NULLS = false>\n+static void StructSearchFunction(DataChunk &args, ExpressionState &state, Vector &result) {\n+\tif (result.GetType().id() == LogicalTypeId::SQLNULL) {\n+\t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t\tConstantVector::SetNull(result, true);\n+\t\treturn;\n+\t}\n+\n+\tconst auto count = args.size();\n+\tauto &input_vector = args.data[0];\n+\tauto &members = StructVector::GetEntries(input_vector);\n+\tauto &target = args.data[1];\n+\n+\tStructSearchOp<RETURN_TYPE, FIND_NULLS>(input_vector, members, target, count, result);\n+\n+\tif (count == 1) {\n+\t\tresult.SetVectorType(VectorType::CONSTANT_VECTOR);\n+\t}\n+}\n+\n+static unique_ptr<FunctionData> StructContainsBind(ClientContext &context, ScalarFunction &bound_function,\n+                                                   vector<unique_ptr<Expression>> &arguments) {\n+\tD_ASSERT(bound_function.arguments.size() == 2);\n+\tauto &child_type = arguments[0]->return_type;\n+\tif (child_type.id() == LogicalTypeId::UNKNOWN) {\n+\t\tthrow ParameterNotResolvedException();\n+\t}\n+\n+\tif (child_type.id() == LogicalTypeId::SQLNULL) {\n+\t\tbound_function.arguments[0] = LogicalTypeId::UNKNOWN;\n+\t\tbound_function.arguments[1] = LogicalTypeId::UNKNOWN;\n+\t\tbound_function.return_type = LogicalType::SQLNULL;\n+\t\treturn nullptr;\n+\t}\n+\n+\tauto &struct_children = StructType::GetChildTypes(arguments[0]->return_type);\n+\tif (struct_children.empty()) {\n+\t\tthrow InternalException(\"Can't check for containment in an empty struct\");\n+\t}\n+\tif (!StructType::IsUnnamed(child_type)) {\n+\t\tthrow BinderException(\"%s can only be used on unnamed structs\", bound_function.name);\n+\t}\n+\tbound_function.arguments[0] = child_type;\n+\n+\t// the value type must match one of the struct's children\n+\tLogicalType max_child_type = arguments[1]->return_type;\n+\tvector<LogicalType> new_child_types;\n+\tbool has_match = false;\n+\tfor (auto &child : struct_children) {\n+\t\tif (!LogicalType::TryGetMaxLogicalType(context, child.second, max_child_type, max_child_type)) {\n+\t\t\tnew_child_types.push_back(child.second);\n+\t\t\tcontinue;\n+\t\t}\n+\n+\t\thas_match = true;\n+\t\tnew_child_types.push_back(max_child_type);\n+\t\tbound_function.arguments[1] = max_child_type;\n+\t}\n+\n+\tchild_list_t<LogicalType> matching_children;\n+\tfor (idx_t i = 0; i < new_child_types.size(); i++) {\n+\t\tmatching_children.push_back(make_pair(struct_children[i].first, new_child_types[i]));\n+\t}",
        "comment_created_at": "2025-06-11T14:59:40+00:00",
        "comment_author": "taniabogatsch",
        "comment_body": "Maybe the naming is slightly confusing here - my understanding is that we have the maximum type (if it exists), or the original type in `matching_children`. So maybe we should call it `cast_children` instead, or something else that indicates that this still contains the same number of members.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2139376338",
    "pr_number": 16833,
    "pr_file": "test/sqlite/sqllogic_test_logger.cpp",
    "created_at": "2025-06-11T07:08:21+00:00",
    "commented_code": "SQLLogicTestLogger::~SQLLogicTestLogger() {\n }\n \n-void SQLLogicTestLogger::Log(const string &str) {\n-\tstd::cerr << str;\n+void SQLLogicTestLogger::SafeAppend(const string &log_message) {\n+\tlock_guard<mutex> lock(summary_mutex);\n+\tfailures_summary.push_back(log_message);\n+}\n+\n+void SQLLogicTestLogger::LogBoth(const string &log_message) {",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "2139376338",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 16833,
        "pr_file": "test/sqlite/sqllogic_test_logger.cpp",
        "discussion_id": "2139376338",
        "commented_code": "@@ -13,45 +18,85 @@ SQLLogicTestLogger::SQLLogicTestLogger(ExecuteContext &context, const Command &c\n SQLLogicTestLogger::~SQLLogicTestLogger() {\n }\n \n-void SQLLogicTestLogger::Log(const string &str) {\n-\tstd::cerr << str;\n+void SQLLogicTestLogger::SafeAppend(const string &log_message) {\n+\tlock_guard<mutex> lock(summary_mutex);\n+\tfailures_summary.push_back(log_message);\n+}\n+\n+void SQLLogicTestLogger::LogBoth(const string &log_message) {",
        "comment_created_at": "2025-06-11T07:08:21+00:00",
        "comment_author": "Mytherin",
        "comment_body": "Can we just rename this method to `LogFailure`? The fact that it writes to two destinations is more of a detail of the method.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1379037324",
    "pr_number": 9014,
    "pr_file": "src/planner/binder/tableref/bind_table_function.cpp",
    "created_at": "2023-11-01T16:35:39+00:00",
    "commented_code": "throw BinderException(FormatError(ref, error));\n \t}\n \tauto table_function = function.functions.GetFunctionByOffset(best_function_idx);\n-\n+\tif (ref.with_ordinality && !table_function.ordinality_implemented) {\n+\t\tthrow BinderException(\"WITH ORDINALITY not implemented for \" + ref.ToString());",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "1379037324",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 9014,
        "pr_file": "src/planner/binder/tableref/bind_table_function.cpp",
        "discussion_id": "1379037324",
        "commented_code": "@@ -263,7 +272,10 @@ unique_ptr<BoundTableRef> Binder::Bind(TableFunctionRef &ref) {\n \t\tthrow BinderException(FormatError(ref, error));\n \t}\n \tauto table_function = function.functions.GetFunctionByOffset(best_function_idx);\n-\n+\tif (ref.with_ordinality && !table_function.ordinality_implemented) {\n+\t\tthrow BinderException(\"WITH ORDINALITY not implemented for \" + ref.ToString());",
        "comment_created_at": "2023-11-01T16:35:39+00:00",
        "comment_author": "taniabogatsch",
        "comment_body": "`throw NotImplementedException(...);`\r\n\r\nThen, minor nit, I think we should rename `ordinality_implemented` to `supports_ordinality` for readability.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1923592155",
    "pr_number": 15811,
    "pr_file": "src/main/extension/extension_load.cpp",
    "created_at": "2025-01-21T11:58:57+00:00",
    "commented_code": "load_state.has_error = true;\n \t\t\tload_state.error_data =\n \t\t\t    ErrorData(ExceptionType::UNKNOWN_TYPE,\n-\t\t\t              StringUtil::Format(\"Unknown ABI Type '%s' found when loading extension '%s'\",\n+\t\t\t              StringUtil::Format(\"Unknown ABI Type '%d' found when loading extension '%s'\",",
    "repo_full_name": "duckdb/duckdb",
    "discussion_comments": [
      {
        "comment_id": "1923592155",
        "repo_full_name": "duckdb/duckdb",
        "pr_number": 15811,
        "pr_file": "src/main/extension/extension_load.cpp",
        "discussion_id": "1923592155",
        "commented_code": "@@ -125,7 +125,7 @@ struct ExtensionAccess {\n \t\t\tload_state.has_error = true;\n \t\t\tload_state.error_data =\n \t\t\t    ErrorData(ExceptionType::UNKNOWN_TYPE,\n-\t\t\t              StringUtil::Format(\"Unknown ABI Type '%s' found when loading extension '%s'\",\n+\t\t\t              StringUtil::Format(\"Unknown ABI Type '%d' found when loading extension '%s'\",",
        "comment_created_at": "2025-01-21T11:58:57+00:00",
        "comment_author": "samansmink",
        "comment_body": "I think printing strings is nicer, but indeed this should use the enumutil:\r\n```C++\r\nStringUtil::Format(\"Unknown ABI Type '%s' found when loading extension '%s'\",\r\n\t\t\t                                 EnumUtil::ToString(load_state.init_result.abi_type),\r\n```",
        "pr_file_module": null
      }
    ]
  }
]