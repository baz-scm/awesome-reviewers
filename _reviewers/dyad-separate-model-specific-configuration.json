[
  {
    "discussion_id": "2317783788",
    "pr_number": 1163,
    "pr_file": "src/lib/schemas.ts",
    "created_at": "2025-09-03T05:18:16+00:00",
    "commented_code": "* Zod schema for provider settings\n  */\n export const ProviderSettingSchema = z.object({\n+  // Generic API key (used by most providers except Vertex/Azure)\n   apiKey: SecretSchema.optional(),\n+\n+  // Vertex AI specific optional settings\n+  // We add these as optional to avoid creating a provider-specific schema tree.\n+  projectId: z.string().optional(),\n+  location: z.string().optional(),\n+  // Service account JSON key stored as a Secret (encrypted like apiKey)\n+  serviceAccountKey: SecretSchema.optional(),\n+  // Per-model toggle for Gemini 2.5 Flash thinking (Vertex only)\n+  enableFlashThinking: z.boolean().optional(),",
    "repo_full_name": "dyad-sh/dyad",
    "discussion_comments": [
      {
        "comment_id": "2317783788",
        "repo_full_name": "dyad-sh/dyad",
        "pr_number": 1163,
        "pr_file": "src/lib/schemas.ts",
        "discussion_id": "2317783788",
        "commented_code": "@@ -59,7 +60,17 @@ export type LargeLanguageModel = z.infer<typeof LargeLanguageModelSchema>;\n  * Zod schema for provider settings\n  */\n export const ProviderSettingSchema = z.object({\n+  // Generic API key (used by most providers except Vertex/Azure)\n   apiKey: SecretSchema.optional(),\n+\n+  // Vertex AI specific optional settings\n+  // We add these as optional to avoid creating a provider-specific schema tree.\n+  projectId: z.string().optional(),\n+  location: z.string().optional(),\n+  // Service account JSON key stored as a Secret (encrypted like apiKey)\n+  serviceAccountKey: SecretSchema.optional(),\n+  // Per-model toggle for Gemini 2.5 Flash thinking (Vertex only)\n+  enableFlashThinking: z.boolean().optional(),",
        "comment_created_at": "2025-09-03T05:18:16+00:00",
        "comment_author": "wwwillchen",
        "comment_body": "this doesn't seem right to me, we shouldn't put model-specific info in provider setting.\n\nlet's remove the flash thinking budget from this PR to keep this PR simpler. I think the thinking budget should (ideally) be handled in a model-agnostic, but it's quite tricky because not every model supports thinking budget, or even disabling thinking.",
        "pr_file_module": null
      },
      {
        "comment_id": "2318405286",
        "repo_full_name": "dyad-sh/dyad",
        "pr_number": 1163,
        "pr_file": "src/lib/schemas.ts",
        "discussion_id": "2317783788",
        "commented_code": "@@ -59,7 +60,17 @@ export type LargeLanguageModel = z.infer<typeof LargeLanguageModelSchema>;\n  * Zod schema for provider settings\n  */\n export const ProviderSettingSchema = z.object({\n+  // Generic API key (used by most providers except Vertex/Azure)\n   apiKey: SecretSchema.optional(),\n+\n+  // Vertex AI specific optional settings\n+  // We add these as optional to avoid creating a provider-specific schema tree.\n+  projectId: z.string().optional(),\n+  location: z.string().optional(),\n+  // Service account JSON key stored as a Secret (encrypted like apiKey)\n+  serviceAccountKey: SecretSchema.optional(),\n+  // Per-model toggle for Gemini 2.5 Flash thinking (Vertex only)\n+  enableFlashThinking: z.boolean().optional(),",
        "comment_created_at": "2025-09-03T09:42:17+00:00",
        "comment_author": "rakibulrocky14",
        "comment_body": "@wwwillchen \r\nyeah I am not putting for all models for turn off and on, I added only for 2.5 flash for flexibility because you know that flash 2.5 thinking and non thinking have different pricing and maybe someone want to use non thinking for price that\u2019s why just let\u2019s keep the toggle",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2317790159",
    "pr_number": 1163,
    "pr_file": "src/ipc/handlers/chat_stream_handlers.ts",
    "created_at": "2025-09-03T05:23:25+00:00",
    "commented_code": "} else {\n             logger.log(\"sending AI request\");\n           }\n+          // Determine thinking behavior for Google/Vertex providers\n+          const selectedProviderId = modelClient.builtinProviderId;\n+          const selectedModelName = settings.selectedModel.name;\n+          let includeGoogleThoughts: boolean | undefined = undefined;\n+          if (selectedProviderId === \"google\") {\n+            // Keep existing behavior for Google provider",
    "repo_full_name": "dyad-sh/dyad",
    "discussion_comments": [
      {
        "comment_id": "2317790159",
        "repo_full_name": "dyad-sh/dyad",
        "pr_number": 1163,
        "pr_file": "src/ipc/handlers/chat_stream_handlers.ts",
        "discussion_id": "2317790159",
        "commented_code": "@@ -667,6 +667,26 @@ This conversation includes one or more image attachments. When the user uploads\n           } else {\n             logger.log(\"sending AI request\");\n           }\n+          // Determine thinking behavior for Google/Vertex providers\n+          const selectedProviderId = modelClient.builtinProviderId;\n+          const selectedModelName = settings.selectedModel.name;\n+          let includeGoogleThoughts: boolean | undefined = undefined;\n+          if (selectedProviderId === \"google\") {\n+            // Keep existing behavior for Google provider",
        "comment_created_at": "2025-09-03T05:23:25+00:00",
        "comment_author": "wwwillchen",
        "comment_body": "see other comment - let's remove this thinking budget-related code from this PR - this doesn't seem like a very clean approach and will become a maintenance burden as there's new models.",
        "pr_file_module": null
      },
      {
        "comment_id": "2319179124",
        "repo_full_name": "dyad-sh/dyad",
        "pr_number": 1163,
        "pr_file": "src/ipc/handlers/chat_stream_handlers.ts",
        "discussion_id": "2317790159",
        "commented_code": "@@ -667,6 +667,26 @@ This conversation includes one or more image attachments. When the user uploads\n           } else {\n             logger.log(\"sending AI request\");\n           }\n+          // Determine thinking behavior for Google/Vertex providers\n+          const selectedProviderId = modelClient.builtinProviderId;\n+          const selectedModelName = settings.selectedModel.name;\n+          let includeGoogleThoughts: boolean | undefined = undefined;\n+          if (selectedProviderId === \"google\") {\n+            // Keep existing behavior for Google provider",
        "comment_created_at": "2025-09-03T14:32:10+00:00",
        "comment_author": "rakibulrocky14",
        "comment_body": "@wwwillchen\r\nyeah I am not putting for all models for turn off and on, I added only for 2.5 flash for flexibility because you know that flash 2.5 thinking and non thinking have different pricing and maybe someone want to use non thinking for price that\u2019s why just let\u2019s keep the toggle\r\n\r\n> Well, if you say then I will remove, but keeping this will be loved by the users believe me",
        "pr_file_module": null
      },
      {
        "comment_id": "2320314527",
        "repo_full_name": "dyad-sh/dyad",
        "pr_number": 1163,
        "pr_file": "src/ipc/handlers/chat_stream_handlers.ts",
        "discussion_id": "2317790159",
        "commented_code": "@@ -667,6 +667,26 @@ This conversation includes one or more image attachments. When the user uploads\n           } else {\n             logger.log(\"sending AI request\");\n           }\n+          // Determine thinking behavior for Google/Vertex providers\n+          const selectedProviderId = modelClient.builtinProviderId;\n+          const selectedModelName = settings.selectedModel.name;\n+          let includeGoogleThoughts: boolean | undefined = undefined;\n+          if (selectedProviderId === \"google\") {\n+            // Keep existing behavior for Google provider",
        "comment_created_at": "2025-09-03T21:55:51+00:00",
        "comment_author": "wwwillchen",
        "comment_body": "@rakibulrocky14 during preview, flash2.5 thinking and non-thinking had different prices but now that it's in GA the prices are the same: https://cloud.google.com/vertex-ai/generative-ai/pricing#gemini-models-2.5 so my guess is most people would want to keep thinking on (since price is same and performance is much better with thinking)",
        "pr_file_module": null
      },
      {
        "comment_id": "2320522204",
        "repo_full_name": "dyad-sh/dyad",
        "pr_number": 1163,
        "pr_file": "src/ipc/handlers/chat_stream_handlers.ts",
        "discussion_id": "2317790159",
        "commented_code": "@@ -667,6 +667,26 @@ This conversation includes one or more image attachments. When the user uploads\n           } else {\n             logger.log(\"sending AI request\");\n           }\n+          // Determine thinking behavior for Google/Vertex providers\n+          const selectedProviderId = modelClient.builtinProviderId;\n+          const selectedModelName = settings.selectedModel.name;\n+          let includeGoogleThoughts: boolean | undefined = undefined;\n+          if (selectedProviderId === \"google\") {\n+            // Keep existing behavior for Google provider",
        "comment_created_at": "2025-09-04T00:25:24+00:00",
        "comment_author": "rakibulrocky14",
        "comment_body": "@wwwillchen Well, my bad, Thanks and I will change it",
        "pr_file_module": null
      }
    ]
  }
]