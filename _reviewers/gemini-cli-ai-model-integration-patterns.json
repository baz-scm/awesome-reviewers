[
  {
    "discussion_id": "2173595171",
    "pr_number": 2260,
    "pr_file": "packages/core/src/core/turn.ts",
    "created_at": "2025-06-29T06:50:20+00:00",
    "commented_code": "this.lastUsageMetadata =\n             resp.usageMetadata as GenerateContentResponseUsageMetadata;\n         }\n+\n+        // Check if response was truncated due to token limits\n+        const finishReason = resp.candidates?.[0]?.finishReason;\n+        if (finishReason === 'MAX_TOKENS') {\n+          yield {\n+            type: GeminiEventType.Content,\n+            value: '\n\n\u26a0\ufe0f  Response truncated due to token limits.',\n+          };\n+        }",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2173616420",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 2260,
        "pr_file": "packages/core/src/core/turn.ts",
        "discussion_id": "2173595171",
        "commented_code": "@@ -215,6 +215,15 @@ export class Turn {\n           this.lastUsageMetadata =\n             resp.usageMetadata as GenerateContentResponseUsageMetadata;\n         }\n+\n+        // Check if response was truncated due to token limits\n+        const finishReason = resp.candidates?.[0]?.finishReason;\n+        if (finishReason === 'MAX_TOKENS') {\n+          yield {\n+            type: GeminiEventType.Content,\n+            value: '\\n\\n\u26a0\ufe0f  Response truncated due to token limits.',\n+          };\n+        }",
        "comment_created_at": "2025-06-29T06:50:20+00:00",
        "comment_author": "darkdarkcocoa",
        "comment_body": "Thanks for the feedback! I've expanded the implementation to handle all finish reasons (SAFETY, RECITATION, LANGUAGE, BLOCKLIST, PROHIBITED_CONTENT, SPII, OTHER) with appropriate user-friendly messages in commit b8e7ff2.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2203845035",
    "pr_number": 2260,
    "pr_file": "packages/core/src/core/turn.ts",
    "created_at": "2025-07-14T04:53:31+00:00",
    "commented_code": "yield event;\n           }\n         }\n+\n+        if (resp.usageMetadata) {\n+          this.lastUsageMetadata =\n+            resp.usageMetadata as GenerateContentResponseUsageMetadata;\n+        }\n+\n+        // Check if response was truncated or stopped for various reasons\n+        const finishReason = resp.candidates?.[0]?.finishReason;\n+        \n+        const finishReasonMessages: Record<string, string> = {\n+          'MAX_TOKENS': '\n\n\u26a0\ufe0f  Response truncated due to token limits.',\n+          'SAFETY': '\n\n\u26a0\ufe0f  Response stopped due to safety reasons.',\n+          'RECITATION': '\n\n\u26a0\ufe0f  Response stopped due to recitation policy.',\n+          'LANGUAGE': '\n\n\u26a0\ufe0f  Response stopped due to unsupported language.',\n+          'BLOCKLIST': '\n\n\u26a0\ufe0f  Response stopped due to forbidden terms.',\n+          'PROHIBITED_CONTENT': '\n\n\u26a0\ufe0f  Response stopped due to prohibited content.',\n+          'SPII': '\n\n\u26a0\ufe0f  Response stopped due to sensitive personally identifiable information.',\n+          'OTHER': '\n\n\u26a0\ufe0f  Response stopped for other reasons.',\n+        };\n+        \n+        if (finishReason && finishReasonMessages[finishReason]) {\n+          yield {\n+            type: GeminiEventType.Content,",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2203845035",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 2260,
        "pr_file": "packages/core/src/core/turn.ts",
        "discussion_id": "2203845035",
        "commented_code": "@@ -216,6 +216,41 @@ export class Turn {\n             yield event;\n           }\n         }\n+\n+        if (resp.usageMetadata) {\n+          this.lastUsageMetadata =\n+            resp.usageMetadata as GenerateContentResponseUsageMetadata;\n+        }\n+\n+        // Check if response was truncated or stopped for various reasons\n+        const finishReason = resp.candidates?.[0]?.finishReason;\n+        \n+        const finishReasonMessages: Record<string, string> = {\n+          'MAX_TOKENS': '\\n\\n\u26a0\ufe0f  Response truncated due to token limits.',\n+          'SAFETY': '\\n\\n\u26a0\ufe0f  Response stopped due to safety reasons.',\n+          'RECITATION': '\\n\\n\u26a0\ufe0f  Response stopped due to recitation policy.',\n+          'LANGUAGE': '\\n\\n\u26a0\ufe0f  Response stopped due to unsupported language.',\n+          'BLOCKLIST': '\\n\\n\u26a0\ufe0f  Response stopped due to forbidden terms.',\n+          'PROHIBITED_CONTENT': '\\n\\n\u26a0\ufe0f  Response stopped due to prohibited content.',\n+          'SPII': '\\n\\n\u26a0\ufe0f  Response stopped due to sensitive personally identifiable information.',\n+          'OTHER': '\\n\\n\u26a0\ufe0f  Response stopped for other reasons.',\n+        };\n+        \n+        if (finishReason && finishReasonMessages[finishReason]) {\n+          yield {\n+            type: GeminiEventType.Content,",
        "comment_created_at": "2025-07-14T04:53:31+00:00",
        "comment_author": "NTaylorMullen",
        "comment_body": "Instead of returning content this way what if we did the message creation in `useGeminiStream.tsx`? To do this you'll want to create a new `GeminiEventType`. Lets call it \"Finished\" that has a value of the `@google/genai`'s `FinishReason` type. This way the useGeminiStream hook can turn each reason into an informational message.\r\n\r\nThis approach will also ensure that anyone consuming the `core` library wont get extra non-model generated messages.",
        "pr_file_module": null
      },
      {
        "comment_id": "2203969094",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 2260,
        "pr_file": "packages/core/src/core/turn.ts",
        "discussion_id": "2203845035",
        "commented_code": "@@ -216,6 +216,41 @@ export class Turn {\n             yield event;\n           }\n         }\n+\n+        if (resp.usageMetadata) {\n+          this.lastUsageMetadata =\n+            resp.usageMetadata as GenerateContentResponseUsageMetadata;\n+        }\n+\n+        // Check if response was truncated or stopped for various reasons\n+        const finishReason = resp.candidates?.[0]?.finishReason;\n+        \n+        const finishReasonMessages: Record<string, string> = {\n+          'MAX_TOKENS': '\\n\\n\u26a0\ufe0f  Response truncated due to token limits.',\n+          'SAFETY': '\\n\\n\u26a0\ufe0f  Response stopped due to safety reasons.',\n+          'RECITATION': '\\n\\n\u26a0\ufe0f  Response stopped due to recitation policy.',\n+          'LANGUAGE': '\\n\\n\u26a0\ufe0f  Response stopped due to unsupported language.',\n+          'BLOCKLIST': '\\n\\n\u26a0\ufe0f  Response stopped due to forbidden terms.',\n+          'PROHIBITED_CONTENT': '\\n\\n\u26a0\ufe0f  Response stopped due to prohibited content.',\n+          'SPII': '\\n\\n\u26a0\ufe0f  Response stopped due to sensitive personally identifiable information.',\n+          'OTHER': '\\n\\n\u26a0\ufe0f  Response stopped for other reasons.',\n+        };\n+        \n+        if (finishReason && finishReasonMessages[finishReason]) {\n+          yield {\n+            type: GeminiEventType.Content,",
        "comment_created_at": "2025-07-14T06:42:13+00:00",
        "comment_author": "darkdarkcocoa",
        "comment_body": "@NTaylorMullen Thank you for the excellent review! I've implemented all your suggestions:\r\n\r\n\u2705 **Migrated to official FinishReason enum** from `@google/genai`\r\n\u2705 **Added new `GeminiEventType.Finished` event** for better separation\r\n\u2705 **Moved message formatting from core to UI layer**:\r\n   - `turn.ts` now only emits the raw FinishReason value\r\n   - `useGeminiStream.ts` handles user-facing message generation\r\n   - Core library consumers won't receive UI-specific messages\r\n\r\nAll tests are passing and the separation of concerns is now properly implemented. Ready for your re-review!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2206528557",
    "pr_number": 2260,
    "pr_file": "packages/core/src/core/turn.ts",
    "created_at": "2025-07-15T06:33:07+00:00",
    "commented_code": "yield event;\n           }\n         }\n+\n+        if (resp.usageMetadata) {\n+          this.lastUsageMetadata =\n+            resp.usageMetadata as GenerateContentResponseUsageMetadata;\n+        }\n+\n+        // Check if response was truncated or stopped for various reasons\n+        const finishReason = resp.candidates?.[0]?.finishReason;\n+        \n+        if (finishReason && finishReason !== FinishReason.STOP && finishReason !== FinishReason.FINISH_REASON_UNSPECIFIED) {",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2206528557",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 2260,
        "pr_file": "packages/core/src/core/turn.ts",
        "discussion_id": "2206528557",
        "commented_code": "@@ -222,6 +240,29 @@ export class Turn {\n             yield event;\n           }\n         }\n+\n+        if (resp.usageMetadata) {\n+          this.lastUsageMetadata =\n+            resp.usageMetadata as GenerateContentResponseUsageMetadata;\n+        }\n+\n+        // Check if response was truncated or stopped for various reasons\n+        const finishReason = resp.candidates?.[0]?.finishReason;\n+        \n+        if (finishReason && finishReason !== FinishReason.STOP && finishReason !== FinishReason.FINISH_REASON_UNSPECIFIED) {",
        "comment_created_at": "2025-07-15T06:33:07+00:00",
        "comment_author": "NTaylorMullen",
        "comment_body": "You can produce the finish event always. We can react in useGeminiStream on whether or not we produce a message or not there",
        "pr_file_module": null
      },
      {
        "comment_id": "2206650534",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 2260,
        "pr_file": "packages/core/src/core/turn.ts",
        "discussion_id": "2206528557",
        "commented_code": "@@ -222,6 +240,29 @@ export class Turn {\n             yield event;\n           }\n         }\n+\n+        if (resp.usageMetadata) {\n+          this.lastUsageMetadata =\n+            resp.usageMetadata as GenerateContentResponseUsageMetadata;\n+        }\n+\n+        // Check if response was truncated or stopped for various reasons\n+        const finishReason = resp.candidates?.[0]?.finishReason;\n+        \n+        if (finishReason && finishReason !== FinishReason.STOP && finishReason !== FinishReason.FINISH_REASON_UNSPECIFIED) {",
        "comment_created_at": "2025-07-15T07:27:44+00:00",
        "comment_author": "darkdarkcocoa",
        "comment_body": "@NTaylorMullen Thanks for the review! \r\nI've implemented all the requested changes:\r\n\u2705 Removed all UsageMetadata-related code to keep the PR focused\r\n\u2705 Changed from content messages to informational messages for warnings\r\n\u2705 Modified to always emit finish events (letting UI layer handle filtering)\r\n\u2705 Updated branch with latest main\r\n\r\nThe build is passing now. You're right about handling finish events in the UI layer - it's a cleaner approach.\r\nLet me know if anything else needs adjustment. :)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2183019401",
    "pr_number": 1805,
    "pr_file": "packages/core/src/core/subagent.ts",
    "created_at": "2025-07-03T15:01:20+00:00",
    "commented_code": "+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import { reportError } from '../utils/errorReporting.js';\n+import { ToolRegistry } from '../tools/tool-registry.js';\n+import { Config } from '../config/config.js';\n+import { ToolCallRequestInfo } from './turn.js';\n+import { executeToolCall } from './nonInteractiveToolExecutor.js';\n+import { createContentGenerator } from './contentGenerator.js';\n+import { getFolderStructure } from '../utils/getFolderStructure.js';\n+import {\n+  Content,\n+  Part,\n+  FunctionCall,\n+  GenerateContentConfig,\n+  FunctionDeclaration,\n+  Type,\n+} from '@google/genai';\n+import { GeminiChat } from './geminiChat.js';\n+import { ReadManyFilesTool } from '../tools/read-many-files.js';\n+\n+/**\n+ * @fileoverview Defines the configuration interfaces for a subagent.\n+ *\n+ * These interfaces specify the structure for defining the subagent's prompt,\n+ * the model parameters, and the execution settings.\n+ */\n+\n+/**\n+ * Describes the possible termination modes for a subagent.\n+ * This enum provides a clear indication of why a subagent's execution might have ended.\n+ */\n+export enum SubagentTerminateMode {\n+  /**\n+   * Indicates that the subagent's execution terminated due to an unrecoverable error.\n+   */\n+  ERROR = 'ERROR',\n+  /**\n+   * Indicates that the subagent's execution terminated because it exceeded the maximum allowed working time.\n+   */\n+  TIMEOUT = 'TIMEOUT',\n+  /**\n+   * Indicates that the subagent's execution successfully completed all its defined goals.\n+   */\n+  GOAL = 'GOAL',\n+}\n+\n+/**\n+ * Represents the output structure of a subagent's execution.\n+ * This interface defines the data that a subagent will return upon completion,\n+ * including any emitted variables and the reason for its termination.\n+ */\n+export interface OutputObject {\n+  /**\n+   * A record of key-value pairs representing variables emitted by the subagent\n+   * during its execution. These variables can be used by the calling agent.\n+   */\n+  emitted_vars: Record<string, string>;\n+  /**\n+   * The reason for the subagent's termination, indicating whether it completed\n+   * successfully, timed out, or encountered an error.\n+   */\n+  terminate_reason: SubagentTerminateMode;\n+}\n+\n+/**\n+ * Configures the prompt and expected behavior of the subagent.\n+ * This interface defines the essential parameters that guide the subagent's\n+ * interaction and task execution, including its plan, goals, and available tools.\n+ */\n+export interface PromptConfig {\n+  /** A high-level plan or strategy for the subagent to follow. */\n+  plan: string;\n+  /** The specific goals the subagent is expected to achieve. */\n+  goals: string;\n+  /** A list of expected output objects and the variables they should emit. */\n+  outputs: Record<string, string>;\n+  /** A list of tool names (in the tool registry) or full function declarations that the subagent is permitted to use. */\n+  tools: Array<string | FunctionDeclaration>;\n+}\n+\n+/**\n+ * Configures the generative model parameters for the subagent.\n+ * This interface specifies the model to be used and its associated generation settings,\n+ * such as temperature and top-p values, which influence the creativity and diversity of the model's output.\n+ */\n+export interface ModelConfig {\n+  /** The name or identifier of the model to be used. */\n+  model: string;\n+  /** The temperature for the model's sampling process. */\n+  temp: number;\n+  /** The top-p value for nucleus sampling. */\n+  top_p: number;\n+}\n+\n+/**\n+ * Configures the execution environment and constraints for the subagent.\n+ * This interface defines parameters that control the subagent's runtime behavior,\n+ * such as maximum execution time, to prevent infinite loops or excessive resource consumption.\n+ */\n+export interface RunConfig {\n+  /** The maximum execution time for the subagent in minutes. */\n+  max_time_minutes: number;\n+}\n+\n+/**\n+ * Manages the runtime context state for the subagent.\n+ * This class provides a mechanism to store and retrieve key-value pairs\n+ * that represent the dynamic state and variables accessible to the subagent\n+ * during its execution.\n+ */\n+export class ContextState {\n+  private state: Record<string, unknown> = {};\n+\n+  /**\n+   * Retrieves a value from the context state.\n+   *\n+   * @param key - The key of the value to retrieve.\n+   * @returns The value associated with the key, or undefined if the key is not found.\n+   */\n+  get(key: string): unknown {\n+    return this.state[key];\n+  }\n+\n+  /**\n+   * Sets a value in the context state.\n+   *\n+   * @param key - The key to set the value under.\n+   * @param value - The value to set.\n+   */\n+  set(key: string, value: unknown): void {\n+    this.state[key] = value;\n+  }\n+\n+  /**\n+   * Retrieves all keys in the context state.\n+   *\n+   * @returns An array of all keys in the context state.\n+   */\n+  get_keys(): string[] {\n+    return Object.keys(this.state);\n+  }\n+}\n+\n+/**\n+ * Replaces `${...}` placeholders in a template string with values from a context.\n+ *\n+ * This function identifies all placeholders in the format `${key}`, validates that\n+ * each key exists in the provided `ContextState`, and then performs the substitution.\n+ *\n+ * @param template The template string containing placeholders.\n+ * @param context The `ContextState` object providing placeholder values.\n+ * @returns The populated string with all placeholders replaced.\n+ * @throws {Error} if any placeholder key is not found in the context.\n+ */\n+function templateString(template: string, context: ContextState): string {\n+  const placeholderRegex = /\\$\\{(\\w+)\\}/g;\n+\n+  // First, find all unique keys required by the template.\n+  const requiredKeys = new Set(\n+    Array.from(template.matchAll(placeholderRegex), (match) => match[1]),\n+  );\n+\n+  // Check if all required keys exist in the context.\n+  const contextKeys = new Set(context.get_keys());\n+  const missingKeys = Array.from(requiredKeys).filter(\n+    (key) => !contextKeys.has(key),\n+  );\n+\n+  if (missingKeys.length > 0) {\n+    throw new Error(\n+      `Missing context values for the following keys: ${missingKeys.join(\n+        ', ',\n+      )}`,\n+    );\n+  }\n+\n+  // Perform the replacement using a replacer function.\n+  return template.replace(placeholderRegex, (_match, key) =>\n+    String(context.get(key)),\n+  );\n+}\n+\n+/**\n+ * Represents the scope and execution environment for a subagent.\n+ * This class orchestrates the subagent's lifecycle, managing its chat interactions,\n+ * runtime context, and the collection of its outputs.\n+ */\n+export class SubAgentScope {\n+  output: OutputObject = {\n+    terminate_reason: SubagentTerminateMode.ERROR,\n+    emitted_vars: {},\n+  };\n+\n+  /**\n+   * Constructs a new SubAgentScope instance.\n+   * @param runtimeContext - The shared runtime configuration and services.\n+   * @param promptConfig - Configuration for the subagent's prompt and behavior.\n+   * @param modelConfig - Configuration for the generative model parameters.\n+   * @param runConfig - Configuration for the subagent's execution environment and constraints.\n+   */\n+  constructor(\n+    readonly runtimeContext: Config,\n+    private readonly promptConfig: PromptConfig,\n+    private readonly modelConfig: ModelConfig,\n+    private readonly runConfig: RunConfig,\n+  ) {}\n+\n+  /**\n+   * Runs the subagent in a non-interactive mode.\n+   * This method orchestrates the subagent's execution loop, including prompt templating,\n+   * tool execution, and termination conditions. It manages the chat history, handles\n+   * tool calls, and determines when the subagent's goals are met or if a timeout occurs.\n+   * @param {ContextState} context - The current context state containing variables for prompt templating.\n+   * @returns {Promise<void>} A promise that resolves when the subagent has completed its execution.\n+   */\n+  async runNonInteractive(context: ContextState): Promise<void> {\n+    const chat = await this.createChatObject();\n+\n+    if (!chat) {\n+      this.output.terminate_reason = SubagentTerminateMode.ERROR;\n+      return;\n+    }\n+\n+    const abortController = new AbortController();\n+    const toolRegistry: ToolRegistry =\n+      await this.runtimeContext.getToolRegistry();\n+\n+    // Prepare the list of tools available to the subagent.\n+    const tools_to_load: string[] = [];\n+    const toolsList: FunctionDeclaration[] = [];\n+    for (const toolName of this.promptConfig.tools) {\n+      if (typeof toolName === 'string') {\n+        tools_to_load.push(toolName);\n+      } else {\n+        toolsList.push(toolName);\n+      }\n+    }\n+\n+    toolsList.push(\n+      ...toolRegistry.getFunctionDeclarationsFiltered(tools_to_load),\n+    );\n+    toolsList.push(...this.getScopeLocalFuncDefs());\n+\n+    chat.setSystemInstruction(this.buildChatSystemPrompt(context, toolsList));\n+\n+    let currentMessages: Content[] = [\n+      { role: 'user', parts: [{ text: 'Get Started!' }] },\n+    ];\n+\n+    const startTime = Date.now();\n+    try {\n+      while (true) {\n+        // Check for timeout.\n+        const duration = Date.now() - startTime;\n+        const durationMin = duration / (1000 * 60);\n+        if (durationMin >= this.runConfig.max_time_minutes) {\n+          this.output.terminate_reason = SubagentTerminateMode.TIMEOUT;\n+          break;\n+        }\n+\n+        const messageParams = {\n+          message: currentMessages[0]?.parts || [],\n+          config: {\n+            abortSignal: abortController.signal,\n+            tools: [{ functionDeclarations: toolsList }],\n+          },\n+        };\n+\n+        // Send the message to the GeminiChat object, which will manage its own history\n+        const responseStream = await chat.sendMessageStream(messageParams);\n+\n+        // Combine all chunks in stream for proper processing.\n+        const functionCalls: FunctionCall[] = [];\n+        for await (const resp of responseStream) {\n+          if (abortController.signal.aborted) {\n+            console.error('Operation cancelled.');\n+            return;\n+          }\n+\n+          const calls = resp.functionCalls;\n+          if (calls) {\n+            functionCalls.push(...calls);\n+          }\n+        }\n+\n+        if (functionCalls.length > 0) {\n+          currentMessages = await this.processFunctionCalls(\n+            functionCalls,\n+            toolRegistry,\n+            abortController,\n+            currentMessages,\n+          );\n+        } else {\n+          // The model has stopped calling tools, which signals completion.\n+          // Verify that all expected output variables have been emitted.\n+          const remainingVars = Object.keys(this.promptConfig.outputs).filter(\n+            (key) => !(key in this.output.emitted_vars),\n+          );\n+\n+          if (remainingVars.length === 0) {\n+            this.output.terminate_reason = SubagentTerminateMode.GOAL;\n+            break;\n+          }\n+\n+          // If variables are missing, the loop continues, relying on the\n+          // system prompt to guide the model to call self.emitvalue.\n+          console.debug(\n+            'Variables appear to be missing. Relying on model to call EmitValue.',\n+          );\n+        }\n+      }\n+    } catch (error) {\n+      console.error('Error during subagent execution:', error);\n+      this.output.terminate_reason = SubagentTerminateMode.ERROR;\n+      throw error;\n+    }\n+  }\n+\n+  /**\n+   * Processes a list of function calls, executing each one and collecting their responses.\n+   * This method iterates through the provided function calls, executes them using the\n+   * `executeToolCall` function (or handles `self.emitvalue` internally), and aggregates\n+   * their results. It also manages error reporting for failed tool executions.\n+   * @param {FunctionCall[]} functionCalls - An array of `FunctionCall` objects to process.\n+   * @param {ToolRegistry} toolRegistry - The tool registry to look up and execute tools.\n+   * @param {AbortController} abortController - An `AbortController` to signal cancellation of tool executions.\n+   * @param {Content[]} currentMessages - The current list of messages in the chat history, which will be updated with tool responses.\n+   * @returns {Promise<Content[]>} A promise that resolves to an array of `Content` parts representing the tool responses,\n+   *          which are then used to update the chat history.\n+   */\n+  private async processFunctionCalls(\n+    functionCalls: FunctionCall[],\n+    toolRegistry: ToolRegistry,\n+    abortController: AbortController,\n+    currentMessages: Content[],\n+  ) {\n+    const toolResponseParts: Part[] = [];\n+\n+    for (const functionCall of functionCalls) {\n+      const callId = functionCall.id ?? `${functionCall.name}-${Date.now()}`;\n+      const requestInfo: ToolCallRequestInfo = {\n+        callId,\n+        name: functionCall.name as string,\n+        args: (functionCall.args ?? {}) as Record<string, unknown>,\n+        isClientInitiated: true,\n+      };\n+\n+      let toolResponse;\n+\n+      // Handle scope-local tools first.\n+      if (callId.startsWith('self.emitvalue')) {\n+        const valName = String(requestInfo.args['emit_variable_name']);\n+        const valVal = String(requestInfo.args['emit_variable_value']);\n+        this.output.emitted_vars[valName] = valVal;\n+\n+        toolResponse = {\n+          callId,\n+          responseParts: `Emitted variable ${valName} successfully`,\n+          resultDisplay: `Emitted variable ${valName} successfully`,\n+          error: undefined,\n+        };\n+      } else {\n+        toolResponse = await executeToolCall(\n+          this.runtimeContext,\n+          requestInfo,\n+          toolRegistry,\n+          abortController.signal,\n+        );\n+      }\n+\n+      if (toolResponse.error) {\n+        console.error(\n+          `Error executing tool ${functionCall.name}: ${toolResponse.resultDisplay || toolResponse.error.message}`,\n+        );\n+        // Continue to the next tool call instead of halting execution.\n+        continue;\n+      }\n+\n+      if (toolResponse.responseParts) {\n+        const parts = Array.isArray(toolResponse.responseParts)\n+          ? toolResponse.responseParts\n+          : [toolResponse.responseParts];\n+        for (const part of parts) {\n+          if (typeof part === 'string') {\n+            toolResponseParts.push({ text: part });\n+          } else if (part) {\n+            toolResponseParts.push(part);\n+          }\n+        }\n+      }\n+    }\n+    currentMessages = [{ role: 'user', parts: toolResponseParts }];\n+    return currentMessages;\n+  }\n+\n+  /**\n+   * Creates an instance of `GeminiChat` unique for the subagent's purposes.\n+   * It initializes the chat with environment variables and configures the content generator.\n+   * @param {Content[]} [extraHistory] - Optional additional chat history to include.\n+   * @returns {Promise<GeminiChat | undefined>} A promise that resolves to a `GeminiChat` instance, or undefined if creation fails.\n+   */\n+  private async createChatObject(extraHistory?: Content[]) {\n+    const envParts = await this.getEnvironment();\n+    const initialHistory: Content[] = [\n+      {\n+        role: 'user',\n+        parts: envParts,\n+      },\n+      {\n+        role: 'model',\n+        parts: [{ text: 'Got it. Thanks for the context!' }],\n+      },\n+    ];\n+\n+    const start_history = [...initialHistory, ...(extraHistory ?? [])];\n+\n+    // The system instruction is set dynamically within the run loop to allow\n+    // for context-based templating.\n+    const systemInstruction = '';\n+\n+    try {\n+      const targetContentConfig: GenerateContentConfig = {\n+        temperature: this.modelConfig.temp,\n+        topP: this.modelConfig.top_p,\n+      };\n+\n+      const generationConfig = {\n+        systemInstruction,\n+        ...targetContentConfig,\n+      };\n+\n+      const contentGenerator = await createContentGenerator(\n+        this.runtimeContext.getContentGeneratorConfig(),\n+      );\n+\n+      this.runtimeContext.setModel(this.modelConfig.model);\n+\n+      return new GeminiChat(\n+        this.runtimeContext,\n+        contentGenerator,\n+        generationConfig,\n+        start_history,\n+      );\n+    } catch (error) {\n+      await reportError(\n+        error,\n+        'Error initializing Gemini chat session.',\n+        start_history,\n+        'startChat',\n+      );\n+      // The calling function will handle the undefined return.\n+      return undefined;\n+    }\n+  }\n+\n+  /**\n+   * Retrieves environment-related information to be included in the chat context.\n+   * This includes the current working directory, date, operating system, and folder structure.\n+   * Optionally, it can also include the full file context if enabled.\n+   * @returns A promise that resolves to an array of `Part` objects containing environment information.\n+   */\n+  private async getEnvironment(): Promise<Part[]> {\n+    const cwd = this.runtimeContext.getWorkingDir();\n+    const today = new Date().toLocaleDateString(undefined, {\n+      weekday: 'long',\n+      year: 'numeric',\n+      month: 'long',\n+      day: 'numeric',\n+    });\n+    const platform = process.platform;\n+    const folderStructure = await getFolderStructure(cwd, {\n+      fileService: this.runtimeContext.getFileService(),\n+    });\n+    const context = `\n+  Okay, just setting up the context for our chat.\n+  Today is ${today}.\n+  My operating system is: ${platform}\n+  I'm currently working in the directory: ${cwd}\n+  ${folderStructure}\n+          `.trim();\n+\n+    const initialParts: Part[] = [{ text: context }];\n+    const toolRegistry = await this.runtimeContext.getToolRegistry();\n+\n+    // Add full file context if the flag is set\n+    if (this.runtimeContext.getFullContext()) {\n+      try {\n+        const readManyFilesTool = toolRegistry.getTool(\n+          'read_many_files',\n+        ) as ReadManyFilesTool;\n+        if (readManyFilesTool) {\n+          // Read all files in the target directory\n+          const result = await readManyFilesTool.execute(\n+            {\n+              paths: ['**/*'], // Read everything recursively\n+              useDefaultExcludes: true, // Use default excludes\n+            },\n+            AbortSignal.timeout(30000),\n+          );\n+          if (result.llmContent) {\n+            initialParts.push({\n+              text: `\n--- Full File Context ---\n${result.llmContent}`,\n+            });\n+          } else {\n+            console.warn(\n+              'Full context requested, but read_many_files returned no content.',\n+            );\n+          }\n+        }\n+      } catch (error) {\n+        // This error is logged but doesn't halt the process, as full context is optional.\n+        console.error('Error reading full file context:', error);\n+        initialParts.push({\n+          text: '\n--- Error reading full file context ---',\n+        });\n+      }\n+    }\n+\n+    return initialParts;\n+  }\n+\n+  /**\n+   * Returns an array of FunctionDeclaration objects for tools that are local to the subagent's scope.\n+   * Currently, this includes the `self.emitvalue` tool for emitting variables.\n+   * @returns An array of `FunctionDeclaration` objects.\n+   */\n+  private getScopeLocalFuncDefs() {\n+    const emitValueTool: FunctionDeclaration = {\n+      name: 'self.emitvalue',\n+      description: `* This tool emits A SINGLE return value from this execution, such that it can be collected and presented to the calling function.\n+        * You can only emit ONE VALUE each time you call this tool. You are expected to call this tool MULTIPLE TIMES if you have MULTIPLE OUTPUTS.`,\n+      parameters: {\n+        type: Type.OBJECT,\n+        properties: {\n+          emit_variable_name: {\n+            description: 'This is the name of the variable to be returned.',\n+            type: Type.STRING,\n+          },\n+          emit_variable_value: {\n+            description:\n+              'This is the _value_ to be returned for this variable.',\n+            type: Type.STRING,\n+          },\n+        },\n+        required: ['emit_variable_name', 'emit_variable_value'],\n+      },\n+    };\n+\n+    return [emitValueTool];\n+  }\n+\n+  /**\n+   * Builds the system prompt for the chat, incorporating the subagent's plan, goals, and available tools.\n+   * This prompt is intentionally different from the main agent's prompt to allow for scoped work with specific tools or personas.\n+   * @param {ContextState} context - The current context state containing variables for prompt templating.\n+   * @param {FunctionDeclaration[]} toolsList - An array of `FunctionDeclaration` objects representing the tools available to the subagent.\n+   * @returns {string} The complete system prompt for the chat.\n+   */\n+  private buildChatSystemPrompt(\n+    context: ContextState,\n+    toolsList: FunctionDeclaration[],\n+  ): string {\n+    const templated_plan = templateString(this.promptConfig.plan, context);\n+    let templated_goals = templateString(this.promptConfig.goals, context);\n+\n+    // Add variable emission goals..\n+    for (const [key, value] of Object.entries(this.promptConfig.outputs)) {\n+      templated_goals += `\n* Use the 'self.emitvalue' tool to emit the '${key}' key, with a value described as '${value}'`;\n+    }\n+\n+    const input = `You are an expert AI that takes on all sorts of roles to accomplish tasks for the user. You will continue to iterate, and call tools until the goals are complete. \n+\n+Here are the tools you have access to, for this session, to solve the goals:\n+<TOOLS>",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2183019401",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 1805,
        "pr_file": "packages/core/src/core/subagent.ts",
        "discussion_id": "2183019401",
        "commented_code": "@@ -0,0 +1,599 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import { reportError } from '../utils/errorReporting.js';\n+import { ToolRegistry } from '../tools/tool-registry.js';\n+import { Config } from '../config/config.js';\n+import { ToolCallRequestInfo } from './turn.js';\n+import { executeToolCall } from './nonInteractiveToolExecutor.js';\n+import { createContentGenerator } from './contentGenerator.js';\n+import { getFolderStructure } from '../utils/getFolderStructure.js';\n+import {\n+  Content,\n+  Part,\n+  FunctionCall,\n+  GenerateContentConfig,\n+  FunctionDeclaration,\n+  Type,\n+} from '@google/genai';\n+import { GeminiChat } from './geminiChat.js';\n+import { ReadManyFilesTool } from '../tools/read-many-files.js';\n+\n+/**\n+ * @fileoverview Defines the configuration interfaces for a subagent.\n+ *\n+ * These interfaces specify the structure for defining the subagent's prompt,\n+ * the model parameters, and the execution settings.\n+ */\n+\n+/**\n+ * Describes the possible termination modes for a subagent.\n+ * This enum provides a clear indication of why a subagent's execution might have ended.\n+ */\n+export enum SubagentTerminateMode {\n+  /**\n+   * Indicates that the subagent's execution terminated due to an unrecoverable error.\n+   */\n+  ERROR = 'ERROR',\n+  /**\n+   * Indicates that the subagent's execution terminated because it exceeded the maximum allowed working time.\n+   */\n+  TIMEOUT = 'TIMEOUT',\n+  /**\n+   * Indicates that the subagent's execution successfully completed all its defined goals.\n+   */\n+  GOAL = 'GOAL',\n+}\n+\n+/**\n+ * Represents the output structure of a subagent's execution.\n+ * This interface defines the data that a subagent will return upon completion,\n+ * including any emitted variables and the reason for its termination.\n+ */\n+export interface OutputObject {\n+  /**\n+   * A record of key-value pairs representing variables emitted by the subagent\n+   * during its execution. These variables can be used by the calling agent.\n+   */\n+  emitted_vars: Record<string, string>;\n+  /**\n+   * The reason for the subagent's termination, indicating whether it completed\n+   * successfully, timed out, or encountered an error.\n+   */\n+  terminate_reason: SubagentTerminateMode;\n+}\n+\n+/**\n+ * Configures the prompt and expected behavior of the subagent.\n+ * This interface defines the essential parameters that guide the subagent's\n+ * interaction and task execution, including its plan, goals, and available tools.\n+ */\n+export interface PromptConfig {\n+  /** A high-level plan or strategy for the subagent to follow. */\n+  plan: string;\n+  /** The specific goals the subagent is expected to achieve. */\n+  goals: string;\n+  /** A list of expected output objects and the variables they should emit. */\n+  outputs: Record<string, string>;\n+  /** A list of tool names (in the tool registry) or full function declarations that the subagent is permitted to use. */\n+  tools: Array<string | FunctionDeclaration>;\n+}\n+\n+/**\n+ * Configures the generative model parameters for the subagent.\n+ * This interface specifies the model to be used and its associated generation settings,\n+ * such as temperature and top-p values, which influence the creativity and diversity of the model's output.\n+ */\n+export interface ModelConfig {\n+  /** The name or identifier of the model to be used. */\n+  model: string;\n+  /** The temperature for the model's sampling process. */\n+  temp: number;\n+  /** The top-p value for nucleus sampling. */\n+  top_p: number;\n+}\n+\n+/**\n+ * Configures the execution environment and constraints for the subagent.\n+ * This interface defines parameters that control the subagent's runtime behavior,\n+ * such as maximum execution time, to prevent infinite loops or excessive resource consumption.\n+ */\n+export interface RunConfig {\n+  /** The maximum execution time for the subagent in minutes. */\n+  max_time_minutes: number;\n+}\n+\n+/**\n+ * Manages the runtime context state for the subagent.\n+ * This class provides a mechanism to store and retrieve key-value pairs\n+ * that represent the dynamic state and variables accessible to the subagent\n+ * during its execution.\n+ */\n+export class ContextState {\n+  private state: Record<string, unknown> = {};\n+\n+  /**\n+   * Retrieves a value from the context state.\n+   *\n+   * @param key - The key of the value to retrieve.\n+   * @returns The value associated with the key, or undefined if the key is not found.\n+   */\n+  get(key: string): unknown {\n+    return this.state[key];\n+  }\n+\n+  /**\n+   * Sets a value in the context state.\n+   *\n+   * @param key - The key to set the value under.\n+   * @param value - The value to set.\n+   */\n+  set(key: string, value: unknown): void {\n+    this.state[key] = value;\n+  }\n+\n+  /**\n+   * Retrieves all keys in the context state.\n+   *\n+   * @returns An array of all keys in the context state.\n+   */\n+  get_keys(): string[] {\n+    return Object.keys(this.state);\n+  }\n+}\n+\n+/**\n+ * Replaces `${...}` placeholders in a template string with values from a context.\n+ *\n+ * This function identifies all placeholders in the format `${key}`, validates that\n+ * each key exists in the provided `ContextState`, and then performs the substitution.\n+ *\n+ * @param template The template string containing placeholders.\n+ * @param context The `ContextState` object providing placeholder values.\n+ * @returns The populated string with all placeholders replaced.\n+ * @throws {Error} if any placeholder key is not found in the context.\n+ */\n+function templateString(template: string, context: ContextState): string {\n+  const placeholderRegex = /\\$\\{(\\w+)\\}/g;\n+\n+  // First, find all unique keys required by the template.\n+  const requiredKeys = new Set(\n+    Array.from(template.matchAll(placeholderRegex), (match) => match[1]),\n+  );\n+\n+  // Check if all required keys exist in the context.\n+  const contextKeys = new Set(context.get_keys());\n+  const missingKeys = Array.from(requiredKeys).filter(\n+    (key) => !contextKeys.has(key),\n+  );\n+\n+  if (missingKeys.length > 0) {\n+    throw new Error(\n+      `Missing context values for the following keys: ${missingKeys.join(\n+        ', ',\n+      )}`,\n+    );\n+  }\n+\n+  // Perform the replacement using a replacer function.\n+  return template.replace(placeholderRegex, (_match, key) =>\n+    String(context.get(key)),\n+  );\n+}\n+\n+/**\n+ * Represents the scope and execution environment for a subagent.\n+ * This class orchestrates the subagent's lifecycle, managing its chat interactions,\n+ * runtime context, and the collection of its outputs.\n+ */\n+export class SubAgentScope {\n+  output: OutputObject = {\n+    terminate_reason: SubagentTerminateMode.ERROR,\n+    emitted_vars: {},\n+  };\n+\n+  /**\n+   * Constructs a new SubAgentScope instance.\n+   * @param runtimeContext - The shared runtime configuration and services.\n+   * @param promptConfig - Configuration for the subagent's prompt and behavior.\n+   * @param modelConfig - Configuration for the generative model parameters.\n+   * @param runConfig - Configuration for the subagent's execution environment and constraints.\n+   */\n+  constructor(\n+    readonly runtimeContext: Config,\n+    private readonly promptConfig: PromptConfig,\n+    private readonly modelConfig: ModelConfig,\n+    private readonly runConfig: RunConfig,\n+  ) {}\n+\n+  /**\n+   * Runs the subagent in a non-interactive mode.\n+   * This method orchestrates the subagent's execution loop, including prompt templating,\n+   * tool execution, and termination conditions. It manages the chat history, handles\n+   * tool calls, and determines when the subagent's goals are met or if a timeout occurs.\n+   * @param {ContextState} context - The current context state containing variables for prompt templating.\n+   * @returns {Promise<void>} A promise that resolves when the subagent has completed its execution.\n+   */\n+  async runNonInteractive(context: ContextState): Promise<void> {\n+    const chat = await this.createChatObject();\n+\n+    if (!chat) {\n+      this.output.terminate_reason = SubagentTerminateMode.ERROR;\n+      return;\n+    }\n+\n+    const abortController = new AbortController();\n+    const toolRegistry: ToolRegistry =\n+      await this.runtimeContext.getToolRegistry();\n+\n+    // Prepare the list of tools available to the subagent.\n+    const tools_to_load: string[] = [];\n+    const toolsList: FunctionDeclaration[] = [];\n+    for (const toolName of this.promptConfig.tools) {\n+      if (typeof toolName === 'string') {\n+        tools_to_load.push(toolName);\n+      } else {\n+        toolsList.push(toolName);\n+      }\n+    }\n+\n+    toolsList.push(\n+      ...toolRegistry.getFunctionDeclarationsFiltered(tools_to_load),\n+    );\n+    toolsList.push(...this.getScopeLocalFuncDefs());\n+\n+    chat.setSystemInstruction(this.buildChatSystemPrompt(context, toolsList));\n+\n+    let currentMessages: Content[] = [\n+      { role: 'user', parts: [{ text: 'Get Started!' }] },\n+    ];\n+\n+    const startTime = Date.now();\n+    try {\n+      while (true) {\n+        // Check for timeout.\n+        const duration = Date.now() - startTime;\n+        const durationMin = duration / (1000 * 60);\n+        if (durationMin >= this.runConfig.max_time_minutes) {\n+          this.output.terminate_reason = SubagentTerminateMode.TIMEOUT;\n+          break;\n+        }\n+\n+        const messageParams = {\n+          message: currentMessages[0]?.parts || [],\n+          config: {\n+            abortSignal: abortController.signal,\n+            tools: [{ functionDeclarations: toolsList }],\n+          },\n+        };\n+\n+        // Send the message to the GeminiChat object, which will manage its own history\n+        const responseStream = await chat.sendMessageStream(messageParams);\n+\n+        // Combine all chunks in stream for proper processing.\n+        const functionCalls: FunctionCall[] = [];\n+        for await (const resp of responseStream) {\n+          if (abortController.signal.aborted) {\n+            console.error('Operation cancelled.');\n+            return;\n+          }\n+\n+          const calls = resp.functionCalls;\n+          if (calls) {\n+            functionCalls.push(...calls);\n+          }\n+        }\n+\n+        if (functionCalls.length > 0) {\n+          currentMessages = await this.processFunctionCalls(\n+            functionCalls,\n+            toolRegistry,\n+            abortController,\n+            currentMessages,\n+          );\n+        } else {\n+          // The model has stopped calling tools, which signals completion.\n+          // Verify that all expected output variables have been emitted.\n+          const remainingVars = Object.keys(this.promptConfig.outputs).filter(\n+            (key) => !(key in this.output.emitted_vars),\n+          );\n+\n+          if (remainingVars.length === 0) {\n+            this.output.terminate_reason = SubagentTerminateMode.GOAL;\n+            break;\n+          }\n+\n+          // If variables are missing, the loop continues, relying on the\n+          // system prompt to guide the model to call self.emitvalue.\n+          console.debug(\n+            'Variables appear to be missing. Relying on model to call EmitValue.',\n+          );\n+        }\n+      }\n+    } catch (error) {\n+      console.error('Error during subagent execution:', error);\n+      this.output.terminate_reason = SubagentTerminateMode.ERROR;\n+      throw error;\n+    }\n+  }\n+\n+  /**\n+   * Processes a list of function calls, executing each one and collecting their responses.\n+   * This method iterates through the provided function calls, executes them using the\n+   * `executeToolCall` function (or handles `self.emitvalue` internally), and aggregates\n+   * their results. It also manages error reporting for failed tool executions.\n+   * @param {FunctionCall[]} functionCalls - An array of `FunctionCall` objects to process.\n+   * @param {ToolRegistry} toolRegistry - The tool registry to look up and execute tools.\n+   * @param {AbortController} abortController - An `AbortController` to signal cancellation of tool executions.\n+   * @param {Content[]} currentMessages - The current list of messages in the chat history, which will be updated with tool responses.\n+   * @returns {Promise<Content[]>} A promise that resolves to an array of `Content` parts representing the tool responses,\n+   *          which are then used to update the chat history.\n+   */\n+  private async processFunctionCalls(\n+    functionCalls: FunctionCall[],\n+    toolRegistry: ToolRegistry,\n+    abortController: AbortController,\n+    currentMessages: Content[],\n+  ) {\n+    const toolResponseParts: Part[] = [];\n+\n+    for (const functionCall of functionCalls) {\n+      const callId = functionCall.id ?? `${functionCall.name}-${Date.now()}`;\n+      const requestInfo: ToolCallRequestInfo = {\n+        callId,\n+        name: functionCall.name as string,\n+        args: (functionCall.args ?? {}) as Record<string, unknown>,\n+        isClientInitiated: true,\n+      };\n+\n+      let toolResponse;\n+\n+      // Handle scope-local tools first.\n+      if (callId.startsWith('self.emitvalue')) {\n+        const valName = String(requestInfo.args['emit_variable_name']);\n+        const valVal = String(requestInfo.args['emit_variable_value']);\n+        this.output.emitted_vars[valName] = valVal;\n+\n+        toolResponse = {\n+          callId,\n+          responseParts: `Emitted variable ${valName} successfully`,\n+          resultDisplay: `Emitted variable ${valName} successfully`,\n+          error: undefined,\n+        };\n+      } else {\n+        toolResponse = await executeToolCall(\n+          this.runtimeContext,\n+          requestInfo,\n+          toolRegistry,\n+          abortController.signal,\n+        );\n+      }\n+\n+      if (toolResponse.error) {\n+        console.error(\n+          `Error executing tool ${functionCall.name}: ${toolResponse.resultDisplay || toolResponse.error.message}`,\n+        );\n+        // Continue to the next tool call instead of halting execution.\n+        continue;\n+      }\n+\n+      if (toolResponse.responseParts) {\n+        const parts = Array.isArray(toolResponse.responseParts)\n+          ? toolResponse.responseParts\n+          : [toolResponse.responseParts];\n+        for (const part of parts) {\n+          if (typeof part === 'string') {\n+            toolResponseParts.push({ text: part });\n+          } else if (part) {\n+            toolResponseParts.push(part);\n+          }\n+        }\n+      }\n+    }\n+    currentMessages = [{ role: 'user', parts: toolResponseParts }];\n+    return currentMessages;\n+  }\n+\n+  /**\n+   * Creates an instance of `GeminiChat` unique for the subagent's purposes.\n+   * It initializes the chat with environment variables and configures the content generator.\n+   * @param {Content[]} [extraHistory] - Optional additional chat history to include.\n+   * @returns {Promise<GeminiChat | undefined>} A promise that resolves to a `GeminiChat` instance, or undefined if creation fails.\n+   */\n+  private async createChatObject(extraHistory?: Content[]) {\n+    const envParts = await this.getEnvironment();\n+    const initialHistory: Content[] = [\n+      {\n+        role: 'user',\n+        parts: envParts,\n+      },\n+      {\n+        role: 'model',\n+        parts: [{ text: 'Got it. Thanks for the context!' }],\n+      },\n+    ];\n+\n+    const start_history = [...initialHistory, ...(extraHistory ?? [])];\n+\n+    // The system instruction is set dynamically within the run loop to allow\n+    // for context-based templating.\n+    const systemInstruction = '';\n+\n+    try {\n+      const targetContentConfig: GenerateContentConfig = {\n+        temperature: this.modelConfig.temp,\n+        topP: this.modelConfig.top_p,\n+      };\n+\n+      const generationConfig = {\n+        systemInstruction,\n+        ...targetContentConfig,\n+      };\n+\n+      const contentGenerator = await createContentGenerator(\n+        this.runtimeContext.getContentGeneratorConfig(),\n+      );\n+\n+      this.runtimeContext.setModel(this.modelConfig.model);\n+\n+      return new GeminiChat(\n+        this.runtimeContext,\n+        contentGenerator,\n+        generationConfig,\n+        start_history,\n+      );\n+    } catch (error) {\n+      await reportError(\n+        error,\n+        'Error initializing Gemini chat session.',\n+        start_history,\n+        'startChat',\n+      );\n+      // The calling function will handle the undefined return.\n+      return undefined;\n+    }\n+  }\n+\n+  /**\n+   * Retrieves environment-related information to be included in the chat context.\n+   * This includes the current working directory, date, operating system, and folder structure.\n+   * Optionally, it can also include the full file context if enabled.\n+   * @returns A promise that resolves to an array of `Part` objects containing environment information.\n+   */\n+  private async getEnvironment(): Promise<Part[]> {\n+    const cwd = this.runtimeContext.getWorkingDir();\n+    const today = new Date().toLocaleDateString(undefined, {\n+      weekday: 'long',\n+      year: 'numeric',\n+      month: 'long',\n+      day: 'numeric',\n+    });\n+    const platform = process.platform;\n+    const folderStructure = await getFolderStructure(cwd, {\n+      fileService: this.runtimeContext.getFileService(),\n+    });\n+    const context = `\n+  Okay, just setting up the context for our chat.\n+  Today is ${today}.\n+  My operating system is: ${platform}\n+  I'm currently working in the directory: ${cwd}\n+  ${folderStructure}\n+          `.trim();\n+\n+    const initialParts: Part[] = [{ text: context }];\n+    const toolRegistry = await this.runtimeContext.getToolRegistry();\n+\n+    // Add full file context if the flag is set\n+    if (this.runtimeContext.getFullContext()) {\n+      try {\n+        const readManyFilesTool = toolRegistry.getTool(\n+          'read_many_files',\n+        ) as ReadManyFilesTool;\n+        if (readManyFilesTool) {\n+          // Read all files in the target directory\n+          const result = await readManyFilesTool.execute(\n+            {\n+              paths: ['**/*'], // Read everything recursively\n+              useDefaultExcludes: true, // Use default excludes\n+            },\n+            AbortSignal.timeout(30000),\n+          );\n+          if (result.llmContent) {\n+            initialParts.push({\n+              text: `\\n--- Full File Context ---\\n${result.llmContent}`,\n+            });\n+          } else {\n+            console.warn(\n+              'Full context requested, but read_many_files returned no content.',\n+            );\n+          }\n+        }\n+      } catch (error) {\n+        // This error is logged but doesn't halt the process, as full context is optional.\n+        console.error('Error reading full file context:', error);\n+        initialParts.push({\n+          text: '\\n--- Error reading full file context ---',\n+        });\n+      }\n+    }\n+\n+    return initialParts;\n+  }\n+\n+  /**\n+   * Returns an array of FunctionDeclaration objects for tools that are local to the subagent's scope.\n+   * Currently, this includes the `self.emitvalue` tool for emitting variables.\n+   * @returns An array of `FunctionDeclaration` objects.\n+   */\n+  private getScopeLocalFuncDefs() {\n+    const emitValueTool: FunctionDeclaration = {\n+      name: 'self.emitvalue',\n+      description: `* This tool emits A SINGLE return value from this execution, such that it can be collected and presented to the calling function.\n+        * You can only emit ONE VALUE each time you call this tool. You are expected to call this tool MULTIPLE TIMES if you have MULTIPLE OUTPUTS.`,\n+      parameters: {\n+        type: Type.OBJECT,\n+        properties: {\n+          emit_variable_name: {\n+            description: 'This is the name of the variable to be returned.',\n+            type: Type.STRING,\n+          },\n+          emit_variable_value: {\n+            description:\n+              'This is the _value_ to be returned for this variable.',\n+            type: Type.STRING,\n+          },\n+        },\n+        required: ['emit_variable_name', 'emit_variable_value'],\n+      },\n+    };\n+\n+    return [emitValueTool];\n+  }\n+\n+  /**\n+   * Builds the system prompt for the chat, incorporating the subagent's plan, goals, and available tools.\n+   * This prompt is intentionally different from the main agent's prompt to allow for scoped work with specific tools or personas.\n+   * @param {ContextState} context - The current context state containing variables for prompt templating.\n+   * @param {FunctionDeclaration[]} toolsList - An array of `FunctionDeclaration` objects representing the tools available to the subagent.\n+   * @returns {string} The complete system prompt for the chat.\n+   */\n+  private buildChatSystemPrompt(\n+    context: ContextState,\n+    toolsList: FunctionDeclaration[],\n+  ): string {\n+    const templated_plan = templateString(this.promptConfig.plan, context);\n+    let templated_goals = templateString(this.promptConfig.goals, context);\n+\n+    // Add variable emission goals..\n+    for (const [key, value] of Object.entries(this.promptConfig.outputs)) {\n+      templated_goals += `\\n* Use the 'self.emitvalue' tool to emit the '${key}' key, with a value described as '${value}'`;\n+    }\n+\n+    const input = `You are an expert AI that takes on all sorts of roles to accomplish tasks for the user. You will continue to iterate, and call tools until the goals are complete. \n+\n+Here are the tools you have access to, for this session, to solve the goals:\n+<TOOLS>",
        "comment_created_at": "2025-07-03T15:01:20+00:00",
        "comment_author": "NTaylorMullen",
        "comment_body": "Why re-iterate the tools in this way when the core Gemini stack does this already?",
        "pr_file_module": null
      },
      {
        "comment_id": "2188286965",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 1805,
        "pr_file": "packages/core/src/core/subagent.ts",
        "discussion_id": "2183019401",
        "commented_code": "@@ -0,0 +1,599 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import { reportError } from '../utils/errorReporting.js';\n+import { ToolRegistry } from '../tools/tool-registry.js';\n+import { Config } from '../config/config.js';\n+import { ToolCallRequestInfo } from './turn.js';\n+import { executeToolCall } from './nonInteractiveToolExecutor.js';\n+import { createContentGenerator } from './contentGenerator.js';\n+import { getFolderStructure } from '../utils/getFolderStructure.js';\n+import {\n+  Content,\n+  Part,\n+  FunctionCall,\n+  GenerateContentConfig,\n+  FunctionDeclaration,\n+  Type,\n+} from '@google/genai';\n+import { GeminiChat } from './geminiChat.js';\n+import { ReadManyFilesTool } from '../tools/read-many-files.js';\n+\n+/**\n+ * @fileoverview Defines the configuration interfaces for a subagent.\n+ *\n+ * These interfaces specify the structure for defining the subagent's prompt,\n+ * the model parameters, and the execution settings.\n+ */\n+\n+/**\n+ * Describes the possible termination modes for a subagent.\n+ * This enum provides a clear indication of why a subagent's execution might have ended.\n+ */\n+export enum SubagentTerminateMode {\n+  /**\n+   * Indicates that the subagent's execution terminated due to an unrecoverable error.\n+   */\n+  ERROR = 'ERROR',\n+  /**\n+   * Indicates that the subagent's execution terminated because it exceeded the maximum allowed working time.\n+   */\n+  TIMEOUT = 'TIMEOUT',\n+  /**\n+   * Indicates that the subagent's execution successfully completed all its defined goals.\n+   */\n+  GOAL = 'GOAL',\n+}\n+\n+/**\n+ * Represents the output structure of a subagent's execution.\n+ * This interface defines the data that a subagent will return upon completion,\n+ * including any emitted variables and the reason for its termination.\n+ */\n+export interface OutputObject {\n+  /**\n+   * A record of key-value pairs representing variables emitted by the subagent\n+   * during its execution. These variables can be used by the calling agent.\n+   */\n+  emitted_vars: Record<string, string>;\n+  /**\n+   * The reason for the subagent's termination, indicating whether it completed\n+   * successfully, timed out, or encountered an error.\n+   */\n+  terminate_reason: SubagentTerminateMode;\n+}\n+\n+/**\n+ * Configures the prompt and expected behavior of the subagent.\n+ * This interface defines the essential parameters that guide the subagent's\n+ * interaction and task execution, including its plan, goals, and available tools.\n+ */\n+export interface PromptConfig {\n+  /** A high-level plan or strategy for the subagent to follow. */\n+  plan: string;\n+  /** The specific goals the subagent is expected to achieve. */\n+  goals: string;\n+  /** A list of expected output objects and the variables they should emit. */\n+  outputs: Record<string, string>;\n+  /** A list of tool names (in the tool registry) or full function declarations that the subagent is permitted to use. */\n+  tools: Array<string | FunctionDeclaration>;\n+}\n+\n+/**\n+ * Configures the generative model parameters for the subagent.\n+ * This interface specifies the model to be used and its associated generation settings,\n+ * such as temperature and top-p values, which influence the creativity and diversity of the model's output.\n+ */\n+export interface ModelConfig {\n+  /** The name or identifier of the model to be used. */\n+  model: string;\n+  /** The temperature for the model's sampling process. */\n+  temp: number;\n+  /** The top-p value for nucleus sampling. */\n+  top_p: number;\n+}\n+\n+/**\n+ * Configures the execution environment and constraints for the subagent.\n+ * This interface defines parameters that control the subagent's runtime behavior,\n+ * such as maximum execution time, to prevent infinite loops or excessive resource consumption.\n+ */\n+export interface RunConfig {\n+  /** The maximum execution time for the subagent in minutes. */\n+  max_time_minutes: number;\n+}\n+\n+/**\n+ * Manages the runtime context state for the subagent.\n+ * This class provides a mechanism to store and retrieve key-value pairs\n+ * that represent the dynamic state and variables accessible to the subagent\n+ * during its execution.\n+ */\n+export class ContextState {\n+  private state: Record<string, unknown> = {};\n+\n+  /**\n+   * Retrieves a value from the context state.\n+   *\n+   * @param key - The key of the value to retrieve.\n+   * @returns The value associated with the key, or undefined if the key is not found.\n+   */\n+  get(key: string): unknown {\n+    return this.state[key];\n+  }\n+\n+  /**\n+   * Sets a value in the context state.\n+   *\n+   * @param key - The key to set the value under.\n+   * @param value - The value to set.\n+   */\n+  set(key: string, value: unknown): void {\n+    this.state[key] = value;\n+  }\n+\n+  /**\n+   * Retrieves all keys in the context state.\n+   *\n+   * @returns An array of all keys in the context state.\n+   */\n+  get_keys(): string[] {\n+    return Object.keys(this.state);\n+  }\n+}\n+\n+/**\n+ * Replaces `${...}` placeholders in a template string with values from a context.\n+ *\n+ * This function identifies all placeholders in the format `${key}`, validates that\n+ * each key exists in the provided `ContextState`, and then performs the substitution.\n+ *\n+ * @param template The template string containing placeholders.\n+ * @param context The `ContextState` object providing placeholder values.\n+ * @returns The populated string with all placeholders replaced.\n+ * @throws {Error} if any placeholder key is not found in the context.\n+ */\n+function templateString(template: string, context: ContextState): string {\n+  const placeholderRegex = /\\$\\{(\\w+)\\}/g;\n+\n+  // First, find all unique keys required by the template.\n+  const requiredKeys = new Set(\n+    Array.from(template.matchAll(placeholderRegex), (match) => match[1]),\n+  );\n+\n+  // Check if all required keys exist in the context.\n+  const contextKeys = new Set(context.get_keys());\n+  const missingKeys = Array.from(requiredKeys).filter(\n+    (key) => !contextKeys.has(key),\n+  );\n+\n+  if (missingKeys.length > 0) {\n+    throw new Error(\n+      `Missing context values for the following keys: ${missingKeys.join(\n+        ', ',\n+      )}`,\n+    );\n+  }\n+\n+  // Perform the replacement using a replacer function.\n+  return template.replace(placeholderRegex, (_match, key) =>\n+    String(context.get(key)),\n+  );\n+}\n+\n+/**\n+ * Represents the scope and execution environment for a subagent.\n+ * This class orchestrates the subagent's lifecycle, managing its chat interactions,\n+ * runtime context, and the collection of its outputs.\n+ */\n+export class SubAgentScope {\n+  output: OutputObject = {\n+    terminate_reason: SubagentTerminateMode.ERROR,\n+    emitted_vars: {},\n+  };\n+\n+  /**\n+   * Constructs a new SubAgentScope instance.\n+   * @param runtimeContext - The shared runtime configuration and services.\n+   * @param promptConfig - Configuration for the subagent's prompt and behavior.\n+   * @param modelConfig - Configuration for the generative model parameters.\n+   * @param runConfig - Configuration for the subagent's execution environment and constraints.\n+   */\n+  constructor(\n+    readonly runtimeContext: Config,\n+    private readonly promptConfig: PromptConfig,\n+    private readonly modelConfig: ModelConfig,\n+    private readonly runConfig: RunConfig,\n+  ) {}\n+\n+  /**\n+   * Runs the subagent in a non-interactive mode.\n+   * This method orchestrates the subagent's execution loop, including prompt templating,\n+   * tool execution, and termination conditions. It manages the chat history, handles\n+   * tool calls, and determines when the subagent's goals are met or if a timeout occurs.\n+   * @param {ContextState} context - The current context state containing variables for prompt templating.\n+   * @returns {Promise<void>} A promise that resolves when the subagent has completed its execution.\n+   */\n+  async runNonInteractive(context: ContextState): Promise<void> {\n+    const chat = await this.createChatObject();\n+\n+    if (!chat) {\n+      this.output.terminate_reason = SubagentTerminateMode.ERROR;\n+      return;\n+    }\n+\n+    const abortController = new AbortController();\n+    const toolRegistry: ToolRegistry =\n+      await this.runtimeContext.getToolRegistry();\n+\n+    // Prepare the list of tools available to the subagent.\n+    const tools_to_load: string[] = [];\n+    const toolsList: FunctionDeclaration[] = [];\n+    for (const toolName of this.promptConfig.tools) {\n+      if (typeof toolName === 'string') {\n+        tools_to_load.push(toolName);\n+      } else {\n+        toolsList.push(toolName);\n+      }\n+    }\n+\n+    toolsList.push(\n+      ...toolRegistry.getFunctionDeclarationsFiltered(tools_to_load),\n+    );\n+    toolsList.push(...this.getScopeLocalFuncDefs());\n+\n+    chat.setSystemInstruction(this.buildChatSystemPrompt(context, toolsList));\n+\n+    let currentMessages: Content[] = [\n+      { role: 'user', parts: [{ text: 'Get Started!' }] },\n+    ];\n+\n+    const startTime = Date.now();\n+    try {\n+      while (true) {\n+        // Check for timeout.\n+        const duration = Date.now() - startTime;\n+        const durationMin = duration / (1000 * 60);\n+        if (durationMin >= this.runConfig.max_time_minutes) {\n+          this.output.terminate_reason = SubagentTerminateMode.TIMEOUT;\n+          break;\n+        }\n+\n+        const messageParams = {\n+          message: currentMessages[0]?.parts || [],\n+          config: {\n+            abortSignal: abortController.signal,\n+            tools: [{ functionDeclarations: toolsList }],\n+          },\n+        };\n+\n+        // Send the message to the GeminiChat object, which will manage its own history\n+        const responseStream = await chat.sendMessageStream(messageParams);\n+\n+        // Combine all chunks in stream for proper processing.\n+        const functionCalls: FunctionCall[] = [];\n+        for await (const resp of responseStream) {\n+          if (abortController.signal.aborted) {\n+            console.error('Operation cancelled.');\n+            return;\n+          }\n+\n+          const calls = resp.functionCalls;\n+          if (calls) {\n+            functionCalls.push(...calls);\n+          }\n+        }\n+\n+        if (functionCalls.length > 0) {\n+          currentMessages = await this.processFunctionCalls(\n+            functionCalls,\n+            toolRegistry,\n+            abortController,\n+            currentMessages,\n+          );\n+        } else {\n+          // The model has stopped calling tools, which signals completion.\n+          // Verify that all expected output variables have been emitted.\n+          const remainingVars = Object.keys(this.promptConfig.outputs).filter(\n+            (key) => !(key in this.output.emitted_vars),\n+          );\n+\n+          if (remainingVars.length === 0) {\n+            this.output.terminate_reason = SubagentTerminateMode.GOAL;\n+            break;\n+          }\n+\n+          // If variables are missing, the loop continues, relying on the\n+          // system prompt to guide the model to call self.emitvalue.\n+          console.debug(\n+            'Variables appear to be missing. Relying on model to call EmitValue.',\n+          );\n+        }\n+      }\n+    } catch (error) {\n+      console.error('Error during subagent execution:', error);\n+      this.output.terminate_reason = SubagentTerminateMode.ERROR;\n+      throw error;\n+    }\n+  }\n+\n+  /**\n+   * Processes a list of function calls, executing each one and collecting their responses.\n+   * This method iterates through the provided function calls, executes them using the\n+   * `executeToolCall` function (or handles `self.emitvalue` internally), and aggregates\n+   * their results. It also manages error reporting for failed tool executions.\n+   * @param {FunctionCall[]} functionCalls - An array of `FunctionCall` objects to process.\n+   * @param {ToolRegistry} toolRegistry - The tool registry to look up and execute tools.\n+   * @param {AbortController} abortController - An `AbortController` to signal cancellation of tool executions.\n+   * @param {Content[]} currentMessages - The current list of messages in the chat history, which will be updated with tool responses.\n+   * @returns {Promise<Content[]>} A promise that resolves to an array of `Content` parts representing the tool responses,\n+   *          which are then used to update the chat history.\n+   */\n+  private async processFunctionCalls(\n+    functionCalls: FunctionCall[],\n+    toolRegistry: ToolRegistry,\n+    abortController: AbortController,\n+    currentMessages: Content[],\n+  ) {\n+    const toolResponseParts: Part[] = [];\n+\n+    for (const functionCall of functionCalls) {\n+      const callId = functionCall.id ?? `${functionCall.name}-${Date.now()}`;\n+      const requestInfo: ToolCallRequestInfo = {\n+        callId,\n+        name: functionCall.name as string,\n+        args: (functionCall.args ?? {}) as Record<string, unknown>,\n+        isClientInitiated: true,\n+      };\n+\n+      let toolResponse;\n+\n+      // Handle scope-local tools first.\n+      if (callId.startsWith('self.emitvalue')) {\n+        const valName = String(requestInfo.args['emit_variable_name']);\n+        const valVal = String(requestInfo.args['emit_variable_value']);\n+        this.output.emitted_vars[valName] = valVal;\n+\n+        toolResponse = {\n+          callId,\n+          responseParts: `Emitted variable ${valName} successfully`,\n+          resultDisplay: `Emitted variable ${valName} successfully`,\n+          error: undefined,\n+        };\n+      } else {\n+        toolResponse = await executeToolCall(\n+          this.runtimeContext,\n+          requestInfo,\n+          toolRegistry,\n+          abortController.signal,\n+        );\n+      }\n+\n+      if (toolResponse.error) {\n+        console.error(\n+          `Error executing tool ${functionCall.name}: ${toolResponse.resultDisplay || toolResponse.error.message}`,\n+        );\n+        // Continue to the next tool call instead of halting execution.\n+        continue;\n+      }\n+\n+      if (toolResponse.responseParts) {\n+        const parts = Array.isArray(toolResponse.responseParts)\n+          ? toolResponse.responseParts\n+          : [toolResponse.responseParts];\n+        for (const part of parts) {\n+          if (typeof part === 'string') {\n+            toolResponseParts.push({ text: part });\n+          } else if (part) {\n+            toolResponseParts.push(part);\n+          }\n+        }\n+      }\n+    }\n+    currentMessages = [{ role: 'user', parts: toolResponseParts }];\n+    return currentMessages;\n+  }\n+\n+  /**\n+   * Creates an instance of `GeminiChat` unique for the subagent's purposes.\n+   * It initializes the chat with environment variables and configures the content generator.\n+   * @param {Content[]} [extraHistory] - Optional additional chat history to include.\n+   * @returns {Promise<GeminiChat | undefined>} A promise that resolves to a `GeminiChat` instance, or undefined if creation fails.\n+   */\n+  private async createChatObject(extraHistory?: Content[]) {\n+    const envParts = await this.getEnvironment();\n+    const initialHistory: Content[] = [\n+      {\n+        role: 'user',\n+        parts: envParts,\n+      },\n+      {\n+        role: 'model',\n+        parts: [{ text: 'Got it. Thanks for the context!' }],\n+      },\n+    ];\n+\n+    const start_history = [...initialHistory, ...(extraHistory ?? [])];\n+\n+    // The system instruction is set dynamically within the run loop to allow\n+    // for context-based templating.\n+    const systemInstruction = '';\n+\n+    try {\n+      const targetContentConfig: GenerateContentConfig = {\n+        temperature: this.modelConfig.temp,\n+        topP: this.modelConfig.top_p,\n+      };\n+\n+      const generationConfig = {\n+        systemInstruction,\n+        ...targetContentConfig,\n+      };\n+\n+      const contentGenerator = await createContentGenerator(\n+        this.runtimeContext.getContentGeneratorConfig(),\n+      );\n+\n+      this.runtimeContext.setModel(this.modelConfig.model);\n+\n+      return new GeminiChat(\n+        this.runtimeContext,\n+        contentGenerator,\n+        generationConfig,\n+        start_history,\n+      );\n+    } catch (error) {\n+      await reportError(\n+        error,\n+        'Error initializing Gemini chat session.',\n+        start_history,\n+        'startChat',\n+      );\n+      // The calling function will handle the undefined return.\n+      return undefined;\n+    }\n+  }\n+\n+  /**\n+   * Retrieves environment-related information to be included in the chat context.\n+   * This includes the current working directory, date, operating system, and folder structure.\n+   * Optionally, it can also include the full file context if enabled.\n+   * @returns A promise that resolves to an array of `Part` objects containing environment information.\n+   */\n+  private async getEnvironment(): Promise<Part[]> {\n+    const cwd = this.runtimeContext.getWorkingDir();\n+    const today = new Date().toLocaleDateString(undefined, {\n+      weekday: 'long',\n+      year: 'numeric',\n+      month: 'long',\n+      day: 'numeric',\n+    });\n+    const platform = process.platform;\n+    const folderStructure = await getFolderStructure(cwd, {\n+      fileService: this.runtimeContext.getFileService(),\n+    });\n+    const context = `\n+  Okay, just setting up the context for our chat.\n+  Today is ${today}.\n+  My operating system is: ${platform}\n+  I'm currently working in the directory: ${cwd}\n+  ${folderStructure}\n+          `.trim();\n+\n+    const initialParts: Part[] = [{ text: context }];\n+    const toolRegistry = await this.runtimeContext.getToolRegistry();\n+\n+    // Add full file context if the flag is set\n+    if (this.runtimeContext.getFullContext()) {\n+      try {\n+        const readManyFilesTool = toolRegistry.getTool(\n+          'read_many_files',\n+        ) as ReadManyFilesTool;\n+        if (readManyFilesTool) {\n+          // Read all files in the target directory\n+          const result = await readManyFilesTool.execute(\n+            {\n+              paths: ['**/*'], // Read everything recursively\n+              useDefaultExcludes: true, // Use default excludes\n+            },\n+            AbortSignal.timeout(30000),\n+          );\n+          if (result.llmContent) {\n+            initialParts.push({\n+              text: `\\n--- Full File Context ---\\n${result.llmContent}`,\n+            });\n+          } else {\n+            console.warn(\n+              'Full context requested, but read_many_files returned no content.',\n+            );\n+          }\n+        }\n+      } catch (error) {\n+        // This error is logged but doesn't halt the process, as full context is optional.\n+        console.error('Error reading full file context:', error);\n+        initialParts.push({\n+          text: '\\n--- Error reading full file context ---',\n+        });\n+      }\n+    }\n+\n+    return initialParts;\n+  }\n+\n+  /**\n+   * Returns an array of FunctionDeclaration objects for tools that are local to the subagent's scope.\n+   * Currently, this includes the `self.emitvalue` tool for emitting variables.\n+   * @returns An array of `FunctionDeclaration` objects.\n+   */\n+  private getScopeLocalFuncDefs() {\n+    const emitValueTool: FunctionDeclaration = {\n+      name: 'self.emitvalue',\n+      description: `* This tool emits A SINGLE return value from this execution, such that it can be collected and presented to the calling function.\n+        * You can only emit ONE VALUE each time you call this tool. You are expected to call this tool MULTIPLE TIMES if you have MULTIPLE OUTPUTS.`,\n+      parameters: {\n+        type: Type.OBJECT,\n+        properties: {\n+          emit_variable_name: {\n+            description: 'This is the name of the variable to be returned.',\n+            type: Type.STRING,\n+          },\n+          emit_variable_value: {\n+            description:\n+              'This is the _value_ to be returned for this variable.',\n+            type: Type.STRING,\n+          },\n+        },\n+        required: ['emit_variable_name', 'emit_variable_value'],\n+      },\n+    };\n+\n+    return [emitValueTool];\n+  }\n+\n+  /**\n+   * Builds the system prompt for the chat, incorporating the subagent's plan, goals, and available tools.\n+   * This prompt is intentionally different from the main agent's prompt to allow for scoped work with specific tools or personas.\n+   * @param {ContextState} context - The current context state containing variables for prompt templating.\n+   * @param {FunctionDeclaration[]} toolsList - An array of `FunctionDeclaration` objects representing the tools available to the subagent.\n+   * @returns {string} The complete system prompt for the chat.\n+   */\n+  private buildChatSystemPrompt(\n+    context: ContextState,\n+    toolsList: FunctionDeclaration[],\n+  ): string {\n+    const templated_plan = templateString(this.promptConfig.plan, context);\n+    let templated_goals = templateString(this.promptConfig.goals, context);\n+\n+    // Add variable emission goals..\n+    for (const [key, value] of Object.entries(this.promptConfig.outputs)) {\n+      templated_goals += `\\n* Use the 'self.emitvalue' tool to emit the '${key}' key, with a value described as '${value}'`;\n+    }\n+\n+    const input = `You are an expert AI that takes on all sorts of roles to accomplish tasks for the user. You will continue to iterate, and call tools until the goals are complete. \n+\n+Here are the tools you have access to, for this session, to solve the goals:\n+<TOOLS>",
        "comment_created_at": "2025-07-06T13:37:15+00:00",
        "comment_author": "mainroach",
        "comment_body": "Initial testing was showing that w/o this block, tools would not be called by the GenAI::GenerateContent invocation. \r\n\r\nWe tested probably 40-50 iterations, and was unable to get generateContent call inside of GeminiChat to produce a tool call correctly w/o some reference to the tools themselves. We also tried just listing the _names_ of the tools (similar to how prompts.ts does it), but that also resulted in lack of tool invocation. After a few iterations, we found that we had to include the full definition list.\r\n\r\nNow, it may be that the full definition list was required during the initial phases of testing due to the _brevity_ of this prompt, and that building a larger prompt (like prompts.ts) would trigger the GenerateContent invocation to return tools properly.. or that something else is going on \ud83e\udd37 .\r\n\r\nWe will take a look at this before submitting the updated PR.\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2188458829",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 1805,
        "pr_file": "packages/core/src/core/subagent.ts",
        "discussion_id": "2183019401",
        "commented_code": "@@ -0,0 +1,599 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import { reportError } from '../utils/errorReporting.js';\n+import { ToolRegistry } from '../tools/tool-registry.js';\n+import { Config } from '../config/config.js';\n+import { ToolCallRequestInfo } from './turn.js';\n+import { executeToolCall } from './nonInteractiveToolExecutor.js';\n+import { createContentGenerator } from './contentGenerator.js';\n+import { getFolderStructure } from '../utils/getFolderStructure.js';\n+import {\n+  Content,\n+  Part,\n+  FunctionCall,\n+  GenerateContentConfig,\n+  FunctionDeclaration,\n+  Type,\n+} from '@google/genai';\n+import { GeminiChat } from './geminiChat.js';\n+import { ReadManyFilesTool } from '../tools/read-many-files.js';\n+\n+/**\n+ * @fileoverview Defines the configuration interfaces for a subagent.\n+ *\n+ * These interfaces specify the structure for defining the subagent's prompt,\n+ * the model parameters, and the execution settings.\n+ */\n+\n+/**\n+ * Describes the possible termination modes for a subagent.\n+ * This enum provides a clear indication of why a subagent's execution might have ended.\n+ */\n+export enum SubagentTerminateMode {\n+  /**\n+   * Indicates that the subagent's execution terminated due to an unrecoverable error.\n+   */\n+  ERROR = 'ERROR',\n+  /**\n+   * Indicates that the subagent's execution terminated because it exceeded the maximum allowed working time.\n+   */\n+  TIMEOUT = 'TIMEOUT',\n+  /**\n+   * Indicates that the subagent's execution successfully completed all its defined goals.\n+   */\n+  GOAL = 'GOAL',\n+}\n+\n+/**\n+ * Represents the output structure of a subagent's execution.\n+ * This interface defines the data that a subagent will return upon completion,\n+ * including any emitted variables and the reason for its termination.\n+ */\n+export interface OutputObject {\n+  /**\n+   * A record of key-value pairs representing variables emitted by the subagent\n+   * during its execution. These variables can be used by the calling agent.\n+   */\n+  emitted_vars: Record<string, string>;\n+  /**\n+   * The reason for the subagent's termination, indicating whether it completed\n+   * successfully, timed out, or encountered an error.\n+   */\n+  terminate_reason: SubagentTerminateMode;\n+}\n+\n+/**\n+ * Configures the prompt and expected behavior of the subagent.\n+ * This interface defines the essential parameters that guide the subagent's\n+ * interaction and task execution, including its plan, goals, and available tools.\n+ */\n+export interface PromptConfig {\n+  /** A high-level plan or strategy for the subagent to follow. */\n+  plan: string;\n+  /** The specific goals the subagent is expected to achieve. */\n+  goals: string;\n+  /** A list of expected output objects and the variables they should emit. */\n+  outputs: Record<string, string>;\n+  /** A list of tool names (in the tool registry) or full function declarations that the subagent is permitted to use. */\n+  tools: Array<string | FunctionDeclaration>;\n+}\n+\n+/**\n+ * Configures the generative model parameters for the subagent.\n+ * This interface specifies the model to be used and its associated generation settings,\n+ * such as temperature and top-p values, which influence the creativity and diversity of the model's output.\n+ */\n+export interface ModelConfig {\n+  /** The name or identifier of the model to be used. */\n+  model: string;\n+  /** The temperature for the model's sampling process. */\n+  temp: number;\n+  /** The top-p value for nucleus sampling. */\n+  top_p: number;\n+}\n+\n+/**\n+ * Configures the execution environment and constraints for the subagent.\n+ * This interface defines parameters that control the subagent's runtime behavior,\n+ * such as maximum execution time, to prevent infinite loops or excessive resource consumption.\n+ */\n+export interface RunConfig {\n+  /** The maximum execution time for the subagent in minutes. */\n+  max_time_minutes: number;\n+}\n+\n+/**\n+ * Manages the runtime context state for the subagent.\n+ * This class provides a mechanism to store and retrieve key-value pairs\n+ * that represent the dynamic state and variables accessible to the subagent\n+ * during its execution.\n+ */\n+export class ContextState {\n+  private state: Record<string, unknown> = {};\n+\n+  /**\n+   * Retrieves a value from the context state.\n+   *\n+   * @param key - The key of the value to retrieve.\n+   * @returns The value associated with the key, or undefined if the key is not found.\n+   */\n+  get(key: string): unknown {\n+    return this.state[key];\n+  }\n+\n+  /**\n+   * Sets a value in the context state.\n+   *\n+   * @param key - The key to set the value under.\n+   * @param value - The value to set.\n+   */\n+  set(key: string, value: unknown): void {\n+    this.state[key] = value;\n+  }\n+\n+  /**\n+   * Retrieves all keys in the context state.\n+   *\n+   * @returns An array of all keys in the context state.\n+   */\n+  get_keys(): string[] {\n+    return Object.keys(this.state);\n+  }\n+}\n+\n+/**\n+ * Replaces `${...}` placeholders in a template string with values from a context.\n+ *\n+ * This function identifies all placeholders in the format `${key}`, validates that\n+ * each key exists in the provided `ContextState`, and then performs the substitution.\n+ *\n+ * @param template The template string containing placeholders.\n+ * @param context The `ContextState` object providing placeholder values.\n+ * @returns The populated string with all placeholders replaced.\n+ * @throws {Error} if any placeholder key is not found in the context.\n+ */\n+function templateString(template: string, context: ContextState): string {\n+  const placeholderRegex = /\\$\\{(\\w+)\\}/g;\n+\n+  // First, find all unique keys required by the template.\n+  const requiredKeys = new Set(\n+    Array.from(template.matchAll(placeholderRegex), (match) => match[1]),\n+  );\n+\n+  // Check if all required keys exist in the context.\n+  const contextKeys = new Set(context.get_keys());\n+  const missingKeys = Array.from(requiredKeys).filter(\n+    (key) => !contextKeys.has(key),\n+  );\n+\n+  if (missingKeys.length > 0) {\n+    throw new Error(\n+      `Missing context values for the following keys: ${missingKeys.join(\n+        ', ',\n+      )}`,\n+    );\n+  }\n+\n+  // Perform the replacement using a replacer function.\n+  return template.replace(placeholderRegex, (_match, key) =>\n+    String(context.get(key)),\n+  );\n+}\n+\n+/**\n+ * Represents the scope and execution environment for a subagent.\n+ * This class orchestrates the subagent's lifecycle, managing its chat interactions,\n+ * runtime context, and the collection of its outputs.\n+ */\n+export class SubAgentScope {\n+  output: OutputObject = {\n+    terminate_reason: SubagentTerminateMode.ERROR,\n+    emitted_vars: {},\n+  };\n+\n+  /**\n+   * Constructs a new SubAgentScope instance.\n+   * @param runtimeContext - The shared runtime configuration and services.\n+   * @param promptConfig - Configuration for the subagent's prompt and behavior.\n+   * @param modelConfig - Configuration for the generative model parameters.\n+   * @param runConfig - Configuration for the subagent's execution environment and constraints.\n+   */\n+  constructor(\n+    readonly runtimeContext: Config,\n+    private readonly promptConfig: PromptConfig,\n+    private readonly modelConfig: ModelConfig,\n+    private readonly runConfig: RunConfig,\n+  ) {}\n+\n+  /**\n+   * Runs the subagent in a non-interactive mode.\n+   * This method orchestrates the subagent's execution loop, including prompt templating,\n+   * tool execution, and termination conditions. It manages the chat history, handles\n+   * tool calls, and determines when the subagent's goals are met or if a timeout occurs.\n+   * @param {ContextState} context - The current context state containing variables for prompt templating.\n+   * @returns {Promise<void>} A promise that resolves when the subagent has completed its execution.\n+   */\n+  async runNonInteractive(context: ContextState): Promise<void> {\n+    const chat = await this.createChatObject();\n+\n+    if (!chat) {\n+      this.output.terminate_reason = SubagentTerminateMode.ERROR;\n+      return;\n+    }\n+\n+    const abortController = new AbortController();\n+    const toolRegistry: ToolRegistry =\n+      await this.runtimeContext.getToolRegistry();\n+\n+    // Prepare the list of tools available to the subagent.\n+    const tools_to_load: string[] = [];\n+    const toolsList: FunctionDeclaration[] = [];\n+    for (const toolName of this.promptConfig.tools) {\n+      if (typeof toolName === 'string') {\n+        tools_to_load.push(toolName);\n+      } else {\n+        toolsList.push(toolName);\n+      }\n+    }\n+\n+    toolsList.push(\n+      ...toolRegistry.getFunctionDeclarationsFiltered(tools_to_load),\n+    );\n+    toolsList.push(...this.getScopeLocalFuncDefs());\n+\n+    chat.setSystemInstruction(this.buildChatSystemPrompt(context, toolsList));\n+\n+    let currentMessages: Content[] = [\n+      { role: 'user', parts: [{ text: 'Get Started!' }] },\n+    ];\n+\n+    const startTime = Date.now();\n+    try {\n+      while (true) {\n+        // Check for timeout.\n+        const duration = Date.now() - startTime;\n+        const durationMin = duration / (1000 * 60);\n+        if (durationMin >= this.runConfig.max_time_minutes) {\n+          this.output.terminate_reason = SubagentTerminateMode.TIMEOUT;\n+          break;\n+        }\n+\n+        const messageParams = {\n+          message: currentMessages[0]?.parts || [],\n+          config: {\n+            abortSignal: abortController.signal,\n+            tools: [{ functionDeclarations: toolsList }],\n+          },\n+        };\n+\n+        // Send the message to the GeminiChat object, which will manage its own history\n+        const responseStream = await chat.sendMessageStream(messageParams);\n+\n+        // Combine all chunks in stream for proper processing.\n+        const functionCalls: FunctionCall[] = [];\n+        for await (const resp of responseStream) {\n+          if (abortController.signal.aborted) {\n+            console.error('Operation cancelled.');\n+            return;\n+          }\n+\n+          const calls = resp.functionCalls;\n+          if (calls) {\n+            functionCalls.push(...calls);\n+          }\n+        }\n+\n+        if (functionCalls.length > 0) {\n+          currentMessages = await this.processFunctionCalls(\n+            functionCalls,\n+            toolRegistry,\n+            abortController,\n+            currentMessages,\n+          );\n+        } else {\n+          // The model has stopped calling tools, which signals completion.\n+          // Verify that all expected output variables have been emitted.\n+          const remainingVars = Object.keys(this.promptConfig.outputs).filter(\n+            (key) => !(key in this.output.emitted_vars),\n+          );\n+\n+          if (remainingVars.length === 0) {\n+            this.output.terminate_reason = SubagentTerminateMode.GOAL;\n+            break;\n+          }\n+\n+          // If variables are missing, the loop continues, relying on the\n+          // system prompt to guide the model to call self.emitvalue.\n+          console.debug(\n+            'Variables appear to be missing. Relying on model to call EmitValue.',\n+          );\n+        }\n+      }\n+    } catch (error) {\n+      console.error('Error during subagent execution:', error);\n+      this.output.terminate_reason = SubagentTerminateMode.ERROR;\n+      throw error;\n+    }\n+  }\n+\n+  /**\n+   * Processes a list of function calls, executing each one and collecting their responses.\n+   * This method iterates through the provided function calls, executes them using the\n+   * `executeToolCall` function (or handles `self.emitvalue` internally), and aggregates\n+   * their results. It also manages error reporting for failed tool executions.\n+   * @param {FunctionCall[]} functionCalls - An array of `FunctionCall` objects to process.\n+   * @param {ToolRegistry} toolRegistry - The tool registry to look up and execute tools.\n+   * @param {AbortController} abortController - An `AbortController` to signal cancellation of tool executions.\n+   * @param {Content[]} currentMessages - The current list of messages in the chat history, which will be updated with tool responses.\n+   * @returns {Promise<Content[]>} A promise that resolves to an array of `Content` parts representing the tool responses,\n+   *          which are then used to update the chat history.\n+   */\n+  private async processFunctionCalls(\n+    functionCalls: FunctionCall[],\n+    toolRegistry: ToolRegistry,\n+    abortController: AbortController,\n+    currentMessages: Content[],\n+  ) {\n+    const toolResponseParts: Part[] = [];\n+\n+    for (const functionCall of functionCalls) {\n+      const callId = functionCall.id ?? `${functionCall.name}-${Date.now()}`;\n+      const requestInfo: ToolCallRequestInfo = {\n+        callId,\n+        name: functionCall.name as string,\n+        args: (functionCall.args ?? {}) as Record<string, unknown>,\n+        isClientInitiated: true,\n+      };\n+\n+      let toolResponse;\n+\n+      // Handle scope-local tools first.\n+      if (callId.startsWith('self.emitvalue')) {\n+        const valName = String(requestInfo.args['emit_variable_name']);\n+        const valVal = String(requestInfo.args['emit_variable_value']);\n+        this.output.emitted_vars[valName] = valVal;\n+\n+        toolResponse = {\n+          callId,\n+          responseParts: `Emitted variable ${valName} successfully`,\n+          resultDisplay: `Emitted variable ${valName} successfully`,\n+          error: undefined,\n+        };\n+      } else {\n+        toolResponse = await executeToolCall(\n+          this.runtimeContext,\n+          requestInfo,\n+          toolRegistry,\n+          abortController.signal,\n+        );\n+      }\n+\n+      if (toolResponse.error) {\n+        console.error(\n+          `Error executing tool ${functionCall.name}: ${toolResponse.resultDisplay || toolResponse.error.message}`,\n+        );\n+        // Continue to the next tool call instead of halting execution.\n+        continue;\n+      }\n+\n+      if (toolResponse.responseParts) {\n+        const parts = Array.isArray(toolResponse.responseParts)\n+          ? toolResponse.responseParts\n+          : [toolResponse.responseParts];\n+        for (const part of parts) {\n+          if (typeof part === 'string') {\n+            toolResponseParts.push({ text: part });\n+          } else if (part) {\n+            toolResponseParts.push(part);\n+          }\n+        }\n+      }\n+    }\n+    currentMessages = [{ role: 'user', parts: toolResponseParts }];\n+    return currentMessages;\n+  }\n+\n+  /**\n+   * Creates an instance of `GeminiChat` unique for the subagent's purposes.\n+   * It initializes the chat with environment variables and configures the content generator.\n+   * @param {Content[]} [extraHistory] - Optional additional chat history to include.\n+   * @returns {Promise<GeminiChat | undefined>} A promise that resolves to a `GeminiChat` instance, or undefined if creation fails.\n+   */\n+  private async createChatObject(extraHistory?: Content[]) {\n+    const envParts = await this.getEnvironment();\n+    const initialHistory: Content[] = [\n+      {\n+        role: 'user',\n+        parts: envParts,\n+      },\n+      {\n+        role: 'model',\n+        parts: [{ text: 'Got it. Thanks for the context!' }],\n+      },\n+    ];\n+\n+    const start_history = [...initialHistory, ...(extraHistory ?? [])];\n+\n+    // The system instruction is set dynamically within the run loop to allow\n+    // for context-based templating.\n+    const systemInstruction = '';\n+\n+    try {\n+      const targetContentConfig: GenerateContentConfig = {\n+        temperature: this.modelConfig.temp,\n+        topP: this.modelConfig.top_p,\n+      };\n+\n+      const generationConfig = {\n+        systemInstruction,\n+        ...targetContentConfig,\n+      };\n+\n+      const contentGenerator = await createContentGenerator(\n+        this.runtimeContext.getContentGeneratorConfig(),\n+      );\n+\n+      this.runtimeContext.setModel(this.modelConfig.model);\n+\n+      return new GeminiChat(\n+        this.runtimeContext,\n+        contentGenerator,\n+        generationConfig,\n+        start_history,\n+      );\n+    } catch (error) {\n+      await reportError(\n+        error,\n+        'Error initializing Gemini chat session.',\n+        start_history,\n+        'startChat',\n+      );\n+      // The calling function will handle the undefined return.\n+      return undefined;\n+    }\n+  }\n+\n+  /**\n+   * Retrieves environment-related information to be included in the chat context.\n+   * This includes the current working directory, date, operating system, and folder structure.\n+   * Optionally, it can also include the full file context if enabled.\n+   * @returns A promise that resolves to an array of `Part` objects containing environment information.\n+   */\n+  private async getEnvironment(): Promise<Part[]> {\n+    const cwd = this.runtimeContext.getWorkingDir();\n+    const today = new Date().toLocaleDateString(undefined, {\n+      weekday: 'long',\n+      year: 'numeric',\n+      month: 'long',\n+      day: 'numeric',\n+    });\n+    const platform = process.platform;\n+    const folderStructure = await getFolderStructure(cwd, {\n+      fileService: this.runtimeContext.getFileService(),\n+    });\n+    const context = `\n+  Okay, just setting up the context for our chat.\n+  Today is ${today}.\n+  My operating system is: ${platform}\n+  I'm currently working in the directory: ${cwd}\n+  ${folderStructure}\n+          `.trim();\n+\n+    const initialParts: Part[] = [{ text: context }];\n+    const toolRegistry = await this.runtimeContext.getToolRegistry();\n+\n+    // Add full file context if the flag is set\n+    if (this.runtimeContext.getFullContext()) {\n+      try {\n+        const readManyFilesTool = toolRegistry.getTool(\n+          'read_many_files',\n+        ) as ReadManyFilesTool;\n+        if (readManyFilesTool) {\n+          // Read all files in the target directory\n+          const result = await readManyFilesTool.execute(\n+            {\n+              paths: ['**/*'], // Read everything recursively\n+              useDefaultExcludes: true, // Use default excludes\n+            },\n+            AbortSignal.timeout(30000),\n+          );\n+          if (result.llmContent) {\n+            initialParts.push({\n+              text: `\\n--- Full File Context ---\\n${result.llmContent}`,\n+            });\n+          } else {\n+            console.warn(\n+              'Full context requested, but read_many_files returned no content.',\n+            );\n+          }\n+        }\n+      } catch (error) {\n+        // This error is logged but doesn't halt the process, as full context is optional.\n+        console.error('Error reading full file context:', error);\n+        initialParts.push({\n+          text: '\\n--- Error reading full file context ---',\n+        });\n+      }\n+    }\n+\n+    return initialParts;\n+  }\n+\n+  /**\n+   * Returns an array of FunctionDeclaration objects for tools that are local to the subagent's scope.\n+   * Currently, this includes the `self.emitvalue` tool for emitting variables.\n+   * @returns An array of `FunctionDeclaration` objects.\n+   */\n+  private getScopeLocalFuncDefs() {\n+    const emitValueTool: FunctionDeclaration = {\n+      name: 'self.emitvalue',\n+      description: `* This tool emits A SINGLE return value from this execution, such that it can be collected and presented to the calling function.\n+        * You can only emit ONE VALUE each time you call this tool. You are expected to call this tool MULTIPLE TIMES if you have MULTIPLE OUTPUTS.`,\n+      parameters: {\n+        type: Type.OBJECT,\n+        properties: {\n+          emit_variable_name: {\n+            description: 'This is the name of the variable to be returned.',\n+            type: Type.STRING,\n+          },\n+          emit_variable_value: {\n+            description:\n+              'This is the _value_ to be returned for this variable.',\n+            type: Type.STRING,\n+          },\n+        },\n+        required: ['emit_variable_name', 'emit_variable_value'],\n+      },\n+    };\n+\n+    return [emitValueTool];\n+  }\n+\n+  /**\n+   * Builds the system prompt for the chat, incorporating the subagent's plan, goals, and available tools.\n+   * This prompt is intentionally different from the main agent's prompt to allow for scoped work with specific tools or personas.\n+   * @param {ContextState} context - The current context state containing variables for prompt templating.\n+   * @param {FunctionDeclaration[]} toolsList - An array of `FunctionDeclaration` objects representing the tools available to the subagent.\n+   * @returns {string} The complete system prompt for the chat.\n+   */\n+  private buildChatSystemPrompt(\n+    context: ContextState,\n+    toolsList: FunctionDeclaration[],\n+  ): string {\n+    const templated_plan = templateString(this.promptConfig.plan, context);\n+    let templated_goals = templateString(this.promptConfig.goals, context);\n+\n+    // Add variable emission goals..\n+    for (const [key, value] of Object.entries(this.promptConfig.outputs)) {\n+      templated_goals += `\\n* Use the 'self.emitvalue' tool to emit the '${key}' key, with a value described as '${value}'`;\n+    }\n+\n+    const input = `You are an expert AI that takes on all sorts of roles to accomplish tasks for the user. You will continue to iterate, and call tools until the goals are complete. \n+\n+Here are the tools you have access to, for this session, to solve the goals:\n+<TOOLS>",
        "comment_created_at": "2025-07-06T16:39:37+00:00",
        "comment_author": "NTaylorMullen",
        "comment_body": "Appreciate you taking a second look here. I'm definitely a bit surprised on the requirement here. Typically systems will perform better when the system prompt clearly defines \"when\" to use said tools BUT doesn't require the full schema or information",
        "pr_file_module": null
      },
      {
        "comment_id": "2192726713",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 1805,
        "pr_file": "packages/core/src/core/subagent.ts",
        "discussion_id": "2183019401",
        "commented_code": "@@ -0,0 +1,599 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import { reportError } from '../utils/errorReporting.js';\n+import { ToolRegistry } from '../tools/tool-registry.js';\n+import { Config } from '../config/config.js';\n+import { ToolCallRequestInfo } from './turn.js';\n+import { executeToolCall } from './nonInteractiveToolExecutor.js';\n+import { createContentGenerator } from './contentGenerator.js';\n+import { getFolderStructure } from '../utils/getFolderStructure.js';\n+import {\n+  Content,\n+  Part,\n+  FunctionCall,\n+  GenerateContentConfig,\n+  FunctionDeclaration,\n+  Type,\n+} from '@google/genai';\n+import { GeminiChat } from './geminiChat.js';\n+import { ReadManyFilesTool } from '../tools/read-many-files.js';\n+\n+/**\n+ * @fileoverview Defines the configuration interfaces for a subagent.\n+ *\n+ * These interfaces specify the structure for defining the subagent's prompt,\n+ * the model parameters, and the execution settings.\n+ */\n+\n+/**\n+ * Describes the possible termination modes for a subagent.\n+ * This enum provides a clear indication of why a subagent's execution might have ended.\n+ */\n+export enum SubagentTerminateMode {\n+  /**\n+   * Indicates that the subagent's execution terminated due to an unrecoverable error.\n+   */\n+  ERROR = 'ERROR',\n+  /**\n+   * Indicates that the subagent's execution terminated because it exceeded the maximum allowed working time.\n+   */\n+  TIMEOUT = 'TIMEOUT',\n+  /**\n+   * Indicates that the subagent's execution successfully completed all its defined goals.\n+   */\n+  GOAL = 'GOAL',\n+}\n+\n+/**\n+ * Represents the output structure of a subagent's execution.\n+ * This interface defines the data that a subagent will return upon completion,\n+ * including any emitted variables and the reason for its termination.\n+ */\n+export interface OutputObject {\n+  /**\n+   * A record of key-value pairs representing variables emitted by the subagent\n+   * during its execution. These variables can be used by the calling agent.\n+   */\n+  emitted_vars: Record<string, string>;\n+  /**\n+   * The reason for the subagent's termination, indicating whether it completed\n+   * successfully, timed out, or encountered an error.\n+   */\n+  terminate_reason: SubagentTerminateMode;\n+}\n+\n+/**\n+ * Configures the prompt and expected behavior of the subagent.\n+ * This interface defines the essential parameters that guide the subagent's\n+ * interaction and task execution, including its plan, goals, and available tools.\n+ */\n+export interface PromptConfig {\n+  /** A high-level plan or strategy for the subagent to follow. */\n+  plan: string;\n+  /** The specific goals the subagent is expected to achieve. */\n+  goals: string;\n+  /** A list of expected output objects and the variables they should emit. */\n+  outputs: Record<string, string>;\n+  /** A list of tool names (in the tool registry) or full function declarations that the subagent is permitted to use. */\n+  tools: Array<string | FunctionDeclaration>;\n+}\n+\n+/**\n+ * Configures the generative model parameters for the subagent.\n+ * This interface specifies the model to be used and its associated generation settings,\n+ * such as temperature and top-p values, which influence the creativity and diversity of the model's output.\n+ */\n+export interface ModelConfig {\n+  /** The name or identifier of the model to be used. */\n+  model: string;\n+  /** The temperature for the model's sampling process. */\n+  temp: number;\n+  /** The top-p value for nucleus sampling. */\n+  top_p: number;\n+}\n+\n+/**\n+ * Configures the execution environment and constraints for the subagent.\n+ * This interface defines parameters that control the subagent's runtime behavior,\n+ * such as maximum execution time, to prevent infinite loops or excessive resource consumption.\n+ */\n+export interface RunConfig {\n+  /** The maximum execution time for the subagent in minutes. */\n+  max_time_minutes: number;\n+}\n+\n+/**\n+ * Manages the runtime context state for the subagent.\n+ * This class provides a mechanism to store and retrieve key-value pairs\n+ * that represent the dynamic state and variables accessible to the subagent\n+ * during its execution.\n+ */\n+export class ContextState {\n+  private state: Record<string, unknown> = {};\n+\n+  /**\n+   * Retrieves a value from the context state.\n+   *\n+   * @param key - The key of the value to retrieve.\n+   * @returns The value associated with the key, or undefined if the key is not found.\n+   */\n+  get(key: string): unknown {\n+    return this.state[key];\n+  }\n+\n+  /**\n+   * Sets a value in the context state.\n+   *\n+   * @param key - The key to set the value under.\n+   * @param value - The value to set.\n+   */\n+  set(key: string, value: unknown): void {\n+    this.state[key] = value;\n+  }\n+\n+  /**\n+   * Retrieves all keys in the context state.\n+   *\n+   * @returns An array of all keys in the context state.\n+   */\n+  get_keys(): string[] {\n+    return Object.keys(this.state);\n+  }\n+}\n+\n+/**\n+ * Replaces `${...}` placeholders in a template string with values from a context.\n+ *\n+ * This function identifies all placeholders in the format `${key}`, validates that\n+ * each key exists in the provided `ContextState`, and then performs the substitution.\n+ *\n+ * @param template The template string containing placeholders.\n+ * @param context The `ContextState` object providing placeholder values.\n+ * @returns The populated string with all placeholders replaced.\n+ * @throws {Error} if any placeholder key is not found in the context.\n+ */\n+function templateString(template: string, context: ContextState): string {\n+  const placeholderRegex = /\\$\\{(\\w+)\\}/g;\n+\n+  // First, find all unique keys required by the template.\n+  const requiredKeys = new Set(\n+    Array.from(template.matchAll(placeholderRegex), (match) => match[1]),\n+  );\n+\n+  // Check if all required keys exist in the context.\n+  const contextKeys = new Set(context.get_keys());\n+  const missingKeys = Array.from(requiredKeys).filter(\n+    (key) => !contextKeys.has(key),\n+  );\n+\n+  if (missingKeys.length > 0) {\n+    throw new Error(\n+      `Missing context values for the following keys: ${missingKeys.join(\n+        ', ',\n+      )}`,\n+    );\n+  }\n+\n+  // Perform the replacement using a replacer function.\n+  return template.replace(placeholderRegex, (_match, key) =>\n+    String(context.get(key)),\n+  );\n+}\n+\n+/**\n+ * Represents the scope and execution environment for a subagent.\n+ * This class orchestrates the subagent's lifecycle, managing its chat interactions,\n+ * runtime context, and the collection of its outputs.\n+ */\n+export class SubAgentScope {\n+  output: OutputObject = {\n+    terminate_reason: SubagentTerminateMode.ERROR,\n+    emitted_vars: {},\n+  };\n+\n+  /**\n+   * Constructs a new SubAgentScope instance.\n+   * @param runtimeContext - The shared runtime configuration and services.\n+   * @param promptConfig - Configuration for the subagent's prompt and behavior.\n+   * @param modelConfig - Configuration for the generative model parameters.\n+   * @param runConfig - Configuration for the subagent's execution environment and constraints.\n+   */\n+  constructor(\n+    readonly runtimeContext: Config,\n+    private readonly promptConfig: PromptConfig,\n+    private readonly modelConfig: ModelConfig,\n+    private readonly runConfig: RunConfig,\n+  ) {}\n+\n+  /**\n+   * Runs the subagent in a non-interactive mode.\n+   * This method orchestrates the subagent's execution loop, including prompt templating,\n+   * tool execution, and termination conditions. It manages the chat history, handles\n+   * tool calls, and determines when the subagent's goals are met or if a timeout occurs.\n+   * @param {ContextState} context - The current context state containing variables for prompt templating.\n+   * @returns {Promise<void>} A promise that resolves when the subagent has completed its execution.\n+   */\n+  async runNonInteractive(context: ContextState): Promise<void> {\n+    const chat = await this.createChatObject();\n+\n+    if (!chat) {\n+      this.output.terminate_reason = SubagentTerminateMode.ERROR;\n+      return;\n+    }\n+\n+    const abortController = new AbortController();\n+    const toolRegistry: ToolRegistry =\n+      await this.runtimeContext.getToolRegistry();\n+\n+    // Prepare the list of tools available to the subagent.\n+    const tools_to_load: string[] = [];\n+    const toolsList: FunctionDeclaration[] = [];\n+    for (const toolName of this.promptConfig.tools) {\n+      if (typeof toolName === 'string') {\n+        tools_to_load.push(toolName);\n+      } else {\n+        toolsList.push(toolName);\n+      }\n+    }\n+\n+    toolsList.push(\n+      ...toolRegistry.getFunctionDeclarationsFiltered(tools_to_load),\n+    );\n+    toolsList.push(...this.getScopeLocalFuncDefs());\n+\n+    chat.setSystemInstruction(this.buildChatSystemPrompt(context, toolsList));\n+\n+    let currentMessages: Content[] = [\n+      { role: 'user', parts: [{ text: 'Get Started!' }] },\n+    ];\n+\n+    const startTime = Date.now();\n+    try {\n+      while (true) {\n+        // Check for timeout.\n+        const duration = Date.now() - startTime;\n+        const durationMin = duration / (1000 * 60);\n+        if (durationMin >= this.runConfig.max_time_minutes) {\n+          this.output.terminate_reason = SubagentTerminateMode.TIMEOUT;\n+          break;\n+        }\n+\n+        const messageParams = {\n+          message: currentMessages[0]?.parts || [],\n+          config: {\n+            abortSignal: abortController.signal,\n+            tools: [{ functionDeclarations: toolsList }],\n+          },\n+        };\n+\n+        // Send the message to the GeminiChat object, which will manage its own history\n+        const responseStream = await chat.sendMessageStream(messageParams);\n+\n+        // Combine all chunks in stream for proper processing.\n+        const functionCalls: FunctionCall[] = [];\n+        for await (const resp of responseStream) {\n+          if (abortController.signal.aborted) {\n+            console.error('Operation cancelled.');\n+            return;\n+          }\n+\n+          const calls = resp.functionCalls;\n+          if (calls) {\n+            functionCalls.push(...calls);\n+          }\n+        }\n+\n+        if (functionCalls.length > 0) {\n+          currentMessages = await this.processFunctionCalls(\n+            functionCalls,\n+            toolRegistry,\n+            abortController,\n+            currentMessages,\n+          );\n+        } else {\n+          // The model has stopped calling tools, which signals completion.\n+          // Verify that all expected output variables have been emitted.\n+          const remainingVars = Object.keys(this.promptConfig.outputs).filter(\n+            (key) => !(key in this.output.emitted_vars),\n+          );\n+\n+          if (remainingVars.length === 0) {\n+            this.output.terminate_reason = SubagentTerminateMode.GOAL;\n+            break;\n+          }\n+\n+          // If variables are missing, the loop continues, relying on the\n+          // system prompt to guide the model to call self.emitvalue.\n+          console.debug(\n+            'Variables appear to be missing. Relying on model to call EmitValue.',\n+          );\n+        }\n+      }\n+    } catch (error) {\n+      console.error('Error during subagent execution:', error);\n+      this.output.terminate_reason = SubagentTerminateMode.ERROR;\n+      throw error;\n+    }\n+  }\n+\n+  /**\n+   * Processes a list of function calls, executing each one and collecting their responses.\n+   * This method iterates through the provided function calls, executes them using the\n+   * `executeToolCall` function (or handles `self.emitvalue` internally), and aggregates\n+   * their results. It also manages error reporting for failed tool executions.\n+   * @param {FunctionCall[]} functionCalls - An array of `FunctionCall` objects to process.\n+   * @param {ToolRegistry} toolRegistry - The tool registry to look up and execute tools.\n+   * @param {AbortController} abortController - An `AbortController` to signal cancellation of tool executions.\n+   * @param {Content[]} currentMessages - The current list of messages in the chat history, which will be updated with tool responses.\n+   * @returns {Promise<Content[]>} A promise that resolves to an array of `Content` parts representing the tool responses,\n+   *          which are then used to update the chat history.\n+   */\n+  private async processFunctionCalls(\n+    functionCalls: FunctionCall[],\n+    toolRegistry: ToolRegistry,\n+    abortController: AbortController,\n+    currentMessages: Content[],\n+  ) {\n+    const toolResponseParts: Part[] = [];\n+\n+    for (const functionCall of functionCalls) {\n+      const callId = functionCall.id ?? `${functionCall.name}-${Date.now()}`;\n+      const requestInfo: ToolCallRequestInfo = {\n+        callId,\n+        name: functionCall.name as string,\n+        args: (functionCall.args ?? {}) as Record<string, unknown>,\n+        isClientInitiated: true,\n+      };\n+\n+      let toolResponse;\n+\n+      // Handle scope-local tools first.\n+      if (callId.startsWith('self.emitvalue')) {\n+        const valName = String(requestInfo.args['emit_variable_name']);\n+        const valVal = String(requestInfo.args['emit_variable_value']);\n+        this.output.emitted_vars[valName] = valVal;\n+\n+        toolResponse = {\n+          callId,\n+          responseParts: `Emitted variable ${valName} successfully`,\n+          resultDisplay: `Emitted variable ${valName} successfully`,\n+          error: undefined,\n+        };\n+      } else {\n+        toolResponse = await executeToolCall(\n+          this.runtimeContext,\n+          requestInfo,\n+          toolRegistry,\n+          abortController.signal,\n+        );\n+      }\n+\n+      if (toolResponse.error) {\n+        console.error(\n+          `Error executing tool ${functionCall.name}: ${toolResponse.resultDisplay || toolResponse.error.message}`,\n+        );\n+        // Continue to the next tool call instead of halting execution.\n+        continue;\n+      }\n+\n+      if (toolResponse.responseParts) {\n+        const parts = Array.isArray(toolResponse.responseParts)\n+          ? toolResponse.responseParts\n+          : [toolResponse.responseParts];\n+        for (const part of parts) {\n+          if (typeof part === 'string') {\n+            toolResponseParts.push({ text: part });\n+          } else if (part) {\n+            toolResponseParts.push(part);\n+          }\n+        }\n+      }\n+    }\n+    currentMessages = [{ role: 'user', parts: toolResponseParts }];\n+    return currentMessages;\n+  }\n+\n+  /**\n+   * Creates an instance of `GeminiChat` unique for the subagent's purposes.\n+   * It initializes the chat with environment variables and configures the content generator.\n+   * @param {Content[]} [extraHistory] - Optional additional chat history to include.\n+   * @returns {Promise<GeminiChat | undefined>} A promise that resolves to a `GeminiChat` instance, or undefined if creation fails.\n+   */\n+  private async createChatObject(extraHistory?: Content[]) {\n+    const envParts = await this.getEnvironment();\n+    const initialHistory: Content[] = [\n+      {\n+        role: 'user',\n+        parts: envParts,\n+      },\n+      {\n+        role: 'model',\n+        parts: [{ text: 'Got it. Thanks for the context!' }],\n+      },\n+    ];\n+\n+    const start_history = [...initialHistory, ...(extraHistory ?? [])];\n+\n+    // The system instruction is set dynamically within the run loop to allow\n+    // for context-based templating.\n+    const systemInstruction = '';\n+\n+    try {\n+      const targetContentConfig: GenerateContentConfig = {\n+        temperature: this.modelConfig.temp,\n+        topP: this.modelConfig.top_p,\n+      };\n+\n+      const generationConfig = {\n+        systemInstruction,\n+        ...targetContentConfig,\n+      };\n+\n+      const contentGenerator = await createContentGenerator(\n+        this.runtimeContext.getContentGeneratorConfig(),\n+      );\n+\n+      this.runtimeContext.setModel(this.modelConfig.model);\n+\n+      return new GeminiChat(\n+        this.runtimeContext,\n+        contentGenerator,\n+        generationConfig,\n+        start_history,\n+      );\n+    } catch (error) {\n+      await reportError(\n+        error,\n+        'Error initializing Gemini chat session.',\n+        start_history,\n+        'startChat',\n+      );\n+      // The calling function will handle the undefined return.\n+      return undefined;\n+    }\n+  }\n+\n+  /**\n+   * Retrieves environment-related information to be included in the chat context.\n+   * This includes the current working directory, date, operating system, and folder structure.\n+   * Optionally, it can also include the full file context if enabled.\n+   * @returns A promise that resolves to an array of `Part` objects containing environment information.\n+   */\n+  private async getEnvironment(): Promise<Part[]> {\n+    const cwd = this.runtimeContext.getWorkingDir();\n+    const today = new Date().toLocaleDateString(undefined, {\n+      weekday: 'long',\n+      year: 'numeric',\n+      month: 'long',\n+      day: 'numeric',\n+    });\n+    const platform = process.platform;\n+    const folderStructure = await getFolderStructure(cwd, {\n+      fileService: this.runtimeContext.getFileService(),\n+    });\n+    const context = `\n+  Okay, just setting up the context for our chat.\n+  Today is ${today}.\n+  My operating system is: ${platform}\n+  I'm currently working in the directory: ${cwd}\n+  ${folderStructure}\n+          `.trim();\n+\n+    const initialParts: Part[] = [{ text: context }];\n+    const toolRegistry = await this.runtimeContext.getToolRegistry();\n+\n+    // Add full file context if the flag is set\n+    if (this.runtimeContext.getFullContext()) {\n+      try {\n+        const readManyFilesTool = toolRegistry.getTool(\n+          'read_many_files',\n+        ) as ReadManyFilesTool;\n+        if (readManyFilesTool) {\n+          // Read all files in the target directory\n+          const result = await readManyFilesTool.execute(\n+            {\n+              paths: ['**/*'], // Read everything recursively\n+              useDefaultExcludes: true, // Use default excludes\n+            },\n+            AbortSignal.timeout(30000),\n+          );\n+          if (result.llmContent) {\n+            initialParts.push({\n+              text: `\\n--- Full File Context ---\\n${result.llmContent}`,\n+            });\n+          } else {\n+            console.warn(\n+              'Full context requested, but read_many_files returned no content.',\n+            );\n+          }\n+        }\n+      } catch (error) {\n+        // This error is logged but doesn't halt the process, as full context is optional.\n+        console.error('Error reading full file context:', error);\n+        initialParts.push({\n+          text: '\\n--- Error reading full file context ---',\n+        });\n+      }\n+    }\n+\n+    return initialParts;\n+  }\n+\n+  /**\n+   * Returns an array of FunctionDeclaration objects for tools that are local to the subagent's scope.\n+   * Currently, this includes the `self.emitvalue` tool for emitting variables.\n+   * @returns An array of `FunctionDeclaration` objects.\n+   */\n+  private getScopeLocalFuncDefs() {\n+    const emitValueTool: FunctionDeclaration = {\n+      name: 'self.emitvalue',\n+      description: `* This tool emits A SINGLE return value from this execution, such that it can be collected and presented to the calling function.\n+        * You can only emit ONE VALUE each time you call this tool. You are expected to call this tool MULTIPLE TIMES if you have MULTIPLE OUTPUTS.`,\n+      parameters: {\n+        type: Type.OBJECT,\n+        properties: {\n+          emit_variable_name: {\n+            description: 'This is the name of the variable to be returned.',\n+            type: Type.STRING,\n+          },\n+          emit_variable_value: {\n+            description:\n+              'This is the _value_ to be returned for this variable.',\n+            type: Type.STRING,\n+          },\n+        },\n+        required: ['emit_variable_name', 'emit_variable_value'],\n+      },\n+    };\n+\n+    return [emitValueTool];\n+  }\n+\n+  /**\n+   * Builds the system prompt for the chat, incorporating the subagent's plan, goals, and available tools.\n+   * This prompt is intentionally different from the main agent's prompt to allow for scoped work with specific tools or personas.\n+   * @param {ContextState} context - The current context state containing variables for prompt templating.\n+   * @param {FunctionDeclaration[]} toolsList - An array of `FunctionDeclaration` objects representing the tools available to the subagent.\n+   * @returns {string} The complete system prompt for the chat.\n+   */\n+  private buildChatSystemPrompt(\n+    context: ContextState,\n+    toolsList: FunctionDeclaration[],\n+  ): string {\n+    const templated_plan = templateString(this.promptConfig.plan, context);\n+    let templated_goals = templateString(this.promptConfig.goals, context);\n+\n+    // Add variable emission goals..\n+    for (const [key, value] of Object.entries(this.promptConfig.outputs)) {\n+      templated_goals += `\\n* Use the 'self.emitvalue' tool to emit the '${key}' key, with a value described as '${value}'`;\n+    }\n+\n+    const input = `You are an expert AI that takes on all sorts of roles to accomplish tasks for the user. You will continue to iterate, and call tools until the goals are complete. \n+\n+Here are the tools you have access to, for this session, to solve the goals:\n+<TOOLS>",
        "comment_created_at": "2025-07-08T14:44:18+00:00",
        "comment_author": "abhipatel12",
        "comment_body": "Update here! I worked on retesting this behavior.\r\n\r\nI followed the following process:\r\n\r\n1. Create new implementation of a subagent that uses two tools: LS tool, Write File Tool\r\n2. Remove `<tool>` from `subagent.ts`\r\n3. Run an input that activates this smart tool for 10 directories\r\n4. See if write file correctly creates 10 files using the ls tool for its content.\r\n5. Repeat 5 times (50 iterations)\r\n\r\nAfter running this experiment, the tools seem to be called even without the `<tool>` block in the system.\r\n\r\nI've removed it from the impl!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2211840096",
    "pr_number": 4337,
    "pr_file": "packages/core/src/telemetry/types.ts",
    "created_at": "2025-07-16T23:44:13+00:00",
    "commented_code": "export enum LoopType {\n   CONSECUTIVE_IDENTICAL_TOOL_CALLS = 'consecutive_identical_tool_calls',\n   CHANTING_IDENTICAL_SENTENCES = 'chanting_identical_sentences',\n+  LLM_DETECTED_LOOP = 'llm_detected_loop',",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2211840096",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4337,
        "pr_file": "packages/core/src/telemetry/types.ts",
        "discussion_id": "2211840096",
        "commented_code": "@@ -249,6 +249,7 @@ export class FlashFallbackEvent {\n export enum LoopType {\n   CONSECUTIVE_IDENTICAL_TOOL_CALLS = 'consecutive_identical_tool_calls',\n   CHANTING_IDENTICAL_SENTENCES = 'chanting_identical_sentences',\n+  LLM_DETECTED_LOOP = 'llm_detected_loop',",
        "comment_created_at": "2025-07-16T23:44:13+00:00",
        "comment_author": "anj-s",
        "comment_body": "Is this fixing any particular looping issue? If this is a general cognitive loop then we should tackle this a different IMO",
        "pr_file_module": null
      },
      {
        "comment_id": "2213853937",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4337,
        "pr_file": "packages/core/src/telemetry/types.ts",
        "discussion_id": "2211840096",
        "commented_code": "@@ -249,6 +249,7 @@ export class FlashFallbackEvent {\n export enum LoopType {\n   CONSECUTIVE_IDENTICAL_TOOL_CALLS = 'consecutive_identical_tool_calls',\n   CHANTING_IDENTICAL_SENTENCES = 'chanting_identical_sentences',\n+  LLM_DETECTED_LOOP = 'llm_detected_loop',",
        "comment_created_at": "2025-07-17T16:57:13+00:00",
        "comment_author": "SandyTao520",
        "comment_body": "This change won't fix the loop issue itself, but it will detect and stop it. It should prevent Gemini CLI burning users' tokens and this will provide us with metrics and help us verify the effectiveness of future fixes",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2211847760",
    "pr_number": 4337,
    "pr_file": "packages/core/src/core/client.ts",
    "created_at": "2025-07-16T23:52:11+00:00",
    "commented_code": "import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';\n import { LoopDetectionService } from '../services/loopDetectionService.js';\n \n+const LLM_CHECK_AFTER_TURNS = 10;\n+const LLM_CHECK_INTERVAL = 3;",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2211847760",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4337,
        "pr_file": "packages/core/src/core/client.ts",
        "discussion_id": "2211847760",
        "commented_code": "@@ -42,6 +42,9 @@ import { ProxyAgent, setGlobalDispatcher } from 'undici';\n import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';\n import { LoopDetectionService } from '../services/loopDetectionService.js';\n \n+const LLM_CHECK_AFTER_TURNS = 10;\n+const LLM_CHECK_INTERVAL = 3;",
        "comment_created_at": "2025-07-16T23:52:11+00:00",
        "comment_author": "NTaylorMullen",
        "comment_body": "This should probably be dynamic, for instance the loop check should probably return some level of confidence interval which should inform how quickly we should re-check. 3 turns feels like too little though",
        "pr_file_module": null
      },
      {
        "comment_id": "2214036056",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4337,
        "pr_file": "packages/core/src/core/client.ts",
        "discussion_id": "2211847760",
        "commented_code": "@@ -42,6 +42,9 @@ import { ProxyAgent, setGlobalDispatcher } from 'undici';\n import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';\n import { LoopDetectionService } from '../services/loopDetectionService.js';\n \n+const LLM_CHECK_AFTER_TURNS = 10;\n+const LLM_CHECK_INTERVAL = 3;",
        "comment_created_at": "2025-07-17T18:39:28+00:00",
        "comment_author": "SandyTao520",
        "comment_body": "Implemented dynamic check interval",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2211850260",
    "pr_number": 4337,
    "pr_file": "packages/core/src/services/loopDetectionService.ts",
    "created_at": "2025-07-16T23:55:00+00:00",
    "commented_code": "return false;\n   }\n \n+  async checkForLoopWithLLM(\n+    streamSignal: AbortSignal,\n+    abortController: AbortController,\n+  ) {\n+    try {\n+      const recentHistory = this.client!.getHistory().slice(\n+        -LLM_LOOP_CHECK_HISTORY_COUNT,\n+      );\n+\n+      const prompt = `You are an expert at detecting conversation loops.\n+The following is the recent history of a conversation with an AI assistant.\n+Please analyze it to determine if the conversation is stuck in a repetitive loop.\n+A loop is defined as the AI assistant making a sequence of 5 or more tool calls that are repetitive and not making progress.\n+This can be a single tool call repeated 5 times, or a repeating pattern of tool calls (e.g., A, B, A, B, A, B, A, B, A, B).",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2211850260",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4337,
        "pr_file": "packages/core/src/services/loopDetectionService.ts",
        "discussion_id": "2211850260",
        "commented_code": "@@ -119,6 +124,58 @@ export class LoopDetectionService {\n     return false;\n   }\n \n+  async checkForLoopWithLLM(\n+    streamSignal: AbortSignal,\n+    abortController: AbortController,\n+  ) {\n+    try {\n+      const recentHistory = this.client!.getHistory().slice(\n+        -LLM_LOOP_CHECK_HISTORY_COUNT,\n+      );\n+\n+      const prompt = `You are an expert at detecting conversation loops.\n+The following is the recent history of a conversation with an AI assistant.\n+Please analyze it to determine if the conversation is stuck in a repetitive loop.\n+A loop is defined as the AI assistant making a sequence of 5 or more tool calls that are repetitive and not making progress.\n+This can be a single tool call repeated 5 times, or a repeating pattern of tool calls (e.g., A, B, A, B, A, B, A, B, A, B).",
        "comment_created_at": "2025-07-16T23:55:00+00:00",
        "comment_author": "NTaylorMullen",
        "comment_body": "You should double check that this doesn't fire for small edits to a single file. I.e. I could imagine asking the model to individually add doc comments one tool call at a time, 20 calls later this one line might false-positive",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2214333602",
    "pr_number": 4337,
    "pr_file": "packages/core/src/services/loopDetectionService.ts",
    "created_at": "2025-07-17T21:18:56+00:00",
    "commented_code": "return false;\n   }\n \n+  private async checkForLoopWithLLM(signal: AbortSignal) {\n+    const recentHistory = this.config\n+      .getGeminiClient()\n+      .getHistory()\n+      .slice(-LLM_LOOP_CHECK_HISTORY_COUNT);\n+\n+    const prompt = `You are a sophisticated AI diagnostic agent specializing in identifying when a conversational AI is stuck in an unproductive state. Your task is to analyze the provided conversation history and determine if the assistant has ceased to make meaningful progress.\n+\n+An unproductive state is characterized by one or more of the following patterns over the last 5 or more assistant turns:\n+\n+Repetitive Actions: The assistant repeats the same tool calls or conversational responses a decent number of times. This includes simple loops (e.g., tool_A, tool_A, tool_A) and alternating patterns (e.g., tool_A, tool_B, tool_A, tool_B, ...).\n+\n+Cognitive Loop: The assistant seems unable to determine the next logical step. It might express confusion, repeatedly ask the same questions, or generate responses that don't logically follow from the previous turns, indicating it's stuck and not advancing the task.\n+\n+Crucially, differentiate between a true unproductive state and legitimate, incremental progress.\n+For example, a series of 'replace' or 'write_file' tool calls that make small, distinct changes to the same file (like adding docstrings to functions one by one) is considered forward progress and is NOT a loop. A loop would be repeatedly replacing the same text with the same content, or cycling between a small set of files with no net change.\n+\n+Please analyze the conversation history to determine the possibility that the conversation is stuck in a repetitive, non-productive state.\n+\n+**Conversation History:**:",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2214333602",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4337,
        "pr_file": "packages/core/src/services/loopDetectionService.ts",
        "discussion_id": "2214333602",
        "commented_code": "@@ -118,12 +156,85 @@ export class LoopDetectionService {\n     return false;\n   }\n \n+  private async checkForLoopWithLLM(signal: AbortSignal) {\n+    const recentHistory = this.config\n+      .getGeminiClient()\n+      .getHistory()\n+      .slice(-LLM_LOOP_CHECK_HISTORY_COUNT);\n+\n+    const prompt = `You are a sophisticated AI diagnostic agent specializing in identifying when a conversational AI is stuck in an unproductive state. Your task is to analyze the provided conversation history and determine if the assistant has ceased to make meaningful progress.\n+\n+An unproductive state is characterized by one or more of the following patterns over the last 5 or more assistant turns:\n+\n+Repetitive Actions: The assistant repeats the same tool calls or conversational responses a decent number of times. This includes simple loops (e.g., tool_A, tool_A, tool_A) and alternating patterns (e.g., tool_A, tool_B, tool_A, tool_B, ...).\n+\n+Cognitive Loop: The assistant seems unable to determine the next logical step. It might express confusion, repeatedly ask the same questions, or generate responses that don't logically follow from the previous turns, indicating it's stuck and not advancing the task.\n+\n+Crucially, differentiate between a true unproductive state and legitimate, incremental progress.\n+For example, a series of 'replace' or 'write_file' tool calls that make small, distinct changes to the same file (like adding docstrings to functions one by one) is considered forward progress and is NOT a loop. A loop would be repeatedly replacing the same text with the same content, or cycling between a small set of files with no net change.\n+\n+Please analyze the conversation history to determine the possibility that the conversation is stuck in a repetitive, non-productive state.\n+\n+**Conversation History:**:",
        "comment_created_at": "2025-07-17T21:18:56+00:00",
        "comment_author": "NTaylorMullen",
        "comment_body": "You shouldn't need to provide conversation history in this way. You can pass this to the `generateJson` method. See the nextSpeakerChecker as context if you need",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2214334342",
    "pr_number": 4337,
    "pr_file": "packages/core/src/services/loopDetectionService.ts",
    "created_at": "2025-07-17T21:19:29+00:00",
    "commented_code": "return false;\n   }\n \n+  private async checkForLoopWithLLM(signal: AbortSignal) {\n+    const recentHistory = this.config\n+      .getGeminiClient()\n+      .getHistory()\n+      .slice(-LLM_LOOP_CHECK_HISTORY_COUNT);\n+\n+    const prompt = `You are a sophisticated AI diagnostic agent specializing in identifying when a conversational AI is stuck in an unproductive state. Your task is to analyze the provided conversation history and determine if the assistant has ceased to make meaningful progress.\n+\n+An unproductive state is characterized by one or more of the following patterns over the last 5 or more assistant turns:\n+\n+Repetitive Actions: The assistant repeats the same tool calls or conversational responses a decent number of times. This includes simple loops (e.g., tool_A, tool_A, tool_A) and alternating patterns (e.g., tool_A, tool_B, tool_A, tool_B, ...).\n+\n+Cognitive Loop: The assistant seems unable to determine the next logical step. It might express confusion, repeatedly ask the same questions, or generate responses that don't logically follow from the previous turns, indicating it's stuck and not advancing the task.\n+\n+Crucially, differentiate between a true unproductive state and legitimate, incremental progress.\n+For example, a series of 'replace' or 'write_file' tool calls that make small, distinct changes to the same file (like adding docstrings to functions one by one) is considered forward progress and is NOT a loop. A loop would be repeatedly replacing the same text with the same content, or cycling between a small set of files with no net change.\n+\n+Please analyze the conversation history to determine the possibility that the conversation is stuck in a repetitive, non-productive state.\n+\n+**Conversation History:**:\n+${JSON.stringify(recentHistory, null, 2)}\n+`;\n+    const schema: SchemaUnion = {\n+      type: Type.OBJECT,\n+      properties: {\n+        confidence: {\n+          type: Type.NUMBER,\n+          description:\n+            'A number between 0.0 and 1.0 representing your confidence that the conversation is in an unproductive state.',\n+        },\n+        reasoning: {",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2214334342",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4337,
        "pr_file": "packages/core/src/services/loopDetectionService.ts",
        "discussion_id": "2214334342",
        "commented_code": "@@ -118,12 +156,85 @@ export class LoopDetectionService {\n     return false;\n   }\n \n+  private async checkForLoopWithLLM(signal: AbortSignal) {\n+    const recentHistory = this.config\n+      .getGeminiClient()\n+      .getHistory()\n+      .slice(-LLM_LOOP_CHECK_HISTORY_COUNT);\n+\n+    const prompt = `You are a sophisticated AI diagnostic agent specializing in identifying when a conversational AI is stuck in an unproductive state. Your task is to analyze the provided conversation history and determine if the assistant has ceased to make meaningful progress.\n+\n+An unproductive state is characterized by one or more of the following patterns over the last 5 or more assistant turns:\n+\n+Repetitive Actions: The assistant repeats the same tool calls or conversational responses a decent number of times. This includes simple loops (e.g., tool_A, tool_A, tool_A) and alternating patterns (e.g., tool_A, tool_B, tool_A, tool_B, ...).\n+\n+Cognitive Loop: The assistant seems unable to determine the next logical step. It might express confusion, repeatedly ask the same questions, or generate responses that don't logically follow from the previous turns, indicating it's stuck and not advancing the task.\n+\n+Crucially, differentiate between a true unproductive state and legitimate, incremental progress.\n+For example, a series of 'replace' or 'write_file' tool calls that make small, distinct changes to the same file (like adding docstrings to functions one by one) is considered forward progress and is NOT a loop. A loop would be repeatedly replacing the same text with the same content, or cycling between a small set of files with no net change.\n+\n+Please analyze the conversation history to determine the possibility that the conversation is stuck in a repetitive, non-productive state.\n+\n+**Conversation History:**:\n+${JSON.stringify(recentHistory, null, 2)}\n+`;\n+    const schema: SchemaUnion = {\n+      type: Type.OBJECT,\n+      properties: {\n+        confidence: {\n+          type: Type.NUMBER,\n+          description:\n+            'A number between 0.0 and 1.0 representing your confidence that the conversation is in an unproductive state.',\n+        },\n+        reasoning: {",
        "comment_created_at": "2025-07-17T21:19:29+00:00",
        "comment_author": "NTaylorMullen",
        "comment_body": "Put reasoning before `confidence`. In this case the order matters. We want to encourage the LLM to \"reason\" before responding to improve its confidence result",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2214336495",
    "pr_number": 4337,
    "pr_file": "packages/core/src/services/loopDetectionService.ts",
    "created_at": "2025-07-17T21:20:53+00:00",
    "commented_code": "return false;\n   }\n \n+  private async checkForLoopWithLLM(signal: AbortSignal) {\n+    const recentHistory = this.config\n+      .getGeminiClient()\n+      .getHistory()\n+      .slice(-LLM_LOOP_CHECK_HISTORY_COUNT);\n+\n+    const prompt = `You are a sophisticated AI diagnostic agent specializing in identifying when a conversational AI is stuck in an unproductive state. Your task is to analyze the provided conversation history and determine if the assistant has ceased to make meaningful progress.\n+\n+An unproductive state is characterized by one or more of the following patterns over the last 5 or more assistant turns:\n+\n+Repetitive Actions: The assistant repeats the same tool calls or conversational responses a decent number of times. This includes simple loops (e.g., tool_A, tool_A, tool_A) and alternating patterns (e.g., tool_A, tool_B, tool_A, tool_B, ...).\n+\n+Cognitive Loop: The assistant seems unable to determine the next logical step. It might express confusion, repeatedly ask the same questions, or generate responses that don't logically follow from the previous turns, indicating it's stuck and not advancing the task.\n+\n+Crucially, differentiate between a true unproductive state and legitimate, incremental progress.\n+For example, a series of 'replace' or 'write_file' tool calls that make small, distinct changes to the same file (like adding docstrings to functions one by one) is considered forward progress and is NOT a loop. A loop would be repeatedly replacing the same text with the same content, or cycling between a small set of files with no net change.\n+\n+Please analyze the conversation history to determine the possibility that the conversation is stuck in a repetitive, non-productive state.\n+\n+**Conversation History:**:\n+${JSON.stringify(recentHistory, null, 2)}\n+`;\n+    const schema: SchemaUnion = {\n+      type: Type.OBJECT,\n+      properties: {\n+        confidence: {\n+          type: Type.NUMBER,\n+          description:\n+            'A number between 0.0 and 1.0 representing your confidence that the conversation is in an unproductive state.',\n+        },\n+        reasoning: {\n+          type: Type.STRING,\n+          description:\n+            'Your reasoning on if the conversation is looping without forward progress.',\n+        },\n+      },\n+      required: ['confidence', 'reasoning'],\n+    };\n+    let result;\n+    try {\n+      result = await this.config\n+        .getGeminiClient()\n+        .generateJson(\n+          [{ role: 'user', parts: [{ text: prompt }] }],\n+          schema,\n+          signal,\n+          DEFAULT_GEMINI_FLASH_MODEL,\n+        );\n+    } catch (e) {\n+      // Do nothing, treat it as a non-loop.\n+      this.config.getDebugMode() ? console.error(e) : console.debug(e);\n+      return false;\n+    }\n+\n+    if (typeof result.confidence === 'number') {\n+      if (result.confidence > 0.9) {\n+        logLoopDetected(\n+          this.config,\n+          new LoopDetectedEvent(LoopType.LLM_DETECTED_LOOP),",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2214336495",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4337,
        "pr_file": "packages/core/src/services/loopDetectionService.ts",
        "discussion_id": "2214336495",
        "commented_code": "@@ -118,12 +156,85 @@ export class LoopDetectionService {\n     return false;\n   }\n \n+  private async checkForLoopWithLLM(signal: AbortSignal) {\n+    const recentHistory = this.config\n+      .getGeminiClient()\n+      .getHistory()\n+      .slice(-LLM_LOOP_CHECK_HISTORY_COUNT);\n+\n+    const prompt = `You are a sophisticated AI diagnostic agent specializing in identifying when a conversational AI is stuck in an unproductive state. Your task is to analyze the provided conversation history and determine if the assistant has ceased to make meaningful progress.\n+\n+An unproductive state is characterized by one or more of the following patterns over the last 5 or more assistant turns:\n+\n+Repetitive Actions: The assistant repeats the same tool calls or conversational responses a decent number of times. This includes simple loops (e.g., tool_A, tool_A, tool_A) and alternating patterns (e.g., tool_A, tool_B, tool_A, tool_B, ...).\n+\n+Cognitive Loop: The assistant seems unable to determine the next logical step. It might express confusion, repeatedly ask the same questions, or generate responses that don't logically follow from the previous turns, indicating it's stuck and not advancing the task.\n+\n+Crucially, differentiate between a true unproductive state and legitimate, incremental progress.\n+For example, a series of 'replace' or 'write_file' tool calls that make small, distinct changes to the same file (like adding docstrings to functions one by one) is considered forward progress and is NOT a loop. A loop would be repeatedly replacing the same text with the same content, or cycling between a small set of files with no net change.\n+\n+Please analyze the conversation history to determine the possibility that the conversation is stuck in a repetitive, non-productive state.\n+\n+**Conversation History:**:\n+${JSON.stringify(recentHistory, null, 2)}\n+`;\n+    const schema: SchemaUnion = {\n+      type: Type.OBJECT,\n+      properties: {\n+        confidence: {\n+          type: Type.NUMBER,\n+          description:\n+            'A number between 0.0 and 1.0 representing your confidence that the conversation is in an unproductive state.',\n+        },\n+        reasoning: {\n+          type: Type.STRING,\n+          description:\n+            'Your reasoning on if the conversation is looping without forward progress.',\n+        },\n+      },\n+      required: ['confidence', 'reasoning'],\n+    };\n+    let result;\n+    try {\n+      result = await this.config\n+        .getGeminiClient()\n+        .generateJson(\n+          [{ role: 'user', parts: [{ text: prompt }] }],\n+          schema,\n+          signal,\n+          DEFAULT_GEMINI_FLASH_MODEL,\n+        );\n+    } catch (e) {\n+      // Do nothing, treat it as a non-loop.\n+      this.config.getDebugMode() ? console.error(e) : console.debug(e);\n+      return false;\n+    }\n+\n+    if (typeof result.confidence === 'number') {\n+      if (result.confidence > 0.9) {\n+        logLoopDetected(\n+          this.config,\n+          new LoopDetectedEvent(LoopType.LLM_DETECTED_LOOP),",
        "comment_created_at": "2025-07-17T21:20:53+00:00",
        "comment_author": "NTaylorMullen",
        "comment_body": "Food for thought (no action required): You could also have the LLM fill out a \"loop type\" part of the schema to differentiate between cognitive loops and repetitive actions using the enum json schema. That way you could surface what type of LLM detected loop here",
        "pr_file_module": null
      },
      {
        "comment_id": "2216422638",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4337,
        "pr_file": "packages/core/src/services/loopDetectionService.ts",
        "discussion_id": "2214336495",
        "commented_code": "@@ -118,12 +156,85 @@ export class LoopDetectionService {\n     return false;\n   }\n \n+  private async checkForLoopWithLLM(signal: AbortSignal) {\n+    const recentHistory = this.config\n+      .getGeminiClient()\n+      .getHistory()\n+      .slice(-LLM_LOOP_CHECK_HISTORY_COUNT);\n+\n+    const prompt = `You are a sophisticated AI diagnostic agent specializing in identifying when a conversational AI is stuck in an unproductive state. Your task is to analyze the provided conversation history and determine if the assistant has ceased to make meaningful progress.\n+\n+An unproductive state is characterized by one or more of the following patterns over the last 5 or more assistant turns:\n+\n+Repetitive Actions: The assistant repeats the same tool calls or conversational responses a decent number of times. This includes simple loops (e.g., tool_A, tool_A, tool_A) and alternating patterns (e.g., tool_A, tool_B, tool_A, tool_B, ...).\n+\n+Cognitive Loop: The assistant seems unable to determine the next logical step. It might express confusion, repeatedly ask the same questions, or generate responses that don't logically follow from the previous turns, indicating it's stuck and not advancing the task.\n+\n+Crucially, differentiate between a true unproductive state and legitimate, incremental progress.\n+For example, a series of 'replace' or 'write_file' tool calls that make small, distinct changes to the same file (like adding docstrings to functions one by one) is considered forward progress and is NOT a loop. A loop would be repeatedly replacing the same text with the same content, or cycling between a small set of files with no net change.\n+\n+Please analyze the conversation history to determine the possibility that the conversation is stuck in a repetitive, non-productive state.\n+\n+**Conversation History:**:\n+${JSON.stringify(recentHistory, null, 2)}\n+`;\n+    const schema: SchemaUnion = {\n+      type: Type.OBJECT,\n+      properties: {\n+        confidence: {\n+          type: Type.NUMBER,\n+          description:\n+            'A number between 0.0 and 1.0 representing your confidence that the conversation is in an unproductive state.',\n+        },\n+        reasoning: {\n+          type: Type.STRING,\n+          description:\n+            'Your reasoning on if the conversation is looping without forward progress.',\n+        },\n+      },\n+      required: ['confidence', 'reasoning'],\n+    };\n+    let result;\n+    try {\n+      result = await this.config\n+        .getGeminiClient()\n+        .generateJson(\n+          [{ role: 'user', parts: [{ text: prompt }] }],\n+          schema,\n+          signal,\n+          DEFAULT_GEMINI_FLASH_MODEL,\n+        );\n+    } catch (e) {\n+      // Do nothing, treat it as a non-loop.\n+      this.config.getDebugMode() ? console.error(e) : console.debug(e);\n+      return false;\n+    }\n+\n+    if (typeof result.confidence === 'number') {\n+      if (result.confidence > 0.9) {\n+        logLoopDetected(\n+          this.config,\n+          new LoopDetectedEvent(LoopType.LLM_DETECTED_LOOP),",
        "comment_created_at": "2025-07-18T16:13:27+00:00",
        "comment_author": "SandyTao520",
        "comment_body": "Good idea, let's do this next",
        "pr_file_module": null
      }
    ]
  }
]