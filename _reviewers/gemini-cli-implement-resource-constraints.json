[
  {
    "discussion_id": "2201032775",
    "pr_number": 2157,
    "pr_file": "packages/core/src/telemetry/memory-monitor.ts",
    "created_at": "2025-07-11T15:29:41+00:00",
    "commented_code": "+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import v8 from 'node:v8';\n+import process from 'node:process';\n+import { Config } from '../config/config.js';\n+import {\n+  recordMemoryUsage,\n+  MemoryMetricType,\n+  isPerformanceMonitoringActive,\n+} from './metrics.js';\n+\n+export interface MemorySnapshot {\n+  timestamp: number;\n+  heapUsed: number;\n+  heapTotal: number;\n+  external: number;\n+  rss: number;\n+  arrayBuffers: number;\n+  heapSizeLimit: number;\n+}\n+\n+export interface ProcessMetrics {\n+  cpuUsage: NodeJS.CpuUsage;\n+  memoryUsage: NodeJS.MemoryUsage;\n+  uptime: number;\n+}\n+\n+export class MemoryMonitor {\n+  private intervalId: NodeJS.Timeout | null = null;\n+  private isRunning = false;\n+  private lastSnapshot: MemorySnapshot | null = null;\n+  private monitoringInterval: number = 5000; // 5 seconds default\n+\n+  constructor() {\n+    // No config stored to avoid multi-session attribution issues\n+  }\n+\n+  /**\n+   * Start continuous memory monitoring\n+   */\n+  start(config: Config, intervalMs: number = 5000): void {",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2201032775",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 2157,
        "pr_file": "packages/core/src/telemetry/memory-monitor.ts",
        "discussion_id": "2201032775",
        "commented_code": "@@ -0,0 +1,317 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import v8 from 'node:v8';\n+import process from 'node:process';\n+import { Config } from '../config/config.js';\n+import {\n+  recordMemoryUsage,\n+  MemoryMetricType,\n+  isPerformanceMonitoringActive,\n+} from './metrics.js';\n+\n+export interface MemorySnapshot {\n+  timestamp: number;\n+  heapUsed: number;\n+  heapTotal: number;\n+  external: number;\n+  rss: number;\n+  arrayBuffers: number;\n+  heapSizeLimit: number;\n+}\n+\n+export interface ProcessMetrics {\n+  cpuUsage: NodeJS.CpuUsage;\n+  memoryUsage: NodeJS.MemoryUsage;\n+  uptime: number;\n+}\n+\n+export class MemoryMonitor {\n+  private intervalId: NodeJS.Timeout | null = null;\n+  private isRunning = false;\n+  private lastSnapshot: MemorySnapshot | null = null;\n+  private monitoringInterval: number = 5000; // 5 seconds default\n+\n+  constructor() {\n+    // No config stored to avoid multi-session attribution issues\n+  }\n+\n+  /**\n+   * Start continuous memory monitoring\n+   */\n+  start(config: Config, intervalMs: number = 5000): void {",
        "comment_created_at": "2025-07-11T15:29:41+00:00",
        "comment_author": "jacob314",
        "comment_body": "Thank you for adding this! I am really excited to get analytics to understand how bad user's memory usage usage issues.\r\nHowever, every 5 seconds is a bit too frequent. ideally we could only send this when the app is in use and even then we should rate limit a bit more to perhaps only send this metric at most once every minute. Some other tools only send analytics about memory usage at most once every hour.\r\nThe easiest way to detect that the app is in use would be to have an API the CLI package can call when the user types of an additonal message is added to history. \r\n\r\nAnother complementary option is to poll ever perhaps 10 seconds fetching the RSS side but only report if the RSS is at least 5% greater than the previous high water mark for the largest RSS side. Memory usage will bounce up and down when there are garbage collection, potentially due to garbage collection that happens purely due to tracking these events so you have to be careful you only send events when memory usage has increased relative to the largest value it has ever been rather than the previous value.",
        "pr_file_module": null
      },
      {
        "comment_id": "2203235299",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 2157,
        "pr_file": "packages/core/src/telemetry/memory-monitor.ts",
        "discussion_id": "2201032775",
        "commented_code": "@@ -0,0 +1,317 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import v8 from 'node:v8';\n+import process from 'node:process';\n+import { Config } from '../config/config.js';\n+import {\n+  recordMemoryUsage,\n+  MemoryMetricType,\n+  isPerformanceMonitoringActive,\n+} from './metrics.js';\n+\n+export interface MemorySnapshot {\n+  timestamp: number;\n+  heapUsed: number;\n+  heapTotal: number;\n+  external: number;\n+  rss: number;\n+  arrayBuffers: number;\n+  heapSizeLimit: number;\n+}\n+\n+export interface ProcessMetrics {\n+  cpuUsage: NodeJS.CpuUsage;\n+  memoryUsage: NodeJS.MemoryUsage;\n+  uptime: number;\n+}\n+\n+export class MemoryMonitor {\n+  private intervalId: NodeJS.Timeout | null = null;\n+  private isRunning = false;\n+  private lastSnapshot: MemorySnapshot | null = null;\n+  private monitoringInterval: number = 5000; // 5 seconds default\n+\n+  constructor() {\n+    // No config stored to avoid multi-session attribution issues\n+  }\n+\n+  /**\n+   * Start continuous memory monitoring\n+   */\n+  start(config: Config, intervalMs: number = 5000): void {",
        "comment_created_at": "2025-07-13T08:37:27+00:00",
        "comment_author": "eLyiN",
        "comment_body": "Thank you for the detailed feedback! I've implemented exactly what you suggested:\r\n\r\n- Frequency reduced: 10-second polling with 1-minute rate limiting\r\n- Activity-based: Only records when user is actively using the app\r\n- CLI API: Hooks for user input, message history, tool calls, etc.\r\n- High water mark: 5% RSS growth threshold with GC noise smoothing\r\n\r\nThe system now:\r\n- Polls every 10 seconds (not 5)\r\n- Only triggers when isUserActive() = true (30s idle threshold)\r\n- Records at most once per minute via rate limiter\r\n- Only reports when RSS is 5%+ above previous high water mark\r\n- Provides useActivityRecorder hooks for CLI integration\r\n\r\nThis should give us the memory analytics we need without being too noisy. The implementation follows all your architectural suggestions!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2220440452",
    "pr_number": 3289,
    "pr_file": "packages/cli/src/ui/utils/kittyProtocolDetector.ts",
    "created_at": "2025-07-21T21:54:27+00:00",
    "commented_code": "+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+let detectionComplete = false;\n+let protocolSupported = false;\n+let protocolEnabled = false;\n+\n+/**\n+ * Detects Kitty keyboard protocol support.\n+ * Definitive document about this protocol lives at https://sw.kovidgoyal.net/kitty/keyboard-protocol/\n+ * This function should be called once at app startup.\n+ */\n+export async function detectAndEnableKittyProtocol(): Promise<boolean> {\n+  if (detectionComplete) {\n+    return protocolSupported;\n+  }\n+\n+  return new Promise((resolve) => {\n+    if (!process.stdin.isTTY || !process.stdout.isTTY) {\n+      detectionComplete = true;\n+      resolve(false);\n+      return;\n+    }\n+\n+    const originalRawMode = process.stdin.isRaw;\n+    if (!originalRawMode) {\n+      process.stdin.setRawMode(true);\n+    }\n+\n+    let responseBuffer = '';\n+    let progressiveEnhancementReceived = false;\n+    let checkFinished = false;\n+\n+    const handleData = (data: Buffer) => {\n+      responseBuffer += data.toString();\n+\n+      // Check for progressive enhancement response (CSI ? <flags> u)\n+      if (responseBuffer.includes('\\x1b[?') && responseBuffer.includes('u')) {\n+        progressiveEnhancementReceived = true;\n+      }\n+\n+      // Check for device attributes response (CSI ? <attrs> c)\n+      if (responseBuffer.includes('\\x1b[?') && responseBuffer.includes('c')) {\n+        if (!checkFinished) {\n+          checkFinished = true;\n+          process.stdin.removeListener('data', handleData);\n+\n+          if (!originalRawMode) {\n+            process.stdin.setRawMode(false);\n+          }\n+\n+          if (progressiveEnhancementReceived) {\n+            // Enable the protocol\n+            process.stdout.write('\\x1b[>1u');\n+            protocolSupported = true;\n+            protocolEnabled = true;\n+\n+            // Set up cleanup on exit\n+            process.on('exit', disableProtocol);\n+            process.on('SIGTERM', disableProtocol);\n+          }\n+\n+          detectionComplete = true;\n+          resolve(protocolSupported);\n+        }\n+      }\n+    };\n+\n+    process.stdin.on('data', handleData);\n+\n+    // Send queries\n+    process.stdout.write('\\x1b[?u'); // Query progressive enhancement\n+    process.stdout.write('\\x1b[c'); // Query device attributes\n+\n+    // Timeout after 50ms\n+    setTimeout(() => {\n+      if (!checkFinished) {\n+        process.stdin.removeListener('data', handleData);\n+        if (!originalRawMode) {\n+          process.stdin.setRawMode(false);\n+        }\n+        detectionComplete = true;\n+        resolve(false);\n+      }\n+    }, 50);",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2220440452",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 3289,
        "pr_file": "packages/cli/src/ui/utils/kittyProtocolDetector.ts",
        "discussion_id": "2220440452",
        "commented_code": "@@ -0,0 +1,105 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+let detectionComplete = false;\n+let protocolSupported = false;\n+let protocolEnabled = false;\n+\n+/**\n+ * Detects Kitty keyboard protocol support.\n+ * Definitive document about this protocol lives at https://sw.kovidgoyal.net/kitty/keyboard-protocol/\n+ * This function should be called once at app startup.\n+ */\n+export async function detectAndEnableKittyProtocol(): Promise<boolean> {\n+  if (detectionComplete) {\n+    return protocolSupported;\n+  }\n+\n+  return new Promise((resolve) => {\n+    if (!process.stdin.isTTY || !process.stdout.isTTY) {\n+      detectionComplete = true;\n+      resolve(false);\n+      return;\n+    }\n+\n+    const originalRawMode = process.stdin.isRaw;\n+    if (!originalRawMode) {\n+      process.stdin.setRawMode(true);\n+    }\n+\n+    let responseBuffer = '';\n+    let progressiveEnhancementReceived = false;\n+    let checkFinished = false;\n+\n+    const handleData = (data: Buffer) => {\n+      responseBuffer += data.toString();\n+\n+      // Check for progressive enhancement response (CSI ? <flags> u)\n+      if (responseBuffer.includes('\\x1b[?') && responseBuffer.includes('u')) {\n+        progressiveEnhancementReceived = true;\n+      }\n+\n+      // Check for device attributes response (CSI ? <attrs> c)\n+      if (responseBuffer.includes('\\x1b[?') && responseBuffer.includes('c')) {\n+        if (!checkFinished) {\n+          checkFinished = true;\n+          process.stdin.removeListener('data', handleData);\n+\n+          if (!originalRawMode) {\n+            process.stdin.setRawMode(false);\n+          }\n+\n+          if (progressiveEnhancementReceived) {\n+            // Enable the protocol\n+            process.stdout.write('\\x1b[>1u');\n+            protocolSupported = true;\n+            protocolEnabled = true;\n+\n+            // Set up cleanup on exit\n+            process.on('exit', disableProtocol);\n+            process.on('SIGTERM', disableProtocol);\n+          }\n+\n+          detectionComplete = true;\n+          resolve(protocolSupported);\n+        }\n+      }\n+    };\n+\n+    process.stdin.on('data', handleData);\n+\n+    // Send queries\n+    process.stdout.write('\\x1b[?u'); // Query progressive enhancement\n+    process.stdout.write('\\x1b[c'); // Query device attributes\n+\n+    // Timeout after 50ms\n+    setTimeout(() => {\n+      if (!checkFinished) {\n+        process.stdin.removeListener('data', handleData);\n+        if (!originalRawMode) {\n+          process.stdin.setRawMode(false);\n+        }\n+        detectionComplete = true;\n+        resolve(false);\n+      }\n+    }, 50);",
        "comment_created_at": "2025-07-21T21:54:27+00:00",
        "comment_author": "jacob314",
        "comment_body": "can you comment where the 50 ms threshold comes from? I would worry we might miss that terminals support kitty when the users machine happens to be under heavy load but I also don't love adding >50ms of delay for all users who happen to not be using a kitty protocol terminal.",
        "pr_file_module": null
      },
      {
        "comment_id": "2220557610",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 3289,
        "pr_file": "packages/cli/src/ui/utils/kittyProtocolDetector.ts",
        "discussion_id": "2220440452",
        "commented_code": "@@ -0,0 +1,105 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+let detectionComplete = false;\n+let protocolSupported = false;\n+let protocolEnabled = false;\n+\n+/**\n+ * Detects Kitty keyboard protocol support.\n+ * Definitive document about this protocol lives at https://sw.kovidgoyal.net/kitty/keyboard-protocol/\n+ * This function should be called once at app startup.\n+ */\n+export async function detectAndEnableKittyProtocol(): Promise<boolean> {\n+  if (detectionComplete) {\n+    return protocolSupported;\n+  }\n+\n+  return new Promise((resolve) => {\n+    if (!process.stdin.isTTY || !process.stdout.isTTY) {\n+      detectionComplete = true;\n+      resolve(false);\n+      return;\n+    }\n+\n+    const originalRawMode = process.stdin.isRaw;\n+    if (!originalRawMode) {\n+      process.stdin.setRawMode(true);\n+    }\n+\n+    let responseBuffer = '';\n+    let progressiveEnhancementReceived = false;\n+    let checkFinished = false;\n+\n+    const handleData = (data: Buffer) => {\n+      responseBuffer += data.toString();\n+\n+      // Check for progressive enhancement response (CSI ? <flags> u)\n+      if (responseBuffer.includes('\\x1b[?') && responseBuffer.includes('u')) {\n+        progressiveEnhancementReceived = true;\n+      }\n+\n+      // Check for device attributes response (CSI ? <attrs> c)\n+      if (responseBuffer.includes('\\x1b[?') && responseBuffer.includes('c')) {\n+        if (!checkFinished) {\n+          checkFinished = true;\n+          process.stdin.removeListener('data', handleData);\n+\n+          if (!originalRawMode) {\n+            process.stdin.setRawMode(false);\n+          }\n+\n+          if (progressiveEnhancementReceived) {\n+            // Enable the protocol\n+            process.stdout.write('\\x1b[>1u');\n+            protocolSupported = true;\n+            protocolEnabled = true;\n+\n+            // Set up cleanup on exit\n+            process.on('exit', disableProtocol);\n+            process.on('SIGTERM', disableProtocol);\n+          }\n+\n+          detectionComplete = true;\n+          resolve(protocolSupported);\n+        }\n+      }\n+    };\n+\n+    process.stdin.on('data', handleData);\n+\n+    // Send queries\n+    process.stdout.write('\\x1b[?u'); // Query progressive enhancement\n+    process.stdout.write('\\x1b[c'); // Query device attributes\n+\n+    // Timeout after 50ms\n+    setTimeout(() => {\n+      if (!checkFinished) {\n+        process.stdin.removeListener('data', handleData);\n+        if (!originalRawMode) {\n+          process.stdin.setRawMode(false);\n+        }\n+        detectionComplete = true;\n+        resolve(false);\n+      }\n+    }, 50);",
        "comment_created_at": "2025-07-21T23:20:03+00:00",
        "comment_author": "deepankarsharma",
        "comment_body": "It was an arbitrary \"fast enough\" threshold I came up with, I can reduce the threshold. Alternatively I can do this check for non vscode/windsurf/cursor cases only so that those users are not affected. ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2228993214",
    "pr_number": 1805,
    "pr_file": "packages/core/src/core/subagent.ts",
    "created_at": "2025-07-24T16:28:02+00:00",
    "commented_code": "+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import { reportError } from '../utils/errorReporting.js';\n+import { ToolRegistry } from '../tools/tool-registry.js';\n+import { Config } from '../config/config.js';\n+import { ToolCallRequestInfo } from './turn.js';\n+import { executeToolCall } from './nonInteractiveToolExecutor.js';\n+import { createContentGenerator } from './contentGenerator.js';\n+import { getEnvironmentContext } from '../utils/environmentContext.js';\n+import {\n+  Content,\n+  Part,\n+  FunctionCall,\n+  GenerateContentConfig,\n+  FunctionDeclaration,\n+  Type,\n+} from '@google/genai';\n+import { GeminiChat } from './geminiChat.js';\n+\n+/**\n+ * @fileoverview Defines the configuration interfaces for a subagent.\n+ *\n+ * These interfaces specify the structure for defining the subagent's prompt,\n+ * the model parameters, and the execution settings.\n+ */\n+\n+/**\n+ * Describes the possible termination modes for a subagent.\n+ * This enum provides a clear indication of why a subagent's execution might have ended.\n+ */\n+export enum SubagentTerminateMode {\n+  /**\n+   * Indicates that the subagent's execution terminated due to an unrecoverable error.\n+   */\n+  ERROR = 'ERROR',\n+  /**\n+   * Indicates that the subagent's execution terminated because it exceeded the maximum allowed working time.\n+   */\n+  TIMEOUT = 'TIMEOUT',\n+  /**\n+   * Indicates that the subagent's execution successfully completed all its defined goals.\n+   */\n+  GOAL = 'GOAL',\n+}\n+\n+/**\n+ * Represents the output structure of a subagent's execution.\n+ * This interface defines the data that a subagent will return upon completion,\n+ * including any emitted variables and the reason for its termination.\n+ */\n+export interface OutputObject {\n+  /**\n+   * A record of key-value pairs representing variables emitted by the subagent\n+   * during its execution. These variables can be used by the calling agent.\n+   */\n+  emitted_vars: Record<string, string>;\n+  /**\n+   * The reason for the subagent's termination, indicating whether it completed\n+   * successfully, timed out, or encountered an error.\n+   */\n+  terminate_reason: SubagentTerminateMode;\n+}\n+\n+/**\n+ * Configures the prompt and expected behavior of the subagent.\n+ * This interface defines the essential parameters that guide the subagent's\n+ * interaction and task execution, including its plan, goals, and available tools.\n+ */\n+export interface PromptConfig {\n+  /** A high-level plan or strategy for the subagent to follow. */\n+  plan: string;\n+  /** The specific goals the subagent is expected to achieve. */\n+  goals: string;\n+  /** A list of expected output objects and the variables they should emit. */\n+  outputs: Record<string, string>;\n+  /** A list of tool names (in the tool registry) or full function declarations that the subagent is permitted to use. */\n+  tools: Array<string | FunctionDeclaration>;\n+}\n+\n+/**\n+ * Configures the generative model parameters for the subagent.\n+ * This interface specifies the model to be used and its associated generation settings,\n+ * such as temperature and top-p values, which influence the creativity and diversity of the model's output.\n+ */\n+export interface ModelConfig {\n+  /** The name or identifier of the model to be used. */\n+  model: string;\n+  /** The temperature for the model's sampling process. */\n+  temp: number;\n+  /** The top-p value for nucleus sampling. */\n+  top_p: number;\n+}\n+\n+/**\n+ * Configures the execution environment and constraints for the subagent.\n+ * This interface defines parameters that control the subagent's runtime behavior,\n+ * such as maximum execution time, to prevent infinite loops or excessive resource consumption.\n+ */\n+export interface RunConfig {\n+  /** The maximum execution time for the subagent in minutes. */\n+  max_time_minutes: number;",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2228993214",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 1805,
        "pr_file": "packages/core/src/core/subagent.ts",
        "discussion_id": "2228993214",
        "commented_code": "@@ -0,0 +1,588 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import { reportError } from '../utils/errorReporting.js';\n+import { ToolRegistry } from '../tools/tool-registry.js';\n+import { Config } from '../config/config.js';\n+import { ToolCallRequestInfo } from './turn.js';\n+import { executeToolCall } from './nonInteractiveToolExecutor.js';\n+import { createContentGenerator } from './contentGenerator.js';\n+import { getEnvironmentContext } from '../utils/environmentContext.js';\n+import {\n+  Content,\n+  Part,\n+  FunctionCall,\n+  GenerateContentConfig,\n+  FunctionDeclaration,\n+  Type,\n+} from '@google/genai';\n+import { GeminiChat } from './geminiChat.js';\n+\n+/**\n+ * @fileoverview Defines the configuration interfaces for a subagent.\n+ *\n+ * These interfaces specify the structure for defining the subagent's prompt,\n+ * the model parameters, and the execution settings.\n+ */\n+\n+/**\n+ * Describes the possible termination modes for a subagent.\n+ * This enum provides a clear indication of why a subagent's execution might have ended.\n+ */\n+export enum SubagentTerminateMode {\n+  /**\n+   * Indicates that the subagent's execution terminated due to an unrecoverable error.\n+   */\n+  ERROR = 'ERROR',\n+  /**\n+   * Indicates that the subagent's execution terminated because it exceeded the maximum allowed working time.\n+   */\n+  TIMEOUT = 'TIMEOUT',\n+  /**\n+   * Indicates that the subagent's execution successfully completed all its defined goals.\n+   */\n+  GOAL = 'GOAL',\n+}\n+\n+/**\n+ * Represents the output structure of a subagent's execution.\n+ * This interface defines the data that a subagent will return upon completion,\n+ * including any emitted variables and the reason for its termination.\n+ */\n+export interface OutputObject {\n+  /**\n+   * A record of key-value pairs representing variables emitted by the subagent\n+   * during its execution. These variables can be used by the calling agent.\n+   */\n+  emitted_vars: Record<string, string>;\n+  /**\n+   * The reason for the subagent's termination, indicating whether it completed\n+   * successfully, timed out, or encountered an error.\n+   */\n+  terminate_reason: SubagentTerminateMode;\n+}\n+\n+/**\n+ * Configures the prompt and expected behavior of the subagent.\n+ * This interface defines the essential parameters that guide the subagent's\n+ * interaction and task execution, including its plan, goals, and available tools.\n+ */\n+export interface PromptConfig {\n+  /** A high-level plan or strategy for the subagent to follow. */\n+  plan: string;\n+  /** The specific goals the subagent is expected to achieve. */\n+  goals: string;\n+  /** A list of expected output objects and the variables they should emit. */\n+  outputs: Record<string, string>;\n+  /** A list of tool names (in the tool registry) or full function declarations that the subagent is permitted to use. */\n+  tools: Array<string | FunctionDeclaration>;\n+}\n+\n+/**\n+ * Configures the generative model parameters for the subagent.\n+ * This interface specifies the model to be used and its associated generation settings,\n+ * such as temperature and top-p values, which influence the creativity and diversity of the model's output.\n+ */\n+export interface ModelConfig {\n+  /** The name or identifier of the model to be used. */\n+  model: string;\n+  /** The temperature for the model's sampling process. */\n+  temp: number;\n+  /** The top-p value for nucleus sampling. */\n+  top_p: number;\n+}\n+\n+/**\n+ * Configures the execution environment and constraints for the subagent.\n+ * This interface defines parameters that control the subagent's runtime behavior,\n+ * such as maximum execution time, to prevent infinite loops or excessive resource consumption.\n+ */\n+export interface RunConfig {\n+  /** The maximum execution time for the subagent in minutes. */\n+  max_time_minutes: number;",
        "comment_created_at": "2025-07-24T16:28:02+00:00",
        "comment_author": "allenhutchison",
        "comment_body": "I feel like this could cause problems for long running stuff. I wonder if we would want to be more expressive here. Maybe adding some other fields \n\n- max_turns - which would stop execution after a set number of turns if the agent hasn't returned by then.\n\n- max_tokens - like a budget for how many input tokens you are willing to spend on this task.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2205929407",
    "pr_number": 3957,
    "pr_file": "packages/core/src/telemetry/clearcut-logger/clearcut-logger.ts",
    "created_at": "2025-07-14T22:27:01+00:00",
    "commented_code": "if (this.config?.getDebugMode()) {\n           console.log('Clearcut POST request error: ', e);\n         }\n-        // Add the events back to the front of the queue to be retried.\n-        this.events.unshift(...eventsToSend);\n+        // Add the events back to the front of the queue to be retried, but limit retry queue size\n+        const eventsToRetry = eventsToSend.slice(-this.max_retry_events); // Keep only the most recent events\n+        this.events.unshift(...eventsToRetry);",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2205929407",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 3957,
        "pr_file": "packages/core/src/telemetry/clearcut-logger/clearcut-logger.ts",
        "discussion_id": "2205929407",
        "commented_code": "@@ -139,8 +197,22 @@ export class ClearcutLogger {\n         if (this.config?.getDebugMode()) {\n           console.log('Clearcut POST request error: ', e);\n         }\n-        // Add the events back to the front of the queue to be retried.\n-        this.events.unshift(...eventsToSend);\n+        // Add the events back to the front of the queue to be retried, but limit retry queue size\n+        const eventsToRetry = eventsToSend.slice(-this.max_retry_events); // Keep only the most recent events\n+        this.events.unshift(...eventsToRetry);",
        "comment_created_at": "2025-07-14T22:27:01+00:00",
        "comment_author": "jacob314",
        "comment_body": "unshift, shift, and slice are O(n).\r\nYou might want to use \r\nhttps://yomguithereal.github.io/mnemonist/fixed-deque\r\nor a doubly linked list to make these faster. shouldn't matter that much with a max of 1000 events but might be worth doing anyway to avoid an issue if max_events is raised.",
        "pr_file_module": null
      },
      {
        "comment_id": "2206626684",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 3957,
        "pr_file": "packages/core/src/telemetry/clearcut-logger/clearcut-logger.ts",
        "discussion_id": "2205929407",
        "commented_code": "@@ -139,8 +197,22 @@ export class ClearcutLogger {\n         if (this.config?.getDebugMode()) {\n           console.log('Clearcut POST request error: ', e);\n         }\n-        // Add the events back to the front of the queue to be retried.\n-        this.events.unshift(...eventsToSend);\n+        // Add the events back to the front of the queue to be retried, but limit retry queue size\n+        const eventsToRetry = eventsToSend.slice(-this.max_retry_events); // Keep only the most recent events\n+        this.events.unshift(...eventsToRetry);",
        "comment_created_at": "2025-07-15T07:18:45+00:00",
        "comment_author": "yuvrajangadsingh",
        "comment_body": "Thank you for the performance feedback! I've implemented the FixedDeque solution to  replace the O(n) operations. Here's what changed:\r\n\r\nBefore (O(n) operations):\r\n- splice(0, eventsToRemove) for FIFO eviction\r\n- unshift(...eventsToRetry) for adding retry events\r\n- splice(eventsToRetry.length, excessEvents) for excess cleanup\r\n\r\nAfter (O(1) operations):\r\n- \u2705 Automatic FIFO overflow handling in FixedDeque\r\n- \u2705 Loop of O(1) unshift() operations for retry events\r\n- \u2705 Eliminated excess cleanup entirely (handled by capacity limit)\r\n- \u2705 All existing functionality preserved (event limits, retry logic, debug logging)\r\n\r\nThe FixedDeque automatically handles capacity management and provides O(1) operations for adding/removing from both ends. All tests are passing and the memory leak protection remains intact.\r\n\r\nThis should perform much better if max_events is increased in the future. Thanks for the suggestion!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2207112470",
    "pr_number": 3957,
    "pr_file": "packages/core/src/telemetry/clearcut-logger/clearcut-logger.ts",
    "created_at": "2025-07-15T10:50:18+00:00",
    "commented_code": "if (this.config?.getDebugMode()) {\n           console.log('Clearcut POST request error: ', e);\n         }\n-        // Add the events back to the front of the queue to be retried.\n-        this.events.unshift(...eventsToSend);\n+        // Add the events back to the front of the queue to be retried, but limit retry queue size",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2207139014",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 3957,
        "pr_file": "packages/core/src/telemetry/clearcut-logger/clearcut-logger.ts",
        "discussion_id": "2207112470",
        "commented_code": "@@ -142,8 +164,34 @@ export class ClearcutLogger {\n         if (this.config?.getDebugMode()) {\n           console.log('Clearcut POST request error: ', e);\n         }\n-        // Add the events back to the front of the queue to be retried.\n-        this.events.unshift(...eventsToSend);\n+        // Add the events back to the front of the queue to be retried, but limit retry queue size",
        "comment_created_at": "2025-07-15T10:50:18+00:00",
        "comment_author": "yuvrajangadsingh",
        "comment_body": "@gemini-code-assist This concern is already addressed in the current implementation:\r\n\r\n  1. Queue size is bounded: The FixedDeque is initialized with a maximum capacity of 1000\r\n  events (line 53, 59)\r\n  2. Limited retry count: Only the most recent 100 failed events are retried (line 168:\r\n  eventsToSend.slice(-this.max_retry_events))\r\n  3. Explicit size check: Before adding each event, we check if the queue is at capacity\r\n  (line 174)\r\n  4. Space management: If the queue is full, we remove the oldest event to make room (line\r\n   175)\r\n  5. Graceful overflow handling: The try-catch block (lines 173-186) handles any race\r\n  conditions where the queue might fill up between the check and the add operation\r\n\r\n  The combination of FixedDeque with a hard limit, restricted retry count, and explicit\r\n  capacity checks ensures that memory usage is bounded and cannot grow indefinitely, even\r\n  under continuous failure conditions.",
        "pr_file_module": null
      }
    ]
  }
]