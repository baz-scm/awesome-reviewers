[
  {
    "discussion_id": "2227282807",
    "pr_number": 4737,
    "pr_file": "packages/core/src/utils/filesearch/cache.ts",
    "created_at": "2025-07-24T04:09:08+00:00",
    "commented_code": "+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import fs from 'node:fs';\n+import path from 'node:path';\n+import crypto from 'node:crypto';\n+import os from 'node:os';\n+\n+const cacheDir = path.join(os.homedir(), '.gemini-cli-cache');\n+fs.mkdirSync(cacheDir, { recursive: true });\n+\n+export const getCacheKey = (\n+  directory: string,\n+  ignoreContent: string,\n+): string => {\n+  const hash = crypto.createHash('sha256');\n+  hash.update(directory);\n+  hash.update(ignoreContent);\n+  return hash.digest('hex');\n+};\n+\n+export const getCacheFile = (key: string): string => path.join(cacheDir, key);\n+\n+export const readCache = (file: string): { results: string[] } | undefined => {\n+  if (fs.existsSync(file)) {",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2227282807",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4737,
        "pr_file": "packages/core/src/utils/filesearch/cache.ts",
        "discussion_id": "2227282807",
        "commented_code": "@@ -0,0 +1,52 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import fs from 'node:fs';\n+import path from 'node:path';\n+import crypto from 'node:crypto';\n+import os from 'node:os';\n+\n+const cacheDir = path.join(os.homedir(), '.gemini-cli-cache');\n+fs.mkdirSync(cacheDir, { recursive: true });\n+\n+export const getCacheKey = (\n+  directory: string,\n+  ignoreContent: string,\n+): string => {\n+  const hash = crypto.createHash('sha256');\n+  hash.update(directory);\n+  hash.update(ignoreContent);\n+  return hash.digest('hex');\n+};\n+\n+export const getCacheFile = (key: string): string => path.join(cacheDir, key);\n+\n+export const readCache = (file: string): { results: string[] } | undefined => {\n+  if (fs.existsSync(file)) {",
        "comment_created_at": "2025-07-24T04:09:08+00:00",
        "comment_author": "jacob314",
        "comment_body": "nit: follow style of returning early to reduce nesting.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2230355109",
    "pr_number": 4828,
    "pr_file": "packages/cli/src/ui/commands/promptCommands.ts",
    "created_at": "2025-07-25T07:19:30+00:00",
    "commented_code": "+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import {\n+  SlashCommand,\n+  SlashCommandActionReturn,\n+  CommandContext,\n+  CommandKind,\n+} from './types.js';\n+import {\n+  Config,\n+  getMCPServerPrompts,\n+  getErrorMessage,\n+  invokeMcpPrompt,\n+  connectToMcpServer,\n+} from '@google/gemini-cli-core';\n+\n+export function createPromptCommands(config: Config | null): SlashCommand[] {\n+  const promptCommands: SlashCommand[] = [];\n+  if (config) {",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2230355109",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4828,
        "pr_file": "packages/cli/src/ui/commands/promptCommands.ts",
        "discussion_id": "2230355109",
        "commented_code": "@@ -0,0 +1,183 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import {\n+  SlashCommand,\n+  SlashCommandActionReturn,\n+  CommandContext,\n+  CommandKind,\n+} from './types.js';\n+import {\n+  Config,\n+  getMCPServerPrompts,\n+  getErrorMessage,\n+  invokeMcpPrompt,\n+  connectToMcpServer,\n+} from '@google/gemini-cli-core';\n+\n+export function createPromptCommands(config: Config | null): SlashCommand[] {\n+  const promptCommands: SlashCommand[] = [];\n+  if (config) {",
        "comment_created_at": "2025-07-25T07:19:30+00:00",
        "comment_author": "NTaylorMullen",
        "comment_body": "nit: How do you feel about early. returning here to reduce nesting? I.e. `if (!config) { return promptCommands; }`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2231633561",
    "pr_number": 4811,
    "pr_file": "packages/cli/src/validateNonInterActiveAuth.ts",
    "created_at": "2025-07-25T17:08:16+00:00",
    "commented_code": ") {\n   const effectiveAuthType =\n     configuredAuthType ||\n-    (process.env.GOOGLE_GENAI_USE_VERTEXAI === 'true'\n-      ? AuthType.USE_VERTEX_AI\n-      : process.env.GEMINI_API_KEY\n-        ? AuthType.USE_GEMINI\n-        : undefined);\n+    (process.env.GOOGLE_GENAI_USE_GCP === 'true'",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2231633561",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4811,
        "pr_file": "packages/cli/src/validateNonInterActiveAuth.ts",
        "discussion_id": "2231633561",
        "commented_code": "@@ -14,15 +14,17 @@ export async function validateNonInteractiveAuth(\n ) {\n   const effectiveAuthType =\n     configuredAuthType ||\n-    (process.env.GOOGLE_GENAI_USE_VERTEXAI === 'true'\n-      ? AuthType.USE_VERTEX_AI\n-      : process.env.GEMINI_API_KEY\n-        ? AuthType.USE_GEMINI\n-        : undefined);\n+    (process.env.GOOGLE_GENAI_USE_GCP === 'true'",
        "comment_created_at": "2025-07-25T17:08:16+00:00",
        "comment_author": "jacob314",
        "comment_body": "nit: this conditional is getting a bit hard to read. as a fast follow can you refactor it to use a switch by AuthType or other technique to make it not as nested.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2173315342",
    "pr_number": 2230,
    "pr_file": "packages/core/src/utils/importProcessor.ts",
    "created_at": "2025-06-28T14:55:24+00:00",
    "commented_code": "+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import * as fs from 'fs/promises';\n+import * as path from 'path';\n+\n+// Simple console logger for import processing\n+const logger = {\n+  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n+  debug: (...args: any[]) =>\n+    console.debug('[DEBUG] [ImportProcessor]', ...args),\n+  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n+  warn: (...args: any[]) => console.warn('[WARN] [ImportProcessor]', ...args),\n+  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n+  error: (...args: any[]) =>\n+    console.error('[ERROR] [ImportProcessor]', ...args),\n+};\n+\n+/**\n+ * Interface for tracking import processing state to prevent circular imports\n+ */\n+interface ImportState {\n+  processedFiles: Set<string>;\n+  maxDepth: number;\n+  currentDepth: number;\n+  currentFile?: string; // Track the current file being processed\n+}\n+\n+/**\n+ * Processes import statements in GEMINI.md content\n+ * Supports @path/to/file.md syntax for importing content from other files\n+ *\n+ * @param content - The content to process for imports\n+ * @param basePath - The directory path where the current file is located\n+ * @param debugMode - Whether to enable debug logging\n+ * @param importState - State tracking for circular import prevention\n+ * @returns Processed content with imports resolved\n+ */\n+export async function processImports(\n+  content: string,\n+  basePath: string,\n+  debugMode: boolean = false,\n+  importState: ImportState = {\n+    processedFiles: new Set(),\n+    maxDepth: 10,\n+    currentDepth: 0,\n+  },\n+): Promise<string> {\n+  if (importState.currentDepth >= importState.maxDepth) {\n+    if (debugMode) {\n+      logger.warn(\n+        `Maximum import depth (${importState.maxDepth}) reached. Stopping import processing.`,\n+      );\n+    }\n+    return content;\n+  }\n+\n+  // Regex to match @path/to/file.md imports\n+  // Supports both @path/to/file.md and @./path/to/file.md syntax\n+  const importRegex = /@([./]?[^\\s\n]+\\.md)/g;\n+\n+  let processedContent = content;\n+  let match: RegExpExecArray | null;\n+\n+  // Process all imports in the content\n+  while ((match = importRegex.exec(content)) !== null) {\n+    const importPath = match[1];\n+    const fullPath = path.resolve(basePath, importPath);\n+\n+    if (debugMode) {\n+      logger.debug(`Processing import: ${importPath} -> ${fullPath}`);\n+    }\n+\n+    // Check for circular imports - if we're already processing this file\n+    if (importState.currentFile === fullPath) {\n+      if (debugMode) {\n+        logger.warn(`Circular import detected: ${importPath}`);\n+      }\n+      // Replace the import with a warning comment\n+      processedContent = processedContent.replace(\n+        match[0],\n+        `<!-- Circular import detected: ${importPath} -->`,\n+      );\n+      continue;\n+    }\n+\n+    // Check if we've already processed this file in this import chain\n+    if (importState.processedFiles.has(fullPath)) {\n+      if (debugMode) {\n+        logger.warn(`File already processed in this chain: ${importPath}`);\n+      }\n+      // Replace the import with a warning comment\n+      processedContent = processedContent.replace(\n+        match[0],\n+        `<!-- File already processed: ${importPath} -->`,\n+      );\n+      continue;\n+    }\n+\n+    try {\n+      // Check if the file exists\n+      await fs.access(fullPath);\n+\n+      // Read the imported file content\n+      const importedContent = await fs.readFile(fullPath, 'utf-8');\n+\n+      if (debugMode) {\n+        logger.debug(`Successfully read imported file: ${fullPath}`);\n+      }\n+\n+      // Recursively process imports in the imported content\n+      const processedImportedContent = await processImports(\n+        importedContent,\n+        path.dirname(fullPath),\n+        debugMode,\n+        {\n+          ...importState,\n+          processedFiles: new Set([...importState.processedFiles, fullPath]),\n+          currentDepth: importState.currentDepth + 1,\n+          currentFile: fullPath, // Set the current file being processed\n+        },\n+      );\n+\n+      // Replace the import statement with the processed content\n+      processedContent = processedContent.replace(\n+        match[0],\n+        `<!-- Imported from: ${importPath} -->\n${processedImportedContent}\n<!-- End of import from: ${importPath} -->`,\n+      );\n+    } catch (error) {\n+      const errorMessage =\n+        error instanceof Error ? error.message : String(error);\n+      if (debugMode) {\n+        logger.error(`Failed to import ${importPath}: ${errorMessage}`);\n+      }\n+\n+      // Replace the import with an error comment\n+      processedContent = processedContent.replace(\n+        match[0],\n+        `<!-- Import failed: ${importPath} - ${errorMessage} -->`,\n+      );\n+    }\n+  }\n+\n+  return processedContent;\n+}\n+\n+/**\n+ * Validates import paths to ensure they are safe and within allowed directories\n+ *\n+ * @param importPath - The import path to validate\n+ * @param basePath - The base directory for resolving relative paths\n+ * @param allowedDirectories - Array of allowed directory paths\n+ * @returns Whether the import path is valid\n+ */\n+export function validateImportPath(\n+  importPath: string,\n+  basePath: string,\n+  allowedDirectories: string[],\n+): boolean {\n+  // Reject URLs\n+  if (/^(file|https?):\\/\\//.test(importPath)) {\n+    return false;\n+  }\n+\n+  const resolvedPath = path.resolve(basePath, importPath);\n+\n+  // Reject absolute paths not within allowed directories\n+  if (path.isAbsolute(importPath)) {\n+    return allowedDirectories.some((allowedDir) => {\n+      const normalizedAllowedDir = path.resolve(allowedDir);\n+      const normalizedResolvedPath = path.resolve(resolvedPath);\n+      return normalizedResolvedPath.startsWith(normalizedAllowedDir);\n+    });\n+  }\n+\n+  // For relative paths, check if resolved path is within allowed directories\n+  return allowedDirectories.some((allowedDir) => {\n+    const normalizedAllowedDir = path.resolve(allowedDir);\n+    const normalizedResolvedPath = path.resolve(resolvedPath);\n+    return normalizedResolvedPath.startsWith(normalizedAllowedDir);\n+  });\n+}",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2173315342",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 2230,
        "pr_file": "packages/core/src/utils/importProcessor.ts",
        "discussion_id": "2173315342",
        "commented_code": "@@ -0,0 +1,185 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import * as fs from 'fs/promises';\n+import * as path from 'path';\n+\n+// Simple console logger for import processing\n+const logger = {\n+  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n+  debug: (...args: any[]) =>\n+    console.debug('[DEBUG] [ImportProcessor]', ...args),\n+  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n+  warn: (...args: any[]) => console.warn('[WARN] [ImportProcessor]', ...args),\n+  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n+  error: (...args: any[]) =>\n+    console.error('[ERROR] [ImportProcessor]', ...args),\n+};\n+\n+/**\n+ * Interface for tracking import processing state to prevent circular imports\n+ */\n+interface ImportState {\n+  processedFiles: Set<string>;\n+  maxDepth: number;\n+  currentDepth: number;\n+  currentFile?: string; // Track the current file being processed\n+}\n+\n+/**\n+ * Processes import statements in GEMINI.md content\n+ * Supports @path/to/file.md syntax for importing content from other files\n+ *\n+ * @param content - The content to process for imports\n+ * @param basePath - The directory path where the current file is located\n+ * @param debugMode - Whether to enable debug logging\n+ * @param importState - State tracking for circular import prevention\n+ * @returns Processed content with imports resolved\n+ */\n+export async function processImports(\n+  content: string,\n+  basePath: string,\n+  debugMode: boolean = false,\n+  importState: ImportState = {\n+    processedFiles: new Set(),\n+    maxDepth: 10,\n+    currentDepth: 0,\n+  },\n+): Promise<string> {\n+  if (importState.currentDepth >= importState.maxDepth) {\n+    if (debugMode) {\n+      logger.warn(\n+        `Maximum import depth (${importState.maxDepth}) reached. Stopping import processing.`,\n+      );\n+    }\n+    return content;\n+  }\n+\n+  // Regex to match @path/to/file.md imports\n+  // Supports both @path/to/file.md and @./path/to/file.md syntax\n+  const importRegex = /@([./]?[^\\s\\n]+\\.md)/g;\n+\n+  let processedContent = content;\n+  let match: RegExpExecArray | null;\n+\n+  // Process all imports in the content\n+  while ((match = importRegex.exec(content)) !== null) {\n+    const importPath = match[1];\n+    const fullPath = path.resolve(basePath, importPath);\n+\n+    if (debugMode) {\n+      logger.debug(`Processing import: ${importPath} -> ${fullPath}`);\n+    }\n+\n+    // Check for circular imports - if we're already processing this file\n+    if (importState.currentFile === fullPath) {\n+      if (debugMode) {\n+        logger.warn(`Circular import detected: ${importPath}`);\n+      }\n+      // Replace the import with a warning comment\n+      processedContent = processedContent.replace(\n+        match[0],\n+        `<!-- Circular import detected: ${importPath} -->`,\n+      );\n+      continue;\n+    }\n+\n+    // Check if we've already processed this file in this import chain\n+    if (importState.processedFiles.has(fullPath)) {\n+      if (debugMode) {\n+        logger.warn(`File already processed in this chain: ${importPath}`);\n+      }\n+      // Replace the import with a warning comment\n+      processedContent = processedContent.replace(\n+        match[0],\n+        `<!-- File already processed: ${importPath} -->`,\n+      );\n+      continue;\n+    }\n+\n+    try {\n+      // Check if the file exists\n+      await fs.access(fullPath);\n+\n+      // Read the imported file content\n+      const importedContent = await fs.readFile(fullPath, 'utf-8');\n+\n+      if (debugMode) {\n+        logger.debug(`Successfully read imported file: ${fullPath}`);\n+      }\n+\n+      // Recursively process imports in the imported content\n+      const processedImportedContent = await processImports(\n+        importedContent,\n+        path.dirname(fullPath),\n+        debugMode,\n+        {\n+          ...importState,\n+          processedFiles: new Set([...importState.processedFiles, fullPath]),\n+          currentDepth: importState.currentDepth + 1,\n+          currentFile: fullPath, // Set the current file being processed\n+        },\n+      );\n+\n+      // Replace the import statement with the processed content\n+      processedContent = processedContent.replace(\n+        match[0],\n+        `<!-- Imported from: ${importPath} -->\\n${processedImportedContent}\\n<!-- End of import from: ${importPath} -->`,\n+      );\n+    } catch (error) {\n+      const errorMessage =\n+        error instanceof Error ? error.message : String(error);\n+      if (debugMode) {\n+        logger.error(`Failed to import ${importPath}: ${errorMessage}`);\n+      }\n+\n+      // Replace the import with an error comment\n+      processedContent = processedContent.replace(\n+        match[0],\n+        `<!-- Import failed: ${importPath} - ${errorMessage} -->`,\n+      );\n+    }\n+  }\n+\n+  return processedContent;\n+}\n+\n+/**\n+ * Validates import paths to ensure they are safe and within allowed directories\n+ *\n+ * @param importPath - The import path to validate\n+ * @param basePath - The base directory for resolving relative paths\n+ * @param allowedDirectories - Array of allowed directory paths\n+ * @returns Whether the import path is valid\n+ */\n+export function validateImportPath(\n+  importPath: string,\n+  basePath: string,\n+  allowedDirectories: string[],\n+): boolean {\n+  // Reject URLs\n+  if (/^(file|https?):\\/\\//.test(importPath)) {\n+    return false;\n+  }\n+\n+  const resolvedPath = path.resolve(basePath, importPath);\n+\n+  // Reject absolute paths not within allowed directories\n+  if (path.isAbsolute(importPath)) {\n+    return allowedDirectories.some((allowedDir) => {\n+      const normalizedAllowedDir = path.resolve(allowedDir);\n+      const normalizedResolvedPath = path.resolve(resolvedPath);\n+      return normalizedResolvedPath.startsWith(normalizedAllowedDir);\n+    });\n+  }\n+\n+  // For relative paths, check if resolved path is within allowed directories\n+  return allowedDirectories.some((allowedDir) => {\n+    const normalizedAllowedDir = path.resolve(allowedDir);\n+    const normalizedResolvedPath = path.resolve(resolvedPath);\n+    return normalizedResolvedPath.startsWith(normalizedAllowedDir);\n+  });\n+}",
        "comment_created_at": "2025-06-28T14:55:24+00:00",
        "comment_author": "allenhutchison",
        "comment_body": "The logic in validateImportPath seems a bit redundant. The check for absolute paths and relative paths could be simplified. Since path.resolve handles both cases, you can resolve the path first and then check if it's within the allowed directories.\r\n\r\n  Here's a simplified version of validateImportPath:\r\n\r\n```\r\nexport function validateImportPath(\r\n  importPath: string,\r\n  basePath: string,\r\n  allowedDirectories: string[],\r\n  ): boolean {\r\n     // Reject URLs\r\n     if (/^(file|https?):\\/\\//.test(importPath)) {\r\n        return false;\r\n     }\r\n\r\n     const resolvedPath = path.resolve(basePath, importPath);\r\n \r\n     return allowedDirectories.some((allowedDir) => {\r\n       const normalizedAllowedDir = path.resolve(allowedDir);\r\n       return resolvedPath.startsWith(normalizedAllowedDir);\r\n     });\r\n   }\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2231681517",
    "pr_number": 4823,
    "pr_file": "packages/core/src/services/shellExecutionService.ts",
    "created_at": "2025-07-25T17:35:05+00:00",
    "commented_code": "+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import { spawn } from 'child_process';\n+import { TextDecoder } from 'util';\n+import os from 'os';\n+import stripAnsi from 'strip-ansi';\n+import { getCachedEncodingForBuffer } from '../utils/systemEncoding.js';\n+import { isBinary } from '../utils/textUtils.js';\n+\n+/** A structured result from a shell command execution. */\n+export interface ShellExecutionResult {\n+  /** The raw, unprocessed output buffer. */\n+  rawOutput: Buffer;\n+  /** The combined, decoded stdout and stderr as a string. */\n+  output: string;\n+  /** The decoded stdout as a string. */\n+  stdout: string;\n+  /** The decoded stderr as a string. */\n+  stderr: string;\n+  /** The process exit code, or null if terminated by a signal. */\n+  exitCode: number | null;\n+  /** The signal that terminated the process, if any. */\n+  signal: NodeJS.Signals | null;\n+  /** An error object if the process failed to spawn. */\n+  error: Error | null;\n+  /** A boolean indicating if the command was aborted by the user. */\n+  aborted: boolean;\n+  /** The process ID of the spawned shell. */\n+  pid: number | undefined;\n+}\n+\n+/** A handle for an ongoing shell execution. */\n+export interface ShellExecutionHandle {\n+  /** The process ID of the spawned shell. */\n+  pid: number | undefined;\n+  /** A promise that resolves with the complete execution result. */\n+  result: Promise<ShellExecutionResult>;\n+}\n+\n+/**\n+ * Describes a structured event emitted during shell command execution.\n+ */\n+export type ShellOutputEvent =\n+  | {\n+      /** The event contains a chunk of output data. */\n+      type: 'data';\n+      /** The stream from which the data originated. */\n+      stream: 'stdout' | 'stderr';\n+      /** The decoded string chunk. */\n+      chunk: string;\n+    }\n+  | {\n+      /** Signals that the output stream has been identified as binary. */\n+      type: 'binary_detected';\n+    }\n+  | {\n+      /** Provides progress updates for a binary stream. */\n+      type: 'binary_progress';\n+      /** The total number of bytes received so far. */\n+      bytesReceived: number;\n+    };\n+\n+/**\n+ * A centralized service for executing shell commands with robust process\n+ * management, cross-platform compatibility, and streaming output capabilities.\n+ *\n+ */\n+export class ShellExecutionService {\n+  /**\n+   * Executes a shell command using `spawn`, capturing all output and lifecycle events.\n+   *\n+   * @param commandToExecute The exact command string to run.\n+   * @param cwd The working directory to execute the command in.\n+   * @param onOutputEvent A callback for streaming structured events about the execution, including data chunks and status updates.\n+   * @param abortSignal An AbortSignal to terminate the process and its children.\n+   * @returns An object containing the process ID (pid) and a promise that\n+   *          resolves with the complete execution result.\n+   */\n+  static execute(\n+    commandToExecute: string,\n+    cwd: string,\n+    onOutputEvent: (event: ShellOutputEvent) => void,\n+    abortSignal: AbortSignal,\n+  ): ShellExecutionHandle {\n+    const isWindows = os.platform() === 'win32';\n+    const shell = isWindows ? 'cmd.exe' : 'bash';\n+    const shellArgs = isWindows\n+      ? ['/c', commandToExecute]\n+      : ['-c', commandToExecute];\n+\n+    const child = spawn(shell, shellArgs, {\n+      cwd,\n+      stdio: ['ignore', 'pipe', 'pipe'],\n+      detached: !isWindows, // Use process groups on non-Windows for robust killing\n+      env: {\n+        ...process.env,\n+        GEMINI_CLI: '1',\n+      },\n+    });\n+\n+    const result = new Promise<ShellExecutionResult>((resolve) => {\n+      // Use decoders to handle multi-byte characters safely (for streaming output).\n+      let stdoutDecoder: TextDecoder | null = null;\n+      let stderrDecoder: TextDecoder | null = null;\n+\n+      let stdout = '';\n+      let stderr = '';\n+      const outputChunks: Buffer[] = [];\n+      let error: Error | null = null;\n+      let exited = false;\n+\n+      let isStreamingRawContent = true;\n+      const MAX_SNIFF_SIZE = 4096;\n+      let sniffedBytes = 0;\n+\n+      const handleOutput = (data: Buffer, stream: 'stdout' | 'stderr') => {\n+        if (!stdoutDecoder || !stderrDecoder) {\n+          const encoding = getCachedEncodingForBuffer(data);\n+          stdoutDecoder = new TextDecoder(encoding);\n+          stderrDecoder = new TextDecoder(encoding);\n+        }\n+\n+        outputChunks.push(data);\n+\n+        // Binary detection logic. This only runs until we've made a determination.\n+        if (isStreamingRawContent && sniffedBytes < MAX_SNIFF_SIZE) {\n+          const sniffBuffer = Buffer.concat(outputChunks.slice(0, 20));\n+          sniffedBytes = sniffBuffer.length;\n+\n+          if (isBinary(sniffBuffer)) {\n+            // Change state to stop streaming raw content.\n+            isStreamingRawContent = false;\n+            onOutputEvent({ type: 'binary_detected' });\n+          }\n+        }\n+\n+        const decodedChunk =\n+          stream === 'stdout'\n+            ? stdoutDecoder.decode(data, { stream: true })\n+            : stderrDecoder.decode(data, { stream: true });\n+        const strippedChunk = stripAnsi(decodedChunk);\n+\n+        if (stream === 'stdout') {\n+          stdout += strippedChunk;\n+        } else {\n+          stderr += strippedChunk;\n+        }\n+\n+        if (isStreamingRawContent) {\n+          onOutputEvent({ type: 'data', stream, chunk: strippedChunk });\n+        } else {\n+          const totalBytes = outputChunks.reduce(\n+            (sum, chunk) => sum + chunk.length,\n+            0,\n+          );\n+          onOutputEvent({ type: 'binary_progress', bytesReceived: totalBytes });\n+        }\n+      };\n+\n+      child.stdout.on('data', (data) => handleOutput(data, 'stdout'));\n+      child.stderr.on('data', (data) => handleOutput(data, 'stderr'));\n+      child.on('error', (err) => {\n+        error = err;\n+      });\n+\n+      const abortHandler = async () => {\n+        if (child.pid && !exited) {\n+          if (isWindows) {\n+            spawn('taskkill', ['/pid', child.pid.toString(), '/f', '/t']);\n+          } else {\n+            try {\n+              // Kill the entire process group (negative PID).\n+              // SIGTERM first, then SIGKILL if it doesn't die.\n+              process.kill(-child.pid, 'SIGTERM');\n+              await new Promise((res) => setTimeout(res, 200));",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2231681517",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4823,
        "pr_file": "packages/core/src/services/shellExecutionService.ts",
        "discussion_id": "2231681517",
        "commented_code": "@@ -0,0 +1,222 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import { spawn } from 'child_process';\n+import { TextDecoder } from 'util';\n+import os from 'os';\n+import stripAnsi from 'strip-ansi';\n+import { getCachedEncodingForBuffer } from '../utils/systemEncoding.js';\n+import { isBinary } from '../utils/textUtils.js';\n+\n+/** A structured result from a shell command execution. */\n+export interface ShellExecutionResult {\n+  /** The raw, unprocessed output buffer. */\n+  rawOutput: Buffer;\n+  /** The combined, decoded stdout and stderr as a string. */\n+  output: string;\n+  /** The decoded stdout as a string. */\n+  stdout: string;\n+  /** The decoded stderr as a string. */\n+  stderr: string;\n+  /** The process exit code, or null if terminated by a signal. */\n+  exitCode: number | null;\n+  /** The signal that terminated the process, if any. */\n+  signal: NodeJS.Signals | null;\n+  /** An error object if the process failed to spawn. */\n+  error: Error | null;\n+  /** A boolean indicating if the command was aborted by the user. */\n+  aborted: boolean;\n+  /** The process ID of the spawned shell. */\n+  pid: number | undefined;\n+}\n+\n+/** A handle for an ongoing shell execution. */\n+export interface ShellExecutionHandle {\n+  /** The process ID of the spawned shell. */\n+  pid: number | undefined;\n+  /** A promise that resolves with the complete execution result. */\n+  result: Promise<ShellExecutionResult>;\n+}\n+\n+/**\n+ * Describes a structured event emitted during shell command execution.\n+ */\n+export type ShellOutputEvent =\n+  | {\n+      /** The event contains a chunk of output data. */\n+      type: 'data';\n+      /** The stream from which the data originated. */\n+      stream: 'stdout' | 'stderr';\n+      /** The decoded string chunk. */\n+      chunk: string;\n+    }\n+  | {\n+      /** Signals that the output stream has been identified as binary. */\n+      type: 'binary_detected';\n+    }\n+  | {\n+      /** Provides progress updates for a binary stream. */\n+      type: 'binary_progress';\n+      /** The total number of bytes received so far. */\n+      bytesReceived: number;\n+    };\n+\n+/**\n+ * A centralized service for executing shell commands with robust process\n+ * management, cross-platform compatibility, and streaming output capabilities.\n+ *\n+ */\n+export class ShellExecutionService {\n+  /**\n+   * Executes a shell command using `spawn`, capturing all output and lifecycle events.\n+   *\n+   * @param commandToExecute The exact command string to run.\n+   * @param cwd The working directory to execute the command in.\n+   * @param onOutputEvent A callback for streaming structured events about the execution, including data chunks and status updates.\n+   * @param abortSignal An AbortSignal to terminate the process and its children.\n+   * @returns An object containing the process ID (pid) and a promise that\n+   *          resolves with the complete execution result.\n+   */\n+  static execute(\n+    commandToExecute: string,\n+    cwd: string,\n+    onOutputEvent: (event: ShellOutputEvent) => void,\n+    abortSignal: AbortSignal,\n+  ): ShellExecutionHandle {\n+    const isWindows = os.platform() === 'win32';\n+    const shell = isWindows ? 'cmd.exe' : 'bash';\n+    const shellArgs = isWindows\n+      ? ['/c', commandToExecute]\n+      : ['-c', commandToExecute];\n+\n+    const child = spawn(shell, shellArgs, {\n+      cwd,\n+      stdio: ['ignore', 'pipe', 'pipe'],\n+      detached: !isWindows, // Use process groups on non-Windows for robust killing\n+      env: {\n+        ...process.env,\n+        GEMINI_CLI: '1',\n+      },\n+    });\n+\n+    const result = new Promise<ShellExecutionResult>((resolve) => {\n+      // Use decoders to handle multi-byte characters safely (for streaming output).\n+      let stdoutDecoder: TextDecoder | null = null;\n+      let stderrDecoder: TextDecoder | null = null;\n+\n+      let stdout = '';\n+      let stderr = '';\n+      const outputChunks: Buffer[] = [];\n+      let error: Error | null = null;\n+      let exited = false;\n+\n+      let isStreamingRawContent = true;\n+      const MAX_SNIFF_SIZE = 4096;\n+      let sniffedBytes = 0;\n+\n+      const handleOutput = (data: Buffer, stream: 'stdout' | 'stderr') => {\n+        if (!stdoutDecoder || !stderrDecoder) {\n+          const encoding = getCachedEncodingForBuffer(data);\n+          stdoutDecoder = new TextDecoder(encoding);\n+          stderrDecoder = new TextDecoder(encoding);\n+        }\n+\n+        outputChunks.push(data);\n+\n+        // Binary detection logic. This only runs until we've made a determination.\n+        if (isStreamingRawContent && sniffedBytes < MAX_SNIFF_SIZE) {\n+          const sniffBuffer = Buffer.concat(outputChunks.slice(0, 20));\n+          sniffedBytes = sniffBuffer.length;\n+\n+          if (isBinary(sniffBuffer)) {\n+            // Change state to stop streaming raw content.\n+            isStreamingRawContent = false;\n+            onOutputEvent({ type: 'binary_detected' });\n+          }\n+        }\n+\n+        const decodedChunk =\n+          stream === 'stdout'\n+            ? stdoutDecoder.decode(data, { stream: true })\n+            : stderrDecoder.decode(data, { stream: true });\n+        const strippedChunk = stripAnsi(decodedChunk);\n+\n+        if (stream === 'stdout') {\n+          stdout += strippedChunk;\n+        } else {\n+          stderr += strippedChunk;\n+        }\n+\n+        if (isStreamingRawContent) {\n+          onOutputEvent({ type: 'data', stream, chunk: strippedChunk });\n+        } else {\n+          const totalBytes = outputChunks.reduce(\n+            (sum, chunk) => sum + chunk.length,\n+            0,\n+          );\n+          onOutputEvent({ type: 'binary_progress', bytesReceived: totalBytes });\n+        }\n+      };\n+\n+      child.stdout.on('data', (data) => handleOutput(data, 'stdout'));\n+      child.stderr.on('data', (data) => handleOutput(data, 'stderr'));\n+      child.on('error', (err) => {\n+        error = err;\n+      });\n+\n+      const abortHandler = async () => {\n+        if (child.pid && !exited) {\n+          if (isWindows) {\n+            spawn('taskkill', ['/pid', child.pid.toString(), '/f', '/t']);\n+          } else {\n+            try {\n+              // Kill the entire process group (negative PID).\n+              // SIGTERM first, then SIGKILL if it doesn't die.\n+              process.kill(-child.pid, 'SIGTERM');\n+              await new Promise((res) => setTimeout(res, 200));",
        "comment_created_at": "2025-07-25T17:35:05+00:00",
        "comment_author": "jacob314",
        "comment_body": "200 is a bit of a magic number. make it a const while you are cleaning this up.",
        "pr_file_module": null
      },
      {
        "comment_id": "2232230582",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4823,
        "pr_file": "packages/core/src/services/shellExecutionService.ts",
        "discussion_id": "2231681517",
        "commented_code": "@@ -0,0 +1,222 @@\n+/**\n+ * @license\n+ * Copyright 2025 Google LLC\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+import { spawn } from 'child_process';\n+import { TextDecoder } from 'util';\n+import os from 'os';\n+import stripAnsi from 'strip-ansi';\n+import { getCachedEncodingForBuffer } from '../utils/systemEncoding.js';\n+import { isBinary } from '../utils/textUtils.js';\n+\n+/** A structured result from a shell command execution. */\n+export interface ShellExecutionResult {\n+  /** The raw, unprocessed output buffer. */\n+  rawOutput: Buffer;\n+  /** The combined, decoded stdout and stderr as a string. */\n+  output: string;\n+  /** The decoded stdout as a string. */\n+  stdout: string;\n+  /** The decoded stderr as a string. */\n+  stderr: string;\n+  /** The process exit code, or null if terminated by a signal. */\n+  exitCode: number | null;\n+  /** The signal that terminated the process, if any. */\n+  signal: NodeJS.Signals | null;\n+  /** An error object if the process failed to spawn. */\n+  error: Error | null;\n+  /** A boolean indicating if the command was aborted by the user. */\n+  aborted: boolean;\n+  /** The process ID of the spawned shell. */\n+  pid: number | undefined;\n+}\n+\n+/** A handle for an ongoing shell execution. */\n+export interface ShellExecutionHandle {\n+  /** The process ID of the spawned shell. */\n+  pid: number | undefined;\n+  /** A promise that resolves with the complete execution result. */\n+  result: Promise<ShellExecutionResult>;\n+}\n+\n+/**\n+ * Describes a structured event emitted during shell command execution.\n+ */\n+export type ShellOutputEvent =\n+  | {\n+      /** The event contains a chunk of output data. */\n+      type: 'data';\n+      /** The stream from which the data originated. */\n+      stream: 'stdout' | 'stderr';\n+      /** The decoded string chunk. */\n+      chunk: string;\n+    }\n+  | {\n+      /** Signals that the output stream has been identified as binary. */\n+      type: 'binary_detected';\n+    }\n+  | {\n+      /** Provides progress updates for a binary stream. */\n+      type: 'binary_progress';\n+      /** The total number of bytes received so far. */\n+      bytesReceived: number;\n+    };\n+\n+/**\n+ * A centralized service for executing shell commands with robust process\n+ * management, cross-platform compatibility, and streaming output capabilities.\n+ *\n+ */\n+export class ShellExecutionService {\n+  /**\n+   * Executes a shell command using `spawn`, capturing all output and lifecycle events.\n+   *\n+   * @param commandToExecute The exact command string to run.\n+   * @param cwd The working directory to execute the command in.\n+   * @param onOutputEvent A callback for streaming structured events about the execution, including data chunks and status updates.\n+   * @param abortSignal An AbortSignal to terminate the process and its children.\n+   * @returns An object containing the process ID (pid) and a promise that\n+   *          resolves with the complete execution result.\n+   */\n+  static execute(\n+    commandToExecute: string,\n+    cwd: string,\n+    onOutputEvent: (event: ShellOutputEvent) => void,\n+    abortSignal: AbortSignal,\n+  ): ShellExecutionHandle {\n+    const isWindows = os.platform() === 'win32';\n+    const shell = isWindows ? 'cmd.exe' : 'bash';\n+    const shellArgs = isWindows\n+      ? ['/c', commandToExecute]\n+      : ['-c', commandToExecute];\n+\n+    const child = spawn(shell, shellArgs, {\n+      cwd,\n+      stdio: ['ignore', 'pipe', 'pipe'],\n+      detached: !isWindows, // Use process groups on non-Windows for robust killing\n+      env: {\n+        ...process.env,\n+        GEMINI_CLI: '1',\n+      },\n+    });\n+\n+    const result = new Promise<ShellExecutionResult>((resolve) => {\n+      // Use decoders to handle multi-byte characters safely (for streaming output).\n+      let stdoutDecoder: TextDecoder | null = null;\n+      let stderrDecoder: TextDecoder | null = null;\n+\n+      let stdout = '';\n+      let stderr = '';\n+      const outputChunks: Buffer[] = [];\n+      let error: Error | null = null;\n+      let exited = false;\n+\n+      let isStreamingRawContent = true;\n+      const MAX_SNIFF_SIZE = 4096;\n+      let sniffedBytes = 0;\n+\n+      const handleOutput = (data: Buffer, stream: 'stdout' | 'stderr') => {\n+        if (!stdoutDecoder || !stderrDecoder) {\n+          const encoding = getCachedEncodingForBuffer(data);\n+          stdoutDecoder = new TextDecoder(encoding);\n+          stderrDecoder = new TextDecoder(encoding);\n+        }\n+\n+        outputChunks.push(data);\n+\n+        // Binary detection logic. This only runs until we've made a determination.\n+        if (isStreamingRawContent && sniffedBytes < MAX_SNIFF_SIZE) {\n+          const sniffBuffer = Buffer.concat(outputChunks.slice(0, 20));\n+          sniffedBytes = sniffBuffer.length;\n+\n+          if (isBinary(sniffBuffer)) {\n+            // Change state to stop streaming raw content.\n+            isStreamingRawContent = false;\n+            onOutputEvent({ type: 'binary_detected' });\n+          }\n+        }\n+\n+        const decodedChunk =\n+          stream === 'stdout'\n+            ? stdoutDecoder.decode(data, { stream: true })\n+            : stderrDecoder.decode(data, { stream: true });\n+        const strippedChunk = stripAnsi(decodedChunk);\n+\n+        if (stream === 'stdout') {\n+          stdout += strippedChunk;\n+        } else {\n+          stderr += strippedChunk;\n+        }\n+\n+        if (isStreamingRawContent) {\n+          onOutputEvent({ type: 'data', stream, chunk: strippedChunk });\n+        } else {\n+          const totalBytes = outputChunks.reduce(\n+            (sum, chunk) => sum + chunk.length,\n+            0,\n+          );\n+          onOutputEvent({ type: 'binary_progress', bytesReceived: totalBytes });\n+        }\n+      };\n+\n+      child.stdout.on('data', (data) => handleOutput(data, 'stdout'));\n+      child.stderr.on('data', (data) => handleOutput(data, 'stderr'));\n+      child.on('error', (err) => {\n+        error = err;\n+      });\n+\n+      const abortHandler = async () => {\n+        if (child.pid && !exited) {\n+          if (isWindows) {\n+            spawn('taskkill', ['/pid', child.pid.toString(), '/f', '/t']);\n+          } else {\n+            try {\n+              // Kill the entire process group (negative PID).\n+              // SIGTERM first, then SIGKILL if it doesn't die.\n+              process.kill(-child.pid, 'SIGTERM');\n+              await new Promise((res) => setTimeout(res, 200));",
        "comment_created_at": "2025-07-25T23:48:04+00:00",
        "comment_author": "abhipatel12",
        "comment_body": "Done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2229819333",
    "pr_number": 4795,
    "pr_file": "packages/core/src/tools/shell.ts",
    "created_at": "2025-07-24T23:52:31+00:00",
    "commented_code": "return description;\n   }\n \n+  /**\n+   * Splits a shell command into a list of individual commands, respecting quotes.\n+   * This is used to separate chained commands (e.g., using &&, ||, ;).\n+   * @param command The shell command string to parse\n+   * @returns An array of individual command strings\n+   */\n+  private splitCommands(command: string): string[] {",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2229819333",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4795,
        "pr_file": "packages/core/src/tools/shell.ts",
        "discussion_id": "2229819333",
        "commented_code": "@@ -93,38 +81,198 @@ Process Group PGID: Process group started or \\`(none)\\``,\n     return description;\n   }\n \n+  /**\n+   * Splits a shell command into a list of individual commands, respecting quotes.\n+   * This is used to separate chained commands (e.g., using &&, ||, ;).\n+   * @param command The shell command string to parse\n+   * @returns An array of individual command strings\n+   */\n+  private splitCommands(command: string): string[] {",
        "comment_created_at": "2025-07-24T23:52:31+00:00",
        "comment_author": "NTaylorMullen",
        "comment_body": "Lets pull all of the command extraction logic (this method and others related) into its own utility file to keep shell.ts small / operable by Gemini CLI",
        "pr_file_module": null
      },
      {
        "comment_id": "2231852202",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 4795,
        "pr_file": "packages/core/src/tools/shell.ts",
        "discussion_id": "2229819333",
        "commented_code": "@@ -93,38 +81,198 @@ Process Group PGID: Process group started or \\`(none)\\``,\n     return description;\n   }\n \n+  /**\n+   * Splits a shell command into a list of individual commands, respecting quotes.\n+   * This is used to separate chained commands (e.g., using &&, ||, ;).\n+   * @param command The shell command string to parse\n+   * @returns An array of individual command strings\n+   */\n+  private splitCommands(command: string): string[] {",
        "comment_created_at": "2025-07-25T19:20:45+00:00",
        "comment_author": "mattKorwel",
        "comment_body": "done. @scidomino I had to stomp on your windows changes during the merge commit. appologies. you'll need to revisit those changes, now in `shell-util.test.ts`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2193323207",
    "pr_number": 3532,
    "pr_file": "packages/core/src/code_assist/oauth2.ts",
    "created_at": "2025-07-08T19:47:36+00:00",
    "commented_code": "}\n \n async function authWithWeb(client: OAuth2Client): Promise<OauthWebLogin> {\n-  const port = await getAvailablePort();\n+  let port: number;",
    "repo_full_name": "google-gemini/gemini-cli",
    "discussion_comments": [
      {
        "comment_id": "2193323207",
        "repo_full_name": "google-gemini/gemini-cli",
        "pr_number": 3532,
        "pr_file": "packages/core/src/code_assist/oauth2.ts",
        "discussion_id": "2193323207",
        "commented_code": "@@ -126,7 +151,22 @@ export async function getOauthClient(\n }\n \n async function authWithWeb(client: OAuth2Client): Promise<OauthWebLogin> {\n-  const port = await getAvailablePort();\n+  let port: number;",
        "comment_created_at": "2025-07-08T19:47:36+00:00",
        "comment_author": "scidomino",
        "comment_body": "nit: I would shove all this into a getPort helper method",
        "pr_file_module": null
      }
    ]
  }
]