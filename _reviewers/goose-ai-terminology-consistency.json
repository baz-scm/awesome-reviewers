[
  {
    "discussion_id": "2178060940",
    "pr_number": 3059,
    "pr_file": "documentation/blog/2025-06-24-mcp-jupyter-server/index.md",
    "created_at": "2025-07-01T16:39:16+00:00",
    "commented_code": "+---\n+title: \"MCP Jupyter: AI-Powered Machine Learning and Data Science\"\n+description: Enable AI agents to work directly with your Jupyter notebooks, leveraging persistent memory and stateful collaboration for enhanced ML and data science workflows\n+date: 2025-06-24\n+authors:\n+  - damien\n+  - dean\n+  - harrison\n+---\n+\n+![MCP Jupyter Server](data-goose.png)\n+\n+Machine learning and data science workflows are inherently iterative. You load data, explore patterns, build models, and refine your approach based on results. But traditional AI assistants lose context between interactions, forcing you to reload data and re-establish context repeatedly\u2014making data-heavy development slow and expensive.\n+\n+The [**MCP Jupyter Server**](https://github.com/block/mcp-jupyter) solves this by enabling AI agents like Goose to work directly with your Jupyter notebooks, maintaining persistent memory and state across interactions while letting the AI interact with your data through code execution rather than raw data transfer.\n+\n+<!--truncate-->\n+\n+## The Memory and Context Problem\n+\n+Traditional AI coding assistants face a fundamental limitation: they lose context between code iterations. They also are not designed for adhoc work where the expectation is the code should run from start to finish. This creates several challenges for data-heavy ML workflows:",
    "repo_full_name": "block/goose",
    "discussion_comments": [
      {
        "comment_id": "2178060940",
        "repo_full_name": "block/goose",
        "pr_number": 3059,
        "pr_file": "documentation/blog/2025-06-24-mcp-jupyter-server/index.md",
        "discussion_id": "2178060940",
        "commented_code": "@@ -0,0 +1,158 @@\n+---\n+title: \"MCP Jupyter: AI-Powered Machine Learning and Data Science\"\n+description: Enable AI agents to work directly with your Jupyter notebooks, leveraging persistent memory and stateful collaboration for enhanced ML and data science workflows\n+date: 2025-06-24\n+authors:\n+  - damien\n+  - dean\n+  - harrison\n+---\n+\n+![MCP Jupyter Server](data-goose.png)\n+\n+Machine learning and data science workflows are inherently iterative. You load data, explore patterns, build models, and refine your approach based on results. But traditional AI assistants lose context between interactions, forcing you to reload data and re-establish context repeatedly\u2014making data-heavy development slow and expensive.\n+\n+The [**MCP Jupyter Server**](https://github.com/block/mcp-jupyter) solves this by enabling AI agents like Goose to work directly with your Jupyter notebooks, maintaining persistent memory and state across interactions while letting the AI interact with your data through code execution rather than raw data transfer.\n+\n+<!--truncate-->\n+\n+## The Memory and Context Problem\n+\n+Traditional AI coding assistants face a fundamental limitation: they lose context between code iterations. They also are not designed for adhoc work where the expectation is the code should run from start to finish. This creates several challenges for data-heavy ML workflows:",
        "comment_created_at": "2025-07-01T16:39:16+00:00",
        "comment_author": "dwyatte",
        "comment_body": "```suggestion\r\nTraditional AI coding assistants face a fundamental limitation: they lose context between code iterations. They also are not designed for interactive work like data and model exploration, instead favoring end-to-end solutions to a prompted problem. This creates several challenges for data-heavy ML workflows:\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2178063641",
    "pr_number": 3059,
    "pr_file": "documentation/blog/2025-06-24-mcp-jupyter-server/index.md",
    "created_at": "2025-07-01T16:40:56+00:00",
    "commented_code": "+---\n+title: \"MCP Jupyter: AI-Powered Machine Learning and Data Science\"\n+description: Enable AI agents to work directly with your Jupyter notebooks, leveraging persistent memory and stateful collaboration for enhanced ML and data science workflows\n+date: 2025-06-24\n+authors:\n+  - damien\n+  - dean\n+  - harrison\n+---\n+\n+![MCP Jupyter Server](data-goose.png)\n+\n+Machine learning and data science workflows are inherently iterative. You load data, explore patterns, build models, and refine your approach based on results. But traditional AI assistants lose context between interactions, forcing you to reload data and re-establish context repeatedly\u2014making data-heavy development slow and expensive.\n+\n+The [**MCP Jupyter Server**](https://github.com/block/mcp-jupyter) solves this by enabling AI agents like Goose to work directly with your Jupyter notebooks, maintaining persistent memory and state across interactions while letting the AI interact with your data through code execution rather than raw data transfer.\n+\n+<!--truncate-->\n+\n+## The Memory and Context Problem\n+\n+Traditional AI coding assistants face a fundamental limitation: they lose context between code iterations. They also are not designed for adhoc work where the expectation is the code should run from start to finish. This creates several challenges for data-heavy ML workflows:\n+\n+- **Constant data reloading**: Each interaction requires re-loading or describing your dataset\n+- **Expensive iterations**: Large datasets are slow and costly to process repeatedly\n+- **Context size**: The raw data is also too large to be fit in context\n+- **Not designed for adhoc work**: It is harder to have the model do some steps for you, and then let you take over and then later pass control back to the model",
    "repo_full_name": "block/goose",
    "discussion_comments": [
      {
        "comment_id": "2178063641",
        "repo_full_name": "block/goose",
        "pr_number": 3059,
        "pr_file": "documentation/blog/2025-06-24-mcp-jupyter-server/index.md",
        "discussion_id": "2178063641",
        "commented_code": "@@ -0,0 +1,158 @@\n+---\n+title: \"MCP Jupyter: AI-Powered Machine Learning and Data Science\"\n+description: Enable AI agents to work directly with your Jupyter notebooks, leveraging persistent memory and stateful collaboration for enhanced ML and data science workflows\n+date: 2025-06-24\n+authors:\n+  - damien\n+  - dean\n+  - harrison\n+---\n+\n+![MCP Jupyter Server](data-goose.png)\n+\n+Machine learning and data science workflows are inherently iterative. You load data, explore patterns, build models, and refine your approach based on results. But traditional AI assistants lose context between interactions, forcing you to reload data and re-establish context repeatedly\u2014making data-heavy development slow and expensive.\n+\n+The [**MCP Jupyter Server**](https://github.com/block/mcp-jupyter) solves this by enabling AI agents like Goose to work directly with your Jupyter notebooks, maintaining persistent memory and state across interactions while letting the AI interact with your data through code execution rather than raw data transfer.\n+\n+<!--truncate-->\n+\n+## The Memory and Context Problem\n+\n+Traditional AI coding assistants face a fundamental limitation: they lose context between code iterations. They also are not designed for adhoc work where the expectation is the code should run from start to finish. This creates several challenges for data-heavy ML workflows:\n+\n+- **Constant data reloading**: Each interaction requires re-loading or describing your dataset\n+- **Expensive iterations**: Large datasets are slow and costly to process repeatedly\n+- **Context size**: The raw data is also too large to be fit in context\n+- **Not designed for adhoc work**: It is harder to have the model do some steps for you, and then let you take over and then later pass control back to the model",
        "comment_created_at": "2025-07-01T16:40:56+00:00",
        "comment_author": "dwyatte",
        "comment_body": "```suggestion\r\n- **Not designed for interactive work**: It is harder to have the assistant do some steps and then transfer control back to the human or vice versa\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2178080854",
    "pr_number": 3059,
    "pr_file": "documentation/blog/2025-06-24-mcp-jupyter-server/index.md",
    "created_at": "2025-07-01T16:50:35+00:00",
    "commented_code": "+---\n+title: \"MCP Jupyter: AI-Powered Machine Learning and Data Science\"\n+description: Enable AI agents to work directly with your Jupyter notebooks, leveraging persistent memory and stateful collaboration for enhanced ML and data science workflows\n+date: 2025-06-24\n+authors:\n+  - damien\n+  - dean\n+  - harrison\n+---\n+\n+![MCP Jupyter Server](data-goose.png)\n+\n+Machine learning and data science workflows are inherently iterative. You load data, explore patterns, build models, and refine your approach based on results. But traditional AI assistants lose context between interactions, forcing you to reload data and re-establish context repeatedly\u2014making data-heavy development slow and expensive.\n+\n+The [**MCP Jupyter Server**](https://github.com/block/mcp-jupyter) solves this by enabling AI agents like Goose to work directly with your Jupyter notebooks, maintaining persistent memory and state across interactions while letting the AI interact with your data through code execution rather than raw data transfer.\n+\n+<!--truncate-->\n+\n+## The Memory and Context Problem\n+\n+Traditional AI coding assistants face a fundamental limitation: they lose context between code iterations. They also are not designed for adhoc work where the expectation is the code should run from start to finish. This creates several challenges for data-heavy ML workflows:\n+\n+- **Constant data reloading**: Each interaction requires re-loading or describing your dataset\n+- **Expensive iterations**: Large datasets are slow and costly to process repeatedly\n+- **Context size**: The raw data is also too large to be fit in context\n+- **Not designed for adhoc work**: It is harder to have the model do some steps for you, and then let you take over and then later pass control back to the model\n+\n+This has made it difficult to use AI to help with data science workflows, which led to the creation of the MCP Jupyter Server.\n+\n+## A Better Approach: Persistent State\n+\n+The MCP Jupyter Server takes a different approach. Instead of losing context between interactions, it maintains persistent memory and lets the AI interact with your data through code execution. This creates a powerful paradigm:\n+\n+- **Persistent memory**: Variables and state are maintained across all interactions\n+- **Efficient iterations**: No need to reload data or re-establish context\n+- **Code-based data interaction**: AI explores data through execution, not given the raw data\n+- **True pair programming**: Seamless collaboration within the same notebook context\n+\n+## Transforming ML Workflows\n+\n+### Exploratory Data Analysis\n+\n+Instead of describing your dataset, let the AI explore it directly:\n+\n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"Help me understand this customer dataset\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Let me explore your data structure first\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI executes: df.info(), df.describe(), df.head()]</span>*\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"I can see you have 50,000 customers with 12 features. The data includes demographics (age, income), behavioral metrics (purchase_frequency, avg_order_value), and some missing values in the 'phone_number' column. Would you like me to create visualizations for the key relationships, like age vs income or purchase patterns?\"\n+> \n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"Yes, show me the age and income distributions, and any correlations\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Perfect! I'll create histograms for age and income, plus a correlation heatmap\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI generates and displays visualizations]</span>*\n+\n+The AI can see your actual column names, data types, and distributions\u2014leading to much more relevant suggestions.\n+\n+### Interactive Model Development\n+\n+The AI becomes a true collaborator in your modeling process:\n+\n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"This model isn't performing well\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Let me check the current metrics and feature importance\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI executes your existing model evaluation code]</span>*\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"I see the accuracy is 72% and the most important features are 'price' and 'location'. The model seems to be overfitting - would you like me to try regularization or reduce the feature set?\"\n+> \n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"Try regularization first\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"I'll add L2 regularization and test different alpha values\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI implements and tests changes iteratively]</span>*\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Great! With alpha=0.1, accuracy improved to 78% and the validation curve looks much better. Should I tune it further or try ensemble methods?\"\n+\n+### Real-time Debugging\n+\n+When errors occur, the AI has full context:\n+\n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"I'm getting a KeyError in cell 5\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Let me check what columns are available in your dataframe\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI executes: df.columns, df.info()]</span>*\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"I see the issue - you're trying to access 'customer_id' but the actual column name is 'CustomerID' with capital letters. Also, I notice you have 'purchase_date' as a string - should I convert that to datetime while I fix the KeyError?\"\n+> \n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"Yes, fix both issues\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Done! I've updated the column reference and converted purchase_date to datetime. The cell should run properly now.\"\n+\n+### Continuous Collaboration\n+\n+Imagine a scenario where you are working on a new dataset:\n+\n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[Executes: df = pd.read_csv('sales_data.csv')]</span>*\n+> \n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"Let me check the data types and look for any anomalies\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"I'll analyze your sales data structure\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI executes: df.info(), df.describe(include='all')]</span>*\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"I found a few issues: 'CustomerID' is stored as text but should be numeric, and there are 847 missing values in 'SalesAmount'. Would you like me to convert 'CustomerID' to numeric and fill the missing 'SalesAmount' values with the median?\"\n+> \n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"Yes, please do that and show me the updated info\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Done! CustomerID is now numeric and SalesAmount gaps are filled. Your dataset is clean and ready for modeling.\"\n+\n+*<span style={{color: '#6b7280', fontStyle: 'italic'}}>[Later in the session, after you've trained a model...]</span>*\n+\n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"How is my model performing?\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Let me generate the key metrics for your trained model\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI accesses the existing model variable and generates evaluation metrics]</span>*\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Your Random Forest achieved 0.84 precision and 0.81 recall. The confusion matrix shows some false positives in the high-value sales category. Would you like me to adjust the decision threshold or try feature engineering?\"\n+\n+This fluid back-and-forth, where the AI understands and builds upon the existing notebook state, allows for seamless collaboration without the need for constant context re-establishment or data reloading.",
    "repo_full_name": "block/goose",
    "discussion_comments": [
      {
        "comment_id": "2178080854",
        "repo_full_name": "block/goose",
        "pr_number": 3059,
        "pr_file": "documentation/blog/2025-06-24-mcp-jupyter-server/index.md",
        "discussion_id": "2178080854",
        "commented_code": "@@ -0,0 +1,158 @@\n+---\n+title: \"MCP Jupyter: AI-Powered Machine Learning and Data Science\"\n+description: Enable AI agents to work directly with your Jupyter notebooks, leveraging persistent memory and stateful collaboration for enhanced ML and data science workflows\n+date: 2025-06-24\n+authors:\n+  - damien\n+  - dean\n+  - harrison\n+---\n+\n+![MCP Jupyter Server](data-goose.png)\n+\n+Machine learning and data science workflows are inherently iterative. You load data, explore patterns, build models, and refine your approach based on results. But traditional AI assistants lose context between interactions, forcing you to reload data and re-establish context repeatedly\u2014making data-heavy development slow and expensive.\n+\n+The [**MCP Jupyter Server**](https://github.com/block/mcp-jupyter) solves this by enabling AI agents like Goose to work directly with your Jupyter notebooks, maintaining persistent memory and state across interactions while letting the AI interact with your data through code execution rather than raw data transfer.\n+\n+<!--truncate-->\n+\n+## The Memory and Context Problem\n+\n+Traditional AI coding assistants face a fundamental limitation: they lose context between code iterations. They also are not designed for adhoc work where the expectation is the code should run from start to finish. This creates several challenges for data-heavy ML workflows:\n+\n+- **Constant data reloading**: Each interaction requires re-loading or describing your dataset\n+- **Expensive iterations**: Large datasets are slow and costly to process repeatedly\n+- **Context size**: The raw data is also too large to be fit in context\n+- **Not designed for adhoc work**: It is harder to have the model do some steps for you, and then let you take over and then later pass control back to the model\n+\n+This has made it difficult to use AI to help with data science workflows, which led to the creation of the MCP Jupyter Server.\n+\n+## A Better Approach: Persistent State\n+\n+The MCP Jupyter Server takes a different approach. Instead of losing context between interactions, it maintains persistent memory and lets the AI interact with your data through code execution. This creates a powerful paradigm:\n+\n+- **Persistent memory**: Variables and state are maintained across all interactions\n+- **Efficient iterations**: No need to reload data or re-establish context\n+- **Code-based data interaction**: AI explores data through execution, not given the raw data\n+- **True pair programming**: Seamless collaboration within the same notebook context\n+\n+## Transforming ML Workflows\n+\n+### Exploratory Data Analysis\n+\n+Instead of describing your dataset, let the AI explore it directly:\n+\n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"Help me understand this customer dataset\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Let me explore your data structure first\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI executes: df.info(), df.describe(), df.head()]</span>*\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"I can see you have 50,000 customers with 12 features. The data includes demographics (age, income), behavioral metrics (purchase_frequency, avg_order_value), and some missing values in the 'phone_number' column. Would you like me to create visualizations for the key relationships, like age vs income or purchase patterns?\"\n+> \n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"Yes, show me the age and income distributions, and any correlations\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Perfect! I'll create histograms for age and income, plus a correlation heatmap\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI generates and displays visualizations]</span>*\n+\n+The AI can see your actual column names, data types, and distributions\u2014leading to much more relevant suggestions.\n+\n+### Interactive Model Development\n+\n+The AI becomes a true collaborator in your modeling process:\n+\n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"This model isn't performing well\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Let me check the current metrics and feature importance\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI executes your existing model evaluation code]</span>*\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"I see the accuracy is 72% and the most important features are 'price' and 'location'. The model seems to be overfitting - would you like me to try regularization or reduce the feature set?\"\n+> \n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"Try regularization first\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"I'll add L2 regularization and test different alpha values\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI implements and tests changes iteratively]</span>*\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Great! With alpha=0.1, accuracy improved to 78% and the validation curve looks much better. Should I tune it further or try ensemble methods?\"\n+\n+### Real-time Debugging\n+\n+When errors occur, the AI has full context:\n+\n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"I'm getting a KeyError in cell 5\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Let me check what columns are available in your dataframe\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI executes: df.columns, df.info()]</span>*\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"I see the issue - you're trying to access 'customer_id' but the actual column name is 'CustomerID' with capital letters. Also, I notice you have 'purchase_date' as a string - should I convert that to datetime while I fix the KeyError?\"\n+> \n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"Yes, fix both issues\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Done! I've updated the column reference and converted purchase_date to datetime. The cell should run properly now.\"\n+\n+### Continuous Collaboration\n+\n+Imagine a scenario where you are working on a new dataset:\n+\n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[Executes: df = pd.read_csv('sales_data.csv')]</span>*\n+> \n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"Let me check the data types and look for any anomalies\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"I'll analyze your sales data structure\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI executes: df.info(), df.describe(include='all')]</span>*\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"I found a few issues: 'CustomerID' is stored as text but should be numeric, and there are 847 missing values in 'SalesAmount'. Would you like me to convert 'CustomerID' to numeric and fill the missing 'SalesAmount' values with the median?\"\n+> \n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"Yes, please do that and show me the updated info\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Done! CustomerID is now numeric and SalesAmount gaps are filled. Your dataset is clean and ready for modeling.\"\n+\n+*<span style={{color: '#6b7280', fontStyle: 'italic'}}>[Later in the session, after you've trained a model...]</span>*\n+\n+> <span style={{color: '#2563eb', fontWeight: 'bold'}}>User:</span> \"How is my model performing?\"\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Let me generate the key metrics for your trained model\"\n+> \n+> *<span style={{color: '#6b7280', fontStyle: 'italic'}}>[AI accesses the existing model variable and generates evaluation metrics]</span>*\n+> \n+> <span style={{color: '#059669', fontWeight: 'bold'}}>AI:</span> \"Your Random Forest achieved 0.84 precision and 0.81 recall. The confusion matrix shows some false positives in the high-value sales category. Would you like me to adjust the decision threshold or try feature engineering?\"\n+\n+This fluid back-and-forth, where the AI understands and builds upon the existing notebook state, allows for seamless collaboration without the need for constant context re-establishment or data reloading.",
        "comment_created_at": "2025-07-01T16:50:35+00:00",
        "comment_author": "dwyatte",
        "comment_body": "```suggestion\r\nThis fluid back-and-forth, where the assistant understands and builds upon the existing notebook state, allows for seamless collaboration without the need for constant context re-establishment or data reloading.\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2217455673",
    "pr_number": 3528,
    "pr_file": "documentation/blog/2025-07-21-orchestrating-subagents/index.md",
    "created_at": "2025-07-19T20:55:27+00:00",
    "commented_code": "+---\n+title: Orchestrating 6 Subagents to Build a Collaborative API Playground\n+description: Delegating backend, frontend, docs, and tests so six subagents could build collaborative API tool for kids\n+authors: \n+    - rizel\n+---\n+\n+![built by subagents](built-by-subagents.png)\n+\n+I built Postman meets Google Docs for 10-year-olds.\n+\n+*Cue record scratch.*\n+\n+*Cue freeze frame.*\n+\n+*Cue movie clich\u00e9.*\n+\n+You're probably wondering how I got here.\n+\n+\n+<!--truncate-->\n+\n+Before I explain, it\u2019s better if I just show you:\n+\n+\ud83d\udc49Try it yourself: https://api-playground-production.up.railway.app/ \n+\n+![api playground](api-playground.png)\n+\n+It\u2019s a collaborative API testing playground where kids can run sample requests, get playful error messages, and see live responses in real time. Everyone in the session sees the API response together, turning the experience of solo debugging into multiplayer coding. And I wanted it to look like a literal playground.\n+\n+I was inspired to build this after attending our company\u2019s Bring Your Kids to Work Day. I didn\u2019t bring my kid because she\u2019s still an infant, but I attended to support my teammate Adewale Abati, who led a virtual session introducing kids to Goose. They used it to build comics, games, and music apps that were fun, imaginative, and genuinely impressive.\n+\n+I decided to create a digital resource that teaches foundational concepts like APIs in a way that feels inviting instead of intimidating. Traditional API testing tools are powerful, but for a kid just starting out, they can be confusing and unclear.\n+\n+The wild part is that I let Goose and six subagents bring this idea to life.\n+\n+## Meet the Subagents\n+\n+[Subagents](https://block.github.io/goose/docs/experimental/subagents) are individual AI instances that take on specific tasks. Each one runs in its own session, which helps preserve the main context window and keeps your primary Goose conversation uncluttered and focused on high-level orchestration. I think of subagents as temporary teammates. For this project, I treated them like an on-demand dev squad. I had a Backend Developer to build the server, a Frontend Developer to handle the UI, a Doc Writer to create a beginner-friendly README, and a Test Engineer to put together a simple test suite.\n+\n+:::note  \n+Goose automatically cleans up subagents upon task completion.  \n+:::\n+\n+Typically, I am not a one-shot prompter. I prefer prompt chaining, which means breaking a complex task into smaller prompts and guiding the AI step by step. This method gives me more control over the output, especially when I am trying to build something complex.\n+\n+But this time, I wanted to delegate, walk away, and come back to progress, so I used subagents.\n+\n+Since the feature is still experimental, I had to enable it via an environment variable:\n+\n+```bash\n+export GOOSE_ALPHA_FEATURES=true  \n+```\n+\n+## A Gaggle of Geese\n+\n+There are a few ways to create subagents in Goose. You can use natural language prompts, define them through [recipes](https://block.github.io/goose/docs/guides/recipes/), or even spin up [external subagents](https://block.github.io/goose/docs/experimental/subagents/#external-subagents) like Codex or Claude Code.. \n+\n+I used natural language prompts because of the convenience to directly configure a subagent through one prompt. Here\u2019s the prompt I used:\n+\n+```\n+Build a real-time collaborative API testing platform using 3 AI subagents working sequentially - like \"Google Docs for Postman\" where teams can test APIs together, but for kids. Make it so errors and results are explained in a way that kids can understand and the design is kid friendly using metaphors. \n+\n+3 Sequential subagents \n+\n+- Subagent 1: Create a WebSocket backend server that handles API request execution (GET/POST/PUT/DELETE with headers, body, auth) AND real-time collaboration features (multiple users, shared collections, live updates). \n+\n+- Subagent 2: Build a conflict resolution system for when multiple users edit the same API request simultaneously, plus response formatting and request history management. \n+- Subagent 3: Create the collaborative web UI using HTML, CSS, and vanilla JavaScript with API testing interface (URL input, method selection, headers, request body) that shows live user cursors, real-time updates, and shared results when anyone runs a test. \n+\n+3 other subagents should work in parallel developing a readme, api collections and, a simple test suite. \n+\n+- Subagent 4: Create a beginner friendly README\n+- Subagent 5: Create a spample api collection and examples with 2-3 read to try example requests. Use safe, fun public apis like dog facts and joke api\n+- Subagent 6: Create a simple test suite \n+\n+Final result should be a working web app where multiple people can test APIs together, see each other's requests and responses instantly, and collaborate without conflicts. Use HTML/CSS/JS for the frontend, no frameworks. \n+\n+Set the time out to 9 minutes\n+```\n+\n+Goose lets you run subagents in parallel or sequentially. I chose a hybrid approach. The first three tasks needed to happen in order, since each step relied on the previous one. But the last three could run in parallel, since they only needed the core app to exist before moving forward.\n+\n+I set the timeout to 9 minutes giving the subagents more time to work on accomplishing the tasks. The subagent working on conflict resolution failed to accomplish its task in 9 minutes, so after all the subagents completed their tasks, Goose used the main session to accomplish the failed tasks. \n+\n+## My Parallel Prompt Fail\n+\n+Once I had a working app, I wanted to refine the design and make the interface feel more cohesive. I wrote a follow up prompt asking Goose to spin up five subagents in parallel. Each one was in charge of a different UI component: the header, request builder, tab layout, and collaboration panel.\n+\n+It didn\u2019t go as planned. Each subagent brought its own interpretation of what \u201ckid-friendly\u201d meant. The result was a clashing mix of styles that felt disconnected and inconsistent.\n+\n+That confirmed a hunch I had. When tasks are interdependent, running subagents in parallel is not the right move. Those kinds of tasks are better handled sequentially.\n+\n+## A Better Prompt Strategy\n+\n+This time, I took a different approach. I asked Goose to analyze the existing UI and generate a shared design plan. Then I told Goose to use that plan to span new subagents and assign them tasks based on the plan.",
    "repo_full_name": "block/goose",
    "discussion_comments": [
      {
        "comment_id": "2217455673",
        "repo_full_name": "block/goose",
        "pr_number": 3528,
        "pr_file": "documentation/blog/2025-07-21-orchestrating-subagents/index.md",
        "discussion_id": "2217455673",
        "commented_code": "@@ -0,0 +1,128 @@\n+---\n+title: Orchestrating 6 Subagents to Build a Collaborative API Playground\n+description: Delegating backend, frontend, docs, and tests so six subagents could build collaborative API tool for kids\n+authors: \n+    - rizel\n+---\n+\n+![built by subagents](built-by-subagents.png)\n+\n+I built Postman meets Google Docs for 10-year-olds.\n+\n+*Cue record scratch.*\n+\n+*Cue freeze frame.*\n+\n+*Cue movie clich\u00e9.*\n+\n+You're probably wondering how I got here.\n+\n+\n+<!--truncate-->\n+\n+Before I explain, it\u2019s better if I just show you:\n+\n+\ud83d\udc49Try it yourself: https://api-playground-production.up.railway.app/ \n+\n+![api playground](api-playground.png)\n+\n+It\u2019s a collaborative API testing playground where kids can run sample requests, get playful error messages, and see live responses in real time. Everyone in the session sees the API response together, turning the experience of solo debugging into multiplayer coding. And I wanted it to look like a literal playground.\n+\n+I was inspired to build this after attending our company\u2019s Bring Your Kids to Work Day. I didn\u2019t bring my kid because she\u2019s still an infant, but I attended to support my teammate Adewale Abati, who led a virtual session introducing kids to Goose. They used it to build comics, games, and music apps that were fun, imaginative, and genuinely impressive.\n+\n+I decided to create a digital resource that teaches foundational concepts like APIs in a way that feels inviting instead of intimidating. Traditional API testing tools are powerful, but for a kid just starting out, they can be confusing and unclear.\n+\n+The wild part is that I let Goose and six subagents bring this idea to life.\n+\n+## Meet the Subagents\n+\n+[Subagents](https://block.github.io/goose/docs/experimental/subagents) are individual AI instances that take on specific tasks. Each one runs in its own session, which helps preserve the main context window and keeps your primary Goose conversation uncluttered and focused on high-level orchestration. I think of subagents as temporary teammates. For this project, I treated them like an on-demand dev squad. I had a Backend Developer to build the server, a Frontend Developer to handle the UI, a Doc Writer to create a beginner-friendly README, and a Test Engineer to put together a simple test suite.\n+\n+:::note  \n+Goose automatically cleans up subagents upon task completion.  \n+:::\n+\n+Typically, I am not a one-shot prompter. I prefer prompt chaining, which means breaking a complex task into smaller prompts and guiding the AI step by step. This method gives me more control over the output, especially when I am trying to build something complex.\n+\n+But this time, I wanted to delegate, walk away, and come back to progress, so I used subagents.\n+\n+Since the feature is still experimental, I had to enable it via an environment variable:\n+\n+```bash\n+export GOOSE_ALPHA_FEATURES=true  \n+```\n+\n+## A Gaggle of Geese\n+\n+There are a few ways to create subagents in Goose. You can use natural language prompts, define them through [recipes](https://block.github.io/goose/docs/guides/recipes/), or even spin up [external subagents](https://block.github.io/goose/docs/experimental/subagents/#external-subagents) like Codex or Claude Code.. \n+\n+I used natural language prompts because of the convenience to directly configure a subagent through one prompt. Here\u2019s the prompt I used:\n+\n+```\n+Build a real-time collaborative API testing platform using 3 AI subagents working sequentially - like \"Google Docs for Postman\" where teams can test APIs together, but for kids. Make it so errors and results are explained in a way that kids can understand and the design is kid friendly using metaphors. \n+\n+3 Sequential subagents \n+\n+- Subagent 1: Create a WebSocket backend server that handles API request execution (GET/POST/PUT/DELETE with headers, body, auth) AND real-time collaboration features (multiple users, shared collections, live updates). \n+\n+- Subagent 2: Build a conflict resolution system for when multiple users edit the same API request simultaneously, plus response formatting and request history management. \n+- Subagent 3: Create the collaborative web UI using HTML, CSS, and vanilla JavaScript with API testing interface (URL input, method selection, headers, request body) that shows live user cursors, real-time updates, and shared results when anyone runs a test. \n+\n+3 other subagents should work in parallel developing a readme, api collections and, a simple test suite. \n+\n+- Subagent 4: Create a beginner friendly README\n+- Subagent 5: Create a spample api collection and examples with 2-3 read to try example requests. Use safe, fun public apis like dog facts and joke api\n+- Subagent 6: Create a simple test suite \n+\n+Final result should be a working web app where multiple people can test APIs together, see each other's requests and responses instantly, and collaborate without conflicts. Use HTML/CSS/JS for the frontend, no frameworks. \n+\n+Set the time out to 9 minutes\n+```\n+\n+Goose lets you run subagents in parallel or sequentially. I chose a hybrid approach. The first three tasks needed to happen in order, since each step relied on the previous one. But the last three could run in parallel, since they only needed the core app to exist before moving forward.\n+\n+I set the timeout to 9 minutes giving the subagents more time to work on accomplishing the tasks. The subagent working on conflict resolution failed to accomplish its task in 9 minutes, so after all the subagents completed their tasks, Goose used the main session to accomplish the failed tasks. \n+\n+## My Parallel Prompt Fail\n+\n+Once I had a working app, I wanted to refine the design and make the interface feel more cohesive. I wrote a follow up prompt asking Goose to spin up five subagents in parallel. Each one was in charge of a different UI component: the header, request builder, tab layout, and collaboration panel.\n+\n+It didn\u2019t go as planned. Each subagent brought its own interpretation of what \u201ckid-friendly\u201d meant. The result was a clashing mix of styles that felt disconnected and inconsistent.\n+\n+That confirmed a hunch I had. When tasks are interdependent, running subagents in parallel is not the right move. Those kinds of tasks are better handled sequentially.\n+\n+## A Better Prompt Strategy\n+\n+This time, I took a different approach. I asked Goose to analyze the existing UI and generate a shared design plan. Then I told Goose to use that plan to span new subagents and assign them tasks based on the plan.",
        "comment_created_at": "2025-07-19T20:55:27+00:00",
        "comment_author": "blackgirlbytes",
        "comment_body": "```suggestion\r\nThis time, I took a different approach. I asked Goose to analyze the existing UI and generate a shared design plan. Then I told Goose to use that plan to spawn new subagents and assign them tasks based on the plan.\r\n```",
        "pr_file_module": null
      }
    ]
  }
]