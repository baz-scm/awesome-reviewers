[
  {
    "discussion_id": "2177424921",
    "pr_number": 107305,
    "pr_file": "pkg/storage/unified/resource/storage_backend.go",
    "created_at": "2025-07-01T12:04:50+00:00",
    "commented_code": "+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"math/rand/v2\"\n+\t\"net/http\"\n+\t\"sort\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/bwmarrin/snowflake\"\n+\t\"github.com/grafana/grafana/pkg/apimachinery/utils\"\n+\t\"github.com/grafana/grafana/pkg/storage/unified/resourcepb\"\n+\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n+)\n+\n+const (\n+\tdefaultListBufferSize = 100\n+)\n+\n+// Unified storage backend based on KV storage.\n+type kvStorageBackend struct {\n+\tsnowflake  *snowflake.Node\n+\tkv         KV\n+\tdataStore  *dataStore\n+\tmetaStore  *metadataStore\n+\teventStore *eventStore\n+\tnotifier   *notifier\n+\tbuilder    DocumentBuilder\n+}\n+\n+var _ StorageBackend = &kvStorageBackend{}\n+\n+func NewkvStorageBackend(kv KV) *kvStorageBackend {\n+\ts, err := snowflake.NewNode(rand.Int64N(1024))\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\teventStore := newEventStore(kv)\n+\treturn &kvStorageBackend{\n+\t\tkv:         kv,\n+\t\tdataStore:  newDataStore(kv),\n+\t\tmetaStore:  newMetadataStore(kv),\n+\t\teventStore: eventStore,\n+\t\tnotifier:   newNotifier(eventStore, notifierOptions{}),\n+\t\tsnowflake:  s,\n+\t\tbuilder:    StandardDocumentBuilder(), // For now we use the standard document builder.\n+\t}\n+}\n+\n+// WriteEvent writes a resource event (create/update/delete) to the storage backend.\n+func (k *kvStorageBackend) WriteEvent(ctx context.Context, event WriteEvent) (int64, error) {\n+\tif err := event.Validate(); err != nil {\n+\t\treturn 0, fmt.Errorf(\"invalid event: %w\", err)\n+\t}\n+\trv := k.snowflake.Generate().Int64()\n+\n+\t// Write data.\n+\tvar action DataAction\n+\tswitch event.Type {\n+\tcase resourcepb.WatchEvent_ADDED:\n+\t\taction = DataActionCreated\n+\t\t// Check if resource already exists for create operations\n+\t\t_, err := k.metaStore.GetLatestResourceKey(ctx, MetaGetRequestKey{\n+\t\t\tNamespace: event.Key.Namespace,\n+\t\t\tGroup:     event.Key.Group,\n+\t\t\tResource:  event.Key.Resource,\n+\t\t\tName:      event.Key.Name,\n+\t\t})\n+\t\tif err == nil {\n+\t\t\t// Resource exists, return already exists error\n+\t\t\treturn 0, ErrResourceAlreadyExists\n+\t\t}\n+\t\tif !errors.Is(err, ErrNotFound) {\n+\t\t\t// Some other error occurred\n+\t\t\treturn 0, fmt.Errorf(\"failed to check if resource exists: %w\", err)\n+\t\t}\n+\tcase resourcepb.WatchEvent_MODIFIED:\n+\t\taction = DataActionUpdated\n+\tcase resourcepb.WatchEvent_DELETED:\n+\t\taction = DataActionDeleted\n+\tdefault:\n+\t\treturn 0, fmt.Errorf(\"invalid event type: %d\", event.Type)\n+\t}\n+\n+\t// Build the search document\n+\tdoc, err := k.builder.BuildDocument(ctx, event.Key, rv, event.Value)\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to build document: %w\", err)\n+\t}\n+\n+\t// Write the data\n+\terr = k.dataStore.Save(ctx, DataKey{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t}, io.NopCloser(bytes.NewReader(event.Value)))\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write data: %w\", err)\n+\t}\n+\n+\t// Write metadata\n+\terr = k.metaStore.Save(ctx, MetaDataObj{\n+\t\tKey: MetaDataKey{\n+\t\t\tNamespace:       event.Key.Namespace,\n+\t\t\tGroup:           event.Key.Group,\n+\t\t\tResource:        event.Key.Resource,\n+\t\t\tName:            event.Key.Name,\n+\t\t\tResourceVersion: rv,\n+\t\t\tAction:          action,\n+\t\t\tFolder:          event.Object.GetFolder(),\n+\t\t},\n+\t\tValue: MetaData{\n+\t\t\tIndexableDocument: *doc,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write metadata: %w\", err)\n+\t}\n+\n+\t// Write event\n+\terr = k.eventStore.Save(ctx, Event{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t\tFolder:          event.Object.GetFolder(),\n+\t\tPreviousRV:      event.PreviousRV,\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to save event: %w\", err)\n+\t}\n+\treturn rv, nil\n+}\n+\n+func (k *kvStorageBackend) ReadResource(ctx context.Context, req *resourcepb.ReadRequest) *BackendReadResponse {\n+\tif req.Key == nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusBadRequest, Message: \"missing key\"}}\n+\t}\n+\tmeta, err := k.metaStore.GetResourceKeyAtRevision(ctx, MetaGetRequestKey{\n+\t\tNamespace: req.Key.Namespace,\n+\t\tGroup:     req.Key.Group,\n+\t\tResource:  req.Key.Resource,\n+\t\tName:      req.Key.Name,\n+\t}, req.ResourceVersion)\n+\tif errors.Is(err, ErrNotFound) {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusNotFound, Message: \"not found\"}}\n+\t} else if err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tdata, err := k.dataStore.Get(ctx, DataKey{\n+\t\tNamespace:       req.Key.Namespace,\n+\t\tGroup:           req.Key.Group,\n+\t\tResource:        req.Key.Resource,\n+\t\tName:            req.Key.Name,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tAction:          meta.Action,\n+\t})\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tvalue, err := io.ReadAll(data)",
    "repo_full_name": "grafana/grafana",
    "discussion_comments": [
      {
        "comment_id": "2177424921",
        "repo_full_name": "grafana/grafana",
        "pr_number": 107305,
        "pr_file": "pkg/storage/unified/resource/storage_backend.go",
        "discussion_id": "2177424921",
        "commented_code": "@@ -0,0 +1,777 @@\n+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"math/rand/v2\"\n+\t\"net/http\"\n+\t\"sort\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/bwmarrin/snowflake\"\n+\t\"github.com/grafana/grafana/pkg/apimachinery/utils\"\n+\t\"github.com/grafana/grafana/pkg/storage/unified/resourcepb\"\n+\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n+)\n+\n+const (\n+\tdefaultListBufferSize = 100\n+)\n+\n+// Unified storage backend based on KV storage.\n+type kvStorageBackend struct {\n+\tsnowflake  *snowflake.Node\n+\tkv         KV\n+\tdataStore  *dataStore\n+\tmetaStore  *metadataStore\n+\teventStore *eventStore\n+\tnotifier   *notifier\n+\tbuilder    DocumentBuilder\n+}\n+\n+var _ StorageBackend = &kvStorageBackend{}\n+\n+func NewkvStorageBackend(kv KV) *kvStorageBackend {\n+\ts, err := snowflake.NewNode(rand.Int64N(1024))\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\teventStore := newEventStore(kv)\n+\treturn &kvStorageBackend{\n+\t\tkv:         kv,\n+\t\tdataStore:  newDataStore(kv),\n+\t\tmetaStore:  newMetadataStore(kv),\n+\t\teventStore: eventStore,\n+\t\tnotifier:   newNotifier(eventStore, notifierOptions{}),\n+\t\tsnowflake:  s,\n+\t\tbuilder:    StandardDocumentBuilder(), // For now we use the standard document builder.\n+\t}\n+}\n+\n+// WriteEvent writes a resource event (create/update/delete) to the storage backend.\n+func (k *kvStorageBackend) WriteEvent(ctx context.Context, event WriteEvent) (int64, error) {\n+\tif err := event.Validate(); err != nil {\n+\t\treturn 0, fmt.Errorf(\"invalid event: %w\", err)\n+\t}\n+\trv := k.snowflake.Generate().Int64()\n+\n+\t// Write data.\n+\tvar action DataAction\n+\tswitch event.Type {\n+\tcase resourcepb.WatchEvent_ADDED:\n+\t\taction = DataActionCreated\n+\t\t// Check if resource already exists for create operations\n+\t\t_, err := k.metaStore.GetLatestResourceKey(ctx, MetaGetRequestKey{\n+\t\t\tNamespace: event.Key.Namespace,\n+\t\t\tGroup:     event.Key.Group,\n+\t\t\tResource:  event.Key.Resource,\n+\t\t\tName:      event.Key.Name,\n+\t\t})\n+\t\tif err == nil {\n+\t\t\t// Resource exists, return already exists error\n+\t\t\treturn 0, ErrResourceAlreadyExists\n+\t\t}\n+\t\tif !errors.Is(err, ErrNotFound) {\n+\t\t\t// Some other error occurred\n+\t\t\treturn 0, fmt.Errorf(\"failed to check if resource exists: %w\", err)\n+\t\t}\n+\tcase resourcepb.WatchEvent_MODIFIED:\n+\t\taction = DataActionUpdated\n+\tcase resourcepb.WatchEvent_DELETED:\n+\t\taction = DataActionDeleted\n+\tdefault:\n+\t\treturn 0, fmt.Errorf(\"invalid event type: %d\", event.Type)\n+\t}\n+\n+\t// Build the search document\n+\tdoc, err := k.builder.BuildDocument(ctx, event.Key, rv, event.Value)\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to build document: %w\", err)\n+\t}\n+\n+\t// Write the data\n+\terr = k.dataStore.Save(ctx, DataKey{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t}, io.NopCloser(bytes.NewReader(event.Value)))\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write data: %w\", err)\n+\t}\n+\n+\t// Write metadata\n+\terr = k.metaStore.Save(ctx, MetaDataObj{\n+\t\tKey: MetaDataKey{\n+\t\t\tNamespace:       event.Key.Namespace,\n+\t\t\tGroup:           event.Key.Group,\n+\t\t\tResource:        event.Key.Resource,\n+\t\t\tName:            event.Key.Name,\n+\t\t\tResourceVersion: rv,\n+\t\t\tAction:          action,\n+\t\t\tFolder:          event.Object.GetFolder(),\n+\t\t},\n+\t\tValue: MetaData{\n+\t\t\tIndexableDocument: *doc,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write metadata: %w\", err)\n+\t}\n+\n+\t// Write event\n+\terr = k.eventStore.Save(ctx, Event{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t\tFolder:          event.Object.GetFolder(),\n+\t\tPreviousRV:      event.PreviousRV,\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to save event: %w\", err)\n+\t}\n+\treturn rv, nil\n+}\n+\n+func (k *kvStorageBackend) ReadResource(ctx context.Context, req *resourcepb.ReadRequest) *BackendReadResponse {\n+\tif req.Key == nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusBadRequest, Message: \"missing key\"}}\n+\t}\n+\tmeta, err := k.metaStore.GetResourceKeyAtRevision(ctx, MetaGetRequestKey{\n+\t\tNamespace: req.Key.Namespace,\n+\t\tGroup:     req.Key.Group,\n+\t\tResource:  req.Key.Resource,\n+\t\tName:      req.Key.Name,\n+\t}, req.ResourceVersion)\n+\tif errors.Is(err, ErrNotFound) {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusNotFound, Message: \"not found\"}}\n+\t} else if err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tdata, err := k.dataStore.Get(ctx, DataKey{\n+\t\tNamespace:       req.Key.Namespace,\n+\t\tGroup:           req.Key.Group,\n+\t\tResource:        req.Key.Resource,\n+\t\tName:            req.Key.Name,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tAction:          meta.Action,\n+\t})\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tvalue, err := io.ReadAll(data)",
        "comment_created_at": "2025-07-01T12:04:50+00:00",
        "comment_author": "pstibrany",
        "comment_body": "We should also close `data` stream (always, if `data` is not `nil`), and check for `Close` errors (if there were no errors before).",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2177431749",
    "pr_number": 107305,
    "pr_file": "pkg/storage/unified/resource/storage_backend.go",
    "created_at": "2025-07-01T12:08:35+00:00",
    "commented_code": "+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"math/rand/v2\"\n+\t\"net/http\"\n+\t\"sort\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/bwmarrin/snowflake\"\n+\t\"github.com/grafana/grafana/pkg/apimachinery/utils\"\n+\t\"github.com/grafana/grafana/pkg/storage/unified/resourcepb\"\n+\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n+)\n+\n+const (\n+\tdefaultListBufferSize = 100\n+)\n+\n+// Unified storage backend based on KV storage.\n+type kvStorageBackend struct {\n+\tsnowflake  *snowflake.Node\n+\tkv         KV\n+\tdataStore  *dataStore\n+\tmetaStore  *metadataStore\n+\teventStore *eventStore\n+\tnotifier   *notifier\n+\tbuilder    DocumentBuilder\n+}\n+\n+var _ StorageBackend = &kvStorageBackend{}\n+\n+func NewkvStorageBackend(kv KV) *kvStorageBackend {\n+\ts, err := snowflake.NewNode(rand.Int64N(1024))\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\teventStore := newEventStore(kv)\n+\treturn &kvStorageBackend{\n+\t\tkv:         kv,\n+\t\tdataStore:  newDataStore(kv),\n+\t\tmetaStore:  newMetadataStore(kv),\n+\t\teventStore: eventStore,\n+\t\tnotifier:   newNotifier(eventStore, notifierOptions{}),\n+\t\tsnowflake:  s,\n+\t\tbuilder:    StandardDocumentBuilder(), // For now we use the standard document builder.\n+\t}\n+}\n+\n+// WriteEvent writes a resource event (create/update/delete) to the storage backend.\n+func (k *kvStorageBackend) WriteEvent(ctx context.Context, event WriteEvent) (int64, error) {\n+\tif err := event.Validate(); err != nil {\n+\t\treturn 0, fmt.Errorf(\"invalid event: %w\", err)\n+\t}\n+\trv := k.snowflake.Generate().Int64()\n+\n+\t// Write data.\n+\tvar action DataAction\n+\tswitch event.Type {\n+\tcase resourcepb.WatchEvent_ADDED:\n+\t\taction = DataActionCreated\n+\t\t// Check if resource already exists for create operations\n+\t\t_, err := k.metaStore.GetLatestResourceKey(ctx, MetaGetRequestKey{\n+\t\t\tNamespace: event.Key.Namespace,\n+\t\t\tGroup:     event.Key.Group,\n+\t\t\tResource:  event.Key.Resource,\n+\t\t\tName:      event.Key.Name,\n+\t\t})\n+\t\tif err == nil {\n+\t\t\t// Resource exists, return already exists error\n+\t\t\treturn 0, ErrResourceAlreadyExists\n+\t\t}\n+\t\tif !errors.Is(err, ErrNotFound) {\n+\t\t\t// Some other error occurred\n+\t\t\treturn 0, fmt.Errorf(\"failed to check if resource exists: %w\", err)\n+\t\t}\n+\tcase resourcepb.WatchEvent_MODIFIED:\n+\t\taction = DataActionUpdated\n+\tcase resourcepb.WatchEvent_DELETED:\n+\t\taction = DataActionDeleted\n+\tdefault:\n+\t\treturn 0, fmt.Errorf(\"invalid event type: %d\", event.Type)\n+\t}\n+\n+\t// Build the search document\n+\tdoc, err := k.builder.BuildDocument(ctx, event.Key, rv, event.Value)\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to build document: %w\", err)\n+\t}\n+\n+\t// Write the data\n+\terr = k.dataStore.Save(ctx, DataKey{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t}, io.NopCloser(bytes.NewReader(event.Value)))\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write data: %w\", err)\n+\t}\n+\n+\t// Write metadata\n+\terr = k.metaStore.Save(ctx, MetaDataObj{\n+\t\tKey: MetaDataKey{\n+\t\t\tNamespace:       event.Key.Namespace,\n+\t\t\tGroup:           event.Key.Group,\n+\t\t\tResource:        event.Key.Resource,\n+\t\t\tName:            event.Key.Name,\n+\t\t\tResourceVersion: rv,\n+\t\t\tAction:          action,\n+\t\t\tFolder:          event.Object.GetFolder(),\n+\t\t},\n+\t\tValue: MetaData{\n+\t\t\tIndexableDocument: *doc,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write metadata: %w\", err)\n+\t}\n+\n+\t// Write event\n+\terr = k.eventStore.Save(ctx, Event{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t\tFolder:          event.Object.GetFolder(),\n+\t\tPreviousRV:      event.PreviousRV,\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to save event: %w\", err)\n+\t}\n+\treturn rv, nil\n+}\n+\n+func (k *kvStorageBackend) ReadResource(ctx context.Context, req *resourcepb.ReadRequest) *BackendReadResponse {\n+\tif req.Key == nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusBadRequest, Message: \"missing key\"}}\n+\t}\n+\tmeta, err := k.metaStore.GetResourceKeyAtRevision(ctx, MetaGetRequestKey{\n+\t\tNamespace: req.Key.Namespace,\n+\t\tGroup:     req.Key.Group,\n+\t\tResource:  req.Key.Resource,\n+\t\tName:      req.Key.Name,\n+\t}, req.ResourceVersion)\n+\tif errors.Is(err, ErrNotFound) {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusNotFound, Message: \"not found\"}}\n+\t} else if err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tdata, err := k.dataStore.Get(ctx, DataKey{\n+\t\tNamespace:       req.Key.Namespace,\n+\t\tGroup:           req.Key.Group,\n+\t\tResource:        req.Key.Resource,\n+\t\tName:            req.Key.Name,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tAction:          meta.Action,\n+\t})\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tvalue, err := io.ReadAll(data)\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\treturn &BackendReadResponse{\n+\t\tKey:             req.Key,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tValue:           value,\n+\t\tFolder:          meta.Folder,\n+\t}\n+}\n+\n+// // ListIterator returns an iterator for listing resources.\n+func (k *kvStorageBackend) ListIterator(ctx context.Context, req *resourcepb.ListRequest, cb func(ListIterator) error) (int64, error) {\n+\tif req.Options == nil || req.Options.Key == nil {\n+\t\treturn 0, fmt.Errorf(\"missing options or key in ListRequest\")\n+\t}\n+\t// Parse continue token if provided\n+\toffset := int64(0)\n+\tresourceVersion := req.ResourceVersion\n+\tif req.NextPageToken != \"\" {\n+\t\ttoken, err := GetContinueToken(req.NextPageToken)\n+\t\tif err != nil {\n+\t\t\treturn 0, fmt.Errorf(\"invalid continue token: %w\", err)\n+\t\t}\n+\t\toffset = token.StartOffset\n+\t\tresourceVersion = token.ResourceVersion\n+\t}\n+\n+\t// We set the listRV to the current time.\n+\tlistRV := k.snowflake.Generate().Int64()\n+\tif resourceVersion > 0 {\n+\t\tlistRV = resourceVersion\n+\t}\n+\n+\t// Fetch the latest objects\n+\tkeys := make([]MetaDataKey, 0, min(defaultListBufferSize, req.Limit+1))\n+\tidx := 0\n+\tfor metaKey, err := range k.metaStore.ListResourceKeysAtRevision(ctx, MetaListRequestKey{\n+\t\tNamespace: req.Options.Key.Namespace,\n+\t\tGroup:     req.Options.Key.Group,\n+\t\tResource:  req.Options.Key.Resource,\n+\t\tName:      req.Options.Key.Name,\n+\t}, resourceVersion) {\n+\t\tif err != nil {\n+\t\t\treturn 0, err\n+\t\t}\n+\t\t// Skip the first offset items. This is not efficient, but it's a simple way to implement it for now.\n+\t\tif idx < int(offset) {\n+\t\t\tidx++\n+\t\t\tcontinue\n+\t\t}\n+\t\tkeys = append(keys, metaKey)\n+\t\t// Only fetch the first limit items + 1 to get the next token.\n+\t\tif len(keys) >= int(req.Limit+1) {\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\titer := kvListIterator{\n+\t\tkeys:         keys,\n+\t\tcurrentIndex: -1,\n+\t\tctx:          ctx,\n+\t\tlistRV:       listRV,\n+\t\toffset:       offset,\n+\t\tdataStore:    k.dataStore,\n+\t}\n+\terr := cb(&iter)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\treturn listRV, nil\n+}\n+\n+// kvListIterator implements ListIterator for KV storage\n+type kvListIterator struct {\n+\tctx          context.Context\n+\tkeys         []MetaDataKey\n+\tcurrentIndex int\n+\tdataStore    *dataStore\n+\tlistRV       int64\n+\toffset       int64\n+\n+\t// current\n+\trv    int64\n+\terr   error\n+\tvalue []byte\n+}\n+\n+func (i *kvListIterator) Next() bool {\n+\ti.currentIndex++\n+\n+\tif i.currentIndex >= len(i.keys) {\n+\t\treturn false\n+\t}\n+\n+\ti.rv, i.err = i.keys[i.currentIndex].ResourceVersion, nil\n+\n+\tdata, err := i.dataStore.Get(i.ctx, DataKey{\n+\t\tNamespace:       i.keys[i.currentIndex].Namespace,\n+\t\tGroup:           i.keys[i.currentIndex].Group,\n+\t\tResource:        i.keys[i.currentIndex].Resource,\n+\t\tName:            i.keys[i.currentIndex].Name,\n+\t\tResourceVersion: i.keys[i.currentIndex].ResourceVersion,\n+\t\tAction:          i.keys[i.currentIndex].Action,\n+\t})\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\n+\ti.value, i.err = io.ReadAll(data)",
    "repo_full_name": "grafana/grafana",
    "discussion_comments": [
      {
        "comment_id": "2177431749",
        "repo_full_name": "grafana/grafana",
        "pr_number": 107305,
        "pr_file": "pkg/storage/unified/resource/storage_backend.go",
        "discussion_id": "2177431749",
        "commented_code": "@@ -0,0 +1,777 @@\n+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"math/rand/v2\"\n+\t\"net/http\"\n+\t\"sort\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/bwmarrin/snowflake\"\n+\t\"github.com/grafana/grafana/pkg/apimachinery/utils\"\n+\t\"github.com/grafana/grafana/pkg/storage/unified/resourcepb\"\n+\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n+)\n+\n+const (\n+\tdefaultListBufferSize = 100\n+)\n+\n+// Unified storage backend based on KV storage.\n+type kvStorageBackend struct {\n+\tsnowflake  *snowflake.Node\n+\tkv         KV\n+\tdataStore  *dataStore\n+\tmetaStore  *metadataStore\n+\teventStore *eventStore\n+\tnotifier   *notifier\n+\tbuilder    DocumentBuilder\n+}\n+\n+var _ StorageBackend = &kvStorageBackend{}\n+\n+func NewkvStorageBackend(kv KV) *kvStorageBackend {\n+\ts, err := snowflake.NewNode(rand.Int64N(1024))\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\teventStore := newEventStore(kv)\n+\treturn &kvStorageBackend{\n+\t\tkv:         kv,\n+\t\tdataStore:  newDataStore(kv),\n+\t\tmetaStore:  newMetadataStore(kv),\n+\t\teventStore: eventStore,\n+\t\tnotifier:   newNotifier(eventStore, notifierOptions{}),\n+\t\tsnowflake:  s,\n+\t\tbuilder:    StandardDocumentBuilder(), // For now we use the standard document builder.\n+\t}\n+}\n+\n+// WriteEvent writes a resource event (create/update/delete) to the storage backend.\n+func (k *kvStorageBackend) WriteEvent(ctx context.Context, event WriteEvent) (int64, error) {\n+\tif err := event.Validate(); err != nil {\n+\t\treturn 0, fmt.Errorf(\"invalid event: %w\", err)\n+\t}\n+\trv := k.snowflake.Generate().Int64()\n+\n+\t// Write data.\n+\tvar action DataAction\n+\tswitch event.Type {\n+\tcase resourcepb.WatchEvent_ADDED:\n+\t\taction = DataActionCreated\n+\t\t// Check if resource already exists for create operations\n+\t\t_, err := k.metaStore.GetLatestResourceKey(ctx, MetaGetRequestKey{\n+\t\t\tNamespace: event.Key.Namespace,\n+\t\t\tGroup:     event.Key.Group,\n+\t\t\tResource:  event.Key.Resource,\n+\t\t\tName:      event.Key.Name,\n+\t\t})\n+\t\tif err == nil {\n+\t\t\t// Resource exists, return already exists error\n+\t\t\treturn 0, ErrResourceAlreadyExists\n+\t\t}\n+\t\tif !errors.Is(err, ErrNotFound) {\n+\t\t\t// Some other error occurred\n+\t\t\treturn 0, fmt.Errorf(\"failed to check if resource exists: %w\", err)\n+\t\t}\n+\tcase resourcepb.WatchEvent_MODIFIED:\n+\t\taction = DataActionUpdated\n+\tcase resourcepb.WatchEvent_DELETED:\n+\t\taction = DataActionDeleted\n+\tdefault:\n+\t\treturn 0, fmt.Errorf(\"invalid event type: %d\", event.Type)\n+\t}\n+\n+\t// Build the search document\n+\tdoc, err := k.builder.BuildDocument(ctx, event.Key, rv, event.Value)\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to build document: %w\", err)\n+\t}\n+\n+\t// Write the data\n+\terr = k.dataStore.Save(ctx, DataKey{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t}, io.NopCloser(bytes.NewReader(event.Value)))\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write data: %w\", err)\n+\t}\n+\n+\t// Write metadata\n+\terr = k.metaStore.Save(ctx, MetaDataObj{\n+\t\tKey: MetaDataKey{\n+\t\t\tNamespace:       event.Key.Namespace,\n+\t\t\tGroup:           event.Key.Group,\n+\t\t\tResource:        event.Key.Resource,\n+\t\t\tName:            event.Key.Name,\n+\t\t\tResourceVersion: rv,\n+\t\t\tAction:          action,\n+\t\t\tFolder:          event.Object.GetFolder(),\n+\t\t},\n+\t\tValue: MetaData{\n+\t\t\tIndexableDocument: *doc,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write metadata: %w\", err)\n+\t}\n+\n+\t// Write event\n+\terr = k.eventStore.Save(ctx, Event{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t\tFolder:          event.Object.GetFolder(),\n+\t\tPreviousRV:      event.PreviousRV,\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to save event: %w\", err)\n+\t}\n+\treturn rv, nil\n+}\n+\n+func (k *kvStorageBackend) ReadResource(ctx context.Context, req *resourcepb.ReadRequest) *BackendReadResponse {\n+\tif req.Key == nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusBadRequest, Message: \"missing key\"}}\n+\t}\n+\tmeta, err := k.metaStore.GetResourceKeyAtRevision(ctx, MetaGetRequestKey{\n+\t\tNamespace: req.Key.Namespace,\n+\t\tGroup:     req.Key.Group,\n+\t\tResource:  req.Key.Resource,\n+\t\tName:      req.Key.Name,\n+\t}, req.ResourceVersion)\n+\tif errors.Is(err, ErrNotFound) {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusNotFound, Message: \"not found\"}}\n+\t} else if err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tdata, err := k.dataStore.Get(ctx, DataKey{\n+\t\tNamespace:       req.Key.Namespace,\n+\t\tGroup:           req.Key.Group,\n+\t\tResource:        req.Key.Resource,\n+\t\tName:            req.Key.Name,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tAction:          meta.Action,\n+\t})\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tvalue, err := io.ReadAll(data)\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\treturn &BackendReadResponse{\n+\t\tKey:             req.Key,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tValue:           value,\n+\t\tFolder:          meta.Folder,\n+\t}\n+}\n+\n+// // ListIterator returns an iterator for listing resources.\n+func (k *kvStorageBackend) ListIterator(ctx context.Context, req *resourcepb.ListRequest, cb func(ListIterator) error) (int64, error) {\n+\tif req.Options == nil || req.Options.Key == nil {\n+\t\treturn 0, fmt.Errorf(\"missing options or key in ListRequest\")\n+\t}\n+\t// Parse continue token if provided\n+\toffset := int64(0)\n+\tresourceVersion := req.ResourceVersion\n+\tif req.NextPageToken != \"\" {\n+\t\ttoken, err := GetContinueToken(req.NextPageToken)\n+\t\tif err != nil {\n+\t\t\treturn 0, fmt.Errorf(\"invalid continue token: %w\", err)\n+\t\t}\n+\t\toffset = token.StartOffset\n+\t\tresourceVersion = token.ResourceVersion\n+\t}\n+\n+\t// We set the listRV to the current time.\n+\tlistRV := k.snowflake.Generate().Int64()\n+\tif resourceVersion > 0 {\n+\t\tlistRV = resourceVersion\n+\t}\n+\n+\t// Fetch the latest objects\n+\tkeys := make([]MetaDataKey, 0, min(defaultListBufferSize, req.Limit+1))\n+\tidx := 0\n+\tfor metaKey, err := range k.metaStore.ListResourceKeysAtRevision(ctx, MetaListRequestKey{\n+\t\tNamespace: req.Options.Key.Namespace,\n+\t\tGroup:     req.Options.Key.Group,\n+\t\tResource:  req.Options.Key.Resource,\n+\t\tName:      req.Options.Key.Name,\n+\t}, resourceVersion) {\n+\t\tif err != nil {\n+\t\t\treturn 0, err\n+\t\t}\n+\t\t// Skip the first offset items. This is not efficient, but it's a simple way to implement it for now.\n+\t\tif idx < int(offset) {\n+\t\t\tidx++\n+\t\t\tcontinue\n+\t\t}\n+\t\tkeys = append(keys, metaKey)\n+\t\t// Only fetch the first limit items + 1 to get the next token.\n+\t\tif len(keys) >= int(req.Limit+1) {\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\titer := kvListIterator{\n+\t\tkeys:         keys,\n+\t\tcurrentIndex: -1,\n+\t\tctx:          ctx,\n+\t\tlistRV:       listRV,\n+\t\toffset:       offset,\n+\t\tdataStore:    k.dataStore,\n+\t}\n+\terr := cb(&iter)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\treturn listRV, nil\n+}\n+\n+// kvListIterator implements ListIterator for KV storage\n+type kvListIterator struct {\n+\tctx          context.Context\n+\tkeys         []MetaDataKey\n+\tcurrentIndex int\n+\tdataStore    *dataStore\n+\tlistRV       int64\n+\toffset       int64\n+\n+\t// current\n+\trv    int64\n+\terr   error\n+\tvalue []byte\n+}\n+\n+func (i *kvListIterator) Next() bool {\n+\ti.currentIndex++\n+\n+\tif i.currentIndex >= len(i.keys) {\n+\t\treturn false\n+\t}\n+\n+\ti.rv, i.err = i.keys[i.currentIndex].ResourceVersion, nil\n+\n+\tdata, err := i.dataStore.Get(i.ctx, DataKey{\n+\t\tNamespace:       i.keys[i.currentIndex].Namespace,\n+\t\tGroup:           i.keys[i.currentIndex].Group,\n+\t\tResource:        i.keys[i.currentIndex].Resource,\n+\t\tName:            i.keys[i.currentIndex].Name,\n+\t\tResourceVersion: i.keys[i.currentIndex].ResourceVersion,\n+\t\tAction:          i.keys[i.currentIndex].Action,\n+\t})\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\n+\ti.value, i.err = io.ReadAll(data)",
        "comment_created_at": "2025-07-01T12:08:35+00:00",
        "comment_author": "pstibrany",
        "comment_body": "Same comment about always closing `data` and checking for `Close` errors. Perhaps a helper function like this would work:\n\n```go\nfunc readAndClose(r io.ReadCloser) ([]byte, error) {\n\tdata, err := io.ReadAll(r)\n\treturn data, errors.Join(err, r.Close())\n}\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2177522201",
    "pr_number": 107305,
    "pr_file": "pkg/storage/unified/resource/storage_backend.go",
    "created_at": "2025-07-01T12:48:05+00:00",
    "commented_code": "+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"math/rand/v2\"\n+\t\"net/http\"\n+\t\"sort\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/bwmarrin/snowflake\"\n+\t\"github.com/grafana/grafana/pkg/apimachinery/utils\"\n+\t\"github.com/grafana/grafana/pkg/storage/unified/resourcepb\"\n+\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n+)\n+\n+const (\n+\tdefaultListBufferSize = 100\n+)\n+\n+// Unified storage backend based on KV storage.\n+type kvStorageBackend struct {\n+\tsnowflake  *snowflake.Node\n+\tkv         KV\n+\tdataStore  *dataStore\n+\tmetaStore  *metadataStore\n+\teventStore *eventStore\n+\tnotifier   *notifier\n+\tbuilder    DocumentBuilder\n+}\n+\n+var _ StorageBackend = &kvStorageBackend{}\n+\n+func NewkvStorageBackend(kv KV) *kvStorageBackend {\n+\ts, err := snowflake.NewNode(rand.Int64N(1024))\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\teventStore := newEventStore(kv)\n+\treturn &kvStorageBackend{\n+\t\tkv:         kv,\n+\t\tdataStore:  newDataStore(kv),\n+\t\tmetaStore:  newMetadataStore(kv),\n+\t\teventStore: eventStore,\n+\t\tnotifier:   newNotifier(eventStore, notifierOptions{}),\n+\t\tsnowflake:  s,\n+\t\tbuilder:    StandardDocumentBuilder(), // For now we use the standard document builder.\n+\t}\n+}\n+\n+// WriteEvent writes a resource event (create/update/delete) to the storage backend.\n+func (k *kvStorageBackend) WriteEvent(ctx context.Context, event WriteEvent) (int64, error) {\n+\tif err := event.Validate(); err != nil {\n+\t\treturn 0, fmt.Errorf(\"invalid event: %w\", err)\n+\t}\n+\trv := k.snowflake.Generate().Int64()\n+\n+\t// Write data.\n+\tvar action DataAction\n+\tswitch event.Type {\n+\tcase resourcepb.WatchEvent_ADDED:\n+\t\taction = DataActionCreated\n+\t\t// Check if resource already exists for create operations\n+\t\t_, err := k.metaStore.GetLatestResourceKey(ctx, MetaGetRequestKey{\n+\t\t\tNamespace: event.Key.Namespace,\n+\t\t\tGroup:     event.Key.Group,\n+\t\t\tResource:  event.Key.Resource,\n+\t\t\tName:      event.Key.Name,\n+\t\t})\n+\t\tif err == nil {\n+\t\t\t// Resource exists, return already exists error\n+\t\t\treturn 0, ErrResourceAlreadyExists\n+\t\t}\n+\t\tif !errors.Is(err, ErrNotFound) {\n+\t\t\t// Some other error occurred\n+\t\t\treturn 0, fmt.Errorf(\"failed to check if resource exists: %w\", err)\n+\t\t}\n+\tcase resourcepb.WatchEvent_MODIFIED:\n+\t\taction = DataActionUpdated\n+\tcase resourcepb.WatchEvent_DELETED:\n+\t\taction = DataActionDeleted\n+\tdefault:\n+\t\treturn 0, fmt.Errorf(\"invalid event type: %d\", event.Type)\n+\t}\n+\n+\t// Build the search document\n+\tdoc, err := k.builder.BuildDocument(ctx, event.Key, rv, event.Value)\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to build document: %w\", err)\n+\t}\n+\n+\t// Write the data\n+\terr = k.dataStore.Save(ctx, DataKey{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t}, io.NopCloser(bytes.NewReader(event.Value)))\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write data: %w\", err)\n+\t}\n+\n+\t// Write metadata\n+\terr = k.metaStore.Save(ctx, MetaDataObj{\n+\t\tKey: MetaDataKey{\n+\t\t\tNamespace:       event.Key.Namespace,\n+\t\t\tGroup:           event.Key.Group,\n+\t\t\tResource:        event.Key.Resource,\n+\t\t\tName:            event.Key.Name,\n+\t\t\tResourceVersion: rv,\n+\t\t\tAction:          action,\n+\t\t\tFolder:          event.Object.GetFolder(),\n+\t\t},\n+\t\tValue: MetaData{\n+\t\t\tIndexableDocument: *doc,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write metadata: %w\", err)\n+\t}\n+\n+\t// Write event\n+\terr = k.eventStore.Save(ctx, Event{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t\tFolder:          event.Object.GetFolder(),\n+\t\tPreviousRV:      event.PreviousRV,\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to save event: %w\", err)\n+\t}\n+\treturn rv, nil\n+}\n+\n+func (k *kvStorageBackend) ReadResource(ctx context.Context, req *resourcepb.ReadRequest) *BackendReadResponse {\n+\tif req.Key == nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusBadRequest, Message: \"missing key\"}}\n+\t}\n+\tmeta, err := k.metaStore.GetResourceKeyAtRevision(ctx, MetaGetRequestKey{\n+\t\tNamespace: req.Key.Namespace,\n+\t\tGroup:     req.Key.Group,\n+\t\tResource:  req.Key.Resource,\n+\t\tName:      req.Key.Name,\n+\t}, req.ResourceVersion)\n+\tif errors.Is(err, ErrNotFound) {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusNotFound, Message: \"not found\"}}\n+\t} else if err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tdata, err := k.dataStore.Get(ctx, DataKey{\n+\t\tNamespace:       req.Key.Namespace,\n+\t\tGroup:           req.Key.Group,\n+\t\tResource:        req.Key.Resource,\n+\t\tName:            req.Key.Name,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tAction:          meta.Action,\n+\t})\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tvalue, err := io.ReadAll(data)\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\treturn &BackendReadResponse{\n+\t\tKey:             req.Key,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tValue:           value,\n+\t\tFolder:          meta.Folder,\n+\t}\n+}\n+\n+// // ListIterator returns an iterator for listing resources.\n+func (k *kvStorageBackend) ListIterator(ctx context.Context, req *resourcepb.ListRequest, cb func(ListIterator) error) (int64, error) {\n+\tif req.Options == nil || req.Options.Key == nil {\n+\t\treturn 0, fmt.Errorf(\"missing options or key in ListRequest\")\n+\t}\n+\t// Parse continue token if provided\n+\toffset := int64(0)\n+\tresourceVersion := req.ResourceVersion\n+\tif req.NextPageToken != \"\" {\n+\t\ttoken, err := GetContinueToken(req.NextPageToken)\n+\t\tif err != nil {\n+\t\t\treturn 0, fmt.Errorf(\"invalid continue token: %w\", err)\n+\t\t}\n+\t\toffset = token.StartOffset\n+\t\tresourceVersion = token.ResourceVersion\n+\t}\n+\n+\t// We set the listRV to the current time.\n+\tlistRV := k.snowflake.Generate().Int64()\n+\tif resourceVersion > 0 {\n+\t\tlistRV = resourceVersion\n+\t}\n+\n+\t// Fetch the latest objects\n+\tkeys := make([]MetaDataKey, 0, min(defaultListBufferSize, req.Limit+1))\n+\tidx := 0\n+\tfor metaKey, err := range k.metaStore.ListResourceKeysAtRevision(ctx, MetaListRequestKey{\n+\t\tNamespace: req.Options.Key.Namespace,\n+\t\tGroup:     req.Options.Key.Group,\n+\t\tResource:  req.Options.Key.Resource,\n+\t\tName:      req.Options.Key.Name,\n+\t}, resourceVersion) {\n+\t\tif err != nil {\n+\t\t\treturn 0, err\n+\t\t}\n+\t\t// Skip the first offset items. This is not efficient, but it's a simple way to implement it for now.\n+\t\tif idx < int(offset) {\n+\t\t\tidx++\n+\t\t\tcontinue\n+\t\t}\n+\t\tkeys = append(keys, metaKey)\n+\t\t// Only fetch the first limit items + 1 to get the next token.\n+\t\tif len(keys) >= int(req.Limit+1) {\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\titer := kvListIterator{\n+\t\tkeys:         keys,\n+\t\tcurrentIndex: -1,\n+\t\tctx:          ctx,\n+\t\tlistRV:       listRV,\n+\t\toffset:       offset,\n+\t\tdataStore:    k.dataStore,\n+\t}\n+\terr := cb(&iter)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\treturn listRV, nil\n+}\n+\n+// kvListIterator implements ListIterator for KV storage\n+type kvListIterator struct {\n+\tctx          context.Context\n+\tkeys         []MetaDataKey\n+\tcurrentIndex int\n+\tdataStore    *dataStore\n+\tlistRV       int64\n+\toffset       int64\n+\n+\t// current\n+\trv    int64\n+\terr   error\n+\tvalue []byte\n+}\n+\n+func (i *kvListIterator) Next() bool {\n+\ti.currentIndex++\n+\n+\tif i.currentIndex >= len(i.keys) {\n+\t\treturn false\n+\t}\n+\n+\ti.rv, i.err = i.keys[i.currentIndex].ResourceVersion, nil\n+\n+\tdata, err := i.dataStore.Get(i.ctx, DataKey{\n+\t\tNamespace:       i.keys[i.currentIndex].Namespace,\n+\t\tGroup:           i.keys[i.currentIndex].Group,\n+\t\tResource:        i.keys[i.currentIndex].Resource,\n+\t\tName:            i.keys[i.currentIndex].Name,\n+\t\tResourceVersion: i.keys[i.currentIndex].ResourceVersion,\n+\t\tAction:          i.keys[i.currentIndex].Action,\n+\t})\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\n+\ti.value, i.err = io.ReadAll(data)\n+\tif i.err != nil {\n+\t\treturn false\n+\t}\n+\n+\t// increment the offset\n+\ti.offset++\n+\n+\treturn true\n+}\n+\n+func (i *kvListIterator) Error() error {\n+\treturn nil\n+}\n+\n+func (i *kvListIterator) ContinueToken() string {\n+\treturn ContinueToken{\n+\t\tStartOffset:     i.offset,\n+\t\tResourceVersion: i.listRV,\n+\t}.String()\n+}\n+\n+func (i *kvListIterator) ResourceVersion() int64 {\n+\treturn i.rv\n+}\n+\n+func (i *kvListIterator) Namespace() string {\n+\treturn i.keys[i.currentIndex].Namespace\n+}\n+\n+func (i *kvListIterator) Name() string {\n+\treturn i.keys[i.currentIndex].Name\n+}\n+\n+func (i *kvListIterator) Folder() string {\n+\treturn i.keys[i.currentIndex].Folder\n+}\n+\n+func (i *kvListIterator) Value() []byte {\n+\treturn i.value\n+}\n+\n+func validateListHistoryRequest(req *resourcepb.ListRequest) error {\n+\tif req.Options == nil || req.Options.Key == nil {\n+\t\treturn fmt.Errorf(\"missing options or key in ListRequest\")\n+\t}\n+\tkey := req.Options.Key\n+\tif key.Group == \"\" {\n+\t\treturn fmt.Errorf(\"group is required\")\n+\t}\n+\tif key.Resource == \"\" {\n+\t\treturn fmt.Errorf(\"resource is required\")\n+\t}\n+\tif key.Namespace == \"\" {\n+\t\treturn fmt.Errorf(\"namespace is required\")\n+\t}\n+\tif key.Name == \"\" {\n+\t\treturn fmt.Errorf(\"name is required\")\n+\t}\n+\treturn nil\n+}\n+\n+// filterHistoryKeysByVersion filters history keys based on version match criteria\n+func filterHistoryKeysByVersion(historyKeys []DataKey, req *resourcepb.ListRequest) ([]DataKey, error) {\n+\tswitch req.GetVersionMatchV2() {\n+\tcase resourcepb.ResourceVersionMatchV2_Exact:\n+\t\tif req.ResourceVersion <= 0 {\n+\t\t\treturn nil, fmt.Errorf(\"expecting an explicit resource version query when using Exact matching\")\n+\t\t}\n+\t\tvar exactKeys []DataKey\n+\t\tfor _, key := range historyKeys {\n+\t\t\tif key.ResourceVersion == req.ResourceVersion {\n+\t\t\t\texactKeys = append(exactKeys, key)\n+\t\t\t}\n+\t\t}\n+\t\treturn exactKeys, nil\n+\tcase resourcepb.ResourceVersionMatchV2_NotOlderThan:\n+\t\tif req.ResourceVersion > 0 {\n+\t\t\tvar filteredKeys []DataKey\n+\t\t\tfor _, key := range historyKeys {\n+\t\t\t\tif key.ResourceVersion >= req.ResourceVersion {\n+\t\t\t\t\tfilteredKeys = append(filteredKeys, key)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn filteredKeys, nil\n+\t\t}\n+\tdefault:\n+\t\tif req.ResourceVersion > 0 {\n+\t\t\tvar filteredKeys []DataKey\n+\t\t\tfor _, key := range historyKeys {\n+\t\t\t\tif key.ResourceVersion <= req.ResourceVersion {\n+\t\t\t\t\tfilteredKeys = append(filteredKeys, key)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn filteredKeys, nil\n+\t\t}\n+\t}\n+\treturn historyKeys, nil\n+}\n+\n+// applyLiveHistoryFilter applies \"live\" history logic by ignoring events before the last delete\n+func applyLiveHistoryFilter(filteredKeys []DataKey, req *resourcepb.ListRequest) []DataKey {\n+\tuseLatestDeletionAsMinRV := req.ResourceVersion == 0 && req.Source != resourcepb.ListRequest_TRASH && req.GetVersionMatchV2() != resourcepb.ResourceVersionMatchV2_Exact\n+\tif !useLatestDeletionAsMinRV {\n+\t\treturn filteredKeys\n+\t}\n+\n+\tlatestDeleteRV := int64(0)\n+\tfor _, key := range filteredKeys {\n+\t\tif key.Action == DataActionDeleted && key.ResourceVersion > latestDeleteRV {\n+\t\t\tlatestDeleteRV = key.ResourceVersion\n+\t\t}\n+\t}\n+\tif latestDeleteRV > 0 {\n+\t\tvar liveKeys []DataKey\n+\t\tfor _, key := range filteredKeys {\n+\t\t\tif key.ResourceVersion > latestDeleteRV {\n+\t\t\t\tliveKeys = append(liveKeys, key)\n+\t\t\t}\n+\t\t}\n+\t\treturn liveKeys\n+\t}\n+\treturn filteredKeys\n+}\n+\n+// sortHistoryKeys sorts the history keys based on the sortAscending flag\n+func sortHistoryKeys(filteredKeys []DataKey, sortAscending bool) {\n+\tif sortAscending {\n+\t\tsort.Slice(filteredKeys, func(i, j int) bool {\n+\t\t\treturn filteredKeys[i].ResourceVersion < filteredKeys[j].ResourceVersion\n+\t\t})\n+\t} else {\n+\t\tsort.Slice(filteredKeys, func(i, j int) bool {\n+\t\t\treturn filteredKeys[i].ResourceVersion > filteredKeys[j].ResourceVersion\n+\t\t})\n+\t}\n+}\n+\n+// applyPagination filters keys based on pagination parameters\n+func applyPagination(keys []DataKey, lastSeenRV int64, sortAscending bool) []DataKey {\n+\tif lastSeenRV == 0 {\n+\t\treturn keys\n+\t}\n+\n+\tvar pagedKeys []DataKey\n+\tfor _, key := range keys {\n+\t\tif sortAscending && key.ResourceVersion > lastSeenRV {\n+\t\t\tpagedKeys = append(pagedKeys, key)\n+\t\t} else if !sortAscending && key.ResourceVersion < lastSeenRV {\n+\t\t\tpagedKeys = append(pagedKeys, key)\n+\t\t}\n+\t}\n+\treturn pagedKeys\n+}\n+\n+// ListHistory is like ListIterator, but it returns the history of a resource.\n+func (k *kvStorageBackend) ListHistory(ctx context.Context, req *resourcepb.ListRequest, fn func(ListIterator) error) (int64, error) {\n+\tif err := validateListHistoryRequest(req); err != nil {\n+\t\treturn 0, err\n+\t}\n+\tkey := req.Options.Key\n+\t// Parse continue token if provided\n+\tlastSeenRV := int64(0)\n+\tsortAscending := req.GetVersionMatchV2() == resourcepb.ResourceVersionMatchV2_NotOlderThan\n+\tif req.NextPageToken != \"\" {\n+\t\ttoken, err := GetContinueToken(req.NextPageToken)\n+\t\tif err != nil {\n+\t\t\treturn 0, fmt.Errorf(\"invalid continue token: %w\", err)\n+\t\t}\n+\t\tlastSeenRV = token.ResourceVersion\n+\t\tsortAscending = token.SortAscending\n+\t}\n+\n+\t// Generate a new resource version for the list\n+\tlistRV := k.snowflake.Generate().Int64()\n+\n+\t// Get all history entries by iterating through datastore keys\n+\thistoryKeys := make([]DataKey, 0, min(defaultListBufferSize, req.Limit+1))\n+\n+\t// Use datastore.Keys to get all data keys for this specific resource\n+\tfor dataKey, err := range k.dataStore.Keys(ctx, ListRequestKey{\n+\t\tNamespace: key.Namespace,\n+\t\tGroup:     key.Group,\n+\t\tResource:  key.Resource,\n+\t\tName:      key.Name,\n+\t}) {\n+\t\tif err != nil {\n+\t\t\treturn 0, err\n+\t\t}\n+\t\thistoryKeys = append(historyKeys, dataKey)\n+\t}\n+\n+\t// Check if context has been cancelled\n+\tif ctx.Err() != nil {\n+\t\treturn 0, ctx.Err()\n+\t}\n+\n+\t// Handle trash differently from regular history\n+\tif req.Source == resourcepb.ListRequest_TRASH {\n+\t\treturn k.processTrashEntries(ctx, req, fn, historyKeys, lastSeenRV, sortAscending, listRV)\n+\t}\n+\n+\t// Apply filtering based on version match\n+\tfilteredKeys, filterErr := filterHistoryKeysByVersion(historyKeys, req)\n+\tif filterErr != nil {\n+\t\treturn 0, filterErr\n+\t}\n+\n+\t// Apply \"live\" history logic: ignore events before the last delete\n+\tfilteredKeys = applyLiveHistoryFilter(filteredKeys, req)\n+\n+\t// Sort the entries if not already sorted correctly\n+\tsortHistoryKeys(filteredKeys, sortAscending)\n+\n+\t// Pagination: filter out items up to and including lastSeenRV\n+\tpagedKeys := applyPagination(filteredKeys, lastSeenRV, sortAscending)\n+\n+\titer := kvHistoryIterator{\n+\t\tkeys:          pagedKeys,\n+\t\tcurrentIndex:  -1,\n+\t\tctx:           ctx,\n+\t\tlistRV:        listRV,\n+\t\tsortAscending: sortAscending,\n+\t\tdataStore:     k.dataStore,\n+\t}\n+\n+\terr := fn(&iter)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\treturn listRV, nil\n+}\n+\n+// processTrashEntries handles the special case of listing deleted items (trash)\n+func (k *kvStorageBackend) processTrashEntries(ctx context.Context, req *resourcepb.ListRequest, fn func(ListIterator) error, historyKeys []DataKey, lastSeenRV int64, sortAscending bool, listRV int64) (int64, error) {\n+\t// Filter to only deleted entries\n+\tvar deletedKeys []DataKey\n+\tfor _, key := range historyKeys {\n+\t\tif key.Action == DataActionDeleted {\n+\t\t\tdeletedKeys = append(deletedKeys, key)\n+\t\t}\n+\t}\n+\n+\t// Check if the resource currently exists (is live)\n+\t// If it exists, don't return any trash entries\n+\t_, err := k.metaStore.GetLatestResourceKey(ctx, MetaGetRequestKey{\n+\t\tNamespace: req.Options.Key.Namespace,\n+\t\tGroup:     req.Options.Key.Group,\n+\t\tResource:  req.Options.Key.Resource,\n+\t\tName:      req.Options.Key.Name,\n+\t})\n+\n+\tvar trashKeys []DataKey\n+\tif errors.Is(err, ErrNotFound) {\n+\t\t// Resource doesn't exist currently, so we can return the latest delete\n+\t\t// Find the latest delete event\n+\t\tvar latestDelete *DataKey\n+\t\tfor _, key := range deletedKeys {\n+\t\t\tif latestDelete == nil || key.ResourceVersion > latestDelete.ResourceVersion {\n+\t\t\t\tlatestDelete = &key\n+\t\t\t}\n+\t\t}\n+\t\tif latestDelete != nil {\n+\t\t\ttrashKeys = append(trashKeys, *latestDelete)\n+\t\t}\n+\t}\n+\t// If err != ErrNotFound, the resource exists, so no trash entries should be returned\n+\n+\t// Apply version filtering\n+\tfilteredKeys, err := filterHistoryKeysByVersion(trashKeys, req)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\t// Sort the entries\n+\tsortHistoryKeys(filteredKeys, sortAscending)\n+\n+\t// Pagination: filter out items up to and including lastSeenRV\n+\tpagedKeys := applyPagination(filteredKeys, lastSeenRV, sortAscending)\n+\n+\titer := kvHistoryIterator{\n+\t\tkeys:          pagedKeys,\n+\t\tcurrentIndex:  -1,\n+\t\tctx:           ctx,\n+\t\tlistRV:        listRV,\n+\t\tsortAscending: sortAscending,\n+\t\tdataStore:     k.dataStore,\n+\t}\n+\n+\terr = fn(&iter)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\treturn listRV, nil\n+}\n+\n+// kvHistoryIterator implements ListIterator for KV storage history\n+type kvHistoryIterator struct {\n+\tctx           context.Context\n+\tkeys          []DataKey\n+\tcurrentIndex  int\n+\tlistRV        int64\n+\tsortAscending bool\n+\tdataStore     *dataStore\n+\n+\t// current\n+\trv     int64\n+\terr    error\n+\tvalue  []byte\n+\tfolder string\n+}\n+\n+func (i *kvHistoryIterator) Next() bool {\n+\ti.currentIndex++\n+\n+\tif i.currentIndex >= len(i.keys) {\n+\t\treturn false\n+\t}\n+\n+\tkey := i.keys[i.currentIndex]\n+\ti.rv = key.ResourceVersion\n+\n+\t// Read the value from the ReadCloser\n+\tdata, err := i.dataStore.Get(i.ctx, key)\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\ti.value, err = io.ReadAll(data)\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\n+\t// Extract the folder from the meta data\n+\tpartial := &metav1.PartialObjectMetadata{}\n+\terr = json.Unmarshal(i.value, partial)\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\n+\tmeta, err := utils.MetaAccessor(partial)\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\ti.folder = meta.GetFolder()\n+\ti.err = nil\n+\n+\treturn true\n+}\n+\n+func (i *kvHistoryIterator) Error() error {\n+\treturn i.err\n+}\n+\n+func (i *kvHistoryIterator) ContinueToken() string {\n+\tif i.currentIndex < 0 || i.currentIndex >= len(i.keys) {\n+\t\treturn \"\"\n+\t}\n+\ttoken := ContinueToken{\n+\t\tStartOffset:     i.rv,\n+\t\tResourceVersion: i.keys[i.currentIndex].ResourceVersion,\n+\t\tSortAscending:   i.sortAscending,\n+\t}\n+\treturn token.String()\n+}\n+\n+func (i *kvHistoryIterator) ResourceVersion() int64 {\n+\treturn i.rv\n+}\n+\n+func (i *kvHistoryIterator) Namespace() string {\n+\tif i.currentIndex >= 0 && i.currentIndex < len(i.keys) {\n+\t\treturn i.keys[i.currentIndex].Namespace\n+\t}\n+\treturn \"\"\n+}\n+\n+func (i *kvHistoryIterator) Name() string {\n+\tif i.currentIndex >= 0 && i.currentIndex < len(i.keys) {\n+\t\treturn i.keys[i.currentIndex].Name\n+\t}\n+\treturn \"\"\n+}\n+\n+func (i *kvHistoryIterator) Folder() string {\n+\treturn i.folder\n+}\n+\n+func (i *kvHistoryIterator) Value() []byte {\n+\treturn i.value\n+}\n+\n+// WatchWriteEvents returns a channel that receives write events.\n+func (k *kvStorageBackend) WatchWriteEvents(ctx context.Context) (<-chan *WrittenEvent, error) {\n+\t// Create a channel to receive events\n+\tevents := make(chan *WrittenEvent, 10000) // TODO: make this configurable\n+\n+\tnotifierEvents := k.notifier.Watch(ctx, defaultWatchOptions())\n+\tgo func() {\n+\t\tfor event := range notifierEvents {\n+\t\t\t// fetch the data\n+\t\t\tdataReader, err := k.dataStore.Get(ctx, DataKey{\n+\t\t\t\tNamespace:       event.Namespace,\n+\t\t\t\tGroup:           event.Group,\n+\t\t\t\tResource:        event.Resource,\n+\t\t\t\tName:            event.Name,\n+\t\t\t\tResourceVersion: event.ResourceVersion,\n+\t\t\t\tAction:          event.Action,\n+\t\t\t})\n+\t\t\tif err != nil {\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t\tdata, err := io.ReadAll(dataReader)",
    "repo_full_name": "grafana/grafana",
    "discussion_comments": [
      {
        "comment_id": "2177522201",
        "repo_full_name": "grafana/grafana",
        "pr_number": 107305,
        "pr_file": "pkg/storage/unified/resource/storage_backend.go",
        "discussion_id": "2177522201",
        "commented_code": "@@ -0,0 +1,777 @@\n+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"math/rand/v2\"\n+\t\"net/http\"\n+\t\"sort\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/bwmarrin/snowflake\"\n+\t\"github.com/grafana/grafana/pkg/apimachinery/utils\"\n+\t\"github.com/grafana/grafana/pkg/storage/unified/resourcepb\"\n+\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n+)\n+\n+const (\n+\tdefaultListBufferSize = 100\n+)\n+\n+// Unified storage backend based on KV storage.\n+type kvStorageBackend struct {\n+\tsnowflake  *snowflake.Node\n+\tkv         KV\n+\tdataStore  *dataStore\n+\tmetaStore  *metadataStore\n+\teventStore *eventStore\n+\tnotifier   *notifier\n+\tbuilder    DocumentBuilder\n+}\n+\n+var _ StorageBackend = &kvStorageBackend{}\n+\n+func NewkvStorageBackend(kv KV) *kvStorageBackend {\n+\ts, err := snowflake.NewNode(rand.Int64N(1024))\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\teventStore := newEventStore(kv)\n+\treturn &kvStorageBackend{\n+\t\tkv:         kv,\n+\t\tdataStore:  newDataStore(kv),\n+\t\tmetaStore:  newMetadataStore(kv),\n+\t\teventStore: eventStore,\n+\t\tnotifier:   newNotifier(eventStore, notifierOptions{}),\n+\t\tsnowflake:  s,\n+\t\tbuilder:    StandardDocumentBuilder(), // For now we use the standard document builder.\n+\t}\n+}\n+\n+// WriteEvent writes a resource event (create/update/delete) to the storage backend.\n+func (k *kvStorageBackend) WriteEvent(ctx context.Context, event WriteEvent) (int64, error) {\n+\tif err := event.Validate(); err != nil {\n+\t\treturn 0, fmt.Errorf(\"invalid event: %w\", err)\n+\t}\n+\trv := k.snowflake.Generate().Int64()\n+\n+\t// Write data.\n+\tvar action DataAction\n+\tswitch event.Type {\n+\tcase resourcepb.WatchEvent_ADDED:\n+\t\taction = DataActionCreated\n+\t\t// Check if resource already exists for create operations\n+\t\t_, err := k.metaStore.GetLatestResourceKey(ctx, MetaGetRequestKey{\n+\t\t\tNamespace: event.Key.Namespace,\n+\t\t\tGroup:     event.Key.Group,\n+\t\t\tResource:  event.Key.Resource,\n+\t\t\tName:      event.Key.Name,\n+\t\t})\n+\t\tif err == nil {\n+\t\t\t// Resource exists, return already exists error\n+\t\t\treturn 0, ErrResourceAlreadyExists\n+\t\t}\n+\t\tif !errors.Is(err, ErrNotFound) {\n+\t\t\t// Some other error occurred\n+\t\t\treturn 0, fmt.Errorf(\"failed to check if resource exists: %w\", err)\n+\t\t}\n+\tcase resourcepb.WatchEvent_MODIFIED:\n+\t\taction = DataActionUpdated\n+\tcase resourcepb.WatchEvent_DELETED:\n+\t\taction = DataActionDeleted\n+\tdefault:\n+\t\treturn 0, fmt.Errorf(\"invalid event type: %d\", event.Type)\n+\t}\n+\n+\t// Build the search document\n+\tdoc, err := k.builder.BuildDocument(ctx, event.Key, rv, event.Value)\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to build document: %w\", err)\n+\t}\n+\n+\t// Write the data\n+\terr = k.dataStore.Save(ctx, DataKey{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t}, io.NopCloser(bytes.NewReader(event.Value)))\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write data: %w\", err)\n+\t}\n+\n+\t// Write metadata\n+\terr = k.metaStore.Save(ctx, MetaDataObj{\n+\t\tKey: MetaDataKey{\n+\t\t\tNamespace:       event.Key.Namespace,\n+\t\t\tGroup:           event.Key.Group,\n+\t\t\tResource:        event.Key.Resource,\n+\t\t\tName:            event.Key.Name,\n+\t\t\tResourceVersion: rv,\n+\t\t\tAction:          action,\n+\t\t\tFolder:          event.Object.GetFolder(),\n+\t\t},\n+\t\tValue: MetaData{\n+\t\t\tIndexableDocument: *doc,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write metadata: %w\", err)\n+\t}\n+\n+\t// Write event\n+\terr = k.eventStore.Save(ctx, Event{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t\tFolder:          event.Object.GetFolder(),\n+\t\tPreviousRV:      event.PreviousRV,\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to save event: %w\", err)\n+\t}\n+\treturn rv, nil\n+}\n+\n+func (k *kvStorageBackend) ReadResource(ctx context.Context, req *resourcepb.ReadRequest) *BackendReadResponse {\n+\tif req.Key == nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusBadRequest, Message: \"missing key\"}}\n+\t}\n+\tmeta, err := k.metaStore.GetResourceKeyAtRevision(ctx, MetaGetRequestKey{\n+\t\tNamespace: req.Key.Namespace,\n+\t\tGroup:     req.Key.Group,\n+\t\tResource:  req.Key.Resource,\n+\t\tName:      req.Key.Name,\n+\t}, req.ResourceVersion)\n+\tif errors.Is(err, ErrNotFound) {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusNotFound, Message: \"not found\"}}\n+\t} else if err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tdata, err := k.dataStore.Get(ctx, DataKey{\n+\t\tNamespace:       req.Key.Namespace,\n+\t\tGroup:           req.Key.Group,\n+\t\tResource:        req.Key.Resource,\n+\t\tName:            req.Key.Name,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tAction:          meta.Action,\n+\t})\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tvalue, err := io.ReadAll(data)\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\treturn &BackendReadResponse{\n+\t\tKey:             req.Key,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tValue:           value,\n+\t\tFolder:          meta.Folder,\n+\t}\n+}\n+\n+// // ListIterator returns an iterator for listing resources.\n+func (k *kvStorageBackend) ListIterator(ctx context.Context, req *resourcepb.ListRequest, cb func(ListIterator) error) (int64, error) {\n+\tif req.Options == nil || req.Options.Key == nil {\n+\t\treturn 0, fmt.Errorf(\"missing options or key in ListRequest\")\n+\t}\n+\t// Parse continue token if provided\n+\toffset := int64(0)\n+\tresourceVersion := req.ResourceVersion\n+\tif req.NextPageToken != \"\" {\n+\t\ttoken, err := GetContinueToken(req.NextPageToken)\n+\t\tif err != nil {\n+\t\t\treturn 0, fmt.Errorf(\"invalid continue token: %w\", err)\n+\t\t}\n+\t\toffset = token.StartOffset\n+\t\tresourceVersion = token.ResourceVersion\n+\t}\n+\n+\t// We set the listRV to the current time.\n+\tlistRV := k.snowflake.Generate().Int64()\n+\tif resourceVersion > 0 {\n+\t\tlistRV = resourceVersion\n+\t}\n+\n+\t// Fetch the latest objects\n+\tkeys := make([]MetaDataKey, 0, min(defaultListBufferSize, req.Limit+1))\n+\tidx := 0\n+\tfor metaKey, err := range k.metaStore.ListResourceKeysAtRevision(ctx, MetaListRequestKey{\n+\t\tNamespace: req.Options.Key.Namespace,\n+\t\tGroup:     req.Options.Key.Group,\n+\t\tResource:  req.Options.Key.Resource,\n+\t\tName:      req.Options.Key.Name,\n+\t}, resourceVersion) {\n+\t\tif err != nil {\n+\t\t\treturn 0, err\n+\t\t}\n+\t\t// Skip the first offset items. This is not efficient, but it's a simple way to implement it for now.\n+\t\tif idx < int(offset) {\n+\t\t\tidx++\n+\t\t\tcontinue\n+\t\t}\n+\t\tkeys = append(keys, metaKey)\n+\t\t// Only fetch the first limit items + 1 to get the next token.\n+\t\tif len(keys) >= int(req.Limit+1) {\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\titer := kvListIterator{\n+\t\tkeys:         keys,\n+\t\tcurrentIndex: -1,\n+\t\tctx:          ctx,\n+\t\tlistRV:       listRV,\n+\t\toffset:       offset,\n+\t\tdataStore:    k.dataStore,\n+\t}\n+\terr := cb(&iter)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\treturn listRV, nil\n+}\n+\n+// kvListIterator implements ListIterator for KV storage\n+type kvListIterator struct {\n+\tctx          context.Context\n+\tkeys         []MetaDataKey\n+\tcurrentIndex int\n+\tdataStore    *dataStore\n+\tlistRV       int64\n+\toffset       int64\n+\n+\t// current\n+\trv    int64\n+\terr   error\n+\tvalue []byte\n+}\n+\n+func (i *kvListIterator) Next() bool {\n+\ti.currentIndex++\n+\n+\tif i.currentIndex >= len(i.keys) {\n+\t\treturn false\n+\t}\n+\n+\ti.rv, i.err = i.keys[i.currentIndex].ResourceVersion, nil\n+\n+\tdata, err := i.dataStore.Get(i.ctx, DataKey{\n+\t\tNamespace:       i.keys[i.currentIndex].Namespace,\n+\t\tGroup:           i.keys[i.currentIndex].Group,\n+\t\tResource:        i.keys[i.currentIndex].Resource,\n+\t\tName:            i.keys[i.currentIndex].Name,\n+\t\tResourceVersion: i.keys[i.currentIndex].ResourceVersion,\n+\t\tAction:          i.keys[i.currentIndex].Action,\n+\t})\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\n+\ti.value, i.err = io.ReadAll(data)\n+\tif i.err != nil {\n+\t\treturn false\n+\t}\n+\n+\t// increment the offset\n+\ti.offset++\n+\n+\treturn true\n+}\n+\n+func (i *kvListIterator) Error() error {\n+\treturn nil\n+}\n+\n+func (i *kvListIterator) ContinueToken() string {\n+\treturn ContinueToken{\n+\t\tStartOffset:     i.offset,\n+\t\tResourceVersion: i.listRV,\n+\t}.String()\n+}\n+\n+func (i *kvListIterator) ResourceVersion() int64 {\n+\treturn i.rv\n+}\n+\n+func (i *kvListIterator) Namespace() string {\n+\treturn i.keys[i.currentIndex].Namespace\n+}\n+\n+func (i *kvListIterator) Name() string {\n+\treturn i.keys[i.currentIndex].Name\n+}\n+\n+func (i *kvListIterator) Folder() string {\n+\treturn i.keys[i.currentIndex].Folder\n+}\n+\n+func (i *kvListIterator) Value() []byte {\n+\treturn i.value\n+}\n+\n+func validateListHistoryRequest(req *resourcepb.ListRequest) error {\n+\tif req.Options == nil || req.Options.Key == nil {\n+\t\treturn fmt.Errorf(\"missing options or key in ListRequest\")\n+\t}\n+\tkey := req.Options.Key\n+\tif key.Group == \"\" {\n+\t\treturn fmt.Errorf(\"group is required\")\n+\t}\n+\tif key.Resource == \"\" {\n+\t\treturn fmt.Errorf(\"resource is required\")\n+\t}\n+\tif key.Namespace == \"\" {\n+\t\treturn fmt.Errorf(\"namespace is required\")\n+\t}\n+\tif key.Name == \"\" {\n+\t\treturn fmt.Errorf(\"name is required\")\n+\t}\n+\treturn nil\n+}\n+\n+// filterHistoryKeysByVersion filters history keys based on version match criteria\n+func filterHistoryKeysByVersion(historyKeys []DataKey, req *resourcepb.ListRequest) ([]DataKey, error) {\n+\tswitch req.GetVersionMatchV2() {\n+\tcase resourcepb.ResourceVersionMatchV2_Exact:\n+\t\tif req.ResourceVersion <= 0 {\n+\t\t\treturn nil, fmt.Errorf(\"expecting an explicit resource version query when using Exact matching\")\n+\t\t}\n+\t\tvar exactKeys []DataKey\n+\t\tfor _, key := range historyKeys {\n+\t\t\tif key.ResourceVersion == req.ResourceVersion {\n+\t\t\t\texactKeys = append(exactKeys, key)\n+\t\t\t}\n+\t\t}\n+\t\treturn exactKeys, nil\n+\tcase resourcepb.ResourceVersionMatchV2_NotOlderThan:\n+\t\tif req.ResourceVersion > 0 {\n+\t\t\tvar filteredKeys []DataKey\n+\t\t\tfor _, key := range historyKeys {\n+\t\t\t\tif key.ResourceVersion >= req.ResourceVersion {\n+\t\t\t\t\tfilteredKeys = append(filteredKeys, key)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn filteredKeys, nil\n+\t\t}\n+\tdefault:\n+\t\tif req.ResourceVersion > 0 {\n+\t\t\tvar filteredKeys []DataKey\n+\t\t\tfor _, key := range historyKeys {\n+\t\t\t\tif key.ResourceVersion <= req.ResourceVersion {\n+\t\t\t\t\tfilteredKeys = append(filteredKeys, key)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn filteredKeys, nil\n+\t\t}\n+\t}\n+\treturn historyKeys, nil\n+}\n+\n+// applyLiveHistoryFilter applies \"live\" history logic by ignoring events before the last delete\n+func applyLiveHistoryFilter(filteredKeys []DataKey, req *resourcepb.ListRequest) []DataKey {\n+\tuseLatestDeletionAsMinRV := req.ResourceVersion == 0 && req.Source != resourcepb.ListRequest_TRASH && req.GetVersionMatchV2() != resourcepb.ResourceVersionMatchV2_Exact\n+\tif !useLatestDeletionAsMinRV {\n+\t\treturn filteredKeys\n+\t}\n+\n+\tlatestDeleteRV := int64(0)\n+\tfor _, key := range filteredKeys {\n+\t\tif key.Action == DataActionDeleted && key.ResourceVersion > latestDeleteRV {\n+\t\t\tlatestDeleteRV = key.ResourceVersion\n+\t\t}\n+\t}\n+\tif latestDeleteRV > 0 {\n+\t\tvar liveKeys []DataKey\n+\t\tfor _, key := range filteredKeys {\n+\t\t\tif key.ResourceVersion > latestDeleteRV {\n+\t\t\t\tliveKeys = append(liveKeys, key)\n+\t\t\t}\n+\t\t}\n+\t\treturn liveKeys\n+\t}\n+\treturn filteredKeys\n+}\n+\n+// sortHistoryKeys sorts the history keys based on the sortAscending flag\n+func sortHistoryKeys(filteredKeys []DataKey, sortAscending bool) {\n+\tif sortAscending {\n+\t\tsort.Slice(filteredKeys, func(i, j int) bool {\n+\t\t\treturn filteredKeys[i].ResourceVersion < filteredKeys[j].ResourceVersion\n+\t\t})\n+\t} else {\n+\t\tsort.Slice(filteredKeys, func(i, j int) bool {\n+\t\t\treturn filteredKeys[i].ResourceVersion > filteredKeys[j].ResourceVersion\n+\t\t})\n+\t}\n+}\n+\n+// applyPagination filters keys based on pagination parameters\n+func applyPagination(keys []DataKey, lastSeenRV int64, sortAscending bool) []DataKey {\n+\tif lastSeenRV == 0 {\n+\t\treturn keys\n+\t}\n+\n+\tvar pagedKeys []DataKey\n+\tfor _, key := range keys {\n+\t\tif sortAscending && key.ResourceVersion > lastSeenRV {\n+\t\t\tpagedKeys = append(pagedKeys, key)\n+\t\t} else if !sortAscending && key.ResourceVersion < lastSeenRV {\n+\t\t\tpagedKeys = append(pagedKeys, key)\n+\t\t}\n+\t}\n+\treturn pagedKeys\n+}\n+\n+// ListHistory is like ListIterator, but it returns the history of a resource.\n+func (k *kvStorageBackend) ListHistory(ctx context.Context, req *resourcepb.ListRequest, fn func(ListIterator) error) (int64, error) {\n+\tif err := validateListHistoryRequest(req); err != nil {\n+\t\treturn 0, err\n+\t}\n+\tkey := req.Options.Key\n+\t// Parse continue token if provided\n+\tlastSeenRV := int64(0)\n+\tsortAscending := req.GetVersionMatchV2() == resourcepb.ResourceVersionMatchV2_NotOlderThan\n+\tif req.NextPageToken != \"\" {\n+\t\ttoken, err := GetContinueToken(req.NextPageToken)\n+\t\tif err != nil {\n+\t\t\treturn 0, fmt.Errorf(\"invalid continue token: %w\", err)\n+\t\t}\n+\t\tlastSeenRV = token.ResourceVersion\n+\t\tsortAscending = token.SortAscending\n+\t}\n+\n+\t// Generate a new resource version for the list\n+\tlistRV := k.snowflake.Generate().Int64()\n+\n+\t// Get all history entries by iterating through datastore keys\n+\thistoryKeys := make([]DataKey, 0, min(defaultListBufferSize, req.Limit+1))\n+\n+\t// Use datastore.Keys to get all data keys for this specific resource\n+\tfor dataKey, err := range k.dataStore.Keys(ctx, ListRequestKey{\n+\t\tNamespace: key.Namespace,\n+\t\tGroup:     key.Group,\n+\t\tResource:  key.Resource,\n+\t\tName:      key.Name,\n+\t}) {\n+\t\tif err != nil {\n+\t\t\treturn 0, err\n+\t\t}\n+\t\thistoryKeys = append(historyKeys, dataKey)\n+\t}\n+\n+\t// Check if context has been cancelled\n+\tif ctx.Err() != nil {\n+\t\treturn 0, ctx.Err()\n+\t}\n+\n+\t// Handle trash differently from regular history\n+\tif req.Source == resourcepb.ListRequest_TRASH {\n+\t\treturn k.processTrashEntries(ctx, req, fn, historyKeys, lastSeenRV, sortAscending, listRV)\n+\t}\n+\n+\t// Apply filtering based on version match\n+\tfilteredKeys, filterErr := filterHistoryKeysByVersion(historyKeys, req)\n+\tif filterErr != nil {\n+\t\treturn 0, filterErr\n+\t}\n+\n+\t// Apply \"live\" history logic: ignore events before the last delete\n+\tfilteredKeys = applyLiveHistoryFilter(filteredKeys, req)\n+\n+\t// Sort the entries if not already sorted correctly\n+\tsortHistoryKeys(filteredKeys, sortAscending)\n+\n+\t// Pagination: filter out items up to and including lastSeenRV\n+\tpagedKeys := applyPagination(filteredKeys, lastSeenRV, sortAscending)\n+\n+\titer := kvHistoryIterator{\n+\t\tkeys:          pagedKeys,\n+\t\tcurrentIndex:  -1,\n+\t\tctx:           ctx,\n+\t\tlistRV:        listRV,\n+\t\tsortAscending: sortAscending,\n+\t\tdataStore:     k.dataStore,\n+\t}\n+\n+\terr := fn(&iter)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\treturn listRV, nil\n+}\n+\n+// processTrashEntries handles the special case of listing deleted items (trash)\n+func (k *kvStorageBackend) processTrashEntries(ctx context.Context, req *resourcepb.ListRequest, fn func(ListIterator) error, historyKeys []DataKey, lastSeenRV int64, sortAscending bool, listRV int64) (int64, error) {\n+\t// Filter to only deleted entries\n+\tvar deletedKeys []DataKey\n+\tfor _, key := range historyKeys {\n+\t\tif key.Action == DataActionDeleted {\n+\t\t\tdeletedKeys = append(deletedKeys, key)\n+\t\t}\n+\t}\n+\n+\t// Check if the resource currently exists (is live)\n+\t// If it exists, don't return any trash entries\n+\t_, err := k.metaStore.GetLatestResourceKey(ctx, MetaGetRequestKey{\n+\t\tNamespace: req.Options.Key.Namespace,\n+\t\tGroup:     req.Options.Key.Group,\n+\t\tResource:  req.Options.Key.Resource,\n+\t\tName:      req.Options.Key.Name,\n+\t})\n+\n+\tvar trashKeys []DataKey\n+\tif errors.Is(err, ErrNotFound) {\n+\t\t// Resource doesn't exist currently, so we can return the latest delete\n+\t\t// Find the latest delete event\n+\t\tvar latestDelete *DataKey\n+\t\tfor _, key := range deletedKeys {\n+\t\t\tif latestDelete == nil || key.ResourceVersion > latestDelete.ResourceVersion {\n+\t\t\t\tlatestDelete = &key\n+\t\t\t}\n+\t\t}\n+\t\tif latestDelete != nil {\n+\t\t\ttrashKeys = append(trashKeys, *latestDelete)\n+\t\t}\n+\t}\n+\t// If err != ErrNotFound, the resource exists, so no trash entries should be returned\n+\n+\t// Apply version filtering\n+\tfilteredKeys, err := filterHistoryKeysByVersion(trashKeys, req)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\t// Sort the entries\n+\tsortHistoryKeys(filteredKeys, sortAscending)\n+\n+\t// Pagination: filter out items up to and including lastSeenRV\n+\tpagedKeys := applyPagination(filteredKeys, lastSeenRV, sortAscending)\n+\n+\titer := kvHistoryIterator{\n+\t\tkeys:          pagedKeys,\n+\t\tcurrentIndex:  -1,\n+\t\tctx:           ctx,\n+\t\tlistRV:        listRV,\n+\t\tsortAscending: sortAscending,\n+\t\tdataStore:     k.dataStore,\n+\t}\n+\n+\terr = fn(&iter)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\treturn listRV, nil\n+}\n+\n+// kvHistoryIterator implements ListIterator for KV storage history\n+type kvHistoryIterator struct {\n+\tctx           context.Context\n+\tkeys          []DataKey\n+\tcurrentIndex  int\n+\tlistRV        int64\n+\tsortAscending bool\n+\tdataStore     *dataStore\n+\n+\t// current\n+\trv     int64\n+\terr    error\n+\tvalue  []byte\n+\tfolder string\n+}\n+\n+func (i *kvHistoryIterator) Next() bool {\n+\ti.currentIndex++\n+\n+\tif i.currentIndex >= len(i.keys) {\n+\t\treturn false\n+\t}\n+\n+\tkey := i.keys[i.currentIndex]\n+\ti.rv = key.ResourceVersion\n+\n+\t// Read the value from the ReadCloser\n+\tdata, err := i.dataStore.Get(i.ctx, key)\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\ti.value, err = io.ReadAll(data)\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\n+\t// Extract the folder from the meta data\n+\tpartial := &metav1.PartialObjectMetadata{}\n+\terr = json.Unmarshal(i.value, partial)\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\n+\tmeta, err := utils.MetaAccessor(partial)\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\ti.folder = meta.GetFolder()\n+\ti.err = nil\n+\n+\treturn true\n+}\n+\n+func (i *kvHistoryIterator) Error() error {\n+\treturn i.err\n+}\n+\n+func (i *kvHistoryIterator) ContinueToken() string {\n+\tif i.currentIndex < 0 || i.currentIndex >= len(i.keys) {\n+\t\treturn \"\"\n+\t}\n+\ttoken := ContinueToken{\n+\t\tStartOffset:     i.rv,\n+\t\tResourceVersion: i.keys[i.currentIndex].ResourceVersion,\n+\t\tSortAscending:   i.sortAscending,\n+\t}\n+\treturn token.String()\n+}\n+\n+func (i *kvHistoryIterator) ResourceVersion() int64 {\n+\treturn i.rv\n+}\n+\n+func (i *kvHistoryIterator) Namespace() string {\n+\tif i.currentIndex >= 0 && i.currentIndex < len(i.keys) {\n+\t\treturn i.keys[i.currentIndex].Namespace\n+\t}\n+\treturn \"\"\n+}\n+\n+func (i *kvHistoryIterator) Name() string {\n+\tif i.currentIndex >= 0 && i.currentIndex < len(i.keys) {\n+\t\treturn i.keys[i.currentIndex].Name\n+\t}\n+\treturn \"\"\n+}\n+\n+func (i *kvHistoryIterator) Folder() string {\n+\treturn i.folder\n+}\n+\n+func (i *kvHistoryIterator) Value() []byte {\n+\treturn i.value\n+}\n+\n+// WatchWriteEvents returns a channel that receives write events.\n+func (k *kvStorageBackend) WatchWriteEvents(ctx context.Context) (<-chan *WrittenEvent, error) {\n+\t// Create a channel to receive events\n+\tevents := make(chan *WrittenEvent, 10000) // TODO: make this configurable\n+\n+\tnotifierEvents := k.notifier.Watch(ctx, defaultWatchOptions())\n+\tgo func() {\n+\t\tfor event := range notifierEvents {\n+\t\t\t// fetch the data\n+\t\t\tdataReader, err := k.dataStore.Get(ctx, DataKey{\n+\t\t\t\tNamespace:       event.Namespace,\n+\t\t\t\tGroup:           event.Group,\n+\t\t\t\tResource:        event.Resource,\n+\t\t\t\tName:            event.Name,\n+\t\t\t\tResourceVersion: event.ResourceVersion,\n+\t\t\t\tAction:          event.Action,\n+\t\t\t})\n+\t\t\tif err != nil {\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t\tdata, err := io.ReadAll(dataReader)",
        "comment_created_at": "2025-07-01T12:48:05+00:00",
        "comment_author": "pstibrany",
        "comment_body": "`dataReader` needs to be closed.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2172134043",
    "pr_number": 107182,
    "pr_file": "pkg/storage/unified/resource/eventstore.go",
    "created_at": "2025-06-27T14:11:04+00:00",
    "commented_code": "+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"fmt\"\n+\t\"iter\"\n+\t\"strconv\"\n+\t\"strings\"\n+)\n+\n+const (\n+\teventsSection = \"unified/events\"\n+)\n+\n+// eventStore is a store for events.\n+type eventStore struct {\n+\tkv KV\n+}\n+\n+type EventKey struct {\n+\tNamespace       string\n+\tGroup           string\n+\tResource        string\n+\tName            string\n+\tResourceVersion int64\n+}\n+\n+func (k EventKey) String() string {\n+\treturn fmt.Sprintf(\"%d~%s~%s~%s~%s\", k.ResourceVersion, k.Namespace, k.Group, k.Resource, k.Name)\n+}\n+\n+func (k EventKey) Validate() error {\n+\tif k.Namespace == \"\" {\n+\t\treturn fmt.Errorf(\"namespace cannot be empty\")\n+\t}\n+\tif k.Group == \"\" {\n+\t\treturn fmt.Errorf(\"group cannot be empty\")\n+\t}\n+\tif k.Resource == \"\" {\n+\t\treturn fmt.Errorf(\"resource cannot be empty\")\n+\t}\n+\tif k.Name == \"\" {\n+\t\treturn fmt.Errorf(\"name cannot be empty\")\n+\t}\n+\tif k.ResourceVersion < 0 {\n+\t\treturn fmt.Errorf(\"resource version must be non-negative\")\n+\t}\n+\n+\t// Validate each field against the naming rules (reusing the regex from datastore.go)\n+\tif !validNameRegex.MatchString(k.Namespace) {\n+\t\treturn fmt.Errorf(\"namespace '%s' is invalid\", k.Namespace)\n+\t}\n+\tif !validNameRegex.MatchString(k.Group) {\n+\t\treturn fmt.Errorf(\"group '%s' is invalid\", k.Group)\n+\t}\n+\tif !validNameRegex.MatchString(k.Resource) {\n+\t\treturn fmt.Errorf(\"resource '%s' is invalid\", k.Resource)\n+\t}\n+\tif !validNameRegex.MatchString(k.Name) {\n+\t\treturn fmt.Errorf(\"name '%s' is invalid\", k.Name)\n+\t}\n+\n+\treturn nil\n+}\n+\n+type Event struct {\n+\tNamespace       string     `json:\"namespace\"`\n+\tGroup           string     `json:\"group\"`\n+\tResource        string     `json:\"resource\"`\n+\tName            string     `json:\"name\"`\n+\tResourceVersion int64      `json:\"resource_version\"`\n+\tAction          DataAction `json:\"action\"`\n+\tFolder          string     `json:\"folder\"`\n+\tPreviousRV      int64      `json:\"previous_rv\"`\n+}\n+\n+func newEventStore(kv KV) *eventStore {\n+\treturn &eventStore{\n+\t\tkv: kv,\n+\t}\n+}\n+\n+// ParseEventKey parses a key string back into an EventKey struct\n+func ParseEventKey(key string) (EventKey, error) {\n+\tparts := strings.Split(key, \"~\")\n+\tif len(parts) != 5 {\n+\t\treturn EventKey{}, fmt.Errorf(\"invalid key format: expected 5 parts, got %d\", len(parts))\n+\t}\n+\n+\trv, err := strconv.ParseInt(parts[0], 10, 64)\n+\tif err != nil {\n+\t\treturn EventKey{}, fmt.Errorf(\"invalid resource version: %w\", err)\n+\t}\n+\n+\treturn EventKey{\n+\t\tResourceVersion: rv,\n+\t\tNamespace:       parts[1],\n+\t\tGroup:           parts[2],\n+\t\tResource:        parts[3],\n+\t\tName:            parts[4],\n+\t}, nil\n+}\n+\n+// LastEventKey returns the Event Key of the event with the highest resource version.\n+// If no events are found, it returns ErrNotFound.\n+func (n *eventStore) LastEventKey(ctx context.Context) (EventKey, error) {\n+\tfor key, err := range n.kv.Keys(ctx, eventsSection, ListOptions{Sort: SortOrderDesc, Limit: 1}) {\n+\t\tif err != nil {\n+\t\t\treturn EventKey{}, err\n+\t\t}\n+\t\teventKey, err := ParseEventKey(key)\n+\t\tif err != nil {\n+\t\t\treturn EventKey{}, err\n+\t\t}\n+\t\treturn eventKey, nil\n+\t}\n+\n+\treturn EventKey{}, ErrNotFound\n+}\n+\n+// Save an event to the store.\n+func (n *eventStore) Save(ctx context.Context, event Event) error {\n+\teventKey := EventKey{\n+\t\tNamespace:       event.Namespace,\n+\t\tGroup:           event.Group,\n+\t\tResource:        event.Resource,\n+\t\tName:            event.Name,\n+\t\tResourceVersion: event.ResourceVersion,\n+\t}\n+\n+\tif err := eventKey.Validate(); err != nil {\n+\t\treturn fmt.Errorf(\"invalid event key: %w\", err)\n+\t}\n+\n+\tvar buf bytes.Buffer\n+\tencoder := json.NewEncoder(&buf)\n+\tif err := encoder.Encode(event); err != nil {\n+\t\treturn err\n+\t}\n+\treturn n.kv.Save(ctx, eventsSection, eventKey.String(), &buf)\n+}\n+\n+func (n *eventStore) Get(ctx context.Context, key EventKey) (Event, error) {\n+\tif err := key.Validate(); err != nil {\n+\t\treturn Event{}, fmt.Errorf(\"invalid event key: %w\", err)\n+\t}\n+\n+\tobj, err := n.kv.Get(ctx, eventsSection, key.String())\n+\tif err != nil {\n+\t\treturn Event{}, err\n+\t}\n+\tvar event Event\n+\tif err = json.NewDecoder(obj.Value).Decode(&event); err != nil {\n+\t\t_ = obj.Value.Close()\n+\t\treturn Event{}, err\n+\t}\n+\tif err = obj.Value.Close(); err != nil {",
    "repo_full_name": "grafana/grafana",
    "discussion_comments": [
      {
        "comment_id": "2172134043",
        "repo_full_name": "grafana/grafana",
        "pr_number": 107182,
        "pr_file": "pkg/storage/unified/resource/eventstore.go",
        "discussion_id": "2172134043",
        "commented_code": "@@ -0,0 +1,191 @@\n+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"fmt\"\n+\t\"iter\"\n+\t\"strconv\"\n+\t\"strings\"\n+)\n+\n+const (\n+\teventsSection = \"unified/events\"\n+)\n+\n+// eventStore is a store for events.\n+type eventStore struct {\n+\tkv KV\n+}\n+\n+type EventKey struct {\n+\tNamespace       string\n+\tGroup           string\n+\tResource        string\n+\tName            string\n+\tResourceVersion int64\n+}\n+\n+func (k EventKey) String() string {\n+\treturn fmt.Sprintf(\"%d~%s~%s~%s~%s\", k.ResourceVersion, k.Namespace, k.Group, k.Resource, k.Name)\n+}\n+\n+func (k EventKey) Validate() error {\n+\tif k.Namespace == \"\" {\n+\t\treturn fmt.Errorf(\"namespace cannot be empty\")\n+\t}\n+\tif k.Group == \"\" {\n+\t\treturn fmt.Errorf(\"group cannot be empty\")\n+\t}\n+\tif k.Resource == \"\" {\n+\t\treturn fmt.Errorf(\"resource cannot be empty\")\n+\t}\n+\tif k.Name == \"\" {\n+\t\treturn fmt.Errorf(\"name cannot be empty\")\n+\t}\n+\tif k.ResourceVersion < 0 {\n+\t\treturn fmt.Errorf(\"resource version must be non-negative\")\n+\t}\n+\n+\t// Validate each field against the naming rules (reusing the regex from datastore.go)\n+\tif !validNameRegex.MatchString(k.Namespace) {\n+\t\treturn fmt.Errorf(\"namespace '%s' is invalid\", k.Namespace)\n+\t}\n+\tif !validNameRegex.MatchString(k.Group) {\n+\t\treturn fmt.Errorf(\"group '%s' is invalid\", k.Group)\n+\t}\n+\tif !validNameRegex.MatchString(k.Resource) {\n+\t\treturn fmt.Errorf(\"resource '%s' is invalid\", k.Resource)\n+\t}\n+\tif !validNameRegex.MatchString(k.Name) {\n+\t\treturn fmt.Errorf(\"name '%s' is invalid\", k.Name)\n+\t}\n+\n+\treturn nil\n+}\n+\n+type Event struct {\n+\tNamespace       string     `json:\"namespace\"`\n+\tGroup           string     `json:\"group\"`\n+\tResource        string     `json:\"resource\"`\n+\tName            string     `json:\"name\"`\n+\tResourceVersion int64      `json:\"resource_version\"`\n+\tAction          DataAction `json:\"action\"`\n+\tFolder          string     `json:\"folder\"`\n+\tPreviousRV      int64      `json:\"previous_rv\"`\n+}\n+\n+func newEventStore(kv KV) *eventStore {\n+\treturn &eventStore{\n+\t\tkv: kv,\n+\t}\n+}\n+\n+// ParseEventKey parses a key string back into an EventKey struct\n+func ParseEventKey(key string) (EventKey, error) {\n+\tparts := strings.Split(key, \"~\")\n+\tif len(parts) != 5 {\n+\t\treturn EventKey{}, fmt.Errorf(\"invalid key format: expected 5 parts, got %d\", len(parts))\n+\t}\n+\n+\trv, err := strconv.ParseInt(parts[0], 10, 64)\n+\tif err != nil {\n+\t\treturn EventKey{}, fmt.Errorf(\"invalid resource version: %w\", err)\n+\t}\n+\n+\treturn EventKey{\n+\t\tResourceVersion: rv,\n+\t\tNamespace:       parts[1],\n+\t\tGroup:           parts[2],\n+\t\tResource:        parts[3],\n+\t\tName:            parts[4],\n+\t}, nil\n+}\n+\n+// LastEventKey returns the Event Key of the event with the highest resource version.\n+// If no events are found, it returns ErrNotFound.\n+func (n *eventStore) LastEventKey(ctx context.Context) (EventKey, error) {\n+\tfor key, err := range n.kv.Keys(ctx, eventsSection, ListOptions{Sort: SortOrderDesc, Limit: 1}) {\n+\t\tif err != nil {\n+\t\t\treturn EventKey{}, err\n+\t\t}\n+\t\teventKey, err := ParseEventKey(key)\n+\t\tif err != nil {\n+\t\t\treturn EventKey{}, err\n+\t\t}\n+\t\treturn eventKey, nil\n+\t}\n+\n+\treturn EventKey{}, ErrNotFound\n+}\n+\n+// Save an event to the store.\n+func (n *eventStore) Save(ctx context.Context, event Event) error {\n+\teventKey := EventKey{\n+\t\tNamespace:       event.Namespace,\n+\t\tGroup:           event.Group,\n+\t\tResource:        event.Resource,\n+\t\tName:            event.Name,\n+\t\tResourceVersion: event.ResourceVersion,\n+\t}\n+\n+\tif err := eventKey.Validate(); err != nil {\n+\t\treturn fmt.Errorf(\"invalid event key: %w\", err)\n+\t}\n+\n+\tvar buf bytes.Buffer\n+\tencoder := json.NewEncoder(&buf)\n+\tif err := encoder.Encode(event); err != nil {\n+\t\treturn err\n+\t}\n+\treturn n.kv.Save(ctx, eventsSection, eventKey.String(), &buf)\n+}\n+\n+func (n *eventStore) Get(ctx context.Context, key EventKey) (Event, error) {\n+\tif err := key.Validate(); err != nil {\n+\t\treturn Event{}, fmt.Errorf(\"invalid event key: %w\", err)\n+\t}\n+\n+\tobj, err := n.kv.Get(ctx, eventsSection, key.String())\n+\tif err != nil {\n+\t\treturn Event{}, err\n+\t}\n+\tvar event Event\n+\tif err = json.NewDecoder(obj.Value).Decode(&event); err != nil {\n+\t\t_ = obj.Value.Close()\n+\t\treturn Event{}, err\n+\t}\n+\tif err = obj.Value.Close(); err != nil {",
        "comment_created_at": "2025-06-27T14:11:04+00:00",
        "comment_author": "pstibrany",
        "comment_body": "Nit: I wouldn't worry about `Close()` errors when we already process the data and detect errors there -- like here, we parse JSON. If we parsed JSON object successfully, we don't really care if there was a problem reading the remaining data, as we don't expect more.\n\nHowever we should not not ignoring `Close` errors if we simply read data without processing it (e.g. into byte buffer), because we may miss errors. And obviously we should never ignore `Close` errors on writes.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2166763027",
    "pr_number": 107151,
    "pr_file": "pkg/storage/unified/resource/metadata.go",
    "created_at": "2025-06-25T13:45:55+00:00",
    "commented_code": "+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"iter\"\n+\t\"math\"\n+\t\"strconv\"\n+\t\"strings\"\n+)\n+\n+const (\n+\tmetaSection = \"unified/meta\"\n+)\n+\n+// Metadata store stores search documents for resources in unified storage.\n+// The store keeps track of the latest versions of each resource.\n+type MetaData struct {\n+\tIndexableDocument\n+}\n+\n+type MetaDataKey struct {\n+\tNamespace       string\n+\tGroup           string\n+\tResource        string\n+\tName            string\n+\tResourceVersion int64\n+\tFolder          string\n+\tAction          DataAction\n+}\n+\n+type MetaDataObj struct {\n+\tKey   MetaDataKey\n+\tValue MetaData\n+}\n+\n+type metadataStore struct {\n+\tkv KV\n+}\n+\n+func newMetadataStore(kv KV) *metadataStore {\n+\treturn &metadataStore{\n+\t\tkv: kv,\n+\t}\n+}\n+\n+func (d *metadataStore) Get(ctx context.Context, key MetaDataKey) (MetaData, error) {\n+\tobj, err := d.kv.Get(ctx, metaSection, d.getKey(key))\n+\tif err != nil {\n+\t\treturn MetaData{}, err\n+\t}\n+\tvalue, err := io.ReadAll(obj.Value)\n+\tif err != nil {\n+\t\treturn MetaData{}, err\n+\t}\n+\tvar meta MetaData\n+\tif err := json.Unmarshal(value, &meta); err != nil {\n+\t\treturn meta, err\n+\t}\n+\treturn meta, nil",
    "repo_full_name": "grafana/grafana",
    "discussion_comments": [
      {
        "comment_id": "2166763027",
        "repo_full_name": "grafana/grafana",
        "pr_number": 107151,
        "pr_file": "pkg/storage/unified/resource/metadata.go",
        "discussion_id": "2166763027",
        "commented_code": "@@ -0,0 +1,273 @@\n+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"iter\"\n+\t\"math\"\n+\t\"strconv\"\n+\t\"strings\"\n+)\n+\n+const (\n+\tmetaSection = \"unified/meta\"\n+)\n+\n+// Metadata store stores search documents for resources in unified storage.\n+// The store keeps track of the latest versions of each resource.\n+type MetaData struct {\n+\tIndexableDocument\n+}\n+\n+type MetaDataKey struct {\n+\tNamespace       string\n+\tGroup           string\n+\tResource        string\n+\tName            string\n+\tResourceVersion int64\n+\tFolder          string\n+\tAction          DataAction\n+}\n+\n+type MetaDataObj struct {\n+\tKey   MetaDataKey\n+\tValue MetaData\n+}\n+\n+type metadataStore struct {\n+\tkv KV\n+}\n+\n+func newMetadataStore(kv KV) *metadataStore {\n+\treturn &metadataStore{\n+\t\tkv: kv,\n+\t}\n+}\n+\n+func (d *metadataStore) Get(ctx context.Context, key MetaDataKey) (MetaData, error) {\n+\tobj, err := d.kv.Get(ctx, metaSection, d.getKey(key))\n+\tif err != nil {\n+\t\treturn MetaData{}, err\n+\t}\n+\tvalue, err := io.ReadAll(obj.Value)\n+\tif err != nil {\n+\t\treturn MetaData{}, err\n+\t}\n+\tvar meta MetaData\n+\tif err := json.Unmarshal(value, &meta); err != nil {\n+\t\treturn meta, err\n+\t}\n+\treturn meta, nil",
        "comment_created_at": "2025-06-25T13:45:55+00:00",
        "comment_author": "pstibrany",
        "comment_body": "We need to close `obj.Value` after successful call to `Get`. (We should perhaps document this on `Get` method). We can also decode JSON without reading it to memory first.\n\n(in case it's not clear... in my IDE it looks weird... this suggestion replaces code between line with `io.ReadAll(obj.Value)` and `return meta, nil`, both lines included)\n\n```suggestion\n\tdefer obj.Value.Close()\n\tvar meta MetaData\n\terr = json.NewDecoder(obj.Value).Decode(&meta)\n\treturn meta, err\n```",
        "pr_file_module": null
      }
    ]
  }
]