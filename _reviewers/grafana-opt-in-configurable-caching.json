[
  {
    "discussion_id": "1580770646",
    "pr_number": 86957,
    "pr_file": "public/app/features/query/state/runRequest.ts",
    "created_at": "2024-04-26T09:44:39+00:00",
    "commented_code": "request.endTime = Date.now();\n \n       state = processResponsePacket(packet, state);\n+      cache.set(cacheKey, state.panelData);",
    "repo_full_name": "grafana/grafana",
    "discussion_comments": [
      {
        "comment_id": "1580770646",
        "repo_full_name": "grafana/grafana",
        "pr_number": 86957,
        "pr_file": "public/app/features/query/state/runRequest.ts",
        "discussion_id": "1580770646",
        "commented_code": "@@ -159,6 +169,7 @@ export function runRequest(\n       request.endTime = Date.now();\n \n       state = processResponsePacket(packet, state);\n+      cache.set(cacheKey, state.panelData);",
        "comment_created_at": "2024-04-26T09:44:39+00:00",
        "comment_author": "ifrost",
        "comment_body": "Cache is set after getting the result, so if there are multiple requests initiated before the cache is set they will be executed (e.g. on initial render). Another way to apporach it could be shortly debouncing runRequest per hash. Either way, as you said it may come with some perf cost so maybe it'd make sense if it was optional and enabled on case by case basis.\r\n\r\nTo cache interpolated queries maybe the cache could live closer to the [.query()](https://github.com/grafana/grafana/blob/5a8384a2455bbd3c0ba5ec67e5f5e3cc4a836904/packages/grafana-runtime/src/utils/DataSourceWithBackend.ts#L129) method. There's already queryCachingTTL for backend caching but it's only used in Enterprise.\r\n\r\nMy gut feeling is that It seems it could be a nice thing to have in general if was opt-in rather than default ðŸ¤” ",
        "pr_file_module": null
      },
      {
        "comment_id": "1580867093",
        "repo_full_name": "grafana/grafana",
        "pr_number": 86957,
        "pr_file": "public/app/features/query/state/runRequest.ts",
        "discussion_id": "1580770646",
        "commented_code": "@@ -159,6 +169,7 @@ export function runRequest(\n       request.endTime = Date.now();\n \n       state = processResponsePacket(packet, state);\n+      cache.set(cacheKey, state.panelData);",
        "comment_created_at": "2024-04-26T11:00:24+00:00",
        "comment_author": "gillesdemey",
        "comment_body": "I'd advise some caution when thinking of moving it closer to the `query` method unless there is a way to opt-out of caching â€“ some teams (including ours, the Alerting team) have already implemented RTK Query in parts of the code base but still call the `query()` function in `queryFn`. A double layer of cache would be ... well you know what they say about cache invalidation :D",
        "pr_file_module": null
      },
      {
        "comment_id": "1584352075",
        "repo_full_name": "grafana/grafana",
        "pr_number": 86957,
        "pr_file": "public/app/features/query/state/runRequest.ts",
        "discussion_id": "1580770646",
        "commented_code": "@@ -159,6 +169,7 @@ export function runRequest(\n       request.endTime = Date.now();\n \n       state = processResponsePacket(packet, state);\n+      cache.set(cacheKey, state.panelData);",
        "comment_created_at": "2024-04-30T08:28:06+00:00",
        "comment_author": "torkelo",
        "comment_body": "@ifrost yea, we could implement a query cache concept similar to react-query to handle that (So multiple queries with same key does not cause multiple real queries). \r\n\r\nI originally tried to use the react-query cache but does not look possible. \r\n\r\nThe point with a cache here is to have a shared cache across different apps / parts of Grafana. ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1583069357",
    "pr_number": 86957,
    "pr_file": "public/app/features/query/state/runRequest.ts",
    "created_at": "2024-04-29T13:13:50+00:00",
    "commented_code": "request.endTime = Date.now();\n \n       state = processResponsePacket(packet, state);\n+      cache.set(cacheKey, state.panelData);",
    "repo_full_name": "grafana/grafana",
    "discussion_comments": [
      {
        "comment_id": "1583069357",
        "repo_full_name": "grafana/grafana",
        "pr_number": 86957,
        "pr_file": "public/app/features/query/state/runRequest.ts",
        "discussion_id": "1583069357",
        "commented_code": "@@ -159,6 +169,7 @@ export function runRequest(\n       request.endTime = Date.now();\n \n       state = processResponsePacket(packet, state);\n+      cache.set(cacheKey, state.panelData);",
        "comment_created_at": "2024-04-29T13:13:50+00:00",
        "comment_author": "svennergr",
        "comment_body": "I think if we would go with that, we should only cache successful data, i.e. no error responses.",
        "pr_file_module": null
      }
    ]
  }
]