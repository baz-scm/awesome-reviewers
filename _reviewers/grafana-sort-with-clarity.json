[
  {
    "discussion_id": "2176685365",
    "pr_number": 107435,
    "pr_file": "pkg/registry/apis/provisioning/resources/dualwriter.go",
    "created_at": "2025-07-01T07:43:34+00:00",
    "commented_code": "return apierrors.NewForbidden(FolderResource.GroupResource(), \"\",\n \t\tfmt.Errorf(\"must be admin or editor to access folders with provisioning\"))\n }\n+\n+func (r *DualReadWriter) deleteFolder(ctx context.Context, opts DualWriteOptions) (*ParsedResource, error) {\n+\t// if the ref is not the active branch, just delete the files from the branch\n+\t// do not delete the items from grafana itself\n+\tif opts.Ref != \"\" && opts.Ref != r.getConfiguredBranch() {\n+\t\terr := r.repo.Delete(ctx, opts.Path, opts.Ref, opts.Message)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"error deleting folder from repository: %w\", err)\n+\t\t}\n+\n+\t\treturn folderDeleteResponse(opts.Path, opts.Ref, r.repo.Config()), nil\n+\t}\n+\n+\t// before deleting from the repo, first get all children resources to delete from grafana afterwards\n+\ttreeEntries, err := r.repo.ReadTree(ctx, \"\")\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"read repository tree: %w\", err)\n+\t}\n+\t// note: parsedFolders will include the folder itself\n+\tparsedResources, parsedFolders, err := r.getChildren(ctx, opts.Path, treeEntries)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"parse resources in folder: %w\", err)\n+\t}\n+\n+\t// delete from the repo\n+\terr = r.repo.Delete(ctx, opts.Path, opts.Ref, opts.Message)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"delete folder from repository: %w\", err)\n+\t}\n+\n+\t// delete from grafana\n+\tctx, _, err = identity.WithProvisioningIdentity(ctx, r.repo.Config().Namespace)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tif err := r.deleteChildren(ctx, parsedResources, parsedFolders); err != nil {\n+\t\treturn nil, fmt.Errorf(\"delete folder from grafana: %w\", err)\n+\t}\n+\n+\treturn folderDeleteResponse(opts.Path, opts.Ref, r.repo.Config()), nil\n+}\n+\n+func folderDeleteResponse(path, ref string, cfg *provisioning.Repository) *ParsedResource {\n+\treturn &ParsedResource{\n+\t\tAction: provisioning.ResourceActionDelete,\n+\t\tInfo: &repository.FileInfo{\n+\t\t\tPath: path,\n+\t\t\tRef:  ref,\n+\t\t},\n+\t\tGVK: schema.GroupVersionKind{\n+\t\t\tGroup:   FolderResource.Group,\n+\t\t\tVersion: FolderResource.Version,\n+\t\t\tKind:    \"Folder\",\n+\t\t},\n+\t\tGVR: FolderResource,\n+\t\tRepo: provisioning.ResourceRepositoryInfo{\n+\t\t\tType:      cfg.Spec.Type,\n+\t\t\tNamespace: cfg.Namespace,\n+\t\t\tName:      cfg.Name,\n+\t\t\tTitle:     cfg.Spec.Title,\n+\t\t},\n+\t}\n+}\n+\n+func (r *DualReadWriter) getChildren(ctx context.Context, folderPath string, treeEntries []repository.FileTreeEntry) ([]*ParsedResource, []Folder, error) {\n+\tvar resourcesInFolder []repository.FileTreeEntry\n+\tvar foldersInFolder []Folder\n+\tfor _, entry := range treeEntries {\n+\t\t// the folder itself should be included in this, to do that, trim the suffix of the folder path and see if it matches exactly\n+\t\tif !strings.HasPrefix(entry.Path, folderPath) && entry.Path != strings.TrimSuffix(folderPath, \"/\") {\n+\t\t\tcontinue\n+\t\t}\n+\t\t// folders cannot be parsed as resources, so handle them separately\n+\t\tif entry.Blob {\n+\t\t\tresourcesInFolder = append(resourcesInFolder, entry)\n+\t\t} else {\n+\t\t\tfolder := ParseFolder(entry.Path, r.repo.Config().Name)\n+\t\t\tfoldersInFolder = append(foldersInFolder, folder)\n+\t\t}\n+\t}\n+\n+\tparsedResources := make([]*ParsedResource, len(resourcesInFolder))\n+\tfor i, entry := range resourcesInFolder {\n+\t\tfileInfo, err := r.repo.Read(ctx, entry.Path, \"\")\n+\t\tif err != nil && !apierrors.IsNotFound(err) {\n+\t\t\treturn nil, nil, fmt.Errorf(\"could not find resource in repository: %w\", err)\n+\t\t}\n+\n+\t\tparsed, err := r.parser.Parse(ctx, fileInfo)\n+\t\tif err != nil {\n+\t\t\treturn nil, nil, fmt.Errorf(\"could not parse resource: %w\", err)\n+\t\t}\n+\n+\t\tparsedResources[i] = parsed\n+\t}\n+\n+\treturn parsedResources, foldersInFolder, nil\n+}\n+\n+func (r *DualReadWriter) deleteChildren(ctx context.Context, childrenResources []*ParsedResource, folders []Folder) error {\n+\tfor _, parsed := range childrenResources {\n+\t\terr := parsed.Client.Delete(ctx, parsed.Obj.GetName(), metav1.DeleteOptions{})\n+\t\tif err != nil && !apierrors.IsNotFound(err) {\n+\t\t\treturn fmt.Errorf(\"failed to delete nested resource from grafana: %w\", err)\n+\t\t}\n+\t}\n+\n+\t// we need to delete the folders furthest down in the tree first, as folder deletion will fail if there is anything inside of it\n+\tsort.Slice(folders, func(i, j int) bool {",
    "repo_full_name": "grafana/grafana",
    "discussion_comments": [
      {
        "comment_id": "2176685365",
        "repo_full_name": "grafana/grafana",
        "pr_number": 107435,
        "pr_file": "pkg/registry/apis/provisioning/resources/dualwriter.go",
        "discussion_id": "2176685365",
        "commented_code": "@@ -317,3 +337,126 @@ func (r *DualReadWriter) authorizeCreateFolder(ctx context.Context, _ string) er\n \treturn apierrors.NewForbidden(FolderResource.GroupResource(), \"\",\n \t\tfmt.Errorf(\"must be admin or editor to access folders with provisioning\"))\n }\n+\n+func (r *DualReadWriter) deleteFolder(ctx context.Context, opts DualWriteOptions) (*ParsedResource, error) {\n+\t// if the ref is not the active branch, just delete the files from the branch\n+\t// do not delete the items from grafana itself\n+\tif opts.Ref != \"\" && opts.Ref != r.getConfiguredBranch() {\n+\t\terr := r.repo.Delete(ctx, opts.Path, opts.Ref, opts.Message)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"error deleting folder from repository: %w\", err)\n+\t\t}\n+\n+\t\treturn folderDeleteResponse(opts.Path, opts.Ref, r.repo.Config()), nil\n+\t}\n+\n+\t// before deleting from the repo, first get all children resources to delete from grafana afterwards\n+\ttreeEntries, err := r.repo.ReadTree(ctx, \"\")\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"read repository tree: %w\", err)\n+\t}\n+\t// note: parsedFolders will include the folder itself\n+\tparsedResources, parsedFolders, err := r.getChildren(ctx, opts.Path, treeEntries)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"parse resources in folder: %w\", err)\n+\t}\n+\n+\t// delete from the repo\n+\terr = r.repo.Delete(ctx, opts.Path, opts.Ref, opts.Message)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"delete folder from repository: %w\", err)\n+\t}\n+\n+\t// delete from grafana\n+\tctx, _, err = identity.WithProvisioningIdentity(ctx, r.repo.Config().Namespace)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tif err := r.deleteChildren(ctx, parsedResources, parsedFolders); err != nil {\n+\t\treturn nil, fmt.Errorf(\"delete folder from grafana: %w\", err)\n+\t}\n+\n+\treturn folderDeleteResponse(opts.Path, opts.Ref, r.repo.Config()), nil\n+}\n+\n+func folderDeleteResponse(path, ref string, cfg *provisioning.Repository) *ParsedResource {\n+\treturn &ParsedResource{\n+\t\tAction: provisioning.ResourceActionDelete,\n+\t\tInfo: &repository.FileInfo{\n+\t\t\tPath: path,\n+\t\t\tRef:  ref,\n+\t\t},\n+\t\tGVK: schema.GroupVersionKind{\n+\t\t\tGroup:   FolderResource.Group,\n+\t\t\tVersion: FolderResource.Version,\n+\t\t\tKind:    \"Folder\",\n+\t\t},\n+\t\tGVR: FolderResource,\n+\t\tRepo: provisioning.ResourceRepositoryInfo{\n+\t\t\tType:      cfg.Spec.Type,\n+\t\t\tNamespace: cfg.Namespace,\n+\t\t\tName:      cfg.Name,\n+\t\t\tTitle:     cfg.Spec.Title,\n+\t\t},\n+\t}\n+}\n+\n+func (r *DualReadWriter) getChildren(ctx context.Context, folderPath string, treeEntries []repository.FileTreeEntry) ([]*ParsedResource, []Folder, error) {\n+\tvar resourcesInFolder []repository.FileTreeEntry\n+\tvar foldersInFolder []Folder\n+\tfor _, entry := range treeEntries {\n+\t\t// the folder itself should be included in this, to do that, trim the suffix of the folder path and see if it matches exactly\n+\t\tif !strings.HasPrefix(entry.Path, folderPath) && entry.Path != strings.TrimSuffix(folderPath, \"/\") {\n+\t\t\tcontinue\n+\t\t}\n+\t\t// folders cannot be parsed as resources, so handle them separately\n+\t\tif entry.Blob {\n+\t\t\tresourcesInFolder = append(resourcesInFolder, entry)\n+\t\t} else {\n+\t\t\tfolder := ParseFolder(entry.Path, r.repo.Config().Name)\n+\t\t\tfoldersInFolder = append(foldersInFolder, folder)\n+\t\t}\n+\t}\n+\n+\tparsedResources := make([]*ParsedResource, len(resourcesInFolder))\n+\tfor i, entry := range resourcesInFolder {\n+\t\tfileInfo, err := r.repo.Read(ctx, entry.Path, \"\")\n+\t\tif err != nil && !apierrors.IsNotFound(err) {\n+\t\t\treturn nil, nil, fmt.Errorf(\"could not find resource in repository: %w\", err)\n+\t\t}\n+\n+\t\tparsed, err := r.parser.Parse(ctx, fileInfo)\n+\t\tif err != nil {\n+\t\t\treturn nil, nil, fmt.Errorf(\"could not parse resource: %w\", err)\n+\t\t}\n+\n+\t\tparsedResources[i] = parsed\n+\t}\n+\n+\treturn parsedResources, foldersInFolder, nil\n+}\n+\n+func (r *DualReadWriter) deleteChildren(ctx context.Context, childrenResources []*ParsedResource, folders []Folder) error {\n+\tfor _, parsed := range childrenResources {\n+\t\terr := parsed.Client.Delete(ctx, parsed.Obj.GetName(), metav1.DeleteOptions{})\n+\t\tif err != nil && !apierrors.IsNotFound(err) {\n+\t\t\treturn fmt.Errorf(\"failed to delete nested resource from grafana: %w\", err)\n+\t\t}\n+\t}\n+\n+\t// we need to delete the folders furthest down in the tree first, as folder deletion will fail if there is anything inside of it\n+\tsort.Slice(folders, func(i, j int) bool {",
        "comment_created_at": "2025-07-01T07:43:34+00:00",
        "comment_author": "MissingRoberto",
        "comment_body": "We are doing sorting in different spots. I guess it would make sense to align them so that we know that the dualwriter works in the same way as the sync. At least sorting the same way. \r\n\r\nhttps://github.com/grafana/grafana/blob/d7a41825ddff0b046e6d90e869923bade1fb2fd2/pkg/registry/apis/provisioning/jobs/sync/changes.go?plain=1#L145-L156\r\n\r\n\r\nhttps://github.com/grafana/grafana/blob/d7a41825ddff0b046e6d90e869923bade1fb2fd2/pkg/registry/apis/provisioning/resources/tree.go?plain=1#L98-L101",
        "pr_file_module": null
      },
      {
        "comment_id": "2181571916",
        "repo_full_name": "grafana/grafana",
        "pr_number": 107435,
        "pr_file": "pkg/registry/apis/provisioning/resources/dualwriter.go",
        "discussion_id": "2176685365",
        "commented_code": "@@ -317,3 +337,126 @@ func (r *DualReadWriter) authorizeCreateFolder(ctx context.Context, _ string) er\n \treturn apierrors.NewForbidden(FolderResource.GroupResource(), \"\",\n \t\tfmt.Errorf(\"must be admin or editor to access folders with provisioning\"))\n }\n+\n+func (r *DualReadWriter) deleteFolder(ctx context.Context, opts DualWriteOptions) (*ParsedResource, error) {\n+\t// if the ref is not the active branch, just delete the files from the branch\n+\t// do not delete the items from grafana itself\n+\tif opts.Ref != \"\" && opts.Ref != r.getConfiguredBranch() {\n+\t\terr := r.repo.Delete(ctx, opts.Path, opts.Ref, opts.Message)\n+\t\tif err != nil {\n+\t\t\treturn nil, fmt.Errorf(\"error deleting folder from repository: %w\", err)\n+\t\t}\n+\n+\t\treturn folderDeleteResponse(opts.Path, opts.Ref, r.repo.Config()), nil\n+\t}\n+\n+\t// before deleting from the repo, first get all children resources to delete from grafana afterwards\n+\ttreeEntries, err := r.repo.ReadTree(ctx, \"\")\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"read repository tree: %w\", err)\n+\t}\n+\t// note: parsedFolders will include the folder itself\n+\tparsedResources, parsedFolders, err := r.getChildren(ctx, opts.Path, treeEntries)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"parse resources in folder: %w\", err)\n+\t}\n+\n+\t// delete from the repo\n+\terr = r.repo.Delete(ctx, opts.Path, opts.Ref, opts.Message)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"delete folder from repository: %w\", err)\n+\t}\n+\n+\t// delete from grafana\n+\tctx, _, err = identity.WithProvisioningIdentity(ctx, r.repo.Config().Namespace)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\tif err := r.deleteChildren(ctx, parsedResources, parsedFolders); err != nil {\n+\t\treturn nil, fmt.Errorf(\"delete folder from grafana: %w\", err)\n+\t}\n+\n+\treturn folderDeleteResponse(opts.Path, opts.Ref, r.repo.Config()), nil\n+}\n+\n+func folderDeleteResponse(path, ref string, cfg *provisioning.Repository) *ParsedResource {\n+\treturn &ParsedResource{\n+\t\tAction: provisioning.ResourceActionDelete,\n+\t\tInfo: &repository.FileInfo{\n+\t\t\tPath: path,\n+\t\t\tRef:  ref,\n+\t\t},\n+\t\tGVK: schema.GroupVersionKind{\n+\t\t\tGroup:   FolderResource.Group,\n+\t\t\tVersion: FolderResource.Version,\n+\t\t\tKind:    \"Folder\",\n+\t\t},\n+\t\tGVR: FolderResource,\n+\t\tRepo: provisioning.ResourceRepositoryInfo{\n+\t\t\tType:      cfg.Spec.Type,\n+\t\t\tNamespace: cfg.Namespace,\n+\t\t\tName:      cfg.Name,\n+\t\t\tTitle:     cfg.Spec.Title,\n+\t\t},\n+\t}\n+}\n+\n+func (r *DualReadWriter) getChildren(ctx context.Context, folderPath string, treeEntries []repository.FileTreeEntry) ([]*ParsedResource, []Folder, error) {\n+\tvar resourcesInFolder []repository.FileTreeEntry\n+\tvar foldersInFolder []Folder\n+\tfor _, entry := range treeEntries {\n+\t\t// the folder itself should be included in this, to do that, trim the suffix of the folder path and see if it matches exactly\n+\t\tif !strings.HasPrefix(entry.Path, folderPath) && entry.Path != strings.TrimSuffix(folderPath, \"/\") {\n+\t\t\tcontinue\n+\t\t}\n+\t\t// folders cannot be parsed as resources, so handle them separately\n+\t\tif entry.Blob {\n+\t\t\tresourcesInFolder = append(resourcesInFolder, entry)\n+\t\t} else {\n+\t\t\tfolder := ParseFolder(entry.Path, r.repo.Config().Name)\n+\t\t\tfoldersInFolder = append(foldersInFolder, folder)\n+\t\t}\n+\t}\n+\n+\tparsedResources := make([]*ParsedResource, len(resourcesInFolder))\n+\tfor i, entry := range resourcesInFolder {\n+\t\tfileInfo, err := r.repo.Read(ctx, entry.Path, \"\")\n+\t\tif err != nil && !apierrors.IsNotFound(err) {\n+\t\t\treturn nil, nil, fmt.Errorf(\"could not find resource in repository: %w\", err)\n+\t\t}\n+\n+\t\tparsed, err := r.parser.Parse(ctx, fileInfo)\n+\t\tif err != nil {\n+\t\t\treturn nil, nil, fmt.Errorf(\"could not parse resource: %w\", err)\n+\t\t}\n+\n+\t\tparsedResources[i] = parsed\n+\t}\n+\n+\treturn parsedResources, foldersInFolder, nil\n+}\n+\n+func (r *DualReadWriter) deleteChildren(ctx context.Context, childrenResources []*ParsedResource, folders []Folder) error {\n+\tfor _, parsed := range childrenResources {\n+\t\terr := parsed.Client.Delete(ctx, parsed.Obj.GetName(), metav1.DeleteOptions{})\n+\t\tif err != nil && !apierrors.IsNotFound(err) {\n+\t\t\treturn fmt.Errorf(\"failed to delete nested resource from grafana: %w\", err)\n+\t\t}\n+\t}\n+\n+\t// we need to delete the folders furthest down in the tree first, as folder deletion will fail if there is anything inside of it\n+\tsort.Slice(folders, func(i, j int) bool {",
        "comment_created_at": "2025-07-03T03:38:22+00:00",
        "comment_author": "stephaniehingtgen",
        "comment_body": "Updated!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2177470955",
    "pr_number": 107305,
    "pr_file": "pkg/storage/unified/resource/storage_backend.go",
    "created_at": "2025-07-01T12:22:53+00:00",
    "commented_code": "+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"math/rand/v2\"\n+\t\"net/http\"\n+\t\"sort\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/bwmarrin/snowflake\"\n+\t\"github.com/grafana/grafana/pkg/apimachinery/utils\"\n+\t\"github.com/grafana/grafana/pkg/storage/unified/resourcepb\"\n+\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n+)\n+\n+const (\n+\tdefaultListBufferSize = 100\n+)\n+\n+// Unified storage backend based on KV storage.\n+type kvStorageBackend struct {\n+\tsnowflake  *snowflake.Node\n+\tkv         KV\n+\tdataStore  *dataStore\n+\tmetaStore  *metadataStore\n+\teventStore *eventStore\n+\tnotifier   *notifier\n+\tbuilder    DocumentBuilder\n+}\n+\n+var _ StorageBackend = &kvStorageBackend{}\n+\n+func NewkvStorageBackend(kv KV) *kvStorageBackend {\n+\ts, err := snowflake.NewNode(rand.Int64N(1024))\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\teventStore := newEventStore(kv)\n+\treturn &kvStorageBackend{\n+\t\tkv:         kv,\n+\t\tdataStore:  newDataStore(kv),\n+\t\tmetaStore:  newMetadataStore(kv),\n+\t\teventStore: eventStore,\n+\t\tnotifier:   newNotifier(eventStore, notifierOptions{}),\n+\t\tsnowflake:  s,\n+\t\tbuilder:    StandardDocumentBuilder(), // For now we use the standard document builder.\n+\t}\n+}\n+\n+// WriteEvent writes a resource event (create/update/delete) to the storage backend.\n+func (k *kvStorageBackend) WriteEvent(ctx context.Context, event WriteEvent) (int64, error) {\n+\tif err := event.Validate(); err != nil {\n+\t\treturn 0, fmt.Errorf(\"invalid event: %w\", err)\n+\t}\n+\trv := k.snowflake.Generate().Int64()\n+\n+\t// Write data.\n+\tvar action DataAction\n+\tswitch event.Type {\n+\tcase resourcepb.WatchEvent_ADDED:\n+\t\taction = DataActionCreated\n+\t\t// Check if resource already exists for create operations\n+\t\t_, err := k.metaStore.GetLatestResourceKey(ctx, MetaGetRequestKey{\n+\t\t\tNamespace: event.Key.Namespace,\n+\t\t\tGroup:     event.Key.Group,\n+\t\t\tResource:  event.Key.Resource,\n+\t\t\tName:      event.Key.Name,\n+\t\t})\n+\t\tif err == nil {\n+\t\t\t// Resource exists, return already exists error\n+\t\t\treturn 0, ErrResourceAlreadyExists\n+\t\t}\n+\t\tif !errors.Is(err, ErrNotFound) {\n+\t\t\t// Some other error occurred\n+\t\t\treturn 0, fmt.Errorf(\"failed to check if resource exists: %w\", err)\n+\t\t}\n+\tcase resourcepb.WatchEvent_MODIFIED:\n+\t\taction = DataActionUpdated\n+\tcase resourcepb.WatchEvent_DELETED:\n+\t\taction = DataActionDeleted\n+\tdefault:\n+\t\treturn 0, fmt.Errorf(\"invalid event type: %d\", event.Type)\n+\t}\n+\n+\t// Build the search document\n+\tdoc, err := k.builder.BuildDocument(ctx, event.Key, rv, event.Value)\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to build document: %w\", err)\n+\t}\n+\n+\t// Write the data\n+\terr = k.dataStore.Save(ctx, DataKey{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t}, io.NopCloser(bytes.NewReader(event.Value)))\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write data: %w\", err)\n+\t}\n+\n+\t// Write metadata\n+\terr = k.metaStore.Save(ctx, MetaDataObj{\n+\t\tKey: MetaDataKey{\n+\t\t\tNamespace:       event.Key.Namespace,\n+\t\t\tGroup:           event.Key.Group,\n+\t\t\tResource:        event.Key.Resource,\n+\t\t\tName:            event.Key.Name,\n+\t\t\tResourceVersion: rv,\n+\t\t\tAction:          action,\n+\t\t\tFolder:          event.Object.GetFolder(),\n+\t\t},\n+\t\tValue: MetaData{\n+\t\t\tIndexableDocument: *doc,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write metadata: %w\", err)\n+\t}\n+\n+\t// Write event\n+\terr = k.eventStore.Save(ctx, Event{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t\tFolder:          event.Object.GetFolder(),\n+\t\tPreviousRV:      event.PreviousRV,\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to save event: %w\", err)\n+\t}\n+\treturn rv, nil\n+}\n+\n+func (k *kvStorageBackend) ReadResource(ctx context.Context, req *resourcepb.ReadRequest) *BackendReadResponse {\n+\tif req.Key == nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusBadRequest, Message: \"missing key\"}}\n+\t}\n+\tmeta, err := k.metaStore.GetResourceKeyAtRevision(ctx, MetaGetRequestKey{\n+\t\tNamespace: req.Key.Namespace,\n+\t\tGroup:     req.Key.Group,\n+\t\tResource:  req.Key.Resource,\n+\t\tName:      req.Key.Name,\n+\t}, req.ResourceVersion)\n+\tif errors.Is(err, ErrNotFound) {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusNotFound, Message: \"not found\"}}\n+\t} else if err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tdata, err := k.dataStore.Get(ctx, DataKey{\n+\t\tNamespace:       req.Key.Namespace,\n+\t\tGroup:           req.Key.Group,\n+\t\tResource:        req.Key.Resource,\n+\t\tName:            req.Key.Name,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tAction:          meta.Action,\n+\t})\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tvalue, err := io.ReadAll(data)\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\treturn &BackendReadResponse{\n+\t\tKey:             req.Key,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tValue:           value,\n+\t\tFolder:          meta.Folder,\n+\t}\n+}\n+\n+// // ListIterator returns an iterator for listing resources.\n+func (k *kvStorageBackend) ListIterator(ctx context.Context, req *resourcepb.ListRequest, cb func(ListIterator) error) (int64, error) {\n+\tif req.Options == nil || req.Options.Key == nil {\n+\t\treturn 0, fmt.Errorf(\"missing options or key in ListRequest\")\n+\t}\n+\t// Parse continue token if provided\n+\toffset := int64(0)\n+\tresourceVersion := req.ResourceVersion\n+\tif req.NextPageToken != \"\" {\n+\t\ttoken, err := GetContinueToken(req.NextPageToken)\n+\t\tif err != nil {\n+\t\t\treturn 0, fmt.Errorf(\"invalid continue token: %w\", err)\n+\t\t}\n+\t\toffset = token.StartOffset\n+\t\tresourceVersion = token.ResourceVersion\n+\t}\n+\n+\t// We set the listRV to the current time.\n+\tlistRV := k.snowflake.Generate().Int64()\n+\tif resourceVersion > 0 {\n+\t\tlistRV = resourceVersion\n+\t}\n+\n+\t// Fetch the latest objects\n+\tkeys := make([]MetaDataKey, 0, min(defaultListBufferSize, req.Limit+1))\n+\tidx := 0\n+\tfor metaKey, err := range k.metaStore.ListResourceKeysAtRevision(ctx, MetaListRequestKey{\n+\t\tNamespace: req.Options.Key.Namespace,\n+\t\tGroup:     req.Options.Key.Group,\n+\t\tResource:  req.Options.Key.Resource,\n+\t\tName:      req.Options.Key.Name,\n+\t}, resourceVersion) {\n+\t\tif err != nil {\n+\t\t\treturn 0, err\n+\t\t}\n+\t\t// Skip the first offset items. This is not efficient, but it's a simple way to implement it for now.\n+\t\tif idx < int(offset) {\n+\t\t\tidx++\n+\t\t\tcontinue\n+\t\t}\n+\t\tkeys = append(keys, metaKey)\n+\t\t// Only fetch the first limit items + 1 to get the next token.\n+\t\tif len(keys) >= int(req.Limit+1) {\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\titer := kvListIterator{\n+\t\tkeys:         keys,\n+\t\tcurrentIndex: -1,\n+\t\tctx:          ctx,\n+\t\tlistRV:       listRV,\n+\t\toffset:       offset,\n+\t\tdataStore:    k.dataStore,\n+\t}\n+\terr := cb(&iter)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\treturn listRV, nil\n+}\n+\n+// kvListIterator implements ListIterator for KV storage\n+type kvListIterator struct {\n+\tctx          context.Context\n+\tkeys         []MetaDataKey\n+\tcurrentIndex int\n+\tdataStore    *dataStore\n+\tlistRV       int64\n+\toffset       int64\n+\n+\t// current\n+\trv    int64\n+\terr   error\n+\tvalue []byte\n+}\n+\n+func (i *kvListIterator) Next() bool {\n+\ti.currentIndex++\n+\n+\tif i.currentIndex >= len(i.keys) {\n+\t\treturn false\n+\t}\n+\n+\ti.rv, i.err = i.keys[i.currentIndex].ResourceVersion, nil\n+\n+\tdata, err := i.dataStore.Get(i.ctx, DataKey{\n+\t\tNamespace:       i.keys[i.currentIndex].Namespace,\n+\t\tGroup:           i.keys[i.currentIndex].Group,\n+\t\tResource:        i.keys[i.currentIndex].Resource,\n+\t\tName:            i.keys[i.currentIndex].Name,\n+\t\tResourceVersion: i.keys[i.currentIndex].ResourceVersion,\n+\t\tAction:          i.keys[i.currentIndex].Action,\n+\t})\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\n+\ti.value, i.err = io.ReadAll(data)\n+\tif i.err != nil {\n+\t\treturn false\n+\t}\n+\n+\t// increment the offset\n+\ti.offset++\n+\n+\treturn true\n+}\n+\n+func (i *kvListIterator) Error() error {\n+\treturn nil\n+}\n+\n+func (i *kvListIterator) ContinueToken() string {\n+\treturn ContinueToken{\n+\t\tStartOffset:     i.offset,\n+\t\tResourceVersion: i.listRV,\n+\t}.String()\n+}\n+\n+func (i *kvListIterator) ResourceVersion() int64 {\n+\treturn i.rv\n+}\n+\n+func (i *kvListIterator) Namespace() string {\n+\treturn i.keys[i.currentIndex].Namespace\n+}\n+\n+func (i *kvListIterator) Name() string {\n+\treturn i.keys[i.currentIndex].Name\n+}\n+\n+func (i *kvListIterator) Folder() string {\n+\treturn i.keys[i.currentIndex].Folder\n+}\n+\n+func (i *kvListIterator) Value() []byte {\n+\treturn i.value\n+}\n+\n+func validateListHistoryRequest(req *resourcepb.ListRequest) error {\n+\tif req.Options == nil || req.Options.Key == nil {\n+\t\treturn fmt.Errorf(\"missing options or key in ListRequest\")\n+\t}\n+\tkey := req.Options.Key\n+\tif key.Group == \"\" {\n+\t\treturn fmt.Errorf(\"group is required\")\n+\t}\n+\tif key.Resource == \"\" {\n+\t\treturn fmt.Errorf(\"resource is required\")\n+\t}\n+\tif key.Namespace == \"\" {\n+\t\treturn fmt.Errorf(\"namespace is required\")\n+\t}\n+\tif key.Name == \"\" {\n+\t\treturn fmt.Errorf(\"name is required\")\n+\t}\n+\treturn nil\n+}\n+\n+// filterHistoryKeysByVersion filters history keys based on version match criteria\n+func filterHistoryKeysByVersion(historyKeys []DataKey, req *resourcepb.ListRequest) ([]DataKey, error) {\n+\tswitch req.GetVersionMatchV2() {\n+\tcase resourcepb.ResourceVersionMatchV2_Exact:\n+\t\tif req.ResourceVersion <= 0 {\n+\t\t\treturn nil, fmt.Errorf(\"expecting an explicit resource version query when using Exact matching\")\n+\t\t}\n+\t\tvar exactKeys []DataKey\n+\t\tfor _, key := range historyKeys {\n+\t\t\tif key.ResourceVersion == req.ResourceVersion {\n+\t\t\t\texactKeys = append(exactKeys, key)\n+\t\t\t}\n+\t\t}\n+\t\treturn exactKeys, nil\n+\tcase resourcepb.ResourceVersionMatchV2_NotOlderThan:\n+\t\tif req.ResourceVersion > 0 {\n+\t\t\tvar filteredKeys []DataKey\n+\t\t\tfor _, key := range historyKeys {\n+\t\t\t\tif key.ResourceVersion >= req.ResourceVersion {\n+\t\t\t\t\tfilteredKeys = append(filteredKeys, key)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn filteredKeys, nil\n+\t\t}\n+\tdefault:\n+\t\tif req.ResourceVersion > 0 {\n+\t\t\tvar filteredKeys []DataKey\n+\t\t\tfor _, key := range historyKeys {\n+\t\t\t\tif key.ResourceVersion <= req.ResourceVersion {\n+\t\t\t\t\tfilteredKeys = append(filteredKeys, key)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn filteredKeys, nil\n+\t\t}\n+\t}\n+\treturn historyKeys, nil\n+}\n+\n+// applyLiveHistoryFilter applies \"live\" history logic by ignoring events before the last delete\n+func applyLiveHistoryFilter(filteredKeys []DataKey, req *resourcepb.ListRequest) []DataKey {\n+\tuseLatestDeletionAsMinRV := req.ResourceVersion == 0 && req.Source != resourcepb.ListRequest_TRASH && req.GetVersionMatchV2() != resourcepb.ResourceVersionMatchV2_Exact\n+\tif !useLatestDeletionAsMinRV {\n+\t\treturn filteredKeys\n+\t}\n+\n+\tlatestDeleteRV := int64(0)\n+\tfor _, key := range filteredKeys {\n+\t\tif key.Action == DataActionDeleted && key.ResourceVersion > latestDeleteRV {\n+\t\t\tlatestDeleteRV = key.ResourceVersion\n+\t\t}\n+\t}\n+\tif latestDeleteRV > 0 {\n+\t\tvar liveKeys []DataKey\n+\t\tfor _, key := range filteredKeys {\n+\t\t\tif key.ResourceVersion > latestDeleteRV {\n+\t\t\t\tliveKeys = append(liveKeys, key)\n+\t\t\t}\n+\t\t}\n+\t\treturn liveKeys\n+\t}\n+\treturn filteredKeys\n+}\n+\n+// sortHistoryKeys sorts the history keys based on the sortAscending flag\n+func sortHistoryKeys(filteredKeys []DataKey, sortAscending bool) {",
    "repo_full_name": "grafana/grafana",
    "discussion_comments": [
      {
        "comment_id": "2177470955",
        "repo_full_name": "grafana/grafana",
        "pr_number": 107305,
        "pr_file": "pkg/storage/unified/resource/storage_backend.go",
        "discussion_id": "2177470955",
        "commented_code": "@@ -0,0 +1,777 @@\n+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"math/rand/v2\"\n+\t\"net/http\"\n+\t\"sort\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/bwmarrin/snowflake\"\n+\t\"github.com/grafana/grafana/pkg/apimachinery/utils\"\n+\t\"github.com/grafana/grafana/pkg/storage/unified/resourcepb\"\n+\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n+)\n+\n+const (\n+\tdefaultListBufferSize = 100\n+)\n+\n+// Unified storage backend based on KV storage.\n+type kvStorageBackend struct {\n+\tsnowflake  *snowflake.Node\n+\tkv         KV\n+\tdataStore  *dataStore\n+\tmetaStore  *metadataStore\n+\teventStore *eventStore\n+\tnotifier   *notifier\n+\tbuilder    DocumentBuilder\n+}\n+\n+var _ StorageBackend = &kvStorageBackend{}\n+\n+func NewkvStorageBackend(kv KV) *kvStorageBackend {\n+\ts, err := snowflake.NewNode(rand.Int64N(1024))\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\teventStore := newEventStore(kv)\n+\treturn &kvStorageBackend{\n+\t\tkv:         kv,\n+\t\tdataStore:  newDataStore(kv),\n+\t\tmetaStore:  newMetadataStore(kv),\n+\t\teventStore: eventStore,\n+\t\tnotifier:   newNotifier(eventStore, notifierOptions{}),\n+\t\tsnowflake:  s,\n+\t\tbuilder:    StandardDocumentBuilder(), // For now we use the standard document builder.\n+\t}\n+}\n+\n+// WriteEvent writes a resource event (create/update/delete) to the storage backend.\n+func (k *kvStorageBackend) WriteEvent(ctx context.Context, event WriteEvent) (int64, error) {\n+\tif err := event.Validate(); err != nil {\n+\t\treturn 0, fmt.Errorf(\"invalid event: %w\", err)\n+\t}\n+\trv := k.snowflake.Generate().Int64()\n+\n+\t// Write data.\n+\tvar action DataAction\n+\tswitch event.Type {\n+\tcase resourcepb.WatchEvent_ADDED:\n+\t\taction = DataActionCreated\n+\t\t// Check if resource already exists for create operations\n+\t\t_, err := k.metaStore.GetLatestResourceKey(ctx, MetaGetRequestKey{\n+\t\t\tNamespace: event.Key.Namespace,\n+\t\t\tGroup:     event.Key.Group,\n+\t\t\tResource:  event.Key.Resource,\n+\t\t\tName:      event.Key.Name,\n+\t\t})\n+\t\tif err == nil {\n+\t\t\t// Resource exists, return already exists error\n+\t\t\treturn 0, ErrResourceAlreadyExists\n+\t\t}\n+\t\tif !errors.Is(err, ErrNotFound) {\n+\t\t\t// Some other error occurred\n+\t\t\treturn 0, fmt.Errorf(\"failed to check if resource exists: %w\", err)\n+\t\t}\n+\tcase resourcepb.WatchEvent_MODIFIED:\n+\t\taction = DataActionUpdated\n+\tcase resourcepb.WatchEvent_DELETED:\n+\t\taction = DataActionDeleted\n+\tdefault:\n+\t\treturn 0, fmt.Errorf(\"invalid event type: %d\", event.Type)\n+\t}\n+\n+\t// Build the search document\n+\tdoc, err := k.builder.BuildDocument(ctx, event.Key, rv, event.Value)\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to build document: %w\", err)\n+\t}\n+\n+\t// Write the data\n+\terr = k.dataStore.Save(ctx, DataKey{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t}, io.NopCloser(bytes.NewReader(event.Value)))\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write data: %w\", err)\n+\t}\n+\n+\t// Write metadata\n+\terr = k.metaStore.Save(ctx, MetaDataObj{\n+\t\tKey: MetaDataKey{\n+\t\t\tNamespace:       event.Key.Namespace,\n+\t\t\tGroup:           event.Key.Group,\n+\t\t\tResource:        event.Key.Resource,\n+\t\t\tName:            event.Key.Name,\n+\t\t\tResourceVersion: rv,\n+\t\t\tAction:          action,\n+\t\t\tFolder:          event.Object.GetFolder(),\n+\t\t},\n+\t\tValue: MetaData{\n+\t\t\tIndexableDocument: *doc,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write metadata: %w\", err)\n+\t}\n+\n+\t// Write event\n+\terr = k.eventStore.Save(ctx, Event{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t\tFolder:          event.Object.GetFolder(),\n+\t\tPreviousRV:      event.PreviousRV,\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to save event: %w\", err)\n+\t}\n+\treturn rv, nil\n+}\n+\n+func (k *kvStorageBackend) ReadResource(ctx context.Context, req *resourcepb.ReadRequest) *BackendReadResponse {\n+\tif req.Key == nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusBadRequest, Message: \"missing key\"}}\n+\t}\n+\tmeta, err := k.metaStore.GetResourceKeyAtRevision(ctx, MetaGetRequestKey{\n+\t\tNamespace: req.Key.Namespace,\n+\t\tGroup:     req.Key.Group,\n+\t\tResource:  req.Key.Resource,\n+\t\tName:      req.Key.Name,\n+\t}, req.ResourceVersion)\n+\tif errors.Is(err, ErrNotFound) {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusNotFound, Message: \"not found\"}}\n+\t} else if err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tdata, err := k.dataStore.Get(ctx, DataKey{\n+\t\tNamespace:       req.Key.Namespace,\n+\t\tGroup:           req.Key.Group,\n+\t\tResource:        req.Key.Resource,\n+\t\tName:            req.Key.Name,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tAction:          meta.Action,\n+\t})\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tvalue, err := io.ReadAll(data)\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\treturn &BackendReadResponse{\n+\t\tKey:             req.Key,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tValue:           value,\n+\t\tFolder:          meta.Folder,\n+\t}\n+}\n+\n+// // ListIterator returns an iterator for listing resources.\n+func (k *kvStorageBackend) ListIterator(ctx context.Context, req *resourcepb.ListRequest, cb func(ListIterator) error) (int64, error) {\n+\tif req.Options == nil || req.Options.Key == nil {\n+\t\treturn 0, fmt.Errorf(\"missing options or key in ListRequest\")\n+\t}\n+\t// Parse continue token if provided\n+\toffset := int64(0)\n+\tresourceVersion := req.ResourceVersion\n+\tif req.NextPageToken != \"\" {\n+\t\ttoken, err := GetContinueToken(req.NextPageToken)\n+\t\tif err != nil {\n+\t\t\treturn 0, fmt.Errorf(\"invalid continue token: %w\", err)\n+\t\t}\n+\t\toffset = token.StartOffset\n+\t\tresourceVersion = token.ResourceVersion\n+\t}\n+\n+\t// We set the listRV to the current time.\n+\tlistRV := k.snowflake.Generate().Int64()\n+\tif resourceVersion > 0 {\n+\t\tlistRV = resourceVersion\n+\t}\n+\n+\t// Fetch the latest objects\n+\tkeys := make([]MetaDataKey, 0, min(defaultListBufferSize, req.Limit+1))\n+\tidx := 0\n+\tfor metaKey, err := range k.metaStore.ListResourceKeysAtRevision(ctx, MetaListRequestKey{\n+\t\tNamespace: req.Options.Key.Namespace,\n+\t\tGroup:     req.Options.Key.Group,\n+\t\tResource:  req.Options.Key.Resource,\n+\t\tName:      req.Options.Key.Name,\n+\t}, resourceVersion) {\n+\t\tif err != nil {\n+\t\t\treturn 0, err\n+\t\t}\n+\t\t// Skip the first offset items. This is not efficient, but it's a simple way to implement it for now.\n+\t\tif idx < int(offset) {\n+\t\t\tidx++\n+\t\t\tcontinue\n+\t\t}\n+\t\tkeys = append(keys, metaKey)\n+\t\t// Only fetch the first limit items + 1 to get the next token.\n+\t\tif len(keys) >= int(req.Limit+1) {\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\titer := kvListIterator{\n+\t\tkeys:         keys,\n+\t\tcurrentIndex: -1,\n+\t\tctx:          ctx,\n+\t\tlistRV:       listRV,\n+\t\toffset:       offset,\n+\t\tdataStore:    k.dataStore,\n+\t}\n+\terr := cb(&iter)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\treturn listRV, nil\n+}\n+\n+// kvListIterator implements ListIterator for KV storage\n+type kvListIterator struct {\n+\tctx          context.Context\n+\tkeys         []MetaDataKey\n+\tcurrentIndex int\n+\tdataStore    *dataStore\n+\tlistRV       int64\n+\toffset       int64\n+\n+\t// current\n+\trv    int64\n+\terr   error\n+\tvalue []byte\n+}\n+\n+func (i *kvListIterator) Next() bool {\n+\ti.currentIndex++\n+\n+\tif i.currentIndex >= len(i.keys) {\n+\t\treturn false\n+\t}\n+\n+\ti.rv, i.err = i.keys[i.currentIndex].ResourceVersion, nil\n+\n+\tdata, err := i.dataStore.Get(i.ctx, DataKey{\n+\t\tNamespace:       i.keys[i.currentIndex].Namespace,\n+\t\tGroup:           i.keys[i.currentIndex].Group,\n+\t\tResource:        i.keys[i.currentIndex].Resource,\n+\t\tName:            i.keys[i.currentIndex].Name,\n+\t\tResourceVersion: i.keys[i.currentIndex].ResourceVersion,\n+\t\tAction:          i.keys[i.currentIndex].Action,\n+\t})\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\n+\ti.value, i.err = io.ReadAll(data)\n+\tif i.err != nil {\n+\t\treturn false\n+\t}\n+\n+\t// increment the offset\n+\ti.offset++\n+\n+\treturn true\n+}\n+\n+func (i *kvListIterator) Error() error {\n+\treturn nil\n+}\n+\n+func (i *kvListIterator) ContinueToken() string {\n+\treturn ContinueToken{\n+\t\tStartOffset:     i.offset,\n+\t\tResourceVersion: i.listRV,\n+\t}.String()\n+}\n+\n+func (i *kvListIterator) ResourceVersion() int64 {\n+\treturn i.rv\n+}\n+\n+func (i *kvListIterator) Namespace() string {\n+\treturn i.keys[i.currentIndex].Namespace\n+}\n+\n+func (i *kvListIterator) Name() string {\n+\treturn i.keys[i.currentIndex].Name\n+}\n+\n+func (i *kvListIterator) Folder() string {\n+\treturn i.keys[i.currentIndex].Folder\n+}\n+\n+func (i *kvListIterator) Value() []byte {\n+\treturn i.value\n+}\n+\n+func validateListHistoryRequest(req *resourcepb.ListRequest) error {\n+\tif req.Options == nil || req.Options.Key == nil {\n+\t\treturn fmt.Errorf(\"missing options or key in ListRequest\")\n+\t}\n+\tkey := req.Options.Key\n+\tif key.Group == \"\" {\n+\t\treturn fmt.Errorf(\"group is required\")\n+\t}\n+\tif key.Resource == \"\" {\n+\t\treturn fmt.Errorf(\"resource is required\")\n+\t}\n+\tif key.Namespace == \"\" {\n+\t\treturn fmt.Errorf(\"namespace is required\")\n+\t}\n+\tif key.Name == \"\" {\n+\t\treturn fmt.Errorf(\"name is required\")\n+\t}\n+\treturn nil\n+}\n+\n+// filterHistoryKeysByVersion filters history keys based on version match criteria\n+func filterHistoryKeysByVersion(historyKeys []DataKey, req *resourcepb.ListRequest) ([]DataKey, error) {\n+\tswitch req.GetVersionMatchV2() {\n+\tcase resourcepb.ResourceVersionMatchV2_Exact:\n+\t\tif req.ResourceVersion <= 0 {\n+\t\t\treturn nil, fmt.Errorf(\"expecting an explicit resource version query when using Exact matching\")\n+\t\t}\n+\t\tvar exactKeys []DataKey\n+\t\tfor _, key := range historyKeys {\n+\t\t\tif key.ResourceVersion == req.ResourceVersion {\n+\t\t\t\texactKeys = append(exactKeys, key)\n+\t\t\t}\n+\t\t}\n+\t\treturn exactKeys, nil\n+\tcase resourcepb.ResourceVersionMatchV2_NotOlderThan:\n+\t\tif req.ResourceVersion > 0 {\n+\t\t\tvar filteredKeys []DataKey\n+\t\t\tfor _, key := range historyKeys {\n+\t\t\t\tif key.ResourceVersion >= req.ResourceVersion {\n+\t\t\t\t\tfilteredKeys = append(filteredKeys, key)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn filteredKeys, nil\n+\t\t}\n+\tdefault:\n+\t\tif req.ResourceVersion > 0 {\n+\t\t\tvar filteredKeys []DataKey\n+\t\t\tfor _, key := range historyKeys {\n+\t\t\t\tif key.ResourceVersion <= req.ResourceVersion {\n+\t\t\t\t\tfilteredKeys = append(filteredKeys, key)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn filteredKeys, nil\n+\t\t}\n+\t}\n+\treturn historyKeys, nil\n+}\n+\n+// applyLiveHistoryFilter applies \"live\" history logic by ignoring events before the last delete\n+func applyLiveHistoryFilter(filteredKeys []DataKey, req *resourcepb.ListRequest) []DataKey {\n+\tuseLatestDeletionAsMinRV := req.ResourceVersion == 0 && req.Source != resourcepb.ListRequest_TRASH && req.GetVersionMatchV2() != resourcepb.ResourceVersionMatchV2_Exact\n+\tif !useLatestDeletionAsMinRV {\n+\t\treturn filteredKeys\n+\t}\n+\n+\tlatestDeleteRV := int64(0)\n+\tfor _, key := range filteredKeys {\n+\t\tif key.Action == DataActionDeleted && key.ResourceVersion > latestDeleteRV {\n+\t\t\tlatestDeleteRV = key.ResourceVersion\n+\t\t}\n+\t}\n+\tif latestDeleteRV > 0 {\n+\t\tvar liveKeys []DataKey\n+\t\tfor _, key := range filteredKeys {\n+\t\t\tif key.ResourceVersion > latestDeleteRV {\n+\t\t\t\tliveKeys = append(liveKeys, key)\n+\t\t\t}\n+\t\t}\n+\t\treturn liveKeys\n+\t}\n+\treturn filteredKeys\n+}\n+\n+// sortHistoryKeys sorts the history keys based on the sortAscending flag\n+func sortHistoryKeys(filteredKeys []DataKey, sortAscending bool) {",
        "comment_created_at": "2025-07-01T12:22:53+00:00",
        "comment_author": "pstibrany",
        "comment_body": "This can break sorting by other fields of Key. If input is `[{Name: \"a\", RV: 100}, {Name: \"b\", RV: 10}]`, this function will return `[\"b\", \"a\"]`. Is that OK? We should document it as the name suggests that this is sorting by \"keys\", not just RV.",
        "pr_file_module": null
      },
      {
        "comment_id": "2179683756",
        "repo_full_name": "grafana/grafana",
        "pr_number": 107305,
        "pr_file": "pkg/storage/unified/resource/storage_backend.go",
        "discussion_id": "2177470955",
        "commented_code": "@@ -0,0 +1,777 @@\n+package resource\n+\n+import (\n+\t\"bytes\"\n+\t\"context\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"math/rand/v2\"\n+\t\"net/http\"\n+\t\"sort\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/bwmarrin/snowflake\"\n+\t\"github.com/grafana/grafana/pkg/apimachinery/utils\"\n+\t\"github.com/grafana/grafana/pkg/storage/unified/resourcepb\"\n+\tmetav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\"\n+)\n+\n+const (\n+\tdefaultListBufferSize = 100\n+)\n+\n+// Unified storage backend based on KV storage.\n+type kvStorageBackend struct {\n+\tsnowflake  *snowflake.Node\n+\tkv         KV\n+\tdataStore  *dataStore\n+\tmetaStore  *metadataStore\n+\teventStore *eventStore\n+\tnotifier   *notifier\n+\tbuilder    DocumentBuilder\n+}\n+\n+var _ StorageBackend = &kvStorageBackend{}\n+\n+func NewkvStorageBackend(kv KV) *kvStorageBackend {\n+\ts, err := snowflake.NewNode(rand.Int64N(1024))\n+\tif err != nil {\n+\t\tpanic(err)\n+\t}\n+\teventStore := newEventStore(kv)\n+\treturn &kvStorageBackend{\n+\t\tkv:         kv,\n+\t\tdataStore:  newDataStore(kv),\n+\t\tmetaStore:  newMetadataStore(kv),\n+\t\teventStore: eventStore,\n+\t\tnotifier:   newNotifier(eventStore, notifierOptions{}),\n+\t\tsnowflake:  s,\n+\t\tbuilder:    StandardDocumentBuilder(), // For now we use the standard document builder.\n+\t}\n+}\n+\n+// WriteEvent writes a resource event (create/update/delete) to the storage backend.\n+func (k *kvStorageBackend) WriteEvent(ctx context.Context, event WriteEvent) (int64, error) {\n+\tif err := event.Validate(); err != nil {\n+\t\treturn 0, fmt.Errorf(\"invalid event: %w\", err)\n+\t}\n+\trv := k.snowflake.Generate().Int64()\n+\n+\t// Write data.\n+\tvar action DataAction\n+\tswitch event.Type {\n+\tcase resourcepb.WatchEvent_ADDED:\n+\t\taction = DataActionCreated\n+\t\t// Check if resource already exists for create operations\n+\t\t_, err := k.metaStore.GetLatestResourceKey(ctx, MetaGetRequestKey{\n+\t\t\tNamespace: event.Key.Namespace,\n+\t\t\tGroup:     event.Key.Group,\n+\t\t\tResource:  event.Key.Resource,\n+\t\t\tName:      event.Key.Name,\n+\t\t})\n+\t\tif err == nil {\n+\t\t\t// Resource exists, return already exists error\n+\t\t\treturn 0, ErrResourceAlreadyExists\n+\t\t}\n+\t\tif !errors.Is(err, ErrNotFound) {\n+\t\t\t// Some other error occurred\n+\t\t\treturn 0, fmt.Errorf(\"failed to check if resource exists: %w\", err)\n+\t\t}\n+\tcase resourcepb.WatchEvent_MODIFIED:\n+\t\taction = DataActionUpdated\n+\tcase resourcepb.WatchEvent_DELETED:\n+\t\taction = DataActionDeleted\n+\tdefault:\n+\t\treturn 0, fmt.Errorf(\"invalid event type: %d\", event.Type)\n+\t}\n+\n+\t// Build the search document\n+\tdoc, err := k.builder.BuildDocument(ctx, event.Key, rv, event.Value)\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to build document: %w\", err)\n+\t}\n+\n+\t// Write the data\n+\terr = k.dataStore.Save(ctx, DataKey{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t}, io.NopCloser(bytes.NewReader(event.Value)))\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write data: %w\", err)\n+\t}\n+\n+\t// Write metadata\n+\terr = k.metaStore.Save(ctx, MetaDataObj{\n+\t\tKey: MetaDataKey{\n+\t\t\tNamespace:       event.Key.Namespace,\n+\t\t\tGroup:           event.Key.Group,\n+\t\t\tResource:        event.Key.Resource,\n+\t\t\tName:            event.Key.Name,\n+\t\t\tResourceVersion: rv,\n+\t\t\tAction:          action,\n+\t\t\tFolder:          event.Object.GetFolder(),\n+\t\t},\n+\t\tValue: MetaData{\n+\t\t\tIndexableDocument: *doc,\n+\t\t},\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to write metadata: %w\", err)\n+\t}\n+\n+\t// Write event\n+\terr = k.eventStore.Save(ctx, Event{\n+\t\tNamespace:       event.Key.Namespace,\n+\t\tGroup:           event.Key.Group,\n+\t\tResource:        event.Key.Resource,\n+\t\tName:            event.Key.Name,\n+\t\tResourceVersion: rv,\n+\t\tAction:          action,\n+\t\tFolder:          event.Object.GetFolder(),\n+\t\tPreviousRV:      event.PreviousRV,\n+\t})\n+\tif err != nil {\n+\t\treturn 0, fmt.Errorf(\"failed to save event: %w\", err)\n+\t}\n+\treturn rv, nil\n+}\n+\n+func (k *kvStorageBackend) ReadResource(ctx context.Context, req *resourcepb.ReadRequest) *BackendReadResponse {\n+\tif req.Key == nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusBadRequest, Message: \"missing key\"}}\n+\t}\n+\tmeta, err := k.metaStore.GetResourceKeyAtRevision(ctx, MetaGetRequestKey{\n+\t\tNamespace: req.Key.Namespace,\n+\t\tGroup:     req.Key.Group,\n+\t\tResource:  req.Key.Resource,\n+\t\tName:      req.Key.Name,\n+\t}, req.ResourceVersion)\n+\tif errors.Is(err, ErrNotFound) {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusNotFound, Message: \"not found\"}}\n+\t} else if err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tdata, err := k.dataStore.Get(ctx, DataKey{\n+\t\tNamespace:       req.Key.Namespace,\n+\t\tGroup:           req.Key.Group,\n+\t\tResource:        req.Key.Resource,\n+\t\tName:            req.Key.Name,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tAction:          meta.Action,\n+\t})\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\tvalue, err := io.ReadAll(data)\n+\tif err != nil {\n+\t\treturn &BackendReadResponse{Error: &resourcepb.ErrorResult{Code: http.StatusInternalServerError, Message: err.Error()}}\n+\t}\n+\treturn &BackendReadResponse{\n+\t\tKey:             req.Key,\n+\t\tResourceVersion: meta.ResourceVersion,\n+\t\tValue:           value,\n+\t\tFolder:          meta.Folder,\n+\t}\n+}\n+\n+// // ListIterator returns an iterator for listing resources.\n+func (k *kvStorageBackend) ListIterator(ctx context.Context, req *resourcepb.ListRequest, cb func(ListIterator) error) (int64, error) {\n+\tif req.Options == nil || req.Options.Key == nil {\n+\t\treturn 0, fmt.Errorf(\"missing options or key in ListRequest\")\n+\t}\n+\t// Parse continue token if provided\n+\toffset := int64(0)\n+\tresourceVersion := req.ResourceVersion\n+\tif req.NextPageToken != \"\" {\n+\t\ttoken, err := GetContinueToken(req.NextPageToken)\n+\t\tif err != nil {\n+\t\t\treturn 0, fmt.Errorf(\"invalid continue token: %w\", err)\n+\t\t}\n+\t\toffset = token.StartOffset\n+\t\tresourceVersion = token.ResourceVersion\n+\t}\n+\n+\t// We set the listRV to the current time.\n+\tlistRV := k.snowflake.Generate().Int64()\n+\tif resourceVersion > 0 {\n+\t\tlistRV = resourceVersion\n+\t}\n+\n+\t// Fetch the latest objects\n+\tkeys := make([]MetaDataKey, 0, min(defaultListBufferSize, req.Limit+1))\n+\tidx := 0\n+\tfor metaKey, err := range k.metaStore.ListResourceKeysAtRevision(ctx, MetaListRequestKey{\n+\t\tNamespace: req.Options.Key.Namespace,\n+\t\tGroup:     req.Options.Key.Group,\n+\t\tResource:  req.Options.Key.Resource,\n+\t\tName:      req.Options.Key.Name,\n+\t}, resourceVersion) {\n+\t\tif err != nil {\n+\t\t\treturn 0, err\n+\t\t}\n+\t\t// Skip the first offset items. This is not efficient, but it's a simple way to implement it for now.\n+\t\tif idx < int(offset) {\n+\t\t\tidx++\n+\t\t\tcontinue\n+\t\t}\n+\t\tkeys = append(keys, metaKey)\n+\t\t// Only fetch the first limit items + 1 to get the next token.\n+\t\tif len(keys) >= int(req.Limit+1) {\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\titer := kvListIterator{\n+\t\tkeys:         keys,\n+\t\tcurrentIndex: -1,\n+\t\tctx:          ctx,\n+\t\tlistRV:       listRV,\n+\t\toffset:       offset,\n+\t\tdataStore:    k.dataStore,\n+\t}\n+\terr := cb(&iter)\n+\tif err != nil {\n+\t\treturn 0, err\n+\t}\n+\n+\treturn listRV, nil\n+}\n+\n+// kvListIterator implements ListIterator for KV storage\n+type kvListIterator struct {\n+\tctx          context.Context\n+\tkeys         []MetaDataKey\n+\tcurrentIndex int\n+\tdataStore    *dataStore\n+\tlistRV       int64\n+\toffset       int64\n+\n+\t// current\n+\trv    int64\n+\terr   error\n+\tvalue []byte\n+}\n+\n+func (i *kvListIterator) Next() bool {\n+\ti.currentIndex++\n+\n+\tif i.currentIndex >= len(i.keys) {\n+\t\treturn false\n+\t}\n+\n+\ti.rv, i.err = i.keys[i.currentIndex].ResourceVersion, nil\n+\n+\tdata, err := i.dataStore.Get(i.ctx, DataKey{\n+\t\tNamespace:       i.keys[i.currentIndex].Namespace,\n+\t\tGroup:           i.keys[i.currentIndex].Group,\n+\t\tResource:        i.keys[i.currentIndex].Resource,\n+\t\tName:            i.keys[i.currentIndex].Name,\n+\t\tResourceVersion: i.keys[i.currentIndex].ResourceVersion,\n+\t\tAction:          i.keys[i.currentIndex].Action,\n+\t})\n+\tif err != nil {\n+\t\ti.err = err\n+\t\treturn false\n+\t}\n+\n+\ti.value, i.err = io.ReadAll(data)\n+\tif i.err != nil {\n+\t\treturn false\n+\t}\n+\n+\t// increment the offset\n+\ti.offset++\n+\n+\treturn true\n+}\n+\n+func (i *kvListIterator) Error() error {\n+\treturn nil\n+}\n+\n+func (i *kvListIterator) ContinueToken() string {\n+\treturn ContinueToken{\n+\t\tStartOffset:     i.offset,\n+\t\tResourceVersion: i.listRV,\n+\t}.String()\n+}\n+\n+func (i *kvListIterator) ResourceVersion() int64 {\n+\treturn i.rv\n+}\n+\n+func (i *kvListIterator) Namespace() string {\n+\treturn i.keys[i.currentIndex].Namespace\n+}\n+\n+func (i *kvListIterator) Name() string {\n+\treturn i.keys[i.currentIndex].Name\n+}\n+\n+func (i *kvListIterator) Folder() string {\n+\treturn i.keys[i.currentIndex].Folder\n+}\n+\n+func (i *kvListIterator) Value() []byte {\n+\treturn i.value\n+}\n+\n+func validateListHistoryRequest(req *resourcepb.ListRequest) error {\n+\tif req.Options == nil || req.Options.Key == nil {\n+\t\treturn fmt.Errorf(\"missing options or key in ListRequest\")\n+\t}\n+\tkey := req.Options.Key\n+\tif key.Group == \"\" {\n+\t\treturn fmt.Errorf(\"group is required\")\n+\t}\n+\tif key.Resource == \"\" {\n+\t\treturn fmt.Errorf(\"resource is required\")\n+\t}\n+\tif key.Namespace == \"\" {\n+\t\treturn fmt.Errorf(\"namespace is required\")\n+\t}\n+\tif key.Name == \"\" {\n+\t\treturn fmt.Errorf(\"name is required\")\n+\t}\n+\treturn nil\n+}\n+\n+// filterHistoryKeysByVersion filters history keys based on version match criteria\n+func filterHistoryKeysByVersion(historyKeys []DataKey, req *resourcepb.ListRequest) ([]DataKey, error) {\n+\tswitch req.GetVersionMatchV2() {\n+\tcase resourcepb.ResourceVersionMatchV2_Exact:\n+\t\tif req.ResourceVersion <= 0 {\n+\t\t\treturn nil, fmt.Errorf(\"expecting an explicit resource version query when using Exact matching\")\n+\t\t}\n+\t\tvar exactKeys []DataKey\n+\t\tfor _, key := range historyKeys {\n+\t\t\tif key.ResourceVersion == req.ResourceVersion {\n+\t\t\t\texactKeys = append(exactKeys, key)\n+\t\t\t}\n+\t\t}\n+\t\treturn exactKeys, nil\n+\tcase resourcepb.ResourceVersionMatchV2_NotOlderThan:\n+\t\tif req.ResourceVersion > 0 {\n+\t\t\tvar filteredKeys []DataKey\n+\t\t\tfor _, key := range historyKeys {\n+\t\t\t\tif key.ResourceVersion >= req.ResourceVersion {\n+\t\t\t\t\tfilteredKeys = append(filteredKeys, key)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn filteredKeys, nil\n+\t\t}\n+\tdefault:\n+\t\tif req.ResourceVersion > 0 {\n+\t\t\tvar filteredKeys []DataKey\n+\t\t\tfor _, key := range historyKeys {\n+\t\t\t\tif key.ResourceVersion <= req.ResourceVersion {\n+\t\t\t\t\tfilteredKeys = append(filteredKeys, key)\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\treturn filteredKeys, nil\n+\t\t}\n+\t}\n+\treturn historyKeys, nil\n+}\n+\n+// applyLiveHistoryFilter applies \"live\" history logic by ignoring events before the last delete\n+func applyLiveHistoryFilter(filteredKeys []DataKey, req *resourcepb.ListRequest) []DataKey {\n+\tuseLatestDeletionAsMinRV := req.ResourceVersion == 0 && req.Source != resourcepb.ListRequest_TRASH && req.GetVersionMatchV2() != resourcepb.ResourceVersionMatchV2_Exact\n+\tif !useLatestDeletionAsMinRV {\n+\t\treturn filteredKeys\n+\t}\n+\n+\tlatestDeleteRV := int64(0)\n+\tfor _, key := range filteredKeys {\n+\t\tif key.Action == DataActionDeleted && key.ResourceVersion > latestDeleteRV {\n+\t\t\tlatestDeleteRV = key.ResourceVersion\n+\t\t}\n+\t}\n+\tif latestDeleteRV > 0 {\n+\t\tvar liveKeys []DataKey\n+\t\tfor _, key := range filteredKeys {\n+\t\t\tif key.ResourceVersion > latestDeleteRV {\n+\t\t\t\tliveKeys = append(liveKeys, key)\n+\t\t\t}\n+\t\t}\n+\t\treturn liveKeys\n+\t}\n+\treturn filteredKeys\n+}\n+\n+// sortHistoryKeys sorts the history keys based on the sortAscending flag\n+func sortHistoryKeys(filteredKeys []DataKey, sortAscending bool) {",
        "comment_created_at": "2025-07-02T10:17:54+00:00",
        "comment_author": "chaudyg",
        "comment_body": "Renamed the function",
        "pr_file_module": null
      }
    ]
  }
]