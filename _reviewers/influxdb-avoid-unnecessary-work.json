[
  {
    "discussion_id": "2032038916",
    "pr_number": 26211,
    "pr_file": "tsdb/engine/tsm1/engine.go",
    "created_at": "2025-04-07T21:34:17+00:00",
    "commented_code": "if level, runnable := e.scheduler.next(); runnable {\n \t\t\t\tswitch level {\n \t\t\t\tcase 1:\n-\t\t\t\t\tif e.compactHiPriorityLevel(level1Groups[0], 1, false, wg) {\n+\t\t\t\t\tif e.compactHiPriorityLevel(level1Groups[0], 1, false, wg, tsdb.DefaultMaxPointsPerBlock) {\n \t\t\t\t\t\tlevel1Groups = level1Groups[1:]\n \t\t\t\t\t}\n \t\t\t\tcase 2:\n-\t\t\t\t\tif e.compactHiPriorityLevel(level2Groups[0], 2, false, wg) {\n+\t\t\t\t\tif e.compactHiPriorityLevel(level2Groups[0], 2, false, wg, tsdb.DefaultMaxPointsPerBlock) {\n \t\t\t\t\t\tlevel2Groups = level2Groups[1:]\n \t\t\t\t\t}\n \t\t\t\tcase 3:\n-\t\t\t\t\tif e.compactLoPriorityLevel(level3Groups[0], 3, true, wg) {\n+\t\t\t\t\tif e.compactLoPriorityLevel(level3Groups[0], 3, true, wg, tsdb.DefaultMaxPointsPerBlock) {\n \t\t\t\t\t\tlevel3Groups = level3Groups[1:]\n \t\t\t\t\t}\n \t\t\t\tcase 4:\n+\t\t\t\t\tvar pointsPerBlock int\n \t\t\t\t\t// This is a heuristic. The 10_000 points per block default is suitable for when we have a\n \t\t\t\t\t// single generation with multiple files at max block size under 2 GB.\n \t\t\t\t\tif genLen == 1 {\n \t\t\t\t\t\t// Log TSM files that will have an increased points per block count.\n \t\t\t\t\t\tfor _, f := range level4Groups[0] {\n \t\t\t\t\t\t\te.logger.Info(\"TSM optimized compaction on single generation running, increasing total points per block.\", zap.String(\"path\", f), zap.Int(\"points-per-block\", e.CompactionPlan.GetAggressiveCompactionPointsPerBlock()))\n \t\t\t\t\t\t}\n-\t\t\t\t\t\te.Compactor.Size = e.CompactionPlan.GetAggressiveCompactionPointsPerBlock()\n+\t\t\t\t\t\tpointsPerBlock = tsdb.DefaultAggressiveMaxPointsPerBlock\n \t\t\t\t\t} else {\n-\t\t\t\t\t\te.Compactor.Size = tsdb.DefaultMaxPointsPerBlock\n+\t\t\t\t\t\tpointsPerBlock = tsdb.DefaultMaxPointsPerBlock\n+\t\t\t\t\t\tfor _, f := range level4Groups[0] {\n+\t\t\t\t\t\t\tif tsmPointsPerBlock := e.Compactor.FileStore.BlockCount(f, 1); tsmPointsPerBlock == tsdb.DefaultAggressiveMaxPointsPerBlock {\n+\t\t\t\t\t\t\t\tpointsPerBlock = tsdb.DefaultAggressiveMaxPointsPerBlock\n+\t\t\t\t\t\t\t}",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "2032038916",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 26211,
        "pr_file": "tsdb/engine/tsm1/engine.go",
        "discussion_id": "2032038916",
        "commented_code": "@@ -2157,30 +2165,36 @@ func (e *Engine) compact(wg *sync.WaitGroup) {\n \t\t\tif level, runnable := e.scheduler.next(); runnable {\n \t\t\t\tswitch level {\n \t\t\t\tcase 1:\n-\t\t\t\t\tif e.compactHiPriorityLevel(level1Groups[0], 1, false, wg) {\n+\t\t\t\t\tif e.compactHiPriorityLevel(level1Groups[0], 1, false, wg, tsdb.DefaultMaxPointsPerBlock) {\n \t\t\t\t\t\tlevel1Groups = level1Groups[1:]\n \t\t\t\t\t}\n \t\t\t\tcase 2:\n-\t\t\t\t\tif e.compactHiPriorityLevel(level2Groups[0], 2, false, wg) {\n+\t\t\t\t\tif e.compactHiPriorityLevel(level2Groups[0], 2, false, wg, tsdb.DefaultMaxPointsPerBlock) {\n \t\t\t\t\t\tlevel2Groups = level2Groups[1:]\n \t\t\t\t\t}\n \t\t\t\tcase 3:\n-\t\t\t\t\tif e.compactLoPriorityLevel(level3Groups[0], 3, true, wg) {\n+\t\t\t\t\tif e.compactLoPriorityLevel(level3Groups[0], 3, true, wg, tsdb.DefaultMaxPointsPerBlock) {\n \t\t\t\t\t\tlevel3Groups = level3Groups[1:]\n \t\t\t\t\t}\n \t\t\t\tcase 4:\n+\t\t\t\t\tvar pointsPerBlock int\n \t\t\t\t\t// This is a heuristic. The 10_000 points per block default is suitable for when we have a\n \t\t\t\t\t// single generation with multiple files at max block size under 2 GB.\n \t\t\t\t\tif genLen == 1 {\n \t\t\t\t\t\t// Log TSM files that will have an increased points per block count.\n \t\t\t\t\t\tfor _, f := range level4Groups[0] {\n \t\t\t\t\t\t\te.logger.Info(\"TSM optimized compaction on single generation running, increasing total points per block.\", zap.String(\"path\", f), zap.Int(\"points-per-block\", e.CompactionPlan.GetAggressiveCompactionPointsPerBlock()))\n \t\t\t\t\t\t}\n-\t\t\t\t\t\te.Compactor.Size = e.CompactionPlan.GetAggressiveCompactionPointsPerBlock()\n+\t\t\t\t\t\tpointsPerBlock = tsdb.DefaultAggressiveMaxPointsPerBlock\n \t\t\t\t\t} else {\n-\t\t\t\t\t\te.Compactor.Size = tsdb.DefaultMaxPointsPerBlock\n+\t\t\t\t\t\tpointsPerBlock = tsdb.DefaultMaxPointsPerBlock\n+\t\t\t\t\t\tfor _, f := range level4Groups[0] {\n+\t\t\t\t\t\t\tif tsmPointsPerBlock := e.Compactor.FileStore.BlockCount(f, 1); tsmPointsPerBlock == tsdb.DefaultAggressiveMaxPointsPerBlock {\n+\t\t\t\t\t\t\t\tpointsPerBlock = tsdb.DefaultAggressiveMaxPointsPerBlock\n+\t\t\t\t\t\t\t}",
        "comment_created_at": "2025-04-07T21:34:17+00:00",
        "comment_author": "gwossum",
        "comment_body": "We can break out of the loop once we decide we need to stick with the aggressive points per block to avoid going through the rest of the TSM files.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1896233680",
    "pr_number": 25594,
    "pr_file": "tsdb/engine/tsm1/compact.go",
    "created_at": "2024-12-24T00:36:43+00:00",
    "commented_code": "var skip bool\n \n \t\t\t// Skip the file if it's over the max size and contains a full block and it does not have any tombstones\n-\t\t\tif len(generations) > 2 && group.size() > uint64(maxTSMFileSize) && c.FileStore.BlockCount(group.files[0].Path, 1) == tsdb.DefaultMaxPointsPerBlock && !group.hasTombstones() {\n+\t\t\tif len(generations) > 2 && group.size() > uint64(tsdb.MaxTSMFileSize) && c.FileStore.BlockCount(group.files[0].Path, 1) == tsdb.DefaultMaxPointsPerBlock && !group.hasTombstones() {",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1896233680",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25594,
        "pr_file": "tsdb/engine/tsm1/compact.go",
        "discussion_id": "1896233680",
        "commented_code": "@@ -449,7 +469,7 @@ func (c *DefaultPlanner) Plan(lastWrite time.Time) ([]CompactionGroup, int64) {\n \t\t\tvar skip bool\n \n \t\t\t// Skip the file if it's over the max size and contains a full block and it does not have any tombstones\n-\t\t\tif len(generations) > 2 && group.size() > uint64(maxTSMFileSize) && c.FileStore.BlockCount(group.files[0].Path, 1) == tsdb.DefaultMaxPointsPerBlock && !group.hasTombstones() {\n+\t\t\tif len(generations) > 2 && group.size() > uint64(tsdb.MaxTSMFileSize) && c.FileStore.BlockCount(group.files[0].Path, 1) == tsdb.DefaultMaxPointsPerBlock && !group.hasTombstones() {",
        "comment_created_at": "2024-12-24T00:36:43+00:00",
        "comment_author": "davidby-influx",
        "comment_body": "I think the `c.FileStore.BlockCount(group.files[0].Path, 1) == tsdb.DefaultMaxPointsPerBlock` has to become a `>=` because you may produce files with the aggressive block count in an earlier compaction that you don't want to compact again.",
        "pr_file_module": null
      },
      {
        "comment_id": "1896238360",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25594,
        "pr_file": "tsdb/engine/tsm1/compact.go",
        "discussion_id": "1896233680",
        "commented_code": "@@ -449,7 +469,7 @@ func (c *DefaultPlanner) Plan(lastWrite time.Time) ([]CompactionGroup, int64) {\n \t\t\tvar skip bool\n \n \t\t\t// Skip the file if it's over the max size and contains a full block and it does not have any tombstones\n-\t\t\tif len(generations) > 2 && group.size() > uint64(maxTSMFileSize) && c.FileStore.BlockCount(group.files[0].Path, 1) == tsdb.DefaultMaxPointsPerBlock && !group.hasTombstones() {\n+\t\t\tif len(generations) > 2 && group.size() > uint64(tsdb.MaxTSMFileSize) && c.FileStore.BlockCount(group.files[0].Path, 1) == tsdb.DefaultMaxPointsPerBlock && !group.hasTombstones() {",
        "comment_created_at": "2024-12-24T00:47:02+00:00",
        "comment_author": "davidby-influx",
        "comment_body": "And a test for this?",
        "pr_file_module": null
      },
      {
        "comment_id": "1898053341",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25594,
        "pr_file": "tsdb/engine/tsm1/compact.go",
        "discussion_id": "1896233680",
        "commented_code": "@@ -449,7 +469,7 @@ func (c *DefaultPlanner) Plan(lastWrite time.Time) ([]CompactionGroup, int64) {\n \t\t\tvar skip bool\n \n \t\t\t// Skip the file if it's over the max size and contains a full block and it does not have any tombstones\n-\t\t\tif len(generations) > 2 && group.size() > uint64(maxTSMFileSize) && c.FileStore.BlockCount(group.files[0].Path, 1) == tsdb.DefaultMaxPointsPerBlock && !group.hasTombstones() {\n+\t\t\tif len(generations) > 2 && group.size() > uint64(tsdb.MaxTSMFileSize) && c.FileStore.BlockCount(group.files[0].Path, 1) == tsdb.DefaultMaxPointsPerBlock && !group.hasTombstones() {",
        "comment_created_at": "2024-12-26T18:23:55+00:00",
        "comment_author": "devanbenz",
        "comment_body": "Test added in updated code 👍 ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1844496559",
    "pr_number": 25517,
    "pr_file": "coordinator/points_writer.go",
    "created_at": "2024-11-15T21:11:24+00:00",
    "commented_code": "s.Shards[shardInfo.ID] = shardInfo\n }\n \n+func withinWriteWindow(rp *meta.RetentionPolicyInfo, p models.Point) bool {\n+\tif (rp != nil) &&\n+\t\t(((rp.FutureWriteLimit > 0) && p.Time().After(time.Now().Add(rp.FutureWriteLimit))) ||\n+\t\t\t((rp.PastWriteLimit > 0) && p.Time().Before(time.Now().Add(-rp.PastWriteLimit)))) {",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1844496559",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25517,
        "pr_file": "coordinator/points_writer.go",
        "discussion_id": "1844496559",
        "commented_code": "@@ -121,6 +121,15 @@ func (s *ShardMapping) MapPoint(shardInfo *meta.ShardInfo, p models.Point) {\n \ts.Shards[shardInfo.ID] = shardInfo\n }\n \n+func withinWriteWindow(rp *meta.RetentionPolicyInfo, p models.Point) bool {\n+\tif (rp != nil) &&\n+\t\t(((rp.FutureWriteLimit > 0) && p.Time().After(time.Now().Add(rp.FutureWriteLimit))) ||\n+\t\t\t((rp.PastWriteLimit > 0) && p.Time().Before(time.Now().Add(-rp.PastWriteLimit)))) {",
        "comment_created_at": "2024-11-15T21:11:24+00:00",
        "comment_author": "gwossum",
        "comment_body": "Suggestion for future optimization: Create a `writeWindow` object that caches the value of `time.Now().Add(rp.FutureWriteLimit)` and `time.Now().Add(-rp.PastWriteLimit)` to avoid calculating them twice for every point in request.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1757642067",
    "pr_number": 25312,
    "pr_file": "tsdb/store.go",
    "created_at": "2024-09-12T22:01:06+00:00",
    "commented_code": "})\n }\n \n-// filterShards returns a slice of shards where fn returns true\n+// filterShards takes in a list of functions and\n+// returns a slice of shards where fn returns true\n // for the shard. If the provided predicate is nil then all shards are returned.\n // filterShards should be called under a lock.\n-func (s *Store) filterShards(fn func(sh *Shard) bool) []*Shard {\n+func (s *Store) filterShards(fns []func(sh *Shard) bool) []*Shard {\n \tvar shards []*Shard\n-\tif fn == nil {\n+\n+\t// Early return if nil or 0 len\n+\tif len(fns) == 0 || fns == nil {\n \t\tshards = make([]*Shard, 0, len(s.shards))\n-\t\tfn = func(*Shard) bool { return true }\n-\t} else {\n-\t\tshards = make([]*Shard, 0)\n+\t\tfn := func(*Shard) bool { return true }\n+\n+\t\tfor _, sh := range s.shards {\n+\t\t\tif fn(sh) {",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1757642067",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25312,
        "pr_file": "tsdb/store.go",
        "discussion_id": "1757642067",
        "commented_code": "@@ -1124,23 +1124,42 @@ func (s *Store) DeleteMeasurement(database, name string) error {\n \t})\n }\n \n-// filterShards returns a slice of shards where fn returns true\n+// filterShards takes in a list of functions and\n+// returns a slice of shards where fn returns true\n // for the shard. If the provided predicate is nil then all shards are returned.\n // filterShards should be called under a lock.\n-func (s *Store) filterShards(fn func(sh *Shard) bool) []*Shard {\n+func (s *Store) filterShards(fns []func(sh *Shard) bool) []*Shard {\n \tvar shards []*Shard\n-\tif fn == nil {\n+\n+\t// Early return if nil or 0 len\n+\tif len(fns) == 0 || fns == nil {\n \t\tshards = make([]*Shard, 0, len(s.shards))\n-\t\tfn = func(*Shard) bool { return true }\n-\t} else {\n-\t\tshards = make([]*Shard, 0)\n+\t\tfn := func(*Shard) bool { return true }\n+\n+\t\tfor _, sh := range s.shards {\n+\t\t\tif fn(sh) {",
        "comment_created_at": "2024-09-12T22:01:06+00:00",
        "comment_author": "davidby-influx",
        "comment_body": "You know than `fn` will return true here.  Why call it; why not simply copy the `s.shards` with the `copy` function?  \r\n\r\n`copy(shards, s.shards)`",
        "pr_file_module": null
      },
      {
        "comment_id": "1758926895",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25312,
        "pr_file": "tsdb/store.go",
        "discussion_id": "1757642067",
        "commented_code": "@@ -1124,23 +1124,42 @@ func (s *Store) DeleteMeasurement(database, name string) error {\n \t})\n }\n \n-// filterShards returns a slice of shards where fn returns true\n+// filterShards takes in a list of functions and\n+// returns a slice of shards where fn returns true\n // for the shard. If the provided predicate is nil then all shards are returned.\n // filterShards should be called under a lock.\n-func (s *Store) filterShards(fn func(sh *Shard) bool) []*Shard {\n+func (s *Store) filterShards(fns []func(sh *Shard) bool) []*Shard {\n \tvar shards []*Shard\n-\tif fn == nil {\n+\n+\t// Early return if nil or 0 len\n+\tif len(fns) == 0 || fns == nil {\n \t\tshards = make([]*Shard, 0, len(s.shards))\n-\t\tfn = func(*Shard) bool { return true }\n-\t} else {\n-\t\tshards = make([]*Shard, 0)\n+\t\tfn := func(*Shard) bool { return true }\n+\n+\t\tfor _, sh := range s.shards {\n+\t\t\tif fn(sh) {",
        "comment_created_at": "2024-09-13T13:58:34+00:00",
        "comment_author": "devanbenz",
        "comment_body": "see: https://github.com/influxdata/influxdb/pull/25312#discussion_r1758925237",
        "pr_file_module": null
      }
    ]
  }
]