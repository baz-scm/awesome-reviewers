[
  {
    "discussion_id": "1825970447",
    "pr_number": 25495,
    "pr_file": "influxdb3_id/src/serialize.rs",
    "created_at": "2024-11-01T15:40:30+00:00",
    "commented_code": "#[cfg(test)]\n mod tests {\n-    use hashbrown::HashMap;\n+    use indexmap::IndexMap;\n \n-    use super::SerdeVecHashMap;\n+    use super::SerdeVecMap;\n \n     #[test]\n     fn serde_vec_map_with_json() {\n-        let map = HashMap::<u32, &str>::from_iter([(0, \"foo\"), (1, \"bar\"), (2, \"baz\")]);\n-        let serde_vec_map = SerdeVecHashMap::from(map);\n+        let map = IndexMap::<u32, &str>::from_iter([(0, \"foo\"), (1, \"bar\"), (2, \"baz\")]);\n+        let serde_vec_map = SerdeVecMap::from(map);\n         // test round-trip to JSON:\n         let s = serde_json::to_string(&serde_vec_map).unwrap();\n-        // with using a hashmap the order changes so asserting on the JSON itself is flaky, so if\n-        // you want to see it working use --nocapture on the test...\n-        println!(\"{s}\");\n-        let d: SerdeVecHashMap<u32, &str> = serde_json::from_str(&s).unwrap();\n+        assert_eq!(r#\"[[0,\"foo\"],[1,\"bar\"],[2,\"baz\"]]\"#, s);",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1825970447",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25495,
        "pr_file": "influxdb3_id/src/serialize.rs",
        "discussion_id": "1825970447",
        "commented_code": "@@ -188,20 +207,18 @@ where\n \n #[cfg(test)]\n mod tests {\n-    use hashbrown::HashMap;\n+    use indexmap::IndexMap;\n \n-    use super::SerdeVecHashMap;\n+    use super::SerdeVecMap;\n \n     #[test]\n     fn serde_vec_map_with_json() {\n-        let map = HashMap::<u32, &str>::from_iter([(0, \"foo\"), (1, \"bar\"), (2, \"baz\")]);\n-        let serde_vec_map = SerdeVecHashMap::from(map);\n+        let map = IndexMap::<u32, &str>::from_iter([(0, \"foo\"), (1, \"bar\"), (2, \"baz\")]);\n+        let serde_vec_map = SerdeVecMap::from(map);\n         // test round-trip to JSON:\n         let s = serde_json::to_string(&serde_vec_map).unwrap();\n-        // with using a hashmap the order changes so asserting on the JSON itself is flaky, so if\n-        // you want to see it working use --nocapture on the test...\n-        println!(\"{s}\");\n-        let d: SerdeVecHashMap<u32, &str> = serde_json::from_str(&s).unwrap();\n+        assert_eq!(r#\"[[0,\"foo\"],[1,\"bar\"],[2,\"baz\"]]\"#, s);",
        "comment_created_at": "2024-11-01T15:40:30+00:00",
        "comment_author": "hiltontj",
        "comment_body": "Using [`indexmap`](https://github.com/indexmap-rs/indexmap) makes this assertion (and the use of `insta` snapshots for serialization tests) possible.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1785143179",
    "pr_number": 25421,
    "pr_file": "influxdb3_catalog/src/catalog.rs",
    "created_at": "2024-10-02T19:48:43+00:00",
    "commented_code": "{\n             let json = r#\"{\n                 \"databases\": {\n-                    \"db1\": {\n-                        \"id\": 0,\n+                    \"0\": {",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1785143179",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25421,
        "pr_file": "influxdb3_catalog/src/catalog.rs",
        "discussion_id": "1785143179",
        "commented_code": "@@ -820,13 +940,13 @@ mod tests {\n         {\n             let json = r#\"{\n                 \"databases\": {\n-                    \"db1\": {\n-                        \"id\": 0,\n+                    \"0\": {",
        "comment_created_at": "2024-10-02T19:48:43+00:00",
        "comment_author": "pauldix",
        "comment_body": "Given these serializations have the key as a string, I don't think there's any value in having this be a map. We'd be better off just having a Vec because we want the in-memory structure to be keyed off a u64, not a string. I'd apply this down the line everywhere we're using maps in serialization.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1785145237",
    "pr_number": 25421,
    "pr_file": "influxdb3_id/src/lib.rs",
    "created_at": "2024-10-02T19:50:40+00:00",
    "commented_code": "use serde::Deserialize;\n use serde::Serialize;\n+use serde_with::serde_as;\n+use serde_with::DisplayFromStr;\n+use std::fmt::Display;\n use std::sync::atomic::AtomicU32;\n use std::sync::atomic::Ordering;\n \n-#[derive(Debug, Copy, Clone, Eq, PartialOrd, Ord, PartialEq, Serialize, Deserialize)]\n-pub struct DbId(u32);\n+#[serde_as]\n+#[derive(Debug, Copy, Clone, Eq, PartialOrd, Ord, PartialEq, Serialize, Deserialize, Hash)]\n+pub struct DbId(#[serde_as(as = \"DisplayFromStr\")] u32);",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1785145237",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25421,
        "pr_file": "influxdb3_id/src/lib.rs",
        "discussion_id": "1785145237",
        "commented_code": "@@ -1,10 +1,14 @@\n use serde::Deserialize;\n use serde::Serialize;\n+use serde_with::serde_as;\n+use serde_with::DisplayFromStr;\n+use std::fmt::Display;\n use std::sync::atomic::AtomicU32;\n use std::sync::atomic::Ordering;\n \n-#[derive(Debug, Copy, Clone, Eq, PartialOrd, Ord, PartialEq, Serialize, Deserialize)]\n-pub struct DbId(u32);\n+#[serde_as]\n+#[derive(Debug, Copy, Clone, Eq, PartialOrd, Ord, PartialEq, Serialize, Deserialize, Hash)]\n+pub struct DbId(#[serde_as(as = \"DisplayFromStr\")] u32);",
        "comment_created_at": "2024-10-02T19:50:40+00:00",
        "comment_author": "pauldix",
        "comment_body": "We actually want this serialized as an int, not a string. I believe you're doing this because of the maps elsewhere?",
        "pr_file_module": null
      },
      {
        "comment_id": "1785239962",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25421,
        "pr_file": "influxdb3_id/src/lib.rs",
        "discussion_id": "1785145237",
        "commented_code": "@@ -1,10 +1,14 @@\n use serde::Deserialize;\n use serde::Serialize;\n+use serde_with::serde_as;\n+use serde_with::DisplayFromStr;\n+use std::fmt::Display;\n use std::sync::atomic::AtomicU32;\n use std::sync::atomic::Ordering;\n \n-#[derive(Debug, Copy, Clone, Eq, PartialOrd, Ord, PartialEq, Serialize, Deserialize)]\n-pub struct DbId(u32);\n+#[serde_as]\n+#[derive(Debug, Copy, Clone, Eq, PartialOrd, Ord, PartialEq, Serialize, Deserialize, Hash)]\n+pub struct DbId(#[serde_as(as = \"DisplayFromStr\")] u32);",
        "comment_created_at": "2024-10-02T20:55:02+00:00",
        "comment_author": "mgattozzi",
        "comment_body": "That's correct. If we turn it into a vec though then we lose on the O(1) lookup for quite a few things as the id will not correspond to a position in a vec. It might make sense to have it serialize as a number if it's the value for a field and a string for the map key",
        "pr_file_module": null
      },
      {
        "comment_id": "1785244647",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25421,
        "pr_file": "influxdb3_id/src/lib.rs",
        "discussion_id": "1785145237",
        "commented_code": "@@ -1,10 +1,14 @@\n use serde::Deserialize;\n use serde::Serialize;\n+use serde_with::serde_as;\n+use serde_with::DisplayFromStr;\n+use std::fmt::Display;\n use std::sync::atomic::AtomicU32;\n use std::sync::atomic::Ordering;\n \n-#[derive(Debug, Copy, Clone, Eq, PartialOrd, Ord, PartialEq, Serialize, Deserialize)]\n-pub struct DbId(u32);\n+#[serde_as]\n+#[derive(Debug, Copy, Clone, Eq, PartialOrd, Ord, PartialEq, Serialize, Deserialize, Hash)]\n+pub struct DbId(#[serde_as(as = \"DisplayFromStr\")] u32);",
        "comment_created_at": "2024-10-02T20:59:58+00:00",
        "comment_author": "pauldix",
        "comment_body": "Yeah, so I think we should have one data structure for serialization, which is a vec of the objects, rather than a map. That way we can have all the IDs be ints. Then when you read the serialized data into an in-memory structure for fast lookups, you put it into a map, which should be by int. We should never being lookups against the serialized structure, I think",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1668592955",
    "pr_number": 25125,
    "pr_file": "influxdb3_write/src/last_cache.rs",
    "created_at": "2024-07-08T13:03:00+00:00",
    "commented_code": "/// the [`remove_expired`][LastCache::remove_expired] method.\n     ttl: Duration,\n     /// The key columns for this cache\n-    key_columns: Vec<String>,\n-    /// The Influx Schema for the table that this cache is associated with\n-    schema: Schema,\n+    key_columns: IndexSet<String>,",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1668592955",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25125,
        "pr_file": "influxdb3_write/src/last_cache.rs",
        "discussion_id": "1668592955",
        "commented_code": "@@ -310,21 +319,35 @@ pub(crate) struct LastCache {\n     /// the [`remove_expired`][LastCache::remove_expired] method.\n     ttl: Duration,\n     /// The key columns for this cache\n-    key_columns: Vec<String>,\n-    /// The Influx Schema for the table that this cache is associated with\n-    schema: Schema,\n+    key_columns: IndexSet<String>,",
        "comment_created_at": "2024-07-08T13:03:00+00:00",
        "comment_author": "hiltontj",
        "comment_body": "Maybe add a note on why `IndexSet` was used, i.e., for fast lookup in addition to iteration to the doc comment.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1659357308",
    "pr_number": 25109,
    "pr_file": "influxdb3_write/src/last_cache.rs",
    "created_at": "2024-06-28T21:41:13+00:00",
    "commented_code": "+use std::{any::Any, collections::VecDeque, sync::Arc};\n+\n+use arrow::{\n+    array::{\n+        ArrayRef, BooleanBuilder, Float64Builder, GenericByteDictionaryBuilder, Int64Builder,\n+        RecordBatch, StringBuilder, StringDictionaryBuilder, TimestampNanosecondBuilder,\n+        UInt64Builder,\n+    },\n+    datatypes::{DataType, GenericStringType, Int32Type, SchemaRef, TimeUnit},\n+    error::ArrowError,\n+};\n+use async_trait::async_trait;\n+use datafusion::{\n+    datasource::{TableProvider, TableType},\n+    execution::context::SessionState,\n+    logical_expr::{Expr, TableProviderFilterPushDown},\n+    physical_plan::{memory::MemoryExec, ExecutionPlan},\n+};\n+use hashbrown::{HashMap, HashSet};\n+use indexmap::IndexMap;\n+use iox_time::Time;\n+use parking_lot::RwLock;\n+use schema::TIME_COLUMN_NAME;\n+\n+use crate::{\n+    catalog::LastCacheSize,\n+    write_buffer::{buffer_segment::WriteBatch, FieldData, Row},\n+};\n+\n+#[derive(Debug, thiserror::Error)]\n+pub enum Error {\n+    #[error(\"invalid cache size\")]\n+    InvalidCacheSize,\n+    #[error(\"last cache already exists for database and table\")]\n+    CacheAlreadyExists,\n+}\n+\n+/// A two level hashmap storing Database Name -> Table Name -> LastCache\n+///\n+/// There are two lock levels, one at the top and one at the bottom:\n+/// - Top: lock the entire cache for creating new entries\n+/// - Bottom: lock an individual cache for pushing in new data\n+type CacheMap = RwLock<HashMap<String, HashMap<String, RwLock<LastCache>>>>;\n+\n+pub struct LastCacheProvider {\n+    cache_map: CacheMap,\n+}\n+\n+impl std::fmt::Debug for LastCacheProvider {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        write!(f, \"LastCacheProvider\")\n+    }\n+}\n+\n+impl LastCacheProvider {\n+    /// Create a new [`LastCacheProvider`]\n+    pub(crate) fn new() -> Self {\n+        Self {\n+            cache_map: Default::default(),\n+        }\n+    }\n+\n+    /// Output the records for a given cache as arrow [`RecordBatch`]es\n+    #[cfg(test)]\n+    pub(crate) fn get_cache_record_batches<D, T>(\n+        &self,\n+        db_name: D,\n+        tbl_name: T,\n+    ) -> Option<Result<RecordBatch, ArrowError>>\n+    where\n+        D: AsRef<str>,\n+        T: AsRef<str>,\n+    {\n+        self.cache_map\n+            .read()\n+            .get(db_name.as_ref())\n+            .and_then(|db| db.get(tbl_name.as_ref()))\n+            .map(|lc| lc.read().to_record_batch())\n+    }\n+\n+    /// Create a new entry in the last cache for a given database and table, along with the given\n+    /// parameters.\n+    pub(crate) fn create_cache<D, T>(\n+        &self,\n+        db_name: D,\n+        tbl_name: T,\n+        count: usize,\n+        key_columns: impl IntoIterator<Item: Into<String>>,\n+        schema: SchemaRef,\n+    ) -> Result<(), Error>\n+    where\n+        D: Into<String>,\n+        T: Into<String>,\n+    {\n+        let db_name = db_name.into();\n+        let tbl_name = tbl_name.into();\n+        if self\n+            .cache_map\n+            .read()\n+            .get(&db_name)\n+            .is_some_and(|db| db.contains_key(&tbl_name))\n+        {\n+            return Err(Error::CacheAlreadyExists);\n+        }\n+        let last_cache = RwLock::new(LastCache::new(count, key_columns, schema)?);\n+        self.cache_map\n+            .write()\n+            .entry(db_name)\n+            .or_default()\n+            .insert(tbl_name, last_cache);\n+        Ok(())\n+    }\n+\n+    /// Write a batch from the buffer into the cache by iterating over its database and table batches\n+    /// to find entries that belong in the cache.\n+    ///\n+    /// Only if rows are newer than the latest entry in the cache will they be entered.\n+    pub(crate) fn write_batch_to_cache(&self, write_batch: &WriteBatch) {\n+        for (db_name, db_batch) in &write_batch.database_batches {\n+            for (tbl_name, tbl_batch) in &db_batch.table_batches {\n+                if let Some(db) = self.cache_map.read().get(db_name.as_str()) {\n+                    for row in &tbl_batch.rows {\n+                        if db\n+                            .get(tbl_name)\n+                            .is_some_and(|t| row.time > t.read().last_time.timestamp_nanos())\n+                        {\n+                            db.get(tbl_name).unwrap().write().push(row);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+/// Stores the last N values, as configured, for a given table in a database\n+pub(crate) struct LastCache {\n+    // TODO: not sure if this is needed, given the individual columns track their size\n+    _count: LastCacheSize,\n+    // TODO: use for filter predicates\n+    _key_columns: HashSet<String>,\n+    schema: SchemaRef,\n+    // use an IndexMap to preserve insertion order:\n+    cache: IndexMap<String, CacheColumn>,",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1659357308",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25109,
        "pr_file": "influxdb3_write/src/last_cache.rs",
        "discussion_id": "1659357308",
        "commented_code": "@@ -0,0 +1,498 @@\n+use std::{any::Any, collections::VecDeque, sync::Arc};\n+\n+use arrow::{\n+    array::{\n+        ArrayRef, BooleanBuilder, Float64Builder, GenericByteDictionaryBuilder, Int64Builder,\n+        RecordBatch, StringBuilder, StringDictionaryBuilder, TimestampNanosecondBuilder,\n+        UInt64Builder,\n+    },\n+    datatypes::{DataType, GenericStringType, Int32Type, SchemaRef, TimeUnit},\n+    error::ArrowError,\n+};\n+use async_trait::async_trait;\n+use datafusion::{\n+    datasource::{TableProvider, TableType},\n+    execution::context::SessionState,\n+    logical_expr::{Expr, TableProviderFilterPushDown},\n+    physical_plan::{memory::MemoryExec, ExecutionPlan},\n+};\n+use hashbrown::{HashMap, HashSet};\n+use indexmap::IndexMap;\n+use iox_time::Time;\n+use parking_lot::RwLock;\n+use schema::TIME_COLUMN_NAME;\n+\n+use crate::{\n+    catalog::LastCacheSize,\n+    write_buffer::{buffer_segment::WriteBatch, FieldData, Row},\n+};\n+\n+#[derive(Debug, thiserror::Error)]\n+pub enum Error {\n+    #[error(\"invalid cache size\")]\n+    InvalidCacheSize,\n+    #[error(\"last cache already exists for database and table\")]\n+    CacheAlreadyExists,\n+}\n+\n+/// A two level hashmap storing Database Name -> Table Name -> LastCache\n+///\n+/// There are two lock levels, one at the top and one at the bottom:\n+/// - Top: lock the entire cache for creating new entries\n+/// - Bottom: lock an individual cache for pushing in new data\n+type CacheMap = RwLock<HashMap<String, HashMap<String, RwLock<LastCache>>>>;\n+\n+pub struct LastCacheProvider {\n+    cache_map: CacheMap,\n+}\n+\n+impl std::fmt::Debug for LastCacheProvider {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        write!(f, \"LastCacheProvider\")\n+    }\n+}\n+\n+impl LastCacheProvider {\n+    /// Create a new [`LastCacheProvider`]\n+    pub(crate) fn new() -> Self {\n+        Self {\n+            cache_map: Default::default(),\n+        }\n+    }\n+\n+    /// Output the records for a given cache as arrow [`RecordBatch`]es\n+    #[cfg(test)]\n+    pub(crate) fn get_cache_record_batches<D, T>(\n+        &self,\n+        db_name: D,\n+        tbl_name: T,\n+    ) -> Option<Result<RecordBatch, ArrowError>>\n+    where\n+        D: AsRef<str>,\n+        T: AsRef<str>,\n+    {\n+        self.cache_map\n+            .read()\n+            .get(db_name.as_ref())\n+            .and_then(|db| db.get(tbl_name.as_ref()))\n+            .map(|lc| lc.read().to_record_batch())\n+    }\n+\n+    /// Create a new entry in the last cache for a given database and table, along with the given\n+    /// parameters.\n+    pub(crate) fn create_cache<D, T>(\n+        &self,\n+        db_name: D,\n+        tbl_name: T,\n+        count: usize,\n+        key_columns: impl IntoIterator<Item: Into<String>>,\n+        schema: SchemaRef,\n+    ) -> Result<(), Error>\n+    where\n+        D: Into<String>,\n+        T: Into<String>,\n+    {\n+        let db_name = db_name.into();\n+        let tbl_name = tbl_name.into();\n+        if self\n+            .cache_map\n+            .read()\n+            .get(&db_name)\n+            .is_some_and(|db| db.contains_key(&tbl_name))\n+        {\n+            return Err(Error::CacheAlreadyExists);\n+        }\n+        let last_cache = RwLock::new(LastCache::new(count, key_columns, schema)?);\n+        self.cache_map\n+            .write()\n+            .entry(db_name)\n+            .or_default()\n+            .insert(tbl_name, last_cache);\n+        Ok(())\n+    }\n+\n+    /// Write a batch from the buffer into the cache by iterating over its database and table batches\n+    /// to find entries that belong in the cache.\n+    ///\n+    /// Only if rows are newer than the latest entry in the cache will they be entered.\n+    pub(crate) fn write_batch_to_cache(&self, write_batch: &WriteBatch) {\n+        for (db_name, db_batch) in &write_batch.database_batches {\n+            for (tbl_name, tbl_batch) in &db_batch.table_batches {\n+                if let Some(db) = self.cache_map.read().get(db_name.as_str()) {\n+                    for row in &tbl_batch.rows {\n+                        if db\n+                            .get(tbl_name)\n+                            .is_some_and(|t| row.time > t.read().last_time.timestamp_nanos())\n+                        {\n+                            db.get(tbl_name).unwrap().write().push(row);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+/// Stores the last N values, as configured, for a given table in a database\n+pub(crate) struct LastCache {\n+    // TODO: not sure if this is needed, given the individual columns track their size\n+    _count: LastCacheSize,\n+    // TODO: use for filter predicates\n+    _key_columns: HashSet<String>,\n+    schema: SchemaRef,\n+    // use an IndexMap to preserve insertion order:\n+    cache: IndexMap<String, CacheColumn>,",
        "comment_created_at": "2024-06-28T21:41:13+00:00",
        "comment_author": "pauldix",
        "comment_body": "It's not clear to me why this is being used here. What's the insertion order being preserved here?",
        "pr_file_module": null
      },
      {
        "comment_id": "1659807377",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25109,
        "pr_file": "influxdb3_write/src/last_cache.rs",
        "discussion_id": "1659357308",
        "commented_code": "@@ -0,0 +1,498 @@\n+use std::{any::Any, collections::VecDeque, sync::Arc};\n+\n+use arrow::{\n+    array::{\n+        ArrayRef, BooleanBuilder, Float64Builder, GenericByteDictionaryBuilder, Int64Builder,\n+        RecordBatch, StringBuilder, StringDictionaryBuilder, TimestampNanosecondBuilder,\n+        UInt64Builder,\n+    },\n+    datatypes::{DataType, GenericStringType, Int32Type, SchemaRef, TimeUnit},\n+    error::ArrowError,\n+};\n+use async_trait::async_trait;\n+use datafusion::{\n+    datasource::{TableProvider, TableType},\n+    execution::context::SessionState,\n+    logical_expr::{Expr, TableProviderFilterPushDown},\n+    physical_plan::{memory::MemoryExec, ExecutionPlan},\n+};\n+use hashbrown::{HashMap, HashSet};\n+use indexmap::IndexMap;\n+use iox_time::Time;\n+use parking_lot::RwLock;\n+use schema::TIME_COLUMN_NAME;\n+\n+use crate::{\n+    catalog::LastCacheSize,\n+    write_buffer::{buffer_segment::WriteBatch, FieldData, Row},\n+};\n+\n+#[derive(Debug, thiserror::Error)]\n+pub enum Error {\n+    #[error(\"invalid cache size\")]\n+    InvalidCacheSize,\n+    #[error(\"last cache already exists for database and table\")]\n+    CacheAlreadyExists,\n+}\n+\n+/// A two level hashmap storing Database Name -> Table Name -> LastCache\n+///\n+/// There are two lock levels, one at the top and one at the bottom:\n+/// - Top: lock the entire cache for creating new entries\n+/// - Bottom: lock an individual cache for pushing in new data\n+type CacheMap = RwLock<HashMap<String, HashMap<String, RwLock<LastCache>>>>;\n+\n+pub struct LastCacheProvider {\n+    cache_map: CacheMap,\n+}\n+\n+impl std::fmt::Debug for LastCacheProvider {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        write!(f, \"LastCacheProvider\")\n+    }\n+}\n+\n+impl LastCacheProvider {\n+    /// Create a new [`LastCacheProvider`]\n+    pub(crate) fn new() -> Self {\n+        Self {\n+            cache_map: Default::default(),\n+        }\n+    }\n+\n+    /// Output the records for a given cache as arrow [`RecordBatch`]es\n+    #[cfg(test)]\n+    pub(crate) fn get_cache_record_batches<D, T>(\n+        &self,\n+        db_name: D,\n+        tbl_name: T,\n+    ) -> Option<Result<RecordBatch, ArrowError>>\n+    where\n+        D: AsRef<str>,\n+        T: AsRef<str>,\n+    {\n+        self.cache_map\n+            .read()\n+            .get(db_name.as_ref())\n+            .and_then(|db| db.get(tbl_name.as_ref()))\n+            .map(|lc| lc.read().to_record_batch())\n+    }\n+\n+    /// Create a new entry in the last cache for a given database and table, along with the given\n+    /// parameters.\n+    pub(crate) fn create_cache<D, T>(\n+        &self,\n+        db_name: D,\n+        tbl_name: T,\n+        count: usize,\n+        key_columns: impl IntoIterator<Item: Into<String>>,\n+        schema: SchemaRef,\n+    ) -> Result<(), Error>\n+    where\n+        D: Into<String>,\n+        T: Into<String>,\n+    {\n+        let db_name = db_name.into();\n+        let tbl_name = tbl_name.into();\n+        if self\n+            .cache_map\n+            .read()\n+            .get(&db_name)\n+            .is_some_and(|db| db.contains_key(&tbl_name))\n+        {\n+            return Err(Error::CacheAlreadyExists);\n+        }\n+        let last_cache = RwLock::new(LastCache::new(count, key_columns, schema)?);\n+        self.cache_map\n+            .write()\n+            .entry(db_name)\n+            .or_default()\n+            .insert(tbl_name, last_cache);\n+        Ok(())\n+    }\n+\n+    /// Write a batch from the buffer into the cache by iterating over its database and table batches\n+    /// to find entries that belong in the cache.\n+    ///\n+    /// Only if rows are newer than the latest entry in the cache will they be entered.\n+    pub(crate) fn write_batch_to_cache(&self, write_batch: &WriteBatch) {\n+        for (db_name, db_batch) in &write_batch.database_batches {\n+            for (tbl_name, tbl_batch) in &db_batch.table_batches {\n+                if let Some(db) = self.cache_map.read().get(db_name.as_str()) {\n+                    for row in &tbl_batch.rows {\n+                        if db\n+                            .get(tbl_name)\n+                            .is_some_and(|t| row.time > t.read().last_time.timestamp_nanos())\n+                        {\n+                            db.get(tbl_name).unwrap().write().push(row);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+/// Stores the last N values, as configured, for a given table in a database\n+pub(crate) struct LastCache {\n+    // TODO: not sure if this is needed, given the individual columns track their size\n+    _count: LastCacheSize,\n+    // TODO: use for filter predicates\n+    _key_columns: HashSet<String>,\n+    schema: SchemaRef,\n+    // use an IndexMap to preserve insertion order:\n+    cache: IndexMap<String, CacheColumn>,",
        "comment_created_at": "2024-06-29T12:37:47+00:00",
        "comment_author": "hiltontj",
        "comment_body": "Since I insert columns into the cache using the ordering of fields in the `schema` ([here](https://github.com/influxdata/influxdb/pull/25109/files#diff-6740f1021d631fa570625b9b27f8b4692fd0777c50eabcc435cda7793d0da049R155-R159)), then when producing a record batch out of the cache ([here](https://github.com/influxdata/influxdb/pull/25109/files#diff-6740f1021d631fa570625b9b27f8b4692fd0777c50eabcc435cda7793d0da049R184-R193)), `IndexMap` allows to iterate over the map directly while producing the correct order of columns for the schema.",
        "pr_file_module": null
      },
      {
        "comment_id": "1666823224",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25109,
        "pr_file": "influxdb3_write/src/last_cache.rs",
        "discussion_id": "1659357308",
        "commented_code": "@@ -0,0 +1,498 @@\n+use std::{any::Any, collections::VecDeque, sync::Arc};\n+\n+use arrow::{\n+    array::{\n+        ArrayRef, BooleanBuilder, Float64Builder, GenericByteDictionaryBuilder, Int64Builder,\n+        RecordBatch, StringBuilder, StringDictionaryBuilder, TimestampNanosecondBuilder,\n+        UInt64Builder,\n+    },\n+    datatypes::{DataType, GenericStringType, Int32Type, SchemaRef, TimeUnit},\n+    error::ArrowError,\n+};\n+use async_trait::async_trait;\n+use datafusion::{\n+    datasource::{TableProvider, TableType},\n+    execution::context::SessionState,\n+    logical_expr::{Expr, TableProviderFilterPushDown},\n+    physical_plan::{memory::MemoryExec, ExecutionPlan},\n+};\n+use hashbrown::{HashMap, HashSet};\n+use indexmap::IndexMap;\n+use iox_time::Time;\n+use parking_lot::RwLock;\n+use schema::TIME_COLUMN_NAME;\n+\n+use crate::{\n+    catalog::LastCacheSize,\n+    write_buffer::{buffer_segment::WriteBatch, FieldData, Row},\n+};\n+\n+#[derive(Debug, thiserror::Error)]\n+pub enum Error {\n+    #[error(\"invalid cache size\")]\n+    InvalidCacheSize,\n+    #[error(\"last cache already exists for database and table\")]\n+    CacheAlreadyExists,\n+}\n+\n+/// A two level hashmap storing Database Name -> Table Name -> LastCache\n+///\n+/// There are two lock levels, one at the top and one at the bottom:\n+/// - Top: lock the entire cache for creating new entries\n+/// - Bottom: lock an individual cache for pushing in new data\n+type CacheMap = RwLock<HashMap<String, HashMap<String, RwLock<LastCache>>>>;\n+\n+pub struct LastCacheProvider {\n+    cache_map: CacheMap,\n+}\n+\n+impl std::fmt::Debug for LastCacheProvider {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        write!(f, \"LastCacheProvider\")\n+    }\n+}\n+\n+impl LastCacheProvider {\n+    /// Create a new [`LastCacheProvider`]\n+    pub(crate) fn new() -> Self {\n+        Self {\n+            cache_map: Default::default(),\n+        }\n+    }\n+\n+    /// Output the records for a given cache as arrow [`RecordBatch`]es\n+    #[cfg(test)]\n+    pub(crate) fn get_cache_record_batches<D, T>(\n+        &self,\n+        db_name: D,\n+        tbl_name: T,\n+    ) -> Option<Result<RecordBatch, ArrowError>>\n+    where\n+        D: AsRef<str>,\n+        T: AsRef<str>,\n+    {\n+        self.cache_map\n+            .read()\n+            .get(db_name.as_ref())\n+            .and_then(|db| db.get(tbl_name.as_ref()))\n+            .map(|lc| lc.read().to_record_batch())\n+    }\n+\n+    /// Create a new entry in the last cache for a given database and table, along with the given\n+    /// parameters.\n+    pub(crate) fn create_cache<D, T>(\n+        &self,\n+        db_name: D,\n+        tbl_name: T,\n+        count: usize,\n+        key_columns: impl IntoIterator<Item: Into<String>>,\n+        schema: SchemaRef,\n+    ) -> Result<(), Error>\n+    where\n+        D: Into<String>,\n+        T: Into<String>,\n+    {\n+        let db_name = db_name.into();\n+        let tbl_name = tbl_name.into();\n+        if self\n+            .cache_map\n+            .read()\n+            .get(&db_name)\n+            .is_some_and(|db| db.contains_key(&tbl_name))\n+        {\n+            return Err(Error::CacheAlreadyExists);\n+        }\n+        let last_cache = RwLock::new(LastCache::new(count, key_columns, schema)?);\n+        self.cache_map\n+            .write()\n+            .entry(db_name)\n+            .or_default()\n+            .insert(tbl_name, last_cache);\n+        Ok(())\n+    }\n+\n+    /// Write a batch from the buffer into the cache by iterating over its database and table batches\n+    /// to find entries that belong in the cache.\n+    ///\n+    /// Only if rows are newer than the latest entry in the cache will they be entered.\n+    pub(crate) fn write_batch_to_cache(&self, write_batch: &WriteBatch) {\n+        for (db_name, db_batch) in &write_batch.database_batches {\n+            for (tbl_name, tbl_batch) in &db_batch.table_batches {\n+                if let Some(db) = self.cache_map.read().get(db_name.as_str()) {\n+                    for row in &tbl_batch.rows {\n+                        if db\n+                            .get(tbl_name)\n+                            .is_some_and(|t| row.time > t.read().last_time.timestamp_nanos())\n+                        {\n+                            db.get(tbl_name).unwrap().write().push(row);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+/// Stores the last N values, as configured, for a given table in a database\n+pub(crate) struct LastCache {\n+    // TODO: not sure if this is needed, given the individual columns track their size\n+    _count: LastCacheSize,\n+    // TODO: use for filter predicates\n+    _key_columns: HashSet<String>,\n+    schema: SchemaRef,\n+    // use an IndexMap to preserve insertion order:\n+    cache: IndexMap<String, CacheColumn>,",
        "comment_created_at": "2024-07-05T13:39:55+00:00",
        "comment_author": "hiltontj",
        "comment_body": "The links in that comment look to be out-of-date. But I have added docs/comments in the code to help explain this.",
        "pr_file_module": null
      },
      {
        "comment_id": "1670532604",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25109,
        "pr_file": "influxdb3_write/src/last_cache.rs",
        "discussion_id": "1659357308",
        "commented_code": "@@ -0,0 +1,498 @@\n+use std::{any::Any, collections::VecDeque, sync::Arc};\n+\n+use arrow::{\n+    array::{\n+        ArrayRef, BooleanBuilder, Float64Builder, GenericByteDictionaryBuilder, Int64Builder,\n+        RecordBatch, StringBuilder, StringDictionaryBuilder, TimestampNanosecondBuilder,\n+        UInt64Builder,\n+    },\n+    datatypes::{DataType, GenericStringType, Int32Type, SchemaRef, TimeUnit},\n+    error::ArrowError,\n+};\n+use async_trait::async_trait;\n+use datafusion::{\n+    datasource::{TableProvider, TableType},\n+    execution::context::SessionState,\n+    logical_expr::{Expr, TableProviderFilterPushDown},\n+    physical_plan::{memory::MemoryExec, ExecutionPlan},\n+};\n+use hashbrown::{HashMap, HashSet};\n+use indexmap::IndexMap;\n+use iox_time::Time;\n+use parking_lot::RwLock;\n+use schema::TIME_COLUMN_NAME;\n+\n+use crate::{\n+    catalog::LastCacheSize,\n+    write_buffer::{buffer_segment::WriteBatch, FieldData, Row},\n+};\n+\n+#[derive(Debug, thiserror::Error)]\n+pub enum Error {\n+    #[error(\"invalid cache size\")]\n+    InvalidCacheSize,\n+    #[error(\"last cache already exists for database and table\")]\n+    CacheAlreadyExists,\n+}\n+\n+/// A two level hashmap storing Database Name -> Table Name -> LastCache\n+///\n+/// There are two lock levels, one at the top and one at the bottom:\n+/// - Top: lock the entire cache for creating new entries\n+/// - Bottom: lock an individual cache for pushing in new data\n+type CacheMap = RwLock<HashMap<String, HashMap<String, RwLock<LastCache>>>>;\n+\n+pub struct LastCacheProvider {\n+    cache_map: CacheMap,\n+}\n+\n+impl std::fmt::Debug for LastCacheProvider {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        write!(f, \"LastCacheProvider\")\n+    }\n+}\n+\n+impl LastCacheProvider {\n+    /// Create a new [`LastCacheProvider`]\n+    pub(crate) fn new() -> Self {\n+        Self {\n+            cache_map: Default::default(),\n+        }\n+    }\n+\n+    /// Output the records for a given cache as arrow [`RecordBatch`]es\n+    #[cfg(test)]\n+    pub(crate) fn get_cache_record_batches<D, T>(\n+        &self,\n+        db_name: D,\n+        tbl_name: T,\n+    ) -> Option<Result<RecordBatch, ArrowError>>\n+    where\n+        D: AsRef<str>,\n+        T: AsRef<str>,\n+    {\n+        self.cache_map\n+            .read()\n+            .get(db_name.as_ref())\n+            .and_then(|db| db.get(tbl_name.as_ref()))\n+            .map(|lc| lc.read().to_record_batch())\n+    }\n+\n+    /// Create a new entry in the last cache for a given database and table, along with the given\n+    /// parameters.\n+    pub(crate) fn create_cache<D, T>(\n+        &self,\n+        db_name: D,\n+        tbl_name: T,\n+        count: usize,\n+        key_columns: impl IntoIterator<Item: Into<String>>,\n+        schema: SchemaRef,\n+    ) -> Result<(), Error>\n+    where\n+        D: Into<String>,\n+        T: Into<String>,\n+    {\n+        let db_name = db_name.into();\n+        let tbl_name = tbl_name.into();\n+        if self\n+            .cache_map\n+            .read()\n+            .get(&db_name)\n+            .is_some_and(|db| db.contains_key(&tbl_name))\n+        {\n+            return Err(Error::CacheAlreadyExists);\n+        }\n+        let last_cache = RwLock::new(LastCache::new(count, key_columns, schema)?);\n+        self.cache_map\n+            .write()\n+            .entry(db_name)\n+            .or_default()\n+            .insert(tbl_name, last_cache);\n+        Ok(())\n+    }\n+\n+    /// Write a batch from the buffer into the cache by iterating over its database and table batches\n+    /// to find entries that belong in the cache.\n+    ///\n+    /// Only if rows are newer than the latest entry in the cache will they be entered.\n+    pub(crate) fn write_batch_to_cache(&self, write_batch: &WriteBatch) {\n+        for (db_name, db_batch) in &write_batch.database_batches {\n+            for (tbl_name, tbl_batch) in &db_batch.table_batches {\n+                if let Some(db) = self.cache_map.read().get(db_name.as_str()) {\n+                    for row in &tbl_batch.rows {\n+                        if db\n+                            .get(tbl_name)\n+                            .is_some_and(|t| row.time > t.read().last_time.timestamp_nanos())\n+                        {\n+                            db.get(tbl_name).unwrap().write().push(row);\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+}\n+\n+/// Stores the last N values, as configured, for a given table in a database\n+pub(crate) struct LastCache {\n+    // TODO: not sure if this is needed, given the individual columns track their size\n+    _count: LastCacheSize,\n+    // TODO: use for filter predicates\n+    _key_columns: HashSet<String>,\n+    schema: SchemaRef,\n+    // use an IndexMap to preserve insertion order:\n+    cache: IndexMap<String, CacheColumn>,",
        "comment_created_at": "2024-07-09T13:27:18+00:00",
        "comment_author": "hiltontj",
        "comment_body": "@pauldix - while working on https://github.com/influxdata/influxdb/pull/25125 to enable caches that add new fields, I have found that the insertion order guarantee falls apart in scenarios where writes come in with different fields/orders for different key values. So, we can't rely on that, and I will be removing the comments about insertion order.\r\n\r\nI still like the use of `IndexMap` because it gives fast iteration over keys, as well as fast lookups (see [here](https://github.com/indexmap-rs/indexmap?tab=readme-ov-file#performance)), but if we want to avoid the dependency, or just optimize for lookup speed, then we could use a `HashMap` here.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1647796176",
    "pr_number": 25074,
    "pr_file": "influxdb3_write/src/write_buffer/buffer_segment.rs",
    "created_at": "2024-06-20T15:48:24+00:00",
    "commented_code": ");\n \n                     let db_name = &write.db_name;\n-                    if !buffered_data.database_buffers.contains_key(db_name) {\n-                        buffered_data.database_buffers.insert(\n+                    if !loaded_buffer\n+                        .buffered_data\n+                        .database_buffers\n+                        .contains_key(db_name)\n+                    {\n+                        loaded_buffer.buffered_data.database_buffers.insert(\n                             db_name.clone(),\n                             DatabaseBuffer {\n                                 table_buffers: HashMap::new(),\n                             },\n                         );\n                     }\n-                    let db_buffer = buffered_data.database_buffers.get_mut(db_name).unwrap();\n+                    let db_buffer = loaded_buffer\n+                        .buffered_data\n+                        .database_buffers\n+                        .get_mut(db_name)\n+                        .unwrap();",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1647796176",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25074,
        "pr_file": "influxdb3_write/src/write_buffer/buffer_segment.rs",
        "discussion_id": "1647796176",
        "commented_code": "@@ -201,15 +342,23 @@ pub(crate) fn load_buffer_from_segment(\n                         );\n \n                     let db_name = &write.db_name;\n-                    if !buffered_data.database_buffers.contains_key(db_name) {\n-                        buffered_data.database_buffers.insert(\n+                    if !loaded_buffer\n+                        .buffered_data\n+                        .database_buffers\n+                        .contains_key(db_name)\n+                    {\n+                        loaded_buffer.buffered_data.database_buffers.insert(\n                             db_name.clone(),\n                             DatabaseBuffer {\n                                 table_buffers: HashMap::new(),\n                             },\n                         );\n                     }\n-                    let db_buffer = buffered_data.database_buffers.get_mut(db_name).unwrap();\n+                    let db_buffer = loaded_buffer\n+                        .buffered_data\n+                        .database_buffers\n+                        .get_mut(db_name)\n+                        .unwrap();",
        "comment_created_at": "2024-06-20T15:48:24+00:00",
        "comment_author": "hiltontj",
        "comment_body": "I guess you avoid the `entry` API on `buffered_data.database_buffers` here in order to avoid cloning `db_name` on every access?\r\n\r\nWe could consider using the `hashbrown` crate for its `HashMap` impl (which gets used here and there in IOx) and has the [`entry_ref` API](https://docs.rs/hashbrown/latest/hashbrown/struct.HashMap.html#method.entry_ref). I think there are a few places in this code where we could leverage that - I think introducing `hashbrown` can be a separate issue/PR though.",
        "pr_file_module": null
      },
      {
        "comment_id": "1648094102",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25074,
        "pr_file": "influxdb3_write/src/write_buffer/buffer_segment.rs",
        "discussion_id": "1647796176",
        "commented_code": "@@ -201,15 +342,23 @@ pub(crate) fn load_buffer_from_segment(\n                         );\n \n                     let db_name = &write.db_name;\n-                    if !buffered_data.database_buffers.contains_key(db_name) {\n-                        buffered_data.database_buffers.insert(\n+                    if !loaded_buffer\n+                        .buffered_data\n+                        .database_buffers\n+                        .contains_key(db_name)\n+                    {\n+                        loaded_buffer.buffered_data.database_buffers.insert(\n                             db_name.clone(),\n                             DatabaseBuffer {\n                                 table_buffers: HashMap::new(),\n                             },\n                         );\n                     }\n-                    let db_buffer = buffered_data.database_buffers.get_mut(db_name).unwrap();\n+                    let db_buffer = loaded_buffer\n+                        .buffered_data\n+                        .database_buffers\n+                        .get_mut(db_name)\n+                        .unwrap();",
        "comment_created_at": "2024-06-20T20:30:31+00:00",
        "comment_author": "mgattozzi",
        "comment_body": "That would actually be really nice. We ran into this issues a couple of times and `entry_ref` would be great. Since std's hashmap is just hashbrown under the hood we won't lose out.",
        "pr_file_module": null
      },
      {
        "comment_id": "1649326802",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25074,
        "pr_file": "influxdb3_write/src/write_buffer/buffer_segment.rs",
        "discussion_id": "1647796176",
        "commented_code": "@@ -201,15 +342,23 @@ pub(crate) fn load_buffer_from_segment(\n                         );\n \n                     let db_name = &write.db_name;\n-                    if !buffered_data.database_buffers.contains_key(db_name) {\n-                        buffered_data.database_buffers.insert(\n+                    if !loaded_buffer\n+                        .buffered_data\n+                        .database_buffers\n+                        .contains_key(db_name)\n+                    {\n+                        loaded_buffer.buffered_data.database_buffers.insert(\n                             db_name.clone(),\n                             DatabaseBuffer {\n                                 table_buffers: HashMap::new(),\n                             },\n                         );\n                     }\n-                    let db_buffer = buffered_data.database_buffers.get_mut(db_name).unwrap();\n+                    let db_buffer = loaded_buffer\n+                        .buffered_data\n+                        .database_buffers\n+                        .get_mut(db_name)\n+                        .unwrap();",
        "comment_created_at": "2024-06-21T18:54:41+00:00",
        "comment_author": "pauldix",
        "comment_body": "yeah, that's why I'm doing it. Moving to using hashbrown sounds good.",
        "pr_file_module": null
      }
    ]
  }
]