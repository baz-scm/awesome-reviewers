[
  {
    "discussion_id": "1949729829",
    "pr_number": 25982,
    "pr_file": "kv/task_test.go",
    "created_at": "2025-02-10T19:12:53+00:00",
    "commented_code": ")\n \n \tstore = itesting.NewTestInmemStore(t)\n-\tif err != nil {\n-\t\tt.Fatal(\"failed to create InmemStore\", err)\n-\t}\n \n \tts.Store = store\n \n \ttenantStore := tenant.NewStore(store)\n \ttenantSvc := tenant.NewService(tenantStore)\n \n-\tauthStore, err := authorization.NewStore(store)\n+\tauthStore, err := authorization.NewStore(ctx, store, useTokenHashing)",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1949729829",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25982,
        "pr_file": "kv/task_test.go",
        "discussion_id": "1949729829",
        "commented_code": "@@ -86,16 +101,13 @@ func newService(t *testing.T, ctx context.Context, c clock.Clock) *testService {\n \t)\n \n \tstore = itesting.NewTestInmemStore(t)\n-\tif err != nil {\n-\t\tt.Fatal(\"failed to create InmemStore\", err)\n-\t}\n \n \tts.Store = store\n \n \ttenantStore := tenant.NewStore(store)\n \ttenantSvc := tenant.NewService(tenantStore)\n \n-\tauthStore, err := authorization.NewStore(store)\n+\tauthStore, err := authorization.NewStore(ctx, store, useTokenHashing)",
        "comment_created_at": "2025-02-10T19:12:53+00:00",
        "comment_author": "davidby-influx",
        "comment_body": "Should this be an option function instead of a flag?",
        "pr_file_module": null
      },
      {
        "comment_id": "1956786047",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25982,
        "pr_file": "kv/task_test.go",
        "discussion_id": "1949729829",
        "commented_code": "@@ -86,16 +101,13 @@ func newService(t *testing.T, ctx context.Context, c clock.Clock) *testService {\n \t)\n \n \tstore = itesting.NewTestInmemStore(t)\n-\tif err != nil {\n-\t\tt.Fatal(\"failed to create InmemStore\", err)\n-\t}\n \n \tts.Store = store\n \n \ttenantStore := tenant.NewStore(store)\n \ttenantSvc := tenant.NewService(tenantStore)\n \n-\tauthStore, err := authorization.NewStore(store)\n+\tauthStore, err := authorization.NewStore(ctx, store, useTokenHashing)",
        "comment_created_at": "2025-02-14T22:30:06+00:00",
        "comment_author": "gwossum",
        "comment_body": "If the user wanted token hashing but it was accidentally left out, that's a big security problem. This way it forces us to specify token hashing. The hashing algorithm is done as an option to avoid polluting test code. I thought this acceptable because using a different hashing algorithm other than the requested is probably not a sever security issue. We also don't provide a configuration for it yet.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1949833205",
    "pr_number": 25982,
    "pr_file": "tenant/service_onboarding_test.go",
    "created_at": "2025-02-10T20:27:17+00:00",
    "commented_code": "influxdbtesting.OnboardInitialUser(initBoltOnboardingService, t)\n }\n \n-func initBoltOnboardingService(f influxdbtesting.OnboardingFields, t *testing.T) (influxdb.OnboardingService, func()) {\n+func initBoltOnboardingService(f influxdbtesting.OnboardingFields, useTokenHashing bool, t *testing.T) (influxdb.OnboardingService, func()) {\n \ts := influxdbtesting.NewTestInmemStore(t)\n-\tsvc := initOnboardingService(s, f, t)\n+\tsvc := initOnboardingService(s, f, useTokenHashing, t)\n \treturn svc, func() {}\n }\n \n-func initOnboardingService(s kv.Store, f influxdbtesting.OnboardingFields, t *testing.T) influxdb.OnboardingService {\n+func initOnboardingService(s kv.Store, f influxdbtesting.OnboardingFields, useTokenHashing bool, t *testing.T) influxdb.OnboardingService {\n+\tctx := context.Background()\n+\n \tstorage := tenant.NewStore(s)\n \tten := tenant.NewService(storage)\n \n-\tauthStore, err := authorization.NewStore(s)\n+\tauthStore, err := authorization.NewStore(ctx, s, useTokenHashing)",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1949833205",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25982,
        "pr_file": "tenant/service_onboarding_test.go",
        "discussion_id": "1949833205",
        "commented_code": "@@ -22,25 +23,25 @@ func TestBoltOnboardingService(t *testing.T) {\n \tinfluxdbtesting.OnboardInitialUser(initBoltOnboardingService, t)\n }\n \n-func initBoltOnboardingService(f influxdbtesting.OnboardingFields, t *testing.T) (influxdb.OnboardingService, func()) {\n+func initBoltOnboardingService(f influxdbtesting.OnboardingFields, useTokenHashing bool, t *testing.T) (influxdb.OnboardingService, func()) {\n \ts := influxdbtesting.NewTestInmemStore(t)\n-\tsvc := initOnboardingService(s, f, t)\n+\tsvc := initOnboardingService(s, f, useTokenHashing, t)\n \treturn svc, func() {}\n }\n \n-func initOnboardingService(s kv.Store, f influxdbtesting.OnboardingFields, t *testing.T) influxdb.OnboardingService {\n+func initOnboardingService(s kv.Store, f influxdbtesting.OnboardingFields, useTokenHashing bool, t *testing.T) influxdb.OnboardingService {\n+\tctx := context.Background()\n+\n \tstorage := tenant.NewStore(s)\n \tten := tenant.NewService(storage)\n \n-\tauthStore, err := authorization.NewStore(s)\n+\tauthStore, err := authorization.NewStore(ctx, s, useTokenHashing)",
        "comment_created_at": "2025-02-10T20:27:17+00:00",
        "comment_author": "davidby-influx",
        "comment_body": "Should `useTokenHashing` be an option function?",
        "pr_file_module": null
      },
      {
        "comment_id": "1956824387",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25982,
        "pr_file": "tenant/service_onboarding_test.go",
        "discussion_id": "1949833205",
        "commented_code": "@@ -22,25 +23,25 @@ func TestBoltOnboardingService(t *testing.T) {\n \tinfluxdbtesting.OnboardInitialUser(initBoltOnboardingService, t)\n }\n \n-func initBoltOnboardingService(f influxdbtesting.OnboardingFields, t *testing.T) (influxdb.OnboardingService, func()) {\n+func initBoltOnboardingService(f influxdbtesting.OnboardingFields, useTokenHashing bool, t *testing.T) (influxdb.OnboardingService, func()) {\n \ts := influxdbtesting.NewTestInmemStore(t)\n-\tsvc := initOnboardingService(s, f, t)\n+\tsvc := initOnboardingService(s, f, useTokenHashing, t)\n \treturn svc, func() {}\n }\n \n-func initOnboardingService(s kv.Store, f influxdbtesting.OnboardingFields, t *testing.T) influxdb.OnboardingService {\n+func initOnboardingService(s kv.Store, f influxdbtesting.OnboardingFields, useTokenHashing bool, t *testing.T) influxdb.OnboardingService {\n+\tctx := context.Background()\n+\n \tstorage := tenant.NewStore(s)\n \tten := tenant.NewService(storage)\n \n-\tauthStore, err := authorization.NewStore(s)\n+\tauthStore, err := authorization.NewStore(ctx, s, useTokenHashing)",
        "comment_created_at": "2025-02-14T23:03:09+00:00",
        "comment_author": "gwossum",
        "comment_body": "It's potential security issue if we forget to pass it, so I wanted to make sure we always pass it. It also helps locate tests that need to be run with both hashing enabled and disabled.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1964273399",
    "pr_number": 25982,
    "pr_file": "authorization/storage.go",
    "created_at": "2025-02-20T20:10:54+00:00",
    "commented_code": "import (\n \t\"context\"\n+\tgoerrors \"errors\"\n+\t\"fmt\"\n+\t\"slices\"\n \n+\t\"github.com/go-crypt/crypt\"\n+\t\"github.com/influxdata/influxdb/v2\"\n \t\"github.com/influxdata/influxdb/v2/kit/platform\"\n \t\"github.com/influxdata/influxdb/v2/kit/platform/errors\"\n \t\"github.com/influxdata/influxdb/v2/kit/tracing\"\n \t\"github.com/influxdata/influxdb/v2/kv\"\n+\tinfluxdb2_algo \"github.com/influxdata/influxdb/v2/pkg/crypt/algorithm/influxdb2\"\n \t\"github.com/influxdata/influxdb/v2/snowflake\"\n )\n \n+/*---\n+Token storage and verification\n+\n+Storage of hashed tokens has been added as an optional feature. This stores only the hash of a token\n+in BoltDB. Token hashing is enabled with the `--use-hashed-tokens` option.\n+\n+Upgrading the BoltDB schema is automatic on startup when using a new version of InfluxDB with token hashing support.\n+Additionally, raw tokens are automatically migrated to hashed tokens if `--use-hashed-tokens` is configured.\n+Due to the schema changes, to use a version of InfluxDB without hashed token support, a manual downgrade using\n+`influxd downgrade` must be run. Any tokens stored as hashed tokens will be unusable by the old version of InfluxDB\n+and must be reset or recreated.\n+\n+The implementation has the following behaviors under different scenarios:\n+* Token hashing is enabled.\n+  * On startup and upgrade, any raw tokens in BoltDB are automatically hashed. The hashed token is\n+    stored and the raw token is removed. No raw tokens remain in BoltDB.\n+  * On downgrade, hashed tokens are deleted from BoltDB along with their indices. User confirmation\n+    is required to proceed if hashed tokens are present.\n+  * Token verification is performed by hashing the token and finding the hashed token in BoltDB.\n+  * New tokens generated are stored only as hashes.\n+  * When creating a backup, only hashed tokens are exported.\n+  * When restoring a backup, any raw tokens are converted to hashed tokens and stored only as hashes.\n+    No raw tokens are imported into BoltDB.\n+  * When listing tokens, the hash algorithm used (e.g. `SHA-512`) is returned instead of the hashed token value.\n+* Token hashing is disabled.\n+  * On upgrade and startup, no user visible action is taken. Any hashed tokens in BoltDB remain unchanged.\n+    The BoltDB store is updated to support hashed tokens, but no existing tokens are migrated.\n+  * On downgrade, hashed tokens are deleted from BoltDB along with their indices. User confirmation\n+    is required to proceed if hashed tokens are present.\n+  * Token verification is performed by looking up the raw token value, if the provided token is not in PHC format.\n+    If the raw token value is not found, then the hashed token value is calculated and token lookup attempted again.\n+  * New tokens generated are stored as raw tokens.\n+  * When creating a backup, tokens are exported in the format found in BoltDB (raw or hashed).\n+  * When restoring a backup, both raw tokens and hashed tokens are restored unchanged.\n+  * When listing tokens, raw tokens in BoltDB are returned. Hashed tokens in BoltDB are returned as\n+    the hash algorithm (e.g. `SHA-512``) instead of the hashed token value.\n+* Downgrading to an older InfluxDB without hashed token support with a BoltDB containing hashed tokens.\n+  * Downgrading requires a manual `influxd downgrade` command. If hashed tokens are found in the\n+    BoltDB, user confirmation is required. The user can also list impacted tokens. When downgrade is\n+\tcomplete, all hashed tokens have been deleted from BoltDB along with their indices. The tokens with\n+\tdeleted hashes are no longer useable.\n+  * Operations are as usual in InfluxDB 2.7.\n+\n+The hashed tokens in `Authorization.HashedToken` are stored in PHC format. PHC allows specifying the\n+algorithm used and any parameters. This allows gradual token algorithm transitions if new token hashing\n+algorithms are added in the future. PHC is used over MCF (Modular Crypt Format) because PHC is more\n+flexible and MCF does not support our chosen hash scheme.\n+\n+When token hashing is enabled, on every startup (not just upgrade) InfluxDB scans the BoltDB for raw tokens in\n+the `Authorization.Token` field. When found, a hash is immediately stored in the `Authorization.HashedToken`\n+field and the `Authorization.Token` field is cleared. The token index is also updated to use the hashed\n+token value instead of the raw token value. This migration must occur on every startup and not just upgrades\n+because hashed tokens can be turned on and off with configuration.\n+\n+When a backup is made, the format stored in BoltDB is exported as-is. If hashed tokens are enabled, only hashed\n+tokens are exported since only hashed tokens are stored. Without enabling hashed tokens, a mix of raw and\n+hashed tokens may be present in the backup.\n+\n+When token hashing is enabled and a backup is restored, raw tokens are hashed before importing\n+into BoltDB. Raw tokens are not stored.\n+\n+To verify tokens when hashed tokens are enabled, the presented token's hash is calculated and used\n+for token index lookup. The rest of the authorization flow is unchanged.\n+\n+To verify tokens when hashed tokens are disabled, the an attempt is made to parse the presented token as\n+PHC. If the parse succeeds, the access is denied. This prevents an attack described below. After this check,\n+the presented raw token is used to lookup the token in the raw token index. If found, authorization proceeds\n+as normal. Otherwise, the token hash is calculated and used to lookup the token in the hashed token index.\n+A second check is then done on the authorization record token or token hash matches the presented token.\n+If found, authorization proceeds as normal.\n+\n+The hashed token index is separate from the raw token index. Newer versions also verify that the token\n+is not a valid PHC string before starting authorization. This prevents the following attack:\n+1. Hashed token is extracted from BoltDB.\n+2. Token hashing is disabled.\n+3. The hashed token is presented to the API, which will misinterpret it as a raw token and allow access.\n+\n+The token hashing algorithm is SHA-512. This provides a good level of security and is allowed by FIPS 140-2.\n+Because the token hashes must be useable as index lookups, salted password hashes (e.g. bcrypt, PBKDF2, Argon)\n+can not be used.\n+\n+A potential future security would be optionally storing \"peppered\" hashes. This would require retrieving\n+the pepper key from outside of BoltDB, for example from Vault.\n+\n+When listing tokens, hashed tokens are listed as \"REDACTED\" instead of the hashed\n+token value. Raw token values are returned as in previous versions.\n+\n+---*/\n+\n const MaxIDGenerationN = 100\n const ReservedIDs = 1000\n \n var (\n-\tauthBucket = []byte(\"authorizationsv1\")\n-\tauthIndex  = []byte(\"authorizationindexv1\")\n+\tErrReadOnly = goerrors.New(\"authorization store is read-only\")\n+)\n+\n+var (\n+\tauthBucket      = []byte(\"authorizationsv1\")\n+\tauthIndex       = []byte(\"authorizationindexv1\")\n+\thashedAuthIndex = []byte(\"authorizationhashedindexv1\")\n )\n \n type Store struct {\n \tkvStore kv.Store\n \tIDGen   platform.IDGenerator\n+\thasher  *AuthorizationHasher\n+\n+\t// Indicates if tokens should be stored in hashed PHC format.\n+\tuseHashedTokens bool\n+\n+\t// Indicates if Store is read-only.\n+\treadOnly bool\n+\n+\t// ignoreMissingHashIndex indicates if missing hash indices in store should be ignored.\n+\t// This is almost exclusively for testing.\n+\tignoreMissingHashIndex bool\n }\n \n-func NewStore(kvStore kv.Store) (*Store, error) {\n-\tst := &Store{\n-\t\tkvStore: kvStore,\n-\t\tIDGen:   snowflake.NewDefaultIDGenerator(),\n+type storePlusOptions struct {\n+\t*Store\n+\thasherVariantName string\n+}\n+\n+type StoreOption func(*storePlusOptions)\n+\n+func WithAuthorizationHasher(hasher *AuthorizationHasher) StoreOption {\n+\treturn func(s *storePlusOptions) {\n+\t\ts.hasher = hasher\n+\t}\n+}\n+\n+func WithAuthorizationHashVariantName(name string) StoreOption {\n+\treturn func(s *storePlusOptions) {\n+\t\ts.hasherVariantName = name\n+\t}\n+}\n+\n+func WithReadOnly(readOnly bool) StoreOption {\n+\treturn func(s *storePlusOptions) {\n+\t\ts.readOnly = readOnly\n+\t}\n+}\n+\n+func WithIgnoreMissingHashIndex(allowMissing bool) StoreOption {\n+\treturn func(s *storePlusOptions) {\n+\t\ts.ignoreMissingHashIndex = allowMissing\n \t}\n-\treturn st, st.setup()\n+}\n+\n+// NewStore creates a new authorization.Store object. kvStore is the underlying key-value store.\n+func NewStore(ctx context.Context, kvStore kv.Store, useHashedTokens bool, opts ...StoreOption) (*Store, error) {\n+\ts := &storePlusOptions{",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1964273399",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25982,
        "pr_file": "authorization/storage.go",
        "discussion_id": "1964273399",
        "commented_code": "@@ -2,33 +2,295 @@ package authorization\n \n import (\n \t\"context\"\n+\tgoerrors \"errors\"\n+\t\"fmt\"\n+\t\"slices\"\n \n+\t\"github.com/go-crypt/crypt\"\n+\t\"github.com/influxdata/influxdb/v2\"\n \t\"github.com/influxdata/influxdb/v2/kit/platform\"\n \t\"github.com/influxdata/influxdb/v2/kit/platform/errors\"\n \t\"github.com/influxdata/influxdb/v2/kit/tracing\"\n \t\"github.com/influxdata/influxdb/v2/kv\"\n+\tinfluxdb2_algo \"github.com/influxdata/influxdb/v2/pkg/crypt/algorithm/influxdb2\"\n \t\"github.com/influxdata/influxdb/v2/snowflake\"\n )\n \n+/*---\n+Token storage and verification\n+\n+Storage of hashed tokens has been added as an optional feature. This stores only the hash of a token\n+in BoltDB. Token hashing is enabled with the `--use-hashed-tokens` option.\n+\n+Upgrading the BoltDB schema is automatic on startup when using a new version of InfluxDB with token hashing support.\n+Additionally, raw tokens are automatically migrated to hashed tokens if `--use-hashed-tokens` is configured.\n+Due to the schema changes, to use a version of InfluxDB without hashed token support, a manual downgrade using\n+`influxd downgrade` must be run. Any tokens stored as hashed tokens will be unusable by the old version of InfluxDB\n+and must be reset or recreated.\n+\n+The implementation has the following behaviors under different scenarios:\n+* Token hashing is enabled.\n+  * On startup and upgrade, any raw tokens in BoltDB are automatically hashed. The hashed token is\n+    stored and the raw token is removed. No raw tokens remain in BoltDB.\n+  * On downgrade, hashed tokens are deleted from BoltDB along with their indices. User confirmation\n+    is required to proceed if hashed tokens are present.\n+  * Token verification is performed by hashing the token and finding the hashed token in BoltDB.\n+  * New tokens generated are stored only as hashes.\n+  * When creating a backup, only hashed tokens are exported.\n+  * When restoring a backup, any raw tokens are converted to hashed tokens and stored only as hashes.\n+    No raw tokens are imported into BoltDB.\n+  * When listing tokens, the hash algorithm used (e.g. `SHA-512`) is returned instead of the hashed token value.\n+* Token hashing is disabled.\n+  * On upgrade and startup, no user visible action is taken. Any hashed tokens in BoltDB remain unchanged.\n+    The BoltDB store is updated to support hashed tokens, but no existing tokens are migrated.\n+  * On downgrade, hashed tokens are deleted from BoltDB along with their indices. User confirmation\n+    is required to proceed if hashed tokens are present.\n+  * Token verification is performed by looking up the raw token value, if the provided token is not in PHC format.\n+    If the raw token value is not found, then the hashed token value is calculated and token lookup attempted again.\n+  * New tokens generated are stored as raw tokens.\n+  * When creating a backup, tokens are exported in the format found in BoltDB (raw or hashed).\n+  * When restoring a backup, both raw tokens and hashed tokens are restored unchanged.\n+  * When listing tokens, raw tokens in BoltDB are returned. Hashed tokens in BoltDB are returned as\n+    the hash algorithm (e.g. `SHA-512``) instead of the hashed token value.\n+* Downgrading to an older InfluxDB without hashed token support with a BoltDB containing hashed tokens.\n+  * Downgrading requires a manual `influxd downgrade` command. If hashed tokens are found in the\n+    BoltDB, user confirmation is required. The user can also list impacted tokens. When downgrade is\n+\tcomplete, all hashed tokens have been deleted from BoltDB along with their indices. The tokens with\n+\tdeleted hashes are no longer useable.\n+  * Operations are as usual in InfluxDB 2.7.\n+\n+The hashed tokens in `Authorization.HashedToken` are stored in PHC format. PHC allows specifying the\n+algorithm used and any parameters. This allows gradual token algorithm transitions if new token hashing\n+algorithms are added in the future. PHC is used over MCF (Modular Crypt Format) because PHC is more\n+flexible and MCF does not support our chosen hash scheme.\n+\n+When token hashing is enabled, on every startup (not just upgrade) InfluxDB scans the BoltDB for raw tokens in\n+the `Authorization.Token` field. When found, a hash is immediately stored in the `Authorization.HashedToken`\n+field and the `Authorization.Token` field is cleared. The token index is also updated to use the hashed\n+token value instead of the raw token value. This migration must occur on every startup and not just upgrades\n+because hashed tokens can be turned on and off with configuration.\n+\n+When a backup is made, the format stored in BoltDB is exported as-is. If hashed tokens are enabled, only hashed\n+tokens are exported since only hashed tokens are stored. Without enabling hashed tokens, a mix of raw and\n+hashed tokens may be present in the backup.\n+\n+When token hashing is enabled and a backup is restored, raw tokens are hashed before importing\n+into BoltDB. Raw tokens are not stored.\n+\n+To verify tokens when hashed tokens are enabled, the presented token's hash is calculated and used\n+for token index lookup. The rest of the authorization flow is unchanged.\n+\n+To verify tokens when hashed tokens are disabled, the an attempt is made to parse the presented token as\n+PHC. If the parse succeeds, the access is denied. This prevents an attack described below. After this check,\n+the presented raw token is used to lookup the token in the raw token index. If found, authorization proceeds\n+as normal. Otherwise, the token hash is calculated and used to lookup the token in the hashed token index.\n+A second check is then done on the authorization record token or token hash matches the presented token.\n+If found, authorization proceeds as normal.\n+\n+The hashed token index is separate from the raw token index. Newer versions also verify that the token\n+is not a valid PHC string before starting authorization. This prevents the following attack:\n+1. Hashed token is extracted from BoltDB.\n+2. Token hashing is disabled.\n+3. The hashed token is presented to the API, which will misinterpret it as a raw token and allow access.\n+\n+The token hashing algorithm is SHA-512. This provides a good level of security and is allowed by FIPS 140-2.\n+Because the token hashes must be useable as index lookups, salted password hashes (e.g. bcrypt, PBKDF2, Argon)\n+can not be used.\n+\n+A potential future security would be optionally storing \"peppered\" hashes. This would require retrieving\n+the pepper key from outside of BoltDB, for example from Vault.\n+\n+When listing tokens, hashed tokens are listed as \"REDACTED\" instead of the hashed\n+token value. Raw token values are returned as in previous versions.\n+\n+---*/\n+\n const MaxIDGenerationN = 100\n const ReservedIDs = 1000\n \n var (\n-\tauthBucket = []byte(\"authorizationsv1\")\n-\tauthIndex  = []byte(\"authorizationindexv1\")\n+\tErrReadOnly = goerrors.New(\"authorization store is read-only\")\n+)\n+\n+var (\n+\tauthBucket      = []byte(\"authorizationsv1\")\n+\tauthIndex       = []byte(\"authorizationindexv1\")\n+\thashedAuthIndex = []byte(\"authorizationhashedindexv1\")\n )\n \n type Store struct {\n \tkvStore kv.Store\n \tIDGen   platform.IDGenerator\n+\thasher  *AuthorizationHasher\n+\n+\t// Indicates if tokens should be stored in hashed PHC format.\n+\tuseHashedTokens bool\n+\n+\t// Indicates if Store is read-only.\n+\treadOnly bool\n+\n+\t// ignoreMissingHashIndex indicates if missing hash indices in store should be ignored.\n+\t// This is almost exclusively for testing.\n+\tignoreMissingHashIndex bool\n }\n \n-func NewStore(kvStore kv.Store) (*Store, error) {\n-\tst := &Store{\n-\t\tkvStore: kvStore,\n-\t\tIDGen:   snowflake.NewDefaultIDGenerator(),\n+type storePlusOptions struct {\n+\t*Store\n+\thasherVariantName string\n+}\n+\n+type StoreOption func(*storePlusOptions)\n+\n+func WithAuthorizationHasher(hasher *AuthorizationHasher) StoreOption {\n+\treturn func(s *storePlusOptions) {\n+\t\ts.hasher = hasher\n+\t}\n+}\n+\n+func WithAuthorizationHashVariantName(name string) StoreOption {\n+\treturn func(s *storePlusOptions) {\n+\t\ts.hasherVariantName = name\n+\t}\n+}\n+\n+func WithReadOnly(readOnly bool) StoreOption {\n+\treturn func(s *storePlusOptions) {\n+\t\ts.readOnly = readOnly\n+\t}\n+}\n+\n+func WithIgnoreMissingHashIndex(allowMissing bool) StoreOption {\n+\treturn func(s *storePlusOptions) {\n+\t\ts.ignoreMissingHashIndex = allowMissing\n \t}\n-\treturn st, st.setup()\n+}\n+\n+// NewStore creates a new authorization.Store object. kvStore is the underlying key-value store.\n+func NewStore(ctx context.Context, kvStore kv.Store, useHashedTokens bool, opts ...StoreOption) (*Store, error) {\n+\ts := &storePlusOptions{",
        "comment_created_at": "2025-02-20T20:10:54+00:00",
        "comment_author": "davidby-influx",
        "comment_body": "Should `useHashedTokens` be a `StoreOption` call, not a separate parameter?",
        "pr_file_module": null
      },
      {
        "comment_id": "1966330765",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25982,
        "pr_file": "authorization/storage.go",
        "discussion_id": "1964273399",
        "commented_code": "@@ -2,33 +2,295 @@ package authorization\n \n import (\n \t\"context\"\n+\tgoerrors \"errors\"\n+\t\"fmt\"\n+\t\"slices\"\n \n+\t\"github.com/go-crypt/crypt\"\n+\t\"github.com/influxdata/influxdb/v2\"\n \t\"github.com/influxdata/influxdb/v2/kit/platform\"\n \t\"github.com/influxdata/influxdb/v2/kit/platform/errors\"\n \t\"github.com/influxdata/influxdb/v2/kit/tracing\"\n \t\"github.com/influxdata/influxdb/v2/kv\"\n+\tinfluxdb2_algo \"github.com/influxdata/influxdb/v2/pkg/crypt/algorithm/influxdb2\"\n \t\"github.com/influxdata/influxdb/v2/snowflake\"\n )\n \n+/*---\n+Token storage and verification\n+\n+Storage of hashed tokens has been added as an optional feature. This stores only the hash of a token\n+in BoltDB. Token hashing is enabled with the `--use-hashed-tokens` option.\n+\n+Upgrading the BoltDB schema is automatic on startup when using a new version of InfluxDB with token hashing support.\n+Additionally, raw tokens are automatically migrated to hashed tokens if `--use-hashed-tokens` is configured.\n+Due to the schema changes, to use a version of InfluxDB without hashed token support, a manual downgrade using\n+`influxd downgrade` must be run. Any tokens stored as hashed tokens will be unusable by the old version of InfluxDB\n+and must be reset or recreated.\n+\n+The implementation has the following behaviors under different scenarios:\n+* Token hashing is enabled.\n+  * On startup and upgrade, any raw tokens in BoltDB are automatically hashed. The hashed token is\n+    stored and the raw token is removed. No raw tokens remain in BoltDB.\n+  * On downgrade, hashed tokens are deleted from BoltDB along with their indices. User confirmation\n+    is required to proceed if hashed tokens are present.\n+  * Token verification is performed by hashing the token and finding the hashed token in BoltDB.\n+  * New tokens generated are stored only as hashes.\n+  * When creating a backup, only hashed tokens are exported.\n+  * When restoring a backup, any raw tokens are converted to hashed tokens and stored only as hashes.\n+    No raw tokens are imported into BoltDB.\n+  * When listing tokens, the hash algorithm used (e.g. `SHA-512`) is returned instead of the hashed token value.\n+* Token hashing is disabled.\n+  * On upgrade and startup, no user visible action is taken. Any hashed tokens in BoltDB remain unchanged.\n+    The BoltDB store is updated to support hashed tokens, but no existing tokens are migrated.\n+  * On downgrade, hashed tokens are deleted from BoltDB along with their indices. User confirmation\n+    is required to proceed if hashed tokens are present.\n+  * Token verification is performed by looking up the raw token value, if the provided token is not in PHC format.\n+    If the raw token value is not found, then the hashed token value is calculated and token lookup attempted again.\n+  * New tokens generated are stored as raw tokens.\n+  * When creating a backup, tokens are exported in the format found in BoltDB (raw or hashed).\n+  * When restoring a backup, both raw tokens and hashed tokens are restored unchanged.\n+  * When listing tokens, raw tokens in BoltDB are returned. Hashed tokens in BoltDB are returned as\n+    the hash algorithm (e.g. `SHA-512``) instead of the hashed token value.\n+* Downgrading to an older InfluxDB without hashed token support with a BoltDB containing hashed tokens.\n+  * Downgrading requires a manual `influxd downgrade` command. If hashed tokens are found in the\n+    BoltDB, user confirmation is required. The user can also list impacted tokens. When downgrade is\n+\tcomplete, all hashed tokens have been deleted from BoltDB along with their indices. The tokens with\n+\tdeleted hashes are no longer useable.\n+  * Operations are as usual in InfluxDB 2.7.\n+\n+The hashed tokens in `Authorization.HashedToken` are stored in PHC format. PHC allows specifying the\n+algorithm used and any parameters. This allows gradual token algorithm transitions if new token hashing\n+algorithms are added in the future. PHC is used over MCF (Modular Crypt Format) because PHC is more\n+flexible and MCF does not support our chosen hash scheme.\n+\n+When token hashing is enabled, on every startup (not just upgrade) InfluxDB scans the BoltDB for raw tokens in\n+the `Authorization.Token` field. When found, a hash is immediately stored in the `Authorization.HashedToken`\n+field and the `Authorization.Token` field is cleared. The token index is also updated to use the hashed\n+token value instead of the raw token value. This migration must occur on every startup and not just upgrades\n+because hashed tokens can be turned on and off with configuration.\n+\n+When a backup is made, the format stored in BoltDB is exported as-is. If hashed tokens are enabled, only hashed\n+tokens are exported since only hashed tokens are stored. Without enabling hashed tokens, a mix of raw and\n+hashed tokens may be present in the backup.\n+\n+When token hashing is enabled and a backup is restored, raw tokens are hashed before importing\n+into BoltDB. Raw tokens are not stored.\n+\n+To verify tokens when hashed tokens are enabled, the presented token's hash is calculated and used\n+for token index lookup. The rest of the authorization flow is unchanged.\n+\n+To verify tokens when hashed tokens are disabled, the an attempt is made to parse the presented token as\n+PHC. If the parse succeeds, the access is denied. This prevents an attack described below. After this check,\n+the presented raw token is used to lookup the token in the raw token index. If found, authorization proceeds\n+as normal. Otherwise, the token hash is calculated and used to lookup the token in the hashed token index.\n+A second check is then done on the authorization record token or token hash matches the presented token.\n+If found, authorization proceeds as normal.\n+\n+The hashed token index is separate from the raw token index. Newer versions also verify that the token\n+is not a valid PHC string before starting authorization. This prevents the following attack:\n+1. Hashed token is extracted from BoltDB.\n+2. Token hashing is disabled.\n+3. The hashed token is presented to the API, which will misinterpret it as a raw token and allow access.\n+\n+The token hashing algorithm is SHA-512. This provides a good level of security and is allowed by FIPS 140-2.\n+Because the token hashes must be useable as index lookups, salted password hashes (e.g. bcrypt, PBKDF2, Argon)\n+can not be used.\n+\n+A potential future security would be optionally storing \"peppered\" hashes. This would require retrieving\n+the pepper key from outside of BoltDB, for example from Vault.\n+\n+When listing tokens, hashed tokens are listed as \"REDACTED\" instead of the hashed\n+token value. Raw token values are returned as in previous versions.\n+\n+---*/\n+\n const MaxIDGenerationN = 100\n const ReservedIDs = 1000\n \n var (\n-\tauthBucket = []byte(\"authorizationsv1\")\n-\tauthIndex  = []byte(\"authorizationindexv1\")\n+\tErrReadOnly = goerrors.New(\"authorization store is read-only\")\n+)\n+\n+var (\n+\tauthBucket      = []byte(\"authorizationsv1\")\n+\tauthIndex       = []byte(\"authorizationindexv1\")\n+\thashedAuthIndex = []byte(\"authorizationhashedindexv1\")\n )\n \n type Store struct {\n \tkvStore kv.Store\n \tIDGen   platform.IDGenerator\n+\thasher  *AuthorizationHasher\n+\n+\t// Indicates if tokens should be stored in hashed PHC format.\n+\tuseHashedTokens bool\n+\n+\t// Indicates if Store is read-only.\n+\treadOnly bool\n+\n+\t// ignoreMissingHashIndex indicates if missing hash indices in store should be ignored.\n+\t// This is almost exclusively for testing.\n+\tignoreMissingHashIndex bool\n }\n \n-func NewStore(kvStore kv.Store) (*Store, error) {\n-\tst := &Store{\n-\t\tkvStore: kvStore,\n-\t\tIDGen:   snowflake.NewDefaultIDGenerator(),\n+type storePlusOptions struct {\n+\t*Store\n+\thasherVariantName string\n+}\n+\n+type StoreOption func(*storePlusOptions)\n+\n+func WithAuthorizationHasher(hasher *AuthorizationHasher) StoreOption {\n+\treturn func(s *storePlusOptions) {\n+\t\ts.hasher = hasher\n+\t}\n+}\n+\n+func WithAuthorizationHashVariantName(name string) StoreOption {\n+\treturn func(s *storePlusOptions) {\n+\t\ts.hasherVariantName = name\n+\t}\n+}\n+\n+func WithReadOnly(readOnly bool) StoreOption {\n+\treturn func(s *storePlusOptions) {\n+\t\ts.readOnly = readOnly\n+\t}\n+}\n+\n+func WithIgnoreMissingHashIndex(allowMissing bool) StoreOption {\n+\treturn func(s *storePlusOptions) {\n+\t\ts.ignoreMissingHashIndex = allowMissing\n \t}\n-\treturn st, st.setup()\n+}\n+\n+// NewStore creates a new authorization.Store object. kvStore is the underlying key-value store.\n+func NewStore(ctx context.Context, kvStore kv.Store, useHashedTokens bool, opts ...StoreOption) (*Store, error) {\n+\ts := &storePlusOptions{",
        "comment_created_at": "2025-02-21T23:51:57+00:00",
        "comment_author": "gwossum",
        "comment_body": "Because leaving out a `WithHashedTokens` parameter could introduce a security issue, I wanted to force the programmer to specify if the parameter. Getting the hash algorithm (SHA256 vs SHA512) is relatively minor compared to accidentally running without token hashing.",
        "pr_file_module": null
      }
    ]
  }
]