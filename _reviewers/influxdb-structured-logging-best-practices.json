[
  {
    "discussion_id": "2050994123",
    "pr_number": 26294,
    "pr_file": "pkg/wg_timeout/wg_timeout.go",
    "created_at": "2025-04-18T18:51:22+00:00",
    "commented_code": "+package wg_timeout\n+\n+import (\n+\t\"sync\"\n+\t\"time\"\n+)\n+\n+func WaitGroupTimeout(wg *sync.WaitGroup, timeout time.Duration) bool {",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "2050994123",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 26294,
        "pr_file": "pkg/wg_timeout/wg_timeout.go",
        "discussion_id": "2050994123",
        "commented_code": "@@ -0,0 +1,25 @@\n+package wg_timeout\n+\n+import (\n+\t\"sync\"\n+\t\"time\"\n+)\n+\n+func WaitGroupTimeout(wg *sync.WaitGroup, timeout time.Duration) bool {",
        "comment_created_at": "2025-04-18T18:51:22+00:00",
        "comment_author": "davidby-influx",
        "comment_body": "I would take a `zap.Logger` and a message here.  Print the message at `Warn` level each time around the loop, with the total elapsed duration as a `zap` field. No return value - make this like `Wait`\r\n\r\nI would not return on  timer ticks; that will change the behavior of the system. Just log the wait. \r\n\r\nStyle suggestion: take `c` as an argument to the lambda, restricting its directionality, and renaming it.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2027747235",
    "pr_number": 26211,
    "pr_file": "tsdb/engine/tsm1/engine.go",
    "created_at": "2025-04-03T21:10:06+00:00",
    "commented_code": "// If no full compactions are need, see if an optimize is needed\n \t\t\tvar genLen int64\n \t\t\tif len(level4Groups) == 0 {\n-\t\t\t\tlevel4Groups, len4, genLen = e.CompactionPlan.PlanOptimize()\n+\t\t\t\tlevel4Groups, len4, genLen = e.CompactionPlan.PlanOptimize(e.LastModified())\n+\t\t\t\tif len(level4Groups) > 0 {\n+\t\t\t\t\tfor _, group := range level4Groups {\n+\t\t\t\t\t\te.logger.Info(\"TSM scheduled for optimized compaction\", zap.Any(\"file\", group))",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "2027747235",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 26211,
        "pr_file": "tsdb/engine/tsm1/engine.go",
        "discussion_id": "2027747235",
        "commented_code": "@@ -2134,7 +2134,12 @@ func (e *Engine) compact(wg *sync.WaitGroup) {\n \t\t\t// If no full compactions are need, see if an optimize is needed\n \t\t\tvar genLen int64\n \t\t\tif len(level4Groups) == 0 {\n-\t\t\t\tlevel4Groups, len4, genLen = e.CompactionPlan.PlanOptimize()\n+\t\t\t\tlevel4Groups, len4, genLen = e.CompactionPlan.PlanOptimize(e.LastModified())\n+\t\t\t\tif len(level4Groups) > 0 {\n+\t\t\t\t\tfor _, group := range level4Groups {\n+\t\t\t\t\t\te.logger.Info(\"TSM scheduled for optimized compaction\", zap.Any(\"file\", group))",
        "comment_created_at": "2025-04-03T21:10:06+00:00",
        "comment_author": "davidby-influx",
        "comment_body": "What does the `zap.Any` for the `group` print in the log?  This looks like it could be a huge log line.\r\n\r\nMaybe make a `tsmGeneration` method that returns a slice with just the file names, and use `zap.StringArray` or whatever? \r\n\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2027808015",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 26211,
        "pr_file": "tsdb/engine/tsm1/engine.go",
        "discussion_id": "2027747235",
        "commented_code": "@@ -2134,7 +2134,12 @@ func (e *Engine) compact(wg *sync.WaitGroup) {\n \t\t\t// If no full compactions are need, see if an optimize is needed\n \t\t\tvar genLen int64\n \t\t\tif len(level4Groups) == 0 {\n-\t\t\t\tlevel4Groups, len4, genLen = e.CompactionPlan.PlanOptimize()\n+\t\t\t\tlevel4Groups, len4, genLen = e.CompactionPlan.PlanOptimize(e.LastModified())\n+\t\t\t\tif len(level4Groups) > 0 {\n+\t\t\t\t\tfor _, group := range level4Groups {\n+\t\t\t\t\t\te.logger.Info(\"TSM scheduled for optimized compaction\", zap.Any(\"file\", group))",
        "comment_created_at": "2025-04-03T22:04:34+00:00",
        "comment_author": "devanbenz",
        "comment_body": "`group` is a list of the TSM files that will be picked up during compaction:\r\n\r\n```go\r\ntype CompactionGroup []string\r\n```\r\n\r\n~~I could not use `zap.StringArray` with it. Likely because its a custom type? I'll try to modify this.~~\r\n\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2027809227",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 26211,
        "pr_file": "tsdb/engine/tsm1/engine.go",
        "discussion_id": "2027747235",
        "commented_code": "@@ -2134,7 +2134,12 @@ func (e *Engine) compact(wg *sync.WaitGroup) {\n \t\t\t// If no full compactions are need, see if an optimize is needed\n \t\t\tvar genLen int64\n \t\t\tif len(level4Groups) == 0 {\n-\t\t\t\tlevel4Groups, len4, genLen = e.CompactionPlan.PlanOptimize()\n+\t\t\t\tlevel4Groups, len4, genLen = e.CompactionPlan.PlanOptimize(e.LastModified())\n+\t\t\t\tif len(level4Groups) > 0 {\n+\t\t\t\t\tfor _, group := range level4Groups {\n+\t\t\t\t\t\te.logger.Info(\"TSM scheduled for optimized compaction\", zap.Any(\"file\", group))",
        "comment_created_at": "2025-04-03T22:05:54+00:00",
        "comment_author": "devanbenz",
        "comment_body": "Disregard I was able to use `zap.Strings` ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1981977344",
    "pr_number": 26089,
    "pr_file": "tsdb/engine/tsm1/file_store.go",
    "created_at": "2025-03-05T18:44:48+00:00",
    "commented_code": "}\n \n func (p *purger) add(files []TSMFile) {\n+\tvar fileNames []string\n \tp.mu.Lock()\n \tfor _, f := range files {\n-\t\tp.files[f.Path()] = f\n+\t\tfileName := f.Path()\n+\t\tfileNames = append(fileNames, fileName)\n+\t\tp.files[fileName] = f\n \t}\n \tp.mu.Unlock()\n-\tp.purge()\n+\tp.purge(fileNames)\n }\n \n-func (p *purger) purge() {\n+func (p *purger) purge(fileNames []string) {\n+\tlogger, logEndOp := logger.NewOperation(p.logger, \"Purge held files\", \"filestore_purger\")\n+\n+\tlogger.Info(\"added\", zap.Int(\"count\", len(fileNames)))\n+\tlogger.Debug(\"purging\", zap.Strings(\"files\", fileNames))\n \tp.mu.Lock()\n \tif p.running {\n \t\tp.mu.Unlock()\n+\t\tlogger.Info(\"already running, files added to previous operation\")\n+\t\tlogEndOp()\n \t\treturn\n \t}\n \tp.running = true\n \tp.mu.Unlock()\n \n \tgo func() {\n+\t\tvar purgeCount int\n+\t\tdefer func() {\n+\t\t\tlogger.Info(\"removed\", zap.Int(\"files\", purgeCount))",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1981977344",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 26089,
        "pr_file": "tsdb/engine/tsm1/file_store.go",
        "discussion_id": "1981977344",
        "commented_code": "@@ -1570,24 +1568,38 @@ type purger struct {\n }\n \n func (p *purger) add(files []TSMFile) {\n+\tvar fileNames []string\n \tp.mu.Lock()\n \tfor _, f := range files {\n-\t\tp.files[f.Path()] = f\n+\t\tfileName := f.Path()\n+\t\tfileNames = append(fileNames, fileName)\n+\t\tp.files[fileName] = f\n \t}\n \tp.mu.Unlock()\n-\tp.purge()\n+\tp.purge(fileNames)\n }\n \n-func (p *purger) purge() {\n+func (p *purger) purge(fileNames []string) {\n+\tlogger, logEndOp := logger.NewOperation(p.logger, \"Purge held files\", \"filestore_purger\")\n+\n+\tlogger.Info(\"added\", zap.Int(\"count\", len(fileNames)))\n+\tlogger.Debug(\"purging\", zap.Strings(\"files\", fileNames))\n \tp.mu.Lock()\n \tif p.running {\n \t\tp.mu.Unlock()\n+\t\tlogger.Info(\"already running, files added to previous operation\")\n+\t\tlogEndOp()\n \t\treturn\n \t}\n \tp.running = true\n \tp.mu.Unlock()\n \n \tgo func() {\n+\t\tvar purgeCount int\n+\t\tdefer func() {\n+\t\t\tlogger.Info(\"removed\", zap.Int(\"files\", purgeCount))",
        "comment_created_at": "2025-03-05T18:44:48+00:00",
        "comment_author": "devanbenz",
        "comment_body": "Would it be a good idea to log out the file names that were removed as well as the count? I see we log the names out above, this may make it easier to compare the lists in the logs if any issues arise.  ",
        "pr_file_module": null
      },
      {
        "comment_id": "1982041548",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 26089,
        "pr_file": "tsdb/engine/tsm1/file_store.go",
        "discussion_id": "1981977344",
        "commented_code": "@@ -1570,24 +1568,38 @@ type purger struct {\n }\n \n func (p *purger) add(files []TSMFile) {\n+\tvar fileNames []string\n \tp.mu.Lock()\n \tfor _, f := range files {\n-\t\tp.files[f.Path()] = f\n+\t\tfileName := f.Path()\n+\t\tfileNames = append(fileNames, fileName)\n+\t\tp.files[fileName] = f\n \t}\n \tp.mu.Unlock()\n-\tp.purge()\n+\tp.purge(fileNames)\n }\n \n-func (p *purger) purge() {\n+func (p *purger) purge(fileNames []string) {\n+\tlogger, logEndOp := logger.NewOperation(p.logger, \"Purge held files\", \"filestore_purger\")\n+\n+\tlogger.Info(\"added\", zap.Int(\"count\", len(fileNames)))\n+\tlogger.Debug(\"purging\", zap.Strings(\"files\", fileNames))\n \tp.mu.Lock()\n \tif p.running {\n \t\tp.mu.Unlock()\n+\t\tlogger.Info(\"already running, files added to previous operation\")\n+\t\tlogEndOp()\n \t\treturn\n \t}\n \tp.running = true\n \tp.mu.Unlock()\n \n \tgo func() {\n+\t\tvar purgeCount int\n+\t\tdefer func() {\n+\t\t\tlogger.Info(\"removed\", zap.Int(\"files\", purgeCount))",
        "comment_created_at": "2025-03-05T19:07:08+00:00",
        "comment_author": "davidby-influx",
        "comment_body": "We print them out as they are deleted when the log level is `debug`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1909570865",
    "pr_number": 25710,
    "pr_file": "cmd/influxd/run/server.go",
    "created_at": "2025-01-09T23:09:03+00:00",
    "commented_code": "// so it only logs as is appropriate.\n \t\ts.QueryExecutor.TaskManager.Logger = s.Logger\n \t}\n+\tif s.config.Data.QueryLogPath != \"\" {\n+\t\tpath := s.config.Data.QueryLogPath\n+\t\tflw := query.NewFileLogWatcher(s.QueryExecutor, path, s.Logger, s.config.Logging.Format)\n+\t\tif flw != nil {\n+\t\t\ts.QueryExecutor.WithLogWriter(flw, context.Background())\n+\t\t} else {\n+\t\t\ts.Logger.Error(\"error creating log writer\", zap.String(\"path\", path))",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1909570865",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25710,
        "pr_file": "cmd/influxd/run/server.go",
        "discussion_id": "1909570865",
        "commented_code": "@@ -487,6 +487,16 @@ func (s *Server) Open() error {\n \t\t// so it only logs as is appropriate.\n \t\ts.QueryExecutor.TaskManager.Logger = s.Logger\n \t}\n+\tif s.config.Data.QueryLogPath != \"\" {\n+\t\tpath := s.config.Data.QueryLogPath\n+\t\tflw := query.NewFileLogWatcher(s.QueryExecutor, path, s.Logger, s.config.Logging.Format)\n+\t\tif flw != nil {\n+\t\t\ts.QueryExecutor.WithLogWriter(flw, context.Background())\n+\t\t} else {\n+\t\t\ts.Logger.Error(\"error creating log writer\", zap.String(\"path\", path))",
        "comment_created_at": "2025-01-09T23:09:03+00:00",
        "comment_author": "gwossum",
        "comment_body": "Yeah, if `NewFileLogWatcher` returned an error, you could log the error right here instead of this generic log message.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1842660673",
    "pr_number": 25517,
    "pr_file": "coordinator/points_writer.go",
    "created_at": "2024-11-14T17:51:50+00:00",
    "commented_code": "}\n \n // MapPoint adds the point to the ShardMapping, associated with the given shardInfo.\n-func (s *ShardMapping) MapPoint(shardInfo *meta.ShardInfo, p models.Point) {\n+func (s *ShardMapping) MapPoint(rp *meta.RetentionPolicyInfo, shardInfo *meta.ShardInfo, p models.Point) (dropped bool) {\n+\tif (rp != nil) &&\n+\t\t(((rp.FutureWriteLimit > 0) && p.Time().After(time.Now().Add(rp.FutureWriteLimit))) ||\n+\t\t\t((rp.PastWriteLimit > 0) && p.Time().Before(time.Now().Add(-rp.PastWriteLimit)))) {\n+\t\t// Point is too far in the future or too far in the past\n+\t\ts.Dropped = append(s.Dropped, p)",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1842660673",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25517,
        "pr_file": "coordinator/points_writer.go",
        "discussion_id": "1842660673",
        "commented_code": "@@ -113,12 +113,20 @@ func NewShardMapping(n int) *ShardMapping {\n }\n \n // MapPoint adds the point to the ShardMapping, associated with the given shardInfo.\n-func (s *ShardMapping) MapPoint(shardInfo *meta.ShardInfo, p models.Point) {\n+func (s *ShardMapping) MapPoint(rp *meta.RetentionPolicyInfo, shardInfo *meta.ShardInfo, p models.Point) (dropped bool) {\n+\tif (rp != nil) &&\n+\t\t(((rp.FutureWriteLimit > 0) && p.Time().After(time.Now().Add(rp.FutureWriteLimit))) ||\n+\t\t\t((rp.PastWriteLimit > 0) && p.Time().Before(time.Now().Add(-rp.PastWriteLimit)))) {\n+\t\t// Point is too far in the future or too far in the past\n+\t\ts.Dropped = append(s.Dropped, p)",
        "comment_created_at": "2024-11-14T17:51:50+00:00",
        "comment_author": "devanbenz",
        "comment_body": "Do we want to info log this information at all for potential debugging in the future? ",
        "pr_file_module": null
      },
      {
        "comment_id": "1842983694",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25517,
        "pr_file": "coordinator/points_writer.go",
        "discussion_id": "1842660673",
        "commented_code": "@@ -113,12 +113,20 @@ func NewShardMapping(n int) *ShardMapping {\n }\n \n // MapPoint adds the point to the ShardMapping, associated with the given shardInfo.\n-func (s *ShardMapping) MapPoint(shardInfo *meta.ShardInfo, p models.Point) {\n+func (s *ShardMapping) MapPoint(rp *meta.RetentionPolicyInfo, shardInfo *meta.ShardInfo, p models.Point) (dropped bool) {\n+\tif (rp != nil) &&\n+\t\t(((rp.FutureWriteLimit > 0) && p.Time().After(time.Now().Add(rp.FutureWriteLimit))) ||\n+\t\t\t((rp.PastWriteLimit > 0) && p.Time().Before(time.Now().Add(-rp.PastWriteLimit)))) {\n+\t\t// Point is too far in the future or too far in the past\n+\t\ts.Dropped = append(s.Dropped, p)",
        "comment_created_at": "2024-11-14T22:52:42+00:00",
        "comment_author": "davidby-influx",
        "comment_body": "There has been debate about this in 3.X; there can be thousands or millions of rejected points in some scenarios, so, at most, we would want to log the first few. I believe 3.X settled on logging the first 100 from every write request.\r\n\r\nThe error, and number of points dropped, are returned in a Partial Write Error, so the writer does receive the error.",
        "pr_file_module": null
      }
    ]
  }
]