[
  {
    "discussion_id": "2122376373",
    "pr_number": 26479,
    "pr_file": "influxdb3_catalog/src/catalog/update.rs",
    "created_at": "2025-06-03T00:28:18+00:00",
    "commented_code": ".await\n     }\n \n+    pub async fn set_retention_period_for_database(\n+        &self,\n+        db_name: &str,\n+        duration: Duration,\n+    ) -> Result<OrderedCatalogBatch> {\n+        info!(\"create new retention policy\");",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "2122376373",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 26479,
        "pr_file": "influxdb3_catalog/src/catalog/update.rs",
        "discussion_id": "2122376373",
        "commented_code": "@@ -702,6 +704,56 @@ impl Catalog {\n         .await\n     }\n \n+    pub async fn set_retention_period_for_database(\n+        &self,\n+        db_name: &str,\n+        duration: Duration,\n+    ) -> Result<OrderedCatalogBatch> {\n+        info!(\"create new retention policy\");",
        "comment_created_at": "2025-06-03T00:28:18+00:00",
        "comment_author": "hiltontj",
        "comment_body": "It would be useful to log the `db_name` and `duration` provided.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2122376506",
    "pr_number": 26479,
    "pr_file": "influxdb3_catalog/src/catalog/update.rs",
    "created_at": "2025-06-03T00:28:29+00:00",
    "commented_code": ".await\n     }\n \n+    pub async fn set_retention_period_for_database(\n+        &self,\n+        db_name: &str,\n+        duration: Duration,\n+    ) -> Result<OrderedCatalogBatch> {\n+        info!(\"create new retention policy\");\n+        let Some(db) = self.db_schema(db_name) else {\n+            return Err(CatalogError::NotFound);\n+        };\n+        self.catalog_update_with_retry(|| {\n+            Ok(CatalogBatch::database(\n+                self.time_provider.now().timestamp_nanos(),\n+                db.id,\n+                db.name(),\n+                vec![DatabaseCatalogOp::SetRetentionPeriod(\n+                    SetRetentionPeriodLog {\n+                        database_name: db.name(),\n+                        database_id: db.id,\n+                        retention_period: RetentionPeriod::Duration(duration),\n+                    },\n+                )],\n+            ))\n+        })\n+        .await\n+    }\n+\n+    pub async fn clear_retention_period_for_database(\n+        &self,\n+        db_name: &str,\n+    ) -> Result<OrderedCatalogBatch> {\n+        info!(\"delete retention policy\");",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "2122376506",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 26479,
        "pr_file": "influxdb3_catalog/src/catalog/update.rs",
        "discussion_id": "2122376506",
        "commented_code": "@@ -702,6 +704,56 @@ impl Catalog {\n         .await\n     }\n \n+    pub async fn set_retention_period_for_database(\n+        &self,\n+        db_name: &str,\n+        duration: Duration,\n+    ) -> Result<OrderedCatalogBatch> {\n+        info!(\"create new retention policy\");\n+        let Some(db) = self.db_schema(db_name) else {\n+            return Err(CatalogError::NotFound);\n+        };\n+        self.catalog_update_with_retry(|| {\n+            Ok(CatalogBatch::database(\n+                self.time_provider.now().timestamp_nanos(),\n+                db.id,\n+                db.name(),\n+                vec![DatabaseCatalogOp::SetRetentionPeriod(\n+                    SetRetentionPeriodLog {\n+                        database_name: db.name(),\n+                        database_id: db.id,\n+                        retention_period: RetentionPeriod::Duration(duration),\n+                    },\n+                )],\n+            ))\n+        })\n+        .await\n+    }\n+\n+    pub async fn clear_retention_period_for_database(\n+        &self,\n+        db_name: &str,\n+    ) -> Result<OrderedCatalogBatch> {\n+        info!(\"delete retention policy\");",
        "comment_created_at": "2025-06-03T00:28:29+00:00",
        "comment_author": "hiltontj",
        "comment_body": "It would be useful to log the `db_name`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1765033207",
    "pr_number": 25360,
    "pr_file": "influxdb3_write/src/persister.rs",
    "created_at": "2024-09-18T13:12:57+00:00",
    "commented_code": "&self.host_identifier_prefix\n     }\n \n-    /// Loads the most recently persisted catalog from object storage, and uses it to initialize\n-    /// a [`LastCacheProvider`].\n-    ///\n-    /// This is intended to be used on server start.\n-    pub async fn load_last_cache_and_catalog(\n-        &self,\n-        host_id: Arc<str>,\n-    ) -> Result<(LastCacheProvider, Catalog)> {\n-        match self.load_catalog().await? {\n-            Some(c) => Ok((\n-                LastCacheProvider::new_from_catalog(&c.catalog)?,\n-                Catalog::from_inner(c.catalog),\n-            )),\n+    /// Try loading the catalog, if there is no catalog generate new\n+    /// instance id and create a new catalog and persist it immediately\n+    pub async fn load_or_create_catalog(&self) -> Result<Catalog> {\n+        let catalog = match self.load_catalog().await? {\n+            Some(c) => Catalog::from_inner(c.catalog),\n             None => {\n                 let uuid = Uuid::new_v4().to_string();\n                 let instance_id = Arc::from(uuid.as_str());\n-                Ok((LastCacheProvider::new(), Catalog::new(host_id, instance_id)))\n+                info!(\"Created new instance id {:?}\", instance_id);",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1765033207",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25360,
        "pr_file": "influxdb3_write/src/persister.rs",
        "discussion_id": "1765033207",
        "commented_code": "@@ -120,25 +120,23 @@ impl Persister {\n         &self.host_identifier_prefix\n     }\n \n-    /// Loads the most recently persisted catalog from object storage, and uses it to initialize\n-    /// a [`LastCacheProvider`].\n-    ///\n-    /// This is intended to be used on server start.\n-    pub async fn load_last_cache_and_catalog(\n-        &self,\n-        host_id: Arc<str>,\n-    ) -> Result<(LastCacheProvider, Catalog)> {\n-        match self.load_catalog().await? {\n-            Some(c) => Ok((\n-                LastCacheProvider::new_from_catalog(&c.catalog)?,\n-                Catalog::from_inner(c.catalog),\n-            )),\n+    /// Try loading the catalog, if there is no catalog generate new\n+    /// instance id and create a new catalog and persist it immediately\n+    pub async fn load_or_create_catalog(&self) -> Result<Catalog> {\n+        let catalog = match self.load_catalog().await? {\n+            Some(c) => Catalog::from_inner(c.catalog),\n             None => {\n                 let uuid = Uuid::new_v4().to_string();\n                 let instance_id = Arc::from(uuid.as_str());\n-                Ok((LastCacheProvider::new(), Catalog::new(host_id, instance_id)))\n+                info!(\"Created new instance id {:?}\", instance_id);",
        "comment_created_at": "2024-09-18T13:12:57+00:00",
        "comment_author": "hiltontj",
        "comment_body": "```suggestion\r\n                info!(instance_id = ?instance_id, \"catalog not found, creating new instance id\");\r\n```\r\nJust encouraging use of `tracing`'s field syntax.\r\n\r\nThis is somewhat redundant with the `info!` emitted at the caller level, but I don't think it hurts to have.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1647754254",
    "pr_number": 25074,
    "pr_file": "influxdb3_write/src/write_buffer/buffer_segment.rs",
    "created_at": "2024-06-20T15:17:47+00:00",
    "commented_code": "self.segment_writer.write_batch(write_batch)\n     }\n \n+    pub fn sizes(&self) -> SegmentSizes {\n+        let mut database_buffer_sizes = HashMap::new();\n+        for (db_name, db_buffer) in &self.buffered_data.database_buffers {\n+            let mut table_sizes = HashMap::new();\n+            for (table_name, table_buffer) in &db_buffer.table_buffers {\n+                table_sizes.insert(table_name.clone(), table_buffer.computed_size());\n+            }\n+            database_buffer_sizes.insert(db_name.clone(), DatabaseBufferSizes { table_sizes });\n+        }\n+        SegmentSizes {\n+            database_buffer_sizes,\n+            segment_id: self.segment_id,\n+            segment_duration: self.segment_duration,\n+            segment_key: self.segment_key.clone(),\n+            segment_start_time: self.segment_range.start_time,\n+            last_write_time: self.last_write_time,\n+        }\n+    }\n+\n+    pub fn split_table_for_persistence(\n+        &mut self,\n+        db_name: &str,\n+        table_name: &str,\n+        schema: &Schema,\n+    ) -> Option<(ParquetFilePath, RecordBatch)> {\n+        let db_buffer = self.buffered_data.database_buffers.get_mut(db_name)?;\n+\n+        let table_buffer = db_buffer.table_buffers.get_mut(table_name)?;\n+\n+        let persist_batch = match table_buffer.split(schema.as_arrow()) {\n+            Ok(b) => b,\n+            Err(e) => {\n+                error!(%e, \"Error splitting table buffer for persistence\");",
    "repo_full_name": "influxdata/influxdb",
    "discussion_comments": [
      {
        "comment_id": "1647754254",
        "repo_full_name": "influxdata/influxdb",
        "pr_number": 25074,
        "pr_file": "influxdb3_write/src/write_buffer/buffer_segment.rs",
        "discussion_id": "1647754254",
        "commented_code": "@@ -99,6 +104,103 @@ impl OpenBufferSegment {\n         self.segment_writer.write_batch(write_batch)\n     }\n \n+    pub fn sizes(&self) -> SegmentSizes {\n+        let mut database_buffer_sizes = HashMap::new();\n+        for (db_name, db_buffer) in &self.buffered_data.database_buffers {\n+            let mut table_sizes = HashMap::new();\n+            for (table_name, table_buffer) in &db_buffer.table_buffers {\n+                table_sizes.insert(table_name.clone(), table_buffer.computed_size());\n+            }\n+            database_buffer_sizes.insert(db_name.clone(), DatabaseBufferSizes { table_sizes });\n+        }\n+        SegmentSizes {\n+            database_buffer_sizes,\n+            segment_id: self.segment_id,\n+            segment_duration: self.segment_duration,\n+            segment_key: self.segment_key.clone(),\n+            segment_start_time: self.segment_range.start_time,\n+            last_write_time: self.last_write_time,\n+        }\n+    }\n+\n+    pub fn split_table_for_persistence(\n+        &mut self,\n+        db_name: &str,\n+        table_name: &str,\n+        schema: &Schema,\n+    ) -> Option<(ParquetFilePath, RecordBatch)> {\n+        let db_buffer = self.buffered_data.database_buffers.get_mut(db_name)?;\n+\n+        let table_buffer = db_buffer.table_buffers.get_mut(table_name)?;\n+\n+        let persist_batch = match table_buffer.split(schema.as_arrow()) {\n+            Ok(b) => b,\n+            Err(e) => {\n+                error!(%e, \"Error splitting table buffer for persistence\");",
        "comment_created_at": "2024-06-20T15:17:47+00:00",
        "comment_author": "hiltontj",
        "comment_body": "This will show up in the logs as `e=<error message>`, I would either format it inline or use a more descriptive name, e.g.,\r\n```rust\r\nerror!(error = %e, \"...\");\r\n```\r\nOr rename the `e` to `error`, such that it appears as `error=<error message>` in the logs.",
        "pr_file_module": null
      }
    ]
  }
]