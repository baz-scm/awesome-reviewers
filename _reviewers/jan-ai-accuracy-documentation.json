[
  {
    "discussion_id": "2256280842",
    "pr_number": 6039,
    "pr_file": "docs/src/pages/post/deepresearch.mdx",
    "created_at": "2025-08-06T08:05:39+00:00",
    "commented_code": "+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this: \n+![Deep Research Flow Excalidraw](./_assets/deepresearch-flow.png)\n+The crux of Deep Research lies in the pipeline\u2019s ability to output a substantiated report which has cited information from a variety of sources.",
    "repo_full_name": "menloresearch/jan",
    "discussion_comments": [
      {
        "comment_id": "2256280842",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 6039,
        "pr_file": "docs/src/pages/post/deepresearch.mdx",
        "discussion_id": "2256280842",
        "commented_code": "@@ -0,0 +1,122 @@\n+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this: \n+![Deep Research Flow Excalidraw](./_assets/deepresearch-flow.png)\n+The crux of Deep Research lies in the pipeline\u2019s ability to output a substantiated report which has cited information from a variety of sources. ",
        "comment_created_at": "2025-08-06T08:05:39+00:00",
        "comment_author": "ramonpzg",
        "comment_body": "The crux of deep research is not the pipeline, it is the model and its capabilities. Without a model's ability to successfully call tools, check its state, absorb content, retry, and summarize, the pipeline means nothing. Some leaks around the deep research functionality of OpenAI say that the pipeline has very thin tools around it and the model does most of the heavy lifting.\r\n\r\nAnthropic has an excellent post on how their [research functionality works](https://web.archive.org/web/20250709175450/https://www.anthropic.com/engineering/built-multi-agent-research-system)",
        "pr_file_module": null
      },
      {
        "comment_id": "2258734348",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 6039,
        "pr_file": "docs/src/pages/post/deepresearch.mdx",
        "discussion_id": "2256280842",
        "commented_code": "@@ -0,0 +1,122 @@\n+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this: \n+![Deep Research Flow Excalidraw](./_assets/deepresearch-flow.png)\n+The crux of Deep Research lies in the pipeline\u2019s ability to output a substantiated report which has cited information from a variety of sources. ",
        "comment_created_at": "2025-08-07T02:42:11+00:00",
        "comment_author": "danielcwq",
        "comment_body": "oh this is really good. not sure why i missed it :/ ",
        "pr_file_module": null
      },
      {
        "comment_id": "2261819943",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 6039,
        "pr_file": "docs/src/pages/post/deepresearch.mdx",
        "discussion_id": "2256280842",
        "commented_code": "@@ -0,0 +1,122 @@\n+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this: \n+![Deep Research Flow Excalidraw](./_assets/deepresearch-flow.png)\n+The crux of Deep Research lies in the pipeline\u2019s ability to output a substantiated report which has cited information from a variety of sources. ",
        "comment_created_at": "2025-08-08T02:47:17+00:00",
        "comment_author": "danielcwq",
        "comment_body": "Addressed! Shifted it up to the first paragraph under \"unpacking deep research\": While the outputs of deep research might be mind-blowing at first glance, the underlying process is surprisingly systematic. The crux of Deep Research lies in the base model and its capabilities to use tools that are provided to it. Also added the blog post by Anthropic into the Claude Code section",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2256480284",
    "pr_number": 6039,
    "pr_file": "docs/src/pages/post/deepresearch.mdx",
    "created_at": "2025-08-06T09:04:47+00:00",
    "commented_code": "+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this: \n+![Deep Research Flow Excalidraw](./_assets/deepresearch-flow.png)\n+The crux of Deep Research lies in the pipeline\u2019s ability to output a substantiated report which has cited information from a variety of sources. \n+\n+<Callout type=\"info\">\n+**Different Flows for Different Providers**\n+\n+Note that not all Deep Research flows are the same as what's shown in the above diagram, only OpenAI and Kimi does this currently! Most providers would adopt a simpler approach, as shown below in the comparison table.\n+</Callout>\n+\n+| Platform | Pipeline Flow | Planning Approach | Sources Used | Duration (mins)  | Export Options | Unique Features | Deep Research Usage |\n+| --- | --- | --- | --- | --- | --- | --- | --- |\n+| OpenAI | Original prompt \u2192 clarification (smaller model) \u2192 user answers \u2192 rewriter bundles prompts \u2192 specific model \u2192 output | Chain of thought (COT), no explicit planning | 10\u201330 | 10\u201315 | PDF, Markdown with inline references | Clarification questions, lightweight rewriter model | Paid |\n+| Grok\u2019s DeeperSearch  | Planning \u2192 research execution \u2192 output with survey notes | Planning phase before research | 70\u2013100 | 5\u201310  | Not specified | Heavy Twitter/X source integration, \"Survey Note\" reasoning | Free |\n+| Claude | Research plan \u2192 breadth-first search \u2192 depth-first search | Research plan generated, multiple subagents for complex queries | 100+ | 5\u201310  | Artifact format | Breadth-first then depth-first approach, metadata extraction | Paid |\n+| Gemini | Original prompt \u2192 editable research plan \u2192 execution | Editable research plan (user can modify) | 50+ | 10\u201320  | Google Docs export | Editable planning phase, newer pipeline | Free |\n+| Perplexity | Research plan \u2192 execution with speed options | Research plan crafted and followed | 50\u2013100 | 3\u20135  | Not specified | \"Answer now\" option for quick results | Paid |\n+| Kimi | Query \u2192 clarifying questions \u2192 planning \u2192 research \u2192 synthesis | Explicit planning with clear phase transitions | 50\u2013100 | 30\u201360+ (slower inference)  | PDF, Interactive website | Distinction between \"search\" vs \"browser use\", interactive output | Free |\n+\n+### Understanding Search Strategies\n+\n+In general, when looking at the number of sources that are used, we can classify whether a search is *breadth first* or *depth first*. \n+\n+*Breadth first* searches would result in a greater number of sources that are used, which might be better for a brief survey over a landscape for instance. \n+\n+*Depth first* searches would entail diving deeper into a few particular sources (or have multiple search variations between a particular context), which might be better for extracting nuanced insight. \n+\n+<Callout>\n+In Claude\u2019s Deep Research, a *classifier* is used to determine whether a user query is *breadth first* or *depth first*. This results in a customization of the pipeline that is used for conducting research. For instance, a complex *breadth first* query might result in *sub-agents* being spun up to research various parts of the research query in parallel. \n+</Callout>\n+\n+## Replicating Deep Research Results with Jan\n+Given this overview, how would we replicate this in Jan? \n+\n+We\u2019ll make use of features that are available to us in order to customize the model output such that it gets as close to a Deep Research output without having to spend a cent, and having full control over your data!\n+\n+<Callout>\n+This is using the latest version of Jan (v0.6.6!) The features in this guide require at least 0.6.3 but for the best experience please use 0.6.6!\n+</Callout>\n+\n+### Setting up a Purpose Built Model for Deep Research with Jan\n+1. Under `Hub`, go to `Jan-Nano-128k-Gguf` and enable `Show variants`. Download the largest model that your computer can run! Jan-nano is a 4B model, so even with the largest quantization it should be able to run on your hardware comfortably. \n+![Navigate to Jan-Nano-128k](./_assets/jan-nano-hub.png)\n+\n+### Enabling Search through MCP\n+2. Once the model has been downloaded, it should appear under the `llama.cpp` provider.\n+3. Go to `Settings` > `General` and click on the toggle button next to `Experimental Features`. `MCP Servers` should then appear on the side bar. \n+![Enable MCP in Jan](./_assets/experimental-settings-jan.png)\n+4. Upon clicking on `MCP Servers`, click on the toggle beside `Allow All Tool Permissions` as well as the toggle beside `Serper`. Feel free to look through [this guide in our documentation](https://jan.ai/docs/mcp-examples/search/exa) if you would like to play around with different providers.\n+5. Click on the pencil (edit) button on `Serper` and navigate to [Serper login](https://serper.dev/login) to retrieve your Serper API key. Ensure that that is loaded under `Environment Variables` as shown below. \n+![Edit MCP Settings in Jan](./_assets/edit-mcp-settings.gif)\n+6. Upon inputting that, the following should appear on the top right hand of the screen. \n+![Successful Serper Init](./_assets/successful-serper.png)\n+7. Ensure that the downloaded model has access to tools by navigating to the following: `Settings` > `Model Providers` > Clicking on the `Pencil` icon and toggling `Tools` on!\n+![Enable Tools gif](./_assets/enable-tools-local.gif)\n+\n+### Customizing Assistants\n+8. Great! Now that you have search set up, let\u2019s [configure assistants](https://jan.ai/docs/assistants) to ensure that you make the most out of the model. Here\u2019s the prompt that we used for our assistant \u201cReport Writer\u201d:\n+```\n+Report Writing Instructions\n+You are a research analyst. Follow this exact process:\n+MANDATORY RESEARCH PHASE (Do this first)\n+\n+Conduct 5-10 searches maximum - then STOP searching and write the report\n+Each search query must be unique - no repeating previous searches\n+Search different angles: statistics, expert opinions, case studies, recent news, industry reports\n+Use web_fetch to read full articles from search results\n+\n+WRITING PHASE (Do this after research is complete)\n+Write a comprehensive report with:\n+\n+Executive summary with key findings\n+Evidence-based analysis with citations for every claim\n+Actionable recommendations with rationale\n+\n+CRITICAL: After 10 searches, immediately stop searching and write the report. Do not continue searching beyond 10 calls.\n+```\n+\n+## Piecing it All Together\n+The final result should look something like this! And voil\u00e0, you would have replicated the Deep Research flow on Jan!",
    "repo_full_name": "menloresearch/jan",
    "discussion_comments": [
      {
        "comment_id": "2256480284",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 6039,
        "pr_file": "docs/src/pages/post/deepresearch.mdx",
        "discussion_id": "2256480284",
        "commented_code": "@@ -0,0 +1,122 @@\n+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this: \n+![Deep Research Flow Excalidraw](./_assets/deepresearch-flow.png)\n+The crux of Deep Research lies in the pipeline\u2019s ability to output a substantiated report which has cited information from a variety of sources. \n+\n+<Callout type=\"info\">\n+**Different Flows for Different Providers**\n+\n+Note that not all Deep Research flows are the same as what's shown in the above diagram, only OpenAI and Kimi does this currently! Most providers would adopt a simpler approach, as shown below in the comparison table.\n+</Callout>\n+\n+| Platform | Pipeline Flow | Planning Approach | Sources Used | Duration (mins)  | Export Options | Unique Features | Deep Research Usage |\n+| --- | --- | --- | --- | --- | --- | --- | --- |\n+| OpenAI | Original prompt \u2192 clarification (smaller model) \u2192 user answers \u2192 rewriter bundles prompts \u2192 specific model \u2192 output | Chain of thought (COT), no explicit planning | 10\u201330 | 10\u201315 | PDF, Markdown with inline references | Clarification questions, lightweight rewriter model | Paid |\n+| Grok\u2019s DeeperSearch  | Planning \u2192 research execution \u2192 output with survey notes | Planning phase before research | 70\u2013100 | 5\u201310  | Not specified | Heavy Twitter/X source integration, \"Survey Note\" reasoning | Free |\n+| Claude | Research plan \u2192 breadth-first search \u2192 depth-first search | Research plan generated, multiple subagents for complex queries | 100+ | 5\u201310  | Artifact format | Breadth-first then depth-first approach, metadata extraction | Paid |\n+| Gemini | Original prompt \u2192 editable research plan \u2192 execution | Editable research plan (user can modify) | 50+ | 10\u201320  | Google Docs export | Editable planning phase, newer pipeline | Free |\n+| Perplexity | Research plan \u2192 execution with speed options | Research plan crafted and followed | 50\u2013100 | 3\u20135  | Not specified | \"Answer now\" option for quick results | Paid |\n+| Kimi | Query \u2192 clarifying questions \u2192 planning \u2192 research \u2192 synthesis | Explicit planning with clear phase transitions | 50\u2013100 | 30\u201360+ (slower inference)  | PDF, Interactive website | Distinction between \"search\" vs \"browser use\", interactive output | Free |\n+\n+### Understanding Search Strategies\n+\n+In general, when looking at the number of sources that are used, we can classify whether a search is *breadth first* or *depth first*. \n+\n+*Breadth first* searches would result in a greater number of sources that are used, which might be better for a brief survey over a landscape for instance. \n+\n+*Depth first* searches would entail diving deeper into a few particular sources (or have multiple search variations between a particular context), which might be better for extracting nuanced insight. \n+\n+<Callout>\n+In Claude\u2019s Deep Research, a *classifier* is used to determine whether a user query is *breadth first* or *depth first*. This results in a customization of the pipeline that is used for conducting research. For instance, a complex *breadth first* query might result in *sub-agents* being spun up to research various parts of the research query in parallel. \n+</Callout>\n+\n+## Replicating Deep Research Results with Jan\n+Given this overview, how would we replicate this in Jan? \n+\n+We\u2019ll make use of features that are available to us in order to customize the model output such that it gets as close to a Deep Research output without having to spend a cent, and having full control over your data!\n+\n+<Callout>\n+This is using the latest version of Jan (v0.6.6!) The features in this guide require at least 0.6.3 but for the best experience please use 0.6.6!\n+</Callout>\n+\n+### Setting up a Purpose Built Model for Deep Research with Jan\n+1. Under `Hub`, go to `Jan-Nano-128k-Gguf` and enable `Show variants`. Download the largest model that your computer can run! Jan-nano is a 4B model, so even with the largest quantization it should be able to run on your hardware comfortably. \n+![Navigate to Jan-Nano-128k](./_assets/jan-nano-hub.png)\n+\n+### Enabling Search through MCP\n+2. Once the model has been downloaded, it should appear under the `llama.cpp` provider.\n+3. Go to `Settings` > `General` and click on the toggle button next to `Experimental Features`. `MCP Servers` should then appear on the side bar. \n+![Enable MCP in Jan](./_assets/experimental-settings-jan.png)\n+4. Upon clicking on `MCP Servers`, click on the toggle beside `Allow All Tool Permissions` as well as the toggle beside `Serper`. Feel free to look through [this guide in our documentation](https://jan.ai/docs/mcp-examples/search/exa) if you would like to play around with different providers.\n+5. Click on the pencil (edit) button on `Serper` and navigate to [Serper login](https://serper.dev/login) to retrieve your Serper API key. Ensure that that is loaded under `Environment Variables` as shown below. \n+![Edit MCP Settings in Jan](./_assets/edit-mcp-settings.gif)\n+6. Upon inputting that, the following should appear on the top right hand of the screen. \n+![Successful Serper Init](./_assets/successful-serper.png)\n+7. Ensure that the downloaded model has access to tools by navigating to the following: `Settings` > `Model Providers` > Clicking on the `Pencil` icon and toggling `Tools` on!\n+![Enable Tools gif](./_assets/enable-tools-local.gif)\n+\n+### Customizing Assistants\n+8. Great! Now that you have search set up, let\u2019s [configure assistants](https://jan.ai/docs/assistants) to ensure that you make the most out of the model. Here\u2019s the prompt that we used for our assistant \u201cReport Writer\u201d:\n+```\n+Report Writing Instructions\n+You are a research analyst. Follow this exact process:\n+MANDATORY RESEARCH PHASE (Do this first)\n+\n+Conduct 5-10 searches maximum - then STOP searching and write the report\n+Each search query must be unique - no repeating previous searches\n+Search different angles: statistics, expert opinions, case studies, recent news, industry reports\n+Use web_fetch to read full articles from search results\n+\n+WRITING PHASE (Do this after research is complete)\n+Write a comprehensive report with:\n+\n+Executive summary with key findings\n+Evidence-based analysis with citations for every claim\n+Actionable recommendations with rationale\n+\n+CRITICAL: After 10 searches, immediately stop searching and write the report. Do not continue searching beyond 10 calls.\n+```\n+\n+## Piecing it All Together\n+The final result should look something like this! And voil\u00e0, you would have replicated the Deep Research flow on Jan!",
        "comment_created_at": "2025-08-06T09:04:47+00:00",
        "comment_author": "ramonpzg",
        "comment_body": "We can't claim having replicated Deep Research in Jan but perhaps having created our own flavor of it in Jan.\r\n\r\nShowcase how to do this in Jan with cloud models as well. Compare the output of Jan Nanon with GPT-4o or other models. Dive deeper",
        "pr_file_module": null
      },
      {
        "comment_id": "2261832995",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 6039,
        "pr_file": "docs/src/pages/post/deepresearch.mdx",
        "discussion_id": "2256480284",
        "commented_code": "@@ -0,0 +1,122 @@\n+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this: \n+![Deep Research Flow Excalidraw](./_assets/deepresearch-flow.png)\n+The crux of Deep Research lies in the pipeline\u2019s ability to output a substantiated report which has cited information from a variety of sources. \n+\n+<Callout type=\"info\">\n+**Different Flows for Different Providers**\n+\n+Note that not all Deep Research flows are the same as what's shown in the above diagram, only OpenAI and Kimi does this currently! Most providers would adopt a simpler approach, as shown below in the comparison table.\n+</Callout>\n+\n+| Platform | Pipeline Flow | Planning Approach | Sources Used | Duration (mins)  | Export Options | Unique Features | Deep Research Usage |\n+| --- | --- | --- | --- | --- | --- | --- | --- |\n+| OpenAI | Original prompt \u2192 clarification (smaller model) \u2192 user answers \u2192 rewriter bundles prompts \u2192 specific model \u2192 output | Chain of thought (COT), no explicit planning | 10\u201330 | 10\u201315 | PDF, Markdown with inline references | Clarification questions, lightweight rewriter model | Paid |\n+| Grok\u2019s DeeperSearch  | Planning \u2192 research execution \u2192 output with survey notes | Planning phase before research | 70\u2013100 | 5\u201310  | Not specified | Heavy Twitter/X source integration, \"Survey Note\" reasoning | Free |\n+| Claude | Research plan \u2192 breadth-first search \u2192 depth-first search | Research plan generated, multiple subagents for complex queries | 100+ | 5\u201310  | Artifact format | Breadth-first then depth-first approach, metadata extraction | Paid |\n+| Gemini | Original prompt \u2192 editable research plan \u2192 execution | Editable research plan (user can modify) | 50+ | 10\u201320  | Google Docs export | Editable planning phase, newer pipeline | Free |\n+| Perplexity | Research plan \u2192 execution with speed options | Research plan crafted and followed | 50\u2013100 | 3\u20135  | Not specified | \"Answer now\" option for quick results | Paid |\n+| Kimi | Query \u2192 clarifying questions \u2192 planning \u2192 research \u2192 synthesis | Explicit planning with clear phase transitions | 50\u2013100 | 30\u201360+ (slower inference)  | PDF, Interactive website | Distinction between \"search\" vs \"browser use\", interactive output | Free |\n+\n+### Understanding Search Strategies\n+\n+In general, when looking at the number of sources that are used, we can classify whether a search is *breadth first* or *depth first*. \n+\n+*Breadth first* searches would result in a greater number of sources that are used, which might be better for a brief survey over a landscape for instance. \n+\n+*Depth first* searches would entail diving deeper into a few particular sources (or have multiple search variations between a particular context), which might be better for extracting nuanced insight. \n+\n+<Callout>\n+In Claude\u2019s Deep Research, a *classifier* is used to determine whether a user query is *breadth first* or *depth first*. This results in a customization of the pipeline that is used for conducting research. For instance, a complex *breadth first* query might result in *sub-agents* being spun up to research various parts of the research query in parallel. \n+</Callout>\n+\n+## Replicating Deep Research Results with Jan\n+Given this overview, how would we replicate this in Jan? \n+\n+We\u2019ll make use of features that are available to us in order to customize the model output such that it gets as close to a Deep Research output without having to spend a cent, and having full control over your data!\n+\n+<Callout>\n+This is using the latest version of Jan (v0.6.6!) The features in this guide require at least 0.6.3 but for the best experience please use 0.6.6!\n+</Callout>\n+\n+### Setting up a Purpose Built Model for Deep Research with Jan\n+1. Under `Hub`, go to `Jan-Nano-128k-Gguf` and enable `Show variants`. Download the largest model that your computer can run! Jan-nano is a 4B model, so even with the largest quantization it should be able to run on your hardware comfortably. \n+![Navigate to Jan-Nano-128k](./_assets/jan-nano-hub.png)\n+\n+### Enabling Search through MCP\n+2. Once the model has been downloaded, it should appear under the `llama.cpp` provider.\n+3. Go to `Settings` > `General` and click on the toggle button next to `Experimental Features`. `MCP Servers` should then appear on the side bar. \n+![Enable MCP in Jan](./_assets/experimental-settings-jan.png)\n+4. Upon clicking on `MCP Servers`, click on the toggle beside `Allow All Tool Permissions` as well as the toggle beside `Serper`. Feel free to look through [this guide in our documentation](https://jan.ai/docs/mcp-examples/search/exa) if you would like to play around with different providers.\n+5. Click on the pencil (edit) button on `Serper` and navigate to [Serper login](https://serper.dev/login) to retrieve your Serper API key. Ensure that that is loaded under `Environment Variables` as shown below. \n+![Edit MCP Settings in Jan](./_assets/edit-mcp-settings.gif)\n+6. Upon inputting that, the following should appear on the top right hand of the screen. \n+![Successful Serper Init](./_assets/successful-serper.png)\n+7. Ensure that the downloaded model has access to tools by navigating to the following: `Settings` > `Model Providers` > Clicking on the `Pencil` icon and toggling `Tools` on!\n+![Enable Tools gif](./_assets/enable-tools-local.gif)\n+\n+### Customizing Assistants\n+8. Great! Now that you have search set up, let\u2019s [configure assistants](https://jan.ai/docs/assistants) to ensure that you make the most out of the model. Here\u2019s the prompt that we used for our assistant \u201cReport Writer\u201d:\n+```\n+Report Writing Instructions\n+You are a research analyst. Follow this exact process:\n+MANDATORY RESEARCH PHASE (Do this first)\n+\n+Conduct 5-10 searches maximum - then STOP searching and write the report\n+Each search query must be unique - no repeating previous searches\n+Search different angles: statistics, expert opinions, case studies, recent news, industry reports\n+Use web_fetch to read full articles from search results\n+\n+WRITING PHASE (Do this after research is complete)\n+Write a comprehensive report with:\n+\n+Executive summary with key findings\n+Evidence-based analysis with citations for every claim\n+Actionable recommendations with rationale\n+\n+CRITICAL: After 10 searches, immediately stop searching and write the report. Do not continue searching beyond 10 calls.\n+```\n+\n+## Piecing it All Together\n+The final result should look something like this! And voil\u00e0, you would have replicated the Deep Research flow on Jan!",
        "comment_created_at": "2025-08-08T03:01:48+00:00",
        "comment_author": "danielcwq",
        "comment_body": "Addressed -- see above! ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1937305799",
    "pr_number": 4552,
    "pr_file": "docs/src/pages/post/deepseek-r1-locally.mdx",
    "created_at": "2025-01-31T13:15:33+00:00",
    "commented_code": "+---\n+title: \"Beginner's Guide: Run DeepSeek R1 Locally (Private)\"\n+description: \"Quick steps on how to run DeepSeek R1 locally for full privacy. Perfect for beginners\u2014no coding required.\"\n+tags: DeepSeek, R1, local AI, Jan, GGUF, Qwen, Llama\n+categories: guides\n+date: 2024-01-31\n+ogImage: assets/run-deepseek-r1-locally-in-jan.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Beginner\u2019s Guide: Run DeepSeek R1 Locally \n+\n+![image](./_assets/run-deepseek-r1-locally-in-jan.jpg)\n+\n+You can run DeepSeek R1 on your own computer! While the full model needs very powerful hardware, we'll use a smaller version that works great on regular computers.\n+\n+Why use a smaller version?\n+- Works smoothly on most modern computers\n+- Downloads much faster\n+- Uses less storage space on your computer\n+\n+## Quick Steps at a Glance\n+1. Download and install [Jan](https://jan.ai/) (just like any other app!)\n+2. Pick a version that fits your computer\n+3. Choose the best settings\n+4. Set up a quick template & start chatting!\n+\n+Keep reading for a step-by-step guide with pictures.\n+\n+## Step 1: Download Jan\n+[Jan](https://jan.ai/) is a free app that helps you run AI models on your computer. It works on Windows, Mac, and Linux, and it's super easy to use - no coding needed!\n+\n+![image](./_assets/download-jan.jpg)\n+\n+- Get Jan from [jan.ai](https://jan.ai)\n+- Install it like you would any other app\n+- That's it! Jan takes care of all the technical stuff for you\n+\n+## Step 2: Choose Your DeepSeek R1 Version\n+DeepSeek R1 comes in different sizes. Let's help you pick the right one for your computer.\n+\n+<Callout type=\"info\">\n+\ud83d\udca1 Not sure how much VRAM your computer has? \n+- Windows: Press Windows + R, type \"dxdiag\", press Enter, and click the \"Display\" tab\n+- Mac: Click Apple menu > About This Mac > More Info > Graphics/Displays\n+</Callout>\n+\n+Below is a detailed table showing which version you can run based on your computer's VRAM:",
    "repo_full_name": "menloresearch/jan",
    "discussion_comments": [
      {
        "comment_id": "1937305799",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 4552,
        "pr_file": "docs/src/pages/post/deepseek-r1-locally.mdx",
        "discussion_id": "1937305799",
        "commented_code": "@@ -0,0 +1,109 @@\n+---\n+title: \"Beginner's Guide: Run DeepSeek R1 Locally (Private)\"\n+description: \"Quick steps on how to run DeepSeek R1 locally for full privacy. Perfect for beginners\u2014no coding required.\"\n+tags: DeepSeek, R1, local AI, Jan, GGUF, Qwen, Llama\n+categories: guides\n+date: 2024-01-31\n+ogImage: assets/run-deepseek-r1-locally-in-jan.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Beginner\u2019s Guide: Run DeepSeek R1 Locally \n+\n+![image](./_assets/run-deepseek-r1-locally-in-jan.jpg)\n+\n+You can run DeepSeek R1 on your own computer! While the full model needs very powerful hardware, we'll use a smaller version that works great on regular computers.\n+\n+Why use a smaller version?\n+- Works smoothly on most modern computers\n+- Downloads much faster\n+- Uses less storage space on your computer\n+\n+## Quick Steps at a Glance\n+1. Download and install [Jan](https://jan.ai/) (just like any other app!)\n+2. Pick a version that fits your computer\n+3. Choose the best settings\n+4. Set up a quick template & start chatting!\n+\n+Keep reading for a step-by-step guide with pictures.\n+\n+## Step 1: Download Jan\n+[Jan](https://jan.ai/) is a free app that helps you run AI models on your computer. It works on Windows, Mac, and Linux, and it's super easy to use - no coding needed!\n+\n+![image](./_assets/download-jan.jpg)\n+\n+- Get Jan from [jan.ai](https://jan.ai)\n+- Install it like you would any other app\n+- That's it! Jan takes care of all the technical stuff for you\n+\n+## Step 2: Choose Your DeepSeek R1 Version\n+DeepSeek R1 comes in different sizes. Let's help you pick the right one for your computer.\n+\n+<Callout type=\"info\">\n+\ud83d\udca1 Not sure how much VRAM your computer has? \n+- Windows: Press Windows + R, type \"dxdiag\", press Enter, and click the \"Display\" tab\n+- Mac: Click Apple menu > About This Mac > More Info > Graphics/Displays\n+</Callout>\n+\n+Below is a detailed table showing which version you can run based on your computer's VRAM:",
        "comment_created_at": "2025-01-31T13:15:33+00:00",
        "comment_author": "ramonpzg",
        "comment_body": "I would recommend adding a bit of wording on what is a distilled model versus the full one and why these say qwen vs llama. A lot of people won't know and are assuming they are downloading the original one.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1516347505",
    "pr_number": 2273,
    "pr_file": "docs/docs/guides/integration/groq.mdx",
    "created_at": "2024-03-07T15:20:34+00:00",
    "commented_code": "+---\n+title: Groq\n+sidebar_position: 10\n+slug: /guides/integration/groq\n+description: Learn how to integrate Groq API with Jan for enhanced functionality.\n+keywords:\n+  [\n+    Groq API,\n+    Jan,\n+    Jan AI,\n+    ChatGPT alternative,\n+    conversational AI,\n+    large language model,\n+    integration,\n+    Groq integration,\n+    API integration\n+  ]\n+---\n+\n+## How to Integrate Mistral AI with Jan\n+\n+This guide provides step-by-step instructions on integrating the Groq API with Jan, enabling users to leverage Groq's capabilities within Jan's conversational interface.\n+\n+Before proceeding, ensure you have the following:\n+- Access to the Jan platform\n+- Groq API credentials\n+\n+## Integration Steps\n+\n+### Step 1: Obtain Groq API Credentials\n+\n+If you haven't already, sign up for the Groq API and obtain your API credentials.\n+Obtain Groq API keys from your [Groq Console](https://console.groq.com/keys).\n+\n+### Step 2: Configure Jan Settings\n+\n+1. Insert the Groq AI API key into `~/jan/engines/openai.json`.\n+\n+```json title=\"~/jan/engines/openai.json\"\n+{\n+  \"full_url\": \"https://api.groq.com/openai/v1\",\n+  \"api_key\": \"<your-groq-api-key>\"\n+}\n+```\n+\n+### Step 3: Enable Groq Integration\n+\n+To set up the configuration for Groq in Jan, follow these steps:\n+\n+1. Navigate to `~/jan/models`.\n+2. Create a folder named `groq`.\n+3. Inside the groq folder, create a model.json file with the specified settings:\n+```json title=\"~/jan/models/groq/model.json\n+{\n+  \"id\": \"groq\",\n+  \"object\": \"model\",\n+  \"name\": \"Groq Integration\",\n+  \"version\": \"1.0\",\n+  \"description\": \"Integration with Groq API for enhanced functionality.\",\n+  \"format\": \"api\",\n+  \"sources\": [],\n+  \"settings\": {},\n+  \"parameters\": {},\n+  \"metadata\": {\n+    \"author\": \"Your Name\",",
    "repo_full_name": "menloresearch/jan",
    "discussion_comments": [
      {
        "comment_id": "1516347505",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 2273,
        "pr_file": "docs/docs/guides/integration/groq.mdx",
        "discussion_id": "1516347505",
        "commented_code": "@@ -0,0 +1,84 @@\n+---\n+title: Groq\n+sidebar_position: 10\n+slug: /guides/integration/groq\n+description: Learn how to integrate Groq API with Jan for enhanced functionality.\n+keywords:\n+  [\n+    Groq API,\n+    Jan,\n+    Jan AI,\n+    ChatGPT alternative,\n+    conversational AI,\n+    large language model,\n+    integration,\n+    Groq integration,\n+    API integration\n+  ]\n+---\n+\n+## How to Integrate Mistral AI with Jan\n+\n+This guide provides step-by-step instructions on integrating the Groq API with Jan, enabling users to leverage Groq's capabilities within Jan's conversational interface.\n+\n+Before proceeding, ensure you have the following:\n+- Access to the Jan platform\n+- Groq API credentials\n+\n+## Integration Steps\n+\n+### Step 1: Obtain Groq API Credentials\n+\n+If you haven't already, sign up for the Groq API and obtain your API credentials.\n+Obtain Groq API keys from your [Groq Console](https://console.groq.com/keys).\n+\n+### Step 2: Configure Jan Settings\n+\n+1. Insert the Groq AI API key into `~/jan/engines/openai.json`.\n+\n+```json title=\"~/jan/engines/openai.json\"\n+{\n+  \"full_url\": \"https://api.groq.com/openai/v1\",\n+  \"api_key\": \"<your-groq-api-key>\"\n+}\n+```\n+\n+### Step 3: Enable Groq Integration\n+\n+To set up the configuration for Groq in Jan, follow these steps:\n+\n+1. Navigate to `~/jan/models`.\n+2. Create a folder named `groq`.\n+3. Inside the groq folder, create a model.json file with the specified settings:\n+```json title=\"~/jan/models/groq/model.json\n+{\n+  \"id\": \"groq\",\n+  \"object\": \"model\",\n+  \"name\": \"Groq Integration\",\n+  \"version\": \"1.0\",\n+  \"description\": \"Integration with Groq API for enhanced functionality.\",\n+  \"format\": \"api\",\n+  \"sources\": [],\n+  \"settings\": {},\n+  \"parameters\": {},\n+  \"metadata\": {\n+    \"author\": \"Your Name\",",
        "comment_created_at": "2024-03-07T15:20:34+00:00",
        "comment_author": "0xHieu01",
        "comment_body": "Author should set based on model https://console.groq.com/docs/models. `Meta` for Llama2 and `Mistral`  for mixtral-8x7b-32768 so it's more meaningful\r\n",
        "pr_file_module": null
      }
    ]
  }
]