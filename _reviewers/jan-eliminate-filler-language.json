[
  {
    "discussion_id": "2256231791",
    "pr_number": 6039,
    "pr_file": "docs/src/pages/post/deepresearch.mdx",
    "created_at": "2025-08-06T07:52:19+00:00",
    "commented_code": "+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below.",
    "repo_full_name": "menloresearch/jan",
    "discussion_comments": [
      {
        "comment_id": "2256231791",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 6039,
        "pr_file": "docs/src/pages/post/deepresearch.mdx",
        "discussion_id": "2256231791",
        "commented_code": "@@ -0,0 +1,122 @@\n+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. ",
        "comment_created_at": "2025-08-06T07:52:19+00:00",
        "comment_author": "ramonpzg",
        "comment_body": "Don't use words such as essentially, just, simple, easy, and, for the love of god, basically, among others. :relieved: \r\n\r\nIf OAI's works was so essentially straightforward, there would be no chatgpts today.\r\n\r\nGo straight to the point:\r\n\r\n\"Deep Research, at a high level, is a pipeline or tool chain through which a user would go through.\"\r\n\r\nI would even recommend saying\"\r\n\r\n\"Deep Research is a form of investigation a regular person, or one with specialized skills (like a detective) would go through. Think of it as a pipeline where we plan, search, reflect, use tools, reflect, search more, and continue iterating until we are satisfied with the result. The inner working of this pipeline, as well as the tools, will change from person to person but the sequential nature of this investigation remains.\"",
        "pr_file_module": null
      },
      {
        "comment_id": "2261818943",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 6039,
        "pr_file": "docs/src/pages/post/deepresearch.mdx",
        "discussion_id": "2256231791",
        "commented_code": "@@ -0,0 +1,122 @@\n+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. ",
        "comment_created_at": "2025-08-08T02:46:09+00:00",
        "comment_author": "danielcwq",
        "comment_body": "Addressed, changed the following comments to \r\n<img width=\"787\" height=\"921\" alt=\"Screenshot 2025-08-08 at 10 44 54\u202fAM\" src=\"https://github.com/user-attachments/assets/108efddb-0ab7-4daa-b0b5-915488465186\" />\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2256245485",
    "pr_number": 6039,
    "pr_file": "docs/src/pages/post/deepresearch.mdx",
    "created_at": "2025-08-06T07:55:56+00:00",
    "commented_code": "+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this:",
    "repo_full_name": "menloresearch/jan",
    "discussion_comments": [
      {
        "comment_id": "2256245485",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 6039,
        "pr_file": "docs/src/pages/post/deepresearch.mdx",
        "discussion_id": "2256245485",
        "commented_code": "@@ -0,0 +1,122 @@\n+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this: ",
        "comment_created_at": "2025-08-06T07:55:56+00:00",
        "comment_author": "ramonpzg",
        "comment_body": "You can't hit me with \"at a high level\" twice in subsequent sentences. This hints that you are assuming too much or not respecting the intelligence of the reader. Instead:\r\n\r\n\"For example, a straightforward pipeline might look as follows:\"",
        "pr_file_module": null
      },
      {
        "comment_id": "2261819257",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 6039,
        "pr_file": "docs/src/pages/post/deepresearch.mdx",
        "discussion_id": "2256245485",
        "commented_code": "@@ -0,0 +1,122 @@\n+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this: ",
        "comment_created_at": "2025-08-08T02:46:33+00:00",
        "comment_author": "danielcwq",
        "comment_body": "Addressed! Refactored words are in the above image (previous comment)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2256471820",
    "pr_number": 6039,
    "pr_file": "docs/src/pages/post/deepresearch.mdx",
    "created_at": "2025-08-06T09:02:00+00:00",
    "commented_code": "+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this: \n+![Deep Research Flow Excalidraw](./_assets/deepresearch-flow.png)\n+The crux of Deep Research lies in the pipeline\u2019s ability to output a substantiated report which has cited information from a variety of sources. \n+\n+<Callout type=\"info\">\n+**Different Flows for Different Providers**\n+\n+Note that not all Deep Research flows are the same as what's shown in the above diagram, only OpenAI and Kimi does this currently! Most providers would adopt a simpler approach, as shown below in the comparison table.\n+</Callout>\n+\n+| Platform | Pipeline Flow | Planning Approach | Sources Used | Duration (mins)  | Export Options | Unique Features | Deep Research Usage |\n+| --- | --- | --- | --- | --- | --- | --- | --- |\n+| OpenAI | Original prompt \u2192 clarification (smaller model) \u2192 user answers \u2192 rewriter bundles prompts \u2192 specific model \u2192 output | Chain of thought (COT), no explicit planning | 10\u201330 | 10\u201315 | PDF, Markdown with inline references | Clarification questions, lightweight rewriter model | Paid |\n+| Grok\u2019s DeeperSearch  | Planning \u2192 research execution \u2192 output with survey notes | Planning phase before research | 70\u2013100 | 5\u201310  | Not specified | Heavy Twitter/X source integration, \"Survey Note\" reasoning | Free |\n+| Claude | Research plan \u2192 breadth-first search \u2192 depth-first search | Research plan generated, multiple subagents for complex queries | 100+ | 5\u201310  | Artifact format | Breadth-first then depth-first approach, metadata extraction | Paid |\n+| Gemini | Original prompt \u2192 editable research plan \u2192 execution | Editable research plan (user can modify) | 50+ | 10\u201320  | Google Docs export | Editable planning phase, newer pipeline | Free |\n+| Perplexity | Research plan \u2192 execution with speed options | Research plan crafted and followed | 50\u2013100 | 3\u20135  | Not specified | \"Answer now\" option for quick results | Paid |\n+| Kimi | Query \u2192 clarifying questions \u2192 planning \u2192 research \u2192 synthesis | Explicit planning with clear phase transitions | 50\u2013100 | 30\u201360+ (slower inference)  | PDF, Interactive website | Distinction between \"search\" vs \"browser use\", interactive output | Free |\n+\n+### Understanding Search Strategies\n+\n+In general, when looking at the number of sources that are used, we can classify whether a search is *breadth first* or *depth first*. \n+\n+*Breadth first* searches would result in a greater number of sources that are used, which might be better for a brief survey over a landscape for instance. \n+\n+*Depth first* searches would entail diving deeper into a few particular sources (or have multiple search variations between a particular context), which might be better for extracting nuanced insight. \n+\n+<Callout>\n+In Claude\u2019s Deep Research, a *classifier* is used to determine whether a user query is *breadth first* or *depth first*. This results in a customization of the pipeline that is used for conducting research. For instance, a complex *breadth first* query might result in *sub-agents* being spun up to research various parts of the research query in parallel. \n+</Callout>\n+\n+## Replicating Deep Research Results with Jan\n+Given this overview, how would we replicate this in Jan? \n+\n+We\u2019ll make use of features that are available to us in order to customize the model output such that it gets as close to a Deep Research output without having to spend a cent, and having full control over your data!\n+\n+<Callout>\n+This is using the latest version of Jan (v0.6.6!) The features in this guide require at least 0.6.3 but for the best experience please use 0.6.6!\n+</Callout>\n+\n+### Setting up a Purpose Built Model for Deep Research with Jan\n+1. Under `Hub`, go to `Jan-Nano-128k-Gguf` and enable `Show variants`. Download the largest model that your computer can run! Jan-nano is a 4B model, so even with the largest quantization it should be able to run on your hardware comfortably. \n+![Navigate to Jan-Nano-128k](./_assets/jan-nano-hub.png)\n+\n+### Enabling Search through MCP",
    "repo_full_name": "menloresearch/jan",
    "discussion_comments": [
      {
        "comment_id": "2256471820",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 6039,
        "pr_file": "docs/src/pages/post/deepresearch.mdx",
        "discussion_id": "2256471820",
        "commented_code": "@@ -0,0 +1,122 @@\n+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this: \n+![Deep Research Flow Excalidraw](./_assets/deepresearch-flow.png)\n+The crux of Deep Research lies in the pipeline\u2019s ability to output a substantiated report which has cited information from a variety of sources. \n+\n+<Callout type=\"info\">\n+**Different Flows for Different Providers**\n+\n+Note that not all Deep Research flows are the same as what's shown in the above diagram, only OpenAI and Kimi does this currently! Most providers would adopt a simpler approach, as shown below in the comparison table.\n+</Callout>\n+\n+| Platform | Pipeline Flow | Planning Approach | Sources Used | Duration (mins)  | Export Options | Unique Features | Deep Research Usage |\n+| --- | --- | --- | --- | --- | --- | --- | --- |\n+| OpenAI | Original prompt \u2192 clarification (smaller model) \u2192 user answers \u2192 rewriter bundles prompts \u2192 specific model \u2192 output | Chain of thought (COT), no explicit planning | 10\u201330 | 10\u201315 | PDF, Markdown with inline references | Clarification questions, lightweight rewriter model | Paid |\n+| Grok\u2019s DeeperSearch  | Planning \u2192 research execution \u2192 output with survey notes | Planning phase before research | 70\u2013100 | 5\u201310  | Not specified | Heavy Twitter/X source integration, \"Survey Note\" reasoning | Free |\n+| Claude | Research plan \u2192 breadth-first search \u2192 depth-first search | Research plan generated, multiple subagents for complex queries | 100+ | 5\u201310  | Artifact format | Breadth-first then depth-first approach, metadata extraction | Paid |\n+| Gemini | Original prompt \u2192 editable research plan \u2192 execution | Editable research plan (user can modify) | 50+ | 10\u201320  | Google Docs export | Editable planning phase, newer pipeline | Free |\n+| Perplexity | Research plan \u2192 execution with speed options | Research plan crafted and followed | 50\u2013100 | 3\u20135  | Not specified | \"Answer now\" option for quick results | Paid |\n+| Kimi | Query \u2192 clarifying questions \u2192 planning \u2192 research \u2192 synthesis | Explicit planning with clear phase transitions | 50\u2013100 | 30\u201360+ (slower inference)  | PDF, Interactive website | Distinction between \"search\" vs \"browser use\", interactive output | Free |\n+\n+### Understanding Search Strategies\n+\n+In general, when looking at the number of sources that are used, we can classify whether a search is *breadth first* or *depth first*. \n+\n+*Breadth first* searches would result in a greater number of sources that are used, which might be better for a brief survey over a landscape for instance. \n+\n+*Depth first* searches would entail diving deeper into a few particular sources (or have multiple search variations between a particular context), which might be better for extracting nuanced insight. \n+\n+<Callout>\n+In Claude\u2019s Deep Research, a *classifier* is used to determine whether a user query is *breadth first* or *depth first*. This results in a customization of the pipeline that is used for conducting research. For instance, a complex *breadth first* query might result in *sub-agents* being spun up to research various parts of the research query in parallel. \n+</Callout>\n+\n+## Replicating Deep Research Results with Jan\n+Given this overview, how would we replicate this in Jan? \n+\n+We\u2019ll make use of features that are available to us in order to customize the model output such that it gets as close to a Deep Research output without having to spend a cent, and having full control over your data!\n+\n+<Callout>\n+This is using the latest version of Jan (v0.6.6!) The features in this guide require at least 0.6.3 but for the best experience please use 0.6.6!\n+</Callout>\n+\n+### Setting up a Purpose Built Model for Deep Research with Jan\n+1. Under `Hub`, go to `Jan-Nano-128k-Gguf` and enable `Show variants`. Download the largest model that your computer can run! Jan-nano is a 4B model, so even with the largest quantization it should be able to run on your hardware comfortably. \n+![Navigate to Jan-Nano-128k](./_assets/jan-nano-hub.png)\n+\n+### Enabling Search through MCP",
        "comment_created_at": "2025-08-06T09:02:00+00:00",
        "comment_author": "ramonpzg",
        "comment_body": "Cut out the MCP details, this is not a tutorial but rather a blog post. Highlight the results first and then go to the details, and then to the conclusion of what you tried. Mention\r\n\r\n- how long it took?\r\n- what was the quality of the output?\r\n- how does it compare to other deep research functionalities from other providers?\r\n\r\nDon't leave the reader hungry",
        "pr_file_module": null
      },
      {
        "comment_id": "2261832367",
        "repo_full_name": "menloresearch/jan",
        "pr_number": 6039,
        "pr_file": "docs/src/pages/post/deepresearch.mdx",
        "discussion_id": "2256471820",
        "commented_code": "@@ -0,0 +1,122 @@\n+---\n+title: \"Replicating Deep Research in Jan\"\n+description: \"A simple guide to replicating Deep Research results for free, with Jan.\"\n+tags: AI, local models, Jan, GGUF, Deep Research, local AI\n+categories: guides\n+date: 2025-08-04\n+ogImage: _assets/research-result-local.png\n+twitter:\n+  card: summary_large_image\n+  site: \"@jandotai\"\n+  title: \"Replicating Deep Research with Jan\"\n+  description: \"Learn how to replicate Deep Research results with Jan.\"\n+  image: _assets/research-result-local.jpg\n+---\n+\n+import { Callout } from 'nextra/components'\n+import CTABlog from '@/components/Blog/CTA'\n+\n+# Replicating Deep Research in Jan\n+\n+Ever wondered how OpenAI\u2019s Deep Research works? Since the release of Deep Research in February 2025, it has been lauded as a tool that is able to \u201coutput thorough research\u201d. \n+\n+There are two core features of Deep Research: \n+\n+- Exhaustive searching: all major model providers that offer deep research as a service (proceed to list) would search from a variety of sources. This can be broken down (largely) into two forms of search: **breadth-first search** and **depth-first search**. There will be more of this later!\n+- Report generation: most major model providers will provide an exhaustive, lengthy report at the end of completing the deep research task. For instance, OpenAI gives users the ability to export this to a PDF, while Kimi would also provide an interactive HTML webpage in their UI for easier visualization.\n+\n+## Unpacking Deep Research\n+While the outputs of deep research might be mind blowing at first glance, it is possible to reverse engineer the process through which such a comprehensive output is generated! OpenAI\u2019s [Deep Research API cookbook](https://cookbook.openai.com/examples/deep_research_api/introduction_to_deep_research_api) gives us some insight into the flow that they adopt:\n+![OpenAI's Deep Research UX Flow](./_assets/openai-deep-research-flow.png)\n+\n+Deep Research, at a high level, is essentially a pipeline / tool chain through which a user would go through. The inner workings of this pipeline might vary from provider to provider, but we\u2019ve done up a table for you to compare the results below. \n+\n+At a high level, the pipeline would look something like this: \n+![Deep Research Flow Excalidraw](./_assets/deepresearch-flow.png)\n+The crux of Deep Research lies in the pipeline\u2019s ability to output a substantiated report which has cited information from a variety of sources. \n+\n+<Callout type=\"info\">\n+**Different Flows for Different Providers**\n+\n+Note that not all Deep Research flows are the same as what's shown in the above diagram, only OpenAI and Kimi does this currently! Most providers would adopt a simpler approach, as shown below in the comparison table.\n+</Callout>\n+\n+| Platform | Pipeline Flow | Planning Approach | Sources Used | Duration (mins)  | Export Options | Unique Features | Deep Research Usage |\n+| --- | --- | --- | --- | --- | --- | --- | --- |\n+| OpenAI | Original prompt \u2192 clarification (smaller model) \u2192 user answers \u2192 rewriter bundles prompts \u2192 specific model \u2192 output | Chain of thought (COT), no explicit planning | 10\u201330 | 10\u201315 | PDF, Markdown with inline references | Clarification questions, lightweight rewriter model | Paid |\n+| Grok\u2019s DeeperSearch  | Planning \u2192 research execution \u2192 output with survey notes | Planning phase before research | 70\u2013100 | 5\u201310  | Not specified | Heavy Twitter/X source integration, \"Survey Note\" reasoning | Free |\n+| Claude | Research plan \u2192 breadth-first search \u2192 depth-first search | Research plan generated, multiple subagents for complex queries | 100+ | 5\u201310  | Artifact format | Breadth-first then depth-first approach, metadata extraction | Paid |\n+| Gemini | Original prompt \u2192 editable research plan \u2192 execution | Editable research plan (user can modify) | 50+ | 10\u201320  | Google Docs export | Editable planning phase, newer pipeline | Free |\n+| Perplexity | Research plan \u2192 execution with speed options | Research plan crafted and followed | 50\u2013100 | 3\u20135  | Not specified | \"Answer now\" option for quick results | Paid |\n+| Kimi | Query \u2192 clarifying questions \u2192 planning \u2192 research \u2192 synthesis | Explicit planning with clear phase transitions | 50\u2013100 | 30\u201360+ (slower inference)  | PDF, Interactive website | Distinction between \"search\" vs \"browser use\", interactive output | Free |\n+\n+### Understanding Search Strategies\n+\n+In general, when looking at the number of sources that are used, we can classify whether a search is *breadth first* or *depth first*. \n+\n+*Breadth first* searches would result in a greater number of sources that are used, which might be better for a brief survey over a landscape for instance. \n+\n+*Depth first* searches would entail diving deeper into a few particular sources (or have multiple search variations between a particular context), which might be better for extracting nuanced insight. \n+\n+<Callout>\n+In Claude\u2019s Deep Research, a *classifier* is used to determine whether a user query is *breadth first* or *depth first*. This results in a customization of the pipeline that is used for conducting research. For instance, a complex *breadth first* query might result in *sub-agents* being spun up to research various parts of the research query in parallel. \n+</Callout>\n+\n+## Replicating Deep Research Results with Jan\n+Given this overview, how would we replicate this in Jan? \n+\n+We\u2019ll make use of features that are available to us in order to customize the model output such that it gets as close to a Deep Research output without having to spend a cent, and having full control over your data!\n+\n+<Callout>\n+This is using the latest version of Jan (v0.6.6!) The features in this guide require at least 0.6.3 but for the best experience please use 0.6.6!\n+</Callout>\n+\n+### Setting up a Purpose Built Model for Deep Research with Jan\n+1. Under `Hub`, go to `Jan-Nano-128k-Gguf` and enable `Show variants`. Download the largest model that your computer can run! Jan-nano is a 4B model, so even with the largest quantization it should be able to run on your hardware comfortably. \n+![Navigate to Jan-Nano-128k](./_assets/jan-nano-hub.png)\n+\n+### Enabling Search through MCP",
        "comment_created_at": "2025-08-08T03:01:10+00:00",
        "comment_author": "danielcwq",
        "comment_body": "Got it -- removed the tutorial like version in place of this, would love your comments!\r\n<img width=\"652\" height=\"551\" alt=\"Screenshot 2025-08-08 at 11 00 54\u202fAM\" src=\"https://github.com/user-attachments/assets/f1b280cb-3ae4-47bb-9fe0-3438bbff5864\" />\r\n",
        "pr_file_module": null
      }
    ]
  }
]