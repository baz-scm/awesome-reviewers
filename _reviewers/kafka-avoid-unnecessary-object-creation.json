[
  {
    "discussion_id": "2217957593",
    "pr_number": 19820,
    "pr_file": "group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupCoordinatorService.java",
    "created_at": "2025-07-20T20:45:21+00:00",
    "commented_code": "handlePersisterInitializeResponse(request.groupTopicPartitionData().groupId(), result, new ShareGroupHeartbeatResponseData());\n                         return response;\n                     } else {\n-                        //TODO build new AlterShareGroupOffsetsResponseData for error response\n-                        return response;\n+                        return buildErrorResponse(response, result);\n                     }\n                 } else {\n                     return buildErrorResponse(request, response, exp);\n                 }\n \n             });\n     }\n+    \n+    private AlterShareGroupOffsetsResponseData buildErrorResponse(AlterShareGroupOffsetsResponseData response, InitializeShareGroupStateResult result) {\n+        AlterShareGroupOffsetsResponseData data = new AlterShareGroupOffsetsResponseData();\n+        data.setResponses(\n+            new AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponseTopicCollection(response.responses().stream()\n+                .map(topic -> {\n+                    AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponseTopic topicData = new AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponseTopic()\n+                        .setTopicName(topic.topicName());\n+                    Map<Uuid, Map<Integer, PartitionErrorData>> topicPartitionErrorsMap = result.getErrors();\n+                    topic.partitions().forEach(partition -> {\n+                        if (partition.errorCode() != Errors.NONE.code()) {\n+                            topicData.partitions().add(partition);\n+                            return;\n+                        }\n+                        AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponsePartition partitionData;\n+                        PartitionErrorData error = topicPartitionErrorsMap.get(topic.topicId()).get(partition.partitionIndex());\n+                        if (error == null) {\n+                            partitionData = new AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponsePartition()",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2217957593",
        "repo_full_name": "apache/kafka",
        "pr_number": 19820,
        "pr_file": "group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupCoordinatorService.java",
        "discussion_id": "2217957593",
        "commented_code": "@@ -709,15 +709,47 @@ CompletableFuture<AlterShareGroupOffsetsResponseData> persisterInitialize(\n                         handlePersisterInitializeResponse(request.groupTopicPartitionData().groupId(), result, new ShareGroupHeartbeatResponseData());\n                         return response;\n                     } else {\n-                        //TODO build new AlterShareGroupOffsetsResponseData for error response\n-                        return response;\n+                        return buildErrorResponse(response, result);\n                     }\n                 } else {\n                     return buildErrorResponse(request, response, exp);\n                 }\n \n             });\n     }\n+    \n+    private AlterShareGroupOffsetsResponseData buildErrorResponse(AlterShareGroupOffsetsResponseData response, InitializeShareGroupStateResult result) {\n+        AlterShareGroupOffsetsResponseData data = new AlterShareGroupOffsetsResponseData();\n+        data.setResponses(\n+            new AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponseTopicCollection(response.responses().stream()\n+                .map(topic -> {\n+                    AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponseTopic topicData = new AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponseTopic()\n+                        .setTopicName(topic.topicName());\n+                    Map<Uuid, Map<Integer, PartitionErrorData>> topicPartitionErrorsMap = result.getErrors();\n+                    topic.partitions().forEach(partition -> {\n+                        if (partition.errorCode() != Errors.NONE.code()) {\n+                            topicData.partitions().add(partition);\n+                            return;\n+                        }\n+                        AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponsePartition partitionData;\n+                        PartitionErrorData error = topicPartitionErrorsMap.get(topic.topicId()).get(partition.partitionIndex());\n+                        if (error == null) {\n+                            partitionData = new AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponsePartition()",
        "comment_created_at": "2025-07-20T20:45:21+00:00",
        "comment_author": "chia7712",
        "comment_body": "we could reuse the `partition` instead of creating new `AlterShareGroupOffsetsResponsePartition`, right?",
        "pr_file_module": null
      },
      {
        "comment_id": "2220755722",
        "repo_full_name": "apache/kafka",
        "pr_number": 19820,
        "pr_file": "group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupCoordinatorService.java",
        "discussion_id": "2217957593",
        "commented_code": "@@ -709,15 +709,47 @@ CompletableFuture<AlterShareGroupOffsetsResponseData> persisterInitialize(\n                         handlePersisterInitializeResponse(request.groupTopicPartitionData().groupId(), result, new ShareGroupHeartbeatResponseData());\n                         return response;\n                     } else {\n-                        //TODO build new AlterShareGroupOffsetsResponseData for error response\n-                        return response;\n+                        return buildErrorResponse(response, result);\n                     }\n                 } else {\n                     return buildErrorResponse(request, response, exp);\n                 }\n \n             });\n     }\n+    \n+    private AlterShareGroupOffsetsResponseData buildErrorResponse(AlterShareGroupOffsetsResponseData response, InitializeShareGroupStateResult result) {\n+        AlterShareGroupOffsetsResponseData data = new AlterShareGroupOffsetsResponseData();\n+        data.setResponses(\n+            new AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponseTopicCollection(response.responses().stream()\n+                .map(topic -> {\n+                    AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponseTopic topicData = new AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponseTopic()\n+                        .setTopicName(topic.topicName());\n+                    Map<Uuid, Map<Integer, PartitionErrorData>> topicPartitionErrorsMap = result.getErrors();\n+                    topic.partitions().forEach(partition -> {\n+                        if (partition.errorCode() != Errors.NONE.code()) {\n+                            topicData.partitions().add(partition);\n+                            return;\n+                        }\n+                        AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponsePartition partitionData;\n+                        PartitionErrorData error = topicPartitionErrorsMap.get(topic.topicId()).get(partition.partitionIndex());\n+                        if (error == null) {\n+                            partitionData = new AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponsePartition()",
        "comment_created_at": "2025-07-22T01:36:38+00:00",
        "comment_author": "JimmyWang6",
        "comment_body": "Good idea, I have change to use partition.duplicate() to build the response.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2228614978",
    "pr_number": 20235,
    "pr_file": "tools/src/main/java/org/apache/kafka/tools/consumer/group/ConsumerGroupCommand.java",
    "created_at": "2025-07-24T14:01:01+00:00",
    "commented_code": "return adminClient.describeTopics(topics).allTopicNames().get().entrySet()\n                         .stream()\n                         .flatMap(entry -> entry.getValue().partitions().stream()\n-                                .filter(partitionInfo -> partitionInfo.leader() == null)\n+                                .filter(partitionInfo -> topicPartitions.contains(new TopicPartition(entry.getKey(), partitionInfo.partition())) && partitionInfo.leader() == null)",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2228614978",
        "repo_full_name": "apache/kafka",
        "pr_number": 20235,
        "pr_file": "tools/src/main/java/org/apache/kafka/tools/consumer/group/ConsumerGroupCommand.java",
        "discussion_id": "2228614978",
        "commented_code": "@@ -653,7 +653,7 @@ private List<TopicPartition> filterNoneLeaderPartitions(Collection<TopicPartitio\n                 return adminClient.describeTopics(topics).allTopicNames().get().entrySet()\n                         .stream()\n                         .flatMap(entry -> entry.getValue().partitions().stream()\n-                                .filter(partitionInfo -> partitionInfo.leader() == null)\n+                                .filter(partitionInfo -> topicPartitions.contains(new TopicPartition(entry.getKey(), partitionInfo.partition())) && partitionInfo.leader() == null)",
        "comment_created_at": "2025-07-24T14:01:01+00:00",
        "comment_author": "Yunyung",
        "comment_body": "nit: check `partitionInfo.leader() == null` before creating the `TopicPartition` for performance.",
        "pr_file_module": null
      },
      {
        "comment_id": "2228661633",
        "repo_full_name": "apache/kafka",
        "pr_number": 20235,
        "pr_file": "tools/src/main/java/org/apache/kafka/tools/consumer/group/ConsumerGroupCommand.java",
        "discussion_id": "2228614978",
        "commented_code": "@@ -653,7 +653,7 @@ private List<TopicPartition> filterNoneLeaderPartitions(Collection<TopicPartitio\n                 return adminClient.describeTopics(topics).allTopicNames().get().entrySet()\n                         .stream()\n                         .flatMap(entry -> entry.getValue().partitions().stream()\n-                                .filter(partitionInfo -> partitionInfo.leader() == null)\n+                                .filter(partitionInfo -> topicPartitions.contains(new TopicPartition(entry.getKey(), partitionInfo.partition())) && partitionInfo.leader() == null)",
        "comment_created_at": "2025-07-24T14:17:19+00:00",
        "comment_author": "TaiJuWu",
        "comment_body": "Good point, thanks.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2185906200",
    "pr_number": 20083,
    "pr_file": "storage/src/main/java/org/apache/kafka/storage/internals/log/PendingExpandIsr.java",
    "created_at": "2025-07-04T18:20:07+00:00",
    "commented_code": "+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.storage.internals.log;\n+\n+import org.apache.kafka.metadata.LeaderAndIsr;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public record PendingExpandIsr(int newInSyncReplicaId,\n+                               LeaderAndIsr sentLeaderAndIsr,\n+                               CommittedPartitionState lastCommittedState) implements PendingPartitionChange {\n+\n+    @Override\n+    public void notifyListener(AlterPartitionListener alterPartitionListener) {\n+        alterPartitionListener.markIsrExpand();\n+    }\n+\n+    @Override\n+    public Set<Integer> isr() {\n+        return lastCommittedState.isr();\n+    }\n+\n+    @Override\n+    public Set<Integer> maximalIsr() {\n+        Set<Integer> newIsr = new HashSet<>(lastCommittedState.isr());\n+        newIsr.add(newInSyncReplicaId);\n+        return Set.copyOf(newIsr);",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2185906200",
        "repo_full_name": "apache/kafka",
        "pr_number": 20083,
        "pr_file": "storage/src/main/java/org/apache/kafka/storage/internals/log/PendingExpandIsr.java",
        "discussion_id": "2185906200",
        "commented_code": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.storage.internals.log;\n+\n+import org.apache.kafka.metadata.LeaderAndIsr;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public record PendingExpandIsr(int newInSyncReplicaId,\n+                               LeaderAndIsr sentLeaderAndIsr,\n+                               CommittedPartitionState lastCommittedState) implements PendingPartitionChange {\n+\n+    @Override\n+    public void notifyListener(AlterPartitionListener alterPartitionListener) {\n+        alterPartitionListener.markIsrExpand();\n+    }\n+\n+    @Override\n+    public Set<Integer> isr() {\n+        return lastCommittedState.isr();\n+    }\n+\n+    @Override\n+    public Set<Integer> maximalIsr() {\n+        Set<Integer> newIsr = new HashSet<>(lastCommittedState.isr());\n+        newIsr.add(newInSyncReplicaId);\n+        return Set.copyOf(newIsr);",
        "comment_created_at": "2025-07-04T18:20:07+00:00",
        "comment_author": "chia7712",
        "comment_body": "Could you please use `Collections.unmodifiableSet` instead to avoid extra deep copy?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2047502158",
    "pr_number": 19232,
    "pr_file": "metadata/src/main/java/org/apache/kafka/metadata/KRaftMetadataCache.java",
    "created_at": "2025-04-16T18:36:11+00:00",
    "commented_code": "+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.metadata;\n+\n+import org.apache.kafka.common.Node;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.Uuid;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.errors.InvalidTopicException;\n+import org.apache.kafka.common.internals.Topic;\n+import org.apache.kafka.common.message.DescribeClientQuotasRequestData;\n+import org.apache.kafka.common.message.DescribeClientQuotasResponseData;\n+import org.apache.kafka.common.message.DescribeTopicPartitionsResponseData;\n+import org.apache.kafka.common.message.DescribeTopicPartitionsResponseData.Cursor;\n+import org.apache.kafka.common.message.DescribeTopicPartitionsResponseData.DescribeTopicPartitionsResponsePartition;\n+import org.apache.kafka.common.message.DescribeTopicPartitionsResponseData.DescribeTopicPartitionsResponseTopic;\n+import org.apache.kafka.common.message.DescribeUserScramCredentialsRequestData;\n+import org.apache.kafka.common.message.DescribeUserScramCredentialsResponseData;\n+import org.apache.kafka.common.message.MetadataResponseData.MetadataResponsePartition;\n+import org.apache.kafka.common.message.MetadataResponseData.MetadataResponseTopic;\n+import org.apache.kafka.common.network.ListenerName;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.apache.kafka.common.requests.MetadataResponse;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.image.MetadataImage;\n+import org.apache.kafka.image.TopicImage;\n+import org.apache.kafka.server.common.FinalizedFeatures;\n+import org.apache.kafka.server.common.KRaftVersion;\n+import org.apache.kafka.server.common.MetadataVersion;\n+\n+import org.slf4j.Logger;\n+\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Optional;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.Spliterator;\n+import java.util.Spliterators;\n+import java.util.concurrent.ThreadLocalRandom;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+import java.util.stream.StreamSupport;\n+\n+public class KRaftMetadataCache implements MetadataCache {\n+    private final Logger log;\n+    private final Supplier<KRaftVersion> kraftVersionSupplier;\n+\n+    // This is the cache state. Every MetadataImage instance is immutable, and updates\n+    // replace this value with a completely new one. This means reads (which are not under\n+    // any lock) need to grab the value of this variable once, and retain that read copy for\n+    // the duration of their operation. Multiple reads of this value risk getting different\n+    // image values.\n+    private volatile MetadataImage currentImage = MetadataImage.EMPTY;\n+\n+    public KRaftMetadataCache(int brokerId, Supplier<KRaftVersion> kraftVersionSupplier) {\n+        this.kraftVersionSupplier = kraftVersionSupplier;\n+        this.log = new LogContext(\"[MetadataCache brokerId=\" + brokerId + \"] \").logger(KRaftMetadataCache.class);\n+    }\n+\n+    // This method is the main hotspot when it comes to the performance of metadata requests,\n+    // we should be careful about adding additional logic here.\n+    // filterUnavailableEndpoints exists to support v0 MetadataResponses\n+    private List<Integer> maybeFilterAliveReplicas(MetadataImage image, int[] brokers, ListenerName listenerName, boolean filterUnavailableEndpoints) {\n+        if (!filterUnavailableEndpoints) {\n+            return Replicas.toList(brokers);\n+        } else {\n+            List<Integer> res = new ArrayList<>(brokers.length);\n+            for (int brokerId : brokers) {\n+                Optional.ofNullable(image.cluster().broker(brokerId)).ifPresent(b -> {",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2047502158",
        "repo_full_name": "apache/kafka",
        "pr_number": 19232,
        "pr_file": "metadata/src/main/java/org/apache/kafka/metadata/KRaftMetadataCache.java",
        "discussion_id": "2047502158",
        "commented_code": "@@ -0,0 +1,518 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.metadata;\n+\n+import org.apache.kafka.common.Node;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.Uuid;\n+import org.apache.kafka.common.config.ConfigResource;\n+import org.apache.kafka.common.errors.InvalidTopicException;\n+import org.apache.kafka.common.internals.Topic;\n+import org.apache.kafka.common.message.DescribeClientQuotasRequestData;\n+import org.apache.kafka.common.message.DescribeClientQuotasResponseData;\n+import org.apache.kafka.common.message.DescribeTopicPartitionsResponseData;\n+import org.apache.kafka.common.message.DescribeTopicPartitionsResponseData.Cursor;\n+import org.apache.kafka.common.message.DescribeTopicPartitionsResponseData.DescribeTopicPartitionsResponsePartition;\n+import org.apache.kafka.common.message.DescribeTopicPartitionsResponseData.DescribeTopicPartitionsResponseTopic;\n+import org.apache.kafka.common.message.DescribeUserScramCredentialsRequestData;\n+import org.apache.kafka.common.message.DescribeUserScramCredentialsResponseData;\n+import org.apache.kafka.common.message.MetadataResponseData.MetadataResponsePartition;\n+import org.apache.kafka.common.message.MetadataResponseData.MetadataResponseTopic;\n+import org.apache.kafka.common.network.ListenerName;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.apache.kafka.common.requests.MetadataResponse;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.image.MetadataImage;\n+import org.apache.kafka.image.TopicImage;\n+import org.apache.kafka.server.common.FinalizedFeatures;\n+import org.apache.kafka.server.common.KRaftVersion;\n+import org.apache.kafka.server.common.MetadataVersion;\n+\n+import org.slf4j.Logger;\n+\n+import java.util.AbstractMap;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Optional;\n+import java.util.Properties;\n+import java.util.Set;\n+import java.util.Spliterator;\n+import java.util.Spliterators;\n+import java.util.concurrent.ThreadLocalRandom;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Function;\n+import java.util.function.Predicate;\n+import java.util.function.Supplier;\n+import java.util.stream.Collectors;\n+import java.util.stream.StreamSupport;\n+\n+public class KRaftMetadataCache implements MetadataCache {\n+    private final Logger log;\n+    private final Supplier<KRaftVersion> kraftVersionSupplier;\n+\n+    // This is the cache state. Every MetadataImage instance is immutable, and updates\n+    // replace this value with a completely new one. This means reads (which are not under\n+    // any lock) need to grab the value of this variable once, and retain that read copy for\n+    // the duration of their operation. Multiple reads of this value risk getting different\n+    // image values.\n+    private volatile MetadataImage currentImage = MetadataImage.EMPTY;\n+\n+    public KRaftMetadataCache(int brokerId, Supplier<KRaftVersion> kraftVersionSupplier) {\n+        this.kraftVersionSupplier = kraftVersionSupplier;\n+        this.log = new LogContext(\"[MetadataCache brokerId=\" + brokerId + \"] \").logger(KRaftMetadataCache.class);\n+    }\n+\n+    // This method is the main hotspot when it comes to the performance of metadata requests,\n+    // we should be careful about adding additional logic here.\n+    // filterUnavailableEndpoints exists to support v0 MetadataResponses\n+    private List<Integer> maybeFilterAliveReplicas(MetadataImage image, int[] brokers, ListenerName listenerName, boolean filterUnavailableEndpoints) {\n+        if (!filterUnavailableEndpoints) {\n+            return Replicas.toList(brokers);\n+        } else {\n+            List<Integer> res = new ArrayList<>(brokers.length);\n+            for (int brokerId : brokers) {\n+                Optional.ofNullable(image.cluster().broker(brokerId)).ifPresent(b -> {",
        "comment_created_at": "2025-04-16T18:36:11+00:00",
        "comment_author": "chia7712",
        "comment_body": "If it is hotspot, we should not generate optional object.\r\n```java\r\n            for (int brokerId : brokers) {\r\n                var broker = image.cluster().broker(brokerId);\r\n                if (broker != null && !broker.fenced() && broker.listeners().containsKey(listenerName.value()))\r\n                    res.add(brokerId);\r\n            }\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2195314548",
    "pr_number": 19869,
    "pr_file": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMakerConfig.java",
    "created_at": "2025-07-09T15:24:54+00:00",
    "commented_code": "Set<String> allConfigNames() {\n         Set<String> allNames = new HashSet<>();\n-        List<ConfigDef> connectorConfigDefs = Arrays.asList(\n+        List<ConfigDef> connectorConfigDefs = List.of(",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2195314548",
        "repo_full_name": "apache/kafka",
        "pr_number": 19869,
        "pr_file": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorMakerConfig.java",
        "discussion_id": "2195314548",
        "commented_code": "@@ -215,7 +213,7 @@ public Map<String, String> workerConfig(SourceAndTarget sourceAndTarget) {\n \n     Set<String> allConfigNames() {\n         Set<String> allNames = new HashSet<>();\n-        List<ConfigDef> connectorConfigDefs = Arrays.asList(\n+        List<ConfigDef> connectorConfigDefs = List.of(",
        "comment_created_at": "2025-07-09T15:24:54+00:00",
        "comment_author": "chia7712",
        "comment_body": "Perhaps we don't need to create this temporary list.\r\n```java\r\n        Set<String> allNames = new HashSet<>();\r\n        allNames.addAll(MirrorCheckpointConfig.CONNECTOR_CONFIG_DEF.names());\r\n        allNames.addAll(MirrorSourceConfig.CONNECTOR_CONFIG_DEF.names());\r\n        allNames.addAll(MirrorHeartbeatConfig.CONNECTOR_CONFIG_DEF.names());\r\n        return allNames;\r\n```\r\n\r\nor\r\n\r\n```java\r\n        return Stream.of(\r\n                    MirrorCheckpointConfig.CONNECTOR_CONFIG_DEF.names(),\r\n                    MirrorSourceConfig.CONNECTOR_CONFIG_DEF.names(),\r\n                    MirrorHeartbeatConfig.CONNECTOR_CONFIG_DEF.names()\r\n                )\r\n                .flatMap(Set::stream)\r\n                .collect(Collectors.toSet());\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2083621752",
    "pr_number": 18929,
    "pr_file": "clients/src/main/java/org/apache/kafka/common/requests/AlterShareGroupOffsetsRequest.java",
    "created_at": "2025-05-11T21:07:23+00:00",
    "commented_code": ".setPartitions(topicResult.partitions().stream()\n                     .map(partitionData -> new AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponsePartition()\n                         .setPartitionIndex(partitionData.partitionIndex())\n-                        .setErrorCode(Errors.forException(e).code()))\n+                        .setErrorCode(Errors.forException(e).code())",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2083621752",
        "repo_full_name": "apache/kafka",
        "pr_number": 18929,
        "pr_file": "clients/src/main/java/org/apache/kafka/common/requests/AlterShareGroupOffsetsRequest.java",
        "discussion_id": "2083621752",
        "commented_code": "@@ -65,7 +65,8 @@ public AbstractResponse getErrorResponse(int throttleTimeMs, Throwable e) {\n                 .setPartitions(topicResult.partitions().stream()\n                     .map(partitionData -> new AlterShareGroupOffsetsResponseData.AlterShareGroupOffsetsResponsePartition()\n                         .setPartitionIndex(partitionData.partitionIndex())\n-                        .setErrorCode(Errors.forException(e).code()))\n+                        .setErrorCode(Errors.forException(e).code())",
        "comment_created_at": "2025-05-11T21:07:23+00:00",
        "comment_author": "AndrewJSchofield",
        "comment_body": "`Errors.forException()` scans the list of Errors matching on exception class. I would prefer this to be done just once, such as assigning a local Errors variable and then using it to set the error code and message on each loop iteration.",
        "pr_file_module": null
      }
    ]
  }
]