[
  {
    "discussion_id": "2185925364",
    "pr_number": 20083,
    "pr_file": "core/src/main/scala/kafka/cluster/Partition.scala",
    "created_at": "2025-07-04T18:40:22+00:00",
    "commented_code": "// When shrinking the ISR, we cannot assume that the update will succeed as this could\n     // erroneously advance the HW if the `AlterPartition` were to fail. Hence the \"maximal ISR\"\n     // for `PendingShrinkIsr` is the current ISR.\n-    val isrToSend = partitionState.isr -- outOfSyncReplicaIds\n+    val isrToSend = partitionState.isr.asScala.map(_.toInt).toSet -- outOfSyncReplicaIds",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2185925364",
        "repo_full_name": "apache/kafka",
        "pr_number": 20083,
        "pr_file": "core/src/main/scala/kafka/cluster/Partition.scala",
        "discussion_id": "2185925364",
        "commented_code": "@@ -1779,7 +1629,7 @@ class Partition(val topicPartition: TopicPartition,\n     // When shrinking the ISR, we cannot assume that the update will succeed as this could\n     // erroneously advance the HW if the `AlterPartition` were to fail. Hence the \"maximal ISR\"\n     // for `PendingShrinkIsr` is the current ISR.\n-    val isrToSend = partitionState.isr -- outOfSyncReplicaIds\n+    val isrToSend = partitionState.isr.asScala.map(_.toInt).toSet -- outOfSyncReplicaIds",
        "comment_created_at": "2025-07-04T18:40:22+00:00",
        "comment_author": "chia7712",
        "comment_body": "This will create many temporary collections. How about `partitionState.isr.asScala.map(_.toInt).diff(outOfSyncReplicaIds)`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2185927012",
    "pr_number": 20083,
    "pr_file": "core/src/main/scala/kafka/cluster/Partition.scala",
    "created_at": "2025-07-04T18:41:33+00:00",
    "commented_code": "def getOutOfSyncReplicas(maxLagMs: Long): Set[Int] = {\n     val current = partitionState\n     if (!current.isInflight) {\n-      val candidateReplicaIds = current.isr - localBrokerId\n+      val candidateReplicaIds = current.isr.asScala.map(_.toInt).toSet - localBrokerId",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2185927012",
        "repo_full_name": "apache/kafka",
        "pr_number": 20083,
        "pr_file": "core/src/main/scala/kafka/cluster/Partition.scala",
        "discussion_id": "2185927012",
        "commented_code": "@@ -1298,7 +1148,7 @@ class Partition(val topicPartition: TopicPartition,\n   def getOutOfSyncReplicas(maxLagMs: Long): Set[Int] = {\n     val current = partitionState\n     if (!current.isInflight) {\n-      val candidateReplicaIds = current.isr - localBrokerId\n+      val candidateReplicaIds = current.isr.asScala.map(_.toInt).toSet - localBrokerId",
        "comment_created_at": "2025-07-04T18:41:33+00:00",
        "comment_author": "chia7712",
        "comment_body": "ditto",
        "pr_file_module": null
      },
      {
        "comment_id": "2193983660",
        "repo_full_name": "apache/kafka",
        "pr_number": 20083,
        "pr_file": "core/src/main/scala/kafka/cluster/Partition.scala",
        "discussion_id": "2185927012",
        "commented_code": "@@ -1298,7 +1148,7 @@ class Partition(val topicPartition: TopicPartition,\n   def getOutOfSyncReplicas(maxLagMs: Long): Set[Int] = {\n     val current = partitionState\n     if (!current.isInflight) {\n-      val candidateReplicaIds = current.isr - localBrokerId\n+      val candidateReplicaIds = current.isr.asScala.map(_.toInt).toSet - localBrokerId",
        "comment_created_at": "2025-07-09T04:24:34+00:00",
        "comment_author": "joshua2519",
        "comment_body": "> ditto\r\n\r\n@chia7712 \r\nTo reduce collection copies, we could use an iterator like this: \r\n`current.isr.asScala.iterator.map(_.toInt).filter(_ != localBrokerId)).to(Set)`\r\nHowever, this approach is less concise.",
        "pr_file_module": null
      },
      {
        "comment_id": "2194000609",
        "repo_full_name": "apache/kafka",
        "pr_number": 20083,
        "pr_file": "core/src/main/scala/kafka/cluster/Partition.scala",
        "discussion_id": "2185927012",
        "commented_code": "@@ -1298,7 +1148,7 @@ class Partition(val topicPartition: TopicPartition,\n   def getOutOfSyncReplicas(maxLagMs: Long): Set[Int] = {\n     val current = partitionState\n     if (!current.isInflight) {\n-      val candidateReplicaIds = current.isr - localBrokerId\n+      val candidateReplicaIds = current.isr.asScala.map(_.toInt).toSet - localBrokerId",
        "comment_created_at": "2025-07-09T04:41:09+00:00",
        "comment_author": "frankvicky",
        "comment_body": "How about \r\n```\r\ncurrent.isr.stream().filter(isr => isr != localBrokerId).collect(Collectors.toUnmodifiableSet).asScala\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2185927203",
    "pr_number": 20083,
    "pr_file": "core/src/main/scala/kafka/cluster/Partition.scala",
    "created_at": "2025-07-04T18:41:53+00:00",
    "commented_code": "case (brokerId, logEndOffset) => s\"broker $brokerId: $logEndOffset\"\n           }\n \n-          val curInSyncReplicaObjects = (curMaximalIsr - localBrokerId).flatMap(getReplica)\n+          val curInSyncReplicaObjects = (curMaximalIsr.asScala.map(_.toInt) - localBrokerId).flatMap(getReplica)",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2185927203",
        "repo_full_name": "apache/kafka",
        "pr_number": 20083,
        "pr_file": "core/src/main/scala/kafka/cluster/Partition.scala",
        "discussion_id": "2185927203",
        "commented_code": "@@ -1098,7 +948,7 @@ class Partition(val topicPartition: TopicPartition,\n             case (brokerId, logEndOffset) => s\"broker $brokerId: $logEndOffset\"\n           }\n \n-          val curInSyncReplicaObjects = (curMaximalIsr - localBrokerId).flatMap(getReplica)\n+          val curInSyncReplicaObjects = (curMaximalIsr.asScala.map(_.toInt) - localBrokerId).flatMap(getReplica)",
        "comment_created_at": "2025-07-04T18:41:53+00:00",
        "comment_author": "chia7712",
        "comment_body": "ditto",
        "pr_file_module": null
      },
      {
        "comment_id": "2193986394",
        "repo_full_name": "apache/kafka",
        "pr_number": 20083,
        "pr_file": "core/src/main/scala/kafka/cluster/Partition.scala",
        "discussion_id": "2185927203",
        "commented_code": "@@ -1098,7 +948,7 @@ class Partition(val topicPartition: TopicPartition,\n             case (brokerId, logEndOffset) => s\"broker $brokerId: $logEndOffset\"\n           }\n \n-          val curInSyncReplicaObjects = (curMaximalIsr - localBrokerId).flatMap(getReplica)\n+          val curInSyncReplicaObjects = (curMaximalIsr.asScala.map(_.toInt) - localBrokerId).flatMap(getReplica)",
        "comment_created_at": "2025-07-09T04:27:13+00:00",
        "comment_author": "joshua2519",
        "comment_body": "Same as https://github.com/apache/kafka/pull/20083#discussion_r2193983660\r\n\r\n```\r\ncurMaximalIsr.asScala.iterator.filter(_.intValue() != localBrokerId).map(_.toInt).flatMap(getReplica).to(Set)\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2108470367",
    "pr_number": 19793,
    "pr_file": "core/src/main/scala/kafka/server/ReplicaManager.scala",
    "created_at": "2025-05-27T07:53:57+00:00",
    "commented_code": "delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys.asJava)\n     } else {\n       // we can respond immediately\n-      val produceResponseStatus = initialProduceStatus.map { case (k, status) => k -> status.responseStatus }\n+      val produceResponseStatus = new util.HashMap[TopicIdPartition, PartitionResponse]\n+      initialProduceStatus.foreach { case (k, status) => k -> produceResponseStatus.put(k, status.responseStatus) }",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2108470367",
        "repo_full_name": "apache/kafka",
        "pr_number": 19793,
        "pr_file": "core/src/main/scala/kafka/server/ReplicaManager.scala",
        "discussion_id": "2108470367",
        "commented_code": "@@ -983,23 +1003,25 @@ class ReplicaManager(val config: KafkaConfig,\n       delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys.asJava)\n     } else {\n       // we can respond immediately\n-      val produceResponseStatus = initialProduceStatus.map { case (k, status) => k -> status.responseStatus }\n+      val produceResponseStatus = new util.HashMap[TopicIdPartition, PartitionResponse]\n+      initialProduceStatus.foreach { case (k, status) => k -> produceResponseStatus.put(k, status.responseStatus) }",
        "comment_created_at": "2025-05-27T07:53:57+00:00",
        "comment_author": "m1a2st",
        "comment_body": "```suggestion\r\n      val produceResponseStatus = initialProduceStatus.map { case (k, status) =>\r\n        k -> status.responseStatus\r\n      }.asJava\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2108582444",
        "repo_full_name": "apache/kafka",
        "pr_number": 19793,
        "pr_file": "core/src/main/scala/kafka/server/ReplicaManager.scala",
        "discussion_id": "2108470367",
        "commented_code": "@@ -983,23 +1003,25 @@ class ReplicaManager(val config: KafkaConfig,\n       delayedProducePurgatory.tryCompleteElseWatch(delayedProduce, producerRequestKeys.asJava)\n     } else {\n       // we can respond immediately\n-      val produceResponseStatus = initialProduceStatus.map { case (k, status) => k -> status.responseStatus }\n+      val produceResponseStatus = new util.HashMap[TopicIdPartition, PartitionResponse]\n+      initialProduceStatus.foreach { case (k, status) => k -> produceResponseStatus.put(k, status.responseStatus) }",
        "comment_created_at": "2025-05-27T08:33:33+00:00",
        "comment_author": "frankvicky",
        "comment_body": "I think it's ok to use `HashMap` instead of `asJava` conversion.",
        "pr_file_module": null
      }
    ]
  }
]