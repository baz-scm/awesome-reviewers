[
  {
    "discussion_id": "2190419333",
    "pr_number": 19967,
    "pr_file": "group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupConfigManager.java",
    "created_at": "2025-07-07T15:33:57+00:00",
    "commented_code": "newGroupConfig\n         );\n         configMap.put(groupId, newConfig);\n+        listenerMap.getOrDefault(groupId, Collections.emptyList())",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2190419333",
        "repo_full_name": "apache/kafka",
        "pr_number": 19967,
        "pr_file": "group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupConfigManager.java",
        "discussion_id": "2190419333",
        "commented_code": "@@ -57,6 +62,8 @@ public void updateGroupConfig(String groupId, Properties newGroupConfig) {\n             newGroupConfig\n         );\n         configMap.put(groupId, newConfig);\n+        listenerMap.getOrDefault(groupId, Collections.emptyList())",
        "comment_created_at": "2025-07-07T15:33:57+00:00",
        "comment_author": "lucasbru",
        "comment_body": "`List.of` would me more modern",
        "pr_file_module": null
      },
      {
        "comment_id": "2190623384",
        "repo_full_name": "apache/kafka",
        "pr_number": 19967,
        "pr_file": "group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupConfigManager.java",
        "discussion_id": "2190419333",
        "commented_code": "@@ -57,6 +62,8 @@ public void updateGroupConfig(String groupId, Properties newGroupConfig) {\n             newGroupConfig\n         );\n         configMap.put(groupId, newConfig);\n+        listenerMap.getOrDefault(groupId, Collections.emptyList())",
        "comment_created_at": "2025-07-07T16:48:58+00:00",
        "comment_author": "UladzislauBlok",
        "comment_body": "True, I used Collections.emptyList() as it more verbal. Could fix it",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2204747748",
    "pr_number": 20156,
    "pr_file": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/ConnectorHandle.java",
    "created_at": "2025-07-14T12:13:32+00:00",
    "commented_code": "? taskHandles.values().stream()\n                 .map(task -> task.expectedStarts(expectedStarts))\n                 .collect(Collectors.toList())",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2204747748",
        "repo_full_name": "apache/kafka",
        "pr_number": 20156,
        "pr_file": "connect/runtime/src/test/java/org/apache/kafka/connect/integration/ConnectorHandle.java",
        "discussion_id": "2204747748",
        "commented_code": "@@ -284,7 +283,7 @@ public StartAndStopLatch expectedStarts(int expectedStarts, boolean includeTasks\n                 ? taskHandles.values().stream()\n                 .map(task -> task.expectedStarts(expectedStarts))\n                 .collect(Collectors.toList())",
        "comment_created_at": "2025-07-14T12:13:32+00:00",
        "comment_author": "m1a2st",
        "comment_body": "```suggestion\r\n                .toList()\r\n```\r\n\r\nCould you check other `collect(Collectors.toList())` usage and change to ` .toList()`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2222434730",
    "pr_number": 20214,
    "pr_file": "trogdor/src/main/java/org/apache/kafka/trogdor/coordinator/CoordinatorClient.java",
    "created_at": "2025-07-22T12:50:29+00:00",
    "commented_code": "}\n         List<List<String>> lines = new ArrayList<>();\n         List<String> header = new ArrayList<>(\n-            Arrays.asList(\"ID\", \"TYPE\", \"STATE\", \"INFO\"));\n+            List.of(\"ID\", \"TYPE\", \"STATE\", \"INFO\"));",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2222434730",
        "repo_full_name": "apache/kafka",
        "pr_number": 20214,
        "pr_file": "trogdor/src/main/java/org/apache/kafka/trogdor/coordinator/CoordinatorClient.java",
        "discussion_id": "2222434730",
        "commented_code": "@@ -472,7 +471,7 @@ static String prettyPrintTasksResponse(TasksResponse response, ZoneOffset zoneOf\n         }\n         List<List<String>> lines = new ArrayList<>();\n         List<String> header = new ArrayList<>(\n-            Arrays.asList(\"ID\", \"TYPE\", \"STATE\", \"INFO\"));\n+            List.of(\"ID\", \"TYPE\", \"STATE\", \"INFO\"));",
        "comment_created_at": "2025-07-22T12:50:29+00:00",
        "comment_author": "m1a2st",
        "comment_body": "```suggestion\r\n            List<String> header = List.of(\"ID\", \"TYPE\", \"STATE\", \"INFO\");\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2222467968",
    "pr_number": 20214,
    "pr_file": "trogdor/src/test/java/org/apache/kafka/trogdor/workload/PayloadGeneratorTest.java",
    "created_at": "2025-07-22T13:03:45+00:00",
    "commented_code": "new ConstantPayloadGenerator(4, new byte[0]);\n         RandomComponent constantConfig = new RandomComponent(25, constantGenerator);\n         \n-        List<RandomComponent> components1 = new ArrayList<>(Arrays.asList(nullConfig, uniformConfig));\n-        List<RandomComponent> components2 = new ArrayList<>(Arrays.asList(sequentialConfig, constantConfig));\n+        List<RandomComponent> components1 = new ArrayList<>(List.of(nullConfig, uniformConfig));\n+        List<RandomComponent> components2 = new ArrayList<>(List.of(sequentialConfig, constantConfig));",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2222467968",
        "repo_full_name": "apache/kafka",
        "pr_number": 20214,
        "pr_file": "trogdor/src/test/java/org/apache/kafka/trogdor/workload/PayloadGeneratorTest.java",
        "discussion_id": "2222467968",
        "commented_code": "@@ -146,8 +146,8 @@ public void testRandomComponentPayloadGenerator() {\n             new ConstantPayloadGenerator(4, new byte[0]);\n         RandomComponent constantConfig = new RandomComponent(25, constantGenerator);\n         \n-        List<RandomComponent> components1 = new ArrayList<>(Arrays.asList(nullConfig, uniformConfig));\n-        List<RandomComponent> components2 = new ArrayList<>(Arrays.asList(sequentialConfig, constantConfig));\n+        List<RandomComponent> components1 = new ArrayList<>(List.of(nullConfig, uniformConfig));\n+        List<RandomComponent> components2 = new ArrayList<>(List.of(sequentialConfig, constantConfig));",
        "comment_created_at": "2025-07-22T13:03:45+00:00",
        "comment_author": "m1a2st",
        "comment_body": "```suggestion\r\n        List<RandomComponent> components1 = List.of(nullConfig, uniformConfig);\r\n        List<RandomComponent> components2 = List.of(sequentialConfig, constantConfig);\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2222827608",
        "repo_full_name": "apache/kafka",
        "pr_number": 20214,
        "pr_file": "trogdor/src/test/java/org/apache/kafka/trogdor/workload/PayloadGeneratorTest.java",
        "discussion_id": "2222467968",
        "commented_code": "@@ -146,8 +146,8 @@ public void testRandomComponentPayloadGenerator() {\n             new ConstantPayloadGenerator(4, new byte[0]);\n         RandomComponent constantConfig = new RandomComponent(25, constantGenerator);\n         \n-        List<RandomComponent> components1 = new ArrayList<>(Arrays.asList(nullConfig, uniformConfig));\n-        List<RandomComponent> components2 = new ArrayList<>(Arrays.asList(sequentialConfig, constantConfig));\n+        List<RandomComponent> components1 = new ArrayList<>(List.of(nullConfig, uniformConfig));\n+        List<RandomComponent> components2 = new ArrayList<>(List.of(sequentialConfig, constantConfig));",
        "comment_created_at": "2025-07-22T14:57:48+00:00",
        "comment_author": "Pankraz76",
        "comment_body": "kindly considering possible solution for this to avoid/align:\r\n\r\n- https://docs.openrewrite.org/recipes/java/migrate/util/migratecollectionsunmodifiablelist\r\n- https://github.com/apache/kafka/pull/20219",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2180169462",
    "pr_number": 20091,
    "pr_file": "tools/src/main/java/org/apache/kafka/tools/AclCommand.java",
    "created_at": "2025-07-02T14:11:02+00:00",
    "commented_code": "Set<ResourcePatternFilter> groups = filters.stream().filter(f -> f.resourceType() == ResourceType.GROUP).collect(Collectors.toSet());\n \n         //Read, Describe on topic, Read on consumerGroup\n-        Set<AccessControlEntry> topicAcls = getAcl(opts, new HashSet<>(Arrays.asList(READ, DESCRIBE)));\n-        Set<AccessControlEntry> groupAcls = getAcl(opts, Collections.singleton(READ));\n+        Set<AccessControlEntry> topicAcls = getAcl(opts, new HashSet<>(List.of(READ, DESCRIBE)));",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2180169462",
        "repo_full_name": "apache/kafka",
        "pr_number": 20091,
        "pr_file": "tools/src/main/java/org/apache/kafka/tools/AclCommand.java",
        "discussion_id": "2180169462",
        "commented_code": "@@ -272,8 +270,8 @@ private static Map<ResourcePatternFilter, Set<AccessControlEntry>> getConsumerRe\n         Set<ResourcePatternFilter> groups = filters.stream().filter(f -> f.resourceType() == ResourceType.GROUP).collect(Collectors.toSet());\n \n         //Read, Describe on topic, Read on consumerGroup\n-        Set<AccessControlEntry> topicAcls = getAcl(opts, new HashSet<>(Arrays.asList(READ, DESCRIBE)));\n-        Set<AccessControlEntry> groupAcls = getAcl(opts, Collections.singleton(READ));\n+        Set<AccessControlEntry> topicAcls = getAcl(opts, new HashSet<>(List.of(READ, DESCRIBE)));",
        "comment_created_at": "2025-07-02T14:11:02+00:00",
        "comment_author": "m1a2st",
        "comment_body": "Could these properties be made immutable?\r\n```suggestion\r\n        Set<AccessControlEntry> topicAcls = getAcl(opts, new Set.of(READ, DESCRIBE));\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2123359886",
    "pr_number": 19869,
    "pr_file": "connect/api/src/test/java/org/apache/kafka/connect/data/ConnectSchemaTest.java",
    "created_at": "2025-06-03T10:10:21+00:00",
    "commented_code": "// Same as testArrayEquality, but checks differences in fields. Only does a simple check, relying on tests of\n         // Field's equals() method to validate all variations in the list of fields will be checked\n         ConnectSchema s1 = new ConnectSchema(Schema.Type.STRUCT, false, null, null, null, null, null,\n-                Arrays.asList(new Field(\"field\", 0, SchemaBuilder.int8().build()),\n+                List.of(new Field(\"field\", 0, SchemaBuilder.int8().build()),\n                         new Field(\"field2\", 1, SchemaBuilder.int16().build())), null, null);\n         ConnectSchema s2 = new ConnectSchema(Schema.Type.STRUCT, false, null, null, null, null, null,\n-                Arrays.asList(new Field(\"field\", 0, SchemaBuilder.int8().build()),\n+                List.of(new Field(\"field\", 0, SchemaBuilder.int8().build()),\n                         new Field(\"field2\", 1, SchemaBuilder.int16().build())), null, null);\n         ConnectSchema differentField = new ConnectSchema(Schema.Type.STRUCT, false, null, null, null, null, null,\n-                Arrays.asList(new Field(\"field\", 0, SchemaBuilder.int8().build()),\n+                List.of(new Field(\"field\", 0, SchemaBuilder.int8().build()),\n                         new Field(\"different field name\", 1, SchemaBuilder.int16().build())), null, null);\n \n         assertEquals(s1, s2);",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2123359886",
        "repo_full_name": "apache/kafka",
        "pr_number": 19869,
        "pr_file": "connect/api/src/test/java/org/apache/kafka/connect/data/ConnectSchemaTest.java",
        "discussion_id": "2123359886",
        "commented_code": "@@ -311,13 +312,13 @@ public void testStructEquality() {\n         // Same as testArrayEquality, but checks differences in fields. Only does a simple check, relying on tests of\n         // Field's equals() method to validate all variations in the list of fields will be checked\n         ConnectSchema s1 = new ConnectSchema(Schema.Type.STRUCT, false, null, null, null, null, null,\n-                Arrays.asList(new Field(\"field\", 0, SchemaBuilder.int8().build()),\n+                List.of(new Field(\"field\", 0, SchemaBuilder.int8().build()),\n                         new Field(\"field2\", 1, SchemaBuilder.int16().build())), null, null);\n         ConnectSchema s2 = new ConnectSchema(Schema.Type.STRUCT, false, null, null, null, null, null,\n-                Arrays.asList(new Field(\"field\", 0, SchemaBuilder.int8().build()),\n+                List.of(new Field(\"field\", 0, SchemaBuilder.int8().build()),\n                         new Field(\"field2\", 1, SchemaBuilder.int16().build())), null, null);\n         ConnectSchema differentField = new ConnectSchema(Schema.Type.STRUCT, false, null, null, null, null, null,\n-                Arrays.asList(new Field(\"field\", 0, SchemaBuilder.int8().build()),\n+                List.of(new Field(\"field\", 0, SchemaBuilder.int8().build()),\n                         new Field(\"different field name\", 1, SchemaBuilder.int16().build())), null, null);\n \n         assertEquals(s1, s2);",
        "comment_created_at": "2025-06-03T10:10:21+00:00",
        "comment_author": "m1a2st",
        "comment_body": "L384 `Arrays.asList` also need to transfer to `List.of()`\r\nL380 `Collections.emptyList()`\r\nL381 `Collections.singletonList(\"hello\")`\r\nL389 `Collections.singletonList(true)`\r\n\r\nPlease double-check this file",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2195299248",
    "pr_number": 19869,
    "pr_file": "connect/api/src/main/java/org/apache/kafka/connect/data/ConnectSchema.java",
    "created_at": "2025-07-09T15:18:45+00:00",
    "commented_code": "import java.math.BigDecimal;\n import java.nio.ByteBuffer;\n-import java.util.Arrays;\n import java.util.Collections;\n import java.util.EnumMap;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Objects;\n+import java.util.stream.Collectors;\n \n public class ConnectSchema implements Schema {\n     /**\n      * Maps {@link Schema.Type}s to a list of Java classes that can be used to represent them.\n      */\n-    private static final Map<Type, List<Class<?>>> SCHEMA_TYPE_CLASSES = new EnumMap<>(Type.class);\n+    private static final Map<Type, List<Class<?>>> SCHEMA_TYPE_CLASSES = Collections.unmodifiableMap(new EnumMap<>(Map.ofEntries(\n+        Map.entry(Type.INT8, List.of(Byte.class)),\n+        Map.entry(Type.INT16, List.of(Short.class)),\n+        Map.entry(Type.INT32, List.of(Integer.class)),\n+        Map.entry(Type.INT64, List.of(Long.class)),\n+        Map.entry(Type.FLOAT32, List.of(Float.class)),\n+        Map.entry(Type.FLOAT64, List.of(Double.class)),\n+        Map.entry(Type.BOOLEAN, List.of(Boolean.class)),\n+        Map.entry(Type.STRING, List.of(String.class)),\n+        // Bytes are special and have 2 representations. byte[] causes problems because it doesn't handle equals() and\n+        // hashCode() like we want objects to, so we support both byte[] and ByteBuffer. Using plain byte[] can cause\n+        // those methods to fail, so ByteBuffers are recommended\n+        Map.entry(Type.BYTES, List.of(byte[].class, ByteBuffer.class)),\n+        Map.entry(Type.ARRAY, List.of(List.class)),\n+        Map.entry(Type.MAP, List.of(Map.class)),\n+        Map.entry(Type.STRUCT, List.of(Struct.class))\n+    )));\n     /**\n      * Maps known logical types to a list of Java classes that can be used to represent them.\n      */\n-    private static final Map<String, List<Class<?>>> LOGICAL_TYPE_CLASSES = new HashMap<>();\n+    // We don't need to put these into JAVA_CLASS_SCHEMA_TYPES since that's only used to determine schemas for\n+    // schemaless data and logical types will have ambiguous schemas (e.g. many of them use the same Java class) so\n+    // they should not be used without schemas.\n+    private static final Map<String, List<Class<?>>> LOGICAL_TYPE_CLASSES = Map.of(\n+        Decimal.LOGICAL_NAME, List.of(BigDecimal.class),\n+        Date.LOGICAL_NAME, List.of(java.util.Date.class),\n+        Time.LOGICAL_NAME, List.of(java.util.Date.class),\n+        Timestamp.LOGICAL_NAME, List.of(java.util.Date.class)\n+    );\n \n     /**\n      * Maps the Java classes to the corresponding {@link Schema.Type}.\n      */\n-    private static final Map<Class<?>, Type> JAVA_CLASS_SCHEMA_TYPES = new HashMap<>();\n-\n-    static {\n-        SCHEMA_TYPE_CLASSES.put(Type.INT8, Collections.singletonList(Byte.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.INT16, Collections.singletonList(Short.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.INT32, Collections.singletonList(Integer.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.INT64, Collections.singletonList(Long.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.FLOAT32, Collections.singletonList(Float.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.FLOAT64, Collections.singletonList(Double.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.BOOLEAN, Collections.singletonList(Boolean.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.STRING, Collections.singletonList(String.class));\n-        // Bytes are special and have 2 representations. byte[] causes problems because it doesn't handle equals() and\n-        // hashCode() like we want objects to, so we support both byte[] and ByteBuffer. Using plain byte[] can cause\n-        // those methods to fail, so ByteBuffers are recommended\n-        SCHEMA_TYPE_CLASSES.put(Type.BYTES, Arrays.asList(byte[].class, ByteBuffer.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.ARRAY, Collections.singletonList(List.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.MAP, Collections.singletonList(Map.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.STRUCT, Collections.singletonList(Struct.class));\n-\n-        for (Map.Entry<Type, List<Class<?>>> schemaClasses : SCHEMA_TYPE_CLASSES.entrySet()) {\n-            for (Class<?> schemaClass : schemaClasses.getValue())\n-                JAVA_CLASS_SCHEMA_TYPES.put(schemaClass, schemaClasses.getKey());\n-        }\n-\n-        LOGICAL_TYPE_CLASSES.put(Decimal.LOGICAL_NAME, Collections.singletonList(BigDecimal.class));\n-        LOGICAL_TYPE_CLASSES.put(Date.LOGICAL_NAME, Collections.singletonList(java.util.Date.class));\n-        LOGICAL_TYPE_CLASSES.put(Time.LOGICAL_NAME, Collections.singletonList(java.util.Date.class));\n-        LOGICAL_TYPE_CLASSES.put(Timestamp.LOGICAL_NAME, Collections.singletonList(java.util.Date.class));\n-        // We don't need to put these into JAVA_CLASS_SCHEMA_TYPES since that's only used to determine schemas for\n-        // schemaless data and logical types will have ambiguous schemas (e.g. many of them use the same Java class) so\n-        // they should not be used without schemas.\n-    }\n+    private static final Map<Class<?>, Type> JAVA_CLASS_SCHEMA_TYPES = new HashMap<>(SCHEMA_TYPE_CLASSES.entrySet()",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2195299248",
        "repo_full_name": "apache/kafka",
        "pr_number": 19869,
        "pr_file": "connect/api/src/main/java/org/apache/kafka/connect/data/ConnectSchema.java",
        "discussion_id": "2195299248",
        "commented_code": "@@ -20,59 +20,55 @@\n \n import java.math.BigDecimal;\n import java.nio.ByteBuffer;\n-import java.util.Arrays;\n import java.util.Collections;\n import java.util.EnumMap;\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n import java.util.Objects;\n+import java.util.stream.Collectors;\n \n public class ConnectSchema implements Schema {\n     /**\n      * Maps {@link Schema.Type}s to a list of Java classes that can be used to represent them.\n      */\n-    private static final Map<Type, List<Class<?>>> SCHEMA_TYPE_CLASSES = new EnumMap<>(Type.class);\n+    private static final Map<Type, List<Class<?>>> SCHEMA_TYPE_CLASSES = Collections.unmodifiableMap(new EnumMap<>(Map.ofEntries(\n+        Map.entry(Type.INT8, List.of(Byte.class)),\n+        Map.entry(Type.INT16, List.of(Short.class)),\n+        Map.entry(Type.INT32, List.of(Integer.class)),\n+        Map.entry(Type.INT64, List.of(Long.class)),\n+        Map.entry(Type.FLOAT32, List.of(Float.class)),\n+        Map.entry(Type.FLOAT64, List.of(Double.class)),\n+        Map.entry(Type.BOOLEAN, List.of(Boolean.class)),\n+        Map.entry(Type.STRING, List.of(String.class)),\n+        // Bytes are special and have 2 representations. byte[] causes problems because it doesn't handle equals() and\n+        // hashCode() like we want objects to, so we support both byte[] and ByteBuffer. Using plain byte[] can cause\n+        // those methods to fail, so ByteBuffers are recommended\n+        Map.entry(Type.BYTES, List.of(byte[].class, ByteBuffer.class)),\n+        Map.entry(Type.ARRAY, List.of(List.class)),\n+        Map.entry(Type.MAP, List.of(Map.class)),\n+        Map.entry(Type.STRUCT, List.of(Struct.class))\n+    )));\n     /**\n      * Maps known logical types to a list of Java classes that can be used to represent them.\n      */\n-    private static final Map<String, List<Class<?>>> LOGICAL_TYPE_CLASSES = new HashMap<>();\n+    // We don't need to put these into JAVA_CLASS_SCHEMA_TYPES since that's only used to determine schemas for\n+    // schemaless data and logical types will have ambiguous schemas (e.g. many of them use the same Java class) so\n+    // they should not be used without schemas.\n+    private static final Map<String, List<Class<?>>> LOGICAL_TYPE_CLASSES = Map.of(\n+        Decimal.LOGICAL_NAME, List.of(BigDecimal.class),\n+        Date.LOGICAL_NAME, List.of(java.util.Date.class),\n+        Time.LOGICAL_NAME, List.of(java.util.Date.class),\n+        Timestamp.LOGICAL_NAME, List.of(java.util.Date.class)\n+    );\n \n     /**\n      * Maps the Java classes to the corresponding {@link Schema.Type}.\n      */\n-    private static final Map<Class<?>, Type> JAVA_CLASS_SCHEMA_TYPES = new HashMap<>();\n-\n-    static {\n-        SCHEMA_TYPE_CLASSES.put(Type.INT8, Collections.singletonList(Byte.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.INT16, Collections.singletonList(Short.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.INT32, Collections.singletonList(Integer.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.INT64, Collections.singletonList(Long.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.FLOAT32, Collections.singletonList(Float.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.FLOAT64, Collections.singletonList(Double.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.BOOLEAN, Collections.singletonList(Boolean.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.STRING, Collections.singletonList(String.class));\n-        // Bytes are special and have 2 representations. byte[] causes problems because it doesn't handle equals() and\n-        // hashCode() like we want objects to, so we support both byte[] and ByteBuffer. Using plain byte[] can cause\n-        // those methods to fail, so ByteBuffers are recommended\n-        SCHEMA_TYPE_CLASSES.put(Type.BYTES, Arrays.asList(byte[].class, ByteBuffer.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.ARRAY, Collections.singletonList(List.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.MAP, Collections.singletonList(Map.class));\n-        SCHEMA_TYPE_CLASSES.put(Type.STRUCT, Collections.singletonList(Struct.class));\n-\n-        for (Map.Entry<Type, List<Class<?>>> schemaClasses : SCHEMA_TYPE_CLASSES.entrySet()) {\n-            for (Class<?> schemaClass : schemaClasses.getValue())\n-                JAVA_CLASS_SCHEMA_TYPES.put(schemaClass, schemaClasses.getKey());\n-        }\n-\n-        LOGICAL_TYPE_CLASSES.put(Decimal.LOGICAL_NAME, Collections.singletonList(BigDecimal.class));\n-        LOGICAL_TYPE_CLASSES.put(Date.LOGICAL_NAME, Collections.singletonList(java.util.Date.class));\n-        LOGICAL_TYPE_CLASSES.put(Time.LOGICAL_NAME, Collections.singletonList(java.util.Date.class));\n-        LOGICAL_TYPE_CLASSES.put(Timestamp.LOGICAL_NAME, Collections.singletonList(java.util.Date.class));\n-        // We don't need to put these into JAVA_CLASS_SCHEMA_TYPES since that's only used to determine schemas for\n-        // schemaless data and logical types will have ambiguous schemas (e.g. many of them use the same Java class) so\n-        // they should not be used without schemas.\n-    }\n+    private static final Map<Class<?>, Type> JAVA_CLASS_SCHEMA_TYPES = new HashMap<>(SCHEMA_TYPE_CLASSES.entrySet()",
        "comment_created_at": "2025-07-09T15:18:45+00:00",
        "comment_author": "chia7712",
        "comment_body": "`toMap` returns the mutable map, so `new HashMap` is unnecessary.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2195302066",
    "pr_number": 19869,
    "pr_file": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/rest/MirrorRestServer.java",
    "created_at": "2025-07-09T15:20:02+00:00",
    "commented_code": "@Override\n     protected Collection<Class<?>> regularResources() {\n-        return Collections.singletonList(\n+        return List.of(",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2195302066",
        "repo_full_name": "apache/kafka",
        "pr_number": 19869,
        "pr_file": "connect/mirror/src/main/java/org/apache/kafka/connect/mirror/rest/MirrorRestServer.java",
        "discussion_id": "2195302066",
        "commented_code": "@@ -48,14 +48,14 @@ public void initializeInternalResources(Map<SourceAndTarget, Herder> herders) {\n \n     @Override\n     protected Collection<Class<?>> regularResources() {\n-        return Collections.singletonList(\n+        return List.of(",
        "comment_created_at": "2025-07-09T15:20:02+00:00",
        "comment_author": "chia7712",
        "comment_body": "```java\r\nreturn List.of(InternalMirrorResource.class);\r\n```",
        "pr_file_module": null
      }
    ]
  }
]