[
  {
    "discussion_id": "2237817680",
    "pr_number": 20253,
    "pr_file": "core/src/main/java/kafka/server/share/SharePartition.java",
    "created_at": "2025-07-28T20:36:33+00:00",
    "commented_code": "}\n     }\n \n+    private LastOffsetAndMaxRecords lastOffsetAndMaxRecordsToAcquire(long fetchOffset, int maxFetchRecords, long lastOffset) {\n+        // There can always be records fetched exceeding the max in-flight messages limit. Hence,\n+        // we need to check if the share partition has reached the max in-flight messages limit\n+        // and only acquire limited records.\n+        int maxRecordsToAcquire;\n+        long lastOffsetToAcquire = lastOffset;\n+        lock.readLock().lock();\n+        try {\n+            int inFlightRecordsCount = numInFlightRecords();\n+            // Take minimum of maxFetchRecords and remaining capacity to fill max in-flight messages limit.\n+            maxRecordsToAcquire = Math.min(maxFetchRecords, maxInFlightMessages - inFlightRecordsCount);",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2237817680",
        "repo_full_name": "apache/kafka",
        "pr_number": 20253,
        "pr_file": "core/src/main/java/kafka/server/share/SharePartition.java",
        "discussion_id": "2237817680",
        "commented_code": "@@ -1449,6 +1461,46 @@ private void maybeUpdateReadGapFetchOffset(long offset) {\n         }\n     }\n \n+    private LastOffsetAndMaxRecords lastOffsetAndMaxRecordsToAcquire(long fetchOffset, int maxFetchRecords, long lastOffset) {\n+        // There can always be records fetched exceeding the max in-flight messages limit. Hence,\n+        // we need to check if the share partition has reached the max in-flight messages limit\n+        // and only acquire limited records.\n+        int maxRecordsToAcquire;\n+        long lastOffsetToAcquire = lastOffset;\n+        lock.readLock().lock();\n+        try {\n+            int inFlightRecordsCount = numInFlightRecords();\n+            // Take minimum of maxFetchRecords and remaining capacity to fill max in-flight messages limit.\n+            maxRecordsToAcquire = Math.min(maxFetchRecords, maxInFlightMessages - inFlightRecordsCount);",
        "comment_created_at": "2025-07-28T20:36:33+00:00",
        "comment_author": "AndrewJSchofield",
        "comment_body": "nit: Generally, we use \"records\" but it's \"maxInFlightMessages\". Maybe should rename to \"maxInFlightRecords\".",
        "pr_file_module": null
      },
      {
        "comment_id": "2237892481",
        "repo_full_name": "apache/kafka",
        "pr_number": 20253,
        "pr_file": "core/src/main/java/kafka/server/share/SharePartition.java",
        "discussion_id": "2237817680",
        "commented_code": "@@ -1449,6 +1461,46 @@ private void maybeUpdateReadGapFetchOffset(long offset) {\n         }\n     }\n \n+    private LastOffsetAndMaxRecords lastOffsetAndMaxRecordsToAcquire(long fetchOffset, int maxFetchRecords, long lastOffset) {\n+        // There can always be records fetched exceeding the max in-flight messages limit. Hence,\n+        // we need to check if the share partition has reached the max in-flight messages limit\n+        // and only acquire limited records.\n+        int maxRecordsToAcquire;\n+        long lastOffsetToAcquire = lastOffset;\n+        lock.readLock().lock();\n+        try {\n+            int inFlightRecordsCount = numInFlightRecords();\n+            // Take minimum of maxFetchRecords and remaining capacity to fill max in-flight messages limit.\n+            maxRecordsToAcquire = Math.min(maxFetchRecords, maxInFlightMessages - inFlightRecordsCount);",
        "comment_created_at": "2025-07-28T21:25:01+00:00",
        "comment_author": "apoorvmittal10",
        "comment_body": "I have noted this. I wll send a separate patch for this. As I have to change a lot of comments and it will be a big refactor. I am avoiding it in this PR, else the main change of the PR will be hard to determine.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2190417759",
    "pr_number": 19967,
    "pr_file": "group-coordinator/src/main/java/org/apache/kafka/coordinator/group/ConfigUpdateEvent.java",
    "created_at": "2025-07-07T15:33:10+00:00",
    "commented_code": "+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.coordinator.group;\n+\n+public enum ConfigUpdateEvent {\n+    // Client Actions Required",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2190417759",
        "repo_full_name": "apache/kafka",
        "pr_number": 19967,
        "pr_file": "group-coordinator/src/main/java/org/apache/kafka/coordinator/group/ConfigUpdateEvent.java",
        "discussion_id": "2190417759",
        "commented_code": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.coordinator.group;\n+\n+public enum ConfigUpdateEvent {\n+    // Client Actions Required",
        "comment_created_at": "2025-07-07T15:33:10+00:00",
        "comment_author": "lucasbru",
        "comment_body": "What does \"client\" refer to here?",
        "pr_file_module": null
      },
      {
        "comment_id": "2190618422",
        "repo_full_name": "apache/kafka",
        "pr_number": 19967,
        "pr_file": "group-coordinator/src/main/java/org/apache/kafka/coordinator/group/ConfigUpdateEvent.java",
        "discussion_id": "2190417759",
        "commented_code": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.kafka.coordinator.group;\n+\n+public enum ConfigUpdateEvent {\n+    // Client Actions Required",
        "comment_created_at": "2025-07-07T16:46:15+00:00",
        "comment_author": "UladzislauBlok",
        "comment_body": "Here client == subscriber / listener, so any place in code where we want to react to config update",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2075807817",
    "pr_number": 19589,
    "pr_file": "raft/src/main/java/org/apache/kafka/raft/FollowerState.java",
    "created_at": "2025-05-06T16:08:58+00:00",
    "commented_code": "private final Set<Integer> voters;\n     // Used for tracking the expiration of both the Fetch and FetchSnapshot requests\n     private final Timer fetchTimer;\n-    // Used to track when to send another update voter request\n+    // Used to track when to send another add, remove, or update voter request\n     private final Timer updateVoterPeriodTimer;",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2075807817",
        "repo_full_name": "apache/kafka",
        "pr_number": 19589,
        "pr_file": "raft/src/main/java/org/apache/kafka/raft/FollowerState.java",
        "discussion_id": "2075807817",
        "commented_code": "@@ -40,10 +40,8 @@ public class FollowerState implements EpochState {\n     private final Set<Integer> voters;\n     // Used for tracking the expiration of both the Fetch and FetchSnapshot requests\n     private final Timer fetchTimer;\n-    // Used to track when to send another update voter request\n+    // Used to track when to send another add, remove, or update voter request\n     private final Timer updateVoterPeriodTimer;",
        "comment_created_at": "2025-05-06T16:08:58+00:00",
        "comment_author": "jsancio",
        "comment_body": "Subtle but maybe `updateVoterSetPeriodTimer` is a better now since it is used to update a voter, remove a voter or add a voter.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2071532836",
    "pr_number": 19400,
    "pr_file": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java",
    "created_at": "2025-05-02T12:19:05+00:00",
    "commented_code": "return Math.max(now - previous, 0);\n     }\n \n+    public void shutdown() {",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2071532836",
        "repo_full_name": "apache/kafka",
        "pr_number": 19400,
        "pr_file": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java",
        "discussion_id": "2071532836",
        "commented_code": "@@ -1776,22 +1780,28 @@ private long advanceNowAndComputeLatency() {\n         return Math.max(now - previous, 0);\n     }\n \n+    public void shutdown() {",
        "comment_created_at": "2025-05-02T12:19:05+00:00",
        "comment_author": "ableegoldman",
        "comment_body": "as mentioned above, let's just get rid of the overload without a `leaveGroup` parameter, this way the caller has to consciously decide whether it should be leaving the group or not",
        "pr_file_module": null
      },
      {
        "comment_id": "2072333954",
        "repo_full_name": "apache/kafka",
        "pr_number": 19400,
        "pr_file": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java",
        "discussion_id": "2071532836",
        "commented_code": "@@ -1776,22 +1780,28 @@ private long advanceNowAndComputeLatency() {\n         return Math.max(now - previous, 0);\n     }\n \n+    public void shutdown() {",
        "comment_created_at": "2025-05-03T06:39:51+00:00",
        "comment_author": "frankvicky",
        "comment_body": "Make sense!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1937607369",
    "pr_number": 18600,
    "pr_file": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java",
    "created_at": "2025-01-31T16:53:10+00:00",
    "commented_code": "}\n \n     @ParameterizedTest\n-    @CsvSource({ \"false,false\", \"false,true\", \"true,false\", \"true,true\" })\n-    public void testLeaderListenerNotified(boolean entireLog, boolean withKip853Rpc) throws Exception {\n+    @MethodSource(\"generateKip853TestMatrix\")\n+    public void testLeaderListenerNotified(boolean entireLog, RaftProtocol raftProtocol) throws Exception {",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "1937607369",
        "repo_full_name": "apache/kafka",
        "pr_number": 18600,
        "pr_file": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java",
        "discussion_id": "1937607369",
        "commented_code": "@@ -95,15 +103,15 @@ public void testLatestSnapshotIdMissing() throws Exception {\n     }\n \n     @ParameterizedTest\n-    @CsvSource({ \"false,false\", \"false,true\", \"true,false\", \"true,true\" })\n-    public void testLeaderListenerNotified(boolean entireLog, boolean withKip853Rpc) throws Exception {\n+    @MethodSource(\"generateKip853TestMatrix\")\n+    public void testLeaderListenerNotified(boolean entireLog, RaftProtocol raftProtocol) throws Exception {",
        "comment_created_at": "2025-01-31T16:53:10+00:00",
        "comment_author": "ahuang98",
        "comment_body": "I guess another option would be just renaming the second parameter to `boolean isReconfigSupported`, potentially easier for readers to know at a glance that we're not testing the entire set of raftProtocols (rather than navigating to the method source definition)\r\n\r\n(then we would do `.withRaftProtocol(isReconfigSupported ? KIP_853_PROTOCOL : KIP_595_PROTOCOL)` which I understand is a bit bulkier)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2195503577",
    "pr_number": 20124,
    "pr_file": "core/src/main/java/kafka/server/share/SharePartition.java",
    "created_at": "2025-07-09T16:54:10+00:00",
    "commented_code": "private InFlightState rollbackState;\n         // The timer task for the acquisition lock timeout.\n         private AcquisitionLockTimerTask acquisitionLockTimeoutTask;\n+        // The boolean determines if the record has achieved a final state of ARCHIVED from which it cannot transition\n+        // to any other state. This could happen because of LSO movement etc.\n+        private boolean isMarkedArchived = false;",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2195503577",
        "repo_full_name": "apache/kafka",
        "pr_number": 20124,
        "pr_file": "core/src/main/java/kafka/server/share/SharePartition.java",
        "discussion_id": "2195503577",
        "commented_code": "@@ -3016,6 +3023,9 @@ static final class InFlightState {\n         private InFlightState rollbackState;\n         // The timer task for the acquisition lock timeout.\n         private AcquisitionLockTimerTask acquisitionLockTimeoutTask;\n+        // The boolean determines if the record has achieved a final state of ARCHIVED from which it cannot transition\n+        // to any other state. This could happen because of LSO movement etc.\n+        private boolean isMarkedArchived = false;",
        "comment_created_at": "2025-07-09T16:54:10+00:00",
        "comment_author": "AndrewJSchofield",
        "comment_body": "If this is set to `true`, it means that the state of the record is ARCHIVED, and that there will be no further state transitions allowed? That seems like a terminal state to me, as opposed to \"marked archived\" which is a bit more nebulous in meaning.",
        "pr_file_module": null
      },
      {
        "comment_id": "2195525999",
        "repo_full_name": "apache/kafka",
        "pr_number": 20124,
        "pr_file": "core/src/main/java/kafka/server/share/SharePartition.java",
        "discussion_id": "2195503577",
        "commented_code": "@@ -3016,6 +3023,9 @@ static final class InFlightState {\n         private InFlightState rollbackState;\n         // The timer task for the acquisition lock timeout.\n         private AcquisitionLockTimerTask acquisitionLockTimeoutTask;\n+        // The boolean determines if the record has achieved a final state of ARCHIVED from which it cannot transition\n+        // to any other state. This could happen because of LSO movement etc.\n+        private boolean isMarkedArchived = false;",
        "comment_created_at": "2025-07-09T17:06:32+00:00",
        "comment_author": "adixitconfluent",
        "comment_body": "Agreed, I can use `isTerminalState`, sounds better to me",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2173285324",
    "pr_number": 20040,
    "pr_file": "coordinator-common/src/main/java/org/apache/kafka/coordinator/common/runtime/CoordinatorRuntime.java",
    "created_at": "2025-06-28T14:27:03+00:00",
    "commented_code": "LogConfig logConfig = partitionWriter.config(tp);\n                 int maxBatchSize = logConfig.maxMessageSize();\n                 long prevLastWrittenOffset = coordinator.lastWrittenOffset();\n-                ByteBuffer buffer = bufferSupplier.get(maxBatchSize);\n+                ByteBuffer buffer = bufferSupplier.get(min(MIN_BUFFER_SIZE, maxBatchSize));",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2173285324",
        "repo_full_name": "apache/kafka",
        "pr_number": 20040,
        "pr_file": "coordinator-common/src/main/java/org/apache/kafka/coordinator/common/runtime/CoordinatorRuntime.java",
        "discussion_id": "2173285324",
        "commented_code": "@@ -859,7 +866,7 @@ private void maybeAllocateNewBatch(\n                 LogConfig logConfig = partitionWriter.config(tp);\n                 int maxBatchSize = logConfig.maxMessageSize();\n                 long prevLastWrittenOffset = coordinator.lastWrittenOffset();\n-                ByteBuffer buffer = bufferSupplier.get(maxBatchSize);\n+                ByteBuffer buffer = bufferSupplier.get(min(MIN_BUFFER_SIZE, maxBatchSize));",
        "comment_created_at": "2025-06-28T14:27:03+00:00",
        "comment_author": "Yunyung",
        "comment_body": "If so, since we allow users to assign `maxBatchSize` smaller than `MIN_BUFFER_SIZE`. `MIN_BUFFER_SIZE` variable name does not match its semantics. Maybe rename it to \"DEFAULT_BUFFER_SIZE\" or something similar.",
        "pr_file_module": null
      },
      {
        "comment_id": "2173383416",
        "repo_full_name": "apache/kafka",
        "pr_number": 20040,
        "pr_file": "coordinator-common/src/main/java/org/apache/kafka/coordinator/common/runtime/CoordinatorRuntime.java",
        "discussion_id": "2173285324",
        "commented_code": "@@ -859,7 +866,7 @@ private void maybeAllocateNewBatch(\n                 LogConfig logConfig = partitionWriter.config(tp);\n                 int maxBatchSize = logConfig.maxMessageSize();\n                 long prevLastWrittenOffset = coordinator.lastWrittenOffset();\n-                ByteBuffer buffer = bufferSupplier.get(maxBatchSize);\n+                ByteBuffer buffer = bufferSupplier.get(min(MIN_BUFFER_SIZE, maxBatchSize));",
        "comment_created_at": "2025-06-28T15:57:48+00:00",
        "comment_author": "mingyen066",
        "comment_body": "Good suggestion! I\u2019ve renamed MIN_BUFFER_SIZE to INITIAL_BUFFER_SIZE.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2157277385",
    "pr_number": 19646,
    "pr_file": "tools/src/main/java/org/apache/kafka/tools/streams/StreamsGroupCommand.java",
    "created_at": "2025-06-19T15:29:51+00:00",
    "commented_code": "result.put(groupId, resetOffsetsForInactiveGroup(groupId, dryRun));\n                                 // delete internal topics\n                                 if (!dryRun) {\n-                                    List<String> internalTopics = retrieveInternalTopics(List.of(groupId)).get(groupId);\n-                                    if (internalTopics != null && !internalTopics.isEmpty()) {\n+                                    List<String> internalTopics = getInternalTopicsForGroup(groupId);",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2157277385",
        "repo_full_name": "apache/kafka",
        "pr_number": 19646,
        "pr_file": "tools/src/main/java/org/apache/kafka/tools/streams/StreamsGroupCommand.java",
        "discussion_id": "2157277385",
        "commented_code": "@@ -483,8 +483,8 @@ Map<String, Map<TopicPartition, OffsetAndMetadata>> resetOffsets() {\n                                 result.put(groupId, resetOffsetsForInactiveGroup(groupId, dryRun));\n                                 // delete internal topics\n                                 if (!dryRun) {\n-                                    List<String> internalTopics = retrieveInternalTopics(List.of(groupId)).get(groupId);\n-                                    if (internalTopics != null && !internalTopics.isEmpty()) {\n+                                    List<String> internalTopics = getInternalTopicsForGroup(groupId);",
        "comment_created_at": "2025-06-19T15:29:51+00:00",
        "comment_author": "lucasbru",
        "comment_body": "`getInternalTopicsToBeDeleted` maybe?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2171298092",
    "pr_number": 20055,
    "pr_file": "group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupMetadataManager.java",
    "created_at": "2025-06-27T08:55:38+00:00",
    "commented_code": "BiFunction<Uuid, Integer, Integer> currentPartitionEpoch,\n         int targetAssignmentEpoch,\n         Assignment targetAssignment,\n+        Map<String, ResolvedRegularExpression> resolvedRegularExpressions,\n+        boolean forceSubscriptionConsistency,",
    "repo_full_name": "apache/kafka",
    "discussion_comments": [
      {
        "comment_id": "2171298092",
        "repo_full_name": "apache/kafka",
        "pr_number": 20055,
        "pr_file": "group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupMetadataManager.java",
        "discussion_id": "2171298092",
        "commented_code": "@@ -3463,15 +3473,19 @@ private ConsumerGroupMember maybeReconcile(\n         BiFunction<Uuid, Integer, Integer> currentPartitionEpoch,\n         int targetAssignmentEpoch,\n         Assignment targetAssignment,\n+        Map<String, ResolvedRegularExpression> resolvedRegularExpressions,\n+        boolean forceSubscriptionConsistency,",
        "comment_created_at": "2025-06-27T08:55:38+00:00",
        "comment_author": "dajac",
        "comment_body": "nit: `hasUpdatedSubscription`?",
        "pr_file_module": null
      },
      {
        "comment_id": "2174220866",
        "repo_full_name": "apache/kafka",
        "pr_number": 20055,
        "pr_file": "group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupMetadataManager.java",
        "discussion_id": "2171298092",
        "commented_code": "@@ -3463,15 +3473,19 @@ private ConsumerGroupMember maybeReconcile(\n         BiFunction<Uuid, Integer, Integer> currentPartitionEpoch,\n         int targetAssignmentEpoch,\n         Assignment targetAssignment,\n+        Map<String, ResolvedRegularExpression> resolvedRegularExpressions,\n+        boolean forceSubscriptionConsistency,",
        "comment_created_at": "2025-06-30T04:56:18+00:00",
        "comment_author": "squah-confluent",
        "comment_body": "Renamed it to `hasSubscriptionChanged`, to be similar to the `hasMemberSubscriptionChanged` method.",
        "pr_file_module": null
      }
    ]
  }
]