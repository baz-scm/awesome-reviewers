[
  {
    "discussion_id": "2224990400",
    "pr_number": 130653,
    "pr_file": "test/integration/scheduler_perf/misc/templates/pod-with-extended-resource.yaml",
    "created_at": "2025-07-23T09:39:57+00:00",
    "commented_code": "+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: test-extended-resource-{{.Index}}\n+spec:\n+  containers:\n+  - image: registry.k8s.io/pause:3.9\n+    name: pause\n+    resources:\n+      requests:\n+        foo.com/bar-{{.Index}}: 1\n+      limits:\n+        foo.com/bar-{{.Index}}: 1",
    "repo_full_name": "kubernetes/kubernetes",
    "discussion_comments": [
      {
        "comment_id": "2224990400",
        "repo_full_name": "kubernetes/kubernetes",
        "pr_number": 130653,
        "pr_file": "test/integration/scheduler_perf/misc/templates/pod-with-extended-resource.yaml",
        "discussion_id": "2224990400",
        "commented_code": "@@ -0,0 +1,13 @@\n+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: test-extended-resource-{{.Index}}\n+spec:\n+  containers:\n+  - image: registry.k8s.io/pause:3.9\n+    name: pause\n+    resources:\n+      requests:\n+        foo.com/bar-{{.Index}}: 1\n+      limits:\n+        foo.com/bar-{{.Index}}: 1",
        "comment_created_at": "2025-07-23T09:39:57+00:00",
        "comment_author": "macsko",
        "comment_body": "Let's drop limits as they are redundant",
        "pr_file_module": null
      },
      {
        "comment_id": "2226253816",
        "repo_full_name": "kubernetes/kubernetes",
        "pr_number": 130653,
        "pr_file": "test/integration/scheduler_perf/misc/templates/pod-with-extended-resource.yaml",
        "discussion_id": "2224990400",
        "commented_code": "@@ -0,0 +1,13 @@\n+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: test-extended-resource-{{.Index}}\n+spec:\n+  containers:\n+  - image: registry.k8s.io/pause:3.9\n+    name: pause\n+    resources:\n+      requests:\n+        foo.com/bar-{{.Index}}: 1\n+      limits:\n+        foo.com/bar-{{.Index}}: 1",
        "comment_created_at": "2025-07-23T17:43:08+00:00",
        "comment_author": "yliaog",
        "comment_body": "done",
        "pr_file_module": null
      },
      {
        "comment_id": "2226450523",
        "repo_full_name": "kubernetes/kubernetes",
        "pr_number": 130653,
        "pr_file": "test/integration/scheduler_perf/misc/templates/pod-with-extended-resource.yaml",
        "discussion_id": "2224990400",
        "commented_code": "@@ -0,0 +1,13 @@\n+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: test-extended-resource-{{.Index}}\n+spec:\n+  containers:\n+  - image: registry.k8s.io/pause:3.9\n+    name: pause\n+    resources:\n+      requests:\n+        foo.com/bar-{{.Index}}: 1\n+      limits:\n+        foo.com/bar-{{.Index}}: 1",
        "comment_created_at": "2025-07-23T19:24:42+00:00",
        "comment_author": "yliaog",
        "comment_body": "added them back due to following errors in integration test.\r\n\r\nhttps://prow.k8s.io/view/gs/kubernetes-ci-logs/pr-logs/pull/130653/pull-kubernetes-integration/1948078177184124928\r\n\r\n    scheduler_perf.go:1324: FATAL ERROR: Error running workload fast: op 5: error creating pod: failed to create object with non-retriable error: Pod \"test-dra-3\" is invalid: spec.containers[0].resources.limits: Required value: Limit must be set for non overcommitable resources \r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2210691719",
    "pr_number": 131357,
    "pr_file": "test/integration/scheduler_perf/dra/performance-config.yaml",
    "created_at": "2025-07-16T15:03:15+00:00",
    "commented_code": "measurePods: 1\n       duration: 2s\n \n+# SchedulingWithResourceClaimTemplateMixins is a variant of\n+# SchedulingWithResourceClaimTemplate.\n+- name: SteadyStateClusterResourceClaimTemplateResourceSliceMixins\n+  featureGates:\n+    DynamicResourceAllocation: true\n+    DRAPrioritizedList: true\n+    DRAResourceSliceMixins: true\n+  workloadTemplate:\n+  - opcode: createNodes\n+    countParam: $nodesWithoutDRA\n+  - opcode: createNodes\n+    nodeTemplatePath: templates/node-with-dra-test-driver.yaml\n+    countParam: $nodesWithDRA\n+  - opcode: createResourceDriver\n+    driverName: test-driver.cdi.k8s.io\n+    nodes: scheduler-perf-dra-*\n+    maxClaimsPerNodeParam: $maxClaimsPerNode\n+    useMixins: true\n+  - opcode: createAny\n+    templatePath: templates/deviceclass.yaml\n+  - opcode: createAny\n+    templatePath: templates/resourceclaim.yaml\n+    countParam: $initClaims\n+    namespace: init\n+  - opcode: allocResourceClaims\n+    namespace: init\n+  - opcode: createAny\n+    templatePath: templates/resourceclaimtemplate-with-selector.yaml\n+    namespace: test\n+  - opcode: createPods\n+    namespace: test\n+    count: 10\n+    steadyState: true\n+    durationParam: $duration\n+    podTemplatePath: templates/pod-with-claim-template.yaml\n+    collectMetrics: true\n+  workloads:\n+  - name: fast",
    "repo_full_name": "kubernetes/kubernetes",
    "discussion_comments": [
      {
        "comment_id": "2210691719",
        "repo_full_name": "kubernetes/kubernetes",
        "pr_number": 131357,
        "pr_file": "test/integration/scheduler_perf/dra/performance-config.yaml",
        "discussion_id": "2210691719",
        "commented_code": "@@ -541,6 +541,54 @@\n       measurePods: 1\n       duration: 2s\n \n+# SchedulingWithResourceClaimTemplateMixins is a variant of\n+# SchedulingWithResourceClaimTemplate.\n+- name: SteadyStateClusterResourceClaimTemplateResourceSliceMixins\n+  featureGates:\n+    DynamicResourceAllocation: true\n+    DRAPrioritizedList: true\n+    DRAResourceSliceMixins: true\n+  workloadTemplate:\n+  - opcode: createNodes\n+    countParam: $nodesWithoutDRA\n+  - opcode: createNodes\n+    nodeTemplatePath: templates/node-with-dra-test-driver.yaml\n+    countParam: $nodesWithDRA\n+  - opcode: createResourceDriver\n+    driverName: test-driver.cdi.k8s.io\n+    nodes: scheduler-perf-dra-*\n+    maxClaimsPerNodeParam: $maxClaimsPerNode\n+    useMixins: true\n+  - opcode: createAny\n+    templatePath: templates/deviceclass.yaml\n+  - opcode: createAny\n+    templatePath: templates/resourceclaim.yaml\n+    countParam: $initClaims\n+    namespace: init\n+  - opcode: allocResourceClaims\n+    namespace: init\n+  - opcode: createAny\n+    templatePath: templates/resourceclaimtemplate-with-selector.yaml\n+    namespace: test\n+  - opcode: createPods\n+    namespace: test\n+    count: 10\n+    steadyState: true\n+    durationParam: $duration\n+    podTemplatePath: templates/pod-with-claim-template.yaml\n+    collectMetrics: true\n+  workloads:\n+  - name: fast",
        "comment_created_at": "2025-07-16T15:03:15+00:00",
        "comment_author": "pohly",
        "comment_body": "Having a variant which measures performance would be useful. It doesn't need to run in the CI, defining it for manual invocation is sufficient.\r\n\r\nI'm genuinely curious: how do results compare between using and not using mixins?",
        "pr_file_module": null
      },
      {
        "comment_id": "2212081458",
        "repo_full_name": "kubernetes/kubernetes",
        "pr_number": 131357,
        "pr_file": "test/integration/scheduler_perf/dra/performance-config.yaml",
        "discussion_id": "2210691719",
        "commented_code": "@@ -541,6 +541,54 @@\n       measurePods: 1\n       duration: 2s\n \n+# SchedulingWithResourceClaimTemplateMixins is a variant of\n+# SchedulingWithResourceClaimTemplate.\n+- name: SteadyStateClusterResourceClaimTemplateResourceSliceMixins\n+  featureGates:\n+    DynamicResourceAllocation: true\n+    DRAPrioritizedList: true\n+    DRAResourceSliceMixins: true\n+  workloadTemplate:\n+  - opcode: createNodes\n+    countParam: $nodesWithoutDRA\n+  - opcode: createNodes\n+    nodeTemplatePath: templates/node-with-dra-test-driver.yaml\n+    countParam: $nodesWithDRA\n+  - opcode: createResourceDriver\n+    driverName: test-driver.cdi.k8s.io\n+    nodes: scheduler-perf-dra-*\n+    maxClaimsPerNodeParam: $maxClaimsPerNode\n+    useMixins: true\n+  - opcode: createAny\n+    templatePath: templates/deviceclass.yaml\n+  - opcode: createAny\n+    templatePath: templates/resourceclaim.yaml\n+    countParam: $initClaims\n+    namespace: init\n+  - opcode: allocResourceClaims\n+    namespace: init\n+  - opcode: createAny\n+    templatePath: templates/resourceclaimtemplate-with-selector.yaml\n+    namespace: test\n+  - opcode: createPods\n+    namespace: test\n+    count: 10\n+    steadyState: true\n+    durationParam: $duration\n+    podTemplatePath: templates/pod-with-claim-template.yaml\n+    collectMetrics: true\n+  workloads:\n+  - name: fast",
        "comment_created_at": "2025-07-17T03:39:08+00:00",
        "comment_author": "mortent",
        "comment_body": "I added a performance variant and the mixins doesn't seem to have an impact, although the test is more of normal case rather than a situation where we have a lot of mixins with many attributes and capacities.\r\n\r\n```\r\n                                                                                            │      withoutMixins.txt       │                 withMixins.txt                 │\r\n                                                                                            │ SchedulingThroughput/Average │ SchedulingThroughput/Average  vs base          │\r\nPerfScheduling/SteadyStateClusterResourceClaimTemplateResourceSliceMixins/empty_500nodes-64                     143.2 ± 3%                     145.5 ± 4%  ~ (p=0.392 n=10)\r\n\r\n                                                                                            │      withoutMixins.txt      │                withMixins.txt                 │\r\n                                                                                            │ SchedulingThroughput/Perc50 │ SchedulingThroughput/Perc50  vs base          │\r\nPerfScheduling/SteadyStateClusterResourceClaimTemplateResourceSliceMixins/empty_500nodes-64                    143.6 ± 4%                    144.6 ± 4%  ~ (p=0.664 n=10)\r\n\r\n                                                                                            │      withoutMixins.txt      │                withMixins.txt                 │\r\n                                                                                            │ SchedulingThroughput/Perc90 │ SchedulingThroughput/Perc90  vs base          │\r\nPerfScheduling/SteadyStateClusterResourceClaimTemplateResourceSliceMixins/empty_500nodes-64                    160.0 ± 4%                    157.6 ± 3%  ~ (p=0.309 n=10)\r\n\r\n                                                                                            │      withoutMixins.txt      │                withMixins.txt                 │\r\n                                                                                            │ SchedulingThroughput/Perc95 │ SchedulingThroughput/Perc95  vs base          │\r\nPerfScheduling/SteadyStateClusterResourceClaimTemplateResourceSliceMixins/empty_500nodes-64                    160.0 ± 4%                    157.6 ± 3%  ~ (p=0.309 n=10)\r\n\r\n                                                                                            │      withoutMixins.txt      │                withMixins.txt                 │\r\n                                                                                            │ SchedulingThroughput/Perc99 │ SchedulingThroughput/Perc99  vs base          │\r\nPerfScheduling/SteadyStateClusterResourceClaimTemplateResourceSliceMixins/empty_500nodes-64                    160.0 ± 4%                    157.6 ± 3%  ~ (p=0.309 n=10)\r\n\r\n                                                                                            │ withoutMixins.txt │          withMixins.txt           │\r\n                                                                                            │  runtime_seconds  │ runtime_seconds  vs base          │\r\nPerfScheduling/SteadyStateClusterResourceClaimTemplateResourceSliceMixins/empty_500nodes-64          21.89 ± 2%        21.88 ± 1%  ~ (p=0.839 n=10)\r\n```",
        "pr_file_module": null
      }
    ]
  }
]