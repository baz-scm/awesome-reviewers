---
title: Avoid hardcoded configurations
description: Always parameterize values that might vary across different environments
  or users instead of hardcoding them in your code. This applies to API endpoints,
  regions, dimensions, credentials, and other configuration values.
repository: langchain-ai/langchainjs
label: Configurations
language: Typescript
comments_count: 4
repository_stars: 15004
---

Always parameterize values that might vary across different environments or users instead of hardcoding them in your code. This applies to API endpoints, regions, dimensions, credentials, and other configuration values.

When providing fallbacks to environment variables, use nullish coalescing (`??`) to only override missing values rather than replacing all values if any are missing:

```typescript
// ❌ Don't do this
if (!id || !secret || !uri) {
  id = getEnvironmentVariable("OUTLOOK_CLIENT_ID");
  secret = getEnvironmentVariable("OUTLOOK_CLIENT_SECRET");
  uri = getEnvironmentVariable("OUTLOOK_REDIRECT_URI");
}

// ✅ Do this instead
id = id ?? getEnvironmentVariable("OUTLOOK_CLIENT_ID");
secret = secret ?? getEnvironmentVariable("OUTLOOK_CLIENT_SECRET");
uri = uri ?? getEnvironmentVariable("OUTLOOK_REDIRECT_URI");
```

For service defaults, prefer leaving values unset when possible and let the backend/service set the defaults. This prevents issues when service providers change their best practices:

```typescript
// ❌ Don't hardcode dimensions, regions, endpoints, etc.
vectorSearchDimensions: 1536, // Hardcoded to ada-002's size

// ✅ Make these configurable via parameters
vectorSearchDimensions: config.dimensions || embeddings.dimensions,
```

When integrating with SDKs, only pass overridden values and avoid setting unnecessary defaults:

```typescript
// ❌ Don't do this
const app = new FirecrawlApp({ apiKey: this.apiKey, apiUrl: "https://api.firecrawl.dev" });

// ✅ Do this instead
const params = { apiKey: this.apiKey };
if (this.apiUrl !== undefined) {
  params.apiUrl = this.apiUrl;
}
const app = new FirecrawlApp(params);
```


[
  {
    "discussion_id": "1417967601",
    "pr_number": 3465,
    "pr_file": "langchain/src/tools/outlook/authFlowREST.ts",
    "created_at": "2023-12-06T20:54:51+00:00",
    "commented_code": "import * as http from \"http\";\nimport * as url from \"url\";\nimport { AuthFlowBase } from \"./authFlowBase.js\";\nimport { getEnvironmentVariable } from \"../../util/env.js\";\n\ninterface AccessTokenResponse {\n  access_token: string;\n  refresh_token: string;\n}\n\n// this class uses your clientId, clientSecret and redirectUri\n// to get access token and refresh token, if you already have them,\n// you can use AuthFlowToken or AuthFlowRefresh instead\nexport class AuthFlowREST extends AuthFlowBase {\n  private clientSecret: string;\n\n  private redirectUri: string;\n\n  private port: number;\n\n  private pathname: string;\n\n  private refreshToken = \"\";\n\n  constructor({\n    clientId,\n    clientSecret,\n    redirectUri,\n  }: { clientId?: string; clientSecret?: string; redirectUri?: string } = {}) {\n    let id = clientId;\n    let secret = clientSecret;\n    let uri = redirectUri;\n    if (!id || !secret || !uri) {\n      id = getEnvironmentVariable(\"OUTLOOK_CLIENT_ID\");\n      secret = getEnvironmentVariable(\"OUTLOOK_CLIENT_SECRET\");\n      uri = getEnvironmentVariable(\"OUTLOOK_REDIRECT_URI\");\n    }",
    "repo_full_name": "langchain-ai/langchainjs",
    "discussion_comments": [
      {
        "comment_id": "1417967601",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 3465,
        "pr_file": "langchain/src/tools/outlook/authFlowREST.ts",
        "discussion_id": "1417967601",
        "commented_code": "@@ -0,0 +1,205 @@\n+import * as http from \"http\";\n+import * as url from \"url\";\n+import { AuthFlowBase } from \"./authFlowBase.js\";\n+import { getEnvironmentVariable } from \"../../util/env.js\";\n+\n+interface AccessTokenResponse {\n+  access_token: string;\n+  refresh_token: string;\n+}\n+\n+// this class uses your clientId, clientSecret and redirectUri\n+// to get access token and refresh token, if you already have them,\n+// you can use AuthFlowToken or AuthFlowRefresh instead\n+export class AuthFlowREST extends AuthFlowBase {\n+  private clientSecret: string;\n+\n+  private redirectUri: string;\n+\n+  private port: number;\n+\n+  private pathname: string;\n+\n+  private refreshToken = \"\";\n+\n+  constructor({\n+    clientId,\n+    clientSecret,\n+    redirectUri,\n+  }: { clientId?: string; clientSecret?: string; redirectUri?: string } = {}) {\n+    let id = clientId;\n+    let secret = clientSecret;\n+    let uri = redirectUri;\n+    if (!id || !secret || !uri) {\n+      id = getEnvironmentVariable(\"OUTLOOK_CLIENT_ID\");\n+      secret = getEnvironmentVariable(\"OUTLOOK_CLIENT_SECRET\");\n+      uri = getEnvironmentVariable(\"OUTLOOK_REDIRECT_URI\");\n+    }",
        "comment_created_at": "2023-12-06T20:54:51+00:00",
        "comment_author": "bracesproul",
        "comment_body": "We shouldn't override all if one isn't passed, instead lets do something like this:\r\n```suggestion\r\n    let id = clientId;\r\n    let secret = clientSecret;\r\n    let uri = redirectUri;\r\n    if (!id || !secret || !uri) {\r\n      id = id ?? getEnvironmentVariable(\"OUTLOOK_CLIENT_ID\");\r\n      secret = secret ??  getEnvironmentVariable(\"OUTLOOK_CLIENT_SECRET\");\r\n      uri = uri ?? getEnvironmentVariable(\"OUTLOOK_REDIRECT_URI\");\r\n    }\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1456404750",
    "pr_number": 4044,
    "pr_file": "libs/langchain-community/src/vectorstores/azure_aisearch.ts",
    "created_at": "2024-01-17T19:56:38+00:00",
    "commented_code": "import * as uuid from \"uuid\";\nimport {\n  SearchClient,\n  SearchIndexClient,\n  AzureKeyCredential,\n  IndexingResult,\n  SearchIndex,\n} from \"@azure/search-documents\";\nimport {\n  MaxMarginalRelevanceSearchOptions,\n  VectorStore,\n} from \"@langchain/core/vectorstores\";\nimport type { EmbeddingsInterface } from \"@langchain/core/embeddings\";\nimport { Document } from \"@langchain/core/documents\";\nimport { maximalMarginalRelevance } from \"@langchain/core/utils/math\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\n\n/**\n * Azure AI Search query type.\n */\nexport const AzureAISearchQueryType = {\n  /** Vector search. */\n  Similarity: \"similarity\",\n  /** Hybrid full text and vector search. */\n  SimilarityHybrid: \"similarity_hybrid\",\n  /** Hybrid full text and vector search with semantic ranking. */\n  SemanticHybrid: \"semantic_hybrid\",\n} as const;\n\n/**\n * Azure AI Search query type.\n */\nexport type AzureAISearchQueryType =\n  (typeof AzureAISearchQueryType)[keyof typeof AzureAISearchQueryType];\n\n/**\n * Azure AI Search settings.\n */\nexport interface AzureAISearchQueryOptions {\n  readonly type: AzureAISearchQueryType;\n  readonly semanticConfigurationName?: string;\n}\n\n/**\n * Configuration options for the `AzureAISearchStore` constructor.\n */\nexport interface AzureAISearchConfig {\n  readonly client?: SearchClient<AzureAISearchDocument>;\n  readonly indexName?: string;\n  readonly endpoint?: string;\n  readonly key?: string;\n  readonly search: AzureAISearchQueryOptions;\n  /**\n   * The amount of documents to chunk by when adding vectors.\n   * @default 100\n   */\n  readonly chunkSize?: number;\n  /**\n   * The amount of documents to embed at once when adding documents.\n   * Note that some providers like Azure OpenAI can only embed 16 documents\n   * at a time.\n   * @default 16\n   */\n  readonly embeddingBatchSize?: number;\n}\n\n/**\n * Azure AI Search options metadata schema.\n * If yout want to add custom data, use the attributes property.\n */\nexport type AzureAISearchDocumentMetadata = {\n  source: string;\n  attributes?: Array<{ key: string; value: string }>;\n};\n\n/**\n * Azure AI Search indexed document.\n */\nexport type AzureAISearchDocument = {\n  id: string;\n  content: string;\n  content_vector: number[];\n  metadata: AzureAISearchDocumentMetadata;\n};\n\n/**\n * Azure AI Search options for adding documents.\n */\nexport type AzureAISearchAddDocumentsOptions = {\n  ids?: string[];\n};\n\nconst DEFAULT_FIELD_ID = \"id\";\nconst DEFAULT_FIELD_CONTENT = \"content\";\nconst DEFAULT_FIELD_CONTENT_VECTOR = \"content_vector\";\nconst DEFAULT_FIELD_METADATA = \"metadata\";\nconst DEFAULT_FIELD_METADATA_SOURCE = \"source\";\nconst DEFAULT_FIELD_METADATA_ATTRS = \"attributes\";\n\n/**\n * Azure AI Search vector store.\n * To use this, you should have:\n * - the `@azure/search-documents` NPM package installed\n * - an endpoint and key to the Azure AI Search instance\n *\n * If you directly provide a `SearchClient` instance, you need to ensure that\n * an index has been created. When using and endpoint and key, the index will\n * be created automatically if it does not exist.\n */\nexport class AzureAISearchVectorStore extends VectorStore {\n  declare FilterType: string;\n\n  get lc_secrets(): { [key: string]: string } {\n    return {\n      endpoint: \"AZURE_AISEARCH_ENDPOINT\",\n      key: \"AZURE_AISEARCH_KEY\",\n    };\n  }\n\n  _vectorstoreType(): string {\n    return \"azure_aisearch\";\n  }\n\n  private readonly initPromise: Promise<void>;\n\n  private readonly client: SearchClient<AzureAISearchDocument>;\n\n  private readonly indexName: string;\n\n  private readonly chunkSize: number;\n\n  private readonly embeddingBatchSize: number;\n\n  private readonly options: AzureAISearchQueryOptions;\n\n  constructor(embeddings: EmbeddingsInterface, config: AzureAISearchConfig) {\n    super(embeddings, config);\n\n    const endpoint =\n      config.endpoint ?? getEnvironmentVariable(\"AZURE_AISEARCH_ENDPOINT\");\n    const key = config.key ?? getEnvironmentVariable(\"AZURE_AISEARCH_KEY\");\n\n    if (!config.client && !endpoint && !key) {\n      throw new Error(\n        \"Azure AI Search client or connection string must be set.\"\n      );\n    }\n\n    this.indexName = config.indexName ?? \"vectorsearch\";\n    this.chunkSize = config.chunkSize ?? 100;\n    this.embeddingBatchSize = config.embeddingBatchSize ?? 16;\n\n    if (!config.client) {\n      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n      const credential = new AzureKeyCredential(key!);\n      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n      this.client = new SearchClient(endpoint!, this.indexName, credential);\n      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n      const indexClient = new SearchIndexClient(endpoint!, credential);\n\n      // Start initialization, but don't wait for it to finish here\n      this.initPromise = this.ensureIndexExists(indexClient).catch((error) => {\n        console.error(\n          \"Error during Azure AI Search index initialization:\",\n          error\n        );\n      });\n    } else {\n      this.client = config.client;\n    }\n\n    this.options = config.search;\n    this.embeddings = embeddings;\n  }\n\n  /**\n   * Removes specified documents from the AzureAISearchVectorStore using a filter.\n   * @param filter OData filter to find documents to delete.\n   * @returns A promise that resolves when the documents have been removed.\n   */\n  async deleteMany(filter: string): Promise<IndexingResult[]> {\n    const { results } = await this.client.search(\"*\", {\n      filter,\n    });\n\n    const ids: string[] = [];\n    for await (const item of results) {\n      ids.push(item.document.id);\n    }\n\n    const { results: deleteResults } = await this.client.deleteDocuments(\n      DEFAULT_FIELD_ID,\n      ids\n    );\n    return deleteResults;\n  }\n\n  /**\n   * Removes specified documents from the AzureAISearchVectorStore.\n   * @param ids IDs of the documents to be removed.\n   * @returns A promise that resolves when the documents have been removed.\n   */\n  async deleteById(ids: string | string[]): Promise<IndexingResult[]> {\n    await this.initPromise;\n    const { results } = await this.client.deleteDocuments(\n      DEFAULT_FIELD_ID,\n      Array.isArray(ids) ? ids : [ids]\n    );\n    return results;\n  }\n\n  /**\n   * Adds documents to the AzureAISearchVectorStore.\n   * Documents are chunked into batches of size `embeddingBatchSize` then\n   * embedded and added to the AzureAISearchVectorStore.\n   * @param documents The documents to add.\n   * @param options Options for adding documents.\n   * @returns A promise that resolves to the ids of the added documents.\n   */\n  async addDocuments(\n    documents: Document[],\n    options?: AzureAISearchAddDocumentsOptions\n  ) {\n    const texts = documents.map(({ pageContent }) => pageContent);\n    const results: string[] = [];\n\n    for (let i = 0; i < texts.length; i += this.embeddingBatchSize) {\n      const batch = texts.slice(i, i + this.embeddingBatchSize);\n      const docsBatch = documents.slice(i, i + this.embeddingBatchSize);\n      const batchEmbeddings: number[][] = await this.embeddings.embedDocuments(\n        batch\n      );\n      const batchResult = await this.addVectors(\n        batchEmbeddings,\n        docsBatch,\n        options\n      );\n\n      results.push(...batchResult);\n    }\n\n    return results;\n  }\n\n  /**\n   * Adds vectors to the AzureAISearchVectorStore.\n   * @param vectors Vectors to be added.\n   * @param documents Corresponding documents to be added.\n   * @param options Options for adding documents.\n   * @returns A promise that resolves to the ids of the added documents.\n   */\n  async addVectors(\n    vectors: number[][],\n    documents: Document[],\n    options?: AzureAISearchAddDocumentsOptions\n  ): Promise<string[]> {\n    const ids = options?.ids ?? documents.map(() => uuid.v4());\n    const entities: AzureAISearchDocument[] = documents.map((doc, idx) => ({\n      id: ids[idx],\n      content: doc.pageContent,\n      content_vector: vectors[idx],\n      metadata: {\n        source: doc.metadata?.source,\n        attributes: doc.metadata?.attributes ?? [],\n      },\n    }));\n\n    await this.initPromise;\n    for (let i = 0; i < entities.length; i += this.chunkSize) {\n      const chunk = entities.slice(i, i + this.chunkSize);\n      await this.client.uploadDocuments(chunk, { throwOnAnyFailure: true });\n    }\n\n    return ids;\n  }\n\n  /**\n   * Performs a similarity search using query type specified in configuration.\n   * @param query Query text for the similarity search.\n   * @param k=4 Number of nearest neighbors to return.\n   * @param filter Optional OData filter for the documents.\n   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n   */\n  async similaritySearch(\n    query: string,\n    k = 4,\n    filter: this[\"FilterType\"] | undefined = undefined\n  ): Promise<Document[]> {\n    const results = await this.similaritySearchWithScore(query, k, filter);\n\n    return results.map((result) => result[0]);\n  }\n\n  /**\n   * Performs a similarity search using query type specified in configuration.\n   * @param query Query text for the similarity search.\n   * @param k=4 Number of nearest neighbors to return.\n   * @param filter Optional OData filter for the documents.\n   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n   */\n  async similaritySearchWithScore(\n    query: string,\n    k = 4,\n    filter: this[\"FilterType\"] | undefined = undefined\n  ): Promise<[Document, number][]> {\n    const searchType = this.options.type;\n\n    if (searchType === AzureAISearchQueryType.Similarity) {\n      return this.similaritySearchVectorWithScore(\n        await this.embeddings.embedQuery(query),\n        k,\n        filter\n      );\n    } else if (searchType === AzureAISearchQueryType.SimilarityHybrid) {\n      return this.hybridSearchVectorWithScore(\n        query,\n        await this.embeddings.embedQuery(query),\n        k,\n        filter\n      );\n    } else if (searchType === AzureAISearchQueryType.SemanticHybrid) {\n      return this.semanticHybridSearchVectorWithScore(\n        query,\n        await this.embeddings.embedQuery(query),\n        k,\n        filter\n      );\n    }\n\n    throw new Error(`Unrecognized search type '${searchType}'`);\n  }\n\n  /**\n   * Performs a hybrid search using query text.\n   * @param query Query text for the similarity search.\n   * @param queryVector Query vector for the similarity search.\n   *    If not provided, the query text will be embedded.\n   * @param k=4 Number of nearest neighbors to return.\n   * @param filter Optional OData filter for the documents.\n   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n   */\n  async hybridSearchVectorWithScore(\n    query: string,\n    queryVector?: number[],\n    k = 4,\n    filter: string | undefined = undefined\n  ): Promise<[Document, number][]> {\n    const vector = queryVector ?? (await this.embeddings.embedQuery(query));\n\n    await this.initPromise;\n    const { results } = await this.client.search(query, {\n      vectorSearchOptions: {\n        queries: [\n          {\n            kind: \"vector\",\n            vector,\n            kNearestNeighborsCount: k,\n            fields: [DEFAULT_FIELD_CONTENT_VECTOR],\n          },\n        ],\n      },\n      filter,\n      top: k,\n    });\n\n    const docsWithScore: [Document, number][] = [];\n\n    for await (const item of results) {\n      const document = new Document<\n        AzureAISearchDocumentMetadata & { embedding: number[] }\n      >({\n        pageContent: item.document[DEFAULT_FIELD_CONTENT],\n        metadata: {\n          ...item.document[DEFAULT_FIELD_METADATA],\n          embedding: item.document[DEFAULT_FIELD_CONTENT_VECTOR],\n        },\n      });\n      docsWithScore.push([document, item.score]);\n    }\n\n    return docsWithScore;\n  }\n\n  /**\n   * Performs a hybrid search with semantic reranker using query text.\n   * @param query Query text for the similarity search.\n   * @param queryVector Query vector for the similarity search.\n   *    If not provided, the query text will be embedded.\n   * @param k=4 Number of nearest neighbors to return.\n   * @param filter Optional OData filter for the documents.\n   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n   */\n  async semanticHybridSearchVectorWithScore(\n    query: string,\n    queryVector?: number[],\n    k = 4,\n    filter: string | undefined = undefined\n  ): Promise<[Document, number][]> {\n    const vector = queryVector ?? (await this.embeddings.embedQuery(query));\n\n    await this.initPromise;\n    const { results } = await this.client.search(query, {\n      vectorSearchOptions: {\n        queries: [\n          {\n            kind: \"vector\",\n            vector,\n            kNearestNeighborsCount: k,\n            fields: [DEFAULT_FIELD_CONTENT_VECTOR],\n          },\n        ],\n      },\n      filter,\n      top: k,\n      queryType: \"semantic\",\n      semanticSearchOptions: {\n        configurationName: \"semantic-search-config\",\n        captions: {\n          captionType: \"extractive\",\n        },\n        answers: {\n          answerType: \"extractive\",\n        },\n      },\n    });\n\n    const docsWithScore: [Document, number][] = [];\n\n    for await (const item of results) {\n      const document = new Document<\n        AzureAISearchDocumentMetadata & { embedding: number[] }\n      >({\n        pageContent: item.document[DEFAULT_FIELD_CONTENT],\n        metadata: {\n          ...item.document[DEFAULT_FIELD_METADATA],\n          embedding: item.document[DEFAULT_FIELD_CONTENT_VECTOR],\n        },\n      });\n      docsWithScore.push([document, item.score]);\n    }\n\n    return docsWithScore;\n  }\n\n  /**\n   * Performs a similarity search on the vectors stored in the collection.\n   * @param queryVector Query vector for the similarity search.\n   * @param k=4 Number of nearest neighbors to return.\n   * @param filter string OData filter for the documents.\n   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n   */\n  async similaritySearchVectorWithScore(\n    query: number[],\n    k: number,\n    filter?: string\n  ): Promise<[Document, number][]> {\n    await this.initPromise;\n\n    const { results } = await this.client.search(\"*\", {\n      vectorSearchOptions: {\n        queries: [\n          {\n            kind: \"vector\",\n            vector: query,\n            kNearestNeighborsCount: k,\n            fields: [DEFAULT_FIELD_CONTENT_VECTOR],\n          },\n        ],\n      },\n      filter,\n    });\n\n    const docsWithScore: [Document, number][] = [];\n\n    for await (const item of results) {\n      const document = new Document<\n        AzureAISearchDocumentMetadata & { embedding: number[] }\n      >({\n        pageContent: item.document[DEFAULT_FIELD_CONTENT],\n        metadata: {\n          ...item.document[DEFAULT_FIELD_METADATA],\n          embedding: item.document[DEFAULT_FIELD_CONTENT_VECTOR],\n        },\n      });\n      docsWithScore.push([document, item.score]);\n    }\n\n    return docsWithScore;\n  }\n\n  /**\n   * Return documents selected using the maximal marginal relevance.\n   * Maximal marginal relevance optimizes for similarity to the query AND\n   * diversity among selected documents.\n   * @param query Text to look up documents similar to.\n   * @param options.k Number of documents to return.\n   * @param options.fetchK=20 Number of documents to fetch before passing to\n   *     the MMR algorithm.\n   * @param options.lambda=0.5 Number between 0 and 1 that determines the\n   *     degree of diversity among the results, where 0 corresponds to maximum\n   *     diversity and 1 to minimum diversity.\n   * @returns List of documents selected by maximal marginal relevance.\n   */\n  async maxMarginalRelevanceSearch(\n    query: string,\n    options: MaxMarginalRelevanceSearchOptions<this[\"FilterType\"]>\n  ): Promise<Document[]> {\n    const { k, fetchK = 20, lambda = 0.5 } = options;\n\n    const queryEmbedding = await this.embeddings.embedQuery(query);\n    const docs = await this.similaritySearchVectorWithScore(\n      queryEmbedding,\n      fetchK\n    );\n    const embeddingList = docs.map((doc) => doc[0].metadata.embedding);\n\n    // Re-rank the results using MMR\n    const mmrIndexes = maximalMarginalRelevance(\n      queryEmbedding,\n      embeddingList,\n      lambda,\n      k\n    );\n\n    const mmrDocs = mmrIndexes.map((index) => docs[index][0]);\n    return mmrDocs;\n  }\n\n  /**\n   * Ensures that an index exists on the AzureAISearchVectorStore.\n   * @param indexClient The Azure AI Search index client.\n   * @returns A promise that resolves when the AzureAISearchVectorStore index has been initialized.\n   * @protected\n   */\n  protected async ensureIndexExists(\n    indexClient: SearchIndexClient\n  ): Promise<void> {\n    try {\n      await indexClient.getIndex(this.indexName);\n    } catch (e) {\n      // Index does not exists, create it\n      const searchIndex = this.createSearchIndexDefinition(this.indexName);\n      await indexClient.createIndex(searchIndex);\n    }\n  }\n\n  /**\n   * Prepares the search index definition for Azure AI Search.\n   * @param indexName The name of the index.\n   * @returns The SearchIndex object.\n   * @protected\n   */\n  protected createSearchIndexDefinition(indexName: string): SearchIndex {\n    return {\n      name: indexName,\n      vectorSearch: {\n        algorithms: [\n          {\n            name: \"vector-search-algorithm\",\n            kind: \"hnsw\",\n            parameters: {\n              m: 4,\n              efSearch: 500,\n              metric: \"cosine\",\n              efConstruction: 400,\n            },\n          },\n        ],\n        profiles: [\n          {\n            name: \"vector-search-profile\",\n            algorithmConfigurationName: \"vector-search-algorithm\",\n          },\n        ],\n      },\n      semanticSearch: {\n        defaultConfigurationName: \"semantic-search-config\",\n        configurations: [\n          {\n            name: \"semantic-search-config\",\n            prioritizedFields: {\n              contentFields: [\n                {\n                  name: DEFAULT_FIELD_CONTENT,\n                },\n              ],\n              keywordsFields: [\n                {\n                  name: DEFAULT_FIELD_CONTENT,\n                },\n              ],\n            },\n          },\n        ],\n      },\n      fields: [\n        {\n          name: DEFAULT_FIELD_ID,\n          filterable: true,\n          key: true,\n          type: \"Edm.String\",\n        },\n        {\n          name: DEFAULT_FIELD_CONTENT,\n          searchable: true,\n          filterable: true,\n          type: \"Edm.String\",\n        },\n        {\n          name: DEFAULT_FIELD_CONTENT_VECTOR,\n          searchable: true,\n          type: \"Collection(Edm.Single)\",\n          vectorSearchDimensions: 1536,",
    "repo_full_name": "langchain-ai/langchainjs",
    "discussion_comments": [
      {
        "comment_id": "1456404750",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 4044,
        "pr_file": "libs/langchain-community/src/vectorstores/azure_aisearch.ts",
        "discussion_id": "1456404750",
        "commented_code": "@@ -0,0 +1,694 @@\n+import * as uuid from \"uuid\";\n+import {\n+  SearchClient,\n+  SearchIndexClient,\n+  AzureKeyCredential,\n+  IndexingResult,\n+  SearchIndex,\n+} from \"@azure/search-documents\";\n+import {\n+  MaxMarginalRelevanceSearchOptions,\n+  VectorStore,\n+} from \"@langchain/core/vectorstores\";\n+import type { EmbeddingsInterface } from \"@langchain/core/embeddings\";\n+import { Document } from \"@langchain/core/documents\";\n+import { maximalMarginalRelevance } from \"@langchain/core/utils/math\";\n+import { getEnvironmentVariable } from \"@langchain/core/utils/env\";\n+\n+/**\n+ * Azure AI Search query type.\n+ */\n+export const AzureAISearchQueryType = {\n+  /** Vector search. */\n+  Similarity: \"similarity\",\n+  /** Hybrid full text and vector search. */\n+  SimilarityHybrid: \"similarity_hybrid\",\n+  /** Hybrid full text and vector search with semantic ranking. */\n+  SemanticHybrid: \"semantic_hybrid\",\n+} as const;\n+\n+/**\n+ * Azure AI Search query type.\n+ */\n+export type AzureAISearchQueryType =\n+  (typeof AzureAISearchQueryType)[keyof typeof AzureAISearchQueryType];\n+\n+/**\n+ * Azure AI Search settings.\n+ */\n+export interface AzureAISearchQueryOptions {\n+  readonly type: AzureAISearchQueryType;\n+  readonly semanticConfigurationName?: string;\n+}\n+\n+/**\n+ * Configuration options for the `AzureAISearchStore` constructor.\n+ */\n+export interface AzureAISearchConfig {\n+  readonly client?: SearchClient<AzureAISearchDocument>;\n+  readonly indexName?: string;\n+  readonly endpoint?: string;\n+  readonly key?: string;\n+  readonly search: AzureAISearchQueryOptions;\n+  /**\n+   * The amount of documents to chunk by when adding vectors.\n+   * @default 100\n+   */\n+  readonly chunkSize?: number;\n+  /**\n+   * The amount of documents to embed at once when adding documents.\n+   * Note that some providers like Azure OpenAI can only embed 16 documents\n+   * at a time.\n+   * @default 16\n+   */\n+  readonly embeddingBatchSize?: number;\n+}\n+\n+/**\n+ * Azure AI Search options metadata schema.\n+ * If yout want to add custom data, use the attributes property.\n+ */\n+export type AzureAISearchDocumentMetadata = {\n+  source: string;\n+  attributes?: Array<{ key: string; value: string }>;\n+};\n+\n+/**\n+ * Azure AI Search indexed document.\n+ */\n+export type AzureAISearchDocument = {\n+  id: string;\n+  content: string;\n+  content_vector: number[];\n+  metadata: AzureAISearchDocumentMetadata;\n+};\n+\n+/**\n+ * Azure AI Search options for adding documents.\n+ */\n+export type AzureAISearchAddDocumentsOptions = {\n+  ids?: string[];\n+};\n+\n+const DEFAULT_FIELD_ID = \"id\";\n+const DEFAULT_FIELD_CONTENT = \"content\";\n+const DEFAULT_FIELD_CONTENT_VECTOR = \"content_vector\";\n+const DEFAULT_FIELD_METADATA = \"metadata\";\n+const DEFAULT_FIELD_METADATA_SOURCE = \"source\";\n+const DEFAULT_FIELD_METADATA_ATTRS = \"attributes\";\n+\n+/**\n+ * Azure AI Search vector store.\n+ * To use this, you should have:\n+ * - the `@azure/search-documents` NPM package installed\n+ * - an endpoint and key to the Azure AI Search instance\n+ *\n+ * If you directly provide a `SearchClient` instance, you need to ensure that\n+ * an index has been created. When using and endpoint and key, the index will\n+ * be created automatically if it does not exist.\n+ */\n+export class AzureAISearchVectorStore extends VectorStore {\n+  declare FilterType: string;\n+\n+  get lc_secrets(): { [key: string]: string } {\n+    return {\n+      endpoint: \"AZURE_AISEARCH_ENDPOINT\",\n+      key: \"AZURE_AISEARCH_KEY\",\n+    };\n+  }\n+\n+  _vectorstoreType(): string {\n+    return \"azure_aisearch\";\n+  }\n+\n+  private readonly initPromise: Promise<void>;\n+\n+  private readonly client: SearchClient<AzureAISearchDocument>;\n+\n+  private readonly indexName: string;\n+\n+  private readonly chunkSize: number;\n+\n+  private readonly embeddingBatchSize: number;\n+\n+  private readonly options: AzureAISearchQueryOptions;\n+\n+  constructor(embeddings: EmbeddingsInterface, config: AzureAISearchConfig) {\n+    super(embeddings, config);\n+\n+    const endpoint =\n+      config.endpoint ?? getEnvironmentVariable(\"AZURE_AISEARCH_ENDPOINT\");\n+    const key = config.key ?? getEnvironmentVariable(\"AZURE_AISEARCH_KEY\");\n+\n+    if (!config.client && !endpoint && !key) {\n+      throw new Error(\n+        \"Azure AI Search client or connection string must be set.\"\n+      );\n+    }\n+\n+    this.indexName = config.indexName ?? \"vectorsearch\";\n+    this.chunkSize = config.chunkSize ?? 100;\n+    this.embeddingBatchSize = config.embeddingBatchSize ?? 16;\n+\n+    if (!config.client) {\n+      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n+      const credential = new AzureKeyCredential(key!);\n+      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n+      this.client = new SearchClient(endpoint!, this.indexName, credential);\n+      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n+      const indexClient = new SearchIndexClient(endpoint!, credential);\n+\n+      // Start initialization, but don't wait for it to finish here\n+      this.initPromise = this.ensureIndexExists(indexClient).catch((error) => {\n+        console.error(\n+          \"Error during Azure AI Search index initialization:\",\n+          error\n+        );\n+      });\n+    } else {\n+      this.client = config.client;\n+    }\n+\n+    this.options = config.search;\n+    this.embeddings = embeddings;\n+  }\n+\n+  /**\n+   * Removes specified documents from the AzureAISearchVectorStore using a filter.\n+   * @param filter OData filter to find documents to delete.\n+   * @returns A promise that resolves when the documents have been removed.\n+   */\n+  async deleteMany(filter: string): Promise<IndexingResult[]> {\n+    const { results } = await this.client.search(\"*\", {\n+      filter,\n+    });\n+\n+    const ids: string[] = [];\n+    for await (const item of results) {\n+      ids.push(item.document.id);\n+    }\n+\n+    const { results: deleteResults } = await this.client.deleteDocuments(\n+      DEFAULT_FIELD_ID,\n+      ids\n+    );\n+    return deleteResults;\n+  }\n+\n+  /**\n+   * Removes specified documents from the AzureAISearchVectorStore.\n+   * @param ids IDs of the documents to be removed.\n+   * @returns A promise that resolves when the documents have been removed.\n+   */\n+  async deleteById(ids: string | string[]): Promise<IndexingResult[]> {\n+    await this.initPromise;\n+    const { results } = await this.client.deleteDocuments(\n+      DEFAULT_FIELD_ID,\n+      Array.isArray(ids) ? ids : [ids]\n+    );\n+    return results;\n+  }\n+\n+  /**\n+   * Adds documents to the AzureAISearchVectorStore.\n+   * Documents are chunked into batches of size `embeddingBatchSize` then\n+   * embedded and added to the AzureAISearchVectorStore.\n+   * @param documents The documents to add.\n+   * @param options Options for adding documents.\n+   * @returns A promise that resolves to the ids of the added documents.\n+   */\n+  async addDocuments(\n+    documents: Document[],\n+    options?: AzureAISearchAddDocumentsOptions\n+  ) {\n+    const texts = documents.map(({ pageContent }) => pageContent);\n+    const results: string[] = [];\n+\n+    for (let i = 0; i < texts.length; i += this.embeddingBatchSize) {\n+      const batch = texts.slice(i, i + this.embeddingBatchSize);\n+      const docsBatch = documents.slice(i, i + this.embeddingBatchSize);\n+      const batchEmbeddings: number[][] = await this.embeddings.embedDocuments(\n+        batch\n+      );\n+      const batchResult = await this.addVectors(\n+        batchEmbeddings,\n+        docsBatch,\n+        options\n+      );\n+\n+      results.push(...batchResult);\n+    }\n+\n+    return results;\n+  }\n+\n+  /**\n+   * Adds vectors to the AzureAISearchVectorStore.\n+   * @param vectors Vectors to be added.\n+   * @param documents Corresponding documents to be added.\n+   * @param options Options for adding documents.\n+   * @returns A promise that resolves to the ids of the added documents.\n+   */\n+  async addVectors(\n+    vectors: number[][],\n+    documents: Document[],\n+    options?: AzureAISearchAddDocumentsOptions\n+  ): Promise<string[]> {\n+    const ids = options?.ids ?? documents.map(() => uuid.v4());\n+    const entities: AzureAISearchDocument[] = documents.map((doc, idx) => ({\n+      id: ids[idx],\n+      content: doc.pageContent,\n+      content_vector: vectors[idx],\n+      metadata: {\n+        source: doc.metadata?.source,\n+        attributes: doc.metadata?.attributes ?? [],\n+      },\n+    }));\n+\n+    await this.initPromise;\n+    for (let i = 0; i < entities.length; i += this.chunkSize) {\n+      const chunk = entities.slice(i, i + this.chunkSize);\n+      await this.client.uploadDocuments(chunk, { throwOnAnyFailure: true });\n+    }\n+\n+    return ids;\n+  }\n+\n+  /**\n+   * Performs a similarity search using query type specified in configuration.\n+   * @param query Query text for the similarity search.\n+   * @param k=4 Number of nearest neighbors to return.\n+   * @param filter Optional OData filter for the documents.\n+   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n+   */\n+  async similaritySearch(\n+    query: string,\n+    k = 4,\n+    filter: this[\"FilterType\"] | undefined = undefined\n+  ): Promise<Document[]> {\n+    const results = await this.similaritySearchWithScore(query, k, filter);\n+\n+    return results.map((result) => result[0]);\n+  }\n+\n+  /**\n+   * Performs a similarity search using query type specified in configuration.\n+   * @param query Query text for the similarity search.\n+   * @param k=4 Number of nearest neighbors to return.\n+   * @param filter Optional OData filter for the documents.\n+   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n+   */\n+  async similaritySearchWithScore(\n+    query: string,\n+    k = 4,\n+    filter: this[\"FilterType\"] | undefined = undefined\n+  ): Promise<[Document, number][]> {\n+    const searchType = this.options.type;\n+\n+    if (searchType === AzureAISearchQueryType.Similarity) {\n+      return this.similaritySearchVectorWithScore(\n+        await this.embeddings.embedQuery(query),\n+        k,\n+        filter\n+      );\n+    } else if (searchType === AzureAISearchQueryType.SimilarityHybrid) {\n+      return this.hybridSearchVectorWithScore(\n+        query,\n+        await this.embeddings.embedQuery(query),\n+        k,\n+        filter\n+      );\n+    } else if (searchType === AzureAISearchQueryType.SemanticHybrid) {\n+      return this.semanticHybridSearchVectorWithScore(\n+        query,\n+        await this.embeddings.embedQuery(query),\n+        k,\n+        filter\n+      );\n+    }\n+\n+    throw new Error(`Unrecognized search type '${searchType}'`);\n+  }\n+\n+  /**\n+   * Performs a hybrid search using query text.\n+   * @param query Query text for the similarity search.\n+   * @param queryVector Query vector for the similarity search.\n+   *    If not provided, the query text will be embedded.\n+   * @param k=4 Number of nearest neighbors to return.\n+   * @param filter Optional OData filter for the documents.\n+   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n+   */\n+  async hybridSearchVectorWithScore(\n+    query: string,\n+    queryVector?: number[],\n+    k = 4,\n+    filter: string | undefined = undefined\n+  ): Promise<[Document, number][]> {\n+    const vector = queryVector ?? (await this.embeddings.embedQuery(query));\n+\n+    await this.initPromise;\n+    const { results } = await this.client.search(query, {\n+      vectorSearchOptions: {\n+        queries: [\n+          {\n+            kind: \"vector\",\n+            vector,\n+            kNearestNeighborsCount: k,\n+            fields: [DEFAULT_FIELD_CONTENT_VECTOR],\n+          },\n+        ],\n+      },\n+      filter,\n+      top: k,\n+    });\n+\n+    const docsWithScore: [Document, number][] = [];\n+\n+    for await (const item of results) {\n+      const document = new Document<\n+        AzureAISearchDocumentMetadata & { embedding: number[] }\n+      >({\n+        pageContent: item.document[DEFAULT_FIELD_CONTENT],\n+        metadata: {\n+          ...item.document[DEFAULT_FIELD_METADATA],\n+          embedding: item.document[DEFAULT_FIELD_CONTENT_VECTOR],\n+        },\n+      });\n+      docsWithScore.push([document, item.score]);\n+    }\n+\n+    return docsWithScore;\n+  }\n+\n+  /**\n+   * Performs a hybrid search with semantic reranker using query text.\n+   * @param query Query text for the similarity search.\n+   * @param queryVector Query vector for the similarity search.\n+   *    If not provided, the query text will be embedded.\n+   * @param k=4 Number of nearest neighbors to return.\n+   * @param filter Optional OData filter for the documents.\n+   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n+   */\n+  async semanticHybridSearchVectorWithScore(\n+    query: string,\n+    queryVector?: number[],\n+    k = 4,\n+    filter: string | undefined = undefined\n+  ): Promise<[Document, number][]> {\n+    const vector = queryVector ?? (await this.embeddings.embedQuery(query));\n+\n+    await this.initPromise;\n+    const { results } = await this.client.search(query, {\n+      vectorSearchOptions: {\n+        queries: [\n+          {\n+            kind: \"vector\",\n+            vector,\n+            kNearestNeighborsCount: k,\n+            fields: [DEFAULT_FIELD_CONTENT_VECTOR],\n+          },\n+        ],\n+      },\n+      filter,\n+      top: k,\n+      queryType: \"semantic\",\n+      semanticSearchOptions: {\n+        configurationName: \"semantic-search-config\",\n+        captions: {\n+          captionType: \"extractive\",\n+        },\n+        answers: {\n+          answerType: \"extractive\",\n+        },\n+      },\n+    });\n+\n+    const docsWithScore: [Document, number][] = [];\n+\n+    for await (const item of results) {\n+      const document = new Document<\n+        AzureAISearchDocumentMetadata & { embedding: number[] }\n+      >({\n+        pageContent: item.document[DEFAULT_FIELD_CONTENT],\n+        metadata: {\n+          ...item.document[DEFAULT_FIELD_METADATA],\n+          embedding: item.document[DEFAULT_FIELD_CONTENT_VECTOR],\n+        },\n+      });\n+      docsWithScore.push([document, item.score]);\n+    }\n+\n+    return docsWithScore;\n+  }\n+\n+  /**\n+   * Performs a similarity search on the vectors stored in the collection.\n+   * @param queryVector Query vector for the similarity search.\n+   * @param k=4 Number of nearest neighbors to return.\n+   * @param filter string OData filter for the documents.\n+   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n+   */\n+  async similaritySearchVectorWithScore(\n+    query: number[],\n+    k: number,\n+    filter?: string\n+  ): Promise<[Document, number][]> {\n+    await this.initPromise;\n+\n+    const { results } = await this.client.search(\"*\", {\n+      vectorSearchOptions: {\n+        queries: [\n+          {\n+            kind: \"vector\",\n+            vector: query,\n+            kNearestNeighborsCount: k,\n+            fields: [DEFAULT_FIELD_CONTENT_VECTOR],\n+          },\n+        ],\n+      },\n+      filter,\n+    });\n+\n+    const docsWithScore: [Document, number][] = [];\n+\n+    for await (const item of results) {\n+      const document = new Document<\n+        AzureAISearchDocumentMetadata & { embedding: number[] }\n+      >({\n+        pageContent: item.document[DEFAULT_FIELD_CONTENT],\n+        metadata: {\n+          ...item.document[DEFAULT_FIELD_METADATA],\n+          embedding: item.document[DEFAULT_FIELD_CONTENT_VECTOR],\n+        },\n+      });\n+      docsWithScore.push([document, item.score]);\n+    }\n+\n+    return docsWithScore;\n+  }\n+\n+  /**\n+   * Return documents selected using the maximal marginal relevance.\n+   * Maximal marginal relevance optimizes for similarity to the query AND\n+   * diversity among selected documents.\n+   * @param query Text to look up documents similar to.\n+   * @param options.k Number of documents to return.\n+   * @param options.fetchK=20 Number of documents to fetch before passing to\n+   *     the MMR algorithm.\n+   * @param options.lambda=0.5 Number between 0 and 1 that determines the\n+   *     degree of diversity among the results, where 0 corresponds to maximum\n+   *     diversity and 1 to minimum diversity.\n+   * @returns List of documents selected by maximal marginal relevance.\n+   */\n+  async maxMarginalRelevanceSearch(\n+    query: string,\n+    options: MaxMarginalRelevanceSearchOptions<this[\"FilterType\"]>\n+  ): Promise<Document[]> {\n+    const { k, fetchK = 20, lambda = 0.5 } = options;\n+\n+    const queryEmbedding = await this.embeddings.embedQuery(query);\n+    const docs = await this.similaritySearchVectorWithScore(\n+      queryEmbedding,\n+      fetchK\n+    );\n+    const embeddingList = docs.map((doc) => doc[0].metadata.embedding);\n+\n+    // Re-rank the results using MMR\n+    const mmrIndexes = maximalMarginalRelevance(\n+      queryEmbedding,\n+      embeddingList,\n+      lambda,\n+      k\n+    );\n+\n+    const mmrDocs = mmrIndexes.map((index) => docs[index][0]);\n+    return mmrDocs;\n+  }\n+\n+  /**\n+   * Ensures that an index exists on the AzureAISearchVectorStore.\n+   * @param indexClient The Azure AI Search index client.\n+   * @returns A promise that resolves when the AzureAISearchVectorStore index has been initialized.\n+   * @protected\n+   */\n+  protected async ensureIndexExists(\n+    indexClient: SearchIndexClient\n+  ): Promise<void> {\n+    try {\n+      await indexClient.getIndex(this.indexName);\n+    } catch (e) {\n+      // Index does not exists, create it\n+      const searchIndex = this.createSearchIndexDefinition(this.indexName);\n+      await indexClient.createIndex(searchIndex);\n+    }\n+  }\n+\n+  /**\n+   * Prepares the search index definition for Azure AI Search.\n+   * @param indexName The name of the index.\n+   * @returns The SearchIndex object.\n+   * @protected\n+   */\n+  protected createSearchIndexDefinition(indexName: string): SearchIndex {\n+    return {\n+      name: indexName,\n+      vectorSearch: {\n+        algorithms: [\n+          {\n+            name: \"vector-search-algorithm\",\n+            kind: \"hnsw\",\n+            parameters: {\n+              m: 4,\n+              efSearch: 500,\n+              metric: \"cosine\",\n+              efConstruction: 400,\n+            },\n+          },\n+        ],\n+        profiles: [\n+          {\n+            name: \"vector-search-profile\",\n+            algorithmConfigurationName: \"vector-search-algorithm\",\n+          },\n+        ],\n+      },\n+      semanticSearch: {\n+        defaultConfigurationName: \"semantic-search-config\",\n+        configurations: [\n+          {\n+            name: \"semantic-search-config\",\n+            prioritizedFields: {\n+              contentFields: [\n+                {\n+                  name: DEFAULT_FIELD_CONTENT,\n+                },\n+              ],\n+              keywordsFields: [\n+                {\n+                  name: DEFAULT_FIELD_CONTENT,\n+                },\n+              ],\n+            },\n+          },\n+        ],\n+      },\n+      fields: [\n+        {\n+          name: DEFAULT_FIELD_ID,\n+          filterable: true,\n+          key: true,\n+          type: \"Edm.String\",\n+        },\n+        {\n+          name: DEFAULT_FIELD_CONTENT,\n+          searchable: true,\n+          filterable: true,\n+          type: \"Edm.String\",\n+        },\n+        {\n+          name: DEFAULT_FIELD_CONTENT_VECTOR,\n+          searchable: true,\n+          type: \"Collection(Edm.Single)\",\n+          vectorSearchDimensions: 1536,",
        "comment_created_at": "2024-01-17T19:56:38+00:00",
        "comment_author": "pablocastro",
        "comment_body": "Dimensions hardcoded to ada-002's size here, but I'm sure there are many cases where users will use other embedding models. Shouldn't this come from config or by sampling a vector of the ones being used for embeddings?",
        "pr_file_module": null
      },
      {
        "comment_id": "1457272275",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 4044,
        "pr_file": "libs/langchain-community/src/vectorstores/azure_aisearch.ts",
        "discussion_id": "1456404750",
        "commented_code": "@@ -0,0 +1,694 @@\n+import * as uuid from \"uuid\";\n+import {\n+  SearchClient,\n+  SearchIndexClient,\n+  AzureKeyCredential,\n+  IndexingResult,\n+  SearchIndex,\n+} from \"@azure/search-documents\";\n+import {\n+  MaxMarginalRelevanceSearchOptions,\n+  VectorStore,\n+} from \"@langchain/core/vectorstores\";\n+import type { EmbeddingsInterface } from \"@langchain/core/embeddings\";\n+import { Document } from \"@langchain/core/documents\";\n+import { maximalMarginalRelevance } from \"@langchain/core/utils/math\";\n+import { getEnvironmentVariable } from \"@langchain/core/utils/env\";\n+\n+/**\n+ * Azure AI Search query type.\n+ */\n+export const AzureAISearchQueryType = {\n+  /** Vector search. */\n+  Similarity: \"similarity\",\n+  /** Hybrid full text and vector search. */\n+  SimilarityHybrid: \"similarity_hybrid\",\n+  /** Hybrid full text and vector search with semantic ranking. */\n+  SemanticHybrid: \"semantic_hybrid\",\n+} as const;\n+\n+/**\n+ * Azure AI Search query type.\n+ */\n+export type AzureAISearchQueryType =\n+  (typeof AzureAISearchQueryType)[keyof typeof AzureAISearchQueryType];\n+\n+/**\n+ * Azure AI Search settings.\n+ */\n+export interface AzureAISearchQueryOptions {\n+  readonly type: AzureAISearchQueryType;\n+  readonly semanticConfigurationName?: string;\n+}\n+\n+/**\n+ * Configuration options for the `AzureAISearchStore` constructor.\n+ */\n+export interface AzureAISearchConfig {\n+  readonly client?: SearchClient<AzureAISearchDocument>;\n+  readonly indexName?: string;\n+  readonly endpoint?: string;\n+  readonly key?: string;\n+  readonly search: AzureAISearchQueryOptions;\n+  /**\n+   * The amount of documents to chunk by when adding vectors.\n+   * @default 100\n+   */\n+  readonly chunkSize?: number;\n+  /**\n+   * The amount of documents to embed at once when adding documents.\n+   * Note that some providers like Azure OpenAI can only embed 16 documents\n+   * at a time.\n+   * @default 16\n+   */\n+  readonly embeddingBatchSize?: number;\n+}\n+\n+/**\n+ * Azure AI Search options metadata schema.\n+ * If yout want to add custom data, use the attributes property.\n+ */\n+export type AzureAISearchDocumentMetadata = {\n+  source: string;\n+  attributes?: Array<{ key: string; value: string }>;\n+};\n+\n+/**\n+ * Azure AI Search indexed document.\n+ */\n+export type AzureAISearchDocument = {\n+  id: string;\n+  content: string;\n+  content_vector: number[];\n+  metadata: AzureAISearchDocumentMetadata;\n+};\n+\n+/**\n+ * Azure AI Search options for adding documents.\n+ */\n+export type AzureAISearchAddDocumentsOptions = {\n+  ids?: string[];\n+};\n+\n+const DEFAULT_FIELD_ID = \"id\";\n+const DEFAULT_FIELD_CONTENT = \"content\";\n+const DEFAULT_FIELD_CONTENT_VECTOR = \"content_vector\";\n+const DEFAULT_FIELD_METADATA = \"metadata\";\n+const DEFAULT_FIELD_METADATA_SOURCE = \"source\";\n+const DEFAULT_FIELD_METADATA_ATTRS = \"attributes\";\n+\n+/**\n+ * Azure AI Search vector store.\n+ * To use this, you should have:\n+ * - the `@azure/search-documents` NPM package installed\n+ * - an endpoint and key to the Azure AI Search instance\n+ *\n+ * If you directly provide a `SearchClient` instance, you need to ensure that\n+ * an index has been created. When using and endpoint and key, the index will\n+ * be created automatically if it does not exist.\n+ */\n+export class AzureAISearchVectorStore extends VectorStore {\n+  declare FilterType: string;\n+\n+  get lc_secrets(): { [key: string]: string } {\n+    return {\n+      endpoint: \"AZURE_AISEARCH_ENDPOINT\",\n+      key: \"AZURE_AISEARCH_KEY\",\n+    };\n+  }\n+\n+  _vectorstoreType(): string {\n+    return \"azure_aisearch\";\n+  }\n+\n+  private readonly initPromise: Promise<void>;\n+\n+  private readonly client: SearchClient<AzureAISearchDocument>;\n+\n+  private readonly indexName: string;\n+\n+  private readonly chunkSize: number;\n+\n+  private readonly embeddingBatchSize: number;\n+\n+  private readonly options: AzureAISearchQueryOptions;\n+\n+  constructor(embeddings: EmbeddingsInterface, config: AzureAISearchConfig) {\n+    super(embeddings, config);\n+\n+    const endpoint =\n+      config.endpoint ?? getEnvironmentVariable(\"AZURE_AISEARCH_ENDPOINT\");\n+    const key = config.key ?? getEnvironmentVariable(\"AZURE_AISEARCH_KEY\");\n+\n+    if (!config.client && !endpoint && !key) {\n+      throw new Error(\n+        \"Azure AI Search client or connection string must be set.\"\n+      );\n+    }\n+\n+    this.indexName = config.indexName ?? \"vectorsearch\";\n+    this.chunkSize = config.chunkSize ?? 100;\n+    this.embeddingBatchSize = config.embeddingBatchSize ?? 16;\n+\n+    if (!config.client) {\n+      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n+      const credential = new AzureKeyCredential(key!);\n+      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n+      this.client = new SearchClient(endpoint!, this.indexName, credential);\n+      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n+      const indexClient = new SearchIndexClient(endpoint!, credential);\n+\n+      // Start initialization, but don't wait for it to finish here\n+      this.initPromise = this.ensureIndexExists(indexClient).catch((error) => {\n+        console.error(\n+          \"Error during Azure AI Search index initialization:\",\n+          error\n+        );\n+      });\n+    } else {\n+      this.client = config.client;\n+    }\n+\n+    this.options = config.search;\n+    this.embeddings = embeddings;\n+  }\n+\n+  /**\n+   * Removes specified documents from the AzureAISearchVectorStore using a filter.\n+   * @param filter OData filter to find documents to delete.\n+   * @returns A promise that resolves when the documents have been removed.\n+   */\n+  async deleteMany(filter: string): Promise<IndexingResult[]> {\n+    const { results } = await this.client.search(\"*\", {\n+      filter,\n+    });\n+\n+    const ids: string[] = [];\n+    for await (const item of results) {\n+      ids.push(item.document.id);\n+    }\n+\n+    const { results: deleteResults } = await this.client.deleteDocuments(\n+      DEFAULT_FIELD_ID,\n+      ids\n+    );\n+    return deleteResults;\n+  }\n+\n+  /**\n+   * Removes specified documents from the AzureAISearchVectorStore.\n+   * @param ids IDs of the documents to be removed.\n+   * @returns A promise that resolves when the documents have been removed.\n+   */\n+  async deleteById(ids: string | string[]): Promise<IndexingResult[]> {\n+    await this.initPromise;\n+    const { results } = await this.client.deleteDocuments(\n+      DEFAULT_FIELD_ID,\n+      Array.isArray(ids) ? ids : [ids]\n+    );\n+    return results;\n+  }\n+\n+  /**\n+   * Adds documents to the AzureAISearchVectorStore.\n+   * Documents are chunked into batches of size `embeddingBatchSize` then\n+   * embedded and added to the AzureAISearchVectorStore.\n+   * @param documents The documents to add.\n+   * @param options Options for adding documents.\n+   * @returns A promise that resolves to the ids of the added documents.\n+   */\n+  async addDocuments(\n+    documents: Document[],\n+    options?: AzureAISearchAddDocumentsOptions\n+  ) {\n+    const texts = documents.map(({ pageContent }) => pageContent);\n+    const results: string[] = [];\n+\n+    for (let i = 0; i < texts.length; i += this.embeddingBatchSize) {\n+      const batch = texts.slice(i, i + this.embeddingBatchSize);\n+      const docsBatch = documents.slice(i, i + this.embeddingBatchSize);\n+      const batchEmbeddings: number[][] = await this.embeddings.embedDocuments(\n+        batch\n+      );\n+      const batchResult = await this.addVectors(\n+        batchEmbeddings,\n+        docsBatch,\n+        options\n+      );\n+\n+      results.push(...batchResult);\n+    }\n+\n+    return results;\n+  }\n+\n+  /**\n+   * Adds vectors to the AzureAISearchVectorStore.\n+   * @param vectors Vectors to be added.\n+   * @param documents Corresponding documents to be added.\n+   * @param options Options for adding documents.\n+   * @returns A promise that resolves to the ids of the added documents.\n+   */\n+  async addVectors(\n+    vectors: number[][],\n+    documents: Document[],\n+    options?: AzureAISearchAddDocumentsOptions\n+  ): Promise<string[]> {\n+    const ids = options?.ids ?? documents.map(() => uuid.v4());\n+    const entities: AzureAISearchDocument[] = documents.map((doc, idx) => ({\n+      id: ids[idx],\n+      content: doc.pageContent,\n+      content_vector: vectors[idx],\n+      metadata: {\n+        source: doc.metadata?.source,\n+        attributes: doc.metadata?.attributes ?? [],\n+      },\n+    }));\n+\n+    await this.initPromise;\n+    for (let i = 0; i < entities.length; i += this.chunkSize) {\n+      const chunk = entities.slice(i, i + this.chunkSize);\n+      await this.client.uploadDocuments(chunk, { throwOnAnyFailure: true });\n+    }\n+\n+    return ids;\n+  }\n+\n+  /**\n+   * Performs a similarity search using query type specified in configuration.\n+   * @param query Query text for the similarity search.\n+   * @param k=4 Number of nearest neighbors to return.\n+   * @param filter Optional OData filter for the documents.\n+   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n+   */\n+  async similaritySearch(\n+    query: string,\n+    k = 4,\n+    filter: this[\"FilterType\"] | undefined = undefined\n+  ): Promise<Document[]> {\n+    const results = await this.similaritySearchWithScore(query, k, filter);\n+\n+    return results.map((result) => result[0]);\n+  }\n+\n+  /**\n+   * Performs a similarity search using query type specified in configuration.\n+   * @param query Query text for the similarity search.\n+   * @param k=4 Number of nearest neighbors to return.\n+   * @param filter Optional OData filter for the documents.\n+   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n+   */\n+  async similaritySearchWithScore(\n+    query: string,\n+    k = 4,\n+    filter: this[\"FilterType\"] | undefined = undefined\n+  ): Promise<[Document, number][]> {\n+    const searchType = this.options.type;\n+\n+    if (searchType === AzureAISearchQueryType.Similarity) {\n+      return this.similaritySearchVectorWithScore(\n+        await this.embeddings.embedQuery(query),\n+        k,\n+        filter\n+      );\n+    } else if (searchType === AzureAISearchQueryType.SimilarityHybrid) {\n+      return this.hybridSearchVectorWithScore(\n+        query,\n+        await this.embeddings.embedQuery(query),\n+        k,\n+        filter\n+      );\n+    } else if (searchType === AzureAISearchQueryType.SemanticHybrid) {\n+      return this.semanticHybridSearchVectorWithScore(\n+        query,\n+        await this.embeddings.embedQuery(query),\n+        k,\n+        filter\n+      );\n+    }\n+\n+    throw new Error(`Unrecognized search type '${searchType}'`);\n+  }\n+\n+  /**\n+   * Performs a hybrid search using query text.\n+   * @param query Query text for the similarity search.\n+   * @param queryVector Query vector for the similarity search.\n+   *    If not provided, the query text will be embedded.\n+   * @param k=4 Number of nearest neighbors to return.\n+   * @param filter Optional OData filter for the documents.\n+   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n+   */\n+  async hybridSearchVectorWithScore(\n+    query: string,\n+    queryVector?: number[],\n+    k = 4,\n+    filter: string | undefined = undefined\n+  ): Promise<[Document, number][]> {\n+    const vector = queryVector ?? (await this.embeddings.embedQuery(query));\n+\n+    await this.initPromise;\n+    const { results } = await this.client.search(query, {\n+      vectorSearchOptions: {\n+        queries: [\n+          {\n+            kind: \"vector\",\n+            vector,\n+            kNearestNeighborsCount: k,\n+            fields: [DEFAULT_FIELD_CONTENT_VECTOR],\n+          },\n+        ],\n+      },\n+      filter,\n+      top: k,\n+    });\n+\n+    const docsWithScore: [Document, number][] = [];\n+\n+    for await (const item of results) {\n+      const document = new Document<\n+        AzureAISearchDocumentMetadata & { embedding: number[] }\n+      >({\n+        pageContent: item.document[DEFAULT_FIELD_CONTENT],\n+        metadata: {\n+          ...item.document[DEFAULT_FIELD_METADATA],\n+          embedding: item.document[DEFAULT_FIELD_CONTENT_VECTOR],\n+        },\n+      });\n+      docsWithScore.push([document, item.score]);\n+    }\n+\n+    return docsWithScore;\n+  }\n+\n+  /**\n+   * Performs a hybrid search with semantic reranker using query text.\n+   * @param query Query text for the similarity search.\n+   * @param queryVector Query vector for the similarity search.\n+   *    If not provided, the query text will be embedded.\n+   * @param k=4 Number of nearest neighbors to return.\n+   * @param filter Optional OData filter for the documents.\n+   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n+   */\n+  async semanticHybridSearchVectorWithScore(\n+    query: string,\n+    queryVector?: number[],\n+    k = 4,\n+    filter: string | undefined = undefined\n+  ): Promise<[Document, number][]> {\n+    const vector = queryVector ?? (await this.embeddings.embedQuery(query));\n+\n+    await this.initPromise;\n+    const { results } = await this.client.search(query, {\n+      vectorSearchOptions: {\n+        queries: [\n+          {\n+            kind: \"vector\",\n+            vector,\n+            kNearestNeighborsCount: k,\n+            fields: [DEFAULT_FIELD_CONTENT_VECTOR],\n+          },\n+        ],\n+      },\n+      filter,\n+      top: k,\n+      queryType: \"semantic\",\n+      semanticSearchOptions: {\n+        configurationName: \"semantic-search-config\",\n+        captions: {\n+          captionType: \"extractive\",\n+        },\n+        answers: {\n+          answerType: \"extractive\",\n+        },\n+      },\n+    });\n+\n+    const docsWithScore: [Document, number][] = [];\n+\n+    for await (const item of results) {\n+      const document = new Document<\n+        AzureAISearchDocumentMetadata & { embedding: number[] }\n+      >({\n+        pageContent: item.document[DEFAULT_FIELD_CONTENT],\n+        metadata: {\n+          ...item.document[DEFAULT_FIELD_METADATA],\n+          embedding: item.document[DEFAULT_FIELD_CONTENT_VECTOR],\n+        },\n+      });\n+      docsWithScore.push([document, item.score]);\n+    }\n+\n+    return docsWithScore;\n+  }\n+\n+  /**\n+   * Performs a similarity search on the vectors stored in the collection.\n+   * @param queryVector Query vector for the similarity search.\n+   * @param k=4 Number of nearest neighbors to return.\n+   * @param filter string OData filter for the documents.\n+   * @returns Promise that resolves to a list of documents and their corresponding similarity scores.\n+   */\n+  async similaritySearchVectorWithScore(\n+    query: number[],\n+    k: number,\n+    filter?: string\n+  ): Promise<[Document, number][]> {\n+    await this.initPromise;\n+\n+    const { results } = await this.client.search(\"*\", {\n+      vectorSearchOptions: {\n+        queries: [\n+          {\n+            kind: \"vector\",\n+            vector: query,\n+            kNearestNeighborsCount: k,\n+            fields: [DEFAULT_FIELD_CONTENT_VECTOR],\n+          },\n+        ],\n+      },\n+      filter,\n+    });\n+\n+    const docsWithScore: [Document, number][] = [];\n+\n+    for await (const item of results) {\n+      const document = new Document<\n+        AzureAISearchDocumentMetadata & { embedding: number[] }\n+      >({\n+        pageContent: item.document[DEFAULT_FIELD_CONTENT],\n+        metadata: {\n+          ...item.document[DEFAULT_FIELD_METADATA],\n+          embedding: item.document[DEFAULT_FIELD_CONTENT_VECTOR],\n+        },\n+      });\n+      docsWithScore.push([document, item.score]);\n+    }\n+\n+    return docsWithScore;\n+  }\n+\n+  /**\n+   * Return documents selected using the maximal marginal relevance.\n+   * Maximal marginal relevance optimizes for similarity to the query AND\n+   * diversity among selected documents.\n+   * @param query Text to look up documents similar to.\n+   * @param options.k Number of documents to return.\n+   * @param options.fetchK=20 Number of documents to fetch before passing to\n+   *     the MMR algorithm.\n+   * @param options.lambda=0.5 Number between 0 and 1 that determines the\n+   *     degree of diversity among the results, where 0 corresponds to maximum\n+   *     diversity and 1 to minimum diversity.\n+   * @returns List of documents selected by maximal marginal relevance.\n+   */\n+  async maxMarginalRelevanceSearch(\n+    query: string,\n+    options: MaxMarginalRelevanceSearchOptions<this[\"FilterType\"]>\n+  ): Promise<Document[]> {\n+    const { k, fetchK = 20, lambda = 0.5 } = options;\n+\n+    const queryEmbedding = await this.embeddings.embedQuery(query);\n+    const docs = await this.similaritySearchVectorWithScore(\n+      queryEmbedding,\n+      fetchK\n+    );\n+    const embeddingList = docs.map((doc) => doc[0].metadata.embedding);\n+\n+    // Re-rank the results using MMR\n+    const mmrIndexes = maximalMarginalRelevance(\n+      queryEmbedding,\n+      embeddingList,\n+      lambda,\n+      k\n+    );\n+\n+    const mmrDocs = mmrIndexes.map((index) => docs[index][0]);\n+    return mmrDocs;\n+  }\n+\n+  /**\n+   * Ensures that an index exists on the AzureAISearchVectorStore.\n+   * @param indexClient The Azure AI Search index client.\n+   * @returns A promise that resolves when the AzureAISearchVectorStore index has been initialized.\n+   * @protected\n+   */\n+  protected async ensureIndexExists(\n+    indexClient: SearchIndexClient\n+  ): Promise<void> {\n+    try {\n+      await indexClient.getIndex(this.indexName);\n+    } catch (e) {\n+      // Index does not exists, create it\n+      const searchIndex = this.createSearchIndexDefinition(this.indexName);\n+      await indexClient.createIndex(searchIndex);\n+    }\n+  }\n+\n+  /**\n+   * Prepares the search index definition for Azure AI Search.\n+   * @param indexName The name of the index.\n+   * @returns The SearchIndex object.\n+   * @protected\n+   */\n+  protected createSearchIndexDefinition(indexName: string): SearchIndex {\n+    return {\n+      name: indexName,\n+      vectorSearch: {\n+        algorithms: [\n+          {\n+            name: \"vector-search-algorithm\",\n+            kind: \"hnsw\",\n+            parameters: {\n+              m: 4,\n+              efSearch: 500,\n+              metric: \"cosine\",\n+              efConstruction: 400,\n+            },\n+          },\n+        ],\n+        profiles: [\n+          {\n+            name: \"vector-search-profile\",\n+            algorithmConfigurationName: \"vector-search-algorithm\",\n+          },\n+        ],\n+      },\n+      semanticSearch: {\n+        defaultConfigurationName: \"semantic-search-config\",\n+        configurations: [\n+          {\n+            name: \"semantic-search-config\",\n+            prioritizedFields: {\n+              contentFields: [\n+                {\n+                  name: DEFAULT_FIELD_CONTENT,\n+                },\n+              ],\n+              keywordsFields: [\n+                {\n+                  name: DEFAULT_FIELD_CONTENT,\n+                },\n+              ],\n+            },\n+          },\n+        ],\n+      },\n+      fields: [\n+        {\n+          name: DEFAULT_FIELD_ID,\n+          filterable: true,\n+          key: true,\n+          type: \"Edm.String\",\n+        },\n+        {\n+          name: DEFAULT_FIELD_CONTENT,\n+          searchable: true,\n+          filterable: true,\n+          type: \"Edm.String\",\n+        },\n+        {\n+          name: DEFAULT_FIELD_CONTENT_VECTOR,\n+          searchable: true,\n+          type: \"Collection(Edm.Single)\",\n+          vectorSearchDimensions: 1536,",
        "comment_created_at": "2024-01-18T10:55:02+00:00",
        "comment_author": "sinedied",
        "comment_body": "Good catch. I'll check if we can get it from the LC embedding model directly or add it to the config",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1924384814",
    "pr_number": 7561,
    "pr_file": "libs/langchain-community/src/tools/tavily_search.ts",
    "created_at": "2025-01-21T21:28:07+00:00",
    "commented_code": "protected kwargs: Record<string, unknown> = {};\n\n  protected includeImages = false;\n\n  protected includeImageDescriptions = false;\n\n  protected includeAnswer = false;\n\n  protected includeRawContent = false;\n\n  protected includeDomains: string[] = [];\n\n  protected excludeDomains: string[] = [];\n\n  protected searchDepth: \"basic\" | \"deep\" = \"basic\";",
    "repo_full_name": "langchain-ai/langchainjs",
    "discussion_comments": [
      {
        "comment_id": "1924384814",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 7561,
        "pr_file": "libs/langchain-community/src/tools/tavily_search.ts",
        "discussion_id": "1924384814",
        "commented_code": "@@ -93,11 +170,41 @@ export class TavilySearchResults extends Tool {\n \n   protected kwargs: Record<string, unknown> = {};\n \n+  protected includeImages = false;\n+\n+  protected includeImageDescriptions = false;\n+\n+  protected includeAnswer = false;\n+\n+  protected includeRawContent = false;\n+\n+  protected includeDomains: string[] = [];\n+\n+  protected excludeDomains: string[] = [];\n+\n+  protected searchDepth: \"basic\" | \"deep\" = \"basic\";",
        "comment_created_at": "2025-01-21T21:28:07+00:00",
        "comment_author": "jacoblee93",
        "comment_body": "Let's avoid defaults at this level when possible",
        "pr_file_module": null
      },
      {
        "comment_id": "1927795454",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 7561,
        "pr_file": "libs/langchain-community/src/tools/tavily_search.ts",
        "discussion_id": "1924384814",
        "commented_code": "@@ -93,11 +170,41 @@ export class TavilySearchResults extends Tool {\n \n   protected kwargs: Record<string, unknown> = {};\n \n+  protected includeImages = false;\n+\n+  protected includeImageDescriptions = false;\n+\n+  protected includeAnswer = false;\n+\n+  protected includeRawContent = false;\n+\n+  protected includeDomains: string[] = [];\n+\n+  protected excludeDomains: string[] = [];\n+\n+  protected searchDepth: \"basic\" | \"deep\" = \"basic\";",
        "comment_created_at": "2025-01-23T22:57:27+00:00",
        "comment_author": "hugoleborso",
        "comment_body": "Hi @jacoblee93, I did this because these are actually the default settings of the API doc, and also because `maxResults` already had a default value set corresponding to the default value in the doc.\r\n\r\nIf you want me too I can still change it of course, but I think it makes sense as is.\r\n\r\nLet me know what you think!",
        "pr_file_module": null
      },
      {
        "comment_id": "1929361191",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 7561,
        "pr_file": "libs/langchain-community/src/tools/tavily_search.ts",
        "discussion_id": "1924384814",
        "commented_code": "@@ -93,11 +170,41 @@ export class TavilySearchResults extends Tool {\n \n   protected kwargs: Record<string, unknown> = {};\n \n+  protected includeImages = false;\n+\n+  protected includeImageDescriptions = false;\n+\n+  protected includeAnswer = false;\n+\n+  protected includeRawContent = false;\n+\n+  protected includeDomains: string[] = [];\n+\n+  protected excludeDomains: string[] = [];\n+\n+  protected searchDepth: \"basic\" | \"deep\" = \"basic\";",
        "comment_created_at": "2025-01-24T23:25:06+00:00",
        "comment_author": "jacoblee93",
        "comment_body": "We should ideally let the backend set this in case they change best practices, would prefer to have things unset if it won't cause issues (which it wasn't before)",
        "pr_file_module": null
      },
      {
        "comment_id": "1931704972",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 7561,
        "pr_file": "libs/langchain-community/src/tools/tavily_search.ts",
        "discussion_id": "1924384814",
        "commented_code": "@@ -93,11 +170,41 @@ export class TavilySearchResults extends Tool {\n \n   protected kwargs: Record<string, unknown> = {};\n \n+  protected includeImages = false;\n+\n+  protected includeImageDescriptions = false;\n+\n+  protected includeAnswer = false;\n+\n+  protected includeRawContent = false;\n+\n+  protected includeDomains: string[] = [];\n+\n+  protected excludeDomains: string[] = [];\n+\n+  protected searchDepth: \"basic\" | \"deep\" = \"basic\";",
        "comment_created_at": "2025-01-28T08:16:23+00:00",
        "comment_author": "hugoleborso",
        "comment_body": "@jacoblee93 done, let me know if this fit your needs, and thanks for all the quick responses !",
        "pr_file_module": null
      },
      {
        "comment_id": "1934820570",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 7561,
        "pr_file": "libs/langchain-community/src/tools/tavily_search.ts",
        "discussion_id": "1924384814",
        "commented_code": "@@ -93,11 +170,41 @@ export class TavilySearchResults extends Tool {\n \n   protected kwargs: Record<string, unknown> = {};\n \n+  protected includeImages = false;\n+\n+  protected includeImageDescriptions = false;\n+\n+  protected includeAnswer = false;\n+\n+  protected includeRawContent = false;\n+\n+  protected includeDomains: string[] = [];\n+\n+  protected excludeDomains: string[] = [];\n+\n+  protected searchDepth: \"basic\" | \"deep\" = \"basic\";",
        "comment_created_at": "2025-01-29T23:52:18+00:00",
        "comment_author": "jacoblee93",
        "comment_body": "Thank you, old defaults have started causing issues for OpenAI so it's top of mind right now",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1829838921",
    "pr_number": 6999,
    "pr_file": "libs/langchain-google-common/src/connection.ts",
    "created_at": "2024-11-05T18:39:30+00:00",
    "commented_code": "}\n  }\n\n  get computedLocation(): string {\n    switch (this.apiName) {\n      case \"google\":\n        return super.computedLocation;\n      case \"anthropic\":\n        return \"us-east5\";",
    "repo_full_name": "langchain-ai/langchainjs",
    "discussion_comments": [
      {
        "comment_id": "1829838921",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 6999,
        "pr_file": "libs/langchain-google-common/src/connection.ts",
        "discussion_id": "1829838921",
        "commented_code": "@@ -245,6 +288,19 @@ export abstract class GoogleAIConnection<\n     }\n   }\n \n+  get computedLocation(): string {\n+    switch (this.apiName) {\n+      case \"google\":\n+        return super.computedLocation;\n+      case \"anthropic\":\n+        return \"us-east5\";",
        "comment_created_at": "2024-11-05T18:39:30+00:00",
        "comment_author": "jacoblee93",
        "comment_body": "Should we be hardcoding this here?\r\n\r\nIf it's only available in one region now, would prefer to have this configurable or even not have a default at all and just have it documented",
        "pr_file_module": null
      },
      {
        "comment_id": "1829905294",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 6999,
        "pr_file": "libs/langchain-google-common/src/connection.ts",
        "discussion_id": "1829838921",
        "commented_code": "@@ -245,6 +288,19 @@ export abstract class GoogleAIConnection<\n     }\n   }\n \n+  get computedLocation(): string {\n+    switch (this.apiName) {\n+      case \"google\":\n+        return super.computedLocation;\n+      case \"anthropic\":\n+        return \"us-east5\";",
        "comment_created_at": "2024-11-05T19:35:53+00:00",
        "comment_author": "afirstenberg",
        "comment_body": "See above about making magic values as unnecessary as possible.\r\n\r\nSome of the Anthropic models are available in other regions, but all are available in us-east5. And none, mysteriously, are available in us-central1.\r\n\r\nI'd like to keep it as a default, but clearly have it available to be settable.",
        "pr_file_module": null
      }
    ]
  }
]
