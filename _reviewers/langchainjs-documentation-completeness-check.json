[
  {
    "discussion_id": "2092387294",
    "pr_number": 8007,
    "pr_file": "cookbook/oraclevs.md",
    "created_at": "2025-05-16T06:08:25+00:00",
    "commented_code": "Oracle AI Vector Search with LangchainJS Integration",
    "repo_full_name": "langchain-ai/langchainjs",
    "discussion_comments": [
      {
        "comment_id": "2092387294",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 8007,
        "pr_file": "cookbook/oraclevs.md",
        "discussion_id": "2092387294",
        "commented_code": "@@ -0,0 +1,273 @@\n+Oracle AI Vector Search with LangchainJS Integration",
        "comment_created_at": "2025-05-16T06:08:25+00:00",
        "comment_author": "cjbj",
        "comment_body": "Shouldn't headings like this have the appropriate markdown syntax? (There are many occurrences in this file that look odd).",
        "pr_file_module": null
      },
      {
        "comment_id": "2094155633",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 8007,
        "pr_file": "cookbook/oraclevs.md",
        "discussion_id": "2092387294",
        "commented_code": "@@ -0,0 +1,273 @@\n+Oracle AI Vector Search with LangchainJS Integration",
        "comment_created_at": "2025-05-17T16:01:02+00:00",
        "comment_author": "hackerdave",
        "comment_body": "Good catch, have added some markdown syntax to fix the headings and bullets",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2099206512",
    "pr_number": 8007,
    "pr_file": "cookbook/oraclevs.md",
    "created_at": "2025-05-21T02:59:16+00:00",
    "commented_code": "# Oracle AI Vector Search with LangchainJS Integration\n## Introduction\nOracle AI Vector Search enables semantic search on unstructured data while simultaneously providing relational search capabilities on business data, all within a unified system. This approach eliminates the need for a separate vector database, reducing data fragmentation and improving efficiency.\n\nBy integrating Oracle AI Vector Search with Langchain, you can build a powerful pipeline for Retrieval Augmented Generation (RAG), leveraging Oracle's robust database features.\n\nKey Advantages of Oracle Database\nOracle AI Vector Search is built on top of the Oracle Database, providing several key features:\n\n* Partitioning Support\n* Real Application Clusters (RAC) Scalability\n* Exadata Smart Scans\n* Geographically Distributed Shard Processing\n* Transactional Capabilities\n* Parallel SQL\n* Disaster Recovery\n* Advanced Security\n* Oracle Machine Learning\n* Oracle Graph Database\n* Oracle Spatial and Graph\n* Oracle Blockchain\n* JSON Support\n## Guide Overview\nThis guide demonstrates how to integrate Oracle AI Vector Search with Langchain to create an end-to-end RAG pipeline. You'll learn how to:\n\n* Load documents from different sources using OracleDocLoader.\n* Summarize documents inside or outside the database using OracleSummary.\n* Generate embeddings either inside or outside the database using OracleEmbeddings.\n* Chunk documents based on specific needs using OracleTextSplitter.\n* Store, index, and query data using OracleVS.\n## Getting Started\nIf you're new to Oracle Database, consider using the free Oracle 23 AI Database to get started.\n\n## Best Practices\n* User Management: Create dedicated users for your Oracle Database projects instead of using the system user for security and control purposes. See the end-to-end guide for more details.\n* User Privileges: Be sure to manage user privileges effectively to maintain database security. You can find more information in the official Oracle documentation.\n## Prerequisites\nTo get started, install the Oracle JavaScript client driver:\n\n``` typescript\nnpm install oracledb\n```\n\n## Document Preparation\nAssuming you have documents stored in a file system that you want to use with Oracle AI Vector Search and Langchain, these documents need to be instances of langchain/core/documents.\n\nExample: Ingesting JSON Documents\nIn the following TypeScript example, we demonstrate how to ingest documents from JSON files:\n\n```typescript\nprivate createDocument(row: DataRow): Document {\n    const metadata = {\n        id: row.id,    \n        link: row.link,\n    };\n    return new Document({ pageContent: row.text, metadata: metadata });\n}\n\npublic async ingestJson(): Promise<Document[]> {\n   try {\n       const filePath = `${this.docsDir}${this.filename}`;\n       const fileContent = await fs.readFile(filePath, {encoding: 'utf8'});\n       const jsonData: DataRow[] = JSON.parse(fileContent);\n       return jsonData.map((row) => this.createDocument(row));\n   } catch (error) {\n       console.error('An error occurred while ingesting JSON:', error);\n       throw error; // Rethrow for the calling function to handle\n   }\n}\n```\n\n## Langchain and Oracle Integration\nThe Oracle AI Vector Search Langchain library offers a rich set of APIs for document processing, which includes loading, chunking, summarizing, and embedding generation. Here's how to set up a connection and integrate Oracle with Langchain.\n\n## Connecting to Oracle Database\nBelow is an example of how to connect to an Oracle Database using both a direct connection and a connection pool:",
    "repo_full_name": "langchain-ai/langchainjs",
    "discussion_comments": [
      {
        "comment_id": "2099206512",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 8007,
        "pr_file": "cookbook/oraclevs.md",
        "discussion_id": "2099206512",
        "commented_code": "@@ -0,0 +1,273 @@\n+# Oracle AI Vector Search with LangchainJS Integration\n+## Introduction\n+Oracle AI Vector Search enables semantic search on unstructured data while simultaneously providing relational search capabilities on business data, all within a unified system. This approach eliminates the need for a separate vector database, reducing data fragmentation and improving efficiency.\n+\n+By integrating Oracle AI Vector Search with Langchain, you can build a powerful pipeline for Retrieval Augmented Generation (RAG), leveraging Oracle's robust database features.\n+\n+Key Advantages of Oracle Database\n+Oracle AI Vector Search is built on top of the Oracle Database, providing several key features:\n+\n+* Partitioning Support\n+* Real Application Clusters (RAC) Scalability\n+* Exadata Smart Scans\n+* Geographically Distributed Shard Processing\n+* Transactional Capabilities\n+* Parallel SQL\n+* Disaster Recovery\n+* Advanced Security\n+* Oracle Machine Learning\n+* Oracle Graph Database\n+* Oracle Spatial and Graph\n+* Oracle Blockchain\n+* JSON Support\n+## Guide Overview\n+This guide demonstrates how to integrate Oracle AI Vector Search with Langchain to create an end-to-end RAG pipeline. You'll learn how to:\n+\n+* Load documents from different sources using OracleDocLoader.\n+* Summarize documents inside or outside the database using OracleSummary.\n+* Generate embeddings either inside or outside the database using OracleEmbeddings.\n+* Chunk documents based on specific needs using OracleTextSplitter.\n+* Store, index, and query data using OracleVS.\n+## Getting Started\n+If you're new to Oracle Database, consider using the free Oracle 23 AI Database to get started.\n+\n+## Best Practices\n+* User Management: Create dedicated users for your Oracle Database projects instead of using the system user for security and control purposes. See the end-to-end guide for more details.\n+* User Privileges: Be sure to manage user privileges effectively to maintain database security. You can find more information in the official Oracle documentation.\n+## Prerequisites\n+To get started, install the Oracle JavaScript client driver:\n+\n+``` typescript\n+npm install oracledb\n+```\n+\n+## Document Preparation\n+Assuming you have documents stored in a file system that you want to use with Oracle AI Vector Search and Langchain, these documents need to be instances of langchain/core/documents.\n+\n+Example: Ingesting JSON Documents\n+In the following TypeScript example, we demonstrate how to ingest documents from JSON files:\n+\n+```typescript\n+private createDocument(row: DataRow): Document {\n+    const metadata = {\n+        id: row.id,    \n+        link: row.link,\n+    };\n+    return new Document({ pageContent: row.text, metadata: metadata });\n+}\n+\n+public async ingestJson(): Promise<Document[]> {\n+   try {\n+       const filePath = `${this.docsDir}${this.filename}`;\n+       const fileContent = await fs.readFile(filePath, {encoding: 'utf8'});\n+       const jsonData: DataRow[] = JSON.parse(fileContent);\n+       return jsonData.map((row) => this.createDocument(row));\n+   } catch (error) {\n+       console.error('An error occurred while ingesting JSON:', error);\n+       throw error; // Rethrow for the calling function to handle\n+   }\n+}\n+```\n+\n+## Langchain and Oracle Integration\n+The Oracle AI Vector Search Langchain library offers a rich set of APIs for document processing, which includes loading, chunking, summarizing, and embedding generation. Here's how to set up a connection and integrate Oracle with Langchain.\n+\n+## Connecting to Oracle Database\n+Below is an example of how to connect to an Oracle Database using both a direct connection and a connection pool:",
        "comment_created_at": "2025-05-21T02:59:16+00:00",
        "comment_author": "cjbj",
        "comment_body": "Please link here (or somewhere) to https://node-oracledb.readthedocs.io/en/latest/ so users can get more info.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2103914082",
    "pr_number": 8241,
    "pr_file": "libs/langchain-mcp-adapters/README.md",
    "created_at": "2025-05-23T06:42:58+00:00",
    "commented_code": "| `prefixToolNameWithServerName` | boolean | `true`  | If true, prefixes all tool names with the server name (e.g., `serverName__toolName`) |\n| `additionalToolNamePrefix`     | string  | `mcp`   | Additional prefix to add to tool names (e.g., `prefix__serverName__toolName`)        |\n\n## Tool Timeout Configuration\n\nMCP tools support timeout configuration through LangChain's standard `RunnableConfig` interface. This allows you to set custom timeouts on a per-tool-call basis:\n\n```typescript\nconst client = new MultiServerMCPClient({\n  mcpServers: {\n    'data-processor': {\n      command: 'python',\n      args: ['data_server.py']\n    }\n  }\n});\n\nconst tools = await client.getTools();\nconst slowTool = tools.find(t => t.name.includes('process_large_dataset'));\n\n// You can use withConfig to set tool-specific timeouts before handing\n// the tool off to a LangGraph ToolNode or some other part of your\n// application\nconst slowToolWithTimeout = slowTool.withConfig({ timeout: 300000 }); // 5 min timeout\n\n// This invocation will respect the 5 minute timeout\nconst result = await slowToolWithTimeout.invoke(\n  { dataset: 'huge_file.csv' },\n);\n\n// or you can invoke directly without withConfig\nconst directResult = await slowTool.invoke(\n  { dataset: 'huge_file.csv' },\n  { timeout: 300000 }\n);\n\n// Quick timeout for fast operations\nconst quickResult = await fastTool.invoke(\n  { query: 'simple_lookup' },\n  { timeout: 5000 } // 5 seconds\n);\n\n// Default timeout (60 seconds from MCP SDK) when no config provided\nconst normalResult = await tool.invoke({ input: 'normal_processing' });\n```\n\n### Timeout Configuration\n\n| Parameter | Type | Default | Description |\n| --------- | ---- | ------- | ----------- |\n| `timeout` | number | 60000 | Timeout in milliseconds for the tool call |",
    "repo_full_name": "langchain-ai/langchainjs",
    "discussion_comments": [
      {
        "comment_id": "2103914082",
        "repo_full_name": "langchain-ai/langchainjs",
        "pr_number": 8241,
        "pr_file": "libs/langchain-mcp-adapters/README.md",
        "discussion_id": "2103914082",
        "commented_code": "@@ -224,6 +224,57 @@ When loading MCP tools either directly through `loadMcpTools` or via `MultiServe\n | `prefixToolNameWithServerName` | boolean | `true`  | If true, prefixes all tool names with the server name (e.g., `serverName__toolName`) |\n | `additionalToolNamePrefix`     | string  | `mcp`   | Additional prefix to add to tool names (e.g., `prefix__serverName__toolName`)        |\n \n+## Tool Timeout Configuration\n+\n+MCP tools support timeout configuration through LangChain's standard `RunnableConfig` interface. This allows you to set custom timeouts on a per-tool-call basis:\n+\n+```typescript\n+const client = new MultiServerMCPClient({\n+  mcpServers: {\n+    'data-processor': {\n+      command: 'python',\n+      args: ['data_server.py']\n+    }\n+  }\n+});\n+\n+const tools = await client.getTools();\n+const slowTool = tools.find(t => t.name.includes('process_large_dataset'));\n+\n+// You can use withConfig to set tool-specific timeouts before handing\n+// the tool off to a LangGraph ToolNode or some other part of your\n+// application\n+const slowToolWithTimeout = slowTool.withConfig({ timeout: 300000 }); // 5 min timeout\n+\n+// This invocation will respect the 5 minute timeout\n+const result = await slowToolWithTimeout.invoke(\n+  { dataset: 'huge_file.csv' },\n+);\n+\n+// or you can invoke directly without withConfig\n+const directResult = await slowTool.invoke(\n+  { dataset: 'huge_file.csv' },\n+  { timeout: 300000 }\n+);\n+\n+// Quick timeout for fast operations\n+const quickResult = await fastTool.invoke(\n+  { query: 'simple_lookup' },\n+  { timeout: 5000 } // 5 seconds\n+);\n+\n+// Default timeout (60 seconds from MCP SDK) when no config provided\n+const normalResult = await tool.invoke({ input: 'normal_processing' });\n+```\n+\n+### Timeout Configuration\n+\n+| Parameter | Type | Default | Description |\n+| --------- | ---- | ------- | ----------- |\n+| `timeout` | number | 60000 | Timeout in milliseconds for the tool call |",
        "comment_created_at": "2025-05-23T06:42:58+00:00",
        "comment_author": "Copilot",
        "comment_body": "The table documents only the `timeout` parameter, but `signal` from `RunnableConfig` is also supported and should be listed here for completeness.\n```suggestion\n| `timeout` | number | 60000 | Timeout in milliseconds for the tool call |\n| `signal`  | AbortSignal | `undefined` | Optional AbortSignal to cancel the tool call |\n```",
        "pr_file_module": null
      }
    ]
  }
]