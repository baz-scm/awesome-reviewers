[
  {
    "discussion_id": "2317051489",
    "pr_number": 9539,
    "pr_file": "docs/docs/API-Reference/api-openai-responses.mdx",
    "created_at": "2025-09-02T20:09:48+00:00",
    "commented_code": "+---\n+title: OpenAI Responses API\n+slug: /api-openai-responses\n+---\n+\n+import Tabs from '@theme/Tabs';\n+import TabItem from '@theme/Tabs';\n+\n+Langflow includes an OpenAI-compatible API endpoint at `POST /api/v1/responses`.\n+This endpoint allows you to run your flows using OpenAI-compatible request and response formats.",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2317051489",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9539,
        "pr_file": "docs/docs/API-Reference/api-openai-responses.mdx",
        "discussion_id": "2317051489",
        "commented_code": "@@ -0,0 +1,520 @@\n+---\n+title: OpenAI Responses API\n+slug: /api-openai-responses\n+---\n+\n+import Tabs from '@theme/Tabs';\n+import TabItem from '@theme/Tabs';\n+\n+Langflow includes an OpenAI-compatible API endpoint at `POST /api/v1/responses`.\n+This endpoint allows you to run your flows using OpenAI-compatible request and response formats.",
        "comment_created_at": "2025-09-02T20:09:48+00:00",
        "comment_author": "phact",
        "comment_body": "you're overloading the term responses here. the responses api vs request / response format.",
        "pr_file_module": null
      },
      {
        "comment_id": "2317055547",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9539,
        "pr_file": "docs/docs/API-Reference/api-openai-responses.mdx",
        "discussion_id": "2317051489",
        "commented_code": "@@ -0,0 +1,520 @@\n+---\n+title: OpenAI Responses API\n+slug: /api-openai-responses\n+---\n+\n+import Tabs from '@theme/Tabs';\n+import TabItem from '@theme/Tabs';\n+\n+Langflow includes an OpenAI-compatible API endpoint at `POST /api/v1/responses`.\n+This endpoint allows you to run your flows using OpenAI-compatible request and response formats.",
        "comment_created_at": "2025-09-02T20:11:37+00:00",
        "comment_author": "phact",
        "comment_body": "I would also link to the OpenAI responses API docs in this section.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2317059914",
    "pr_number": 9539,
    "pr_file": "docs/docs/API-Reference/api-openai-responses.mdx",
    "created_at": "2025-09-02T20:14:04+00:00",
    "commented_code": "+---\n+title: OpenAI Responses API\n+slug: /api-openai-responses\n+---\n+\n+import Tabs from '@theme/Tabs';\n+import TabItem from '@theme/Tabs';\n+\n+Langflow includes an OpenAI-compatible API endpoint at `POST /api/v1/responses`.\n+This endpoint allows you to run your flows using OpenAI-compatible request and response formats.\n+\n+This enables you to use existing OpenAI client libraries with minimal code changes - just change the `model` name to your `flow_id` instead of using OpenAI model names like \"gpt-4\".\n+Flow IDs can be found on the code snippets on the [**API access** pane](/concepts-publish#api-access) or in a flow's URL.\n+\n+## Prerequisites\n+\n+Your Langflow flow must contain a **ChatInput** component to be compatible with the OpenAI Responses API.\n+Flows without this component will return an error. The component types `ChatInput` and `Chat Input` are recognized as chat inputs.\n+\n+- **Tools**: The `tools` parameter is not yet supported and will return an error if provided.\n+- **Flow Requirements**: Flows must contain a ChatInput component.\n+- **Model Names**: The `model` field must contain a valid flow ID or endpoint name.\n+- **Authentication**: All requests require an API key passed in the `x-api-key` header.\n+For more information, see [API keys and authentication](/api-keys-and-authentication).\n+\n+## Request\n+\n+```\n+POST /api/v1/responses\n+```\n+\n+## Headers\n+\n+| Header | Required | Description | Example |\n+|--------|----------|-------------|---------|\n+| Content-Type | Yes | Specifies the JSON format | \"application/json\" |\n+| x-api-key | Yes | Your Langflow API key for authentication | \"sk-...\" |\n+| X-LANGFLOW-GLOBAL-VAR-* | No | Global variables for the flow | \"X-LANGFLOW-GLOBAL-VAR-API_KEY: sk-...\" |\n+\n+\n+## Example request\n+\n+```curl\n+curl -X POST \\\n+  \"$LANGFLOW_SERVER_URL/api/v1/responses\" \\\n+  -H \"x-api-key: $LANGFLOW_API_KEY\" \\\n+  -H \"Content-Type: application/json\" \\\n+  -d '{\n+    \"model\": \"$YOUR_FLOW_ID\",\n+    \"input\": \"Hello, how are you?\",\n+    \"stream\": false\n+  }'\n+```\n+\n+<details>\n+<summary>Result</summary>\n+\n+```json\n+{\n+  \"id\": \"e5e8ef8a-7efd-4090-a110-6aca082bceb7\",\n+  \"object\": \"response\",\n+  \"created_at\": 1756837941,\n+  \"status\": \"completed\",\n+  \"model\": \"ced2ec91-f325-4bf0-8754-f3198c2b1563\",\n+  \"output\": [\n+    {\n+      \"type\": \"message\",\n+      \"id\": \"msg_e5e8ef8a-7efd-4090-a110-6aca082bceb7\",\n+      \"status\": \"completed\",\n+      \"role\": \"assistant\",\n+      \"content\": [\n+        {\n+          \"type\": \"output_text\",\n+          \"text\": \"Hello! I'm here and ready to help. How can I assist you today?\",\n+          \"annotations\": []\n+        }\n+      ]\n+    }\n+  ],\n+  \"parallel_tool_calls\": true,\n+  \"previous_response_id\": null,\n+  \"reasoning\": {\"effort\": null, \"summary\": null},\n+  \"store\": true,\n+  \"temperature\": 1.0,\n+  \"text\": {\"format\": {\"type\": \"text\"}},\n+  \"tool_choice\": \"auto\",\n+  \"tools\": [],\n+  \"top_p\": 1.0,\n+  \"truncation\": \"disabled\",\n+  \"usage\": null,\n+  \"user\": null,\n+  \"metadata\": {}\n+}\n+```\n+\n+</details>\n+\n+### Request body\n+\n+| Field | Type | Required | Default | Description |\n+|-------|------|----------|---------|-------------|\n+| model | string | Yes | - | The flow ID to execute. |\n+| input | string | Yes | - | The input text to process. |\n+| stream | boolean | No | false | Whether to stream the response. |\n+| background | boolean | No | false | Whether to process in background. |\n+| tools | list[Any] | No | null | Tools are not supported yet. |\n+| previous_response_id | string | No | null | ID of previous response to continue conversation. For more, see [Continue conversations with response and session IDs](#response-id). |\n+| include | list[string] | No | null | Additional response data to include, such as `['tool_call.results']`. For more, see [Retrieve tool call results](#tool-call-results). |\n+\n+### Response body\n+\n+The response contains fields that Langflow sets dynamically and fields that use OpenAI-compatible defaults.\n+\n+The OpenAI-compatible default values shown above are currently fixed and cannot be modified via the request.\n+They are included to maintain API compatibility and provide a consistent response format.\n+\n+For your requests, you will only be setting the dynamic fields.\n+The default values are documented here for completeness and to show the full response structure.\n+\n+Fields set dynamically by Langflow:\n+\n+| Field | Type | Description |\n+|-------|------|-------------|\n+| id | string | Unique response identifier. |\n+| created_at | int | Unix timestamp of response creation. |\n+| model | string | The flow ID that was executed. |\n+| output | list[dict] | Array of output items (messages, tool calls, etc.). |\n+| previous_response_id | string | ID of previous response if continuing conversation. |\n+\n+<details closed>\n+<summary>Fields with OpenAI-compatible default values</summary>\n+\n+| Field | Type | Default Value | Description |\n+|-------|------|---------------|-------------|\n+| object | string | \"response\" | Always \"response\". |\n+| status | string | \"completed\" | Response status: \"completed\", \"in_progress\", or \"failed\". |\n+| error | dict | null | Error details (if any). |\n+| incomplete_details | dict | null | Incomplete response details (if any). |\n+| instructions | string | null | Response instructions (if any). |\n+| max_output_tokens | int | null | Maximum output tokens (if any). |\n+| parallel_tool_calls | boolean | true | Whether parallel tool calls are enabled. |\n+| reasoning | dict | `{\"effort\": null, \"summary\": null}` | Reasoning information with effort and summary. |\n+| store | boolean | true | Whether response is stored. |\n+| temperature | float | 1.0 | Temperature setting. |\n+| text | dict | `{\"format\": {\"type\": \"text\"}}` | Text format configuration. |\n+| tool_choice | string | \"auto\" | Tool choice setting. |\n+| tools | list[dict] | [] | Available tools. |\n+| top_p | float | 1.0 | Top-p setting. |\n+| truncation | string | \"disabled\" | Truncation setting. |\n+| usage | dict | null | Usage statistics (if any). |\n+| user | string | null | User identifier (if any). |\n+| metadata | dict | {} | Additional metadata. |\n+\n+</details>\n+\n+### Example streaming request\n+\n+When you set `\"stream\": true` with your request, the API returns a stream where each chunk contains a small piece of the response as it's generated. This provides a real-time experience where users can see the AI's output appear word by word, similar to ChatGPT's typing effect.\n+\n+```curl\n+curl -X POST \\\n+  \"$LANGFLOW_SERVER_URL/api/v1/responses\" \\\n+  -H \"x-api-key: $LANGFLOW_API_KEY\" \\\n+  -H \"Content-Type: application/json\" \\\n+  -d '{\n+    \"model\": \"$FLOW_ID\",\n+    \"input\": \"Tell me a story about a robot\",\n+    \"stream\": true\n+  }'\n+```\n+\n+<details closed>\n+<summary>Streaming response</summary>\n+\n+```json\n+{\n+  \"id\": \"f7fcea36-f128-41c4-9ac1-e683137375d5\",\n+  \"object\": \"response.chunk\",\n+  \"created\": 1756838094,\n+  \"model\": \"ced2ec91-f325-4bf0-8754-f3198c2b1563\",\n+  \"delta\": {\n+    \"content\": \"Once\"\n+  },\n+  \"status\": null\n+}\n+```\n+\n+</details>\n+### Streaming response body\n+\n+| Field | Type | Description |\n+|-------|------|-------------|\n+| id | string | Unique response identifier. |\n+| object | string | Always \"response.chunk\". |\n+| created | int | Unix timestamp of chunk creation. |\n+| model | string | The flow ID that was executed. |\n+| delta | dict | The new content chunk. |\n+| status | string | Response status: \"completed\", \"in_progress\", or \"failed\" (optional). |\n+\n+The stream continues until a final chunk with `\"status\": \"completed\"` indicates the response is finished.\n+\n+<details closed>\n+<summary>Final completion chunk</summary>\n+\n+```\n+{\n+  \"id\": \"f7fcea36-f128-41c4-9ac1-e683137375d5\",\n+  \"object\": \"response.chunk\",\n+  \"created\": 1756838094,\n+  \"model\": \"ced2ec91-f325-4bf0-8754-f3198c2b1563\",\n+  \"delta\": {},\n+  \"status\": \"completed\"\n+}\n+```\n+</details>\n+\n+## Retrieve tool call results {#tool-call-results}\n+\n+When you send a request to the `/api/v1/responses` endpoint to run a flow that includes tools or function calls, you can retrieve the raw tool execution details by adding `\"include\": [\"tool_call.results\"]` to the request payload.\n+\n+Without the `include` parameter, tool calls return basic function call information, but not the raw tool results, like this example:\n+\n+```json\n+{\n+  \"id\": \"fc_1\",\n+  \"type\": \"function_call\",\n+  \"status\": \"completed\",\n+  \"name\": \"evaluate_expression\",\n+  \"arguments\": \"{\\\"expression\\\": \\\"15*23\\\"}\"\n+},\n+```\n+\n+To get the raw `results` of each tool execution, add the line  `include: [\"tool_call.results\"]` to the request payload.\n+\n+```bash\n+curl -X POST \\\n+  \"http://LANGFLOW_SERVER_URL/api/v1/responses\" \\\n+  -H \"Content-Type: application/json\" \\\n+  -H \"x-api-key: $LANGFLOW_API_KEY\" \\\n+  -d '{\n+    \"model\": \"FLOW_ID\",\n+    \"input\": \"Calculate 25 * 13 and show me the result\",\n+    \"stream\": false,\n+    \"include\": [\"tool_call.results\"]\n+  }'\n+```\n+<details closed>\n+<summary>Response with results</summary>\n+\n+```json\n+{\n+  \"id\": \"a6e5511e-71f8-457a-88d2-7d8c6ea34e36\",\n+  \"object\": \"response\",\n+  \"created_at\": 1756835379,\n+  \"status\": \"completed\",\n+  \"error\": null,\n+  \"incomplete_details\": null,\n+  \"instructions\": null,\n+  \"max_output_tokens\": null,\n+  \"model\": \"ced2ec91-f325-4bf0-8754-f3198c2b1563\",\n+  \"output\": [\n+    {\n+      \"id\": \"evaluate_expression_1\",\n+      \"queries\": [\n+        \"45+67\"\n+      ],\n+      \"status\": \"completed\",\n+      \"tool_name\": \"evaluate_expression\",\n+      \"type\": \"tool_call\",\n+      \"results\": {\n+        \"result\": \"112\"\n+      }\n+    },\n+    {\n+      \"type\": \"message\",\n+      \"id\": \"msg_a6e5511e-71f8-457a-88d2-7d8c6ea34e36\",\n+      \"status\": \"completed\",\n+      \"role\": \"assistant\",\n+      \"content\": [\n+        {\n+          \"type\": \"output_text\",\n+          \"text\": \"The result of 45 + 67 is 112.\",\n+          \"annotations\": []\n+        }\n+      ]\n+    }\n+  ],\n+  \"parallel_tool_calls\": true,\n+  \"previous_response_id\": null,\n+  \"reasoning\": {\n+    \"effort\": null,\n+    \"summary\": null\n+  },\n+  \"store\": true,\n+  \"temperature\": 1.0,\n+  \"text\": {\n+    \"format\": {\n+      \"type\": \"text\"\n+    }\n+  },\n+  \"tool_choice\": \"auto\",\n+  \"tools\": [],\n+  \"top_p\": 1.0,\n+  \"truncation\": \"disabled\",\n+  \"usage\": null,\n+  \"user\": null,\n+  \"metadata\": {}\n+}\n+```\n+</details>\n+\n+The response now includes the tool call's results.\n+\n+```json\n+{\n+  \"id\": \"evaluate_expression_1\",\n+  \"type\": \"tool_call\",\n+  \"tool_name\": \"evaluate_expression\",\n+  \"queries\": [\"15*23\"],\n+  \"results\": {\"result\": \"112\"}\n+}\n+```\n+\n+## Pass global variables to your flows in headers\n+\n+Global variables allow you to pass dynamic values to your flows that can be used by components within that flow run.\n+This is useful for passing API keys, user IDs, or any other configuration that might change between requests.\n+\n+The `/responses` endpoint accepts global variables as custom HTTP headers with the format `X-LANGFLOW-GLOBAL-VAR-{VARIABLE_NAME}`.\n+Variable names are automatically converted to uppercase.\n+\n+Variables passed with `X-LANGFLOW-GLOBAL-VAR-{VARIABLE_NAME}` supersede database variables for a single flow run.\n+If no variable is found in the database, the flow will fail, unless the `FALLBACK_TO_ENV_VARS` environment variable is `true`, in which case the flow will use the variable set in the `.env` file.\n+\n+This example shows how global variables work for a single flow run. The variables are only available during that specific request execution and are not persisted.\n+\n+```bash\n+curl -X POST \\\n+  \"$LANGFLOW_SERVER_URL/api/v1/responses\" \\\n+  -H \"x-api-key: $LANGFLOW_API_KEY\" \\\n+  -H \"Content-Type: application/json\" \\\n+  -H \"X-LANGFLOW-GLOBAL-VAR-OPENAI_API_KEY: sk-...\" \\\n+  -H \"X-LANGFLOW-GLOBAL-VAR-USER_ID: user123\" \\\n+  -H \"X-LANGFLOW-GLOBAL-VAR-ENVIRONMENT: production\" \\\n+  -d '{\n+    \"model\": \"your-flow-id\",\n+    \"input\": \"Hello\"\n+  }'\n+```\n+\n+<details>\n+<summary>Response</summary>\n+\n+```json\n+{\n+  \"id\": \"4a4d2f24-bb45-4a55-a499-0191305264be\",\n+  \"object\": \"response\",\n+  \"created_at\": 1756839935,\n+  \"status\": \"completed\",\n+  \"model\": \"ced2ec91-f325-4bf0-8754-f3198c2b1563\",\n+  \"output\": [\n+    {\n+      \"type\": \"message\",\n+      \"id\": \"msg_4a4d2f24-bb45-4a55-a499-0191305264be\",\n+      \"status\": \"completed\",\n+      \"role\": \"assistant\",\n+      \"content\": [\n+        {\n+          \"type\": \"output_text\",\n+          \"text\": \"Hello! How can I assist you today?\",\n+          \"annotations\": []\n+        }\n+      ]\n+    }\n+  ],\n+  \"previous_response_id\": null\n+}\n+```\n+\n+</details>\n+\n+## Continue conversations with response and session IDs {#response-id}",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2317059914",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9539,
        "pr_file": "docs/docs/API-Reference/api-openai-responses.mdx",
        "discussion_id": "2317059914",
        "commented_code": "@@ -0,0 +1,520 @@\n+---\n+title: OpenAI Responses API\n+slug: /api-openai-responses\n+---\n+\n+import Tabs from '@theme/Tabs';\n+import TabItem from '@theme/Tabs';\n+\n+Langflow includes an OpenAI-compatible API endpoint at `POST /api/v1/responses`.\n+This endpoint allows you to run your flows using OpenAI-compatible request and response formats.\n+\n+This enables you to use existing OpenAI client libraries with minimal code changes - just change the `model` name to your `flow_id` instead of using OpenAI model names like \"gpt-4\".\n+Flow IDs can be found on the code snippets on the [**API access** pane](/concepts-publish#api-access) or in a flow's URL.\n+\n+## Prerequisites\n+\n+Your Langflow flow must contain a **ChatInput** component to be compatible with the OpenAI Responses API.\n+Flows without this component will return an error. The component types `ChatInput` and `Chat Input` are recognized as chat inputs.\n+\n+- **Tools**: The `tools` parameter is not yet supported and will return an error if provided.\n+- **Flow Requirements**: Flows must contain a ChatInput component.\n+- **Model Names**: The `model` field must contain a valid flow ID or endpoint name.\n+- **Authentication**: All requests require an API key passed in the `x-api-key` header.\n+For more information, see [API keys and authentication](/api-keys-and-authentication).\n+\n+## Request\n+\n+```\n+POST /api/v1/responses\n+```\n+\n+## Headers\n+\n+| Header | Required | Description | Example |\n+|--------|----------|-------------|---------|\n+| Content-Type | Yes | Specifies the JSON format | \"application/json\" |\n+| x-api-key | Yes | Your Langflow API key for authentication | \"sk-...\" |\n+| X-LANGFLOW-GLOBAL-VAR-* | No | Global variables for the flow | \"X-LANGFLOW-GLOBAL-VAR-API_KEY: sk-...\" |\n+\n+\n+## Example request\n+\n+```curl\n+curl -X POST \\\n+  \"$LANGFLOW_SERVER_URL/api/v1/responses\" \\\n+  -H \"x-api-key: $LANGFLOW_API_KEY\" \\\n+  -H \"Content-Type: application/json\" \\\n+  -d '{\n+    \"model\": \"$YOUR_FLOW_ID\",\n+    \"input\": \"Hello, how are you?\",\n+    \"stream\": false\n+  }'\n+```\n+\n+<details>\n+<summary>Result</summary>\n+\n+```json\n+{\n+  \"id\": \"e5e8ef8a-7efd-4090-a110-6aca082bceb7\",\n+  \"object\": \"response\",\n+  \"created_at\": 1756837941,\n+  \"status\": \"completed\",\n+  \"model\": \"ced2ec91-f325-4bf0-8754-f3198c2b1563\",\n+  \"output\": [\n+    {\n+      \"type\": \"message\",\n+      \"id\": \"msg_e5e8ef8a-7efd-4090-a110-6aca082bceb7\",\n+      \"status\": \"completed\",\n+      \"role\": \"assistant\",\n+      \"content\": [\n+        {\n+          \"type\": \"output_text\",\n+          \"text\": \"Hello! I'm here and ready to help. How can I assist you today?\",\n+          \"annotations\": []\n+        }\n+      ]\n+    }\n+  ],\n+  \"parallel_tool_calls\": true,\n+  \"previous_response_id\": null,\n+  \"reasoning\": {\"effort\": null, \"summary\": null},\n+  \"store\": true,\n+  \"temperature\": 1.0,\n+  \"text\": {\"format\": {\"type\": \"text\"}},\n+  \"tool_choice\": \"auto\",\n+  \"tools\": [],\n+  \"top_p\": 1.0,\n+  \"truncation\": \"disabled\",\n+  \"usage\": null,\n+  \"user\": null,\n+  \"metadata\": {}\n+}\n+```\n+\n+</details>\n+\n+### Request body\n+\n+| Field | Type | Required | Default | Description |\n+|-------|------|----------|---------|-------------|\n+| model | string | Yes | - | The flow ID to execute. |\n+| input | string | Yes | - | The input text to process. |\n+| stream | boolean | No | false | Whether to stream the response. |\n+| background | boolean | No | false | Whether to process in background. |\n+| tools | list[Any] | No | null | Tools are not supported yet. |\n+| previous_response_id | string | No | null | ID of previous response to continue conversation. For more, see [Continue conversations with response and session IDs](#response-id). |\n+| include | list[string] | No | null | Additional response data to include, such as `['tool_call.results']`. For more, see [Retrieve tool call results](#tool-call-results). |\n+\n+### Response body\n+\n+The response contains fields that Langflow sets dynamically and fields that use OpenAI-compatible defaults.\n+\n+The OpenAI-compatible default values shown above are currently fixed and cannot be modified via the request.\n+They are included to maintain API compatibility and provide a consistent response format.\n+\n+For your requests, you will only be setting the dynamic fields.\n+The default values are documented here for completeness and to show the full response structure.\n+\n+Fields set dynamically by Langflow:\n+\n+| Field | Type | Description |\n+|-------|------|-------------|\n+| id | string | Unique response identifier. |\n+| created_at | int | Unix timestamp of response creation. |\n+| model | string | The flow ID that was executed. |\n+| output | list[dict] | Array of output items (messages, tool calls, etc.). |\n+| previous_response_id | string | ID of previous response if continuing conversation. |\n+\n+<details closed>\n+<summary>Fields with OpenAI-compatible default values</summary>\n+\n+| Field | Type | Default Value | Description |\n+|-------|------|---------------|-------------|\n+| object | string | \"response\" | Always \"response\". |\n+| status | string | \"completed\" | Response status: \"completed\", \"in_progress\", or \"failed\". |\n+| error | dict | null | Error details (if any). |\n+| incomplete_details | dict | null | Incomplete response details (if any). |\n+| instructions | string | null | Response instructions (if any). |\n+| max_output_tokens | int | null | Maximum output tokens (if any). |\n+| parallel_tool_calls | boolean | true | Whether parallel tool calls are enabled. |\n+| reasoning | dict | `{\"effort\": null, \"summary\": null}` | Reasoning information with effort and summary. |\n+| store | boolean | true | Whether response is stored. |\n+| temperature | float | 1.0 | Temperature setting. |\n+| text | dict | `{\"format\": {\"type\": \"text\"}}` | Text format configuration. |\n+| tool_choice | string | \"auto\" | Tool choice setting. |\n+| tools | list[dict] | [] | Available tools. |\n+| top_p | float | 1.0 | Top-p setting. |\n+| truncation | string | \"disabled\" | Truncation setting. |\n+| usage | dict | null | Usage statistics (if any). |\n+| user | string | null | User identifier (if any). |\n+| metadata | dict | {} | Additional metadata. |\n+\n+</details>\n+\n+### Example streaming request\n+\n+When you set `\"stream\": true` with your request, the API returns a stream where each chunk contains a small piece of the response as it's generated. This provides a real-time experience where users can see the AI's output appear word by word, similar to ChatGPT's typing effect.\n+\n+```curl\n+curl -X POST \\\n+  \"$LANGFLOW_SERVER_URL/api/v1/responses\" \\\n+  -H \"x-api-key: $LANGFLOW_API_KEY\" \\\n+  -H \"Content-Type: application/json\" \\\n+  -d '{\n+    \"model\": \"$FLOW_ID\",\n+    \"input\": \"Tell me a story about a robot\",\n+    \"stream\": true\n+  }'\n+```\n+\n+<details closed>\n+<summary>Streaming response</summary>\n+\n+```json\n+{\n+  \"id\": \"f7fcea36-f128-41c4-9ac1-e683137375d5\",\n+  \"object\": \"response.chunk\",\n+  \"created\": 1756838094,\n+  \"model\": \"ced2ec91-f325-4bf0-8754-f3198c2b1563\",\n+  \"delta\": {\n+    \"content\": \"Once\"\n+  },\n+  \"status\": null\n+}\n+```\n+\n+</details>\n+### Streaming response body\n+\n+| Field | Type | Description |\n+|-------|------|-------------|\n+| id | string | Unique response identifier. |\n+| object | string | Always \"response.chunk\". |\n+| created | int | Unix timestamp of chunk creation. |\n+| model | string | The flow ID that was executed. |\n+| delta | dict | The new content chunk. |\n+| status | string | Response status: \"completed\", \"in_progress\", or \"failed\" (optional). |\n+\n+The stream continues until a final chunk with `\"status\": \"completed\"` indicates the response is finished.\n+\n+<details closed>\n+<summary>Final completion chunk</summary>\n+\n+```\n+{\n+  \"id\": \"f7fcea36-f128-41c4-9ac1-e683137375d5\",\n+  \"object\": \"response.chunk\",\n+  \"created\": 1756838094,\n+  \"model\": \"ced2ec91-f325-4bf0-8754-f3198c2b1563\",\n+  \"delta\": {},\n+  \"status\": \"completed\"\n+}\n+```\n+</details>\n+\n+## Retrieve tool call results {#tool-call-results}\n+\n+When you send a request to the `/api/v1/responses` endpoint to run a flow that includes tools or function calls, you can retrieve the raw tool execution details by adding `\"include\": [\"tool_call.results\"]` to the request payload.\n+\n+Without the `include` parameter, tool calls return basic function call information, but not the raw tool results, like this example:\n+\n+```json\n+{\n+  \"id\": \"fc_1\",\n+  \"type\": \"function_call\",\n+  \"status\": \"completed\",\n+  \"name\": \"evaluate_expression\",\n+  \"arguments\": \"{\\\"expression\\\": \\\"15*23\\\"}\"\n+},\n+```\n+\n+To get the raw `results` of each tool execution, add the line  `include: [\"tool_call.results\"]` to the request payload.\n+\n+```bash\n+curl -X POST \\\n+  \"http://LANGFLOW_SERVER_URL/api/v1/responses\" \\\n+  -H \"Content-Type: application/json\" \\\n+  -H \"x-api-key: $LANGFLOW_API_KEY\" \\\n+  -d '{\n+    \"model\": \"FLOW_ID\",\n+    \"input\": \"Calculate 25 * 13 and show me the result\",\n+    \"stream\": false,\n+    \"include\": [\"tool_call.results\"]\n+  }'\n+```\n+<details closed>\n+<summary>Response with results</summary>\n+\n+```json\n+{\n+  \"id\": \"a6e5511e-71f8-457a-88d2-7d8c6ea34e36\",\n+  \"object\": \"response\",\n+  \"created_at\": 1756835379,\n+  \"status\": \"completed\",\n+  \"error\": null,\n+  \"incomplete_details\": null,\n+  \"instructions\": null,\n+  \"max_output_tokens\": null,\n+  \"model\": \"ced2ec91-f325-4bf0-8754-f3198c2b1563\",\n+  \"output\": [\n+    {\n+      \"id\": \"evaluate_expression_1\",\n+      \"queries\": [\n+        \"45+67\"\n+      ],\n+      \"status\": \"completed\",\n+      \"tool_name\": \"evaluate_expression\",\n+      \"type\": \"tool_call\",\n+      \"results\": {\n+        \"result\": \"112\"\n+      }\n+    },\n+    {\n+      \"type\": \"message\",\n+      \"id\": \"msg_a6e5511e-71f8-457a-88d2-7d8c6ea34e36\",\n+      \"status\": \"completed\",\n+      \"role\": \"assistant\",\n+      \"content\": [\n+        {\n+          \"type\": \"output_text\",\n+          \"text\": \"The result of 45 + 67 is 112.\",\n+          \"annotations\": []\n+        }\n+      ]\n+    }\n+  ],\n+  \"parallel_tool_calls\": true,\n+  \"previous_response_id\": null,\n+  \"reasoning\": {\n+    \"effort\": null,\n+    \"summary\": null\n+  },\n+  \"store\": true,\n+  \"temperature\": 1.0,\n+  \"text\": {\n+    \"format\": {\n+      \"type\": \"text\"\n+    }\n+  },\n+  \"tool_choice\": \"auto\",\n+  \"tools\": [],\n+  \"top_p\": 1.0,\n+  \"truncation\": \"disabled\",\n+  \"usage\": null,\n+  \"user\": null,\n+  \"metadata\": {}\n+}\n+```\n+</details>\n+\n+The response now includes the tool call's results.\n+\n+```json\n+{\n+  \"id\": \"evaluate_expression_1\",\n+  \"type\": \"tool_call\",\n+  \"tool_name\": \"evaluate_expression\",\n+  \"queries\": [\"15*23\"],\n+  \"results\": {\"result\": \"112\"}\n+}\n+```\n+\n+## Pass global variables to your flows in headers\n+\n+Global variables allow you to pass dynamic values to your flows that can be used by components within that flow run.\n+This is useful for passing API keys, user IDs, or any other configuration that might change between requests.\n+\n+The `/responses` endpoint accepts global variables as custom HTTP headers with the format `X-LANGFLOW-GLOBAL-VAR-{VARIABLE_NAME}`.\n+Variable names are automatically converted to uppercase.\n+\n+Variables passed with `X-LANGFLOW-GLOBAL-VAR-{VARIABLE_NAME}` supersede database variables for a single flow run.\n+If no variable is found in the database, the flow will fail, unless the `FALLBACK_TO_ENV_VARS` environment variable is `true`, in which case the flow will use the variable set in the `.env` file.\n+\n+This example shows how global variables work for a single flow run. The variables are only available during that specific request execution and are not persisted.\n+\n+```bash\n+curl -X POST \\\n+  \"$LANGFLOW_SERVER_URL/api/v1/responses\" \\\n+  -H \"x-api-key: $LANGFLOW_API_KEY\" \\\n+  -H \"Content-Type: application/json\" \\\n+  -H \"X-LANGFLOW-GLOBAL-VAR-OPENAI_API_KEY: sk-...\" \\\n+  -H \"X-LANGFLOW-GLOBAL-VAR-USER_ID: user123\" \\\n+  -H \"X-LANGFLOW-GLOBAL-VAR-ENVIRONMENT: production\" \\\n+  -d '{\n+    \"model\": \"your-flow-id\",\n+    \"input\": \"Hello\"\n+  }'\n+```\n+\n+<details>\n+<summary>Response</summary>\n+\n+```json\n+{\n+  \"id\": \"4a4d2f24-bb45-4a55-a499-0191305264be\",\n+  \"object\": \"response\",\n+  \"created_at\": 1756839935,\n+  \"status\": \"completed\",\n+  \"model\": \"ced2ec91-f325-4bf0-8754-f3198c2b1563\",\n+  \"output\": [\n+    {\n+      \"type\": \"message\",\n+      \"id\": \"msg_4a4d2f24-bb45-4a55-a499-0191305264be\",\n+      \"status\": \"completed\",\n+      \"role\": \"assistant\",\n+      \"content\": [\n+        {\n+          \"type\": \"output_text\",\n+          \"text\": \"Hello! How can I assist you today?\",\n+          \"annotations\": []\n+        }\n+      ]\n+    }\n+  ],\n+  \"previous_response_id\": null\n+}\n+```\n+\n+</details>\n+\n+## Continue conversations with response and session IDs {#response-id}",
        "comment_created_at": "2025-09-02T20:14:04+00:00",
        "comment_author": "phact",
        "comment_body": "Maybe this should go higher up? In the bit where you say pass flow for model, you can say pass session_id for previous_response_id",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2298422453",
    "pr_number": 9442,
    "pr_file": "docs/docs/Integrations/Composio/integrations-composio.mdx",
    "created_at": "2025-08-25T15:25:09+00:00",
    "commented_code": "Instead of juggling multiple integrations and components in your flow, connect Composio components to an **Agent** component to use all of Composio's supported APIs and actions as tools for your agent.\n \n-The following components are available in the **Composio** bundle:\n-\n-* **Composio Tools**\n-* **GitHub**\n-* **Gmail**\n-* **Google Calendar**\n-* **Outlook**\n-* **Slack**\n+The Composio bundle includes a **Composio Tools** component that provides access to all Composio tools through a unified interface.",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2298422453",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9442,
        "pr_file": "docs/docs/Integrations/Composio/integrations-composio.mdx",
        "discussion_id": "2298422453",
        "commented_code": "@@ -7,14 +7,8 @@ Composio components in Langflow provide [Composio](https://app.composio.dev/) to\n \n Instead of juggling multiple integrations and components in your flow, connect Composio components to an **Agent** component to use all of Composio's supported APIs and actions as tools for your agent.\n \n-The following components are available in the **Composio** bundle:\n-\n-* **Composio Tools**\n-* **GitHub**\n-* **Gmail**\n-* **Google Calendar**\n-* **Outlook**\n-* **Slack**\n+The Composio bundle includes a **Composio Tools** component that provides access to all Composio tools through a unified interface.",
        "comment_created_at": "2025-08-25T15:25:09+00:00",
        "comment_author": "edwinjosechittilappilly",
        "comment_body": "Composio Tools may not have all tool. can you confirm that?\nIt would still be a limited subset.",
        "pr_file_module": null
      },
      {
        "comment_id": "2298896680",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9442,
        "pr_file": "docs/docs/Integrations/Composio/integrations-composio.mdx",
        "discussion_id": "2298422453",
        "commented_code": "@@ -7,14 +7,8 @@ Composio components in Langflow provide [Composio](https://app.composio.dev/) to\n \n Instead of juggling multiple integrations and components in your flow, connect Composio components to an **Agent** component to use all of Composio's supported APIs and actions as tools for your agent.\n \n-The following components are available in the **Composio** bundle:\n-\n-* **Composio Tools**\n-* **GitHub**\n-* **Gmail**\n-* **Google Calendar**\n-* **Outlook**\n-* **Slack**\n+The Composio bundle includes a **Composio Tools** component that provides access to all Composio tools through a unified interface.",
        "comment_created_at": "2025-08-25T19:11:36+00:00",
        "comment_author": "aimurphy",
        "comment_body": "\u2795  I think it depends on your composio api key.",
        "pr_file_module": null
      },
      {
        "comment_id": "2298922737",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9442,
        "pr_file": "docs/docs/Integrations/Composio/integrations-composio.mdx",
        "discussion_id": "2298422453",
        "commented_code": "@@ -7,14 +7,8 @@ Composio components in Langflow provide [Composio](https://app.composio.dev/) to\n \n Instead of juggling multiple integrations and components in your flow, connect Composio components to an **Agent** component to use all of Composio's supported APIs and actions as tools for your agent.\n \n-The following components are available in the **Composio** bundle:\n-\n-* **Composio Tools**\n-* **GitHub**\n-* **Gmail**\n-* **Google Calendar**\n-* **Outlook**\n-* **Slack**\n+The Composio bundle includes a **Composio Tools** component that provides access to all Composio tools through a unified interface.",
        "comment_created_at": "2025-08-25T19:21:01+00:00",
        "comment_author": "aimurphy",
        "comment_body": "Also, the description of the Composio Tools component needs to specify that it _only_ outputs `Tool`, and it can _only_ be used with a Tools input (which is only on the main Agent component and a few other less-common agent components).",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2306042506",
    "pr_number": 9442,
    "pr_file": "docs/docs/Integrations/Composio/integrations-composio.mdx",
    "created_at": "2025-08-28T03:10:57+00:00",
    "commented_code": "slug: /integrations-composio\n ---\n \n-Composio components in Langflow provide [Composio](https://app.composio.dev/) tools to your **Agent** components.\n+import Icon from \"@site/src/components/icon\";\n \n-Instead of juggling multiple integrations and components in your flow, connect Composio components to an **Agent** component to use all of Composio's supported APIs and actions as tools for your agent.\n+[Bundles](/components-bundle-components) contain custom components that support specific third-party integrations with Langflow.\n \n-The following components are available in the **Composio** bundle:\n+This page describes the components that are available in the **Composio** bundle.\n \n-* **Composio Tools**\n-* **GitHub**\n-* **Gmail**\n-* **Google Calendar**\n-* **Outlook**\n-* **Slack**\n+Composio components in Langflow provide [tools](https://app.composio.dev/) to your **Agent** components.\n+Individual services like Gmail, GitHub, and Slack are available as individual components.",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2306042506",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9442,
        "pr_file": "docs/docs/Integrations/Composio/integrations-composio.mdx",
        "discussion_id": "2306042506",
        "commented_code": "@@ -3,77 +3,82 @@ title: Composio\n slug: /integrations-composio\n ---\n \n-Composio components in Langflow provide [Composio](https://app.composio.dev/) tools to your **Agent** components.\n+import Icon from \"@site/src/components/icon\";\n \n-Instead of juggling multiple integrations and components in your flow, connect Composio components to an **Agent** component to use all of Composio's supported APIs and actions as tools for your agent.\n+[Bundles](/components-bundle-components) contain custom components that support specific third-party integrations with Langflow.\n \n-The following components are available in the **Composio** bundle:\n+This page describes the components that are available in the **Composio** bundle.\n \n-* **Composio Tools**\n-* **GitHub**\n-* **Gmail**\n-* **Google Calendar**\n-* **Outlook**\n-* **Slack**\n+Composio components in Langflow provide [tools](https://app.composio.dev/) to your **Agent** components.\n+Individual services like Gmail, GitHub, and Slack are available as individual components.",
        "comment_created_at": "2025-08-28T03:10:57+00:00",
        "comment_author": "aimurphy",
        "comment_body": "```suggestion\r\nComposio components in Langflow primarily serve as [tools](https://app.composio.dev/) for your **Agent** components.\r\n\r\nIndividual services like Gmail, GitHub, and Slack are also available as individual components.\r\nYou can use these components for non-agentic actions in your flows, or you can enable **Tool Mode** to use them as specialized tools for **Agent** components.\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2306008851",
    "pr_number": 9481,
    "pr_file": "docs/docs/Components/components-data.mdx",
    "created_at": "2025-08-28T02:54:06+00:00",
    "commented_code": "| ignore_unsupported_extensions | Ignore Unsupported Extensions | Input parameter. If enabled (true), files with unsupported extensions are accepted but not processed. If disabled (false), the **File** component either can throw an error if an unsupported file type is provided. The default is true. |\n | ignore_unspecified_files | Ignore Unspecified Files | Input parameter. If true, `Data` with no `file_path` property is ignored. If false (default), the component errors when a file isn't specified. |\n | concurrency_multithreading | Processing Concurrency | Input parameter. The number of files to process concurrently if multiple files are uploaded. Default is 1. Values greater than 1 enable parallel processing for 2 or more files. |\n+| markdown | Markdown Export | Input parameter. Export processed documents to Markdown format. Only available when advanced mode is enabled. Default is false. |\n+\n+### Advanced parsing\n+\n+In Langflow version 1.6, the **File** component supports advanced document parsing using the [Docling](https://docling-project.github.io/docling/) library.\n+Advanced parsing can process any of the **File** component's supported file types except `.csv`, `.xlsx`, and `.parquet` files.\n+\n+When advanced parsing is enabled, the File component processes only the first file from the uploaded files and ignores any additional files.\n+For processing multiple files with advanced parsing, use separate **File** components or use the dedicated [**Docling** components](/integrations-docling).\n+\n+The advanced parser option is automatically hidden when you select tabular data files, specifically `.csv`, `.xlsx`, and `.parquet`.\n+Advanced parsing is designed for document processing, such as extracting text from PDFs, rather than structured data analysis.\n+For structured data, use the [**Parser** component](/components-processing#parser).",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2306008851",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9481,
        "pr_file": "docs/docs/Components/components-data.mdx",
        "discussion_id": "2306008851",
        "commented_code": "@@ -170,22 +170,52 @@ You can toggle parameters through the <Icon name=\"SlidersHorizontal\" aria-hidden\n | ignore_unsupported_extensions | Ignore Unsupported Extensions | Input parameter. If enabled (true), files with unsupported extensions are accepted but not processed. If disabled (false), the **File** component either can throw an error if an unsupported file type is provided. The default is true. |\n | ignore_unspecified_files | Ignore Unspecified Files | Input parameter. If true, `Data` with no `file_path` property is ignored. If false (default), the component errors when a file isn't specified. |\n | concurrency_multithreading | Processing Concurrency | Input parameter. The number of files to process concurrently if multiple files are uploaded. Default is 1. Values greater than 1 enable parallel processing for 2 or more files. |\n+| markdown | Markdown Export | Input parameter. Export processed documents to Markdown format. Only available when advanced mode is enabled. Default is false. |\n+\n+### Advanced parsing\n+\n+In Langflow version 1.6, the **File** component supports advanced document parsing using the [Docling](https://docling-project.github.io/docling/) library.\n+Advanced parsing can process any of the **File** component's supported file types except `.csv`, `.xlsx`, and `.parquet` files.\n+\n+When advanced parsing is enabled, the File component processes only the first file from the uploaded files and ignores any additional files.\n+For processing multiple files with advanced parsing, use separate **File** components or use the dedicated [**Docling** components](/integrations-docling).\n+\n+The advanced parser option is automatically hidden when you select tabular data files, specifically `.csv`, `.xlsx`, and `.parquet`.\n+Advanced parsing is designed for document processing, such as extracting text from PDFs, rather than structured data analysis.\n+For structured data, use the [**Parser** component](/components-processing#parser).",
        "comment_created_at": "2025-08-28T02:54:06+00:00",
        "comment_author": "aimurphy",
        "comment_body": "```suggestion\r\n\r\n#### Advancing parsing limitations\r\n\r\nAdvanced parsing mode has the following restrictions:\r\n\r\n* **Only one file**: Advanced parsing mode processes only one file.\r\nIf you select multiple files, the **File** component processes the first file only, ignoring any additional files.\r\n\r\nTo process multiple files with advanced parsing, pass each file to a separate **File** components, or use the dedicated [**Docling** components](/integrations-docling).\r\n\r\n* **No tabular file types**:  Advanced parsing mode isn't available for tabular file types like `.csv`, `.xlsx`, and `.parquet`.\r\nAdvanced parsing is designed for document processing, such as extracting text from PDFs.\r\nFor structured data analysis, use the [**Parser** component](/components-processing#parser).\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2298501254",
    "pr_number": 9378,
    "pr_file": "docs/docs/Concepts/lfx-headless-runner.mdx",
    "created_at": "2025-08-25T16:01:50+00:00",
    "commented_code": "+---\n+title: Run flows with Langflow Executor (LFX)\n+slug: /lfx-headless-runner\n+---\n+\n+The Langflow Executor (LFX) is a command-line tool that serves and runs flows statelessly from [flow JSON files](/concepts-flows-import) with minimal dependencies.\n+\n+Flows are run without the flow builder UI or database, and any flow dependencies are automatically added to complete the run.\n+The flow graph is stored in memory at all times, so there is less overhead for loading the graph from a database.\n+\n+LFX includes two commands for executing flows.\n+\n+* [`lfx serve`](#serve): This command starts a FastAPI server with your flow available at `/flows/{flow_id}/run`.",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2298501254",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9378,
        "pr_file": "docs/docs/Concepts/lfx-headless-runner.mdx",
        "discussion_id": "2298501254",
        "commented_code": "@@ -0,0 +1,134 @@\n+---\n+title: Run flows with Langflow Executor (LFX)\n+slug: /lfx-headless-runner\n+---\n+\n+The Langflow Executor (LFX) is a command-line tool that serves and runs flows statelessly from [flow JSON files](/concepts-flows-import) with minimal dependencies.\n+\n+Flows are run without the flow builder UI or database, and any flow dependencies are automatically added to complete the run.\n+The flow graph is stored in memory at all times, so there is less overhead for loading the graph from a database.\n+\n+LFX includes two commands for executing flows.\n+\n+* [`lfx serve`](#serve): This command starts a FastAPI server with your flow available at `/flows/{flow_id}/run`.",
        "comment_created_at": "2025-08-25T16:01:50+00:00",
        "comment_author": "aimurphy",
        "comment_body": "Consider explicitly mentioning that it's a Langflow API endpoint hosted on a FastAPI server.\r\n\r\nalso consider linking to the reference page: https://docs.langflow.org/api-flows-run\r\n(And, you may want to link from /api-flows-run to this page as well. Possibly as a \"See also\".)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2274828163",
    "pr_number": 9384,
    "pr_file": "docs/docs/Concepts/concepts-file-management.mdx",
    "created_at": "2025-08-13T23:13:26+00:00",
    "commented_code": "### Load files at runtime\n \n You can use preloaded files in your flows, and you can load files at runtime, if your flow accepts file input.\n+To enable file input in your flow, do the following:\n+1. Add a [**File** component](/components-data#file) to your flow.\n+2. In the **API access** pane, click **Input Schema** to add `tweaks` to the request payload in the flow's code snippets.\n+3. In the **File** component's tweaks, under **Files**, enable the **Expose Input** toggle to expose the **Files** field as an API input.\n+4. The **API access** pane's code snippet is automatically updated to include the tweak to the **File** component.",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2274828163",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9384,
        "pr_file": "docs/docs/Concepts/concepts-file-management.mdx",
        "discussion_id": "2274828163",
        "commented_code": "@@ -54,6 +54,13 @@ For more information about the **File** component and other data loading compone\n ### Load files at runtime\n \n You can use preloaded files in your flows, and you can load files at runtime, if your flow accepts file input.\n+To enable file input in your flow, do the following:\n+1. Add a [**File** component](/components-data#file) to your flow.\n+2. In the **API access** pane, click **Input Schema** to add `tweaks` to the request payload in the flow's code snippets.\n+3. In the **File** component's tweaks, under **Files**, enable the **Expose Input** toggle to expose the **Files** field as an API input.\n+4. The **API access** pane's code snippet is automatically updated to include the tweak to the **File** component.",
        "comment_created_at": "2025-08-13T23:13:26+00:00",
        "comment_author": "aimurphy",
        "comment_body": "```suggestion\r\n4. Close the **Input Schema** pane to return to the **API access** pane.\r\nThe payload in each code snippet now includes `tweaks`, your **File** component's ID, and the `path` key that you enabled in **Input Schema**: \r\n\r\n    ```json\r\n    \"tweaks\": {\r\n\t    \"File-qYD5w\": {\r\n\t\t    \"path\": []\r\n\t    }\r\n\t}\r\n    ```\r\n\r\n5. When you run this flow programmatically, your script must upload a file to Langflow file management, and then pass the returned `file_path` to the `path` tweak in the `/run` request:\r\n\r\n    ```json\r\n    \"tweaks\": {\r\n        \"FILE_COMPONENT_ID\": {\r\n            \"path\": [ \"file_path\" ]\r\n        }\r\n    }\r\n    ```\r\n\r\n    For a complete example see [Create a chatbot that can ingest files](/chat-with-files) and [Files endpoints](/api-files).\r\n\r\n    If you want to upload multiple files, you can pass multiple `file_path` values in the `path` array, such as `[ \"path1\", \"path2\" ]`.\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2229288025",
    "pr_number": 9172,
    "pr_file": "docs/docs/Configuration/api-keys-and-authentication.mdx",
    "created_at": "2025-07-24T18:44:27+00:00",
    "commented_code": "+---\n+title: API keys and authentication\n+slug: /api-keys-and-authentication\n+---\n+\n+import Tabs from '@theme/Tabs';\n+import TabItem from '@theme/TabItem';\n+import Icon from \"@site/src/components/icon\";\n+\n+Langflow uses API keys and authentication to control and secure access to user data, flows, and administrative actions on the server.\n+\n+## Create a Langflow API key\n+\n+You can use Langflow API keys to interact with Langflow programmatically.\n+\n+The API key has the same permissions and access as you do when you launch Langflow. This means your API key can only access your own flows, components, and data. You cannot access other users' resources with your own Langflow API keys.\n+\n+An API key represents the user who created it. If you create a key as a superuser, then that key will have superuser privileges.\n+Anyone who has that key can authorize superuser actions through the Langflow API, including user management and flow management.\n+\n+In Langflow versions 1.5 and later, most API endpoints require a Langflow API key, even when `AUTO_LOGIN` is set to `True`.\n+The only exceptions are the MCP endpoints `/v1/mcp`, `/v1/mcp-projects`, and `/v2/mcp`, which never require authentication.\n+\n+<details>\n+<summary>LANGFLOW_AUTO_LOGIN and LANGFLOW_SKIP_AUTH_AUTO_LOGIN options</summary>\n+\n+In Langflow versions earlier than 1.5, if `LANGFLOW_AUTO_LOGIN=true`, then Langflow automatically logs users in as a superuser without requiring authentication.\n+In this case, API requests don't require a Langflow API key.\n+\n+In Langflow version 1.5, you can set `LANGFLOW_SKIP_AUTH_AUTO_LOGIN=true` and `LANGFLOW_AUTO_LOGIN=true` to skip authentication for API requests.\n+However, the `LANGFLOW_SKIP_AUTH_AUTO_LOGIN` option will be removed in a future release.\n+</details>\n+\n+You can generate a Langflow API key with the UI or the CLI.\n+\n+The UI-generated key is appropriate for most cases. The CLI-generated key is needed when your Langflow server is running in `--backend-only` mode.\n+\n+<Tabs>\n+  <TabItem value=\"Langflow UI\" label=\"Langflow UI\" default>\n+\n+    1. In the Langflow UI header, click your profile icon, and then select **Settings**.\n+    2. Click **Langflow API Keys**, and then click **Add New**.\n+    3. Name your key, and then click **Create API Key**.\n+    4. Copy the API key and store it securely.\n+\n+  </TabItem>\n+  <TabItem value=\"Langflow CLI\" label=\"Langflow CLI\">\n+\n+    If you're serving your flow with `--backend-only=true`, you can't create API keys in the UI, because the frontend is not running.\n+\n+    Depending on your authentication settings, note the following requirements for creating API keys with the Langflow CLI:\n+\n+    * If `AUTO_LOGIN` is `FALSE`, you must be logged in as a superuser.\n+    * If `AUTO LOGIN` is `TRUE`, you're already logged in as superuser.\n+\n+    To create an API key for a user from the CLI, do the following:\n+\n+    1. In your `.env` file, set `AUTO_LOGIN=FALSE`, and set superuser credentials for your server.\n+\n+        ```text\n+        LANGFLOW_AUTO_LOGIN=False\n+        LANGFLOW_SUPERUSER=administrator\n+        LANGFLOW_SUPERUSER_PASSWORD=securepassword\n+        ```\n+\n+    2. To confirm your superuser status, call [`GET /users/whoami`](/api-users#get-current-user), and then check that the response contains `\"is_superuser\": true`:\n+\n+        ```bash\n+        curl -X GET \\\n+          \"$LANGFLOW_URL/api/v1/users/whoami\" \\\n+          -H \"accept: application/json\" \\\n+          -H \"x-api-key: $LANGFLOW_API_KEY\"\n+        ```\n+\n+        <details closed>\n+        <summary>Result</summary>\n+\n+        ```json\n+        {\n+          \"id\": \"07e5b864-e367-4f52-b647-a48035ae7e5e\",\n+          \"username\": \"langflow\",\n+          \"profile_image\": null,\n+          \"store_api_key\": null,\n+          \"is_active\": true,\n+          \"is_superuser\": true,\n+          \"create_at\": \"2025-05-08T17:59:07.855965\",\n+          \"updated_at\": \"2025-05-29T15:06:56.157860\",\n+          \"last_login_at\": \"2025-05-29T15:06:56.157016\",\n+        }\n+        ```\n+\n+        </details>\n+\n+    3. Create an API key:\n+\n+        ```shell\n+        uv run langflow api-key\n+        ```\n+  </TabItem>\n+</Tabs>\n+\n+## Authenticate requests with the Langflow API key\n+\n+Include your API key in API requests to authenticate requests to Langflow.\n+\n+API keys allow access only to the flows and components of the specific user who created the key.\n+\n+<Tabs>\n+  <TabItem value=\"HTTP header\" label=\"HTTP header\" default>\n+\n+    To use the API key when making API requests, include the API key in the HTTP header:\n+\n+        ```shell\n+        curl -X POST \\\n+          \"http://LANGFLOW_SERVER_ADDRESS/api/v1/run/FLOW_ID?stream=false\" \\\n+          -H 'Content-Type: application/json' \\\n+          -H 'x-api-key: LANGFLOW_API_KEY' \\\n+          -d '{\"inputs\": {\"text\":\"\"}, \"tweaks\": {}}'\n+        ```\n+\n+  </TabItem>\n+  <TabItem value=\"Query parameter\" label=\"Query parameter\">\n+\n+    To pass the API key as a query parameter:\n+\n+        ```shell\n+        curl -X POST \\\n+          \"http://LANGFLOW_SERVER_ADDRESS/api/v1/run/FLOW_ID?x-api-key=LANGFLOW_API_KEY\" \\\n+          -H 'Content-Type: application/json' \\\n+          -d '{\"inputs\": {\"text\":\"\"}, \"tweaks\": {}}'\n+        ```\n+\n+  </TabItem>\n+</Tabs>\n+",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2229288025",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9172,
        "pr_file": "docs/docs/Configuration/api-keys-and-authentication.mdx",
        "discussion_id": "2229288025",
        "commented_code": "@@ -0,0 +1,338 @@\n+---\n+title: API keys and authentication\n+slug: /api-keys-and-authentication\n+---\n+\n+import Tabs from '@theme/Tabs';\n+import TabItem from '@theme/TabItem';\n+import Icon from \"@site/src/components/icon\";\n+\n+Langflow uses API keys and authentication to control and secure access to user data, flows, and administrative actions on the server.\n+\n+## Create a Langflow API key\n+\n+You can use Langflow API keys to interact with Langflow programmatically.\n+\n+The API key has the same permissions and access as you do when you launch Langflow. This means your API key can only access your own flows, components, and data. You cannot access other users' resources with your own Langflow API keys.\n+\n+An API key represents the user who created it. If you create a key as a superuser, then that key will have superuser privileges.\n+Anyone who has that key can authorize superuser actions through the Langflow API, including user management and flow management.\n+\n+In Langflow versions 1.5 and later, most API endpoints require a Langflow API key, even when `AUTO_LOGIN` is set to `True`.\n+The only exceptions are the MCP endpoints `/v1/mcp`, `/v1/mcp-projects`, and `/v2/mcp`, which never require authentication.\n+\n+<details>\n+<summary>LANGFLOW_AUTO_LOGIN and LANGFLOW_SKIP_AUTH_AUTO_LOGIN options</summary>\n+\n+In Langflow versions earlier than 1.5, if `LANGFLOW_AUTO_LOGIN=true`, then Langflow automatically logs users in as a superuser without requiring authentication.\n+In this case, API requests don't require a Langflow API key.\n+\n+In Langflow version 1.5, you can set `LANGFLOW_SKIP_AUTH_AUTO_LOGIN=true` and `LANGFLOW_AUTO_LOGIN=true` to skip authentication for API requests.\n+However, the `LANGFLOW_SKIP_AUTH_AUTO_LOGIN` option will be removed in a future release.\n+</details>\n+\n+You can generate a Langflow API key with the UI or the CLI.\n+\n+The UI-generated key is appropriate for most cases. The CLI-generated key is needed when your Langflow server is running in `--backend-only` mode.\n+\n+<Tabs>\n+  <TabItem value=\"Langflow UI\" label=\"Langflow UI\" default>\n+\n+    1. In the Langflow UI header, click your profile icon, and then select **Settings**.\n+    2. Click **Langflow API Keys**, and then click **Add New**.\n+    3. Name your key, and then click **Create API Key**.\n+    4. Copy the API key and store it securely.\n+\n+  </TabItem>\n+  <TabItem value=\"Langflow CLI\" label=\"Langflow CLI\">\n+\n+    If you're serving your flow with `--backend-only=true`, you can't create API keys in the UI, because the frontend is not running.\n+\n+    Depending on your authentication settings, note the following requirements for creating API keys with the Langflow CLI:\n+\n+    * If `AUTO_LOGIN` is `FALSE`, you must be logged in as a superuser.\n+    * If `AUTO LOGIN` is `TRUE`, you're already logged in as superuser.\n+\n+    To create an API key for a user from the CLI, do the following:\n+\n+    1. In your `.env` file, set `AUTO_LOGIN=FALSE`, and set superuser credentials for your server.\n+\n+        ```text\n+        LANGFLOW_AUTO_LOGIN=False\n+        LANGFLOW_SUPERUSER=administrator\n+        LANGFLOW_SUPERUSER_PASSWORD=securepassword\n+        ```\n+\n+    2. To confirm your superuser status, call [`GET /users/whoami`](/api-users#get-current-user), and then check that the response contains `\"is_superuser\": true`:\n+\n+        ```bash\n+        curl -X GET \\\n+          \"$LANGFLOW_URL/api/v1/users/whoami\" \\\n+          -H \"accept: application/json\" \\\n+          -H \"x-api-key: $LANGFLOW_API_KEY\"\n+        ```\n+\n+        <details closed>\n+        <summary>Result</summary>\n+\n+        ```json\n+        {\n+          \"id\": \"07e5b864-e367-4f52-b647-a48035ae7e5e\",\n+          \"username\": \"langflow\",\n+          \"profile_image\": null,\n+          \"store_api_key\": null,\n+          \"is_active\": true,\n+          \"is_superuser\": true,\n+          \"create_at\": \"2025-05-08T17:59:07.855965\",\n+          \"updated_at\": \"2025-05-29T15:06:56.157860\",\n+          \"last_login_at\": \"2025-05-29T15:06:56.157016\",\n+        }\n+        ```\n+\n+        </details>\n+\n+    3. Create an API key:\n+\n+        ```shell\n+        uv run langflow api-key\n+        ```\n+  </TabItem>\n+</Tabs>\n+\n+## Authenticate requests with the Langflow API key\n+\n+Include your API key in API requests to authenticate requests to Langflow.\n+\n+API keys allow access only to the flows and components of the specific user who created the key.\n+\n+<Tabs>\n+  <TabItem value=\"HTTP header\" label=\"HTTP header\" default>\n+\n+    To use the API key when making API requests, include the API key in the HTTP header:\n+\n+        ```shell\n+        curl -X POST \\\n+          \"http://LANGFLOW_SERVER_ADDRESS/api/v1/run/FLOW_ID?stream=false\" \\\n+          -H 'Content-Type: application/json' \\\n+          -H 'x-api-key: LANGFLOW_API_KEY' \\\n+          -d '{\"inputs\": {\"text\":\"\"}, \"tweaks\": {}}'\n+        ```\n+\n+  </TabItem>\n+  <TabItem value=\"Query parameter\" label=\"Query parameter\">\n+\n+    To pass the API key as a query parameter:\n+\n+        ```shell\n+        curl -X POST \\\n+          \"http://LANGFLOW_SERVER_ADDRESS/api/v1/run/FLOW_ID?x-api-key=LANGFLOW_API_KEY\" \\\n+          -H 'Content-Type: application/json' \\\n+          -d '{\"inputs\": {\"text\":\"\"}, \"tweaks\": {}}'\n+        ```\n+\n+  </TabItem>\n+</Tabs>\n+",
        "comment_created_at": "2025-07-24T18:44:27+00:00",
        "comment_author": "aimurphy",
        "comment_body": "As a nudge, I would include a couple links here:\r\n```suggestion\r\n\r\nFor more information about forming Langflow API requests, see [Get started with the Langflow API](/api-reference-api-examples) and [Trigger flows with the Langflow API](/concepts-publish).\r\n\r\n```\r\n\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2211141231",
    "pr_number": 9075,
    "pr_file": "docs/docs/Components/components-custom-components.mdx",
    "created_at": "2025-07-16T17:53:56+00:00",
    "commented_code": "]\n ```\n \n+#### Output Grouping Behavior with `group_outputs`\n+\n+By default, components in Langflow that define multiple outputs will display them as a dropdown in the UI. This behavior is controlled by the `group_outputs` parameter.\n+\n+- `group_outputs=False` (default):  \n+  When a component has more than one output and `group_outputs` is not specified (or set to `False`), the outputs are grouped into a dropdown. The user can choose only one output at a time from the UI.\n+\n+- `group_outputs=True`:  \n+  All outputs will be shown simultaneously in the UI. This is useful when the component is expected to return multiple values that should be used in parallel downstream.\n+\n+#### Example: \n+\n+1. `group_outputs=False` (default behavior)\n+\n+```python\n+outputs = [\n+    Output(\n+        name=\"structured_output\",\n+        display_name=\"Structured Output\",\n+        method=\"build_structured_output\",\n+    ),\n+    Output(\n+        name=\"dataframe_output\",\n+        display_name=\"DataFrame Output\",\n+        method=\"build_structured_dataframe\",\n+    ),\n+]\n+```\n+\n+In this example, both outputs will be available via a dropdown selection in the UI.\n+\n+Note: Since `group_outputs=False` is the default behavior, it does not need to be explicitly set in the component.\n+\n+2. `group_outputs=True`\n+\n+```python\n+outputs = [\n+    Output(\n+        name=\"true_result\",\n+        display_name=\"True\",\n+        method=\"true_response\",\n+        group_outputs=True,\n+    ),\n+    Output(\n+        name=\"false_result\",\n+        display_name=\"False\",\n+        method=\"false_response\",\n+        group_outputs=True,\n+    ),\n+]\n+```\n+\n+Here, both outputs will appear independently and be selectable directly in the UI.\n+\n+#### When to Use\n+\n+- Use group_outputs=False when the component is expected to return only one of the outputs depending on the flow logic.\n+\n+- Use group_outputs=True when the component should expose multiple outputs simultaneously, such as structured data and a table that are meant to be used in parallel.",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2211141231",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9075,
        "pr_file": "docs/docs/Components/components-custom-components.mdx",
        "discussion_id": "2211141231",
        "commented_code": "@@ -146,6 +146,66 @@ outputs = [\n ]\n ```\n \n+#### Output Grouping Behavior with `group_outputs`\n+\n+By default, components in Langflow that define multiple outputs will display them as a dropdown in the UI. This behavior is controlled by the `group_outputs` parameter.\n+\n+- `group_outputs=False` (default):  \n+  When a component has more than one output and `group_outputs` is not specified (or set to `False`), the outputs are grouped into a dropdown. The user can choose only one output at a time from the UI.\n+\n+- `group_outputs=True`:  \n+  All outputs will be shown simultaneously in the UI. This is useful when the component is expected to return multiple values that should be used in parallel downstream.\n+\n+#### Example: \n+\n+1. `group_outputs=False` (default behavior)\n+\n+```python\n+outputs = [\n+    Output(\n+        name=\"structured_output\",\n+        display_name=\"Structured Output\",\n+        method=\"build_structured_output\",\n+    ),\n+    Output(\n+        name=\"dataframe_output\",\n+        display_name=\"DataFrame Output\",\n+        method=\"build_structured_dataframe\",\n+    ),\n+]\n+```\n+\n+In this example, both outputs will be available via a dropdown selection in the UI.\n+\n+Note: Since `group_outputs=False` is the default behavior, it does not need to be explicitly set in the component.\n+\n+2. `group_outputs=True`\n+\n+```python\n+outputs = [\n+    Output(\n+        name=\"true_result\",\n+        display_name=\"True\",\n+        method=\"true_response\",\n+        group_outputs=True,\n+    ),\n+    Output(\n+        name=\"false_result\",\n+        display_name=\"False\",\n+        method=\"false_response\",\n+        group_outputs=True,\n+    ),\n+]\n+```\n+\n+Here, both outputs will appear independently and be selectable directly in the UI.\n+\n+#### When to Use\n+\n+- Use group_outputs=False when the component is expected to return only one of the outputs depending on the flow logic.\n+\n+- Use group_outputs=True when the component should expose multiple outputs simultaneously, such as structured data and a table that are meant to be used in parallel.",
        "comment_created_at": "2025-07-16T17:53:56+00:00",
        "comment_author": "mendonk",
        "comment_body": "```suggestion\r\n- Use `group_outputs=True` when the component should expose multiple outputs simultaneously, such as structured data and a table that are meant to be used in parallel.\r\n```",
        "pr_file_module": null
      }
    ]
  }
]