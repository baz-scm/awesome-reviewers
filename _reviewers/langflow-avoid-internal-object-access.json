[
  {
    "discussion_id": "2291893530",
    "pr_number": 9460,
    "pr_file": "src/backend/base/langflow/components/vlmrun/vlmrun_transcription.py",
    "created_at": "2025-08-21T18:58:06+00:00",
    "commented_code": "+from pathlib import Path\n+\n+from loguru import logger\n+\n+from langflow.custom.custom_component.component import Component\n+from langflow.io import (\n+    DropdownInput,\n+    FileInput,\n+    MessageTextInput,\n+    Output,\n+    SecretStrInput,\n+)\n+from langflow.schema.data import Data\n+\n+\n+class VLMRunTranscription(Component):\n+    display_name = \"VLM Run Transcription\"\n+    description = \"Extract structured data from audio and video using [VLM Run AI](https://app.vlm.run)\"\n+    documentation = \"https://docs.vlm.run\"\n+    icon = \"VLMRun\"\n+    beta = True\n+\n+    inputs = [\n+        SecretStrInput(\n+            name=\"api_key\",\n+            display_name=\"VLM Run API Key\",\n+            info=\"Get your API key from https://app.vlm.run\",\n+            required=True,\n+        ),\n+        DropdownInput(\n+            name=\"media_type\",\n+            display_name=\"Media Type\",\n+            options=[\"audio\", \"video\"],\n+            value=\"audio\",\n+            info=\"Select the type of media to process\",\n+        ),\n+        FileInput(\n+            name=\"media_files\",\n+            display_name=\"Media Files\",\n+            file_types=[\n+                \"mp3\",\n+                \"wav\",\n+                \"m4a\",\n+                \"flac\",\n+                \"ogg\",\n+                \"opus\",\n+                \"webm\",\n+                \"aac\",\n+                \"mp4\",\n+                \"mov\",\n+                \"avi\",\n+                \"mkv\",\n+                \"flv\",\n+                \"wmv\",\n+                \"m4v\",\n+            ],\n+            info=\"Upload one or more audio/video files\",\n+            required=False,\n+            is_list=True,\n+        ),\n+        MessageTextInput(\n+            name=\"media_url\",\n+            display_name=\"Media URL\",\n+            info=\"URL to media file (alternative to file upload)\",\n+            required=False,\n+            advanced=True,\n+        ),\n+    ]\n+\n+    outputs = [\n+        Output(\n+            display_name=\"Result\",\n+            name=\"result\",\n+            method=\"process_media\",\n+        ),\n+    ]\n+\n+    def _check_inputs(self) -> str | None:\n+        \"\"\"Validate that either media files or URL is provided.\"\"\"\n+        if not self.media_files and not self.media_url:\n+            return \"Either media files or media URL must be provided\"\n+        return None\n+\n+    def _import_vlmrun(self):\n+        \"\"\"Import and return VLMRun client class.\"\"\"\n+        try:\n+            from vlmrun.client import VLMRun\n+        except ImportError as e:\n+            error_msg = \"VLM Run SDK not installed. Run: pip install 'vlmrun[all]'\"\n+            raise ImportError(error_msg) from e\n+        else:\n+            return VLMRun\n+\n+    def _generate_media_response(self, client, media_source):\n+        \"\"\"Generate response for audio or video media.\"\"\"\n+        if self.media_type == \"audio\":\n+            if isinstance(media_source, Path):\n+                return client.audio.generate(file=media_source, domain=\"audio.transcription\", batch=True)\n+            return client.audio.generate(url=media_source, domain=\"audio.transcription\", batch=True)\n+        # video\n+        if isinstance(media_source, Path):\n+            return client.video.generate(file=media_source, domain=\"video.transcription\", batch=True)\n+        return client.video.generate(url=media_source, domain=\"video.transcription\", batch=True)\n+\n+    def _wait_for_response(self, client, response):\n+        \"\"\"Wait for batch processing to complete if needed.\"\"\"\n+        if hasattr(response, \"id\"):\n+            return client.predictions.wait(response.id, timeout=600)\n+        return response\n+\n+    def _extract_transcription(self, segments: list) -> list[str]:\n+        \"\"\"Extract transcription parts from segments.\"\"\"\n+        transcription_parts = []\n+        for segment in segments:\n+            if self.media_type == \"audio\" and \"audio\" in segment:\n+                transcription_parts.append(segment[\"audio\"].get(\"content\", \"\"))\n+            elif self.media_type == \"video\" and \"video\" in segment:\n+                transcription_parts.append(segment[\"video\"].get(\"content\", \"\"))\n+                # Also include audio if available for video\n+                if \"audio\" in segment:\n+                    audio_content = segment[\"audio\"].get(\"content\", \"\")\n+                    if audio_content and audio_content.strip():\n+                        transcription_parts.append(f\"[Audio: {audio_content}]\")\n+        return transcription_parts\n+\n+    def _create_result_dict(self, response, transcription_parts: list, source_name: str) -> dict:\n+        \"\"\"Create a standardized result dictionary.\"\"\"\n+        response_data = response.response if hasattr(response, \"response\") else {}\n+        result = {\n+            \"prediction_id\": response.id if hasattr(response, \"id\") else None,\n+            \"transcription\": \" \".join(transcription_parts),\n+            \"full_response\": response_data,\n+            \"metadata\": {\n+                \"media_type\": self.media_type,\n+                \"duration\": response_data.get(\"metadata\", {}).get(\"duration\", 0),\n+            },\n+            \"usage\": response.usage.__dict__ if hasattr(response, \"usage\") else None,",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2291893530",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9460,
        "pr_file": "src/backend/base/langflow/components/vlmrun/vlmrun_transcription.py",
        "discussion_id": "2291893530",
        "commented_code": "@@ -0,0 +1,215 @@\n+from pathlib import Path\n+\n+from loguru import logger\n+\n+from langflow.custom.custom_component.component import Component\n+from langflow.io import (\n+    DropdownInput,\n+    FileInput,\n+    MessageTextInput,\n+    Output,\n+    SecretStrInput,\n+)\n+from langflow.schema.data import Data\n+\n+\n+class VLMRunTranscription(Component):\n+    display_name = \"VLM Run Transcription\"\n+    description = \"Extract structured data from audio and video using [VLM Run AI](https://app.vlm.run)\"\n+    documentation = \"https://docs.vlm.run\"\n+    icon = \"VLMRun\"\n+    beta = True\n+\n+    inputs = [\n+        SecretStrInput(\n+            name=\"api_key\",\n+            display_name=\"VLM Run API Key\",\n+            info=\"Get your API key from https://app.vlm.run\",\n+            required=True,\n+        ),\n+        DropdownInput(\n+            name=\"media_type\",\n+            display_name=\"Media Type\",\n+            options=[\"audio\", \"video\"],\n+            value=\"audio\",\n+            info=\"Select the type of media to process\",\n+        ),\n+        FileInput(\n+            name=\"media_files\",\n+            display_name=\"Media Files\",\n+            file_types=[\n+                \"mp3\",\n+                \"wav\",\n+                \"m4a\",\n+                \"flac\",\n+                \"ogg\",\n+                \"opus\",\n+                \"webm\",\n+                \"aac\",\n+                \"mp4\",\n+                \"mov\",\n+                \"avi\",\n+                \"mkv\",\n+                \"flv\",\n+                \"wmv\",\n+                \"m4v\",\n+            ],\n+            info=\"Upload one or more audio/video files\",\n+            required=False,\n+            is_list=True,\n+        ),\n+        MessageTextInput(\n+            name=\"media_url\",\n+            display_name=\"Media URL\",\n+            info=\"URL to media file (alternative to file upload)\",\n+            required=False,\n+            advanced=True,\n+        ),\n+    ]\n+\n+    outputs = [\n+        Output(\n+            display_name=\"Result\",\n+            name=\"result\",\n+            method=\"process_media\",\n+        ),\n+    ]\n+\n+    def _check_inputs(self) -> str | None:\n+        \"\"\"Validate that either media files or URL is provided.\"\"\"\n+        if not self.media_files and not self.media_url:\n+            return \"Either media files or media URL must be provided\"\n+        return None\n+\n+    def _import_vlmrun(self):\n+        \"\"\"Import and return VLMRun client class.\"\"\"\n+        try:\n+            from vlmrun.client import VLMRun\n+        except ImportError as e:\n+            error_msg = \"VLM Run SDK not installed. Run: pip install 'vlmrun[all]'\"\n+            raise ImportError(error_msg) from e\n+        else:\n+            return VLMRun\n+\n+    def _generate_media_response(self, client, media_source):\n+        \"\"\"Generate response for audio or video media.\"\"\"\n+        if self.media_type == \"audio\":\n+            if isinstance(media_source, Path):\n+                return client.audio.generate(file=media_source, domain=\"audio.transcription\", batch=True)\n+            return client.audio.generate(url=media_source, domain=\"audio.transcription\", batch=True)\n+        # video\n+        if isinstance(media_source, Path):\n+            return client.video.generate(file=media_source, domain=\"video.transcription\", batch=True)\n+        return client.video.generate(url=media_source, domain=\"video.transcription\", batch=True)\n+\n+    def _wait_for_response(self, client, response):\n+        \"\"\"Wait for batch processing to complete if needed.\"\"\"\n+        if hasattr(response, \"id\"):\n+            return client.predictions.wait(response.id, timeout=600)\n+        return response\n+\n+    def _extract_transcription(self, segments: list) -> list[str]:\n+        \"\"\"Extract transcription parts from segments.\"\"\"\n+        transcription_parts = []\n+        for segment in segments:\n+            if self.media_type == \"audio\" and \"audio\" in segment:\n+                transcription_parts.append(segment[\"audio\"].get(\"content\", \"\"))\n+            elif self.media_type == \"video\" and \"video\" in segment:\n+                transcription_parts.append(segment[\"video\"].get(\"content\", \"\"))\n+                # Also include audio if available for video\n+                if \"audio\" in segment:\n+                    audio_content = segment[\"audio\"].get(\"content\", \"\")\n+                    if audio_content and audio_content.strip():\n+                        transcription_parts.append(f\"[Audio: {audio_content}]\")\n+        return transcription_parts\n+\n+    def _create_result_dict(self, response, transcription_parts: list, source_name: str) -> dict:\n+        \"\"\"Create a standardized result dictionary.\"\"\"\n+        response_data = response.response if hasattr(response, \"response\") else {}\n+        result = {\n+            \"prediction_id\": response.id if hasattr(response, \"id\") else None,\n+            \"transcription\": \" \".join(transcription_parts),\n+            \"full_response\": response_data,\n+            \"metadata\": {\n+                \"media_type\": self.media_type,\n+                \"duration\": response_data.get(\"metadata\", {}).get(\"duration\", 0),\n+            },\n+            \"usage\": response.usage.__dict__ if hasattr(response, \"usage\") else None,",
        "comment_created_at": "2025-08-21T18:58:06+00:00",
        "comment_author": "dineshreddy91",
        "comment_body": "Avoid response.usage.__dict__\u2014prefer a stable method if provided (e.g., model_dump() or asdict()), or explicitly map known fields to a dict to avoid coupling to object internals.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2291801341",
    "pr_number": 9398,
    "pr_file": "src/backend/base/langflow/components/data/file.py",
    "created_at": "2025-08-21T18:11:53+00:00",
    "commented_code": "info=\"When multiple files are being processed, the number of files to process concurrently.\",\n             value=1,\n         ),\n+        BoolInput(\n+            name=\"markdown\",\n+            display_name=\"Markdown Export\",\n+            info=\"Export processed documents to Markdown format. Only available when advanced mode is enabled.\",\n+            value=False,\n+            show=False,\n+        ),\n     ]\n \n     outputs = [\n-        Output(display_name=\"Raw Content\", name=\"message\", method=\"load_files_message\"),\n+        *BaseFileComponent._base_outputs,\n     ]",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2291801341",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9398,
        "pr_file": "src/backend/base/langflow/components/data/file.py",
        "discussion_id": "2291801341",
        "commented_code": "@@ -45,60 +188,284 @@ class FileComponent(BaseFileComponent):\n             info=\"When multiple files are being processed, the number of files to process concurrently.\",\n             value=1,\n         ),\n+        BoolInput(\n+            name=\"markdown\",\n+            display_name=\"Markdown Export\",\n+            info=\"Export processed documents to Markdown format. Only available when advanced mode is enabled.\",\n+            value=False,\n+            show=False,\n+        ),\n     ]\n \n     outputs = [\n-        Output(display_name=\"Raw Content\", name=\"message\", method=\"load_files_message\"),\n+        *BaseFileComponent._base_outputs,\n     ]",
        "comment_created_at": "2025-08-21T18:11:53+00:00",
        "comment_author": "ogabrielluiz",
        "comment_body": "nit\n```suggestion\noutputs = BaseFileComponent._base_outputs\n```",
        "pr_file_module": null
      }
    ]
  }
]