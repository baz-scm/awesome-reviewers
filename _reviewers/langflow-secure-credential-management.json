[
  {
    "discussion_id": "2240853345",
    "pr_number": 9226,
    "pr_file": "docs/docs/Deployment/deployment-prod-best-practices.mdx",
    "created_at": "2025-07-29T20:06:09+00:00",
    "commented_code": "* **Resource allocation**\n   * **Optimized resource usage and cost efficiency**: By separating the two environments, you can allocate resources more effectively. Each flow can be deployed independently, providing fine-grained resource control.\n   * **Scalability**: The runtime environment can be scaled independently based on application load and performance requirements, without affecting the development environment.\n+\n+## Scaling Resources\n+\n+Langflow's resource requirements vary depending on whether you're deploying the IDE for development or the runtime for production flows. Below are detailed strategies for scaling RAM, disk, instances, and users per instance.\n+\n+**IDE vs. Runtime**:\n+\n+* **IDE**: Deploy for developers using the UI. Requires frontend (512Mi RAM, 0.3 CPU) and backend (1Gi RAM, 0.5 CPU) services.\n+* **Runtime**: Deploy for production flows. Headless, requiring 2Gi RAM and 1 CPU per instance, focused on API endpoints.\n+\n+### Example Resource Configuration\n+\n+| Component | RAM Request | CPU Request | Replica Count | Notes |\n+|-----------|-------------|-------------|---------------|-------|\n+| IDE Backend | 1Gi | 0.5 | 1 | Scale replicas for more developers. |\n+| IDE Frontend | 512Mi | 0.3 | 1 | Adjust based on UI load. |\n+| Runtime | 2Gi | 1000m | 3 | Use HPA for dynamic scaling. |\n+| PostgreSQL | 4Gi | 2 | 1+ | Use replication for high availability. |\n+\n+### RAM\n+\n+**Overview**: RAM usage in Langflow depends on flow complexity, the size of language models, and concurrent request volume. The runtime, used for production flows, has a baseline requirement, while the IDE (for developers) requires additional resources for the frontend and backend.\n+\n+**Base Requirements**:\n+\n+* **Runtime**: 2Gi per instance.\n+* **IDE Backend**: 1Gi per instance.\n+* **IDE Frontend**: 512Mi per instance.\n+\n+**Factors Affecting RAM Usage**:\n+\n+* **Flow Complexity**: Flows with many nodes or large datasets (e.g., RAG pipelines) increase memory needs.\n+* **Language Models**: Larger LLMs or embeddings loaded in-memory consume significant RAM.\n+* **Concurrent Requests**: More simultaneous API calls or UI sessions require additional memory.\n+\n+**Scaling Recommendations**:\n+\n+* Start with 2Gi for runtime instances and 1.5Gi total (1Gi backend + 512Mi frontend) for IDE instances.\n+* Monitor memory usage with tools like Prometheus to identify bottlenecks.\n+* Adjust memory requests and limits in Kubernetes. For example:\n+\n+    ```yaml\n+    resources:\n+      requests:\n+        memory: \"2Gi\"\n+        cpu: \"1000m\"\n+      limits:\n+        memory: \"4Gi\"\n+        cpu: \"2000m\"\n+    ```\n+\n+* For intensive use (e.g., multi-core CPU setups), allocate 4Gi or more per instance.\n+\n+### Disk\n+\n+**Overview**: Disk storage is used for the SQLite or PostgreSQL database and file storage for large files, such as documents for RAG. The database stores flow configurations, user data, and settings, while files are managed on disk.\n+\n+**Usage**:\n+\n+* **Database**: Stores flow definitions, user profiles, and logs. Size depends on the number of flows and users.\n+* **File Storage**: Large files are stored in directories like `/opt/langflow/data/` or `.cache/langflow/`.\n+\n+**Scaling Recommendations**:\n+\n+* Use an external PostgreSQL database for production to improve scalability and reliability.\n+* Configure shared file storage such as NFS or cloud storage for multi-instance setups to ensure file access across replicas.\n+* Estimate initial database size based on expected flows and users, such as 10GB for moderate use, and monitor growth.\n+* Use Persistent Volumes in Kubernetes for database and file storage, with dynamic provisioning for scalability.\n+\n+### Instances\n+\n+**Overview**: Scaling instances involves adding more replicas to handle increased load, applicable to both IDE and runtime deployments. Horizontal scaling is preferred for production environments.\n+\n+**Base Configuration**:\n+\n+* **Runtime**: Default replica count of 3.\n+* **IDE**: Default replica count of 1 for both backend and frontend.\n+\n+**Scaling Recommendations**:\n+\n+* Implement Horizontal Pod Autoscaler (HPA) in Kubernetes to dynamically adjust replicas based on CPU or memory usage. Example HPA configuration:\n+\n+    ```yaml\n+    apiVersion: autoscaling/v2\n+    kind: HorizontalPodAutoscaler\n+    metadata:\n+      name: langflow-runtime-hpa\n+    spec:\n+      scaleTargetRef:\n+        apiVersion: apps/v1\n+        kind: Deployment\n+        name: langflow-runtime\n+      minReplicas: 1\n+      maxReplicas: 10\n+      metrics:\n+      - type: Resource\n+        resource:\n+          name: cpu\n+          target:\n+            type: Utilization\n+            averageUtilization: 80\n+    ```\n+\n+* For bursty workloads, such as 100,000s of tokens per second, ensure sufficient replicas to handle spikes.\n+* Vertically scale by increasing CPU/memory requests for complex flows, but prioritize horizontal scaling for reliability.\n+\n+### Users per Instance\n+\n+**Overview**: The number of users or requests per instance depends on whether you're supporting developers via the IDE or API clients via the runtime.\n+\n+**UI (IDE)**:\n+\n+* Each developer using the UI generates requests to the backend, requiring resources for session handling.\n+* Scale backend replicas based on concurrent developers (e.g., 1 replica per 10-20 developers, adjusted via load testing).\n+\n+**Production Flows (Runtime)**:\n+\n+* Users are typically API clients making requests to flow endpoints.\n+* Capacity depends on request rate and flow complexity. For example, a single instance with 2vCPUs and 2GB RAM can handle ~30 concurrent connections for simple flows.\n+* Perform load testing to determine the number of requests per instance and scale replicas accordingly.\n+\n+**Scaling Recommendations**:\n+\n+* Use load balancers to distribute requests across replicas.\n+* Monitor API request rates and response times to adjust replica counts.\n+* For IDE, ensure frontend and backend replicas are balanced to avoid bottlenecks.\n+\n+## Failure Points\n+\n+Langflow's reliability in production depends on mitigating key failure points, particularly around the database, file system, and instance availability.\n+\n+**Database Failure**:\n+\n+* **Impact**: Disrupts flow retrieval, saving, user authentication, user management, project collection access, configuration updates, and log writing.\n+* **Mitigation**: Use a replicated PostgreSQL setup with high availability and regular backups. Flows already loaded in memory may continue to function.\n+\n+**File System Issues**:\n+\n+* **Impact**: Concurrency issues in file caching, such as `/app/data/.cache`, can cause IO errors in multi-instance setups.\n+* **Mitigation**: Use a shared, POSIX-compliant file system or cloud storage. Avoid ramdisk solutions due to data loss on container shutdown.\n+\n+**Instance Failures**:\n+\n+* **Impact**: A single instance failure can disrupt service if not replicated.\n+* **Mitigation**: Deploy multiple replicas with Kubernetes to ensure availability. Use health checks to detect and replace failed pods.\n+\n+**Network and Dependency Failures**:\n+\n+* **Impact**: External APIs or services used in flows may fail, causing flow errors.\n+* **Mitigation**: Implement retry logic and error handling in flows. Monitor network latency and dependency health.\n+\n+## Monitoring Recommendations\n+\n+Effective monitoring ensures Langflow operates reliably and performs well under varying loads.\n+\n+**Database Health**:\n+\n+* Monitor availability, query performance, and resource usage (CPU, memory, disk).\n+* Use tools like pgAdmin or cloud-native monitoring for PostgreSQL.\n+\n+**Application Logs**:\n+\n+* Collect and analyze logs for errors, warnings, and flow execution issues.\n+* Centralize logs using tools like ELK Stack or Fluentd.\n+\n+**Resource Usage**:\n+\n+* Track CPU, memory, and disk usage of Langflow instances.\n+* Use Prometheus and Grafana for real-time monitoring in Kubernetes.\n+\n+**API Performance**:\n+\n+* Monitor response times, error rates, and request throughput.\n+* Set alerts for high latency or error spikes.\n+\n+**Observability Tools**:\n+\n+* Integrate with LangSmith or LangFuse for detailed flow tracing and metrics.\n+* Use these tools to debug flow performance and optimize execution.\n+\n+**Example Monitoring Setup**:\n+\n+* Deploy Prometheus for metrics collection.\n+* Use Grafana dashboards to visualize resource usage and API performance.\n+* Configure alerts for critical thresholds (e.g., 90% memory usage, 500ms API latency).\n+\n+## Security Implications\n+\n+Running Langflow in production requires robust security measures to protect the application, data, and users.\n+\n+**Container Security**:\n+\n+* Enable `readOnlyRootFilesystem: true` in runtime containers to prevent unauthorized modifications.\n+* Only disable if necessary and with compensating controls.\n+\n+**Secret Management**:\n+\n+* Store sensitive data like API keys in Kubernetes secrets or external secret managers.\n+* Avoid embedding secrets in flow JSON files.\n+\n+**Authentication and Authorization**:\n+\n+* Implement strong authentication for the IDE UI and runtime API like OAuth or API tokens.\n+* Enforce role-based access control to limit user permissions.\n+\n+**Data Privacy**:\n+\n+* Ensure compliance with regulations like GDPR if handling personal data.\n+* Encrypt sensitive data at rest and in transit.\n+\n+**Encryption**:\n+\n+* Use HTTPS for all communications to secure data in transit.\n+* Configure TLS for PostgreSQL connections.\n+\n+**Additional Security Measures**:\n+",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2240853345",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9226,
        "pr_file": "docs/docs/Deployment/deployment-prod-best-practices.mdx",
        "discussion_id": "2240853345",
        "commented_code": "@@ -57,3 +57,223 @@ This separation is designed to enhance security, optimize resource allocation, a\n * **Resource allocation**\n   * **Optimized resource usage and cost efficiency**: By separating the two environments, you can allocate resources more effectively. Each flow can be deployed independently, providing fine-grained resource control.\n   * **Scalability**: The runtime environment can be scaled independently based on application load and performance requirements, without affecting the development environment.\n+\n+## Scaling Resources\n+\n+Langflow's resource requirements vary depending on whether you're deploying the IDE for development or the runtime for production flows. Below are detailed strategies for scaling RAM, disk, instances, and users per instance.\n+\n+**IDE vs. Runtime**:\n+\n+* **IDE**: Deploy for developers using the UI. Requires frontend (512Mi RAM, 0.3 CPU) and backend (1Gi RAM, 0.5 CPU) services.\n+* **Runtime**: Deploy for production flows. Headless, requiring 2Gi RAM and 1 CPU per instance, focused on API endpoints.\n+\n+### Example Resource Configuration\n+\n+| Component | RAM Request | CPU Request | Replica Count | Notes |\n+|-----------|-------------|-------------|---------------|-------|\n+| IDE Backend | 1Gi | 0.5 | 1 | Scale replicas for more developers. |\n+| IDE Frontend | 512Mi | 0.3 | 1 | Adjust based on UI load. |\n+| Runtime | 2Gi | 1000m | 3 | Use HPA for dynamic scaling. |\n+| PostgreSQL | 4Gi | 2 | 1+ | Use replication for high availability. |\n+\n+### RAM\n+\n+**Overview**: RAM usage in Langflow depends on flow complexity, the size of language models, and concurrent request volume. The runtime, used for production flows, has a baseline requirement, while the IDE (for developers) requires additional resources for the frontend and backend.\n+\n+**Base Requirements**:\n+\n+* **Runtime**: 2Gi per instance.\n+* **IDE Backend**: 1Gi per instance.\n+* **IDE Frontend**: 512Mi per instance.\n+\n+**Factors Affecting RAM Usage**:\n+\n+* **Flow Complexity**: Flows with many nodes or large datasets (e.g., RAG pipelines) increase memory needs.\n+* **Language Models**: Larger LLMs or embeddings loaded in-memory consume significant RAM.\n+* **Concurrent Requests**: More simultaneous API calls or UI sessions require additional memory.\n+\n+**Scaling Recommendations**:\n+\n+* Start with 2Gi for runtime instances and 1.5Gi total (1Gi backend + 512Mi frontend) for IDE instances.\n+* Monitor memory usage with tools like Prometheus to identify bottlenecks.\n+* Adjust memory requests and limits in Kubernetes. For example:\n+\n+    ```yaml\n+    resources:\n+      requests:\n+        memory: \"2Gi\"\n+        cpu: \"1000m\"\n+      limits:\n+        memory: \"4Gi\"\n+        cpu: \"2000m\"\n+    ```\n+\n+* For intensive use (e.g., multi-core CPU setups), allocate 4Gi or more per instance.\n+\n+### Disk\n+\n+**Overview**: Disk storage is used for the SQLite or PostgreSQL database and file storage for large files, such as documents for RAG. The database stores flow configurations, user data, and settings, while files are managed on disk.\n+\n+**Usage**:\n+\n+* **Database**: Stores flow definitions, user profiles, and logs. Size depends on the number of flows and users.\n+* **File Storage**: Large files are stored in directories like `/opt/langflow/data/` or `.cache/langflow/`.\n+\n+**Scaling Recommendations**:\n+\n+* Use an external PostgreSQL database for production to improve scalability and reliability.\n+* Configure shared file storage such as NFS or cloud storage for multi-instance setups to ensure file access across replicas.\n+* Estimate initial database size based on expected flows and users, such as 10GB for moderate use, and monitor growth.\n+* Use Persistent Volumes in Kubernetes for database and file storage, with dynamic provisioning for scalability.\n+\n+### Instances\n+\n+**Overview**: Scaling instances involves adding more replicas to handle increased load, applicable to both IDE and runtime deployments. Horizontal scaling is preferred for production environments.\n+\n+**Base Configuration**:\n+\n+* **Runtime**: Default replica count of 3.\n+* **IDE**: Default replica count of 1 for both backend and frontend.\n+\n+**Scaling Recommendations**:\n+\n+* Implement Horizontal Pod Autoscaler (HPA) in Kubernetes to dynamically adjust replicas based on CPU or memory usage. Example HPA configuration:\n+\n+    ```yaml\n+    apiVersion: autoscaling/v2\n+    kind: HorizontalPodAutoscaler\n+    metadata:\n+      name: langflow-runtime-hpa\n+    spec:\n+      scaleTargetRef:\n+        apiVersion: apps/v1\n+        kind: Deployment\n+        name: langflow-runtime\n+      minReplicas: 1\n+      maxReplicas: 10\n+      metrics:\n+      - type: Resource\n+        resource:\n+          name: cpu\n+          target:\n+            type: Utilization\n+            averageUtilization: 80\n+    ```\n+\n+* For bursty workloads, such as 100,000s of tokens per second, ensure sufficient replicas to handle spikes.\n+* Vertically scale by increasing CPU/memory requests for complex flows, but prioritize horizontal scaling for reliability.\n+\n+### Users per Instance\n+\n+**Overview**: The number of users or requests per instance depends on whether you're supporting developers via the IDE or API clients via the runtime.\n+\n+**UI (IDE)**:\n+\n+* Each developer using the UI generates requests to the backend, requiring resources for session handling.\n+* Scale backend replicas based on concurrent developers (e.g., 1 replica per 10-20 developers, adjusted via load testing).\n+\n+**Production Flows (Runtime)**:\n+\n+* Users are typically API clients making requests to flow endpoints.\n+* Capacity depends on request rate and flow complexity. For example, a single instance with 2vCPUs and 2GB RAM can handle ~30 concurrent connections for simple flows.\n+* Perform load testing to determine the number of requests per instance and scale replicas accordingly.\n+\n+**Scaling Recommendations**:\n+\n+* Use load balancers to distribute requests across replicas.\n+* Monitor API request rates and response times to adjust replica counts.\n+* For IDE, ensure frontend and backend replicas are balanced to avoid bottlenecks.\n+\n+## Failure Points\n+\n+Langflow's reliability in production depends on mitigating key failure points, particularly around the database, file system, and instance availability.\n+\n+**Database Failure**:\n+\n+* **Impact**: Disrupts flow retrieval, saving, user authentication, user management, project collection access, configuration updates, and log writing.\n+* **Mitigation**: Use a replicated PostgreSQL setup with high availability and regular backups. Flows already loaded in memory may continue to function.\n+\n+**File System Issues**:\n+\n+* **Impact**: Concurrency issues in file caching, such as `/app/data/.cache`, can cause IO errors in multi-instance setups.\n+* **Mitigation**: Use a shared, POSIX-compliant file system or cloud storage. Avoid ramdisk solutions due to data loss on container shutdown.\n+\n+**Instance Failures**:\n+\n+* **Impact**: A single instance failure can disrupt service if not replicated.\n+* **Mitigation**: Deploy multiple replicas with Kubernetes to ensure availability. Use health checks to detect and replace failed pods.\n+\n+**Network and Dependency Failures**:\n+\n+* **Impact**: External APIs or services used in flows may fail, causing flow errors.\n+* **Mitigation**: Implement retry logic and error handling in flows. Monitor network latency and dependency health.\n+\n+## Monitoring Recommendations\n+\n+Effective monitoring ensures Langflow operates reliably and performs well under varying loads.\n+\n+**Database Health**:\n+\n+* Monitor availability, query performance, and resource usage (CPU, memory, disk).\n+* Use tools like pgAdmin or cloud-native monitoring for PostgreSQL.\n+\n+**Application Logs**:\n+\n+* Collect and analyze logs for errors, warnings, and flow execution issues.\n+* Centralize logs using tools like ELK Stack or Fluentd.\n+\n+**Resource Usage**:\n+\n+* Track CPU, memory, and disk usage of Langflow instances.\n+* Use Prometheus and Grafana for real-time monitoring in Kubernetes.\n+\n+**API Performance**:\n+\n+* Monitor response times, error rates, and request throughput.\n+* Set alerts for high latency or error spikes.\n+\n+**Observability Tools**:\n+\n+* Integrate with LangSmith or LangFuse for detailed flow tracing and metrics.\n+* Use these tools to debug flow performance and optimize execution.\n+\n+**Example Monitoring Setup**:\n+\n+* Deploy Prometheus for metrics collection.\n+* Use Grafana dashboards to visualize resource usage and API performance.\n+* Configure alerts for critical thresholds (e.g., 90% memory usage, 500ms API latency).\n+\n+## Security Implications\n+\n+Running Langflow in production requires robust security measures to protect the application, data, and users.\n+\n+**Container Security**:\n+\n+* Enable `readOnlyRootFilesystem: true` in runtime containers to prevent unauthorized modifications.\n+* Only disable if necessary and with compensating controls.\n+\n+**Secret Management**:\n+\n+* Store sensitive data like API keys in Kubernetes secrets or external secret managers.\n+* Avoid embedding secrets in flow JSON files.\n+\n+**Authentication and Authorization**:\n+\n+* Implement strong authentication for the IDE UI and runtime API like OAuth or API tokens.\n+* Enforce role-based access control to limit user permissions.\n+\n+**Data Privacy**:\n+\n+* Ensure compliance with regulations like GDPR if handling personal data.\n+* Encrypt sensitive data at rest and in transit.\n+\n+**Encryption**:\n+\n+* Use HTTPS for all communications to secure data in transit.\n+* Configure TLS for PostgreSQL connections.\n+\n+**Additional Security Measures**:\n+",
        "comment_created_at": "2025-07-29T20:06:09+00:00",
        "comment_author": "aimurphy",
        "comment_body": "```suggestion\r\n### Container security\r\n\r\n* Enable `readOnlyRootFilesystem: true` in runtime containers to prevent unauthorized modifications.\r\n* Only disable if necessary and with compensating controls.\r\n\r\n### Secrets management\r\n\r\n* Store sensitive data like API keys in Kubernetes secrets or external secret managers.\r\n* Avoid embedding secrets in flow JSON files.\r\n\r\n### Authentication and authorization\r\n\r\n* Implement strong authentication for the IDE UI and runtime API like OAuth or API tokens.\r\n* Enforce role-based access control to limit user permissions.\r\n\r\n### Data privacy\r\n\r\n* Ensure compliance with regulations like GDPR if handling personal data.\r\n* Encrypt sensitive data at rest and in transit.\r\n\r\n### Encryption\r\n\r\n* Use HTTPS for all communications to secure data in transit.\r\n* Configure TLS for PostgreSQL connections.\r\n\r\n### Additional security measures\r\n\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2240865100",
    "pr_number": 9226,
    "pr_file": "docs/docs/Deployment/deployment-prod-best-practices.mdx",
    "created_at": "2025-07-29T20:08:53+00:00",
    "commented_code": "* **Resource allocation**\n   * **Optimized resource usage and cost efficiency**: By separating the two environments, you can allocate resources more effectively. Each flow can be deployed independently, providing fine-grained resource control.\n   * **Scalability**: The runtime environment can be scaled independently based on application load and performance requirements, without affecting the development environment.\n+\n+## Scaling Resources\n+\n+Langflow's resource requirements vary depending on whether you're deploying the IDE for development or the runtime for production flows. Below are detailed strategies for scaling RAM, disk, instances, and users per instance.\n+\n+**IDE vs. Runtime**:\n+\n+* **IDE**: Deploy for developers using the UI. Requires frontend (512Mi RAM, 0.3 CPU) and backend (1Gi RAM, 0.5 CPU) services.\n+* **Runtime**: Deploy for production flows. Headless, requiring 2Gi RAM and 1 CPU per instance, focused on API endpoints.\n+\n+### Example Resource Configuration\n+\n+| Component | RAM Request | CPU Request | Replica Count | Notes |\n+|-----------|-------------|-------------|---------------|-------|\n+| IDE Backend | 1Gi | 0.5 | 1 | Scale replicas for more developers. |\n+| IDE Frontend | 512Mi | 0.3 | 1 | Adjust based on UI load. |\n+| Runtime | 2Gi | 1000m | 3 | Use HPA for dynamic scaling. |\n+| PostgreSQL | 4Gi | 2 | 1+ | Use replication for high availability. |\n+\n+### RAM\n+\n+**Overview**: RAM usage in Langflow depends on flow complexity, the size of language models, and concurrent request volume. The runtime, used for production flows, has a baseline requirement, while the IDE (for developers) requires additional resources for the frontend and backend.\n+\n+**Base Requirements**:\n+\n+* **Runtime**: 2Gi per instance.\n+* **IDE Backend**: 1Gi per instance.\n+* **IDE Frontend**: 512Mi per instance.\n+\n+**Factors Affecting RAM Usage**:\n+\n+* **Flow Complexity**: Flows with many nodes or large datasets (e.g., RAG pipelines) increase memory needs.\n+* **Language Models**: Larger LLMs or embeddings loaded in-memory consume significant RAM.\n+* **Concurrent Requests**: More simultaneous API calls or UI sessions require additional memory.\n+\n+**Scaling Recommendations**:\n+\n+* Start with 2Gi for runtime instances and 1.5Gi total (1Gi backend + 512Mi frontend) for IDE instances.\n+* Monitor memory usage with tools like Prometheus to identify bottlenecks.\n+* Adjust memory requests and limits in Kubernetes. For example:\n+\n+    ```yaml\n+    resources:\n+      requests:\n+        memory: \"2Gi\"\n+        cpu: \"1000m\"\n+      limits:\n+        memory: \"4Gi\"\n+        cpu: \"2000m\"\n+    ```\n+\n+* For intensive use (e.g., multi-core CPU setups), allocate 4Gi or more per instance.\n+\n+### Disk\n+\n+**Overview**: Disk storage is used for the SQLite or PostgreSQL database and file storage for large files, such as documents for RAG. The database stores flow configurations, user data, and settings, while files are managed on disk.\n+\n+**Usage**:\n+\n+* **Database**: Stores flow definitions, user profiles, and logs. Size depends on the number of flows and users.\n+* **File Storage**: Large files are stored in directories like `/opt/langflow/data/` or `.cache/langflow/`.\n+\n+**Scaling Recommendations**:\n+\n+* Use an external PostgreSQL database for production to improve scalability and reliability.\n+* Configure shared file storage such as NFS or cloud storage for multi-instance setups to ensure file access across replicas.\n+* Estimate initial database size based on expected flows and users, such as 10GB for moderate use, and monitor growth.\n+* Use Persistent Volumes in Kubernetes for database and file storage, with dynamic provisioning for scalability.\n+\n+### Instances\n+\n+**Overview**: Scaling instances involves adding more replicas to handle increased load, applicable to both IDE and runtime deployments. Horizontal scaling is preferred for production environments.\n+\n+**Base Configuration**:\n+\n+* **Runtime**: Default replica count of 3.\n+* **IDE**: Default replica count of 1 for both backend and frontend.\n+\n+**Scaling Recommendations**:\n+\n+* Implement Horizontal Pod Autoscaler (HPA) in Kubernetes to dynamically adjust replicas based on CPU or memory usage. Example HPA configuration:\n+\n+    ```yaml\n+    apiVersion: autoscaling/v2\n+    kind: HorizontalPodAutoscaler\n+    metadata:\n+      name: langflow-runtime-hpa\n+    spec:\n+      scaleTargetRef:\n+        apiVersion: apps/v1\n+        kind: Deployment\n+        name: langflow-runtime\n+      minReplicas: 1\n+      maxReplicas: 10\n+      metrics:\n+      - type: Resource\n+        resource:\n+          name: cpu\n+          target:\n+            type: Utilization\n+            averageUtilization: 80\n+    ```\n+\n+* For bursty workloads, such as 100,000s of tokens per second, ensure sufficient replicas to handle spikes.\n+* Vertically scale by increasing CPU/memory requests for complex flows, but prioritize horizontal scaling for reliability.\n+\n+### Users per Instance\n+\n+**Overview**: The number of users or requests per instance depends on whether you're supporting developers via the IDE or API clients via the runtime.\n+\n+**UI (IDE)**:\n+\n+* Each developer using the UI generates requests to the backend, requiring resources for session handling.\n+* Scale backend replicas based on concurrent developers (e.g., 1 replica per 10-20 developers, adjusted via load testing).\n+\n+**Production Flows (Runtime)**:\n+\n+* Users are typically API clients making requests to flow endpoints.\n+* Capacity depends on request rate and flow complexity. For example, a single instance with 2vCPUs and 2GB RAM can handle ~30 concurrent connections for simple flows.\n+* Perform load testing to determine the number of requests per instance and scale replicas accordingly.\n+\n+**Scaling Recommendations**:\n+\n+* Use load balancers to distribute requests across replicas.\n+* Monitor API request rates and response times to adjust replica counts.\n+* For IDE, ensure frontend and backend replicas are balanced to avoid bottlenecks.\n+\n+## Failure Points\n+\n+Langflow's reliability in production depends on mitigating key failure points, particularly around the database, file system, and instance availability.\n+\n+**Database Failure**:\n+\n+* **Impact**: Disrupts flow retrieval, saving, user authentication, user management, project collection access, configuration updates, and log writing.\n+* **Mitigation**: Use a replicated PostgreSQL setup with high availability and regular backups. Flows already loaded in memory may continue to function.\n+\n+**File System Issues**:\n+\n+* **Impact**: Concurrency issues in file caching, such as `/app/data/.cache`, can cause IO errors in multi-instance setups.\n+* **Mitigation**: Use a shared, POSIX-compliant file system or cloud storage. Avoid ramdisk solutions due to data loss on container shutdown.\n+\n+**Instance Failures**:\n+\n+* **Impact**: A single instance failure can disrupt service if not replicated.\n+* **Mitigation**: Deploy multiple replicas with Kubernetes to ensure availability. Use health checks to detect and replace failed pods.\n+\n+**Network and Dependency Failures**:\n+\n+* **Impact**: External APIs or services used in flows may fail, causing flow errors.\n+* **Mitigation**: Implement retry logic and error handling in flows. Monitor network latency and dependency health.\n+\n+## Monitoring Recommendations\n+\n+Effective monitoring ensures Langflow operates reliably and performs well under varying loads.\n+\n+**Database Health**:\n+\n+* Monitor availability, query performance, and resource usage (CPU, memory, disk).\n+* Use tools like pgAdmin or cloud-native monitoring for PostgreSQL.\n+\n+**Application Logs**:\n+\n+* Collect and analyze logs for errors, warnings, and flow execution issues.\n+* Centralize logs using tools like ELK Stack or Fluentd.\n+\n+**Resource Usage**:\n+\n+* Track CPU, memory, and disk usage of Langflow instances.\n+* Use Prometheus and Grafana for real-time monitoring in Kubernetes.\n+\n+**API Performance**:\n+\n+* Monitor response times, error rates, and request throughput.\n+* Set alerts for high latency or error spikes.\n+\n+**Observability Tools**:\n+\n+* Integrate with LangSmith or LangFuse for detailed flow tracing and metrics.\n+* Use these tools to debug flow performance and optimize execution.\n+\n+**Example Monitoring Setup**:\n+\n+* Deploy Prometheus for metrics collection.\n+* Use Grafana dashboards to visualize resource usage and API performance.\n+* Configure alerts for critical thresholds (e.g., 90% memory usage, 500ms API latency).\n+\n+## Security Implications\n+\n+Running Langflow in production requires robust security measures to protect the application, data, and users.\n+\n+**Container Security**:\n+\n+* Enable `readOnlyRootFilesystem: true` in runtime containers to prevent unauthorized modifications.\n+* Only disable if necessary and with compensating controls.\n+\n+**Secret Management**:\n+\n+* Store sensitive data like API keys in Kubernetes secrets or external secret managers.\n+* Avoid embedding secrets in flow JSON files.\n+\n+**Authentication and Authorization**:\n+\n+* Implement strong authentication for the IDE UI and runtime API like OAuth or API tokens.\n+* Enforce role-based access control to limit user permissions.\n+\n+**Data Privacy**:\n+\n+* Ensure compliance with regulations like GDPR if handling personal data.\n+* Encrypt sensitive data at rest and in transit.\n+\n+**Encryption**:\n+\n+* Use HTTPS for all communications to secure data in transit.\n+* Configure TLS for PostgreSQL connections.\n+\n+**Additional Security Measures**:\n+\n+* Conduct regular security audits and apply software updates.\n+* Restrict network access to Langflow services using firewalls or network policies.\n+* Monitor for suspicious activity using intrusion detection systems.",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2240865100",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9226,
        "pr_file": "docs/docs/Deployment/deployment-prod-best-practices.mdx",
        "discussion_id": "2240865100",
        "commented_code": "@@ -57,3 +57,223 @@ This separation is designed to enhance security, optimize resource allocation, a\n * **Resource allocation**\n   * **Optimized resource usage and cost efficiency**: By separating the two environments, you can allocate resources more effectively. Each flow can be deployed independently, providing fine-grained resource control.\n   * **Scalability**: The runtime environment can be scaled independently based on application load and performance requirements, without affecting the development environment.\n+\n+## Scaling Resources\n+\n+Langflow's resource requirements vary depending on whether you're deploying the IDE for development or the runtime for production flows. Below are detailed strategies for scaling RAM, disk, instances, and users per instance.\n+\n+**IDE vs. Runtime**:\n+\n+* **IDE**: Deploy for developers using the UI. Requires frontend (512Mi RAM, 0.3 CPU) and backend (1Gi RAM, 0.5 CPU) services.\n+* **Runtime**: Deploy for production flows. Headless, requiring 2Gi RAM and 1 CPU per instance, focused on API endpoints.\n+\n+### Example Resource Configuration\n+\n+| Component | RAM Request | CPU Request | Replica Count | Notes |\n+|-----------|-------------|-------------|---------------|-------|\n+| IDE Backend | 1Gi | 0.5 | 1 | Scale replicas for more developers. |\n+| IDE Frontend | 512Mi | 0.3 | 1 | Adjust based on UI load. |\n+| Runtime | 2Gi | 1000m | 3 | Use HPA for dynamic scaling. |\n+| PostgreSQL | 4Gi | 2 | 1+ | Use replication for high availability. |\n+\n+### RAM\n+\n+**Overview**: RAM usage in Langflow depends on flow complexity, the size of language models, and concurrent request volume. The runtime, used for production flows, has a baseline requirement, while the IDE (for developers) requires additional resources for the frontend and backend.\n+\n+**Base Requirements**:\n+\n+* **Runtime**: 2Gi per instance.\n+* **IDE Backend**: 1Gi per instance.\n+* **IDE Frontend**: 512Mi per instance.\n+\n+**Factors Affecting RAM Usage**:\n+\n+* **Flow Complexity**: Flows with many nodes or large datasets (e.g., RAG pipelines) increase memory needs.\n+* **Language Models**: Larger LLMs or embeddings loaded in-memory consume significant RAM.\n+* **Concurrent Requests**: More simultaneous API calls or UI sessions require additional memory.\n+\n+**Scaling Recommendations**:\n+\n+* Start with 2Gi for runtime instances and 1.5Gi total (1Gi backend + 512Mi frontend) for IDE instances.\n+* Monitor memory usage with tools like Prometheus to identify bottlenecks.\n+* Adjust memory requests and limits in Kubernetes. For example:\n+\n+    ```yaml\n+    resources:\n+      requests:\n+        memory: \"2Gi\"\n+        cpu: \"1000m\"\n+      limits:\n+        memory: \"4Gi\"\n+        cpu: \"2000m\"\n+    ```\n+\n+* For intensive use (e.g., multi-core CPU setups), allocate 4Gi or more per instance.\n+\n+### Disk\n+\n+**Overview**: Disk storage is used for the SQLite or PostgreSQL database and file storage for large files, such as documents for RAG. The database stores flow configurations, user data, and settings, while files are managed on disk.\n+\n+**Usage**:\n+\n+* **Database**: Stores flow definitions, user profiles, and logs. Size depends on the number of flows and users.\n+* **File Storage**: Large files are stored in directories like `/opt/langflow/data/` or `.cache/langflow/`.\n+\n+**Scaling Recommendations**:\n+\n+* Use an external PostgreSQL database for production to improve scalability and reliability.\n+* Configure shared file storage such as NFS or cloud storage for multi-instance setups to ensure file access across replicas.\n+* Estimate initial database size based on expected flows and users, such as 10GB for moderate use, and monitor growth.\n+* Use Persistent Volumes in Kubernetes for database and file storage, with dynamic provisioning for scalability.\n+\n+### Instances\n+\n+**Overview**: Scaling instances involves adding more replicas to handle increased load, applicable to both IDE and runtime deployments. Horizontal scaling is preferred for production environments.\n+\n+**Base Configuration**:\n+\n+* **Runtime**: Default replica count of 3.\n+* **IDE**: Default replica count of 1 for both backend and frontend.\n+\n+**Scaling Recommendations**:\n+\n+* Implement Horizontal Pod Autoscaler (HPA) in Kubernetes to dynamically adjust replicas based on CPU or memory usage. Example HPA configuration:\n+\n+    ```yaml\n+    apiVersion: autoscaling/v2\n+    kind: HorizontalPodAutoscaler\n+    metadata:\n+      name: langflow-runtime-hpa\n+    spec:\n+      scaleTargetRef:\n+        apiVersion: apps/v1\n+        kind: Deployment\n+        name: langflow-runtime\n+      minReplicas: 1\n+      maxReplicas: 10\n+      metrics:\n+      - type: Resource\n+        resource:\n+          name: cpu\n+          target:\n+            type: Utilization\n+            averageUtilization: 80\n+    ```\n+\n+* For bursty workloads, such as 100,000s of tokens per second, ensure sufficient replicas to handle spikes.\n+* Vertically scale by increasing CPU/memory requests for complex flows, but prioritize horizontal scaling for reliability.\n+\n+### Users per Instance\n+\n+**Overview**: The number of users or requests per instance depends on whether you're supporting developers via the IDE or API clients via the runtime.\n+\n+**UI (IDE)**:\n+\n+* Each developer using the UI generates requests to the backend, requiring resources for session handling.\n+* Scale backend replicas based on concurrent developers (e.g., 1 replica per 10-20 developers, adjusted via load testing).\n+\n+**Production Flows (Runtime)**:\n+\n+* Users are typically API clients making requests to flow endpoints.\n+* Capacity depends on request rate and flow complexity. For example, a single instance with 2vCPUs and 2GB RAM can handle ~30 concurrent connections for simple flows.\n+* Perform load testing to determine the number of requests per instance and scale replicas accordingly.\n+\n+**Scaling Recommendations**:\n+\n+* Use load balancers to distribute requests across replicas.\n+* Monitor API request rates and response times to adjust replica counts.\n+* For IDE, ensure frontend and backend replicas are balanced to avoid bottlenecks.\n+\n+## Failure Points\n+\n+Langflow's reliability in production depends on mitigating key failure points, particularly around the database, file system, and instance availability.\n+\n+**Database Failure**:\n+\n+* **Impact**: Disrupts flow retrieval, saving, user authentication, user management, project collection access, configuration updates, and log writing.\n+* **Mitigation**: Use a replicated PostgreSQL setup with high availability and regular backups. Flows already loaded in memory may continue to function.\n+\n+**File System Issues**:\n+\n+* **Impact**: Concurrency issues in file caching, such as `/app/data/.cache`, can cause IO errors in multi-instance setups.\n+* **Mitigation**: Use a shared, POSIX-compliant file system or cloud storage. Avoid ramdisk solutions due to data loss on container shutdown.\n+\n+**Instance Failures**:\n+\n+* **Impact**: A single instance failure can disrupt service if not replicated.\n+* **Mitigation**: Deploy multiple replicas with Kubernetes to ensure availability. Use health checks to detect and replace failed pods.\n+\n+**Network and Dependency Failures**:\n+\n+* **Impact**: External APIs or services used in flows may fail, causing flow errors.\n+* **Mitigation**: Implement retry logic and error handling in flows. Monitor network latency and dependency health.\n+\n+## Monitoring Recommendations\n+\n+Effective monitoring ensures Langflow operates reliably and performs well under varying loads.\n+\n+**Database Health**:\n+\n+* Monitor availability, query performance, and resource usage (CPU, memory, disk).\n+* Use tools like pgAdmin or cloud-native monitoring for PostgreSQL.\n+\n+**Application Logs**:\n+\n+* Collect and analyze logs for errors, warnings, and flow execution issues.\n+* Centralize logs using tools like ELK Stack or Fluentd.\n+\n+**Resource Usage**:\n+\n+* Track CPU, memory, and disk usage of Langflow instances.\n+* Use Prometheus and Grafana for real-time monitoring in Kubernetes.\n+\n+**API Performance**:\n+\n+* Monitor response times, error rates, and request throughput.\n+* Set alerts for high latency or error spikes.\n+\n+**Observability Tools**:\n+\n+* Integrate with LangSmith or LangFuse for detailed flow tracing and metrics.\n+* Use these tools to debug flow performance and optimize execution.\n+\n+**Example Monitoring Setup**:\n+\n+* Deploy Prometheus for metrics collection.\n+* Use Grafana dashboards to visualize resource usage and API performance.\n+* Configure alerts for critical thresholds (e.g., 90% memory usage, 500ms API latency).\n+\n+## Security Implications\n+\n+Running Langflow in production requires robust security measures to protect the application, data, and users.\n+\n+**Container Security**:\n+\n+* Enable `readOnlyRootFilesystem: true` in runtime containers to prevent unauthorized modifications.\n+* Only disable if necessary and with compensating controls.\n+\n+**Secret Management**:\n+\n+* Store sensitive data like API keys in Kubernetes secrets or external secret managers.\n+* Avoid embedding secrets in flow JSON files.\n+\n+**Authentication and Authorization**:\n+\n+* Implement strong authentication for the IDE UI and runtime API like OAuth or API tokens.\n+* Enforce role-based access control to limit user permissions.\n+\n+**Data Privacy**:\n+\n+* Ensure compliance with regulations like GDPR if handling personal data.\n+* Encrypt sensitive data at rest and in transit.\n+\n+**Encryption**:\n+\n+* Use HTTPS for all communications to secure data in transit.\n+* Configure TLS for PostgreSQL connections.\n+\n+**Additional Security Measures**:\n+\n+* Conduct regular security audits and apply software updates.\n+* Restrict network access to Langflow services using firewalls or network policies.\n+* Monitor for suspicious activity using intrusion detection systems.",
        "comment_created_at": "2025-07-29T20:08:53+00:00",
        "comment_author": "aimurphy",
        "comment_body": "```suggestion\r\n* Monitor for suspicious activity using intrusion detection systems.\r\n\r\n## See also\r\n\r\n* [Database guide for enterprise DBAs](/deployment-enterprise-database)\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2229329496",
    "pr_number": 9172,
    "pr_file": "docs/docs/Configuration/api-keys-and-authentication.mdx",
    "created_at": "2025-07-24T19:01:19+00:00",
    "commented_code": "+---\n+title: API keys and authentication\n+slug: /api-keys-and-authentication\n+---\n+\n+import Tabs from '@theme/Tabs';\n+import TabItem from '@theme/TabItem';\n+import Icon from \"@site/src/components/icon\";\n+\n+Langflow uses API keys and authentication to control and secure access to user data, flows, and administrative actions on the server.\n+\n+## Create a Langflow API key\n+\n+You can use Langflow API keys to interact with Langflow programmatically.\n+\n+The API key has the same permissions and access as you do when you launch Langflow. This means your API key can only access your own flows, components, and data. You cannot access other users' resources with your own Langflow API keys.\n+\n+An API key represents the user who created it. If you create a key as a superuser, then that key will have superuser privileges.\n+Anyone who has that key can authorize superuser actions through the Langflow API, including user management and flow management.\n+\n+In Langflow versions 1.5 and later, most API endpoints require a Langflow API key, even when `AUTO_LOGIN` is set to `True`.\n+The only exceptions are the MCP endpoints `/v1/mcp`, `/v1/mcp-projects`, and `/v2/mcp`, which never require authentication.\n+\n+<details>\n+<summary>LANGFLOW_AUTO_LOGIN and LANGFLOW_SKIP_AUTH_AUTO_LOGIN options</summary>\n+\n+In Langflow versions earlier than 1.5, if `LANGFLOW_AUTO_LOGIN=true`, then Langflow automatically logs users in as a superuser without requiring authentication.\n+In this case, API requests don't require a Langflow API key.\n+\n+In Langflow version 1.5, you can set `LANGFLOW_SKIP_AUTH_AUTO_LOGIN=true` and `LANGFLOW_AUTO_LOGIN=true` to skip authentication for API requests.\n+However, the `LANGFLOW_SKIP_AUTH_AUTO_LOGIN` option will be removed in a future release.\n+</details>\n+\n+You can generate a Langflow API key with the UI or the CLI.\n+\n+The UI-generated key is appropriate for most cases. The CLI-generated key is needed when your Langflow server is running in `--backend-only` mode.\n+\n+<Tabs>\n+  <TabItem value=\"Langflow UI\" label=\"Langflow UI\" default>\n+\n+    1. In the Langflow UI header, click your profile icon, and then select **Settings**.\n+    2. Click **Langflow API Keys**, and then click **Add New**.\n+    3. Name your key, and then click **Create API Key**.\n+    4. Copy the API key and store it securely.\n+\n+  </TabItem>\n+  <TabItem value=\"Langflow CLI\" label=\"Langflow CLI\">\n+\n+    If you're serving your flow with `--backend-only=true`, you can't create API keys in the UI, because the frontend is not running.\n+\n+    Depending on your authentication settings, note the following requirements for creating API keys with the Langflow CLI:\n+\n+    * If `AUTO_LOGIN` is `FALSE`, you must be logged in as a superuser.\n+    * If `AUTO LOGIN` is `TRUE`, you're already logged in as superuser.\n+\n+    To create an API key for a user from the CLI, do the following:\n+\n+    1. In your `.env` file, set `AUTO_LOGIN=FALSE`, and set superuser credentials for your server.\n+\n+        ```text\n+        LANGFLOW_AUTO_LOGIN=False\n+        LANGFLOW_SUPERUSER=administrator\n+        LANGFLOW_SUPERUSER_PASSWORD=securepassword\n+        ```\n+\n+    2. To confirm your superuser status, call [`GET /users/whoami`](/api-users#get-current-user), and then check that the response contains `\"is_superuser\": true`:\n+\n+        ```bash\n+        curl -X GET \\\n+          \"$LANGFLOW_URL/api/v1/users/whoami\" \\\n+          -H \"accept: application/json\" \\\n+          -H \"x-api-key: $LANGFLOW_API_KEY\"\n+        ```\n+\n+        <details closed>\n+        <summary>Result</summary>\n+\n+        ```json\n+        {\n+          \"id\": \"07e5b864-e367-4f52-b647-a48035ae7e5e\",\n+          \"username\": \"langflow\",\n+          \"profile_image\": null,\n+          \"store_api_key\": null,\n+          \"is_active\": true,\n+          \"is_superuser\": true,\n+          \"create_at\": \"2025-05-08T17:59:07.855965\",\n+          \"updated_at\": \"2025-05-29T15:06:56.157860\",\n+          \"last_login_at\": \"2025-05-29T15:06:56.157016\",\n+        }\n+        ```\n+\n+        </details>\n+\n+    3. Create an API key:\n+\n+        ```shell\n+        uv run langflow api-key\n+        ```\n+  </TabItem>\n+</Tabs>\n+\n+## Authenticate requests with the Langflow API key\n+\n+Include your API key in API requests to authenticate requests to Langflow.\n+\n+API keys allow access only to the flows and components of the specific user who created the key.\n+\n+<Tabs>\n+  <TabItem value=\"HTTP header\" label=\"HTTP header\" default>\n+\n+    To use the API key when making API requests, include the API key in the HTTP header:\n+\n+        ```shell\n+        curl -X POST \\\n+          \"http://LANGFLOW_SERVER_ADDRESS/api/v1/run/FLOW_ID?stream=false\" \\\n+          -H 'Content-Type: application/json' \\\n+          -H 'x-api-key: LANGFLOW_API_KEY' \\\n+          -d '{\"inputs\": {\"text\":\"\"}, \"tweaks\": {}}'\n+        ```\n+\n+  </TabItem>\n+  <TabItem value=\"Query parameter\" label=\"Query parameter\">\n+\n+    To pass the API key as a query parameter:\n+\n+        ```shell\n+        curl -X POST \\\n+          \"http://LANGFLOW_SERVER_ADDRESS/api/v1/run/FLOW_ID?x-api-key=LANGFLOW_API_KEY\" \\\n+          -H 'Content-Type: application/json' \\\n+          -d '{\"inputs\": {\"text\":\"\"}, \"tweaks\": {}}'\n+        ```\n+\n+  </TabItem>\n+</Tabs>\n+\n+## Create a Langflow secret key\n+\n+Langflow uses the [Fernet](https://pypi.org/project/cryptography/) library for encrypting sensitive data.\n+\n+If no `LANGFLOW_SECRET_KEY` is provided, Langflow automatically generates one.\n+\n+For more information, see [LANGFLOW_SECRET_KEY](#langflow_secret_key).\n+\n+## Revoke an API key\n+\n+To revoke an API key and delete it from your Langflow settings, do the following:\n+\n+    1. In the Langflow UI header, click your profile icon, and then select **Settings**.\n+    2. Click **Langflow API Keys**.\n+    3. Select the keys you want to delete, and then click <Icon name=\"Trash2\" aria-hidden=\"true\"/> **Delete**.\n+\n+This action immediately invalidates the key and prevents it from being used again.\n+\n+## Add component API keys to Langflow\n+\n+API keys for external services like OpenAI are added as global variables with the Langflow UI, or sourced from the `.env` file.\n+\n+For more information, see [Global variables](/configuration-global-variables).\n+\n+## Authentication configuration values\n+\n+    :::warning\n+    Never expose Langflow ports directly to the internet without proper security measures.\n+\n+    Disable `LANGFLOW_AUTO_LOGIN`, use a secure `LANGFLOW_SECRET_KEY`, and ensure your Langflow server is behind a reverse proxy with authentication enabled.\n+    For more information, see [Start a secure Langflow server with authentication](#start-a-secure-langflow-server-with-authentication).\n+    :::\n+\n+This section describes the available authentication configuration variables.\n+\n+You can use the [`.env.example`](https://github.com/langflow-ai/langflow/blob/main/.env.example) file in the Langflow repository as a template for your own `.env` file.\n+\n+### LANGFLOW_AUTO_LOGIN\n+\n+Langflow **does not** allow users to have simultaneous or shared access to flows.\n+If `AUTO_LOGIN` is enabled and user management is disabled (`LANGFLOW_NEW_USER_IS_ACTIVE=true`), users can access the same environment, but it is not password protected. If two users access the same flow, Langflow saves only the work of the last user to save.\n+\n+```bash\n+LANGFLOW_AUTO_LOGIN=True\n+```\n+\n+In Langflow versions 1.5 and later, most API endpoints require a Langflow API key, even when `AUTO_LOGIN` is set to `True`.\n+The only exceptions are the MCP endpoints `/v1/mcp`, `/v1/mcp-projects`, and `/v2/mcp`, which never require authentication.\n+\n+<details>\n+<summary>AUTO_LOGIN and SKIP_AUTH options</summary>\n+\n+In Langflow versions earlier than 1.5, if `LANGFLOW_AUTO_LOGIN=true`, then Langflow automatically logs users in as a superuser without requiring authentication.\n+In this case, API requests don't require a Langflow API key.\n+\n+In Langflow version 1.5, you can set `LANGFLOW_SKIP_AUTH_AUTO_LOGIN=true` and `LANGFLOW_AUTO_LOGIN=true` to skip authentication for API requests.\n+However, the `LANGFLOW_SKIP_AUTH_AUTO_LOGIN` option will be removed in a future release.\n+</details>\n+\n+### LANGFLOW_SUPERUSER and LANGFLOW_SUPERUSER_PASSWORD\n+\n+These environment variables are only relevant when `LANGFLOW_AUTO_LOGIN` is set to `False`.\n+They specify the username and password for the superuser, which is essential for administrative tasks:\n+\n+```text\n+LANGFLOW_SUPERUSER=administrator\n+LANGFLOW_SUPERUSER_PASSWORD=securepassword\n+```\n+\n+### LANGFLOW_SECRET_KEY\n+\n+This environment variable holds a secret key used for encrypting sensitive data like API keys.\n+Langflow uses the [Fernet](https://pypi.org/project/cryptography/) library for secret key encryption.\n+\n+```text\n+LANGFLOW_SECRET_KEY=dBuuuB_FHLvU8T9eUNlxQF9ppqRxwWpXXQ42kM2_fb\n+```\n+\n+:::warning\n+If no secret key is provided, Langflow automatically generates one. This is not recommended for production environments, especially in multi-instance deployments like Kubernetes, where auto-generated keys can't decrypt data encrypted by other instances.\n+:::\n+\n+To generate a `LANGFLOW_SECRET_KEY`, follow these steps:\n+\n+1. Run the command to generate and copy a secret to the clipboard.\n+    <Tabs>\n+      <TabItem value=\"unix\" label=\"macOS/Linux\">\n+        ```bash\n+        # Copy to clipboard (macOS)\n+        python3 -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\" | pbcopy\n+        # Copy to clipboard (Linux)\n+        python3 -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\" | xclip -selection clipboard\n+        # Or just print\n+        python3 -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\"\n+        ```\n+      </TabItem>\n+      <TabItem value=\"windows\" label=\"Windows\">\n+        ```bash\n+        python -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\"\n+        ```\n+      </TabItem>\n+    </Tabs>\n+\n+2. Paste the value into your `.env` file:\n+        ```text\n+        LANGFLOW_SECRET_KEY=dBuuuB_FHLvU8T9eUNlxQF9ppqRxwWpXXQ42kM2_fb",
    "repo_full_name": "langflow-ai/langflow",
    "discussion_comments": [
      {
        "comment_id": "2229329496",
        "repo_full_name": "langflow-ai/langflow",
        "pr_number": 9172,
        "pr_file": "docs/docs/Configuration/api-keys-and-authentication.mdx",
        "discussion_id": "2229329496",
        "commented_code": "@@ -0,0 +1,338 @@\n+---\n+title: API keys and authentication\n+slug: /api-keys-and-authentication\n+---\n+\n+import Tabs from '@theme/Tabs';\n+import TabItem from '@theme/TabItem';\n+import Icon from \"@site/src/components/icon\";\n+\n+Langflow uses API keys and authentication to control and secure access to user data, flows, and administrative actions on the server.\n+\n+## Create a Langflow API key\n+\n+You can use Langflow API keys to interact with Langflow programmatically.\n+\n+The API key has the same permissions and access as you do when you launch Langflow. This means your API key can only access your own flows, components, and data. You cannot access other users' resources with your own Langflow API keys.\n+\n+An API key represents the user who created it. If you create a key as a superuser, then that key will have superuser privileges.\n+Anyone who has that key can authorize superuser actions through the Langflow API, including user management and flow management.\n+\n+In Langflow versions 1.5 and later, most API endpoints require a Langflow API key, even when `AUTO_LOGIN` is set to `True`.\n+The only exceptions are the MCP endpoints `/v1/mcp`, `/v1/mcp-projects`, and `/v2/mcp`, which never require authentication.\n+\n+<details>\n+<summary>LANGFLOW_AUTO_LOGIN and LANGFLOW_SKIP_AUTH_AUTO_LOGIN options</summary>\n+\n+In Langflow versions earlier than 1.5, if `LANGFLOW_AUTO_LOGIN=true`, then Langflow automatically logs users in as a superuser without requiring authentication.\n+In this case, API requests don't require a Langflow API key.\n+\n+In Langflow version 1.5, you can set `LANGFLOW_SKIP_AUTH_AUTO_LOGIN=true` and `LANGFLOW_AUTO_LOGIN=true` to skip authentication for API requests.\n+However, the `LANGFLOW_SKIP_AUTH_AUTO_LOGIN` option will be removed in a future release.\n+</details>\n+\n+You can generate a Langflow API key with the UI or the CLI.\n+\n+The UI-generated key is appropriate for most cases. The CLI-generated key is needed when your Langflow server is running in `--backend-only` mode.\n+\n+<Tabs>\n+  <TabItem value=\"Langflow UI\" label=\"Langflow UI\" default>\n+\n+    1. In the Langflow UI header, click your profile icon, and then select **Settings**.\n+    2. Click **Langflow API Keys**, and then click **Add New**.\n+    3. Name your key, and then click **Create API Key**.\n+    4. Copy the API key and store it securely.\n+\n+  </TabItem>\n+  <TabItem value=\"Langflow CLI\" label=\"Langflow CLI\">\n+\n+    If you're serving your flow with `--backend-only=true`, you can't create API keys in the UI, because the frontend is not running.\n+\n+    Depending on your authentication settings, note the following requirements for creating API keys with the Langflow CLI:\n+\n+    * If `AUTO_LOGIN` is `FALSE`, you must be logged in as a superuser.\n+    * If `AUTO LOGIN` is `TRUE`, you're already logged in as superuser.\n+\n+    To create an API key for a user from the CLI, do the following:\n+\n+    1. In your `.env` file, set `AUTO_LOGIN=FALSE`, and set superuser credentials for your server.\n+\n+        ```text\n+        LANGFLOW_AUTO_LOGIN=False\n+        LANGFLOW_SUPERUSER=administrator\n+        LANGFLOW_SUPERUSER_PASSWORD=securepassword\n+        ```\n+\n+    2. To confirm your superuser status, call [`GET /users/whoami`](/api-users#get-current-user), and then check that the response contains `\"is_superuser\": true`:\n+\n+        ```bash\n+        curl -X GET \\\n+          \"$LANGFLOW_URL/api/v1/users/whoami\" \\\n+          -H \"accept: application/json\" \\\n+          -H \"x-api-key: $LANGFLOW_API_KEY\"\n+        ```\n+\n+        <details closed>\n+        <summary>Result</summary>\n+\n+        ```json\n+        {\n+          \"id\": \"07e5b864-e367-4f52-b647-a48035ae7e5e\",\n+          \"username\": \"langflow\",\n+          \"profile_image\": null,\n+          \"store_api_key\": null,\n+          \"is_active\": true,\n+          \"is_superuser\": true,\n+          \"create_at\": \"2025-05-08T17:59:07.855965\",\n+          \"updated_at\": \"2025-05-29T15:06:56.157860\",\n+          \"last_login_at\": \"2025-05-29T15:06:56.157016\",\n+        }\n+        ```\n+\n+        </details>\n+\n+    3. Create an API key:\n+\n+        ```shell\n+        uv run langflow api-key\n+        ```\n+  </TabItem>\n+</Tabs>\n+\n+## Authenticate requests with the Langflow API key\n+\n+Include your API key in API requests to authenticate requests to Langflow.\n+\n+API keys allow access only to the flows and components of the specific user who created the key.\n+\n+<Tabs>\n+  <TabItem value=\"HTTP header\" label=\"HTTP header\" default>\n+\n+    To use the API key when making API requests, include the API key in the HTTP header:\n+\n+        ```shell\n+        curl -X POST \\\n+          \"http://LANGFLOW_SERVER_ADDRESS/api/v1/run/FLOW_ID?stream=false\" \\\n+          -H 'Content-Type: application/json' \\\n+          -H 'x-api-key: LANGFLOW_API_KEY' \\\n+          -d '{\"inputs\": {\"text\":\"\"}, \"tweaks\": {}}'\n+        ```\n+\n+  </TabItem>\n+  <TabItem value=\"Query parameter\" label=\"Query parameter\">\n+\n+    To pass the API key as a query parameter:\n+\n+        ```shell\n+        curl -X POST \\\n+          \"http://LANGFLOW_SERVER_ADDRESS/api/v1/run/FLOW_ID?x-api-key=LANGFLOW_API_KEY\" \\\n+          -H 'Content-Type: application/json' \\\n+          -d '{\"inputs\": {\"text\":\"\"}, \"tweaks\": {}}'\n+        ```\n+\n+  </TabItem>\n+</Tabs>\n+\n+## Create a Langflow secret key\n+\n+Langflow uses the [Fernet](https://pypi.org/project/cryptography/) library for encrypting sensitive data.\n+\n+If no `LANGFLOW_SECRET_KEY` is provided, Langflow automatically generates one.\n+\n+For more information, see [LANGFLOW_SECRET_KEY](#langflow_secret_key).\n+\n+## Revoke an API key\n+\n+To revoke an API key and delete it from your Langflow settings, do the following:\n+\n+    1. In the Langflow UI header, click your profile icon, and then select **Settings**.\n+    2. Click **Langflow API Keys**.\n+    3. Select the keys you want to delete, and then click <Icon name=\"Trash2\" aria-hidden=\"true\"/> **Delete**.\n+\n+This action immediately invalidates the key and prevents it from being used again.\n+\n+## Add component API keys to Langflow\n+\n+API keys for external services like OpenAI are added as global variables with the Langflow UI, or sourced from the `.env` file.\n+\n+For more information, see [Global variables](/configuration-global-variables).\n+\n+## Authentication configuration values\n+\n+    :::warning\n+    Never expose Langflow ports directly to the internet without proper security measures.\n+\n+    Disable `LANGFLOW_AUTO_LOGIN`, use a secure `LANGFLOW_SECRET_KEY`, and ensure your Langflow server is behind a reverse proxy with authentication enabled.\n+    For more information, see [Start a secure Langflow server with authentication](#start-a-secure-langflow-server-with-authentication).\n+    :::\n+\n+This section describes the available authentication configuration variables.\n+\n+You can use the [`.env.example`](https://github.com/langflow-ai/langflow/blob/main/.env.example) file in the Langflow repository as a template for your own `.env` file.\n+\n+### LANGFLOW_AUTO_LOGIN\n+\n+Langflow **does not** allow users to have simultaneous or shared access to flows.\n+If `AUTO_LOGIN` is enabled and user management is disabled (`LANGFLOW_NEW_USER_IS_ACTIVE=true`), users can access the same environment, but it is not password protected. If two users access the same flow, Langflow saves only the work of the last user to save.\n+\n+```bash\n+LANGFLOW_AUTO_LOGIN=True\n+```\n+\n+In Langflow versions 1.5 and later, most API endpoints require a Langflow API key, even when `AUTO_LOGIN` is set to `True`.\n+The only exceptions are the MCP endpoints `/v1/mcp`, `/v1/mcp-projects`, and `/v2/mcp`, which never require authentication.\n+\n+<details>\n+<summary>AUTO_LOGIN and SKIP_AUTH options</summary>\n+\n+In Langflow versions earlier than 1.5, if `LANGFLOW_AUTO_LOGIN=true`, then Langflow automatically logs users in as a superuser without requiring authentication.\n+In this case, API requests don't require a Langflow API key.\n+\n+In Langflow version 1.5, you can set `LANGFLOW_SKIP_AUTH_AUTO_LOGIN=true` and `LANGFLOW_AUTO_LOGIN=true` to skip authentication for API requests.\n+However, the `LANGFLOW_SKIP_AUTH_AUTO_LOGIN` option will be removed in a future release.\n+</details>\n+\n+### LANGFLOW_SUPERUSER and LANGFLOW_SUPERUSER_PASSWORD\n+\n+These environment variables are only relevant when `LANGFLOW_AUTO_LOGIN` is set to `False`.\n+They specify the username and password for the superuser, which is essential for administrative tasks:\n+\n+```text\n+LANGFLOW_SUPERUSER=administrator\n+LANGFLOW_SUPERUSER_PASSWORD=securepassword\n+```\n+\n+### LANGFLOW_SECRET_KEY\n+\n+This environment variable holds a secret key used for encrypting sensitive data like API keys.\n+Langflow uses the [Fernet](https://pypi.org/project/cryptography/) library for secret key encryption.\n+\n+```text\n+LANGFLOW_SECRET_KEY=dBuuuB_FHLvU8T9eUNlxQF9ppqRxwWpXXQ42kM2_fb\n+```\n+\n+:::warning\n+If no secret key is provided, Langflow automatically generates one. This is not recommended for production environments, especially in multi-instance deployments like Kubernetes, where auto-generated keys can't decrypt data encrypted by other instances.\n+:::\n+\n+To generate a `LANGFLOW_SECRET_KEY`, follow these steps:\n+\n+1. Run the command to generate and copy a secret to the clipboard.\n+    <Tabs>\n+      <TabItem value=\"unix\" label=\"macOS/Linux\">\n+        ```bash\n+        # Copy to clipboard (macOS)\n+        python3 -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\" | pbcopy\n+        # Copy to clipboard (Linux)\n+        python3 -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\" | xclip -selection clipboard\n+        # Or just print\n+        python3 -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\"\n+        ```\n+      </TabItem>\n+      <TabItem value=\"windows\" label=\"Windows\">\n+        ```bash\n+        python -c \"from secrets import token_urlsafe; print(f'LANGFLOW_SECRET_KEY={token_urlsafe(32)}')\"\n+        ```\n+      </TabItem>\n+    </Tabs>\n+\n+2. Paste the value into your `.env` file:\n+        ```text\n+        LANGFLOW_SECRET_KEY=dBuuuB_FHLvU8T9eUNlxQF9ppqRxwWpXXQ42kM2_fb",
        "comment_created_at": "2025-07-24T19:01:19+00:00",
        "comment_author": "aimurphy",
        "comment_body": "```suggestion\r\n        LANGFLOW_SECRET_KEY=dBuu...2kM2_fb\r\n```\r\n\r\nIt is a good idea to truncate or omit actual credential examples. You can use a templated format like we do for Astra (`AstraCS:...`) or just cut the middle part out.",
        "pr_file_module": null
      }
    ]
  }
]