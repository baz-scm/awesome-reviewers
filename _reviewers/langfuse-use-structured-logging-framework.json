[
  {
    "discussion_id": "2195007331",
    "pr_number": 7771,
    "pr_file": "web/src/features/query/server/queryBuilder.ts",
    "created_at": "2025-07-09T13:14:43+00:00",
    "commented_code": "withFillClause,\n     );\n \n+    console.log(\"Built SQL Query:\", sql);",
    "repo_full_name": "langfuse/langfuse",
    "discussion_comments": [
      {
        "comment_id": "2195007331",
        "repo_full_name": "langfuse/langfuse",
        "pr_number": 7771,
        "pr_file": "web/src/features/query/server/queryBuilder.ts",
        "discussion_id": "2195007331",
        "commented_code": "@@ -837,6 +837,8 @@ export class QueryBuilder {\n       withFillClause,\n     );\n \n+    console.log(\"Built SQL Query:\", sql);",
        "comment_created_at": "2025-07-09T13:14:43+00:00",
        "comment_author": "ellipsis-dev[bot]",
        "comment_body": "Avoid using console.log in production: Consider using a debug-level logger instead to prevent sensitive SQL details from being logged.\n```suggestion\n    logger.debug(\"Built SQL Query:\", sql);\n```\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2184897775",
    "pr_number": 7676,
    "pr_file": "web/src/pages/api/public/observations/[observationId].ts",
    "created_at": "2025-07-04T09:49:49+00:00",
    "commented_code": "})\n         : undefined;\n \n+      console.warn(`Model found: ${JSON.stringify(model)}`);",
    "repo_full_name": "langfuse/langfuse",
    "discussion_comments": [
      {
        "comment_id": "2184897775",
        "repo_full_name": "langfuse/langfuse",
        "pr_number": 7676,
        "pr_file": "web/src/pages/api/public/observations/[observationId].ts",
        "discussion_id": "2184897775",
        "commented_code": "@@ -57,6 +57,9 @@ export default withMiddlewares({\n           })\n         : undefined;\n \n+      console.warn(`Model found: ${JSON.stringify(model)}`);",
        "comment_created_at": "2025-07-04T09:49:49+00:00",
        "comment_author": "ellipsis-dev[bot]",
        "comment_body": "Avoid using console.warn for production logging; consider a proper logging framework or gating logs by environment.\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2140577156",
    "pr_number": 7241,
    "pr_file": "web/src/features/otel/server/index.ts",
    "created_at": "2025-06-11T16:09:23+00:00",
    "commented_code": "-import { type IngestionEventType } from \"@langfuse/shared/src/server\";\n+import {\n+  type TraceEventType,\n+  type IngestionEventType,\n+} from \"@langfuse/shared/src/server\";\n import { randomUUID } from \"crypto\";\n import { ForbiddenError, ObservationLevel } from \"@langfuse/shared\";\n import { LangfuseOtelSpanAttributes } from \"./attributes\";\n+import { redis } from \"@langfuse/shared/src/server\";\n+\n+export async function getSeenTracesSet(\n+  resourceSpans: unknown,\n+  projectId: string,\n+): Promise<Set<string>> {\n+  if (!redis) {\n+    console.warn(\"Redis client not available\");",
    "repo_full_name": "langfuse/langfuse",
    "discussion_comments": [
      {
        "comment_id": "2140577156",
        "repo_full_name": "langfuse/langfuse",
        "pr_number": 7241,
        "pr_file": "web/src/features/otel/server/index.ts",
        "discussion_id": "2140577156",
        "commented_code": "@@ -1,7 +1,57 @@\n-import { type IngestionEventType } from \"@langfuse/shared/src/server\";\n+import {\n+  type TraceEventType,\n+  type IngestionEventType,\n+} from \"@langfuse/shared/src/server\";\n import { randomUUID } from \"crypto\";\n import { ForbiddenError, ObservationLevel } from \"@langfuse/shared\";\n import { LangfuseOtelSpanAttributes } from \"./attributes\";\n+import { redis } from \"@langfuse/shared/src/server\";\n+\n+export async function getSeenTracesSet(\n+  resourceSpans: unknown,\n+  projectId: string,\n+): Promise<Set<string>> {\n+  if (!redis) {\n+    console.warn(\"Redis client not available\");",
        "comment_created_at": "2025-06-11T16:09:23+00:00",
        "comment_author": "Steffen911",
        "comment_body": "Let's use the logger library here instead of console statements.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2139565360",
    "pr_number": 7230,
    "pr_file": "web/src/features/datasets/server/service.ts",
    "created_at": "2025-06-11T08:46:07+00:00",
    "commented_code": "});\n \n   // check in clickhouse if the traces already exist. They arrive delayed.\n-  const traces = await getTracesByIds(\n-    datasetItems\n-      .map((item) => item.sourceTraceId)\n-      .filter((id): id is string => Boolean(id)),\n-    input.projectId,\n-  );\n+  const traceIds = datasetItems\n+    .map((item) => item.sourceTraceId)\n+    .filter((id): id is string => Boolean(id));\n+\n+  const observationIds = datasetItems\n+    .map((item) => item.sourceObservationId)\n+    .filter((id): id is string => Boolean(id));\n+\n+  const traces =\n+    traceIds.length > 0 ? await getTracesByIds(traceIds, input.projectId) : [];\n+  const observations =\n+    observationIds.length > 0\n+      ? await getObservationsById(observationIds, input.projectId)\n+      : [];\n+  // Only use raw SQL when filters are present\n+  if (filters.length > 0) {\n+    try {\n+      // Build base WHERE conditions\n+      let whereConditions = Prisma.sql`dataset_items.dataset_id = ${input.datasetId} AND dataset_items.project_id = ${input.projectId}`;\n+\n+      const filterSql = tableColumnsToSqlFilterAndPrefix(\n+        filters,\n+        datasetItemsTableCols,\n+        \"dataset_items\",\n+      );\n+      if (filterSql !== Prisma.empty) {\n+        whereConditions = Prisma.sql`${whereConditions} ${filterSql}`;\n+      }\n \n-  const observations = await getObservationsById(\n-    datasetItems\n-      .map((item) => item.sourceObservationId)\n-      .filter((id): id is string => Boolean(id)),\n-    input.projectId,\n-  );\n+      // Execute queries with combined conditions\n+      const selectQuery = Prisma.sql`\n+        SELECT * FROM dataset_items\n+        WHERE ${whereConditions}\n+        ORDER BY dataset_items.status ASC, dataset_items.created_at DESC\n+        LIMIT ${input.limit} OFFSET ${input.page * input.limit}\n+      `;\n+\n+      const countQuery = Prisma.sql`\n+        SELECT count(*) as count FROM dataset_items\n+        WHERE ${whereConditions}\n+      `;\n+\n+      const [newDatasetItems, countResult] = await Promise.all([\n+        input.prisma.$queryRaw<any[]>(selectQuery),\n+        input.prisma.$queryRaw<{ count: bigint }[]>(countQuery),\n+      ]);\n+\n+      // Use the filtered results\n+      datasetItems = newDatasetItems;\n+      totalDatasetItems = Number(countResult[0].count);\n+    } catch (error) {\n+      // Fall back to the original datasetItems if the raw query fails\n+      console.warn(",
    "repo_full_name": "langfuse/langfuse",
    "discussion_comments": [
      {
        "comment_id": "2139565360",
        "repo_full_name": "langfuse/langfuse",
        "pr_number": 7230,
        "pr_file": "web/src/features/datasets/server/service.ts",
        "discussion_id": "2139565360",
        "commented_code": "@@ -443,19 +447,64 @@ export const fetchDatasetItems = async (input: DatasetRunItemsTableInput) => {\n   });\n \n   // check in clickhouse if the traces already exist. They arrive delayed.\n-  const traces = await getTracesByIds(\n-    datasetItems\n-      .map((item) => item.sourceTraceId)\n-      .filter((id): id is string => Boolean(id)),\n-    input.projectId,\n-  );\n+  const traceIds = datasetItems\n+    .map((item) => item.sourceTraceId)\n+    .filter((id): id is string => Boolean(id));\n+\n+  const observationIds = datasetItems\n+    .map((item) => item.sourceObservationId)\n+    .filter((id): id is string => Boolean(id));\n+\n+  const traces =\n+    traceIds.length > 0 ? await getTracesByIds(traceIds, input.projectId) : [];\n+  const observations =\n+    observationIds.length > 0\n+      ? await getObservationsById(observationIds, input.projectId)\n+      : [];\n+  // Only use raw SQL when filters are present\n+  if (filters.length > 0) {\n+    try {\n+      // Build base WHERE conditions\n+      let whereConditions = Prisma.sql`dataset_items.dataset_id = ${input.datasetId} AND dataset_items.project_id = ${input.projectId}`;\n+\n+      const filterSql = tableColumnsToSqlFilterAndPrefix(\n+        filters,\n+        datasetItemsTableCols,\n+        \"dataset_items\",\n+      );\n+      if (filterSql !== Prisma.empty) {\n+        whereConditions = Prisma.sql`${whereConditions} ${filterSql}`;\n+      }\n \n-  const observations = await getObservationsById(\n-    datasetItems\n-      .map((item) => item.sourceObservationId)\n-      .filter((id): id is string => Boolean(id)),\n-    input.projectId,\n-  );\n+      // Execute queries with combined conditions\n+      const selectQuery = Prisma.sql`\n+        SELECT * FROM dataset_items\n+        WHERE ${whereConditions}\n+        ORDER BY dataset_items.status ASC, dataset_items.created_at DESC\n+        LIMIT ${input.limit} OFFSET ${input.page * input.limit}\n+      `;\n+\n+      const countQuery = Prisma.sql`\n+        SELECT count(*) as count FROM dataset_items\n+        WHERE ${whereConditions}\n+      `;\n+\n+      const [newDatasetItems, countResult] = await Promise.all([\n+        input.prisma.$queryRaw<any[]>(selectQuery),\n+        input.prisma.$queryRaw<{ count: bigint }[]>(countQuery),\n+      ]);\n+\n+      // Use the filtered results\n+      datasetItems = newDatasetItems;\n+      totalDatasetItems = Number(countResult[0].count);\n+    } catch (error) {\n+      // Fall back to the original datasetItems if the raw query fails\n+      console.warn(",
        "comment_created_at": "2025-06-11T08:46:07+00:00",
        "comment_author": "ellipsis-dev[bot]",
        "comment_body": "In the catch block for the raw SQL query in `fetchDatasetItems`, a `console.warn` is used to log errors. For consistency and better error tracking in a server environment, consider using a dedicated logger (e.g. `logger.warn` or `logger.error`) instead of `console.warn`.\n```suggestion\n      logger.warn(\n```\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2104881514",
    "pr_number": 7001,
    "pr_file": "worker/src/features/batchAction/handleBatchActionJob.ts",
    "created_at": "2025-05-23T15:50:39+00:00",
    "commented_code": "let count = 0;\n     for await (const record of dbReadStream) {\n+      logger.info(`record ${record}`);",
    "repo_full_name": "langfuse/langfuse",
    "discussion_comments": [
      {
        "comment_id": "2104881514",
        "repo_full_name": "langfuse/langfuse",
        "pr_number": 7001,
        "pr_file": "worker/src/features/batchAction/handleBatchActionJob.ts",
        "discussion_id": "2104881514",
        "commented_code": "@@ -209,6 +205,7 @@ export const handleBatchActionJob = async (\n \n     let count = 0;\n     for await (const record of dbReadStream) {\n+      logger.info(`record ${record}`);",
        "comment_created_at": "2025-05-23T15:50:39+00:00",
        "comment_author": "ellipsis-dev[bot]",
        "comment_body": "Logging the `record` object via string interpolation may result in `'[object Object]'`. Consider passing the object directly to the logger (e.g., `logger.info('record', record)`) for clearer output.\n```suggestion\n      logger.info('record', record);\n```\n",
        "pr_file_module": null
      }
    ]
  }
]