[
  {
    "discussion_id": "2265249023",
    "pr_number": 13423,
    "pr_file": "model_prices_and_context_window.json",
    "created_at": "2025-08-10T11:54:12+00:00",
    "commented_code": "},\n     \"gpt-5-2025-08-07\": {\n         \"max_tokens\": 128000,\n-        \"max_input_tokens\": 400000,\n+        \"max_input_tokens\": 2720000,",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2265249023",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 13423,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2265249023",
        "commented_code": "@@ -775,7 +774,7 @@\n     },\n     \"gpt-5-2025-08-07\": {\n         \"max_tokens\": 128000,\n-        \"max_input_tokens\": 400000,\n+        \"max_input_tokens\": 2720000,",
        "comment_created_at": "2025-08-10T11:54:12+00:00",
        "comment_author": "tgabi333",
        "comment_body": "i think its a typo",
        "pr_file_module": null
      },
      {
        "comment_id": "2265318010",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 13423,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2265249023",
        "commented_code": "@@ -775,7 +774,7 @@\n     },\n     \"gpt-5-2025-08-07\": {\n         \"max_tokens\": 128000,\n-        \"max_input_tokens\": 400000,\n+        \"max_input_tokens\": 2720000,",
        "comment_created_at": "2025-08-10T14:50:29+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "fixed on main",
        "pr_file_module": null
      },
      {
        "comment_id": "2265352038",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 13423,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2265249023",
        "commented_code": "@@ -775,7 +774,7 @@\n     },\n     \"gpt-5-2025-08-07\": {\n         \"max_tokens\": 128000,\n-        \"max_input_tokens\": 400000,\n+        \"max_input_tokens\": 2720000,",
        "comment_created_at": "2025-08-10T16:27:19+00:00",
        "comment_author": "emerzon",
        "comment_body": "@krrishdholakia You reverted to the previous incorrect value of 400k. The correct value is 272k. The inicial commit only had an extra zero",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2265160615",
    "pr_number": 13385,
    "pr_file": "litellm/model_prices_and_context_window_backup.json",
    "created_at": "2025-08-10T07:46:33+00:00",
    "commented_code": "\"/v1/audio/speech\"\n         ]\n     },\n+    \"gpt-5\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 1.25e-06,\n+        \"output_cost_per_token\": 1e-05,\n+        \"cache_read_input_token_cost\": 1.25e-07,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-2025-08-07\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 1.25e-06,\n+        \"output_cost_per_token\": 1e-05,\n+        \"cache_read_input_token_cost\": 1.25e-07,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-mini\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 2.5e-07,\n+        \"output_cost_per_token\": 2e-06,\n+        \"cache_read_input_token_cost\": 2.5e-08,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-mini-2025-08-07\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 2.5e-07,\n+        \"output_cost_per_token\": 2e-06,\n+        \"cache_read_input_token_cost\": 2.5e-08,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-nano-2025-08-07\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 5e-08,\n+        \"output_cost_per_token\": 4e-07,\n+        \"cache_read_input_token_cost\": 5e-09,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-nano\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 5e-08,\n+        \"output_cost_per_token\": 4e-07,\n+        \"cache_read_input_token_cost\": 5e-09,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-chat\": {\n+        \"max_tokens\": 32768,\n+        \"max_input_tokens\": 1047576,",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2265160615",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 13385,
        "pr_file": "litellm/model_prices_and_context_window_backup.json",
        "discussion_id": "2265160615",
        "commented_code": "@@ -2007,6 +2007,520 @@\n             \"/v1/audio/speech\"\n         ]\n     },\n+    \"gpt-5\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 1.25e-06,\n+        \"output_cost_per_token\": 1e-05,\n+        \"cache_read_input_token_cost\": 1.25e-07,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-2025-08-07\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 1.25e-06,\n+        \"output_cost_per_token\": 1e-05,\n+        \"cache_read_input_token_cost\": 1.25e-07,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-mini\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 2.5e-07,\n+        \"output_cost_per_token\": 2e-06,\n+        \"cache_read_input_token_cost\": 2.5e-08,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-mini-2025-08-07\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 2.5e-07,\n+        \"output_cost_per_token\": 2e-06,\n+        \"cache_read_input_token_cost\": 2.5e-08,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-nano-2025-08-07\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 5e-08,\n+        \"output_cost_per_token\": 4e-07,\n+        \"cache_read_input_token_cost\": 5e-09,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-nano\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 5e-08,\n+        \"output_cost_per_token\": 4e-07,\n+        \"cache_read_input_token_cost\": 5e-09,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-chat\": {\n+        \"max_tokens\": 32768,\n+        \"max_input_tokens\": 1047576,",
        "comment_created_at": "2025-08-10T07:46:33+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "based on this - it should be 400k input tokens \r\n<img width=\"1082\" height=\"432\" alt=\"Screenshot 2025-08-10 at 12 46 25 AM\" src=\"https://github.com/user-attachments/assets/e8be2274-2fa2-4ff0-b4e4-66c351ae7ae9\" />\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2265161024",
    "pr_number": 13385,
    "pr_file": "litellm/model_prices_and_context_window_backup.json",
    "created_at": "2025-08-10T07:48:02+00:00",
    "commented_code": "\"/v1/audio/speech\"\n         ]\n     },\n+    \"gpt-5\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 1.25e-06,\n+        \"output_cost_per_token\": 1e-05,\n+        \"cache_read_input_token_cost\": 1.25e-07,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-2025-08-07\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 1.25e-06,\n+        \"output_cost_per_token\": 1e-05,\n+        \"cache_read_input_token_cost\": 1.25e-07,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-mini\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 2.5e-07,\n+        \"output_cost_per_token\": 2e-06,\n+        \"cache_read_input_token_cost\": 2.5e-08,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-mini-2025-08-07\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 2.5e-07,\n+        \"output_cost_per_token\": 2e-06,\n+        \"cache_read_input_token_cost\": 2.5e-08,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-nano-2025-08-07\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 5e-08,\n+        \"output_cost_per_token\": 4e-07,\n+        \"cache_read_input_token_cost\": 5e-09,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-nano\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 5e-08,\n+        \"output_cost_per_token\": 4e-07,\n+        \"cache_read_input_token_cost\": 5e-09,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-chat\": {\n+        \"max_tokens\": 32768,\n+        \"max_input_tokens\": 1047576,\n+        \"max_output_tokens\": 32768,\n+        \"input_cost_per_token\": 5e-06,",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2265161024",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 13385,
        "pr_file": "litellm/model_prices_and_context_window_backup.json",
        "discussion_id": "2265161024",
        "commented_code": "@@ -2007,6 +2007,520 @@\n             \"/v1/audio/speech\"\n         ]\n     },\n+    \"gpt-5\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 1.25e-06,\n+        \"output_cost_per_token\": 1e-05,\n+        \"cache_read_input_token_cost\": 1.25e-07,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-2025-08-07\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 1.25e-06,\n+        \"output_cost_per_token\": 1e-05,\n+        \"cache_read_input_token_cost\": 1.25e-07,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-mini\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 2.5e-07,\n+        \"output_cost_per_token\": 2e-06,\n+        \"cache_read_input_token_cost\": 2.5e-08,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-mini-2025-08-07\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 2.5e-07,\n+        \"output_cost_per_token\": 2e-06,\n+        \"cache_read_input_token_cost\": 2.5e-08,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-nano-2025-08-07\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 5e-08,\n+        \"output_cost_per_token\": 4e-07,\n+        \"cache_read_input_token_cost\": 5e-09,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-nano\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 400000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 5e-08,\n+        \"output_cost_per_token\": 4e-07,\n+        \"cache_read_input_token_cost\": 5e-09,\n+        \"litellm_provider\": \"openai\",\n+        \"mode\": \"chat\",\n+        \"supported_endpoints\": [\n+            \"/v1/chat/completions\",\n+            \"/v1/batch\",\n+            \"/v1/responses\"\n+        ],\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"supports_pdf_input\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_parallel_function_calling\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_vision\": true,\n+        \"supports_prompt_caching\": true,\n+        \"supports_system_messages\": true,\n+        \"supports_tool_choice\": true,\n+        \"supports_native_streaming\": true,\n+        \"supports_reasoning\": true\n+    },\n+    \"gpt-5-chat\": {\n+        \"max_tokens\": 32768,\n+        \"max_input_tokens\": 1047576,\n+        \"max_output_tokens\": 32768,\n+        \"input_cost_per_token\": 5e-06,",
        "comment_created_at": "2025-08-10T07:48:02+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "the input_cost_per_Token and output_cost_per_token are incorrect \r\n<img width=\"1168\" height=\"491\" alt=\"Screenshot 2025-08-10 at 12 47 56 AM\" src=\"https://github.com/user-attachments/assets/5ac62e73-dd3a-44c2-acd1-1d15f4f0ef02\" />\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2234041416",
    "pr_number": 12829,
    "pr_file": "litellm/model_prices_and_context_window_backup.json",
    "created_at": "2025-07-27T15:58:33+00:00",
    "commented_code": "\"mode\": \"chat\",\n         \"supports_tool_choice\": true\n     },\n+    \"openrouter/qwen/qwen-vl-plus\": {\n+        \"max_tokens\": 8192,\n+        \"max_input_tokens\": 8192,\n+        \"max_output_tokens\": 2048,\n+        \"input_cost_per_token\": 0.00021,",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2234041416",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 12829,
        "pr_file": "litellm/model_prices_and_context_window_backup.json",
        "discussion_id": "2234041416",
        "commented_code": "@@ -10898,6 +10898,16 @@\n         \"mode\": \"chat\",\n         \"supports_tool_choice\": true\n     },\n+    \"openrouter/qwen/qwen-vl-plus\": {\n+        \"max_tokens\": 8192,\n+        \"max_input_tokens\": 8192,\n+        \"max_output_tokens\": 2048,\n+        \"input_cost_per_token\": 0.00021,",
        "comment_created_at": "2025-07-27T15:58:33+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "this should be in scientific notation. ",
        "pr_file_module": null
      },
      {
        "comment_id": "2234041824",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 12829,
        "pr_file": "litellm/model_prices_and_context_window_backup.json",
        "discussion_id": "2234041416",
        "commented_code": "@@ -10898,6 +10898,16 @@\n         \"mode\": \"chat\",\n         \"supports_tool_choice\": true\n     },\n+    \"openrouter/qwen/qwen-vl-plus\": {\n+        \"max_tokens\": 8192,\n+        \"max_input_tokens\": 8192,\n+        \"max_output_tokens\": 2048,\n+        \"input_cost_per_token\": 0.00021,",
        "comment_created_at": "2025-07-27T15:59:53+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "The pricing `0.00021` is incorrect. It's 0.21/1m tokens\r\n<img width=\"1215\" height=\"210\" alt=\"Screenshot 2025-07-27 at 8 59 26 AM\" src=\"https://github.com/user-attachments/assets/6e2422a3-7611-4b39-b77e-8007895128be\" />\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2199606790",
    "pr_number": 12478,
    "pr_file": "model_prices_and_context_window.json",
    "created_at": "2025-07-11T05:08:35+00:00",
    "commented_code": "\"calculation\": \"$0.22/hour = $0.00366/minute = $0.0000611 per second (enterprise pricing)\",\n             \"notes\": \"ElevenLabs Scribe v1 experimental - enhanced version of the main Scribe model\"\n         }\n+    },\n+    \"eu.mistral.pixtral-large-2502-v1:0\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 128000,\n+        \"max_output_tokens\": 4096,\n+        \"input_cost_per_token\": 2e-06,\n+        \"output_cost_per_token\": 6e-06,\n+        \"litellm_provider\": \"bedrock\",",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2199606790",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 12478,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2199606790",
        "commented_code": "@@ -15795,5 +15795,27 @@\n             \"calculation\": \"$0.22/hour = $0.00366/minute = $0.0000611 per second (enterprise pricing)\",\n             \"notes\": \"ElevenLabs Scribe v1 experimental - enhanced version of the main Scribe model\"\n         }\n+    },\n+    \"eu.mistral.pixtral-large-2502-v1:0\": {\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 128000,\n+        \"max_output_tokens\": 4096,\n+        \"input_cost_per_token\": 2e-06,\n+        \"output_cost_per_token\": 6e-06,\n+        \"litellm_provider\": \"bedrock\",",
        "comment_created_at": "2025-07-11T05:08:35+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "provider should be `bedrock_converse` as these are converse supported models - https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference-supported-models-features.html",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2153166464",
    "pr_number": 11808,
    "pr_file": "model_prices_and_context_window.json",
    "created_at": "2025-06-17T21:03:26+00:00",
    "commented_code": "\"supports_tool_choice\": true,\n         \"supports_web_search\": true\n     },\n+    \"gemini/gemini-2.5-flash-lite-preview-06-17\": {\n+        \"max_tokens\": 8192,\n+        \"max_input_tokens\": 1048576,\n+        \"max_output_tokens\": 8192,\n+        \"max_images_per_prompt\": 3000,\n+        \"max_videos_per_prompt\": 10,\n+        \"max_video_length\": 1,\n+        \"input_cost_per_audio_token\": 7.5e-08,\n+        \"input_cost_per_token\": 7.5e-08,\n+        \"output_cost_per_token\": 3e-07,\n+        \"litellm_provider\": \"gemini\",\n+        \"mode\": \"chat\",\n+        \"rpm\": 60000,\n+        \"tpm\": 10000000,\n+        \"supports_system_messages\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_vision\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_audio_output\": false,\n+        \"supports_tool_choice\": true,\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\",\n+            \"audio\",\n+            \"video\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.5-flash-lite\",\n+        \"supports_web_search\": true\n+    },\n+    \"gemini/gemini-2.5-flash\": {\n+        \"max_tokens\": 8192,\n+        \"max_input_tokens\": 1048576,\n+        \"max_output_tokens\": 8192,\n+        \"max_images_per_prompt\": 3000,\n+        \"max_videos_per_prompt\": 10,\n+        \"input_cost_per_audio_token\": 3e-07,\n+        \"input_cost_per_token\": 3e-07,\n+        \"output_cost_per_token\": 2.5e-06,\n+        \"litellm_provider\": \"gemini\",\n+        \"mode\": \"chat\",\n+        \"rpm\": 60000,\n+        \"tpm\": 10000000,\n+        \"supports_system_messages\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_vision\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_audio_output\": false,\n+        \"supports_tool_choice\": true,\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\",\n+            \"audio\",\n+            \"video\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.5-flash\",\n+        \"supports_web_search\": true\n+    },\n+    \"gemini/gemini-2.5-pro\": {\n+        \"max_tokens\": 8192,\n+        \"max_input_tokens\": 1048576,\n+        \"max_output_tokens\": 8192,",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2153166464",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11808,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2153166464",
        "commented_code": "@@ -7732,6 +7717,100 @@\n         \"supports_tool_choice\": true,\n         \"supports_web_search\": true\n     },\n+    \"gemini/gemini-2.5-flash-lite-preview-06-17\": {\n+        \"max_tokens\": 8192,\n+        \"max_input_tokens\": 1048576,\n+        \"max_output_tokens\": 8192,\n+        \"max_images_per_prompt\": 3000,\n+        \"max_videos_per_prompt\": 10,\n+        \"max_video_length\": 1,\n+        \"input_cost_per_audio_token\": 7.5e-08,\n+        \"input_cost_per_token\": 7.5e-08,\n+        \"output_cost_per_token\": 3e-07,\n+        \"litellm_provider\": \"gemini\",\n+        \"mode\": \"chat\",\n+        \"rpm\": 60000,\n+        \"tpm\": 10000000,\n+        \"supports_system_messages\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_vision\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_audio_output\": false,\n+        \"supports_tool_choice\": true,\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\",\n+            \"audio\",\n+            \"video\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.5-flash-lite\",\n+        \"supports_web_search\": true\n+    },\n+    \"gemini/gemini-2.5-flash\": {\n+        \"max_tokens\": 8192,\n+        \"max_input_tokens\": 1048576,\n+        \"max_output_tokens\": 8192,\n+        \"max_images_per_prompt\": 3000,\n+        \"max_videos_per_prompt\": 10,\n+        \"input_cost_per_audio_token\": 3e-07,\n+        \"input_cost_per_token\": 3e-07,\n+        \"output_cost_per_token\": 2.5e-06,\n+        \"litellm_provider\": \"gemini\",\n+        \"mode\": \"chat\",\n+        \"rpm\": 60000,\n+        \"tpm\": 10000000,\n+        \"supports_system_messages\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_vision\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_audio_output\": false,\n+        \"supports_tool_choice\": true,\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\",\n+            \"audio\",\n+            \"video\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.5-flash\",\n+        \"supports_web_search\": true\n+    },\n+    \"gemini/gemini-2.5-pro\": {\n+        \"max_tokens\": 8192,\n+        \"max_input_tokens\": 1048576,\n+        \"max_output_tokens\": 8192,",
        "comment_created_at": "2025-06-17T21:03:26+00:00",
        "comment_author": "pauljz",
        "comment_body": "Should this be 65535 per [Google's documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-pro)?",
        "pr_file_module": null
      },
      {
        "comment_id": "2153271268",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11808,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2153166464",
        "commented_code": "@@ -7732,6 +7717,100 @@\n         \"supports_tool_choice\": true,\n         \"supports_web_search\": true\n     },\n+    \"gemini/gemini-2.5-flash-lite-preview-06-17\": {\n+        \"max_tokens\": 8192,\n+        \"max_input_tokens\": 1048576,\n+        \"max_output_tokens\": 8192,\n+        \"max_images_per_prompt\": 3000,\n+        \"max_videos_per_prompt\": 10,\n+        \"max_video_length\": 1,\n+        \"input_cost_per_audio_token\": 7.5e-08,\n+        \"input_cost_per_token\": 7.5e-08,\n+        \"output_cost_per_token\": 3e-07,\n+        \"litellm_provider\": \"gemini\",\n+        \"mode\": \"chat\",\n+        \"rpm\": 60000,\n+        \"tpm\": 10000000,\n+        \"supports_system_messages\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_vision\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_audio_output\": false,\n+        \"supports_tool_choice\": true,\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\",\n+            \"audio\",\n+            \"video\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.5-flash-lite\",\n+        \"supports_web_search\": true\n+    },\n+    \"gemini/gemini-2.5-flash\": {\n+        \"max_tokens\": 8192,\n+        \"max_input_tokens\": 1048576,\n+        \"max_output_tokens\": 8192,\n+        \"max_images_per_prompt\": 3000,\n+        \"max_videos_per_prompt\": 10,\n+        \"input_cost_per_audio_token\": 3e-07,\n+        \"input_cost_per_token\": 3e-07,\n+        \"output_cost_per_token\": 2.5e-06,\n+        \"litellm_provider\": \"gemini\",\n+        \"mode\": \"chat\",\n+        \"rpm\": 60000,\n+        \"tpm\": 10000000,\n+        \"supports_system_messages\": true,\n+        \"supports_function_calling\": true,\n+        \"supports_vision\": true,\n+        \"supports_response_schema\": true,\n+        \"supports_audio_output\": false,\n+        \"supports_tool_choice\": true,\n+        \"supported_modalities\": [\n+            \"text\",\n+            \"image\",\n+            \"audio\",\n+            \"video\"\n+        ],\n+        \"supported_output_modalities\": [\n+            \"text\"\n+        ],\n+        \"source\": \"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-2.5-flash\",\n+        \"supports_web_search\": true\n+    },\n+    \"gemini/gemini-2.5-pro\": {\n+        \"max_tokens\": 8192,\n+        \"max_input_tokens\": 1048576,\n+        \"max_output_tokens\": 8192,",
        "comment_created_at": "2025-06-17T22:26:27+00:00",
        "comment_author": "colesmcintosh",
        "comment_body": "Yes!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2159884997",
    "pr_number": 11926,
    "pr_file": "model_prices_and_context_window.json",
    "created_at": "2025-06-21T06:18:45+00:00",
    "commented_code": "\"mode\": \"chat\",\n         \"supports_tool_choice\": true\n     },\n+    \"mistralai/mistral-small-3.2-24b-instruct\": {\n+        \"max_tokens\": 32000,\n+        \"input_cost_per_token\": 1e-07,\n+        \"output_cost_per_token\": 3e-07,\n+        \"litellm_provider\": \"openrouter\",",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2159884997",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11926,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2159884997",
        "commented_code": "@@ -9961,6 +9961,14 @@\n         \"mode\": \"chat\",\n         \"supports_tool_choice\": true\n     },\n+    \"mistralai/mistral-small-3.2-24b-instruct\": {\n+        \"max_tokens\": 32000,\n+        \"input_cost_per_token\": 1e-07,\n+        \"output_cost_per_token\": 3e-07,\n+        \"litellm_provider\": \"openrouter\",",
        "comment_created_at": "2025-06-21T06:18:45+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "the provider should be mistral, if it's openrouter the model name should begin with `openrouter/` ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2153677590",
    "pr_number": 11830,
    "pr_file": "model_prices_and_context_window.json",
    "created_at": "2025-06-18T05:32:31+00:00",
    "commented_code": "\"input_cost_per_token\": 3e-07,\n         \"output_cost_per_token\": 2.5e-06,\n         \"output_cost_per_reasoning_token\": 2.5e-06,\n-        \"litellm_provider\": \"vertex_ai-language-models\",\n+        \"litellm_provider\": \"gemini\",",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2153677590",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11830,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2153677590",
        "commented_code": "@@ -6775,7 +6775,7 @@\n         \"input_cost_per_token\": 3e-07,\n         \"output_cost_per_token\": 2.5e-06,\n         \"output_cost_per_reasoning_token\": 2.5e-06,\n-        \"litellm_provider\": \"vertex_ai-language-models\",\n+        \"litellm_provider\": \"gemini\",",
        "comment_created_at": "2025-06-18T05:32:31+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "this is incorrect. this model is for vertex ai. Not google ai studio. ",
        "pr_file_module": null
      },
      {
        "comment_id": "2153690368",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11830,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2153677590",
        "commented_code": "@@ -6775,7 +6775,7 @@\n         \"input_cost_per_token\": 3e-07,\n         \"output_cost_per_token\": 2.5e-06,\n         \"output_cost_per_reasoning_token\": 2.5e-06,\n-        \"litellm_provider\": \"vertex_ai-language-models\",\n+        \"litellm_provider\": \"gemini\",",
        "comment_created_at": "2025-06-18T05:43:54+00:00",
        "comment_author": "lowjiansheng",
        "comment_body": "Got it, does it mean we'll need to add a new entry for the Gemini version?",
        "pr_file_module": null
      },
      {
        "comment_id": "2153766219",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11830,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2153677590",
        "commented_code": "@@ -6775,7 +6775,7 @@\n         \"input_cost_per_token\": 3e-07,\n         \"output_cost_per_token\": 2.5e-06,\n         \"output_cost_per_reasoning_token\": 2.5e-06,\n-        \"litellm_provider\": \"vertex_ai-language-models\",\n+        \"litellm_provider\": \"gemini\",",
        "comment_created_at": "2025-06-18T06:38:27+00:00",
        "comment_author": "Classic298",
        "comment_body": "Yes",
        "pr_file_module": null
      },
      {
        "comment_id": "2153781132",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11830,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2153677590",
        "commented_code": "@@ -6775,7 +6775,7 @@\n         \"input_cost_per_token\": 3e-07,\n         \"output_cost_per_token\": 2.5e-06,\n         \"output_cost_per_reasoning_token\": 2.5e-06,\n-        \"litellm_provider\": \"vertex_ai-language-models\",\n+        \"litellm_provider\": \"gemini\",",
        "comment_created_at": "2025-06-18T06:47:58+00:00",
        "comment_author": "lowjiansheng",
        "comment_body": "Done, added a new gemini-2.5 flash for AI Studio that's separate from the Vertex one",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2047823960",
    "pr_number": 10077,
    "pr_file": "model_prices_and_context_window.json",
    "created_at": "2025-04-16T21:56:26+00:00",
    "commented_code": "\"supports_prompt_caching\": true\n     },\n     \"groq/deepseek-r1-distill-llama-70b\": {\n-        \"max_tokens\": 131072,\n-        \"max_input_tokens\": 131072,\n-        \"max_output_tokens\": 131072,\n-        \"input_cost_per_token\": 0.00000075,\n-        \"output_cost_per_token\": 0.00000099,\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 128000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 7.5e-07,\n+        \"output_cost_per_token\": 9.9e-07,\n         \"litellm_provider\": \"groq\",\n         \"mode\": \"chat\",\n-        \"supports_system_messages\": false,",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2047823960",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 10077,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2047823960",
        "commented_code": "@@ -3423,25 +3423,24 @@\n         \"supports_prompt_caching\": true\n     },\n     \"groq/deepseek-r1-distill-llama-70b\": {\n-        \"max_tokens\": 131072,\n-        \"max_input_tokens\": 131072,\n-        \"max_output_tokens\": 131072,\n-        \"input_cost_per_token\": 0.00000075,\n-        \"output_cost_per_token\": 0.00000099,\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 128000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 7.5e-07,\n+        \"output_cost_per_token\": 9.9e-07,\n         \"litellm_provider\": \"groq\",\n         \"mode\": \"chat\",\n-        \"supports_system_messages\": false,",
        "comment_created_at": "2025-04-16T21:56:26+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "if we pass a system prompt to deepseek on groq, will it work? ",
        "pr_file_module": null
      },
      {
        "comment_id": "2047855803",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 10077,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2047823960",
        "commented_code": "@@ -3423,25 +3423,24 @@\n         \"supports_prompt_caching\": true\n     },\n     \"groq/deepseek-r1-distill-llama-70b\": {\n-        \"max_tokens\": 131072,\n-        \"max_input_tokens\": 131072,\n-        \"max_output_tokens\": 131072,\n-        \"input_cost_per_token\": 0.00000075,\n-        \"output_cost_per_token\": 0.00000099,\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 128000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 7.5e-07,\n+        \"output_cost_per_token\": 9.9e-07,\n         \"litellm_provider\": \"groq\",\n         \"mode\": \"chat\",\n-        \"supports_system_messages\": false,",
        "comment_created_at": "2025-04-16T22:31:47+00:00",
        "comment_author": "naliotopier",
        "comment_body": "Yes, it will. I think it's just not as accurate when you use a system prompt for R1 based models.\r\n\r\nExample of it working:\r\n<img width=\"1494\" alt=\"Screenshot 2025-04-16 at 3 28 46\u202fPM\" src=\"https://github.com/user-attachments/assets/a6fa1463-9078-412d-9b3b-225df35c118f\" />\r\n(this api key was revoked before posting)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2047824608",
    "pr_number": 10077,
    "pr_file": "model_prices_and_context_window.json",
    "created_at": "2025-04-16T21:56:52+00:00",
    "commented_code": "\"supports_prompt_caching\": true\n     },\n     \"groq/deepseek-r1-distill-llama-70b\": {\n-        \"max_tokens\": 131072,\n-        \"max_input_tokens\": 131072,\n-        \"max_output_tokens\": 131072,\n-        \"input_cost_per_token\": 0.00000075,\n-        \"output_cost_per_token\": 0.00000099,\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 128000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 7.5e-07,\n+        \"output_cost_per_token\": 9.9e-07,\n         \"litellm_provider\": \"groq\",\n         \"mode\": \"chat\",\n-        \"supports_system_messages\": false,\n-        \"supports_function_calling\": false, \n+        \"supports_function_calling\": true,\n+        \"supports_response_schema\": true,\n         \"supports_reasoning\": true,\n-        \"supports_response_schema\": false,\n         \"supports_tool_choice\": true\n     },\n     \"groq/llama-3.3-70b-versatile\": {\n-        \"max_tokens\": 8192,\n+        \"max_tokens\": 32768,",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2047824608",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 10077,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2047824608",
        "commented_code": "@@ -3423,25 +3423,24 @@\n         \"supports_prompt_caching\": true\n     },\n     \"groq/deepseek-r1-distill-llama-70b\": {\n-        \"max_tokens\": 131072,\n-        \"max_input_tokens\": 131072,\n-        \"max_output_tokens\": 131072,\n-        \"input_cost_per_token\": 0.00000075,\n-        \"output_cost_per_token\": 0.00000099,\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 128000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 7.5e-07,\n+        \"output_cost_per_token\": 9.9e-07,\n         \"litellm_provider\": \"groq\",\n         \"mode\": \"chat\",\n-        \"supports_system_messages\": false,\n-        \"supports_function_calling\": false, \n+        \"supports_function_calling\": true,\n+        \"supports_response_schema\": true,\n         \"supports_reasoning\": true,\n-        \"supports_response_schema\": false,\n         \"supports_tool_choice\": true\n     },\n     \"groq/llama-3.3-70b-versatile\": {\n-        \"max_tokens\": 8192,\n+        \"max_tokens\": 32768,",
        "comment_created_at": "2025-04-16T21:56:52+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "can you please cite a source for the changes, so it's easy to see where this data is being pulled from? (similar to vertex ai) ",
        "pr_file_module": null
      },
      {
        "comment_id": "2047844207",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 10077,
        "pr_file": "model_prices_and_context_window.json",
        "discussion_id": "2047824608",
        "commented_code": "@@ -3423,25 +3423,24 @@\n         \"supports_prompt_caching\": true\n     },\n     \"groq/deepseek-r1-distill-llama-70b\": {\n-        \"max_tokens\": 131072,\n-        \"max_input_tokens\": 131072,\n-        \"max_output_tokens\": 131072,\n-        \"input_cost_per_token\": 0.00000075,\n-        \"output_cost_per_token\": 0.00000099,\n+        \"max_tokens\": 128000,\n+        \"max_input_tokens\": 128000,\n+        \"max_output_tokens\": 128000,\n+        \"input_cost_per_token\": 7.5e-07,\n+        \"output_cost_per_token\": 9.9e-07,\n         \"litellm_provider\": \"groq\",\n         \"mode\": \"chat\",\n-        \"supports_system_messages\": false,\n-        \"supports_function_calling\": false, \n+        \"supports_function_calling\": true,\n+        \"supports_response_schema\": true,\n         \"supports_reasoning\": true,\n-        \"supports_response_schema\": false,\n         \"supports_tool_choice\": true\n     },\n     \"groq/llama-3.3-70b-versatile\": {\n-        \"max_tokens\": 8192,\n+        \"max_tokens\": 32768,",
        "comment_created_at": "2025-04-16T22:17:49+00:00",
        "comment_author": "naliotopier",
        "comment_body": "Sure thing, here's the [source](https://console.groq.com/docs/models)\r\n\r\nThis was also linked above (along with all other relevant sources). Please let me know if there was a different way you wanted me to approach that.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1938200206",
    "pr_number": 8093,
    "pr_file": "litellm/model_prices_and_context_window_backup.json",
    "created_at": "2025-02-01T05:15:49+00:00",
    "commented_code": "\"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n         \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}\n     },\n-    \"databricks/meta-llama-3.3-70b-instruct\": {\n+    \"databricks/databricks-meta-llama-3-3-70b-instruct\": {",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "1938200206",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 8093,
        "pr_file": "litellm/model_prices_and_context_window_backup.json",
        "discussion_id": "1938200206",
        "commented_code": "@@ -8015,7 +8015,7 @@\n         \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n         \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}\n     },\n-    \"databricks/meta-llama-3.3-70b-instruct\": {\n+    \"databricks/databricks-meta-llama-3-3-70b-instruct\": {",
        "comment_created_at": "2025-02-01T05:15:49+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "is this the model name returned by databricks? if so, can you share the response object you see? \r\n\r\ncontext - the model name returned by provider is what is used for cost tracking ",
        "pr_file_module": null
      },
      {
        "comment_id": "1939779212",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 8093,
        "pr_file": "litellm/model_prices_and_context_window_backup.json",
        "discussion_id": "1938200206",
        "commented_code": "@@ -8015,7 +8015,7 @@\n         \"source\": \"https://www.databricks.com/product/pricing/foundation-model-serving\",\n         \"metadata\": {\"notes\": \"Input/output cost per token is dbu cost * $0.070, based on databricks Llama 3.1 70B conversion. Number provided for reference, '*_dbu_cost_per_token' used in actual calculation.\"}\n     },\n-    \"databricks/meta-llama-3.3-70b-instruct\": {\n+    \"databricks/databricks-meta-llama-3-3-70b-instruct\": {",
        "comment_created_at": "2025-02-03T17:36:59+00:00",
        "comment_author": "anton164",
        "comment_body": "yes, this is the model name used by Databricks.\r\n\r\nThe current key `databricks/meta-llama-3.3-70b-instruct` has no use in Databricks APIs. It gives a 404 when using it in LiteLLM.\r\n\r\nSee attached img:\r\n<img width=\"1341\" alt=\"Screenshot 2025-02-03 at 12 35 57\u202fPM\" src=\"https://github.com/user-attachments/assets/19ca42b1-c1b6-45cc-ba87-512fb0f5f385\" />\r\n\r\n\r\nAnd the docs: https://docs.databricks.com/en/machine-learning/model-serving/foundation-model-overview.html#pay-per-token",
        "pr_file_module": null
      }
    ]
  }
]