[
  {
    "discussion_id": "1986500456",
    "pr_number": 6981,
    "pr_file": "litellm/utils.py",
    "created_at": "2025-03-10T01:49:08+00:00",
    "commented_code": ")\n \n         except Exception as e:\n+            print(\"error\", e)",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "1986500456",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 6981,
        "pr_file": "litellm/utils.py",
        "discussion_id": "1986500456",
        "commented_code": "@@ -927,6 +927,7 @@ def post_call_processing(original_response, model, optional_params: Optional[dic\n                                     )\n \n         except Exception as e:\n+            print(\"error\", e)",
        "comment_created_at": "2025-03-10T01:49:08+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "please remove any print statements",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1938869606",
    "pr_number": 8202,
    "pr_file": "litellm/litellm_core_utils/streaming_handler.py",
    "created_at": "2025-02-03T06:55:29+00:00",
    "commented_code": "if response is None:\n                         continue\n                     ## LOGGING\n-                    threading.Thread(\n-                        target=self.run_success_logging_and_cache_storage,\n-                        args=(response, cache_hit),\n-                    ).start()  # log response\n+                    if litellm.sync_logging:",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "1938869606",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 8202,
        "pr_file": "litellm/litellm_core_utils/streaming_handler.py",
        "discussion_id": "1938869606",
        "commented_code": "@@ -1427,10 +1430,13 @@ def __next__(self):  # noqa: PLR0915\n                     if response is None:\n                         continue\n                     ## LOGGING\n-                    threading.Thread(\n-                        target=self.run_success_logging_and_cache_storage,\n-                        args=(response, cache_hit),\n-                    ).start()  # log response\n+                    if litellm.sync_logging:",
        "comment_created_at": "2025-02-03T06:55:29+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "having so many if/else blocks re: logging in the codebase can lead to bugs\r\n\r\ncan we use a more general pattern / function here which can ensure consistent behaviour? @B-Step62 @ishaan-jaff ",
        "pr_file_module": null
      },
      {
        "comment_id": "1938887539",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 8202,
        "pr_file": "litellm/litellm_core_utils/streaming_handler.py",
        "discussion_id": "1938869606",
        "commented_code": "@@ -1427,10 +1430,13 @@ def __next__(self):  # noqa: PLR0915\n                     if response is None:\n                         continue\n                     ## LOGGING\n-                    threading.Thread(\n-                        target=self.run_success_logging_and_cache_storage,\n-                        args=(response, cache_hit),\n-                    ).start()  # log response\n+                    if litellm.sync_logging:",
        "comment_created_at": "2025-02-03T07:13:15+00:00",
        "comment_author": "B-Step62",
        "comment_body": "@krrishdholakia Sure, I can pull this combo to a shared utility function. Is that what you suggested?",
        "pr_file_module": null
      },
      {
        "comment_id": "1939461352",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 8202,
        "pr_file": "litellm/litellm_core_utils/streaming_handler.py",
        "discussion_id": "1938869606",
        "commented_code": "@@ -1427,10 +1430,13 @@ def __next__(self):  # noqa: PLR0915\n                     if response is None:\n                         continue\n                     ## LOGGING\n-                    threading.Thread(\n-                        target=self.run_success_logging_and_cache_storage,\n-                        args=(response, cache_hit),\n-                    ).start()  # log response\n+                    if litellm.sync_logging:",
        "comment_created_at": "2025-02-03T14:23:18+00:00",
        "comment_author": "B-Step62",
        "comment_body": "@krrishdholakia I've updated the PR to encapsulate the conditional logic into a single place. Would you mind taking another look? Thank you in advance.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2206421684",
    "pr_number": 12580,
    "pr_file": "litellm/litellm_core_utils/exception_mapping_utils.py",
    "created_at": "2025-07-15T05:25:40+00:00",
    "commented_code": "exception_mapping_worked = False\n     exception_provider = custom_llm_provider\n     if litellm.suppress_debug_info is False:\n-        print()  # noqa\n+        print(file=sys.stderr)  # noqa",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2206421684",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 12580,
        "pr_file": "litellm/litellm_core_utils/exception_mapping_utils.py",
        "discussion_id": "2206421684",
        "commented_code": "@@ -185,14 +186,16 @@ def exception_type(  # type: ignore  # noqa: PLR0915\n     exception_mapping_worked = False\n     exception_provider = custom_llm_provider\n     if litellm.suppress_debug_info is False:\n-        print()  # noqa\n+        print(file=sys.stderr)  # noqa",
        "comment_created_at": "2025-07-15T05:25:40+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "why not just move to using the logging.info here? ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2105726756",
    "pr_number": 11112,
    "pr_file": "litellm/llms/github_copilot/authenticator.py",
    "created_at": "2025-05-24T06:29:16+00:00",
    "commented_code": "user_code = device_code_info[\"user_code\"]\n         verification_uri = device_code_info[\"verification_uri\"]\n \n-        print(\n+        print(  # noqa: T201",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2105726756",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11112,
        "pr_file": "litellm/llms/github_copilot/authenticator.py",
        "discussion_id": "2105726756",
        "commented_code": "@@ -298,7 +298,7 @@ def _login(self) -> str:\n         user_code = device_code_info[\"user_code\"]\n         verification_uri = device_code_info[\"verification_uri\"]\n \n-        print(\n+        print(  # noqa: T201",
        "comment_created_at": "2025-05-24T06:29:16+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "A noqa is not okay for a print statement.\r\n\r\nPlease change this to a verbose_logger.info",
        "pr_file_module": null
      },
      {
        "comment_id": "2105727318",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11112,
        "pr_file": "litellm/llms/github_copilot/authenticator.py",
        "discussion_id": "2105726756",
        "commented_code": "@@ -298,7 +298,7 @@ def _login(self) -> str:\n         user_code = device_code_info[\"user_code\"]\n         verification_uri = device_code_info[\"verification_uri\"]\n \n-        print(\n+        print(  # noqa: T201",
        "comment_created_at": "2025-05-24T06:32:13+00:00",
        "comment_author": "SmartManoj",
        "comment_body": "https://github.com/BerriAI/litellm/issues/6564#issuecomment-2894574403\r\n\r\nIsn't this line a mandatory one? ",
        "pr_file_module": null
      },
      {
        "comment_id": "2105727750",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11112,
        "pr_file": "litellm/llms/github_copilot/authenticator.py",
        "discussion_id": "2105726756",
        "commented_code": "@@ -298,7 +298,7 @@ def _login(self) -> str:\n         user_code = device_code_info[\"user_code\"]\n         verification_uri = device_code_info[\"verification_uri\"]\n \n-        print(\n+        print(  # noqa: T201",
        "comment_created_at": "2025-05-24T06:35:05+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "is webbrowser a new dep? ",
        "pr_file_module": null
      },
      {
        "comment_id": "2105727879",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11112,
        "pr_file": "litellm/llms/github_copilot/authenticator.py",
        "discussion_id": "2105726756",
        "commented_code": "@@ -298,7 +298,7 @@ def _login(self) -> str:\n         user_code = device_code_info[\"user_code\"]\n         verification_uri = device_code_info[\"verification_uri\"]\n \n-        print(\n+        print(  # noqa: T201",
        "comment_created_at": "2025-05-24T06:36:13+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "verbose_logger uses the logging library - so it should print automatically - you can also try `.warning` as i've seen that show up pretty consistently as well. \r\n\r\nWe try to minimize print's in the codebase, so this would ideally not be the approach - but if there are no other options, we can go forward with this. ",
        "pr_file_module": null
      },
      {
        "comment_id": "2105728106",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11112,
        "pr_file": "litellm/llms/github_copilot/authenticator.py",
        "discussion_id": "2105726756",
        "commented_code": "@@ -298,7 +298,7 @@ def _login(self) -> str:\n         user_code = device_code_info[\"user_code\"]\n         verification_uri = device_code_info[\"verification_uri\"]\n \n-        print(\n+        print(  # noqa: T201",
        "comment_created_at": "2025-05-24T06:37:40+00:00",
        "comment_author": "SmartManoj",
        "comment_body": "builtin module, but  `user_code` needs to be printed. Else, would use `pyperclip` third party to copy into the clipboard.",
        "pr_file_module": null
      },
      {
        "comment_id": "2105728320",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11112,
        "pr_file": "litellm/llms/github_copilot/authenticator.py",
        "discussion_id": "2105726756",
        "commented_code": "@@ -298,7 +298,7 @@ def _login(self) -> str:\n         user_code = device_code_info[\"user_code\"]\n         verification_uri = device_code_info[\"verification_uri\"]\n \n-        print(\n+        print(  # noqa: T201",
        "comment_created_at": "2025-05-24T06:39:05+00:00",
        "comment_author": "SmartManoj",
        "comment_body": "for `verbose_logger`, [set_verbose](https://docs.litellm.ai/docs/proxy/config_settings#:~:text=tags.%20Further%20docs-,set_verbose,-boolean`) should be enabled right?",
        "pr_file_module": null
      },
      {
        "comment_id": "2105729273",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11112,
        "pr_file": "litellm/llms/github_copilot/authenticator.py",
        "discussion_id": "2105726756",
        "commented_code": "@@ -298,7 +298,7 @@ def _login(self) -> str:\n         user_code = device_code_info[\"user_code\"]\n         verification_uri = device_code_info[\"verification_uri\"]\n \n-        print(\n+        print(  # noqa: T201",
        "comment_created_at": "2025-05-24T06:42:39+00:00",
        "comment_author": "SmartManoj",
        "comment_body": "As there is already some `noqa` in the codespace, will move with this now and later refactor as it is already ~2 months late.  https://github.com/BerriAI/litellm/issues/11115\r\n\r\nhttps://github.com/BerriAI/litellm/blob/ba2d4d080fda760d616293ab4a56848994824f0e/litellm/caching/caching.py#L37-L44",
        "pr_file_module": null
      },
      {
        "comment_id": "2105730506",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11112,
        "pr_file": "litellm/llms/github_copilot/authenticator.py",
        "discussion_id": "2105726756",
        "commented_code": "@@ -298,7 +298,7 @@ def _login(self) -> str:\n         user_code = device_code_info[\"user_code\"]\n         verification_uri = device_code_info[\"verification_uri\"]\n \n-        print(\n+        print(  # noqa: T201",
        "comment_created_at": "2025-05-24T06:49:31+00:00",
        "comment_author": "SmartManoj",
        "comment_body": "> verbose_logger uses the logging library - so it should print automatically - you can also try `.warning` as i've seen that show up pretty consistently as well.\r\n\r\nbecause `set_verbose` is ~~on~~ by default.",
        "pr_file_module": null
      },
      {
        "comment_id": "2105730725",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 11112,
        "pr_file": "litellm/llms/github_copilot/authenticator.py",
        "discussion_id": "2105726756",
        "commented_code": "@@ -298,7 +298,7 @@ def _login(self) -> str:\n         user_code = device_code_info[\"user_code\"]\n         verification_uri = device_code_info[\"verification_uri\"]\n \n-        print(\n+        print(  # noqa: T201",
        "comment_created_at": "2025-05-24T06:50:34+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "no `.set_verbose` is the old approach and enables `DEBUG` mode for the logging library. \r\n\r\n`INFO` statements should not require any enabling ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1982400281",
    "pr_number": 8989,
    "pr_file": "litellm/integrations/posthog.py",
    "created_at": "2025-03-06T00:59:28+00:00",
    "commented_code": "+#### What this does ####\n+#    On success/failure, logs events to PostHog\n+import os\n+import threading\n+import traceback\n+from typing import Any, Dict\n+\n+from litellm._logging import verbose_logger\n+from litellm.integrations.custom_logger import CustomLogger\n+from litellm.types.utils import (\n+    ModelResponse,\n+    TextCompletionResponse\n+)\n+\n+\n+class PosthogLogger(CustomLogger):\n+    # Class variables\n+    def __init__(self):\n+        # Instance variables\n+        try:\n+            import posthog\n+            self.posthog = posthog\n+            self.posthog_api_key = os.getenv(\"POSTHOG_API_KEY\")\n+            self.posthog_host = os.getenv(\"POSTHOG_API_URL\", \"https://us.i.posthog.com\")\n+            \n+            # Initialize PostHog client\n+            if self.posthog_api_key:\n+                self.posthog.api_key = self.posthog_api_key\n+                if self.posthog_host:\n+                    self.posthog.host = self.posthog_host\n+            else:\n+                verbose_logger.warning(\"PostHog API Key not found in environment variables\")\n+                \n+            # Setup stream tracking\n+            self._stream_id_to_data = {}\n+            self._lock = threading.Lock()  # lock for stream data\n+                \n+        except ImportError:\n+            verbose_logger.warning(\"PostHog Python SDK not installed. Run `pip install posthog`\")\n+            raise\n+\n+    def log_success_event(self, kwargs, response_obj, start_time, end_time):\n+        self._handle_success(kwargs, response_obj, start_time, end_time)\n+\n+    async def async_log_success_event(self, kwargs, response_obj, start_time, end_time):\n+        self._handle_success(kwargs, response_obj, start_time, end_time)\n+\n+    def _handle_success(self, kwargs, response_obj, start_time, end_time):\n+        \"\"\"\n+        Log the success event to PostHog.\n+        \"\"\"\n+        try:\n+            verbose_logger.debug(\"PostHog logging start for success event\")\n+\n+            if kwargs.get(\"stream\"):\n+                self._handle_stream_event(kwargs, response_obj, start_time, end_time)\n+            else:\n+                litellm_call_id = kwargs.get(\"litellm_call_id\")\n+                model = kwargs.get(\"model\", \"\")\n+                call_type = kwargs.get(\"call_type\", \"completion\")\n+                \n+                # Create the event properties based on call type\n+                if call_type == \"embeddings\":\n+                    self._log_embedding_event(model, kwargs, response_obj, start_time, end_time, litellm_call_id)\n+                else:\n+                    self._log_completion_event(model, kwargs, response_obj, start_time, end_time, litellm_call_id)\n+                    \n+        except Exception:\n+            verbose_logger.debug(\"PostHog Logging Error\", stack_info=True)\n+            pass\n+\n+    def log_failure_event(self, kwargs, response_obj, start_time, end_time):\n+        self._handle_failure(kwargs, response_obj, start_time, end_time)\n+\n+    async def async_log_failure_event(self, kwargs, response_obj, start_time, end_time):\n+        self._handle_failure(kwargs, response_obj, start_time, end_time)\n+\n+    def _handle_failure(self, kwargs, response_obj, start_time, end_time):\n+        \"\"\"\n+        Log the failure event to PostHog.\n+        \"\"\"\n+        try:\n+            verbose_logger.debug(\"PostHog logging start for failure event\")\n+            \n+            litellm_call_id = kwargs.get(\"litellm_call_id\")",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "1982400281",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 8989,
        "pr_file": "litellm/integrations/posthog.py",
        "discussion_id": "1982400281",
        "commented_code": "@@ -0,0 +1,362 @@\n+#### What this does ####\n+#    On success/failure, logs events to PostHog\n+import os\n+import threading\n+import traceback\n+from typing import Any, Dict\n+\n+from litellm._logging import verbose_logger\n+from litellm.integrations.custom_logger import CustomLogger\n+from litellm.types.utils import (\n+    ModelResponse,\n+    TextCompletionResponse\n+)\n+\n+\n+class PosthogLogger(CustomLogger):\n+    # Class variables\n+    def __init__(self):\n+        # Instance variables\n+        try:\n+            import posthog\n+            self.posthog = posthog\n+            self.posthog_api_key = os.getenv(\"POSTHOG_API_KEY\")\n+            self.posthog_host = os.getenv(\"POSTHOG_API_URL\", \"https://us.i.posthog.com\")\n+            \n+            # Initialize PostHog client\n+            if self.posthog_api_key:\n+                self.posthog.api_key = self.posthog_api_key\n+                if self.posthog_host:\n+                    self.posthog.host = self.posthog_host\n+            else:\n+                verbose_logger.warning(\"PostHog API Key not found in environment variables\")\n+                \n+            # Setup stream tracking\n+            self._stream_id_to_data = {}\n+            self._lock = threading.Lock()  # lock for stream data\n+                \n+        except ImportError:\n+            verbose_logger.warning(\"PostHog Python SDK not installed. Run `pip install posthog`\")\n+            raise\n+\n+    def log_success_event(self, kwargs, response_obj, start_time, end_time):\n+        self._handle_success(kwargs, response_obj, start_time, end_time)\n+\n+    async def async_log_success_event(self, kwargs, response_obj, start_time, end_time):\n+        self._handle_success(kwargs, response_obj, start_time, end_time)\n+\n+    def _handle_success(self, kwargs, response_obj, start_time, end_time):\n+        \"\"\"\n+        Log the success event to PostHog.\n+        \"\"\"\n+        try:\n+            verbose_logger.debug(\"PostHog logging start for success event\")\n+\n+            if kwargs.get(\"stream\"):\n+                self._handle_stream_event(kwargs, response_obj, start_time, end_time)\n+            else:\n+                litellm_call_id = kwargs.get(\"litellm_call_id\")\n+                model = kwargs.get(\"model\", \"\")\n+                call_type = kwargs.get(\"call_type\", \"completion\")\n+                \n+                # Create the event properties based on call type\n+                if call_type == \"embeddings\":\n+                    self._log_embedding_event(model, kwargs, response_obj, start_time, end_time, litellm_call_id)\n+                else:\n+                    self._log_completion_event(model, kwargs, response_obj, start_time, end_time, litellm_call_id)\n+                    \n+        except Exception:\n+            verbose_logger.debug(\"PostHog Logging Error\", stack_info=True)\n+            pass\n+\n+    def log_failure_event(self, kwargs, response_obj, start_time, end_time):\n+        self._handle_failure(kwargs, response_obj, start_time, end_time)\n+\n+    async def async_log_failure_event(self, kwargs, response_obj, start_time, end_time):\n+        self._handle_failure(kwargs, response_obj, start_time, end_time)\n+\n+    def _handle_failure(self, kwargs, response_obj, start_time, end_time):\n+        \"\"\"\n+        Log the failure event to PostHog.\n+        \"\"\"\n+        try:\n+            verbose_logger.debug(\"PostHog logging start for failure event\")\n+            \n+            litellm_call_id = kwargs.get(\"litellm_call_id\")",
        "comment_created_at": "2025-03-06T00:59:28+00:00",
        "comment_author": "ishaan-jaff",
        "comment_body": "for both success and failure read all fields from kwargs.get(\"standard_logging_object) \r\n\r\nlike we do in datadog.py https://docs.litellm.ai/docs/proxy/logging_spec ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2014272323",
    "pr_number": 9550,
    "pr_file": "litellm/litellm_core_utils/streaming_handler.py",
    "created_at": "2025-03-26T14:18:52+00:00",
    "commented_code": "if processed_chunk is None:\n                         continue\n \n+                    if self.logging_obj.completion_start_time is None:",
    "repo_full_name": "BerriAI/litellm",
    "discussion_comments": [
      {
        "comment_id": "2014272323",
        "repo_full_name": "BerriAI/litellm",
        "pr_number": 9550,
        "pr_file": "litellm/litellm_core_utils/streaming_handler.py",
        "discussion_id": "2014272323",
        "commented_code": "@@ -1723,6 +1724,11 @@ async def __anext__(self):  # noqa: PLR0915\n                     if processed_chunk is None:\n                         continue\n \n+                    if self.logging_obj.completion_start_time is None:",
        "comment_created_at": "2025-03-26T14:18:52+00:00",
        "comment_author": "krrishdholakia",
        "comment_body": "Hey @anthony-liner can we please move this to inside litellm_logging.py and add testing for this - so this change doesn't get accidentally reverted\r\n\r\nideally keeping this logic within the Logging class itself",
        "pr_file_module": null
      }
    ]
  }
]