[
  {
    "discussion_id": "2199896948",
    "pr_number": 14620,
    "pr_file": "gguf-py/gguf/constants.py",
    "created_at": "2025-07-11T07:27:24+00:00",
    "commented_code": "MODEL_TENSOR.POSNET_ATTN_K:             \"posnet.{bid}.attn_k\",\n     MODEL_TENSOR.POSNET_ATTN_V:             \"posnet.{bid}.attn_v\",\n     MODEL_TENSOR.POSNET_ATTN_OUT:           \"posnet.{bid}.attn_output\",\n+    MODEL_TENSOR.SHORTCONV_CONV:            \"blk.{bid}.shortconv.conv\",\n+    MODEL_TENSOR.SHORTCONV_INPROJ:          \"blk.{bid}.shortconv.in_proj\",\n+    MODEL_TENSOR.SHORTCONV_OUTPROJ:         \"blk.{bid}.shortconv.out_proj\",",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2199896948",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14620,
        "pr_file": "gguf-py/gguf/constants.py",
        "discussion_id": "2199896948",
        "commented_code": "@@ -844,6 +852,9 @@ class MODEL_TENSOR(IntEnum):\n     MODEL_TENSOR.POSNET_ATTN_K:             \"posnet.{bid}.attn_k\",\n     MODEL_TENSOR.POSNET_ATTN_V:             \"posnet.{bid}.attn_v\",\n     MODEL_TENSOR.POSNET_ATTN_OUT:           \"posnet.{bid}.attn_output\",\n+    MODEL_TENSOR.SHORTCONV_CONV:            \"blk.{bid}.shortconv.conv\",\n+    MODEL_TENSOR.SHORTCONV_INPROJ:          \"blk.{bid}.shortconv.in_proj\",\n+    MODEL_TENSOR.SHORTCONV_OUTPROJ:         \"blk.{bid}.shortconv.out_proj\",",
        "comment_created_at": "2025-07-11T07:27:24+00:00",
        "comment_author": "ggerganov",
        "comment_body": "Using `shortconv` prefix would be more consistent with the existing naming pattern:\n\n```suggestion\n    MODEL_TENSOR.SHORTCONV_CONV:            \"shortconv.{bid}.shortconv.conv\",\n    MODEL_TENSOR.SHORTCONV_INPROJ:          \"shortconv.{bid}.shortconv.in_proj\",\n    MODEL_TENSOR.SHORTCONV_OUTPROJ:         \"shortconv.{bid}.shortconv.out_proj\",\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2200043182",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14620,
        "pr_file": "gguf-py/gguf/constants.py",
        "discussion_id": "2199896948",
        "commented_code": "@@ -844,6 +852,9 @@ class MODEL_TENSOR(IntEnum):\n     MODEL_TENSOR.POSNET_ATTN_K:             \"posnet.{bid}.attn_k\",\n     MODEL_TENSOR.POSNET_ATTN_V:             \"posnet.{bid}.attn_v\",\n     MODEL_TENSOR.POSNET_ATTN_OUT:           \"posnet.{bid}.attn_output\",\n+    MODEL_TENSOR.SHORTCONV_CONV:            \"blk.{bid}.shortconv.conv\",\n+    MODEL_TENSOR.SHORTCONV_INPROJ:          \"blk.{bid}.shortconv.in_proj\",\n+    MODEL_TENSOR.SHORTCONV_OUTPROJ:         \"blk.{bid}.shortconv.out_proj\",",
        "comment_created_at": "2025-07-11T08:27:01+00:00",
        "comment_author": "ngxson",
        "comment_body": "I think `blk.*.shortconv` is probably fine, because the HF tensor name is `model.layers.*.shortconv`, meaning it's part of an existing layer (same as attn and FFN blocks)\r\n\r\n<img width=\"672\" height=\"278\" alt=\"image\" src=\"https://github.com/user-attachments/assets/55d99431-7949-474e-8ce8-dd758ff3f8b8\" />\r\n\r\nWith the `shortconv.{bid}` prefix, the list of tensors may look a bit strange, as it's duplicated the list of `blk`\r\n\r\n```\r\nblk.0.*\r\nshortconv.0.*\r\nblk.1.*\r\nshortconv.1.*\r\nblk.2.*\r\nshortconv.2.*\r\n...\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2172408108",
    "pr_number": 14425,
    "pr_file": "convert_hf_to_gguf.py",
    "created_at": "2025-06-27T16:31:09+00:00",
    "commented_code": "from enum import IntEnum\n from pathlib import Path\n from hashlib import sha256\n-from typing import TYPE_CHECKING, Any, Callable, ContextManager, Iterable, Iterator, Literal, Sequence, TypeVar, cast\n+from typing import TYPE_CHECKING, Any, Callable, ContextManager, Iterable, Iterator, Literal, Sequence, TypeVar, Dict, cast",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2172408108",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14425,
        "pr_file": "convert_hf_to_gguf.py",
        "discussion_id": "2172408108",
        "commented_code": "@@ -14,7 +14,7 @@\n from enum import IntEnum\n from pathlib import Path\n from hashlib import sha256\n-from typing import TYPE_CHECKING, Any, Callable, ContextManager, Iterable, Iterator, Literal, Sequence, TypeVar, cast\n+from typing import TYPE_CHECKING, Any, Callable, ContextManager, Iterable, Iterator, Literal, Sequence, TypeVar, Dict, cast",
        "comment_created_at": "2025-06-27T16:31:09+00:00",
        "comment_author": "CISC",
        "comment_body": "`Dict` is [deprecated](https://docs.python.org/3/library/typing.html#typing.Dict), just use `dict` (or Mapping if need be).",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2184947826",
    "pr_number": 14425,
    "pr_file": "convert_hf_to_gguf.py",
    "created_at": "2025-07-04T10:13:31+00:00",
    "commented_code": "super().set_gguf_parameters()\n         self.gguf_writer.add_audio_stack_factor(self.global_config[\"stack_factor\"])\n \n+\n+@ModelBase.register(\"HunYuanMoEV1ForCausalLM\")\n+class HunYuanMoEModel(TextModel):",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2184947826",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14425,
        "pr_file": "convert_hf_to_gguf.py",
        "discussion_id": "2184947826",
        "commented_code": "@@ -6436,6 +6439,155 @@ def set_gguf_parameters(self):\n         super().set_gguf_parameters()\n         self.gguf_writer.add_audio_stack_factor(self.global_config[\"stack_factor\"])\n \n+\n+@ModelBase.register(\"HunYuanMoEV1ForCausalLM\")\n+class HunYuanMoEModel(TextModel):",
        "comment_created_at": "2025-07-04T10:13:31+00:00",
        "comment_author": "kzjeef",
        "comment_body": "Could you align with Hunyuan's naming , with version V1 suffix?\r\n",
        "pr_file_module": null
      }
    ]
  }
]