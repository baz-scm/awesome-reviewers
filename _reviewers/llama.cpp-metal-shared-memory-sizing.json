[
  {
    "discussion_id": "2216493456",
    "pr_number": 14743,
    "pr_file": "ggml/src/ggml-metal/ggml-metal.m",
    "created_at": "2025-07-18T16:55:50+00:00",
    "commented_code": "if (ne30 == 1) {\n                     // Mamba-2\n-                    [encoder dispatchThreadgroups:MTLSizeMake(d_inner, n_head, n_seqs) threadsPerThreadgroup:MTLSizeMake(1, 1, 1)];\n+                    [encoder setThreadgroupMemoryLength:32*sizeof(float) atIndex:0]; // SIMD size",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2216493456",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14743,
        "pr_file": "ggml/src/ggml-metal/ggml-metal.m",
        "discussion_id": "2216493456",
        "commented_code": "@@ -3016,7 +3017,8 @@ static bool ggml_metal_encode_node(\n \n                 if (ne30 == 1) {\n                     // Mamba-2\n-                    [encoder dispatchThreadgroups:MTLSizeMake(d_inner, n_head, n_seqs) threadsPerThreadgroup:MTLSizeMake(1, 1, 1)];\n+                    [encoder setThreadgroupMemoryLength:32*sizeof(float) atIndex:0]; // SIMD size",
        "comment_created_at": "2025-07-18T16:55:50+00:00",
        "comment_author": "gabe-l-hart",
        "comment_body": "I think this might be wrong. I'm pretty sure it should actually be sized to fit one sum for each simd group in the threadgroup, so it should be `d_state / <simd_size>`",
        "pr_file_module": null
      },
      {
        "comment_id": "2216743434",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14743,
        "pr_file": "ggml/src/ggml-metal/ggml-metal.m",
        "discussion_id": "2216493456",
        "commented_code": "@@ -3016,7 +3017,8 @@ static bool ggml_metal_encode_node(\n \n                 if (ne30 == 1) {\n                     // Mamba-2\n-                    [encoder dispatchThreadgroups:MTLSizeMake(d_inner, n_head, n_seqs) threadsPerThreadgroup:MTLSizeMake(1, 1, 1)];\n+                    [encoder setThreadgroupMemoryLength:32*sizeof(float) atIndex:0]; // SIMD size",
        "comment_created_at": "2025-07-18T19:03:23+00:00",
        "comment_author": "gabe-l-hart",
        "comment_body": "Fixed now to size for the minimum number of buckets",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2230876005",
    "pr_number": 14743,
    "pr_file": "ggml/src/ggml-metal/ggml-metal.m",
    "created_at": "2025-07-25T11:41:18+00:00",
    "commented_code": "[encoder setBuffer:id_dst  offset:offs_dst  atIndex:7];\n                 [encoder setBytes:&args    length:sizeof(args) atIndex:8];\n \n+                // One shared memory bucket for each simd group in the threadgroup\n+                if (d_state >= 32) {\n+                    const int64_t shmem_size = d_state / 32;",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2230876005",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14743,
        "pr_file": "ggml/src/ggml-metal/ggml-metal.m",
        "discussion_id": "2230876005",
        "commented_code": "@@ -3166,12 +3167,29 @@ static int ggml_metal_encode_node(\n                 [encoder setBuffer:id_dst  offset:offs_dst  atIndex:7];\n                 [encoder setBytes:&args    length:sizeof(args) atIndex:8];\n \n+                // One shared memory bucket for each simd group in the threadgroup\n+                if (d_state >= 32) {\n+                    const int64_t shmem_size = d_state / 32;",
        "comment_created_at": "2025-07-25T11:41:18+00:00",
        "comment_author": "ggerganov",
        "comment_body": "You can always allocate `32*sizeof(float)` bytes of shared memory for simplicity:\r\n\r\n```suggestion\r\n                    const int64_t shmem_size = 32;\r\n```\r\n\r\nNote that shared memory buffers in metal require to have size multiple of 16:\r\n\r\nhttps://github.com/ggml-org/llama.cpp/blob/e2b7621e7c265a6739225125cf9c534f471b3472/ggml/src/ggml-metal/ggml-metal.m#L4912-L4916\r\n\r\nBy forcing `shmem_size = 32;` you handle this requirement.",
        "pr_file_module": null
      },
      {
        "comment_id": "2231352493",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14743,
        "pr_file": "ggml/src/ggml-metal/ggml-metal.m",
        "discussion_id": "2230876005",
        "commented_code": "@@ -3166,12 +3167,29 @@ static int ggml_metal_encode_node(\n                 [encoder setBuffer:id_dst  offset:offs_dst  atIndex:7];\n                 [encoder setBytes:&args    length:sizeof(args) atIndex:8];\n \n+                // One shared memory bucket for each simd group in the threadgroup\n+                if (d_state >= 32) {\n+                    const int64_t shmem_size = d_state / 32;",
        "comment_created_at": "2025-07-25T15:02:02+00:00",
        "comment_author": "gabe-l-hart",
        "comment_body": "Ok, very helpful, thanks!",
        "pr_file_module": null
      }
    ]
  }
]