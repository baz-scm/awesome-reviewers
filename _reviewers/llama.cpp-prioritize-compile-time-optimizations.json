[
  {
    "discussion_id": "2160056083",
    "pr_number": 14316,
    "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
    "created_at": "2025-06-21T14:48:25+00:00",
    "commented_code": "+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\\n+        /* Load kernel to A_block: (BS_K x BS_CRS)*/\\\n+        for(uint32_t r_offset = 0; r_offset < BS_K; r_offset += ArpWg){\\\n+            uint32_t B_ly = r_offset + Ar;\\\n+            uint32_t B_lx = Ac;\\\n+            uint32_t K_idx = B_idx_K*BS_K + B_ly;                /* Global K_idx (row index of A)*/\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_lx;          /* Global CRS_idx (column index of A)*/\\\n+            BOUNDARY_CONDITION_A_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t knl_idx = KW_idx + KH_idx*p.nb01 + Cin_idx*p.nb02 + K_idx*p.nb03;\\\n+                Ash[B_ly * Ash_stride + B_lx] = knl_data[knl_idx];\\\n+            BOUNDARY_CONDITION_A_ELSE()\\\n+        }\\\n+        barrier();\\\n+        /* Load input to B_block: (BS_CRS x BS_NPQ) */\\\n+        for(uint32_t r_offset = 0; r_offset < BS_CRS; r_offset += BrpWg){\\\n+            uint32_t B_ly = r_offset + Br;                      /* Row index of B block */\\\n+            uint32_t B_lx = Bc;                                 /* Column index of B block */\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_ly;         /* Global CRS index (row index of B) */\\\n+            uint32_t NPQ_idx = B_idx_NPQ*BS_NPQ + B_lx;         /* Global NPQ index (column index of B) */\\\n+            BOUNDARY_CONDITION_B_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t H_idx = OH_idx*p.s1 + KH_idx*p.d1 - p.p1;\\\n+                uint32_t W_idx = OW_idx*p.s0 + KW_idx*p.d0 - p.p0;\\\n+                if(H_idx >= 0 && H_idx < p.H && W_idx >= 0 && W_idx < p.W){\\\n+                    uint32_t src_idx = W_idx + H_idx*p.nb11 + Cin_idx*p.nb12 + N_idx*p.nb13;\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = src_data[src_idx];\\\n+                }else{\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+                }\\\n+            BOUNDARY_CONDITION_B_ELSE()\\\n+        }\\\n+        barrier();\\\n+        outProdReg();\\\n+        barrier();\\\n+    }\\\n+    /* Save C* */\\\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\\\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\\\n+            uint32_t K_idx = B_idx_K * BS_K + T_y * TS_K + T_ly;\\\n+            uint32_t NPQ_idx = B_idx_NPQ * BS_NPQ + T_x * TS_NPQ + T_lx;\\\n+            if(K_idx < K && NPQ_idx < NPQ){\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t dst_idx = OW_idx + OH_idx*p.nb1 + K_idx*p.nb2 + N_idx*p.nb3;\\\n+                dst_data[dst_idx] = regC[T_ly][T_lx];\\\n+            }\\\n+        }\\\n+    }\\\n+}\n+\n+// Generates mainLoopBoundaryCheck\n+MAIN_LOOP(BoundaryCheck, \n+    DEF_BOUNDARY_CONDITION_A_IF, \n+    DEF_BOUNDARY_CONDITION_A_ELSE, \n+    DEF_BOUNDARY_CONDITION_B_IF, \n+    DEF_BOUNDARY_CONDITION_B_ELSE)\n+\n+// Generates mainLoopNoBoundaryCheck\n+MAIN_LOOP(NoBoundaryCheck, \n+    NOOP, NOOP, NOOP, NOOP)\n+\n+void main(){\n+    if(gl_WorkGroupID.x == gl_NumWorkGroups.x-1 || gl_WorkGroupID.y == gl_NumWorkGroups.y-1){\n+        mainLoopBoundaryCheck();",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2160056083",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14316,
        "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
        "discussion_id": "2160056083",
        "commented_code": "@@ -0,0 +1,244 @@\n+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\\n+        /* Load kernel to A_block: (BS_K x BS_CRS)*/\\\n+        for(uint32_t r_offset = 0; r_offset < BS_K; r_offset += ArpWg){\\\n+            uint32_t B_ly = r_offset + Ar;\\\n+            uint32_t B_lx = Ac;\\\n+            uint32_t K_idx = B_idx_K*BS_K + B_ly;                /* Global K_idx (row index of A)*/\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_lx;          /* Global CRS_idx (column index of A)*/\\\n+            BOUNDARY_CONDITION_A_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t knl_idx = KW_idx + KH_idx*p.nb01 + Cin_idx*p.nb02 + K_idx*p.nb03;\\\n+                Ash[B_ly * Ash_stride + B_lx] = knl_data[knl_idx];\\\n+            BOUNDARY_CONDITION_A_ELSE()\\\n+        }\\\n+        barrier();\\\n+        /* Load input to B_block: (BS_CRS x BS_NPQ) */\\\n+        for(uint32_t r_offset = 0; r_offset < BS_CRS; r_offset += BrpWg){\\\n+            uint32_t B_ly = r_offset + Br;                      /* Row index of B block */\\\n+            uint32_t B_lx = Bc;                                 /* Column index of B block */\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_ly;         /* Global CRS index (row index of B) */\\\n+            uint32_t NPQ_idx = B_idx_NPQ*BS_NPQ + B_lx;         /* Global NPQ index (column index of B) */\\\n+            BOUNDARY_CONDITION_B_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t H_idx = OH_idx*p.s1 + KH_idx*p.d1 - p.p1;\\\n+                uint32_t W_idx = OW_idx*p.s0 + KW_idx*p.d0 - p.p0;\\\n+                if(H_idx >= 0 && H_idx < p.H && W_idx >= 0 && W_idx < p.W){\\\n+                    uint32_t src_idx = W_idx + H_idx*p.nb11 + Cin_idx*p.nb12 + N_idx*p.nb13;\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = src_data[src_idx];\\\n+                }else{\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+                }\\\n+            BOUNDARY_CONDITION_B_ELSE()\\\n+        }\\\n+        barrier();\\\n+        outProdReg();\\\n+        barrier();\\\n+    }\\\n+    /* Save C* */\\\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\\\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\\\n+            uint32_t K_idx = B_idx_K * BS_K + T_y * TS_K + T_ly;\\\n+            uint32_t NPQ_idx = B_idx_NPQ * BS_NPQ + T_x * TS_NPQ + T_lx;\\\n+            if(K_idx < K && NPQ_idx < NPQ){\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t dst_idx = OW_idx + OH_idx*p.nb1 + K_idx*p.nb2 + N_idx*p.nb3;\\\n+                dst_data[dst_idx] = regC[T_ly][T_lx];\\\n+            }\\\n+        }\\\n+    }\\\n+}\n+\n+// Generates mainLoopBoundaryCheck\n+MAIN_LOOP(BoundaryCheck, \n+    DEF_BOUNDARY_CONDITION_A_IF, \n+    DEF_BOUNDARY_CONDITION_A_ELSE, \n+    DEF_BOUNDARY_CONDITION_B_IF, \n+    DEF_BOUNDARY_CONDITION_B_ELSE)\n+\n+// Generates mainLoopNoBoundaryCheck\n+MAIN_LOOP(NoBoundaryCheck, \n+    NOOP, NOOP, NOOP, NOOP)\n+\n+void main(){\n+    if(gl_WorkGroupID.x == gl_NumWorkGroups.x-1 || gl_WorkGroupID.y == gl_NumWorkGroups.y-1){\n+        mainLoopBoundaryCheck();",
        "comment_created_at": "2025-06-21T14:48:25+00:00",
        "comment_author": "jeffbolznv",
        "comment_body": "Is it possible to just pass in a boolean true/false here and && it with the condition? I think it'll be more readable than all the macros",
        "pr_file_module": null
      },
      {
        "comment_id": "2160098285",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14316,
        "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
        "discussion_id": "2160056083",
        "commented_code": "@@ -0,0 +1,244 @@\n+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\\n+        /* Load kernel to A_block: (BS_K x BS_CRS)*/\\\n+        for(uint32_t r_offset = 0; r_offset < BS_K; r_offset += ArpWg){\\\n+            uint32_t B_ly = r_offset + Ar;\\\n+            uint32_t B_lx = Ac;\\\n+            uint32_t K_idx = B_idx_K*BS_K + B_ly;                /* Global K_idx (row index of A)*/\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_lx;          /* Global CRS_idx (column index of A)*/\\\n+            BOUNDARY_CONDITION_A_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t knl_idx = KW_idx + KH_idx*p.nb01 + Cin_idx*p.nb02 + K_idx*p.nb03;\\\n+                Ash[B_ly * Ash_stride + B_lx] = knl_data[knl_idx];\\\n+            BOUNDARY_CONDITION_A_ELSE()\\\n+        }\\\n+        barrier();\\\n+        /* Load input to B_block: (BS_CRS x BS_NPQ) */\\\n+        for(uint32_t r_offset = 0; r_offset < BS_CRS; r_offset += BrpWg){\\\n+            uint32_t B_ly = r_offset + Br;                      /* Row index of B block */\\\n+            uint32_t B_lx = Bc;                                 /* Column index of B block */\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_ly;         /* Global CRS index (row index of B) */\\\n+            uint32_t NPQ_idx = B_idx_NPQ*BS_NPQ + B_lx;         /* Global NPQ index (column index of B) */\\\n+            BOUNDARY_CONDITION_B_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t H_idx = OH_idx*p.s1 + KH_idx*p.d1 - p.p1;\\\n+                uint32_t W_idx = OW_idx*p.s0 + KW_idx*p.d0 - p.p0;\\\n+                if(H_idx >= 0 && H_idx < p.H && W_idx >= 0 && W_idx < p.W){\\\n+                    uint32_t src_idx = W_idx + H_idx*p.nb11 + Cin_idx*p.nb12 + N_idx*p.nb13;\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = src_data[src_idx];\\\n+                }else{\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+                }\\\n+            BOUNDARY_CONDITION_B_ELSE()\\\n+        }\\\n+        barrier();\\\n+        outProdReg();\\\n+        barrier();\\\n+    }\\\n+    /* Save C* */\\\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\\\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\\\n+            uint32_t K_idx = B_idx_K * BS_K + T_y * TS_K + T_ly;\\\n+            uint32_t NPQ_idx = B_idx_NPQ * BS_NPQ + T_x * TS_NPQ + T_lx;\\\n+            if(K_idx < K && NPQ_idx < NPQ){\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t dst_idx = OW_idx + OH_idx*p.nb1 + K_idx*p.nb2 + N_idx*p.nb3;\\\n+                dst_data[dst_idx] = regC[T_ly][T_lx];\\\n+            }\\\n+        }\\\n+    }\\\n+}\n+\n+// Generates mainLoopBoundaryCheck\n+MAIN_LOOP(BoundaryCheck, \n+    DEF_BOUNDARY_CONDITION_A_IF, \n+    DEF_BOUNDARY_CONDITION_A_ELSE, \n+    DEF_BOUNDARY_CONDITION_B_IF, \n+    DEF_BOUNDARY_CONDITION_B_ELSE)\n+\n+// Generates mainLoopNoBoundaryCheck\n+MAIN_LOOP(NoBoundaryCheck, \n+    NOOP, NOOP, NOOP, NOOP)\n+\n+void main(){\n+    if(gl_WorkGroupID.x == gl_NumWorkGroups.x-1 || gl_WorkGroupID.y == gl_NumWorkGroups.y-1){\n+        mainLoopBoundaryCheck();",
        "comment_created_at": "2025-06-21T17:40:00+00:00",
        "comment_author": "etasnadi",
        "comment_body": "I tested adding the bool expression in the loop but it slows down the execution considerably: 3.7 TFLOPS compared to 4.16 TFLOPS with macros.\r\n\r\nhttps://gist.github.com/etasnadi/a8a3a67fc904c86f35de74c3f8ef819c#file-conv2d_mm-comp",
        "pr_file_module": null
      },
      {
        "comment_id": "2160130823",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14316,
        "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
        "discussion_id": "2160056083",
        "commented_code": "@@ -0,0 +1,244 @@\n+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\\n+        /* Load kernel to A_block: (BS_K x BS_CRS)*/\\\n+        for(uint32_t r_offset = 0; r_offset < BS_K; r_offset += ArpWg){\\\n+            uint32_t B_ly = r_offset + Ar;\\\n+            uint32_t B_lx = Ac;\\\n+            uint32_t K_idx = B_idx_K*BS_K + B_ly;                /* Global K_idx (row index of A)*/\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_lx;          /* Global CRS_idx (column index of A)*/\\\n+            BOUNDARY_CONDITION_A_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t knl_idx = KW_idx + KH_idx*p.nb01 + Cin_idx*p.nb02 + K_idx*p.nb03;\\\n+                Ash[B_ly * Ash_stride + B_lx] = knl_data[knl_idx];\\\n+            BOUNDARY_CONDITION_A_ELSE()\\\n+        }\\\n+        barrier();\\\n+        /* Load input to B_block: (BS_CRS x BS_NPQ) */\\\n+        for(uint32_t r_offset = 0; r_offset < BS_CRS; r_offset += BrpWg){\\\n+            uint32_t B_ly = r_offset + Br;                      /* Row index of B block */\\\n+            uint32_t B_lx = Bc;                                 /* Column index of B block */\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_ly;         /* Global CRS index (row index of B) */\\\n+            uint32_t NPQ_idx = B_idx_NPQ*BS_NPQ + B_lx;         /* Global NPQ index (column index of B) */\\\n+            BOUNDARY_CONDITION_B_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t H_idx = OH_idx*p.s1 + KH_idx*p.d1 - p.p1;\\\n+                uint32_t W_idx = OW_idx*p.s0 + KW_idx*p.d0 - p.p0;\\\n+                if(H_idx >= 0 && H_idx < p.H && W_idx >= 0 && W_idx < p.W){\\\n+                    uint32_t src_idx = W_idx + H_idx*p.nb11 + Cin_idx*p.nb12 + N_idx*p.nb13;\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = src_data[src_idx];\\\n+                }else{\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+                }\\\n+            BOUNDARY_CONDITION_B_ELSE()\\\n+        }\\\n+        barrier();\\\n+        outProdReg();\\\n+        barrier();\\\n+    }\\\n+    /* Save C* */\\\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\\\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\\\n+            uint32_t K_idx = B_idx_K * BS_K + T_y * TS_K + T_ly;\\\n+            uint32_t NPQ_idx = B_idx_NPQ * BS_NPQ + T_x * TS_NPQ + T_lx;\\\n+            if(K_idx < K && NPQ_idx < NPQ){\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t dst_idx = OW_idx + OH_idx*p.nb1 + K_idx*p.nb2 + N_idx*p.nb3;\\\n+                dst_data[dst_idx] = regC[T_ly][T_lx];\\\n+            }\\\n+        }\\\n+    }\\\n+}\n+\n+// Generates mainLoopBoundaryCheck\n+MAIN_LOOP(BoundaryCheck, \n+    DEF_BOUNDARY_CONDITION_A_IF, \n+    DEF_BOUNDARY_CONDITION_A_ELSE, \n+    DEF_BOUNDARY_CONDITION_B_IF, \n+    DEF_BOUNDARY_CONDITION_B_ELSE)\n+\n+// Generates mainLoopNoBoundaryCheck\n+MAIN_LOOP(NoBoundaryCheck, \n+    NOOP, NOOP, NOOP, NOOP)\n+\n+void main(){\n+    if(gl_WorkGroupID.x == gl_NumWorkGroups.x-1 || gl_WorkGroupID.y == gl_NumWorkGroups.y-1){\n+        mainLoopBoundaryCheck();",
        "comment_created_at": "2025-06-21T19:32:46+00:00",
        "comment_author": "jeffbolznv",
        "comment_body": "You should write it with the branch in the main function and each side using true/false. The compiler will inline both copies and fold the constants.",
        "pr_file_module": null
      },
      {
        "comment_id": "2160189242",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14316,
        "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
        "discussion_id": "2160056083",
        "commented_code": "@@ -0,0 +1,244 @@\n+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\\n+        /* Load kernel to A_block: (BS_K x BS_CRS)*/\\\n+        for(uint32_t r_offset = 0; r_offset < BS_K; r_offset += ArpWg){\\\n+            uint32_t B_ly = r_offset + Ar;\\\n+            uint32_t B_lx = Ac;\\\n+            uint32_t K_idx = B_idx_K*BS_K + B_ly;                /* Global K_idx (row index of A)*/\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_lx;          /* Global CRS_idx (column index of A)*/\\\n+            BOUNDARY_CONDITION_A_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t knl_idx = KW_idx + KH_idx*p.nb01 + Cin_idx*p.nb02 + K_idx*p.nb03;\\\n+                Ash[B_ly * Ash_stride + B_lx] = knl_data[knl_idx];\\\n+            BOUNDARY_CONDITION_A_ELSE()\\\n+        }\\\n+        barrier();\\\n+        /* Load input to B_block: (BS_CRS x BS_NPQ) */\\\n+        for(uint32_t r_offset = 0; r_offset < BS_CRS; r_offset += BrpWg){\\\n+            uint32_t B_ly = r_offset + Br;                      /* Row index of B block */\\\n+            uint32_t B_lx = Bc;                                 /* Column index of B block */\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_ly;         /* Global CRS index (row index of B) */\\\n+            uint32_t NPQ_idx = B_idx_NPQ*BS_NPQ + B_lx;         /* Global NPQ index (column index of B) */\\\n+            BOUNDARY_CONDITION_B_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t H_idx = OH_idx*p.s1 + KH_idx*p.d1 - p.p1;\\\n+                uint32_t W_idx = OW_idx*p.s0 + KW_idx*p.d0 - p.p0;\\\n+                if(H_idx >= 0 && H_idx < p.H && W_idx >= 0 && W_idx < p.W){\\\n+                    uint32_t src_idx = W_idx + H_idx*p.nb11 + Cin_idx*p.nb12 + N_idx*p.nb13;\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = src_data[src_idx];\\\n+                }else{\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+                }\\\n+            BOUNDARY_CONDITION_B_ELSE()\\\n+        }\\\n+        barrier();\\\n+        outProdReg();\\\n+        barrier();\\\n+    }\\\n+    /* Save C* */\\\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\\\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\\\n+            uint32_t K_idx = B_idx_K * BS_K + T_y * TS_K + T_ly;\\\n+            uint32_t NPQ_idx = B_idx_NPQ * BS_NPQ + T_x * TS_NPQ + T_lx;\\\n+            if(K_idx < K && NPQ_idx < NPQ){\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t dst_idx = OW_idx + OH_idx*p.nb1 + K_idx*p.nb2 + N_idx*p.nb3;\\\n+                dst_data[dst_idx] = regC[T_ly][T_lx];\\\n+            }\\\n+        }\\\n+    }\\\n+}\n+\n+// Generates mainLoopBoundaryCheck\n+MAIN_LOOP(BoundaryCheck, \n+    DEF_BOUNDARY_CONDITION_A_IF, \n+    DEF_BOUNDARY_CONDITION_A_ELSE, \n+    DEF_BOUNDARY_CONDITION_B_IF, \n+    DEF_BOUNDARY_CONDITION_B_ELSE)\n+\n+// Generates mainLoopNoBoundaryCheck\n+MAIN_LOOP(NoBoundaryCheck, \n+    NOOP, NOOP, NOOP, NOOP)\n+\n+void main(){\n+    if(gl_WorkGroupID.x == gl_NumWorkGroups.x-1 || gl_WorkGroupID.y == gl_NumWorkGroups.y-1){\n+        mainLoopBoundaryCheck();",
        "comment_created_at": "2025-06-22T00:39:57+00:00",
        "comment_author": "etasnadi",
        "comment_body": "~~Thanks, this finally helped to produce better code. I don't want to trigger the pipelines so I pushed the updates to a different branch (https://github.com/etasnadi/llama.cppxx/commit/fe85b4466e5841dba5ab28449f401ad636eafc51), but it seems that the FLOPS are much higher:~~\r\n```\r\nVulkan FLOPS:\r\ndevice                  direct  indirect\r\n------                  ------  --------\r\nRTX 2060                (5.33)     3.40\r\nGTX 1060 (Notebook)     (2.2)     1.73\r\n```\r\nCommand: `GGML_VK_CONV_2D_CONFIG=256,128,16,128,16 GGML_VK_DISABLE_COOPMAT=1 ./bin/test-backend-ops -o CONV_2D_INDIRECT_IMPL -b Vulkan0 perf`",
        "pr_file_module": null
      },
      {
        "comment_id": "2160192760",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14316,
        "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
        "discussion_id": "2160056083",
        "commented_code": "@@ -0,0 +1,244 @@\n+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\\n+        /* Load kernel to A_block: (BS_K x BS_CRS)*/\\\n+        for(uint32_t r_offset = 0; r_offset < BS_K; r_offset += ArpWg){\\\n+            uint32_t B_ly = r_offset + Ar;\\\n+            uint32_t B_lx = Ac;\\\n+            uint32_t K_idx = B_idx_K*BS_K + B_ly;                /* Global K_idx (row index of A)*/\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_lx;          /* Global CRS_idx (column index of A)*/\\\n+            BOUNDARY_CONDITION_A_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t knl_idx = KW_idx + KH_idx*p.nb01 + Cin_idx*p.nb02 + K_idx*p.nb03;\\\n+                Ash[B_ly * Ash_stride + B_lx] = knl_data[knl_idx];\\\n+            BOUNDARY_CONDITION_A_ELSE()\\\n+        }\\\n+        barrier();\\\n+        /* Load input to B_block: (BS_CRS x BS_NPQ) */\\\n+        for(uint32_t r_offset = 0; r_offset < BS_CRS; r_offset += BrpWg){\\\n+            uint32_t B_ly = r_offset + Br;                      /* Row index of B block */\\\n+            uint32_t B_lx = Bc;                                 /* Column index of B block */\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_ly;         /* Global CRS index (row index of B) */\\\n+            uint32_t NPQ_idx = B_idx_NPQ*BS_NPQ + B_lx;         /* Global NPQ index (column index of B) */\\\n+            BOUNDARY_CONDITION_B_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t H_idx = OH_idx*p.s1 + KH_idx*p.d1 - p.p1;\\\n+                uint32_t W_idx = OW_idx*p.s0 + KW_idx*p.d0 - p.p0;\\\n+                if(H_idx >= 0 && H_idx < p.H && W_idx >= 0 && W_idx < p.W){\\\n+                    uint32_t src_idx = W_idx + H_idx*p.nb11 + Cin_idx*p.nb12 + N_idx*p.nb13;\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = src_data[src_idx];\\\n+                }else{\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+                }\\\n+            BOUNDARY_CONDITION_B_ELSE()\\\n+        }\\\n+        barrier();\\\n+        outProdReg();\\\n+        barrier();\\\n+    }\\\n+    /* Save C* */\\\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\\\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\\\n+            uint32_t K_idx = B_idx_K * BS_K + T_y * TS_K + T_ly;\\\n+            uint32_t NPQ_idx = B_idx_NPQ * BS_NPQ + T_x * TS_NPQ + T_lx;\\\n+            if(K_idx < K && NPQ_idx < NPQ){\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t dst_idx = OW_idx + OH_idx*p.nb1 + K_idx*p.nb2 + N_idx*p.nb3;\\\n+                dst_data[dst_idx] = regC[T_ly][T_lx];\\\n+            }\\\n+        }\\\n+    }\\\n+}\n+\n+// Generates mainLoopBoundaryCheck\n+MAIN_LOOP(BoundaryCheck, \n+    DEF_BOUNDARY_CONDITION_A_IF, \n+    DEF_BOUNDARY_CONDITION_A_ELSE, \n+    DEF_BOUNDARY_CONDITION_B_IF, \n+    DEF_BOUNDARY_CONDITION_B_ELSE)\n+\n+// Generates mainLoopNoBoundaryCheck\n+MAIN_LOOP(NoBoundaryCheck, \n+    NOOP, NOOP, NOOP, NOOP)\n+\n+void main(){\n+    if(gl_WorkGroupID.x == gl_NumWorkGroups.x-1 || gl_WorkGroupID.y == gl_NumWorkGroups.y-1){\n+        mainLoopBoundaryCheck();",
        "comment_created_at": "2025-06-22T01:02:11+00:00",
        "comment_author": "etasnadi",
        "comment_body": "In the meantime I implemented the CUDA version and here's the performance:\r\n```\r\nCUDA FLOPS:\r\ndevice                  direct  indirect\r\n------                  ------  --------\r\nGTX 1060 (Notebook)     (2.2)     2.5\r\nRTX 2060                (5.02)    6.14\r\n```\r\n\r\n~~This suggests that my proposed alg is slower than the indirect alg if the latter is well optimized and the indirect Vulkan kernel can be further optimized or their parameters are not general enough to perform well on my devices.~~\r\n\r\nEdit: CUDA branch added: ~~https://github.com/etasnadi/llama.cppxx/commit/c71890eea529142ea9bf4d47d3a17a8fc7dfaa37~~",
        "pr_file_module": null
      },
      {
        "comment_id": "2160309846",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14316,
        "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
        "discussion_id": "2160056083",
        "commented_code": "@@ -0,0 +1,244 @@\n+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\\n+        /* Load kernel to A_block: (BS_K x BS_CRS)*/\\\n+        for(uint32_t r_offset = 0; r_offset < BS_K; r_offset += ArpWg){\\\n+            uint32_t B_ly = r_offset + Ar;\\\n+            uint32_t B_lx = Ac;\\\n+            uint32_t K_idx = B_idx_K*BS_K + B_ly;                /* Global K_idx (row index of A)*/\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_lx;          /* Global CRS_idx (column index of A)*/\\\n+            BOUNDARY_CONDITION_A_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t knl_idx = KW_idx + KH_idx*p.nb01 + Cin_idx*p.nb02 + K_idx*p.nb03;\\\n+                Ash[B_ly * Ash_stride + B_lx] = knl_data[knl_idx];\\\n+            BOUNDARY_CONDITION_A_ELSE()\\\n+        }\\\n+        barrier();\\\n+        /* Load input to B_block: (BS_CRS x BS_NPQ) */\\\n+        for(uint32_t r_offset = 0; r_offset < BS_CRS; r_offset += BrpWg){\\\n+            uint32_t B_ly = r_offset + Br;                      /* Row index of B block */\\\n+            uint32_t B_lx = Bc;                                 /* Column index of B block */\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_ly;         /* Global CRS index (row index of B) */\\\n+            uint32_t NPQ_idx = B_idx_NPQ*BS_NPQ + B_lx;         /* Global NPQ index (column index of B) */\\\n+            BOUNDARY_CONDITION_B_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t H_idx = OH_idx*p.s1 + KH_idx*p.d1 - p.p1;\\\n+                uint32_t W_idx = OW_idx*p.s0 + KW_idx*p.d0 - p.p0;\\\n+                if(H_idx >= 0 && H_idx < p.H && W_idx >= 0 && W_idx < p.W){\\\n+                    uint32_t src_idx = W_idx + H_idx*p.nb11 + Cin_idx*p.nb12 + N_idx*p.nb13;\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = src_data[src_idx];\\\n+                }else{\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+                }\\\n+            BOUNDARY_CONDITION_B_ELSE()\\\n+        }\\\n+        barrier();\\\n+        outProdReg();\\\n+        barrier();\\\n+    }\\\n+    /* Save C* */\\\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\\\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\\\n+            uint32_t K_idx = B_idx_K * BS_K + T_y * TS_K + T_ly;\\\n+            uint32_t NPQ_idx = B_idx_NPQ * BS_NPQ + T_x * TS_NPQ + T_lx;\\\n+            if(K_idx < K && NPQ_idx < NPQ){\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t dst_idx = OW_idx + OH_idx*p.nb1 + K_idx*p.nb2 + N_idx*p.nb3;\\\n+                dst_data[dst_idx] = regC[T_ly][T_lx];\\\n+            }\\\n+        }\\\n+    }\\\n+}\n+\n+// Generates mainLoopBoundaryCheck\n+MAIN_LOOP(BoundaryCheck, \n+    DEF_BOUNDARY_CONDITION_A_IF, \n+    DEF_BOUNDARY_CONDITION_A_ELSE, \n+    DEF_BOUNDARY_CONDITION_B_IF, \n+    DEF_BOUNDARY_CONDITION_B_ELSE)\n+\n+// Generates mainLoopNoBoundaryCheck\n+MAIN_LOOP(NoBoundaryCheck, \n+    NOOP, NOOP, NOOP, NOOP)\n+\n+void main(){\n+    if(gl_WorkGroupID.x == gl_NumWorkGroups.x-1 || gl_WorkGroupID.y == gl_NumWorkGroups.y-1){\n+        mainLoopBoundaryCheck();",
        "comment_created_at": "2025-06-22T11:37:28+00:00",
        "comment_author": "etasnadi",
        "comment_body": "Turns out that the CUDA matmul uses cuBLAS if possible: https://github.com/ggml-org/llama.cpp/blob/40bfa04c95c19fb42bafd4e21b5c2a7771846801/ggml/src/ggml-cuda/ggml-cuda.cu#L1341 so the ~~13.6% improvement~~ can be attributed to the matmul tricks cuBLAS uses. Adding vectorized loads would bring my kernel to this performance, but I will do that when I prepare the CUDA patch.",
        "pr_file_module": null
      },
      {
        "comment_id": "2173437032",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14316,
        "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
        "discussion_id": "2160056083",
        "commented_code": "@@ -0,0 +1,244 @@\n+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\\n+        /* Load kernel to A_block: (BS_K x BS_CRS)*/\\\n+        for(uint32_t r_offset = 0; r_offset < BS_K; r_offset += ArpWg){\\\n+            uint32_t B_ly = r_offset + Ar;\\\n+            uint32_t B_lx = Ac;\\\n+            uint32_t K_idx = B_idx_K*BS_K + B_ly;                /* Global K_idx (row index of A)*/\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_lx;          /* Global CRS_idx (column index of A)*/\\\n+            BOUNDARY_CONDITION_A_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t knl_idx = KW_idx + KH_idx*p.nb01 + Cin_idx*p.nb02 + K_idx*p.nb03;\\\n+                Ash[B_ly * Ash_stride + B_lx] = knl_data[knl_idx];\\\n+            BOUNDARY_CONDITION_A_ELSE()\\\n+        }\\\n+        barrier();\\\n+        /* Load input to B_block: (BS_CRS x BS_NPQ) */\\\n+        for(uint32_t r_offset = 0; r_offset < BS_CRS; r_offset += BrpWg){\\\n+            uint32_t B_ly = r_offset + Br;                      /* Row index of B block */\\\n+            uint32_t B_lx = Bc;                                 /* Column index of B block */\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_ly;         /* Global CRS index (row index of B) */\\\n+            uint32_t NPQ_idx = B_idx_NPQ*BS_NPQ + B_lx;         /* Global NPQ index (column index of B) */\\\n+            BOUNDARY_CONDITION_B_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t H_idx = OH_idx*p.s1 + KH_idx*p.d1 - p.p1;\\\n+                uint32_t W_idx = OW_idx*p.s0 + KW_idx*p.d0 - p.p0;\\\n+                if(H_idx >= 0 && H_idx < p.H && W_idx >= 0 && W_idx < p.W){\\\n+                    uint32_t src_idx = W_idx + H_idx*p.nb11 + Cin_idx*p.nb12 + N_idx*p.nb13;\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = src_data[src_idx];\\\n+                }else{\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+                }\\\n+            BOUNDARY_CONDITION_B_ELSE()\\\n+        }\\\n+        barrier();\\\n+        outProdReg();\\\n+        barrier();\\\n+    }\\\n+    /* Save C* */\\\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\\\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\\\n+            uint32_t K_idx = B_idx_K * BS_K + T_y * TS_K + T_ly;\\\n+            uint32_t NPQ_idx = B_idx_NPQ * BS_NPQ + T_x * TS_NPQ + T_lx;\\\n+            if(K_idx < K && NPQ_idx < NPQ){\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t dst_idx = OW_idx + OH_idx*p.nb1 + K_idx*p.nb2 + N_idx*p.nb3;\\\n+                dst_data[dst_idx] = regC[T_ly][T_lx];\\\n+            }\\\n+        }\\\n+    }\\\n+}\n+\n+// Generates mainLoopBoundaryCheck\n+MAIN_LOOP(BoundaryCheck, \n+    DEF_BOUNDARY_CONDITION_A_IF, \n+    DEF_BOUNDARY_CONDITION_A_ELSE, \n+    DEF_BOUNDARY_CONDITION_B_IF, \n+    DEF_BOUNDARY_CONDITION_B_ELSE)\n+\n+// Generates mainLoopNoBoundaryCheck\n+MAIN_LOOP(NoBoundaryCheck, \n+    NOOP, NOOP, NOOP, NOOP)\n+\n+void main(){\n+    if(gl_WorkGroupID.x == gl_NumWorkGroups.x-1 || gl_WorkGroupID.y == gl_NumWorkGroups.y-1){\n+        mainLoopBoundaryCheck();",
        "comment_created_at": "2025-06-28T17:10:30+00:00",
        "comment_author": "0cc4m",
        "comment_body": "Please update this branch with the new implementation, it makes a big difference.",
        "pr_file_module": null
      },
      {
        "comment_id": "2173470356",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14316,
        "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
        "discussion_id": "2160056083",
        "commented_code": "@@ -0,0 +1,244 @@\n+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\\n+        /* Load kernel to A_block: (BS_K x BS_CRS)*/\\\n+        for(uint32_t r_offset = 0; r_offset < BS_K; r_offset += ArpWg){\\\n+            uint32_t B_ly = r_offset + Ar;\\\n+            uint32_t B_lx = Ac;\\\n+            uint32_t K_idx = B_idx_K*BS_K + B_ly;                /* Global K_idx (row index of A)*/\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_lx;          /* Global CRS_idx (column index of A)*/\\\n+            BOUNDARY_CONDITION_A_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t knl_idx = KW_idx + KH_idx*p.nb01 + Cin_idx*p.nb02 + K_idx*p.nb03;\\\n+                Ash[B_ly * Ash_stride + B_lx] = knl_data[knl_idx];\\\n+            BOUNDARY_CONDITION_A_ELSE()\\\n+        }\\\n+        barrier();\\\n+        /* Load input to B_block: (BS_CRS x BS_NPQ) */\\\n+        for(uint32_t r_offset = 0; r_offset < BS_CRS; r_offset += BrpWg){\\\n+            uint32_t B_ly = r_offset + Br;                      /* Row index of B block */\\\n+            uint32_t B_lx = Bc;                                 /* Column index of B block */\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_ly;         /* Global CRS index (row index of B) */\\\n+            uint32_t NPQ_idx = B_idx_NPQ*BS_NPQ + B_lx;         /* Global NPQ index (column index of B) */\\\n+            BOUNDARY_CONDITION_B_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t H_idx = OH_idx*p.s1 + KH_idx*p.d1 - p.p1;\\\n+                uint32_t W_idx = OW_idx*p.s0 + KW_idx*p.d0 - p.p0;\\\n+                if(H_idx >= 0 && H_idx < p.H && W_idx >= 0 && W_idx < p.W){\\\n+                    uint32_t src_idx = W_idx + H_idx*p.nb11 + Cin_idx*p.nb12 + N_idx*p.nb13;\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = src_data[src_idx];\\\n+                }else{\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+                }\\\n+            BOUNDARY_CONDITION_B_ELSE()\\\n+        }\\\n+        barrier();\\\n+        outProdReg();\\\n+        barrier();\\\n+    }\\\n+    /* Save C* */\\\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\\\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\\\n+            uint32_t K_idx = B_idx_K * BS_K + T_y * TS_K + T_ly;\\\n+            uint32_t NPQ_idx = B_idx_NPQ * BS_NPQ + T_x * TS_NPQ + T_lx;\\\n+            if(K_idx < K && NPQ_idx < NPQ){\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t dst_idx = OW_idx + OH_idx*p.nb1 + K_idx*p.nb2 + N_idx*p.nb3;\\\n+                dst_data[dst_idx] = regC[T_ly][T_lx];\\\n+            }\\\n+        }\\\n+    }\\\n+}\n+\n+// Generates mainLoopBoundaryCheck\n+MAIN_LOOP(BoundaryCheck, \n+    DEF_BOUNDARY_CONDITION_A_IF, \n+    DEF_BOUNDARY_CONDITION_A_ELSE, \n+    DEF_BOUNDARY_CONDITION_B_IF, \n+    DEF_BOUNDARY_CONDITION_B_ELSE)\n+\n+// Generates mainLoopNoBoundaryCheck\n+MAIN_LOOP(NoBoundaryCheck, \n+    NOOP, NOOP, NOOP, NOOP)\n+\n+void main(){\n+    if(gl_WorkGroupID.x == gl_NumWorkGroups.x-1 || gl_WorkGroupID.y == gl_NumWorkGroups.y-1){\n+        mainLoopBoundaryCheck();",
        "comment_created_at": "2025-06-28T17:58:13+00:00",
        "comment_author": "etasnadi",
        "comment_body": "My numbers are misleading in branches out of this pull request because the boundary check is misplaced so lots of computation is not executed resulting in failing tests. Also see comment https://github.com/ggml-org/llama.cpp/pull/14316#issuecomment-3015850603",
        "pr_file_module": null
      },
      {
        "comment_id": "2203631979",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14316,
        "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
        "discussion_id": "2160056083",
        "commented_code": "@@ -0,0 +1,244 @@\n+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\\n+        /* Load kernel to A_block: (BS_K x BS_CRS)*/\\\n+        for(uint32_t r_offset = 0; r_offset < BS_K; r_offset += ArpWg){\\\n+            uint32_t B_ly = r_offset + Ar;\\\n+            uint32_t B_lx = Ac;\\\n+            uint32_t K_idx = B_idx_K*BS_K + B_ly;                /* Global K_idx (row index of A)*/\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_lx;          /* Global CRS_idx (column index of A)*/\\\n+            BOUNDARY_CONDITION_A_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t knl_idx = KW_idx + KH_idx*p.nb01 + Cin_idx*p.nb02 + K_idx*p.nb03;\\\n+                Ash[B_ly * Ash_stride + B_lx] = knl_data[knl_idx];\\\n+            BOUNDARY_CONDITION_A_ELSE()\\\n+        }\\\n+        barrier();\\\n+        /* Load input to B_block: (BS_CRS x BS_NPQ) */\\\n+        for(uint32_t r_offset = 0; r_offset < BS_CRS; r_offset += BrpWg){\\\n+            uint32_t B_ly = r_offset + Br;                      /* Row index of B block */\\\n+            uint32_t B_lx = Bc;                                 /* Column index of B block */\\\n+            uint32_t CRS_idx = B_idx_CRS*BS_CRS + B_ly;         /* Global CRS index (row index of B) */\\\n+            uint32_t NPQ_idx = B_idx_NPQ*BS_NPQ + B_lx;         /* Global NPQ index (column index of B) */\\\n+            BOUNDARY_CONDITION_B_IF()\\\n+                uint32_t Cin_idx = CRS_idx / (p.KW*p.KH);\\\n+                uint32_t KH_idx = (CRS_idx - Cin_idx*p.KW*p.KH) / p.KW;\\\n+                uint32_t KW_idx = CRS_idx - Cin_idx*p.KW*p.KH - KH_idx*p.KW;\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t H_idx = OH_idx*p.s1 + KH_idx*p.d1 - p.p1;\\\n+                uint32_t W_idx = OW_idx*p.s0 + KW_idx*p.d0 - p.p0;\\\n+                if(H_idx >= 0 && H_idx < p.H && W_idx >= 0 && W_idx < p.W){\\\n+                    uint32_t src_idx = W_idx + H_idx*p.nb11 + Cin_idx*p.nb12 + N_idx*p.nb13;\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = src_data[src_idx];\\\n+                }else{\\\n+                    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+                }\\\n+            BOUNDARY_CONDITION_B_ELSE()\\\n+        }\\\n+        barrier();\\\n+        outProdReg();\\\n+        barrier();\\\n+    }\\\n+    /* Save C* */\\\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\\\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\\\n+            uint32_t K_idx = B_idx_K * BS_K + T_y * TS_K + T_ly;\\\n+            uint32_t NPQ_idx = B_idx_NPQ * BS_NPQ + T_x * TS_NPQ + T_lx;\\\n+            if(K_idx < K && NPQ_idx < NPQ){\\\n+                uint32_t N_idx = NPQ_idx / (p.OH*p.OW);\\\n+                uint32_t OH_idx = (NPQ_idx - N_idx*p.OH*p.OW) / p.OW;\\\n+                uint32_t OW_idx = NPQ_idx - N_idx*p.OH*p.OW - OH_idx*p.OW;\\\n+                uint32_t dst_idx = OW_idx + OH_idx*p.nb1 + K_idx*p.nb2 + N_idx*p.nb3;\\\n+                dst_data[dst_idx] = regC[T_ly][T_lx];\\\n+            }\\\n+        }\\\n+    }\\\n+}\n+\n+// Generates mainLoopBoundaryCheck\n+MAIN_LOOP(BoundaryCheck, \n+    DEF_BOUNDARY_CONDITION_A_IF, \n+    DEF_BOUNDARY_CONDITION_A_ELSE, \n+    DEF_BOUNDARY_CONDITION_B_IF, \n+    DEF_BOUNDARY_CONDITION_B_ELSE)\n+\n+// Generates mainLoopNoBoundaryCheck\n+MAIN_LOOP(NoBoundaryCheck, \n+    NOOP, NOOP, NOOP, NOOP)\n+\n+void main(){\n+    if(gl_WorkGroupID.x == gl_NumWorkGroups.x-1 || gl_WorkGroupID.y == gl_NumWorkGroups.y-1){\n+        mainLoopBoundaryCheck();",
        "comment_created_at": "2025-07-13T23:49:39+00:00",
        "comment_author": "etasnadi",
        "comment_body": "0715985edfba0b40dde04254b5d80c8d00afb2a0 eliminates all the macros.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2160097593",
    "pr_number": 14316,
    "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
    "created_at": "2025-06-21T17:36:37+00:00",
    "commented_code": "+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2160097593",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14316,
        "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
        "discussion_id": "2160097593",
        "commented_code": "@@ -0,0 +1,244 @@\n+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\",
        "comment_created_at": "2025-06-21T17:36:37+00:00",
        "comment_author": "jeffbolznv",
        "comment_body": "You might need to add [[unroll]] on loops with constant trip count. Sometimes the compiler will do this automatically, but when there are nested loops sometimes it won't.",
        "pr_file_module": null
      },
      {
        "comment_id": "2160104938",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14316,
        "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
        "discussion_id": "2160097593",
        "commented_code": "@@ -0,0 +1,244 @@\n+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\",
        "comment_created_at": "2025-06-21T18:11:33+00:00",
        "comment_author": "etasnadi",
        "comment_body": "I annotated all the loops except this (because the main loop is sequential) and I get the same flops unfortunately.",
        "pr_file_module": null
      },
      {
        "comment_id": "2203631000",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14316,
        "pr_file": "ggml/src/ggml-vulkan/vulkan-shaders/conv2d_mm.comp",
        "discussion_id": "2160097593",
        "commented_code": "@@ -0,0 +1,244 @@\n+#version 450\n+\n+#extension GL_EXT_control_flow_attributes : enable\n+\n+#include \"types.comp\"\n+\n+// shape notation: [dim(N), ..., dim(0)] -- stride(dim(j)) >= stride(dim(i)) if i > j\n+layout (binding = 0) readonly buffer A {A_TYPE knl_data[];};    // src0 - kernel:   [KW, KH, Cin, Cout] \n+layout (binding = 1) readonly buffer B {B_TYPE src_data[];};    // src1 - input:    [W, H, Cin, N] -- channel_first format\n+layout (binding = 2) writeonly buffer D {D_TYPE dst_data[];};   // dst - result:    [OW, OH, Cout, N]\n+\n+layout (push_constant) uniform parameter {\n+    // I/O channels, batch size\n+    uint32_t Cout;\n+    uint32_t Cin;\n+    uint32_t N;\n+    \n+    // Tensor spatial sizes: kernel, input, output\n+    uint32_t KW;\n+    uint32_t KH;\n+    uint32_t W;\n+    uint32_t H;\n+    uint32_t OW;\n+    uint32_t OH;\n+\n+    // Parameters: stride, padding, dilation - 0=y, 1=x\n+    uint32_t s0;\n+    uint32_t s1;\n+    uint32_t p0;\n+    uint32_t p1;\n+    uint32_t d0;\n+    uint32_t d1;\n+\n+    // Strides in elements\n+    uint32_t nb01;\n+    uint32_t nb02;\n+    uint32_t nb03;\n+\n+    uint32_t nb11;\n+    uint32_t nb12;\n+    uint32_t nb13;\n+\n+    uint32_t nb1;\n+    uint32_t nb2;\n+    uint32_t nb3;\n+} p;\n+\n+#define WG_SIZE 256\n+\n+layout(local_size_x = WG_SIZE, local_size_y = 1, local_size_z = 1) in;\n+\n+uint32_t tid = gl_LocalInvocationID.x;\n+const uint32_t bs = gl_WorkGroupSize.x;\n+\n+uint splitWork(uint work_size, uint block_size){\n+    return (block_size + work_size -1) / block_size;\n+}\n+\n+uint32_t K = p.Cout;\n+uint32_t CRS = p.Cin*p.KH*p.KW;\n+uint32_t NPQ = p.N*p.OH*p.OW;\n+\n+uint32_t n_elems_out = K*NPQ;\n+\n+// Blocktile sizes\n+const uint32_t BS_K = 128;\n+const uint32_t BS_CRS = 16;\n+const uint32_t BS_NPQ = 128;\n+\n+// Number of blocktiles per input\n+uint32_t NB_CRS = splitWork(CRS, BS_CRS);\n+\n+const uint32_t Ash_stride = BS_CRS+1;\n+const uint32_t Bsh_stride = BS_NPQ+1;\n+\n+const uint32_t Ash_numel = BS_K*BS_CRS;\n+const uint32_t Bsh_numel = BS_CRS*BS_NPQ;\n+\n+const uint32_t Ash_len = BS_K*Ash_stride;\n+const uint32_t Bsh_len = BS_CRS*Bsh_stride;\n+\n+shared float Ash[Ash_len];  // K x CRS\n+shared float Bsh[Bsh_len];  // CRS x NPQ\n+\n+// Threadtile sizes\n+const uint32_t TS_K = 16;\n+const uint32_t TS_NPQ = BS_K*BS_NPQ / WG_SIZE / TS_K;\n+\n+// Number of threadtiles per blocktile\n+const uint32_t NT_K = BS_K / TS_K;\n+const uint32_t NT_NPQ = BS_NPQ / TS_NPQ;\n+\n+float regA[TS_K];\n+float regB[TS_NPQ];\n+float regC[TS_K][TS_NPQ];\n+\n+/*\n+Compute\n+KxCRS @ CRSxNPQ = K x NPQ\n+K=Cout\n+C=Cin\n+R,S=KH,KW\n+P,Q=OH,OW\n+*/\n+\n+uint32_t B_idx_K = gl_WorkGroupID.x;\n+uint32_t B_idx_NPQ = gl_WorkGroupID.y;\n+\n+uint32_t T_y = tid / NT_NPQ;\n+uint32_t T_x = tid % NT_NPQ;\n+\n+uint32_t Ar = tid / BS_CRS;\n+uint32_t Ac = tid % BS_CRS;\n+uint32_t ArpWg = WG_SIZE / BS_CRS;\n+\n+uint32_t Br = tid / BS_NPQ;\n+uint32_t Bc = tid % BS_NPQ;\n+uint32_t BrpWg = WG_SIZE / BS_NPQ;\n+\n+void initReg(){\n+    for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regC[T_ly][T_lx] = 0.0;\n+        }\n+    }\n+}\n+\n+void outProdReg(){\n+    for(uint32_t CRS_lidx = 0; CRS_lidx < BS_CRS; CRS_lidx++){\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            regA[T_ly] = Ash[(T_y*TS_K + T_ly)*Ash_stride + CRS_lidx];\n+        }\n+        for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+            regB[T_lx] = Bsh[CRS_lidx*Bsh_stride + T_x*TS_NPQ+T_lx];\n+        }\n+        for(uint32_t T_ly = 0; T_ly < TS_K; T_ly++){\n+            for(uint32_t T_lx = 0; T_lx < TS_NPQ; T_lx++){\n+                regC[T_ly][T_lx] += regA[T_ly] * regB[T_lx];\n+            }\n+        }\n+    }\n+}\n+\n+// Generate different functions for computing the sides.\n+\n+#define NOOP()\n+\n+#define DEF_BOUNDARY_CONDITION_A_IF()\\\n+if(K_idx < K && CRS_idx < CRS){\n+\n+#define DEF_BOUNDARY_CONDITION_A_ELSE()\\\n+}else{\\\n+    Ash[B_ly * Ash_stride + B_lx] = 0.0;\\\n+}\n+\n+#define DEF_BOUNDARY_CONDITION_B_IF()\\\n+if(CRS_idx < CRS && NPQ_idx < NPQ){\n+\n+#define DEF_BOUNDARY_CONDITION_B_ELSE()\\\n+}else{\\\n+    Bsh[B_ly * Bsh_stride + B_lx] = 0.0;\\\n+}\n+\n+#define MAIN_LOOP(FUNC_NAME_SUFFIX, BOUNDARY_CONDITION_A_IF, BOUNDARY_CONDITION_A_ELSE, BOUNDARY_CONDITION_B_IF, BOUNDARY_CONDITION_B_ELSE)\\\n+void mainLoop ## FUNC_NAME_SUFFIX(){\\\n+    initReg();\\\n+    /* Advance block in CRS dim */\\\n+    for(uint32_t B_idx_CRS = 0; B_idx_CRS < NB_CRS; B_idx_CRS++){\\",
        "comment_created_at": "2025-07-13T23:46:22+00:00",
        "comment_author": "etasnadi",
        "comment_body": "0715985edfba0b40dde04254b5d80c8d00afb2a0 fixes this by minimizing the number of statements in branches.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2194098117",
    "pr_number": 14535,
    "pr_file": "ggml/src/ggml-opencl/kernels/mul_mat_f16_f32.cl",
    "created_at": "2025-07-09T06:03:01+00:00",
    "commented_code": "+#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n+\n+#if defined(cl_qcom_reqd_sub_group_size)\n+#pragma OPENCL EXTENSION cl_qcom_reqd_sub_group_size : enable\n+#define REQD_SUBGROUP_SIZE_128 __attribute__((qcom_reqd_sub_group_size(\"full\")))\n+#else\n+#define REQD_SUBGROUP_SIZE_128\n+#endif\n+\n+#define OPWM 64\n+#define OPWN 64\n+#define CPWK 8\n+#define OPTM 4\n+#define OPTN 8\n+\n+#define WG_M (OPWM / OPTM)\n+#define WG_N (OPWN / OPTN)",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2194098117",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14535,
        "pr_file": "ggml/src/ggml-opencl/kernels/mul_mat_f16_f32.cl",
        "discussion_id": "2194098117",
        "commented_code": "@@ -0,0 +1,130 @@\n+#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n+\n+#if defined(cl_qcom_reqd_sub_group_size)\n+#pragma OPENCL EXTENSION cl_qcom_reqd_sub_group_size : enable\n+#define REQD_SUBGROUP_SIZE_128 __attribute__((qcom_reqd_sub_group_size(\"full\")))\n+#else\n+#define REQD_SUBGROUP_SIZE_128\n+#endif\n+\n+#define OPWM 64\n+#define OPWN 64\n+#define CPWK 8\n+#define OPTM 4\n+#define OPTN 8\n+\n+#define WG_M (OPWM / OPTM)\n+#define WG_N (OPWN / OPTN)",
        "comment_created_at": "2025-07-09T06:03:01+00:00",
        "comment_author": "lhez",
        "comment_body": "`WG_M` and `WG_N` seem to be workgroup size - can they be replaced with `get_local_size()`?",
        "pr_file_module": null
      },
      {
        "comment_id": "2194456248",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14535,
        "pr_file": "ggml/src/ggml-opencl/kernels/mul_mat_f16_f32.cl",
        "discussion_id": "2194098117",
        "commented_code": "@@ -0,0 +1,130 @@\n+#pragma OPENCL EXTENSION cl_khr_fp16 : enable\n+\n+#if defined(cl_qcom_reqd_sub_group_size)\n+#pragma OPENCL EXTENSION cl_qcom_reqd_sub_group_size : enable\n+#define REQD_SUBGROUP_SIZE_128 __attribute__((qcom_reqd_sub_group_size(\"full\")))\n+#else\n+#define REQD_SUBGROUP_SIZE_128\n+#endif\n+\n+#define OPWM 64\n+#define OPWN 64\n+#define CPWK 8\n+#define OPTM 4\n+#define OPTN 8\n+\n+#define WG_M (OPWM / OPTM)\n+#define WG_N (OPWN / OPTN)",
        "comment_created_at": "2025-07-09T08:55:32+00:00",
        "comment_author": "rmatif",
        "comment_body": "I tested replacing the macros with get_local_size(), but it resulted in a significant performance regression (~17%). Using compile-time constants is critical here, as it allows the compiler to fully unroll the inner loops and pre-calculate memory address offsets, an optimization that is lost when WG_M becomes a runtime value",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1350353248",
    "pr_number": 2059,
    "pr_file": "ggml-vulkan-shaders.hpp",
    "created_at": "2023-10-09T14:02:49+00:00",
    "commented_code": "+#include <string>\n+\n+// Generic\n+const std::string shader_f32 = R\"(",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "1350353248",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 2059,
        "pr_file": "ggml-vulkan-shaders.hpp",
        "discussion_id": "1350353248",
        "commented_code": "@@ -0,0 +1,773 @@\n+#include <string>\n+\n+// Generic\n+const std::string shader_f32 = R\"(",
        "comment_created_at": "2023-10-09T14:02:49+00:00",
        "comment_author": "Green-Sky",
        "comment_body": "is there a reason to use `std::string` here and not just `const char*` ?",
        "pr_file_module": null
      },
      {
        "comment_id": "1350669067",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 2059,
        "pr_file": "ggml-vulkan-shaders.hpp",
        "discussion_id": "1350353248",
        "commented_code": "@@ -0,0 +1,773 @@\n+#include <string>\n+\n+// Generic\n+const std::string shader_f32 = R\"(",
        "comment_created_at": "2023-10-09T18:30:20+00:00",
        "comment_author": "0cc4m",
        "comment_body": "The Vulkan code is C++, so I used string here instead of const char. But it seems that compiling shaders on runtime causes more issues than it resolves. It seems to cause issues with building on Windows and also @Jipok 's error was with linking shaderc. I'll replace it with something that builds and compiles the shaders on build time, not run time.",
        "pr_file_module": null
      },
      {
        "comment_id": "1350672373",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 2059,
        "pr_file": "ggml-vulkan-shaders.hpp",
        "discussion_id": "1350353248",
        "commented_code": "@@ -0,0 +1,773 @@\n+#include <string>\n+\n+// Generic\n+const std::string shader_f32 = R\"(",
        "comment_created_at": "2023-10-09T18:32:39+00:00",
        "comment_author": "Green-Sky",
        "comment_body": "> The Vulkan code is C++, so I used string here instead of const char.\r\n\r\nyea, but no reason to construct a `std::string`\r\n\r\n> But it seems that compiling shaders on runtime causes more issues than it resolves.\r\n\r\nyea i feel that. guess we will have to ship optimized `.spv` files.",
        "pr_file_module": null
      },
      {
        "comment_id": "1350760689",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 2059,
        "pr_file": "ggml-vulkan-shaders.hpp",
        "discussion_id": "1350353248",
        "commented_code": "@@ -0,0 +1,773 @@\n+#include <string>\n+\n+// Generic\n+const std::string shader_f32 = R\"(",
        "comment_created_at": "2023-10-09T20:25:28+00:00",
        "comment_author": "netrunnereve",
        "comment_body": "I'm not familar with Vulkan but are the shaders specially optimized for the local hardware when they're compiled? This would be a strong argument for runtime compilation as it would make the builds portable across different platforms.",
        "pr_file_module": null
      },
      {
        "comment_id": "1350786238",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 2059,
        "pr_file": "ggml-vulkan-shaders.hpp",
        "discussion_id": "1350353248",
        "commented_code": "@@ -0,0 +1,773 @@\n+#include <string>\n+\n+// Generic\n+const std::string shader_f32 = R\"(",
        "comment_created_at": "2023-10-09T21:03:55+00:00",
        "comment_author": "0cc4m",
        "comment_body": "That was the idea. Currently it only distinguishes between devices with shaderFloat16 and devices without it, which would be easy to ship with SPIR-V files. Another use case will be tensor core usage with NV_cooperative_matrix support. There's probably not enough cases out there to warrant dealing with the issues linking shaderc is causing.",
        "pr_file_module": null
      },
      {
        "comment_id": "1350789462",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 2059,
        "pr_file": "ggml-vulkan-shaders.hpp",
        "discussion_id": "1350353248",
        "commented_code": "@@ -0,0 +1,773 @@\n+#include <string>\n+\n+// Generic\n+const std::string shader_f32 = R\"(",
        "comment_created_at": "2023-10-09T21:09:21+00:00",
        "comment_author": "0cc4m",
        "comment_body": "If you mean automatic optimization for the specific device, that still happens when the driver compiles from the intermediate binary format SPIR-V (.spv file) to whatever it's using internally. I was talking about compiling GLSL code on runtime to SPIR-V.",
        "pr_file_module": null
      },
      {
        "comment_id": "1351136566",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 2059,
        "pr_file": "ggml-vulkan-shaders.hpp",
        "discussion_id": "1350353248",
        "commented_code": "@@ -0,0 +1,773 @@\n+#include <string>\n+\n+// Generic\n+const std::string shader_f32 = R\"(",
        "comment_created_at": "2023-10-10T01:35:09+00:00",
        "comment_author": "lin72h",
        "comment_body": "There's also [VK_KHR_cooperative_matrix](https://github.com/KhronosGroup/SPIRV-Registry/pull/207)",
        "pr_file_module": null
      }
    ]
  }
]