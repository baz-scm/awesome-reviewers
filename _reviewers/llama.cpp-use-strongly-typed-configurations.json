[
  {
    "discussion_id": "2200745919",
    "pr_number": 14622,
    "pr_file": "common/arg.cpp",
    "created_at": "2025-07-11T13:25:17+00:00",
    "commented_code": "}\n     ).set_examples({LLAMA_EXAMPLE_SERVER}));\n \n+    add_opt(common_arg(\n+        {\"--dataset-format\"}, \" \",\n+        string_format(\"type of input data (e.g., 'text', 'parquet') (default: %s)\", params.dataset_format.c_str()),\n+        [](common_params & params, const std::string & format) {\n+            params.dataset_format = format; //TODO ENUM CLASS\n+        }\n+    ).set_examples({LLAMA_EXAMPLE_FINETUNE}));",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2200745919",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14622,
        "pr_file": "common/arg.cpp",
        "discussion_id": "2200745919",
        "commented_code": "@@ -3423,5 +3423,73 @@ common_params_context common_params_parser_init(common_params & params, llama_ex\n         }\n     ).set_examples({LLAMA_EXAMPLE_SERVER}));\n \n+    add_opt(common_arg(\n+        {\"--dataset-format\"}, \" \",\n+        string_format(\"type of input data (e.g., 'text', 'parquet') (default: %s)\", params.dataset_format.c_str()),\n+        [](common_params & params, const std::string & format) {\n+            params.dataset_format = format; //TODO ENUM CLASS\n+        }\n+    ).set_examples({LLAMA_EXAMPLE_FINETUNE}));",
        "comment_created_at": "2025-07-11T13:25:17+00:00",
        "comment_author": "JohannesGaessler",
        "comment_body": "Can't this be determined automatically?",
        "pr_file_module": null
      },
      {
        "comment_id": "2201526524",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14622,
        "pr_file": "common/arg.cpp",
        "discussion_id": "2200745919",
        "commented_code": "@@ -3423,5 +3423,73 @@ common_params_context common_params_parser_init(common_params & params, llama_ex\n         }\n     ).set_examples({LLAMA_EXAMPLE_SERVER}));\n \n+    add_opt(common_arg(\n+        {\"--dataset-format\"}, \" \",\n+        string_format(\"type of input data (e.g., 'text', 'parquet') (default: %s)\", params.dataset_format.c_str()),\n+        [](common_params & params, const std::string & format) {\n+            params.dataset_format = format; //TODO ENUM CLASS\n+        }\n+    ).set_examples({LLAMA_EXAMPLE_FINETUNE}));",
        "comment_created_at": "2025-07-11T18:43:02+00:00",
        "comment_author": "lexasub",
        "comment_body": "I agree we could add `auto` as the default dataset format while retaining the parameter. The converter could automatically detect formats (via file extensions/headers) when set to `auto`, while still allowing explicit overrides. This balances convenience and control.\r\n\r\nFor the `--dataset-format` example:\r\n   - Would you prefer an enum class with `AUTO` instead of raw strings?\r\n   - Should we implement fallback logic when auto-detection fails?\r\n   - What's the priority between auto-detection vs explicit arguments?\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2202440619",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14622,
        "pr_file": "common/arg.cpp",
        "discussion_id": "2200745919",
        "commented_code": "@@ -3423,5 +3423,73 @@ common_params_context common_params_parser_init(common_params & params, llama_ex\n         }\n     ).set_examples({LLAMA_EXAMPLE_SERVER}));\n \n+    add_opt(common_arg(\n+        {\"--dataset-format\"}, \" \",\n+        string_format(\"type of input data (e.g., 'text', 'parquet') (default: %s)\", params.dataset_format.c_str()),\n+        [](common_params & params, const std::string & format) {\n+            params.dataset_format = format; //TODO ENUM CLASS\n+        }\n+    ).set_examples({LLAMA_EXAMPLE_FINETUNE}));",
        "comment_created_at": "2025-07-12T08:25:07+00:00",
        "comment_author": "JohannesGaessler",
        "comment_body": "I think an enum is better than a string.\r\n\r\nThe way I would implement the automatic detection is to try loading GGUF and Parquet first. The order shouldn't matter since the loading will fail if there is a mismatch. If both fail, load as plain text. I don't think fallback logic beyond that is needed.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2211718004",
    "pr_number": 14482,
    "pr_file": "src/llama-kv-cache-unified.cpp",
    "created_at": "2025-07-16T22:19:53+00:00",
    "commented_code": "debug = LLAMA_KV_CACHE_DEBUG ? atoi(LLAMA_KV_CACHE_DEBUG) : 0;\n \n     const char * LLAMA_SET_ROWS = getenv(\"LLAMA_SET_ROWS\");\n-    supports_set_rows = LLAMA_SET_ROWS ? atoi(LLAMA_SET_ROWS) : 0;\n+    supports_set_rows = LLAMA_SET_ROWS ? atoi(LLAMA_SET_ROWS) != 0 : 0;",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2211718004",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14482,
        "pr_file": "src/llama-kv-cache-unified.cpp",
        "discussion_id": "2211718004",
        "commented_code": "@@ -158,7 +158,7 @@ llama_kv_cache_unified::llama_kv_cache_unified(\n     debug = LLAMA_KV_CACHE_DEBUG ? atoi(LLAMA_KV_CACHE_DEBUG) : 0;\n \n     const char * LLAMA_SET_ROWS = getenv(\"LLAMA_SET_ROWS\");\n-    supports_set_rows = LLAMA_SET_ROWS ? atoi(LLAMA_SET_ROWS) : 0;\n+    supports_set_rows = LLAMA_SET_ROWS ? atoi(LLAMA_SET_ROWS) != 0 : 0;",
        "comment_created_at": "2025-07-16T22:19:53+00:00",
        "comment_author": "slaren",
        "comment_body": "```suggestion\r\n    supports_set_rows = LLAMA_SET_ROWS ? atoi(LLAMA_SET_ROWS) != 0 : false;\r\n```",
        "pr_file_module": null
      }
    ]
  }
]