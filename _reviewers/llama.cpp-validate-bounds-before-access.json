[
  {
    "discussion_id": "2186028837",
    "pr_number": 14363,
    "pr_file": "src/llama-kv-cache-unified.cpp",
    "created_at": "2025-07-04T19:37:54+00:00",
    "commented_code": "}\n \n void llama_kv_cache_unified::seq_cp(llama_seq_id seq_id_src, llama_seq_id seq_id_dst, llama_pos p0, llama_pos p1) {\n-    if (seq_id_src == seq_id_dst) {\n+    const auto s0 = seq_to_stream[seq_id_src];\n+    const auto s1 = seq_to_stream[seq_id_dst];",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2186028837",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14363,
        "pr_file": "src/llama-kv-cache-unified.cpp",
        "discussion_id": "2186028837",
        "commented_code": "@@ -224,30 +263,91 @@ bool llama_kv_cache_unified::seq_rm(llama_seq_id seq_id, llama_pos p0, llama_pos\n }\n \n void llama_kv_cache_unified::seq_cp(llama_seq_id seq_id_src, llama_seq_id seq_id_dst, llama_pos p0, llama_pos p1) {\n-    if (seq_id_src == seq_id_dst) {\n+    const auto s0 = seq_to_stream[seq_id_src];\n+    const auto s1 = seq_to_stream[seq_id_dst];",
        "comment_created_at": "2025-07-04T19:37:54+00:00",
        "comment_author": "slaren",
        "comment_body": "Check user inputs to avoid OOB accesses.\r\n```suggestion\r\n    GGML_ASSERT(seq_id_src < seq_to_stream.size());\r\n    GGML_ASSERT(seq_id_dst < seq_to_stream.size());\r\n    const auto s0 = seq_to_stream[seq_id_src];\r\n    const auto s1 = seq_to_stream[seq_id_dst];\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2188455917",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14363,
        "pr_file": "src/llama-kv-cache-unified.cpp",
        "discussion_id": "2186028837",
        "commented_code": "@@ -224,30 +263,91 @@ bool llama_kv_cache_unified::seq_rm(llama_seq_id seq_id, llama_pos p0, llama_pos\n }\n \n void llama_kv_cache_unified::seq_cp(llama_seq_id seq_id_src, llama_seq_id seq_id_dst, llama_pos p0, llama_pos p1) {\n-    if (seq_id_src == seq_id_dst) {\n+    const auto s0 = seq_to_stream[seq_id_src];\n+    const auto s1 = seq_to_stream[seq_id_dst];",
        "comment_created_at": "2025-07-06T16:30:56+00:00",
        "comment_author": "ggerganov",
        "comment_body": "I used the `.at()` method: [11ee725](https://github.com/ggml-org/llama.cpp/pull/14363/commits/11ee725a373f8a3ec8f9c8bd94cdd99e72fcd501)",
        "pr_file_module": null
      },
      {
        "comment_id": "2189627258",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14363,
        "pr_file": "src/llama-kv-cache-unified.cpp",
        "discussion_id": "2186028837",
        "commented_code": "@@ -224,30 +263,91 @@ bool llama_kv_cache_unified::seq_rm(llama_seq_id seq_id, llama_pos p0, llama_pos\n }\n \n void llama_kv_cache_unified::seq_cp(llama_seq_id seq_id_src, llama_seq_id seq_id_dst, llama_pos p0, llama_pos p1) {\n-    if (seq_id_src == seq_id_dst) {\n+    const auto s0 = seq_to_stream[seq_id_src];\n+    const auto s1 = seq_to_stream[seq_id_dst];",
        "comment_created_at": "2025-07-07T10:30:45+00:00",
        "comment_author": "slaren",
        "comment_body": "The exceptions will propagate through the C API, which is not great. If the exception is uncaught, it will call `terminate` which is fine, but if the llama.cpp API is called within a `try..catch` block, the application may end capturing the exception.",
        "pr_file_module": null
      },
      {
        "comment_id": "2189639673",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14363,
        "pr_file": "src/llama-kv-cache-unified.cpp",
        "discussion_id": "2186028837",
        "commented_code": "@@ -224,30 +263,91 @@ bool llama_kv_cache_unified::seq_rm(llama_seq_id seq_id, llama_pos p0, llama_pos\n }\n \n void llama_kv_cache_unified::seq_cp(llama_seq_id seq_id_src, llama_seq_id seq_id_dst, llama_pos p0, llama_pos p1) {\n-    if (seq_id_src == seq_id_dst) {\n+    const auto s0 = seq_to_stream[seq_id_src];\n+    const auto s1 = seq_to_stream[seq_id_dst];",
        "comment_created_at": "2025-07-07T10:34:53+00:00",
        "comment_author": "ggerganov",
        "comment_body": "I missed that. Fixing.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2205045812",
    "pr_number": 14676,
    "pr_file": "ggml/src/ggml-cpu/kleidiai/kleidiai.cpp",
    "created_at": "2025-07-14T14:10:09+00:00",
    "commented_code": "return true;\n     }\n \n+    bool compute_forward_get_rows(struct ggml_compute_params * params, struct ggml_tensor * dst) {\n+        GGML_ASSERT(ctx.kernels);\n+\n+        const ggml_tensor * src0 = dst->src[0];\n+        const ggml_tensor * src1 = dst->src[1];\n+\n+        GGML_TENSOR_BINARY_OP_LOCALS\n+\n+        rhs_packing_info * rhs_info = &ctx.kernels->rhs_info;\n+        kernel_info * kernel        = &ctx.kernels->gemm;\n+\n+        const int64_t nc     = ne00;\n+        const int64_t nr     = ggml_nelements(src1);\n+\n+        const size_t block_rows = kernel->get_nr();\n+        const size_t kr         = kernel->get_kr();\n+\n+        const size_t num_bytes_multiplier = sizeof(uint16_t);\n+        const size_t packed_stride = rhs_info->packed_stride(nc, block_rows, kr, QK4_0);\n+\n+        const int ith = params->ith;\n+        const int nth = params->nth;\n+\n+        const int dr = (nr + nth - 1) / nth;\n+        const int ir0 = dr * ith;\n+        const int ir1 = MIN(ir0 + dr, nr);\n+\n+        for (int64_t i = ir0; i < ir1; ++i) {\n+            int32_t row_idx = ((const int32_t *)src1->data)[i];\n+            GGML_ASSERT(row_idx >= 0 && row_idx < (int32_t)src0->ne[1]);",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2205045812",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14676,
        "pr_file": "ggml/src/ggml-cpu/kleidiai/kleidiai.cpp",
        "discussion_id": "2205045812",
        "commented_code": "@@ -342,6 +354,45 @@ class tensor_traits : public ggml::cpu::tensor_traits {\n         return true;\n     }\n \n+    bool compute_forward_get_rows(struct ggml_compute_params * params, struct ggml_tensor * dst) {\n+        GGML_ASSERT(ctx.kernels);\n+\n+        const ggml_tensor * src0 = dst->src[0];\n+        const ggml_tensor * src1 = dst->src[1];\n+\n+        GGML_TENSOR_BINARY_OP_LOCALS\n+\n+        rhs_packing_info * rhs_info = &ctx.kernels->rhs_info;\n+        kernel_info * kernel        = &ctx.kernels->gemm;\n+\n+        const int64_t nc     = ne00;\n+        const int64_t nr     = ggml_nelements(src1);\n+\n+        const size_t block_rows = kernel->get_nr();\n+        const size_t kr         = kernel->get_kr();\n+\n+        const size_t num_bytes_multiplier = sizeof(uint16_t);\n+        const size_t packed_stride = rhs_info->packed_stride(nc, block_rows, kr, QK4_0);\n+\n+        const int ith = params->ith;\n+        const int nth = params->nth;\n+\n+        const int dr = (nr + nth - 1) / nth;\n+        const int ir0 = dr * ith;\n+        const int ir1 = MIN(ir0 + dr, nr);\n+\n+        for (int64_t i = ir0; i < ir1; ++i) {\n+            int32_t row_idx = ((const int32_t *)src1->data)[i];\n+            GGML_ASSERT(row_idx >= 0 && row_idx < (int32_t)src0->ne[1]);",
        "comment_created_at": "2025-07-14T14:10:09+00:00",
        "comment_author": "ggerganov",
        "comment_body": "This is slightly more future-proof version:\r\n\r\n```suggestion\r\n            GGML_ASSERT(src1->type == GGML_TYPE_I32);\r\n            int64_t row_idx = ((const int32_t *)src1->data)[i];\r\n            GGML_ASSERT(row_idx >= 0 && row_idx < src0->ne[1]);\r\n```\r\n\r\nAt some point in the future we might consider changing the indices of `ggml_get_rows()` to become I64 so this assert will be helpful.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1279037126",
    "pr_number": 2454,
    "pr_file": "examples/common.cpp",
    "created_at": "2023-07-31T09:28:45+00:00",
    "commented_code": "input.resize(output_idx);\n }\n \n+bool validate_params(const std::string& arg, int argc, int& i, char** argv, const gpt_params& default_params, bool optional = false) {\n+    if (++i >= argc) {\n+        if (optional) {\n+            // Argument is optional and not present, return false\n+            return false;\n+        } else {\n+            fprintf(stderr, \"error: invalid parameter for argument: %s\n\", arg.c_str());\n+            throw std::runtime_error(\"Invalid parameter for argument: \" + arg);\n+        }\n+    }\n+\n+    const std::string& nextArg = argv[i];\n+\n+    if (nextArg.empty() || (nextArg[0] == '-' && !std::isdigit(nextArg[1]))) {",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "1279037126",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 2454,
        "pr_file": "examples/common.cpp",
        "discussion_id": "1279037126",
        "commented_code": "@@ -92,414 +92,315 @@ void process_escapes(std::string& input) {\n     input.resize(output_idx);\n }\n \n+bool validate_params(const std::string& arg, int argc, int& i, char** argv, const gpt_params& default_params, bool optional = false) {\n+    if (++i >= argc) {\n+        if (optional) {\n+            // Argument is optional and not present, return false\n+            return false;\n+        } else {\n+            fprintf(stderr, \"error: invalid parameter for argument: %s\\n\", arg.c_str());\n+            throw std::runtime_error(\"Invalid parameter for argument: \" + arg);\n+        }\n+    }\n+\n+    const std::string& nextArg = argv[i];\n+\n+    if (nextArg.empty() || (nextArg[0] == '-' && !std::isdigit(nextArg[1]))) {",
        "comment_created_at": "2023-07-31T09:28:45+00:00",
        "comment_author": "slaren",
        "comment_body": "There is a possible out of bounds access if `nextArg` is just `\"-\"`.",
        "pr_file_module": null
      },
      {
        "comment_id": "1279155202",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 2454,
        "pr_file": "examples/common.cpp",
        "discussion_id": "1279037126",
        "commented_code": "@@ -92,414 +92,315 @@ void process_escapes(std::string& input) {\n     input.resize(output_idx);\n }\n \n+bool validate_params(const std::string& arg, int argc, int& i, char** argv, const gpt_params& default_params, bool optional = false) {\n+    if (++i >= argc) {\n+        if (optional) {\n+            // Argument is optional and not present, return false\n+            return false;\n+        } else {\n+            fprintf(stderr, \"error: invalid parameter for argument: %s\\n\", arg.c_str());\n+            throw std::runtime_error(\"Invalid parameter for argument: \" + arg);\n+        }\n+    }\n+\n+    const std::string& nextArg = argv[i];\n+\n+    if (nextArg.empty() || (nextArg[0] == '-' && !std::isdigit(nextArg[1]))) {",
        "comment_created_at": "2023-07-31T11:19:07+00:00",
        "comment_author": "maddes8cht",
        "comment_body": "think this fixed it\r\n```\r\nif (nextArg.empty() || (nextArg.size() >= 2 && nextArg[0] == '-' && !std::isdigit(nextArg[1]))) {\r\n```\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2178678982",
    "pr_number": 14285,
    "pr_file": "src/llama-kv-cache-unified.cpp",
    "created_at": "2025-07-01T22:43:20+00:00",
    "commented_code": "}\n     }\n \n+    uint32_t n_found  = 0;\n     uint32_t n_tested = 0;\n \n+    const uint32_t n_test = cont ? n_tokens : 1;\n+\n+    slot_info res;\n+\n+    res.idxs.resize(n_tokens);",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2178678982",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14285,
        "pr_file": "src/llama-kv-cache-unified.cpp",
        "discussion_id": "2178678982",
        "commented_code": "@@ -613,17 +624,25 @@ int32_t llama_kv_cache_unified::find_slot(const llama_ubatch & ubatch) const {\n         }\n     }\n \n+    uint32_t n_found  = 0;\n     uint32_t n_tested = 0;\n \n+    const uint32_t n_test = cont ? n_tokens : 1;\n+\n+    slot_info res;\n+\n+    res.idxs.resize(n_tokens);",
        "comment_created_at": "2025-07-01T22:43:20+00:00",
        "comment_author": "slaren",
        "comment_body": "Replacing this with `reserve` and using `push_back` would remove the possibility of an OOB write.",
        "pr_file_module": null
      }
    ]
  }
]