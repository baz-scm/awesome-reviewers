[
  {
    "discussion_id": "2190458895",
    "pr_number": 14392,
    "pr_file": "scripts/compare-llama-bench.py",
    "created_at": "2025-07-07T15:49:53+00:00",
    "commented_code": "build_len_max: int\n     build_len: int = 8\n     builds: list[str] = []\n-    check_keys = set(KEY_PROPERTIES + [\"build_commit\", \"test_time\", \"avg_ts\"])\n+    tool: str = \"llama-bench\"  # Tool type: \"llama-bench\" or \"test-backend-ops\"\n \n-    def __init__(self):\n+    def __init__(self, tool: str = \"llama-bench\"):\n+        self.tool = tool\n         try:\n             self.repo = git.Repo(\".\", search_parent_directories=True)\n         except git.InvalidGitRepositoryError:\n             self.repo = None\n \n+        # Set schema-specific properties based on tool\n+        if self.tool == \"llama-bench\":\n+            self.check_keys = set(LLAMA_BENCH_KEY_PROPERTIES + [\"build_commit\", \"test_time\", \"avg_ts\"])\n+        else:  # test-backend-ops\n+            self.check_keys = set(TEST_BACKEND_OPS_KEY_PROPERTIES + [\"build_commit\", \"test_time\"])",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2190458895",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14392,
        "pr_file": "scripts/compare-llama-bench.py",
        "discussion_id": "2190458895",
        "commented_code": "@@ -161,14 +233,21 @@ class LlamaBenchData:\n     build_len_max: int\n     build_len: int = 8\n     builds: list[str] = []\n-    check_keys = set(KEY_PROPERTIES + [\"build_commit\", \"test_time\", \"avg_ts\"])\n+    tool: str = \"llama-bench\"  # Tool type: \"llama-bench\" or \"test-backend-ops\"\n \n-    def __init__(self):\n+    def __init__(self, tool: str = \"llama-bench\"):\n+        self.tool = tool\n         try:\n             self.repo = git.Repo(\".\", search_parent_directories=True)\n         except git.InvalidGitRepositoryError:\n             self.repo = None\n \n+        # Set schema-specific properties based on tool\n+        if self.tool == \"llama-bench\":\n+            self.check_keys = set(LLAMA_BENCH_KEY_PROPERTIES + [\"build_commit\", \"test_time\", \"avg_ts\"])\n+        else:  # test-backend-ops\n+            self.check_keys = set(TEST_BACKEND_OPS_KEY_PROPERTIES + [\"build_commit\", \"test_time\"])",
        "comment_created_at": "2025-07-07T15:49:53+00:00",
        "comment_author": "JohannesGaessler",
        "comment_body": "```suggestion\r\n        if self.tool == \"llama-bench\":\r\n            self.check_keys = set(LLAMA_BENCH_KEY_PROPERTIES + [\"build_commit\", \"test_time\", \"avg_ts\"])\r\n        elif self.tool == \"test-backend-ops\":\r\n            self.check_keys = set(TEST_BACKEND_OPS_KEY_PROPERTIES + [\"build_commit\", \"test_time\"])\r\n        else:\r\n            assert False\r\n```\r\n\r\nPreferably assert exact matches in case we ever add more tools.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2190476848",
    "pr_number": 14392,
    "pr_file": "scripts/compare-llama-bench.py",
    "created_at": "2025-07-07T15:57:48+00:00",
    "commented_code": "class LlamaBenchDataSQLite3(LlamaBenchData):\n     connection: sqlite3.Connection\n     cursor: sqlite3.Cursor\n+    table_name: str\n \n-    def __init__(self):\n-        super().__init__()\n+    def __init__(self, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n         self.connection = sqlite3.connect(\":memory:\")\n         self.cursor = self.connection.cursor()\n-        self.cursor.execute(f\"CREATE TABLE test({', '.join(' '.join(x) for x in zip(DB_FIELDS, DB_TYPES))});\")\n+\n+        # Set table name and schema based on tool\n+        if self.tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+            db_fields = LLAMA_BENCH_DB_FIELDS\n+            db_types = LLAMA_BENCH_DB_TYPES\n+        else:  # test-backend-ops\n+            self.table_name = \"test_backend_ops\"\n+            db_fields = TEST_BACKEND_OPS_DB_FIELDS\n+            db_types = TEST_BACKEND_OPS_DB_TYPES\n+\n+        self.cursor.execute(f\"CREATE TABLE {self.table_name}({', '.join(' '.join(x) for x in zip(db_fields, db_types))});\")\n \n     def _builds_init(self):\n         if self.connection:\n-            self.build_len_min = self.cursor.execute(\"SELECT MIN(LENGTH(build_commit)) from test;\").fetchone()[0]\n-            self.build_len_max = self.cursor.execute(\"SELECT MAX(LENGTH(build_commit)) from test;\").fetchone()[0]\n+            self.build_len_min = self.cursor.execute(f\"SELECT MIN(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n+            self.build_len_max = self.cursor.execute(f\"SELECT MAX(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n \n             if self.build_len_min != self.build_len_max:\n                 logger.warning(\"Data contains commit hashes of differing lengths. It's possible that the wrong commits will be compared. \"\n                                \"Try purging the the database of old commits.\")\n-                self.cursor.execute(f\"UPDATE test SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n+                self.cursor.execute(f\"UPDATE {self.table_name} SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n \n-            builds = self.cursor.execute(\"SELECT DISTINCT build_commit FROM test;\").fetchall()\n+            builds = self.cursor.execute(f\"SELECT DISTINCT build_commit FROM {self.table_name};\").fetchall()\n             self.builds = list(map(lambda b: b[0], builds))  # list[tuple[str]] -> list[str]\n         super()._builds_init()\n \n     def builds_timestamp(self, reverse: bool = False) -> Union[Iterator[tuple], Sequence[tuple]]:\n         data = self.cursor.execute(\n-            \"SELECT build_commit, test_time FROM test ORDER BY test_time;\").fetchall()\n+            f\"SELECT build_commit, test_time FROM {self.table_name} ORDER BY test_time;\").fetchall()\n         return reversed(data) if reverse else data\n \n     def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        if self.tool == \"llama-bench\":\n+            return self._get_rows_llama_bench(properties, hexsha8_baseline, hexsha8_compare)\n+        else:  # test-backend-ops\n+            return self._get_rows_test_backend_ops(properties, hexsha8_baseline, hexsha8_compare)\n+\n+    def _get_rows_llama_bench(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n         select_string = \", \".join(\n             [f\"tb.{p}\" for p in properties] + [\"tb.n_prompt\", \"tb.n_gen\", \"tb.n_depth\", \"AVG(tb.avg_ts)\", \"AVG(tc.avg_ts)\"])\n         equal_string = \" AND \".join(\n-            [f\"tb.{p} = tc.{p}\" for p in KEY_PROPERTIES] + [\n+            [f\"tb.{p} = tc.{p}\" for p in LLAMA_BENCH_KEY_PROPERTIES] + [\n                 f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\"]\n         )\n         group_order_string = \", \".join([f\"tb.{p}\" for p in properties] + [\"tb.n_gen\", \"tb.n_prompt\", \"tb.n_depth\"])\n-        query = (f\"SELECT {select_string} FROM test tb JOIN test tc ON {equal_string} \"\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n+                 f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n+        return self.cursor.execute(query).fetchall()\n+\n+    def _get_rows_test_backend_ops(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        # For test-backend-ops, we compare FLOPS and bandwidth metrics (prioritizing FLOPS over bandwidth)\n+        select_string = \", \".join(\n+            [f\"tb.{p}\" for p in properties] + [\n+                \"AVG(tb.flops)\", \"AVG(tc.flops)\",\n+                \"AVG(tb.bandwidth_gb_s)\", \"AVG(tc.bandwidth_gb_s)\"\n+            ])\n+        equal_string = \" AND \".join(\n+            [f\"tb.{p} = tc.{p}\" for p in TEST_BACKEND_OPS_KEY_PROPERTIES] + [\n+                f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\",\n+                \"tb.supported = 1\", \"tc.supported = 1\", \"tb.passed = 1\", \"tc.passed = 1\"]  # Only compare successful tests\n+        )\n+        group_order_string = \", \".join([f\"tb.{p}\" for p in properties])\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n                  f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n         return self.cursor.execute(query).fetchall()\n \n \n class LlamaBenchDataSQLite3File(LlamaBenchDataSQLite3):\n-    def __init__(self, data_file: str):\n-        super().__init__()\n+    def __init__(self, data_file: str, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n \n         self.connection.close()\n         self.connection = sqlite3.connect(data_file)\n         self.cursor = self.connection.cursor()\n+\n+        # Check which table exists in the database\n+        tables = self.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n+        table_names = [table[0] for table in tables]\n+\n+        if \"test_backend_ops\" in table_names and tool == \"test-backend-ops\":\n+            self.table_name = \"test_backend_ops\"\n+        elif \"test\" in table_names and tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+        elif \"test\" in table_names:\n+            # Fallback to test table for backward compatibility\n+            self.table_name = \"test\"\n+            if tool == \"test-backend-ops\":\n+                logger.warning(\"test-backend-ops tool specified but only 'test' table found. Assuming llama-bench data.\")\n+                self.tool = \"llama-bench\"",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2190476848",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14392,
        "pr_file": "scripts/compare-llama-bench.py",
        "discussion_id": "2190476848",
        "commented_code": "@@ -252,52 +331,105 @@ def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare\n class LlamaBenchDataSQLite3(LlamaBenchData):\n     connection: sqlite3.Connection\n     cursor: sqlite3.Cursor\n+    table_name: str\n \n-    def __init__(self):\n-        super().__init__()\n+    def __init__(self, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n         self.connection = sqlite3.connect(\":memory:\")\n         self.cursor = self.connection.cursor()\n-        self.cursor.execute(f\"CREATE TABLE test({', '.join(' '.join(x) for x in zip(DB_FIELDS, DB_TYPES))});\")\n+\n+        # Set table name and schema based on tool\n+        if self.tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+            db_fields = LLAMA_BENCH_DB_FIELDS\n+            db_types = LLAMA_BENCH_DB_TYPES\n+        else:  # test-backend-ops\n+            self.table_name = \"test_backend_ops\"\n+            db_fields = TEST_BACKEND_OPS_DB_FIELDS\n+            db_types = TEST_BACKEND_OPS_DB_TYPES\n+\n+        self.cursor.execute(f\"CREATE TABLE {self.table_name}({', '.join(' '.join(x) for x in zip(db_fields, db_types))});\")\n \n     def _builds_init(self):\n         if self.connection:\n-            self.build_len_min = self.cursor.execute(\"SELECT MIN(LENGTH(build_commit)) from test;\").fetchone()[0]\n-            self.build_len_max = self.cursor.execute(\"SELECT MAX(LENGTH(build_commit)) from test;\").fetchone()[0]\n+            self.build_len_min = self.cursor.execute(f\"SELECT MIN(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n+            self.build_len_max = self.cursor.execute(f\"SELECT MAX(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n \n             if self.build_len_min != self.build_len_max:\n                 logger.warning(\"Data contains commit hashes of differing lengths. It's possible that the wrong commits will be compared. \"\n                                \"Try purging the the database of old commits.\")\n-                self.cursor.execute(f\"UPDATE test SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n+                self.cursor.execute(f\"UPDATE {self.table_name} SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n \n-            builds = self.cursor.execute(\"SELECT DISTINCT build_commit FROM test;\").fetchall()\n+            builds = self.cursor.execute(f\"SELECT DISTINCT build_commit FROM {self.table_name};\").fetchall()\n             self.builds = list(map(lambda b: b[0], builds))  # list[tuple[str]] -> list[str]\n         super()._builds_init()\n \n     def builds_timestamp(self, reverse: bool = False) -> Union[Iterator[tuple], Sequence[tuple]]:\n         data = self.cursor.execute(\n-            \"SELECT build_commit, test_time FROM test ORDER BY test_time;\").fetchall()\n+            f\"SELECT build_commit, test_time FROM {self.table_name} ORDER BY test_time;\").fetchall()\n         return reversed(data) if reverse else data\n \n     def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        if self.tool == \"llama-bench\":\n+            return self._get_rows_llama_bench(properties, hexsha8_baseline, hexsha8_compare)\n+        else:  # test-backend-ops\n+            return self._get_rows_test_backend_ops(properties, hexsha8_baseline, hexsha8_compare)\n+\n+    def _get_rows_llama_bench(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n         select_string = \", \".join(\n             [f\"tb.{p}\" for p in properties] + [\"tb.n_prompt\", \"tb.n_gen\", \"tb.n_depth\", \"AVG(tb.avg_ts)\", \"AVG(tc.avg_ts)\"])\n         equal_string = \" AND \".join(\n-            [f\"tb.{p} = tc.{p}\" for p in KEY_PROPERTIES] + [\n+            [f\"tb.{p} = tc.{p}\" for p in LLAMA_BENCH_KEY_PROPERTIES] + [\n                 f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\"]\n         )\n         group_order_string = \", \".join([f\"tb.{p}\" for p in properties] + [\"tb.n_gen\", \"tb.n_prompt\", \"tb.n_depth\"])\n-        query = (f\"SELECT {select_string} FROM test tb JOIN test tc ON {equal_string} \"\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n+                 f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n+        return self.cursor.execute(query).fetchall()\n+\n+    def _get_rows_test_backend_ops(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        # For test-backend-ops, we compare FLOPS and bandwidth metrics (prioritizing FLOPS over bandwidth)\n+        select_string = \", \".join(\n+            [f\"tb.{p}\" for p in properties] + [\n+                \"AVG(tb.flops)\", \"AVG(tc.flops)\",\n+                \"AVG(tb.bandwidth_gb_s)\", \"AVG(tc.bandwidth_gb_s)\"\n+            ])\n+        equal_string = \" AND \".join(\n+            [f\"tb.{p} = tc.{p}\" for p in TEST_BACKEND_OPS_KEY_PROPERTIES] + [\n+                f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\",\n+                \"tb.supported = 1\", \"tc.supported = 1\", \"tb.passed = 1\", \"tc.passed = 1\"]  # Only compare successful tests\n+        )\n+        group_order_string = \", \".join([f\"tb.{p}\" for p in properties])\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n                  f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n         return self.cursor.execute(query).fetchall()\n \n \n class LlamaBenchDataSQLite3File(LlamaBenchDataSQLite3):\n-    def __init__(self, data_file: str):\n-        super().__init__()\n+    def __init__(self, data_file: str, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n \n         self.connection.close()\n         self.connection = sqlite3.connect(data_file)\n         self.cursor = self.connection.cursor()\n+\n+        # Check which table exists in the database\n+        tables = self.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n+        table_names = [table[0] for table in tables]\n+\n+        if \"test_backend_ops\" in table_names and tool == \"test-backend-ops\":\n+            self.table_name = \"test_backend_ops\"\n+        elif \"test\" in table_names and tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+        elif \"test\" in table_names:\n+            # Fallback to test table for backward compatibility\n+            self.table_name = \"test\"\n+            if tool == \"test-backend-ops\":\n+                logger.warning(\"test-backend-ops tool specified but only 'test' table found. Assuming llama-bench data.\")\n+                self.tool = \"llama-bench\"",
        "comment_created_at": "2025-07-07T15:57:48+00:00",
        "comment_author": "JohannesGaessler",
        "comment_body": "I would suggest setting the `--tool` CLI argument to `None` by default. If it is `None` here, use either table if it exists.",
        "pr_file_module": null
      },
      {
        "comment_id": "2191326601",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14392,
        "pr_file": "scripts/compare-llama-bench.py",
        "discussion_id": "2190476848",
        "commented_code": "@@ -252,52 +331,105 @@ def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare\n class LlamaBenchDataSQLite3(LlamaBenchData):\n     connection: sqlite3.Connection\n     cursor: sqlite3.Cursor\n+    table_name: str\n \n-    def __init__(self):\n-        super().__init__()\n+    def __init__(self, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n         self.connection = sqlite3.connect(\":memory:\")\n         self.cursor = self.connection.cursor()\n-        self.cursor.execute(f\"CREATE TABLE test({', '.join(' '.join(x) for x in zip(DB_FIELDS, DB_TYPES))});\")\n+\n+        # Set table name and schema based on tool\n+        if self.tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+            db_fields = LLAMA_BENCH_DB_FIELDS\n+            db_types = LLAMA_BENCH_DB_TYPES\n+        else:  # test-backend-ops\n+            self.table_name = \"test_backend_ops\"\n+            db_fields = TEST_BACKEND_OPS_DB_FIELDS\n+            db_types = TEST_BACKEND_OPS_DB_TYPES\n+\n+        self.cursor.execute(f\"CREATE TABLE {self.table_name}({', '.join(' '.join(x) for x in zip(db_fields, db_types))});\")\n \n     def _builds_init(self):\n         if self.connection:\n-            self.build_len_min = self.cursor.execute(\"SELECT MIN(LENGTH(build_commit)) from test;\").fetchone()[0]\n-            self.build_len_max = self.cursor.execute(\"SELECT MAX(LENGTH(build_commit)) from test;\").fetchone()[0]\n+            self.build_len_min = self.cursor.execute(f\"SELECT MIN(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n+            self.build_len_max = self.cursor.execute(f\"SELECT MAX(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n \n             if self.build_len_min != self.build_len_max:\n                 logger.warning(\"Data contains commit hashes of differing lengths. It's possible that the wrong commits will be compared. \"\n                                \"Try purging the the database of old commits.\")\n-                self.cursor.execute(f\"UPDATE test SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n+                self.cursor.execute(f\"UPDATE {self.table_name} SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n \n-            builds = self.cursor.execute(\"SELECT DISTINCT build_commit FROM test;\").fetchall()\n+            builds = self.cursor.execute(f\"SELECT DISTINCT build_commit FROM {self.table_name};\").fetchall()\n             self.builds = list(map(lambda b: b[0], builds))  # list[tuple[str]] -> list[str]\n         super()._builds_init()\n \n     def builds_timestamp(self, reverse: bool = False) -> Union[Iterator[tuple], Sequence[tuple]]:\n         data = self.cursor.execute(\n-            \"SELECT build_commit, test_time FROM test ORDER BY test_time;\").fetchall()\n+            f\"SELECT build_commit, test_time FROM {self.table_name} ORDER BY test_time;\").fetchall()\n         return reversed(data) if reverse else data\n \n     def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        if self.tool == \"llama-bench\":\n+            return self._get_rows_llama_bench(properties, hexsha8_baseline, hexsha8_compare)\n+        else:  # test-backend-ops\n+            return self._get_rows_test_backend_ops(properties, hexsha8_baseline, hexsha8_compare)\n+\n+    def _get_rows_llama_bench(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n         select_string = \", \".join(\n             [f\"tb.{p}\" for p in properties] + [\"tb.n_prompt\", \"tb.n_gen\", \"tb.n_depth\", \"AVG(tb.avg_ts)\", \"AVG(tc.avg_ts)\"])\n         equal_string = \" AND \".join(\n-            [f\"tb.{p} = tc.{p}\" for p in KEY_PROPERTIES] + [\n+            [f\"tb.{p} = tc.{p}\" for p in LLAMA_BENCH_KEY_PROPERTIES] + [\n                 f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\"]\n         )\n         group_order_string = \", \".join([f\"tb.{p}\" for p in properties] + [\"tb.n_gen\", \"tb.n_prompt\", \"tb.n_depth\"])\n-        query = (f\"SELECT {select_string} FROM test tb JOIN test tc ON {equal_string} \"\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n+                 f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n+        return self.cursor.execute(query).fetchall()\n+\n+    def _get_rows_test_backend_ops(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        # For test-backend-ops, we compare FLOPS and bandwidth metrics (prioritizing FLOPS over bandwidth)\n+        select_string = \", \".join(\n+            [f\"tb.{p}\" for p in properties] + [\n+                \"AVG(tb.flops)\", \"AVG(tc.flops)\",\n+                \"AVG(tb.bandwidth_gb_s)\", \"AVG(tc.bandwidth_gb_s)\"\n+            ])\n+        equal_string = \" AND \".join(\n+            [f\"tb.{p} = tc.{p}\" for p in TEST_BACKEND_OPS_KEY_PROPERTIES] + [\n+                f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\",\n+                \"tb.supported = 1\", \"tc.supported = 1\", \"tb.passed = 1\", \"tc.passed = 1\"]  # Only compare successful tests\n+        )\n+        group_order_string = \", \".join([f\"tb.{p}\" for p in properties])\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n                  f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n         return self.cursor.execute(query).fetchall()\n \n \n class LlamaBenchDataSQLite3File(LlamaBenchDataSQLite3):\n-    def __init__(self, data_file: str):\n-        super().__init__()\n+    def __init__(self, data_file: str, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n \n         self.connection.close()\n         self.connection = sqlite3.connect(data_file)\n         self.cursor = self.connection.cursor()\n+\n+        # Check which table exists in the database\n+        tables = self.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n+        table_names = [table[0] for table in tables]\n+\n+        if \"test_backend_ops\" in table_names and tool == \"test-backend-ops\":\n+            self.table_name = \"test_backend_ops\"\n+        elif \"test\" in table_names and tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+        elif \"test\" in table_names:\n+            # Fallback to test table for backward compatibility\n+            self.table_name = \"test\"\n+            if tool == \"test-backend-ops\":\n+                logger.warning(\"test-backend-ops tool specified but only 'test' table found. Assuming llama-bench data.\")\n+                self.tool = \"llama-bench\"",
        "comment_created_at": "2025-07-08T02:03:47+00:00",
        "comment_author": "yeahdongcn",
        "comment_body": "The code may look a bit more complex here, but that\u2019s intentional to maintain a smooth user experience.",
        "pr_file_module": null
      },
      {
        "comment_id": "2192463732",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14392,
        "pr_file": "scripts/compare-llama-bench.py",
        "discussion_id": "2190476848",
        "commented_code": "@@ -252,52 +331,105 @@ def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare\n class LlamaBenchDataSQLite3(LlamaBenchData):\n     connection: sqlite3.Connection\n     cursor: sqlite3.Cursor\n+    table_name: str\n \n-    def __init__(self):\n-        super().__init__()\n+    def __init__(self, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n         self.connection = sqlite3.connect(\":memory:\")\n         self.cursor = self.connection.cursor()\n-        self.cursor.execute(f\"CREATE TABLE test({', '.join(' '.join(x) for x in zip(DB_FIELDS, DB_TYPES))});\")\n+\n+        # Set table name and schema based on tool\n+        if self.tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+            db_fields = LLAMA_BENCH_DB_FIELDS\n+            db_types = LLAMA_BENCH_DB_TYPES\n+        else:  # test-backend-ops\n+            self.table_name = \"test_backend_ops\"\n+            db_fields = TEST_BACKEND_OPS_DB_FIELDS\n+            db_types = TEST_BACKEND_OPS_DB_TYPES\n+\n+        self.cursor.execute(f\"CREATE TABLE {self.table_name}({', '.join(' '.join(x) for x in zip(db_fields, db_types))});\")\n \n     def _builds_init(self):\n         if self.connection:\n-            self.build_len_min = self.cursor.execute(\"SELECT MIN(LENGTH(build_commit)) from test;\").fetchone()[0]\n-            self.build_len_max = self.cursor.execute(\"SELECT MAX(LENGTH(build_commit)) from test;\").fetchone()[0]\n+            self.build_len_min = self.cursor.execute(f\"SELECT MIN(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n+            self.build_len_max = self.cursor.execute(f\"SELECT MAX(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n \n             if self.build_len_min != self.build_len_max:\n                 logger.warning(\"Data contains commit hashes of differing lengths. It's possible that the wrong commits will be compared. \"\n                                \"Try purging the the database of old commits.\")\n-                self.cursor.execute(f\"UPDATE test SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n+                self.cursor.execute(f\"UPDATE {self.table_name} SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n \n-            builds = self.cursor.execute(\"SELECT DISTINCT build_commit FROM test;\").fetchall()\n+            builds = self.cursor.execute(f\"SELECT DISTINCT build_commit FROM {self.table_name};\").fetchall()\n             self.builds = list(map(lambda b: b[0], builds))  # list[tuple[str]] -> list[str]\n         super()._builds_init()\n \n     def builds_timestamp(self, reverse: bool = False) -> Union[Iterator[tuple], Sequence[tuple]]:\n         data = self.cursor.execute(\n-            \"SELECT build_commit, test_time FROM test ORDER BY test_time;\").fetchall()\n+            f\"SELECT build_commit, test_time FROM {self.table_name} ORDER BY test_time;\").fetchall()\n         return reversed(data) if reverse else data\n \n     def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        if self.tool == \"llama-bench\":\n+            return self._get_rows_llama_bench(properties, hexsha8_baseline, hexsha8_compare)\n+        else:  # test-backend-ops\n+            return self._get_rows_test_backend_ops(properties, hexsha8_baseline, hexsha8_compare)\n+\n+    def _get_rows_llama_bench(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n         select_string = \", \".join(\n             [f\"tb.{p}\" for p in properties] + [\"tb.n_prompt\", \"tb.n_gen\", \"tb.n_depth\", \"AVG(tb.avg_ts)\", \"AVG(tc.avg_ts)\"])\n         equal_string = \" AND \".join(\n-            [f\"tb.{p} = tc.{p}\" for p in KEY_PROPERTIES] + [\n+            [f\"tb.{p} = tc.{p}\" for p in LLAMA_BENCH_KEY_PROPERTIES] + [\n                 f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\"]\n         )\n         group_order_string = \", \".join([f\"tb.{p}\" for p in properties] + [\"tb.n_gen\", \"tb.n_prompt\", \"tb.n_depth\"])\n-        query = (f\"SELECT {select_string} FROM test tb JOIN test tc ON {equal_string} \"\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n+                 f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n+        return self.cursor.execute(query).fetchall()\n+\n+    def _get_rows_test_backend_ops(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        # For test-backend-ops, we compare FLOPS and bandwidth metrics (prioritizing FLOPS over bandwidth)\n+        select_string = \", \".join(\n+            [f\"tb.{p}\" for p in properties] + [\n+                \"AVG(tb.flops)\", \"AVG(tc.flops)\",\n+                \"AVG(tb.bandwidth_gb_s)\", \"AVG(tc.bandwidth_gb_s)\"\n+            ])\n+        equal_string = \" AND \".join(\n+            [f\"tb.{p} = tc.{p}\" for p in TEST_BACKEND_OPS_KEY_PROPERTIES] + [\n+                f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\",\n+                \"tb.supported = 1\", \"tc.supported = 1\", \"tb.passed = 1\", \"tc.passed = 1\"]  # Only compare successful tests\n+        )\n+        group_order_string = \", \".join([f\"tb.{p}\" for p in properties])\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n                  f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n         return self.cursor.execute(query).fetchall()\n \n \n class LlamaBenchDataSQLite3File(LlamaBenchDataSQLite3):\n-    def __init__(self, data_file: str):\n-        super().__init__()\n+    def __init__(self, data_file: str, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n \n         self.connection.close()\n         self.connection = sqlite3.connect(data_file)\n         self.cursor = self.connection.cursor()\n+\n+        # Check which table exists in the database\n+        tables = self.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n+        table_names = [table[0] for table in tables]\n+\n+        if \"test_backend_ops\" in table_names and tool == \"test-backend-ops\":\n+            self.table_name = \"test_backend_ops\"\n+        elif \"test\" in table_names and tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+        elif \"test\" in table_names:\n+            # Fallback to test table for backward compatibility\n+            self.table_name = \"test\"\n+            if tool == \"test-backend-ops\":\n+                logger.warning(\"test-backend-ops tool specified but only 'test' table found. Assuming llama-bench data.\")\n+                self.tool = \"llama-bench\"",
        "comment_created_at": "2025-07-08T13:01:11+00:00",
        "comment_author": "JohannesGaessler",
        "comment_body": "I don't understand what you mean by that.",
        "pr_file_module": null
      },
      {
        "comment_id": "2192495039",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14392,
        "pr_file": "scripts/compare-llama-bench.py",
        "discussion_id": "2190476848",
        "commented_code": "@@ -252,52 +331,105 @@ def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare\n class LlamaBenchDataSQLite3(LlamaBenchData):\n     connection: sqlite3.Connection\n     cursor: sqlite3.Cursor\n+    table_name: str\n \n-    def __init__(self):\n-        super().__init__()\n+    def __init__(self, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n         self.connection = sqlite3.connect(\":memory:\")\n         self.cursor = self.connection.cursor()\n-        self.cursor.execute(f\"CREATE TABLE test({', '.join(' '.join(x) for x in zip(DB_FIELDS, DB_TYPES))});\")\n+\n+        # Set table name and schema based on tool\n+        if self.tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+            db_fields = LLAMA_BENCH_DB_FIELDS\n+            db_types = LLAMA_BENCH_DB_TYPES\n+        else:  # test-backend-ops\n+            self.table_name = \"test_backend_ops\"\n+            db_fields = TEST_BACKEND_OPS_DB_FIELDS\n+            db_types = TEST_BACKEND_OPS_DB_TYPES\n+\n+        self.cursor.execute(f\"CREATE TABLE {self.table_name}({', '.join(' '.join(x) for x in zip(db_fields, db_types))});\")\n \n     def _builds_init(self):\n         if self.connection:\n-            self.build_len_min = self.cursor.execute(\"SELECT MIN(LENGTH(build_commit)) from test;\").fetchone()[0]\n-            self.build_len_max = self.cursor.execute(\"SELECT MAX(LENGTH(build_commit)) from test;\").fetchone()[0]\n+            self.build_len_min = self.cursor.execute(f\"SELECT MIN(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n+            self.build_len_max = self.cursor.execute(f\"SELECT MAX(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n \n             if self.build_len_min != self.build_len_max:\n                 logger.warning(\"Data contains commit hashes of differing lengths. It's possible that the wrong commits will be compared. \"\n                                \"Try purging the the database of old commits.\")\n-                self.cursor.execute(f\"UPDATE test SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n+                self.cursor.execute(f\"UPDATE {self.table_name} SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n \n-            builds = self.cursor.execute(\"SELECT DISTINCT build_commit FROM test;\").fetchall()\n+            builds = self.cursor.execute(f\"SELECT DISTINCT build_commit FROM {self.table_name};\").fetchall()\n             self.builds = list(map(lambda b: b[0], builds))  # list[tuple[str]] -> list[str]\n         super()._builds_init()\n \n     def builds_timestamp(self, reverse: bool = False) -> Union[Iterator[tuple], Sequence[tuple]]:\n         data = self.cursor.execute(\n-            \"SELECT build_commit, test_time FROM test ORDER BY test_time;\").fetchall()\n+            f\"SELECT build_commit, test_time FROM {self.table_name} ORDER BY test_time;\").fetchall()\n         return reversed(data) if reverse else data\n \n     def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        if self.tool == \"llama-bench\":\n+            return self._get_rows_llama_bench(properties, hexsha8_baseline, hexsha8_compare)\n+        else:  # test-backend-ops\n+            return self._get_rows_test_backend_ops(properties, hexsha8_baseline, hexsha8_compare)\n+\n+    def _get_rows_llama_bench(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n         select_string = \", \".join(\n             [f\"tb.{p}\" for p in properties] + [\"tb.n_prompt\", \"tb.n_gen\", \"tb.n_depth\", \"AVG(tb.avg_ts)\", \"AVG(tc.avg_ts)\"])\n         equal_string = \" AND \".join(\n-            [f\"tb.{p} = tc.{p}\" for p in KEY_PROPERTIES] + [\n+            [f\"tb.{p} = tc.{p}\" for p in LLAMA_BENCH_KEY_PROPERTIES] + [\n                 f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\"]\n         )\n         group_order_string = \", \".join([f\"tb.{p}\" for p in properties] + [\"tb.n_gen\", \"tb.n_prompt\", \"tb.n_depth\"])\n-        query = (f\"SELECT {select_string} FROM test tb JOIN test tc ON {equal_string} \"\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n+                 f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n+        return self.cursor.execute(query).fetchall()\n+\n+    def _get_rows_test_backend_ops(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        # For test-backend-ops, we compare FLOPS and bandwidth metrics (prioritizing FLOPS over bandwidth)\n+        select_string = \", \".join(\n+            [f\"tb.{p}\" for p in properties] + [\n+                \"AVG(tb.flops)\", \"AVG(tc.flops)\",\n+                \"AVG(tb.bandwidth_gb_s)\", \"AVG(tc.bandwidth_gb_s)\"\n+            ])\n+        equal_string = \" AND \".join(\n+            [f\"tb.{p} = tc.{p}\" for p in TEST_BACKEND_OPS_KEY_PROPERTIES] + [\n+                f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\",\n+                \"tb.supported = 1\", \"tc.supported = 1\", \"tb.passed = 1\", \"tc.passed = 1\"]  # Only compare successful tests\n+        )\n+        group_order_string = \", \".join([f\"tb.{p}\" for p in properties])\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n                  f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n         return self.cursor.execute(query).fetchall()\n \n \n class LlamaBenchDataSQLite3File(LlamaBenchDataSQLite3):\n-    def __init__(self, data_file: str):\n-        super().__init__()\n+    def __init__(self, data_file: str, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n \n         self.connection.close()\n         self.connection = sqlite3.connect(data_file)\n         self.cursor = self.connection.cursor()\n+\n+        # Check which table exists in the database\n+        tables = self.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n+        table_names = [table[0] for table in tables]\n+\n+        if \"test_backend_ops\" in table_names and tool == \"test-backend-ops\":\n+            self.table_name = \"test_backend_ops\"\n+        elif \"test\" in table_names and tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+        elif \"test\" in table_names:\n+            # Fallback to test table for backward compatibility\n+            self.table_name = \"test\"\n+            if tool == \"test-backend-ops\":\n+                logger.warning(\"test-backend-ops tool specified but only 'test' table found. Assuming llama-bench data.\")\n+                self.tool = \"llama-bench\"",
        "comment_created_at": "2025-07-08T13:13:12+00:00",
        "comment_author": "yeahdongcn",
        "comment_body": "I mean there might be users who run `compare-llama-bench.py` directly, so this helps preserve the existing behavior for them. But if that\u2019s not a concern, I\u2019m happy to update it as suggested.",
        "pr_file_module": null
      },
      {
        "comment_id": "2192533494",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14392,
        "pr_file": "scripts/compare-llama-bench.py",
        "discussion_id": "2190476848",
        "commented_code": "@@ -252,52 +331,105 @@ def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare\n class LlamaBenchDataSQLite3(LlamaBenchData):\n     connection: sqlite3.Connection\n     cursor: sqlite3.Cursor\n+    table_name: str\n \n-    def __init__(self):\n-        super().__init__()\n+    def __init__(self, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n         self.connection = sqlite3.connect(\":memory:\")\n         self.cursor = self.connection.cursor()\n-        self.cursor.execute(f\"CREATE TABLE test({', '.join(' '.join(x) for x in zip(DB_FIELDS, DB_TYPES))});\")\n+\n+        # Set table name and schema based on tool\n+        if self.tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+            db_fields = LLAMA_BENCH_DB_FIELDS\n+            db_types = LLAMA_BENCH_DB_TYPES\n+        else:  # test-backend-ops\n+            self.table_name = \"test_backend_ops\"\n+            db_fields = TEST_BACKEND_OPS_DB_FIELDS\n+            db_types = TEST_BACKEND_OPS_DB_TYPES\n+\n+        self.cursor.execute(f\"CREATE TABLE {self.table_name}({', '.join(' '.join(x) for x in zip(db_fields, db_types))});\")\n \n     def _builds_init(self):\n         if self.connection:\n-            self.build_len_min = self.cursor.execute(\"SELECT MIN(LENGTH(build_commit)) from test;\").fetchone()[0]\n-            self.build_len_max = self.cursor.execute(\"SELECT MAX(LENGTH(build_commit)) from test;\").fetchone()[0]\n+            self.build_len_min = self.cursor.execute(f\"SELECT MIN(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n+            self.build_len_max = self.cursor.execute(f\"SELECT MAX(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n \n             if self.build_len_min != self.build_len_max:\n                 logger.warning(\"Data contains commit hashes of differing lengths. It's possible that the wrong commits will be compared. \"\n                                \"Try purging the the database of old commits.\")\n-                self.cursor.execute(f\"UPDATE test SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n+                self.cursor.execute(f\"UPDATE {self.table_name} SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n \n-            builds = self.cursor.execute(\"SELECT DISTINCT build_commit FROM test;\").fetchall()\n+            builds = self.cursor.execute(f\"SELECT DISTINCT build_commit FROM {self.table_name};\").fetchall()\n             self.builds = list(map(lambda b: b[0], builds))  # list[tuple[str]] -> list[str]\n         super()._builds_init()\n \n     def builds_timestamp(self, reverse: bool = False) -> Union[Iterator[tuple], Sequence[tuple]]:\n         data = self.cursor.execute(\n-            \"SELECT build_commit, test_time FROM test ORDER BY test_time;\").fetchall()\n+            f\"SELECT build_commit, test_time FROM {self.table_name} ORDER BY test_time;\").fetchall()\n         return reversed(data) if reverse else data\n \n     def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        if self.tool == \"llama-bench\":\n+            return self._get_rows_llama_bench(properties, hexsha8_baseline, hexsha8_compare)\n+        else:  # test-backend-ops\n+            return self._get_rows_test_backend_ops(properties, hexsha8_baseline, hexsha8_compare)\n+\n+    def _get_rows_llama_bench(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n         select_string = \", \".join(\n             [f\"tb.{p}\" for p in properties] + [\"tb.n_prompt\", \"tb.n_gen\", \"tb.n_depth\", \"AVG(tb.avg_ts)\", \"AVG(tc.avg_ts)\"])\n         equal_string = \" AND \".join(\n-            [f\"tb.{p} = tc.{p}\" for p in KEY_PROPERTIES] + [\n+            [f\"tb.{p} = tc.{p}\" for p in LLAMA_BENCH_KEY_PROPERTIES] + [\n                 f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\"]\n         )\n         group_order_string = \", \".join([f\"tb.{p}\" for p in properties] + [\"tb.n_gen\", \"tb.n_prompt\", \"tb.n_depth\"])\n-        query = (f\"SELECT {select_string} FROM test tb JOIN test tc ON {equal_string} \"\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n+                 f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n+        return self.cursor.execute(query).fetchall()\n+\n+    def _get_rows_test_backend_ops(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        # For test-backend-ops, we compare FLOPS and bandwidth metrics (prioritizing FLOPS over bandwidth)\n+        select_string = \", \".join(\n+            [f\"tb.{p}\" for p in properties] + [\n+                \"AVG(tb.flops)\", \"AVG(tc.flops)\",\n+                \"AVG(tb.bandwidth_gb_s)\", \"AVG(tc.bandwidth_gb_s)\"\n+            ])\n+        equal_string = \" AND \".join(\n+            [f\"tb.{p} = tc.{p}\" for p in TEST_BACKEND_OPS_KEY_PROPERTIES] + [\n+                f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\",\n+                \"tb.supported = 1\", \"tc.supported = 1\", \"tb.passed = 1\", \"tc.passed = 1\"]  # Only compare successful tests\n+        )\n+        group_order_string = \", \".join([f\"tb.{p}\" for p in properties])\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n                  f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n         return self.cursor.execute(query).fetchall()\n \n \n class LlamaBenchDataSQLite3File(LlamaBenchDataSQLite3):\n-    def __init__(self, data_file: str):\n-        super().__init__()\n+    def __init__(self, data_file: str, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n \n         self.connection.close()\n         self.connection = sqlite3.connect(data_file)\n         self.cursor = self.connection.cursor()\n+\n+        # Check which table exists in the database\n+        tables = self.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n+        table_names = [table[0] for table in tables]\n+\n+        if \"test_backend_ops\" in table_names and tool == \"test-backend-ops\":\n+            self.table_name = \"test_backend_ops\"\n+        elif \"test\" in table_names and tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+        elif \"test\" in table_names:\n+            # Fallback to test table for backward compatibility\n+            self.table_name = \"test\"\n+            if tool == \"test-backend-ops\":\n+                logger.warning(\"test-backend-ops tool specified but only 'test' table found. Assuming llama-bench data.\")\n+                self.tool = \"llama-bench\"",
        "comment_created_at": "2025-07-08T13:26:53+00:00",
        "comment_author": "JohannesGaessler",
        "comment_body": "It should be the same behavior by default. The default value for `--tool` is `None`. If pointed at an SQLite file with a table produced by `llama-bench`, check for the existence of table `test` and use it if it exists. Otherwise use table `test_backend_ops` if it exists. If the user explicitly specifies `--tool`, try to use the corresponding table, raise an error if it doesn't exist.",
        "pr_file_module": null
      },
      {
        "comment_id": "2192541234",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14392,
        "pr_file": "scripts/compare-llama-bench.py",
        "discussion_id": "2190476848",
        "commented_code": "@@ -252,52 +331,105 @@ def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare\n class LlamaBenchDataSQLite3(LlamaBenchData):\n     connection: sqlite3.Connection\n     cursor: sqlite3.Cursor\n+    table_name: str\n \n-    def __init__(self):\n-        super().__init__()\n+    def __init__(self, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n         self.connection = sqlite3.connect(\":memory:\")\n         self.cursor = self.connection.cursor()\n-        self.cursor.execute(f\"CREATE TABLE test({', '.join(' '.join(x) for x in zip(DB_FIELDS, DB_TYPES))});\")\n+\n+        # Set table name and schema based on tool\n+        if self.tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+            db_fields = LLAMA_BENCH_DB_FIELDS\n+            db_types = LLAMA_BENCH_DB_TYPES\n+        else:  # test-backend-ops\n+            self.table_name = \"test_backend_ops\"\n+            db_fields = TEST_BACKEND_OPS_DB_FIELDS\n+            db_types = TEST_BACKEND_OPS_DB_TYPES\n+\n+        self.cursor.execute(f\"CREATE TABLE {self.table_name}({', '.join(' '.join(x) for x in zip(db_fields, db_types))});\")\n \n     def _builds_init(self):\n         if self.connection:\n-            self.build_len_min = self.cursor.execute(\"SELECT MIN(LENGTH(build_commit)) from test;\").fetchone()[0]\n-            self.build_len_max = self.cursor.execute(\"SELECT MAX(LENGTH(build_commit)) from test;\").fetchone()[0]\n+            self.build_len_min = self.cursor.execute(f\"SELECT MIN(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n+            self.build_len_max = self.cursor.execute(f\"SELECT MAX(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n \n             if self.build_len_min != self.build_len_max:\n                 logger.warning(\"Data contains commit hashes of differing lengths. It's possible that the wrong commits will be compared. \"\n                                \"Try purging the the database of old commits.\")\n-                self.cursor.execute(f\"UPDATE test SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n+                self.cursor.execute(f\"UPDATE {self.table_name} SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n \n-            builds = self.cursor.execute(\"SELECT DISTINCT build_commit FROM test;\").fetchall()\n+            builds = self.cursor.execute(f\"SELECT DISTINCT build_commit FROM {self.table_name};\").fetchall()\n             self.builds = list(map(lambda b: b[0], builds))  # list[tuple[str]] -> list[str]\n         super()._builds_init()\n \n     def builds_timestamp(self, reverse: bool = False) -> Union[Iterator[tuple], Sequence[tuple]]:\n         data = self.cursor.execute(\n-            \"SELECT build_commit, test_time FROM test ORDER BY test_time;\").fetchall()\n+            f\"SELECT build_commit, test_time FROM {self.table_name} ORDER BY test_time;\").fetchall()\n         return reversed(data) if reverse else data\n \n     def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        if self.tool == \"llama-bench\":\n+            return self._get_rows_llama_bench(properties, hexsha8_baseline, hexsha8_compare)\n+        else:  # test-backend-ops\n+            return self._get_rows_test_backend_ops(properties, hexsha8_baseline, hexsha8_compare)\n+\n+    def _get_rows_llama_bench(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n         select_string = \", \".join(\n             [f\"tb.{p}\" for p in properties] + [\"tb.n_prompt\", \"tb.n_gen\", \"tb.n_depth\", \"AVG(tb.avg_ts)\", \"AVG(tc.avg_ts)\"])\n         equal_string = \" AND \".join(\n-            [f\"tb.{p} = tc.{p}\" for p in KEY_PROPERTIES] + [\n+            [f\"tb.{p} = tc.{p}\" for p in LLAMA_BENCH_KEY_PROPERTIES] + [\n                 f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\"]\n         )\n         group_order_string = \", \".join([f\"tb.{p}\" for p in properties] + [\"tb.n_gen\", \"tb.n_prompt\", \"tb.n_depth\"])\n-        query = (f\"SELECT {select_string} FROM test tb JOIN test tc ON {equal_string} \"\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n+                 f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n+        return self.cursor.execute(query).fetchall()\n+\n+    def _get_rows_test_backend_ops(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        # For test-backend-ops, we compare FLOPS and bandwidth metrics (prioritizing FLOPS over bandwidth)\n+        select_string = \", \".join(\n+            [f\"tb.{p}\" for p in properties] + [\n+                \"AVG(tb.flops)\", \"AVG(tc.flops)\",\n+                \"AVG(tb.bandwidth_gb_s)\", \"AVG(tc.bandwidth_gb_s)\"\n+            ])\n+        equal_string = \" AND \".join(\n+            [f\"tb.{p} = tc.{p}\" for p in TEST_BACKEND_OPS_KEY_PROPERTIES] + [\n+                f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\",\n+                \"tb.supported = 1\", \"tc.supported = 1\", \"tb.passed = 1\", \"tc.passed = 1\"]  # Only compare successful tests\n+        )\n+        group_order_string = \", \".join([f\"tb.{p}\" for p in properties])\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n                  f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n         return self.cursor.execute(query).fetchall()\n \n \n class LlamaBenchDataSQLite3File(LlamaBenchDataSQLite3):\n-    def __init__(self, data_file: str):\n-        super().__init__()\n+    def __init__(self, data_file: str, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n \n         self.connection.close()\n         self.connection = sqlite3.connect(data_file)\n         self.cursor = self.connection.cursor()\n+\n+        # Check which table exists in the database\n+        tables = self.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n+        table_names = [table[0] for table in tables]\n+\n+        if \"test_backend_ops\" in table_names and tool == \"test-backend-ops\":\n+            self.table_name = \"test_backend_ops\"\n+        elif \"test\" in table_names and tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+        elif \"test\" in table_names:\n+            # Fallback to test table for backward compatibility\n+            self.table_name = \"test\"\n+            if tool == \"test-backend-ops\":\n+                logger.warning(\"test-backend-ops tool specified but only 'test' table found. Assuming llama-bench data.\")\n+                self.tool = \"llama-bench\"",
        "comment_created_at": "2025-07-08T13:29:26+00:00",
        "comment_author": "yeahdongcn",
        "comment_body": "Makes sense \u2014 thanks for the explanation! I\u2019ll update this part tomorrow.",
        "pr_file_module": null
      },
      {
        "comment_id": "2193695757",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14392,
        "pr_file": "scripts/compare-llama-bench.py",
        "discussion_id": "2190476848",
        "commented_code": "@@ -252,52 +331,105 @@ def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare\n class LlamaBenchDataSQLite3(LlamaBenchData):\n     connection: sqlite3.Connection\n     cursor: sqlite3.Cursor\n+    table_name: str\n \n-    def __init__(self):\n-        super().__init__()\n+    def __init__(self, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n         self.connection = sqlite3.connect(\":memory:\")\n         self.cursor = self.connection.cursor()\n-        self.cursor.execute(f\"CREATE TABLE test({', '.join(' '.join(x) for x in zip(DB_FIELDS, DB_TYPES))});\")\n+\n+        # Set table name and schema based on tool\n+        if self.tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+            db_fields = LLAMA_BENCH_DB_FIELDS\n+            db_types = LLAMA_BENCH_DB_TYPES\n+        else:  # test-backend-ops\n+            self.table_name = \"test_backend_ops\"\n+            db_fields = TEST_BACKEND_OPS_DB_FIELDS\n+            db_types = TEST_BACKEND_OPS_DB_TYPES\n+\n+        self.cursor.execute(f\"CREATE TABLE {self.table_name}({', '.join(' '.join(x) for x in zip(db_fields, db_types))});\")\n \n     def _builds_init(self):\n         if self.connection:\n-            self.build_len_min = self.cursor.execute(\"SELECT MIN(LENGTH(build_commit)) from test;\").fetchone()[0]\n-            self.build_len_max = self.cursor.execute(\"SELECT MAX(LENGTH(build_commit)) from test;\").fetchone()[0]\n+            self.build_len_min = self.cursor.execute(f\"SELECT MIN(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n+            self.build_len_max = self.cursor.execute(f\"SELECT MAX(LENGTH(build_commit)) from {self.table_name};\").fetchone()[0]\n \n             if self.build_len_min != self.build_len_max:\n                 logger.warning(\"Data contains commit hashes of differing lengths. It's possible that the wrong commits will be compared. \"\n                                \"Try purging the the database of old commits.\")\n-                self.cursor.execute(f\"UPDATE test SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n+                self.cursor.execute(f\"UPDATE {self.table_name} SET build_commit = SUBSTRING(build_commit, 1, {self.build_len_min});\")\n \n-            builds = self.cursor.execute(\"SELECT DISTINCT build_commit FROM test;\").fetchall()\n+            builds = self.cursor.execute(f\"SELECT DISTINCT build_commit FROM {self.table_name};\").fetchall()\n             self.builds = list(map(lambda b: b[0], builds))  # list[tuple[str]] -> list[str]\n         super()._builds_init()\n \n     def builds_timestamp(self, reverse: bool = False) -> Union[Iterator[tuple], Sequence[tuple]]:\n         data = self.cursor.execute(\n-            \"SELECT build_commit, test_time FROM test ORDER BY test_time;\").fetchall()\n+            f\"SELECT build_commit, test_time FROM {self.table_name} ORDER BY test_time;\").fetchall()\n         return reversed(data) if reverse else data\n \n     def get_rows(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        if self.tool == \"llama-bench\":\n+            return self._get_rows_llama_bench(properties, hexsha8_baseline, hexsha8_compare)\n+        else:  # test-backend-ops\n+            return self._get_rows_test_backend_ops(properties, hexsha8_baseline, hexsha8_compare)\n+\n+    def _get_rows_llama_bench(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n         select_string = \", \".join(\n             [f\"tb.{p}\" for p in properties] + [\"tb.n_prompt\", \"tb.n_gen\", \"tb.n_depth\", \"AVG(tb.avg_ts)\", \"AVG(tc.avg_ts)\"])\n         equal_string = \" AND \".join(\n-            [f\"tb.{p} = tc.{p}\" for p in KEY_PROPERTIES] + [\n+            [f\"tb.{p} = tc.{p}\" for p in LLAMA_BENCH_KEY_PROPERTIES] + [\n                 f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\"]\n         )\n         group_order_string = \", \".join([f\"tb.{p}\" for p in properties] + [\"tb.n_gen\", \"tb.n_prompt\", \"tb.n_depth\"])\n-        query = (f\"SELECT {select_string} FROM test tb JOIN test tc ON {equal_string} \"\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n+                 f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n+        return self.cursor.execute(query).fetchall()\n+\n+    def _get_rows_test_backend_ops(self, properties: list[str], hexsha8_baseline: str, hexsha8_compare: str) -> Sequence[tuple]:\n+        # For test-backend-ops, we compare FLOPS and bandwidth metrics (prioritizing FLOPS over bandwidth)\n+        select_string = \", \".join(\n+            [f\"tb.{p}\" for p in properties] + [\n+                \"AVG(tb.flops)\", \"AVG(tc.flops)\",\n+                \"AVG(tb.bandwidth_gb_s)\", \"AVG(tc.bandwidth_gb_s)\"\n+            ])\n+        equal_string = \" AND \".join(\n+            [f\"tb.{p} = tc.{p}\" for p in TEST_BACKEND_OPS_KEY_PROPERTIES] + [\n+                f\"tb.build_commit = '{hexsha8_baseline}'\", f\"tc.build_commit = '{hexsha8_compare}'\",\n+                \"tb.supported = 1\", \"tc.supported = 1\", \"tb.passed = 1\", \"tc.passed = 1\"]  # Only compare successful tests\n+        )\n+        group_order_string = \", \".join([f\"tb.{p}\" for p in properties])\n+        query = (f\"SELECT {select_string} FROM {self.table_name} tb JOIN {self.table_name} tc ON {equal_string} \"\n                  f\"GROUP BY {group_order_string} ORDER BY {group_order_string};\")\n         return self.cursor.execute(query).fetchall()\n \n \n class LlamaBenchDataSQLite3File(LlamaBenchDataSQLite3):\n-    def __init__(self, data_file: str):\n-        super().__init__()\n+    def __init__(self, data_file: str, tool: str = \"llama-bench\"):\n+        super().__init__(tool)\n \n         self.connection.close()\n         self.connection = sqlite3.connect(data_file)\n         self.cursor = self.connection.cursor()\n+\n+        # Check which table exists in the database\n+        tables = self.cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n+        table_names = [table[0] for table in tables]\n+\n+        if \"test_backend_ops\" in table_names and tool == \"test-backend-ops\":\n+            self.table_name = \"test_backend_ops\"\n+        elif \"test\" in table_names and tool == \"llama-bench\":\n+            self.table_name = \"test\"\n+        elif \"test\" in table_names:\n+            # Fallback to test table for backward compatibility\n+            self.table_name = \"test\"\n+            if tool == \"test-backend-ops\":\n+                logger.warning(\"test-backend-ops tool specified but only 'test' table found. Assuming llama-bench data.\")\n+                self.tool = \"llama-bench\"",
        "comment_created_at": "2025-07-09T01:03:49+00:00",
        "comment_author": "yeahdongcn",
        "comment_body": "PTAL: https://github.com/ggml-org/llama.cpp/pull/14392/commits/a7940f719b025ef0558317cb5a7871ffa0bfddbc\r\nThanks!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2192597249",
    "pr_number": 14534,
    "pr_file": "convert_hf_to_gguf.py",
    "created_at": "2025-07-08T13:51:58+00:00",
    "commented_code": "self.gguf_writer.add_audio_stack_factor(self.global_config[\"stack_factor\"])\n \n \n+@ModelBase.register(\"FalconH1ForCausalLM\")\n+class FalconH1Model(Mamba2Model):\n+    model_arch = gguf.MODEL_ARCH.FALCON_H1\n+\n+    def __init__(self, *args, **kwargs):\n+        # Set the hparam prefixes for Falcon Mamba2\n+        self.hparam_prefixes = [\"mamba\"]\n+\n+        # Initialize the base Mamba2Model\n+        super().__init__(*args, **kwargs)\n+\n+        # Use Llama conversion for attention\n+        self._transformer_model_class = LlamaModel\n+\n+        # n_group and d_inner are used during reshape_tensors for mamaba2\n+        self.d_model = self.find_hparam([\"hidden_size\", \"d_model\"])\n+        self.n_group = self.find_hparam([\"n_groups\"])\n+        self.d_inner = self.find_hparam([\"expand\"]) * self.d_model\n+\n+        # Initialize any Falcon Mamba2 specific attributes\n+        self.has_attention = True  # Falcon Mamba2 has attention components\n+\n+        # Load Falcon-H1 multipliers from hyperparameters\n+        self.attention_in_multiplier = self.find_hparam([\"attention_in_multiplier\"], optional=True)\n+        self.attention_out_multiplier = self.find_hparam([\"attention_out_multiplier\"], optional=True)\n+        self.ssm_in_multiplier = self.find_hparam([\"ssm_in_multiplier\"], optional=True)\n+        self.ssm_out_multiplier = self.find_hparam([\"ssm_out_multiplier\"], optional=True)\n+        self.mlp_multipliers = self.find_hparam([\"mlp_multipliers\"], optional=True)\n+        self.ssm_multipliers = self.find_hparam([\"ssm_multipliers\"], optional=True)\n+        self.intermediate_size = self.find_hparam([\"intermediate_size\"])\n+        self.key_multiplier = self.find_hparam([\"key_multiplier\"], optional=True)\n+\n+    def find_hparam(self, keys: Iterable[str], *args, **kwargs) -> Any:\n+        prefixed = []\n+        for pfx in self.hparam_prefixes:\n+            prefixed.extend(\n+                \"_\".join([pfx, k])\n+                for k in keys\n+            )\n+        keys = list(keys) + prefixed\n+        return super().find_hparam(keys, *args, **kwargs)\n+\n+    def set_vocab(self):\n+        self._set_vocab_gpt2()\n+\n+    def _generate_mup_vector(self, block_id: int) -> torch.Tensor:\n+        zxbcdt_multipliers = self.hparams[\"ssm_multipliers\"]\n+        intermediate_size = self.hparams[\"mamba_d_ssm\"]\n+        groups_time_state_size = self.hparams[\"mamba_n_groups\"] * self.hparams[\"mamba_d_state\"]\n+        vector_shape = (2 * intermediate_size + 2 * groups_time_state_size + self.hparams[\"mamba_n_heads\"])\n+\n+        mup_vector = torch.ones(1, 1, vector_shape, dtype=torch.float64)\n+        mup_vector[:, :, :intermediate_size] *= zxbcdt_multipliers[0]\n+        mup_vector[:, :, intermediate_size:2 * intermediate_size] *= zxbcdt_multipliers[1]\n+        mup_vector[:, :, 2 * intermediate_size:2 * intermediate_size + groups_time_state_size] *= zxbcdt_multipliers[2]\n+        mup_vector[:, :, 2 * intermediate_size + groups_time_state_size:2 * intermediate_size + 2 * groups_time_state_size] *= zxbcdt_multipliers[3]\n+        mup_vector[:, :, 2 * intermediate_size + 2 * groups_time_state_size:] *= zxbcdt_multipliers[4]\n+\n+        return mup_vector\n+\n+    def modify_tensors(self, data_torch: Tensor, name: str, bid: int | None) -> Iterable[tuple[str, Tensor]]:\n+        tensors = list(super().modify_tensors(data_torch, name, bid))\n+        tensor = tensors[0][1]\n+\n+        if \"down_proj\" in name:\n+            tensor = tensor  * self.mlp_multipliers[1]\n+        elif \"gate_proj\" in name:\n+            tensor = tensor * self.mlp_multipliers[0]\n+        elif \"k_proj\" in name:\n+            tensor = tensor * self.key_multiplier * self.attention_in_multiplier\n+        elif \"q_proj\" in name:\n+            tensor = tensor * self.attention_in_multiplier\n+        elif \"v_proj\" in name:\n+            tensor = tensor * self.attention_in_multiplier\n+        elif \"o_proj\" in name:\n+            tensor = tensor * self.attention_out_multiplier\n+        elif \"out_proj\" in name:\n+            tensor = tensor * self.ssm_out_multiplier\n+        elif \"in_proj\" in name:\n+            tensor = tensor * self.ssm_in_multiplier\n+            zxbcdt_multipliers = self.hparams[\"ssm_multipliers\"]\n+            intermediate_size = self.hparams[\"mamba_d_ssm\"]\n+            groups_time_state_size = self.hparams[\"mamba_n_groups\"] * self.hparams[\"mamba_d_state\"]\n+            tensor[:intermediate_size, :] *= zxbcdt_multipliers[0]\n+            tensor[intermediate_size:2 * intermediate_size, :] *= zxbcdt_multipliers[1]\n+            tensor[2 * intermediate_size:2 * intermediate_size + groups_time_state_size, :] *= zxbcdt_multipliers[2]\n+            tensor[2 * intermediate_size + groups_time_state_size:2 * intermediate_size + 2 * groups_time_state_size, :] *= zxbcdt_multipliers[3]\n+            tensor[2 * intermediate_size + 2 * groups_time_state_size:, :] *= zxbcdt_multipliers[4]\n+        elif \"lm_head\" in name:\n+            tensor = tensor * self.hparams[\"lm_head_multiplier\"]\n+        elif \"embed_tokens\" in name:\n+            tensor = tensor * self.hparams[\"embedding_multiplier\"]\n+\n+        tensors = [(tensors[0][0], tensor)]\n+        return tensors\n+\n+    def set_gguf_parameters(self):\n+        super().set_gguf_parameters()\n+\n+        ## General Params ##\n+        self.gguf_writer.add_block_count(self.block_count)\n+        self.gguf_writer.add_context_length(self.hparams.get(\"max_position_embeddings\", 0))\n+        self.gguf_writer.add_vocab_size(self.hparams[\"vocab_size\"])\n+        self.gguf_writer.add_add_bos_token(False)\n+        self.gguf_writer.add_feed_forward_length(self.hparams[\"intermediate_size\"])\n+\n+        ## Mamba mixer params ##\n+        self.gguf_writer.add_ssm_conv_kernel(self.find_hparam([\"conv_kernel\", \"d_conv\"]))\n+        self.gguf_writer.add_ssm_group_count(self.n_group)\n+        self.gguf_writer.add_ssm_inner_size(self.find_hparam([\"mamba_d_ssm\"]))\n+        self.gguf_writer.add_ssm_head_dim(d_head := self.find_hparam([\"d_head\"]))\n+        self.gguf_writer.add_ssm_time_step_rank(self.find_hparam([\"n_heads\"]))",
    "repo_full_name": "ggml-org/llama.cpp",
    "discussion_comments": [
      {
        "comment_id": "2192597249",
        "repo_full_name": "ggml-org/llama.cpp",
        "pr_number": 14534,
        "pr_file": "convert_hf_to_gguf.py",
        "discussion_id": "2192597249",
        "commented_code": "@@ -6539,6 +6553,135 @@ def set_gguf_parameters(self):\n         self.gguf_writer.add_audio_stack_factor(self.global_config[\"stack_factor\"])\n \n \n+@ModelBase.register(\"FalconH1ForCausalLM\")\n+class FalconH1Model(Mamba2Model):\n+    model_arch = gguf.MODEL_ARCH.FALCON_H1\n+\n+    def __init__(self, *args, **kwargs):\n+        # Set the hparam prefixes for Falcon Mamba2\n+        self.hparam_prefixes = [\"mamba\"]\n+\n+        # Initialize the base Mamba2Model\n+        super().__init__(*args, **kwargs)\n+\n+        # Use Llama conversion for attention\n+        self._transformer_model_class = LlamaModel\n+\n+        # n_group and d_inner are used during reshape_tensors for mamaba2\n+        self.d_model = self.find_hparam([\"hidden_size\", \"d_model\"])\n+        self.n_group = self.find_hparam([\"n_groups\"])\n+        self.d_inner = self.find_hparam([\"expand\"]) * self.d_model\n+\n+        # Initialize any Falcon Mamba2 specific attributes\n+        self.has_attention = True  # Falcon Mamba2 has attention components\n+\n+        # Load Falcon-H1 multipliers from hyperparameters\n+        self.attention_in_multiplier = self.find_hparam([\"attention_in_multiplier\"], optional=True)\n+        self.attention_out_multiplier = self.find_hparam([\"attention_out_multiplier\"], optional=True)\n+        self.ssm_in_multiplier = self.find_hparam([\"ssm_in_multiplier\"], optional=True)\n+        self.ssm_out_multiplier = self.find_hparam([\"ssm_out_multiplier\"], optional=True)\n+        self.mlp_multipliers = self.find_hparam([\"mlp_multipliers\"], optional=True)\n+        self.ssm_multipliers = self.find_hparam([\"ssm_multipliers\"], optional=True)\n+        self.intermediate_size = self.find_hparam([\"intermediate_size\"])\n+        self.key_multiplier = self.find_hparam([\"key_multiplier\"], optional=True)\n+\n+    def find_hparam(self, keys: Iterable[str], *args, **kwargs) -> Any:\n+        prefixed = []\n+        for pfx in self.hparam_prefixes:\n+            prefixed.extend(\n+                \"_\".join([pfx, k])\n+                for k in keys\n+            )\n+        keys = list(keys) + prefixed\n+        return super().find_hparam(keys, *args, **kwargs)\n+\n+    def set_vocab(self):\n+        self._set_vocab_gpt2()\n+\n+    def _generate_mup_vector(self, block_id: int) -> torch.Tensor:\n+        zxbcdt_multipliers = self.hparams[\"ssm_multipliers\"]\n+        intermediate_size = self.hparams[\"mamba_d_ssm\"]\n+        groups_time_state_size = self.hparams[\"mamba_n_groups\"] * self.hparams[\"mamba_d_state\"]\n+        vector_shape = (2 * intermediate_size + 2 * groups_time_state_size + self.hparams[\"mamba_n_heads\"])\n+\n+        mup_vector = torch.ones(1, 1, vector_shape, dtype=torch.float64)\n+        mup_vector[:, :, :intermediate_size] *= zxbcdt_multipliers[0]\n+        mup_vector[:, :, intermediate_size:2 * intermediate_size] *= zxbcdt_multipliers[1]\n+        mup_vector[:, :, 2 * intermediate_size:2 * intermediate_size + groups_time_state_size] *= zxbcdt_multipliers[2]\n+        mup_vector[:, :, 2 * intermediate_size + groups_time_state_size:2 * intermediate_size + 2 * groups_time_state_size] *= zxbcdt_multipliers[3]\n+        mup_vector[:, :, 2 * intermediate_size + 2 * groups_time_state_size:] *= zxbcdt_multipliers[4]\n+\n+        return mup_vector\n+\n+    def modify_tensors(self, data_torch: Tensor, name: str, bid: int | None) -> Iterable[tuple[str, Tensor]]:\n+        tensors = list(super().modify_tensors(data_torch, name, bid))\n+        tensor = tensors[0][1]\n+\n+        if \"down_proj\" in name:\n+            tensor = tensor  * self.mlp_multipliers[1]\n+        elif \"gate_proj\" in name:\n+            tensor = tensor * self.mlp_multipliers[0]\n+        elif \"k_proj\" in name:\n+            tensor = tensor * self.key_multiplier * self.attention_in_multiplier\n+        elif \"q_proj\" in name:\n+            tensor = tensor * self.attention_in_multiplier\n+        elif \"v_proj\" in name:\n+            tensor = tensor * self.attention_in_multiplier\n+        elif \"o_proj\" in name:\n+            tensor = tensor * self.attention_out_multiplier\n+        elif \"out_proj\" in name:\n+            tensor = tensor * self.ssm_out_multiplier\n+        elif \"in_proj\" in name:\n+            tensor = tensor * self.ssm_in_multiplier\n+            zxbcdt_multipliers = self.hparams[\"ssm_multipliers\"]\n+            intermediate_size = self.hparams[\"mamba_d_ssm\"]\n+            groups_time_state_size = self.hparams[\"mamba_n_groups\"] * self.hparams[\"mamba_d_state\"]\n+            tensor[:intermediate_size, :] *= zxbcdt_multipliers[0]\n+            tensor[intermediate_size:2 * intermediate_size, :] *= zxbcdt_multipliers[1]\n+            tensor[2 * intermediate_size:2 * intermediate_size + groups_time_state_size, :] *= zxbcdt_multipliers[2]\n+            tensor[2 * intermediate_size + groups_time_state_size:2 * intermediate_size + 2 * groups_time_state_size, :] *= zxbcdt_multipliers[3]\n+            tensor[2 * intermediate_size + 2 * groups_time_state_size:, :] *= zxbcdt_multipliers[4]\n+        elif \"lm_head\" in name:\n+            tensor = tensor * self.hparams[\"lm_head_multiplier\"]\n+        elif \"embed_tokens\" in name:\n+            tensor = tensor * self.hparams[\"embedding_multiplier\"]\n+\n+        tensors = [(tensors[0][0], tensor)]\n+        return tensors\n+\n+    def set_gguf_parameters(self):\n+        super().set_gguf_parameters()\n+\n+        ## General Params ##\n+        self.gguf_writer.add_block_count(self.block_count)\n+        self.gguf_writer.add_context_length(self.hparams.get(\"max_position_embeddings\", 0))\n+        self.gguf_writer.add_vocab_size(self.hparams[\"vocab_size\"])\n+        self.gguf_writer.add_add_bos_token(False)\n+        self.gguf_writer.add_feed_forward_length(self.hparams[\"intermediate_size\"])\n+\n+        ## Mamba mixer params ##\n+        self.gguf_writer.add_ssm_conv_kernel(self.find_hparam([\"conv_kernel\", \"d_conv\"]))\n+        self.gguf_writer.add_ssm_group_count(self.n_group)\n+        self.gguf_writer.add_ssm_inner_size(self.find_hparam([\"mamba_d_ssm\"]))\n+        self.gguf_writer.add_ssm_head_dim(d_head := self.find_hparam([\"d_head\"]))\n+        self.gguf_writer.add_ssm_time_step_rank(self.find_hparam([\"n_heads\"]))",
        "comment_created_at": "2025-07-08T13:51:58+00:00",
        "comment_author": "compilade",
        "comment_body": "A lot of the Mamba-2-related metadata keys are set twice (this overwrites the value and makes a warning).\n\nFor example, `gguf_writer.add_ssm_inner_size` is called both here and in the parent function which was modified to handle the `\"mamba_d_ssm\"` field.\n\nYou should decide where the values should come from.",
        "pr_file_module": null
      }
    ]
  }
]