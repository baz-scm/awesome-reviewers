[
  {
    "discussion_id": "2226570909",
    "pr_number": 148013,
    "pr_file": "llvm/tools/llvm-profgen/ProfiledBinary.h",
    "created_at": "2025-07-23T20:19:12+00:00",
    "commented_code": "return ProbeDecoder.getInlinerDescForProbe(Probe);\n   }\n \n+  void addMMapNonTextEvent(MMapEvent MMap) {\n+    MMapNonTextEvents.push_back(MMap);",
    "repo_full_name": "llvm/llvm-project",
    "discussion_comments": [
      {
        "comment_id": "2226570909",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148013,
        "pr_file": "llvm/tools/llvm-profgen/ProfiledBinary.h",
        "discussion_id": "2226570909",
        "commented_code": "@@ -603,6 +640,16 @@ class ProfiledBinary {\n     return ProbeDecoder.getInlinerDescForProbe(Probe);\n   }\n \n+  void addMMapNonTextEvent(MMapEvent MMap) {\n+    MMapNonTextEvents.push_back(MMap);",
        "comment_created_at": "2025-07-23T20:19:12+00:00",
        "comment_author": "apolloww",
        "comment_body": "Is it possible that multiple mmap events can happen on the same segment? If so, would it be better to use a map here?",
        "pr_file_module": null
      },
      {
        "comment_id": "2226617597",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148013,
        "pr_file": "llvm/tools/llvm-profgen/ProfiledBinary.h",
        "discussion_id": "2226570909",
        "commented_code": "@@ -603,6 +640,16 @@ class ProfiledBinary {\n     return ProbeDecoder.getInlinerDescForProbe(Probe);\n   }\n \n+  void addMMapNonTextEvent(MMapEvent MMap) {\n+    MMapNonTextEvents.push_back(MMap);",
        "comment_created_at": "2025-07-23T20:34:57+00:00",
        "comment_author": "snehasish",
        "comment_body": "I think even if there were mutliple mmap events for the same segment we would still *only* want the last one. For the things we care about .text* .data*, we shouldn't have multiple copies in the address space.",
        "pr_file_module": null
      },
      {
        "comment_id": "2226703940",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148013,
        "pr_file": "llvm/tools/llvm-profgen/ProfiledBinary.h",
        "discussion_id": "2226570909",
        "commented_code": "@@ -603,6 +640,16 @@ class ProfiledBinary {\n     return ProbeDecoder.getInlinerDescForProbe(Probe);\n   }\n \n+  void addMMapNonTextEvent(MMapEvent MMap) {\n+    MMapNonTextEvents.push_back(MMap);",
        "comment_created_at": "2025-07-23T21:14:28+00:00",
        "comment_author": "apolloww",
        "comment_body": "Right. Using vector here, I think there is a chance an address could be matched to an old map during canonicalization. If using map with offsets as keys, we only keep the most recent one.",
        "pr_file_module": null
      },
      {
        "comment_id": "2234111365",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148013,
        "pr_file": "llvm/tools/llvm-profgen/ProfiledBinary.h",
        "discussion_id": "2226570909",
        "commented_code": "@@ -603,6 +640,16 @@ class ProfiledBinary {\n     return ProbeDecoder.getInlinerDescForProbe(Probe);\n   }\n \n+  void addMMapNonTextEvent(MMapEvent MMap) {\n+    MMapNonTextEvents.push_back(MMap);",
        "comment_created_at": "2025-07-27T19:38:26+00:00",
        "comment_author": "mingmingl-llvm",
        "comment_body": "My understanding is that it's rare for the virtual address ranges (i.e., the intervals formed by `[MMapEvent.Address, MMapEvent.Address + MMap.Size)`) of mmap events to overlap with each other. Assuming this is true, I think there are two implementation options here:\n\n1)  Make llvm-profgen to validate mmap events don't have overlapping virtual address (and report 'unimplemented error' otherwise). This way, the implementation can use a map to do efficient address canonicalization and handle the common case. The updated change implements this option.\n  \n2) llvm-profgen doesn't validate address interval and cannot assume non-overlapping address ranges. The implementation uses a vector to record the mmap events in the order they are added and reverse iterate the map to do data address canonicalization. While a linear reverse iteration is probably acceptable given the number of non-text mmap events is observed to be 3 in most cases, I think option 1) does the better trade-off. \n\nLet me know your thoughts and I'd be glad to follow up.\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2237562177",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148013,
        "pr_file": "llvm/tools/llvm-profgen/ProfiledBinary.h",
        "discussion_id": "2226570909",
        "commented_code": "@@ -603,6 +640,16 @@ class ProfiledBinary {\n     return ProbeDecoder.getInlinerDescForProbe(Probe);\n   }\n \n+  void addMMapNonTextEvent(MMapEvent MMap) {\n+    MMapNonTextEvents.push_back(MMap);",
        "comment_created_at": "2025-07-28T18:49:12+00:00",
        "comment_author": "apolloww",
        "comment_body": "Thanks for the update! \r\n\r\nSorry for not making it more clearer. I think this won't be an issue if we only consider the main executable right now. Its sections should just be loaded once and stay the same. I was thinking about if we are going to support dynamic loading/reloading of shared libraries (`dlopen/dlclose`), which may make the same DSO appear at different addresses. Maybe this isn't something we need to consider right now. The current map solution can help surface such issue in case we want to go that direction.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2236229602",
    "pr_number": 150931,
    "pr_file": "llvm/include/llvm/Analysis/TargetFolder.h",
    "created_at": "2025-07-28T12:35:05+00:00",
    "commented_code": "return nullptr;\n   }\n \n+  Value *FoldVectorInterleave(ArrayRef<Value *> Ops) const override {",
    "repo_full_name": "llvm/llvm-project",
    "discussion_comments": [
      {
        "comment_id": "2236229602",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 150931,
        "pr_file": "llvm/include/llvm/Analysis/TargetFolder.h",
        "discussion_id": "2236229602",
        "commented_code": "@@ -189,6 +189,24 @@ class LLVM_ABI TargetFolder final : public IRBuilderFolder {\n     return nullptr;\n   }\n \n+  Value *FoldVectorInterleave(ArrayRef<Value *> Ops) const override {",
        "comment_created_at": "2025-07-28T12:35:05+00:00",
        "comment_author": "nikic",
        "comment_body": "This code should not be in IRBuilder folders, but rather part of the generic intrinsic ConstantFolding support.",
        "pr_file_module": null
      },
      {
        "comment_id": "2236306103",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 150931,
        "pr_file": "llvm/include/llvm/Analysis/TargetFolder.h",
        "discussion_id": "2236229602",
        "commented_code": "@@ -189,6 +189,24 @@ class LLVM_ABI TargetFolder final : public IRBuilderFolder {\n     return nullptr;\n   }\n \n+  Value *FoldVectorInterleave(ArrayRef<Value *> Ops) const override {",
        "comment_created_at": "2025-07-28T12:49:23+00:00",
        "comment_author": "david-arm",
        "comment_body": "I'm not sure I understand. Do you mean that I shouldn't be changing any of the folders whatsoever, or that I should be doing something like this in TargetFolder:\r\n\r\n```\r\n  Value *FoldBinaryIntrinsic(Intrinsic::ID ID, Value *LHS, Value *RHS, Type *Ty,\r\n                             Instruction *FMFSource) const override {\r\n    auto *C1 = dyn_cast<Constant>(LHS);\r\n    auto *C2 = dyn_cast<Constant>(RHS);\r\n    if (C1 && C2)\r\n      return ConstantFoldBinaryIntrinsic(ID, C1, C2, Ty, FMFSource);\r\n    return nullptr;\r\n  }\r\n```\r\n\r\nI thought the standard practice in IRBuilder was to apply folds using the folder, i.e. like we do here:\r\n\r\n```\r\nValue *IRBuilderBase::CreateBinaryIntrinsic(Intrinsic::ID ID, Value *LHS,\r\n                                            Value *RHS, FMFSource FMFSource,\r\n                                            const Twine &Name) {\r\n  Module *M = BB->getModule();\r\n  Function *Fn = Intrinsic::getOrInsertDeclaration(M, ID, {LHS->getType()});\r\n  if (Value *V = Folder.FoldBinaryIntrinsic(ID, LHS, RHS, Fn->getReturnType(),\r\n                                            /*FMFSource=*/nullptr))\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2236321128",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 150931,
        "pr_file": "llvm/include/llvm/Analysis/TargetFolder.h",
        "discussion_id": "2236229602",
        "commented_code": "@@ -189,6 +189,24 @@ class LLVM_ABI TargetFolder final : public IRBuilderFolder {\n     return nullptr;\n   }\n \n+  Value *FoldVectorInterleave(ArrayRef<Value *> Ops) const override {",
        "comment_created_at": "2025-07-28T12:52:20+00:00",
        "comment_author": "david-arm",
        "comment_body": "I can't use the pre-existing `FoldBinaryIntrinsic` or `FoldUnaryIntrinsic` functions either because the number of operands is variable, although I'm happy to add a `FoldUnaryIntrinsic`.",
        "pr_file_module": null
      },
      {
        "comment_id": "2236338130",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 150931,
        "pr_file": "llvm/include/llvm/Analysis/TargetFolder.h",
        "discussion_id": "2236229602",
        "commented_code": "@@ -189,6 +189,24 @@ class LLVM_ABI TargetFolder final : public IRBuilderFolder {\n     return nullptr;\n   }\n \n+  Value *FoldVectorInterleave(ArrayRef<Value *> Ops) const override {",
        "comment_created_at": "2025-07-28T12:56:22+00:00",
        "comment_author": "nikic",
        "comment_body": "You probably want to replace FoldBinaryIntrinsic with FoldIntrinsic -- we shouldn't specialize to binary. This is going to need a small bit of refactoring in ConstantFolding to expose a ConstantFoldIntrinsic function instead of ConstantFoldBinaryIntrinsic.",
        "pr_file_module": null
      },
      {
        "comment_id": "2236347593",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 150931,
        "pr_file": "llvm/include/llvm/Analysis/TargetFolder.h",
        "discussion_id": "2236229602",
        "commented_code": "@@ -189,6 +189,24 @@ class LLVM_ABI TargetFolder final : public IRBuilderFolder {\n     return nullptr;\n   }\n \n+  Value *FoldVectorInterleave(ArrayRef<Value *> Ops) const override {",
        "comment_created_at": "2025-07-28T12:58:37+00:00",
        "comment_author": "david-arm",
        "comment_body": "OK thanks for the pointer, I'll take a look!",
        "pr_file_module": null
      },
      {
        "comment_id": "2236581797",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 150931,
        "pr_file": "llvm/include/llvm/Analysis/TargetFolder.h",
        "discussion_id": "2236229602",
        "commented_code": "@@ -189,6 +189,24 @@ class LLVM_ABI TargetFolder final : public IRBuilderFolder {\n     return nullptr;\n   }\n \n+  Value *FoldVectorInterleave(ArrayRef<Value *> Ops) const override {",
        "comment_created_at": "2025-07-28T13:52:41+00:00",
        "comment_author": "david-arm",
        "comment_body": "The places where I'd like to see these constant folds happening are where we're using a default version of IRBuilder, which uses ConstantFolder. However, the ConstantFolder.h version of FoldBinaryIntrinsic says the caller should be using TargetFolder or InstSimplifyFolder instead. So I could change FoldBinaryIntrinsic in llvm/Analysis/ConstantFolding.h (used by TargetFolder.h), but then I wouldn't see any improvements in generated code for IRBuilder instances using the default version.\r\n\r\nTo be honest, I'm not really sure the best way to proceed now. Would it be acceptable to add a variant of FoldIntrinsic to ConstantFolder.h as well, or is the preferred solution to just change all the IRBuilder instances I care about to use the TargetFolder instead?",
        "pr_file_module": null
      },
      {
        "comment_id": "2236742356",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 150931,
        "pr_file": "llvm/include/llvm/Analysis/TargetFolder.h",
        "discussion_id": "2236229602",
        "commented_code": "@@ -189,6 +189,24 @@ class LLVM_ABI TargetFolder final : public IRBuilderFolder {\n     return nullptr;\n   }\n \n+  Value *FoldVectorInterleave(ArrayRef<Value *> Ops) const override {",
        "comment_created_at": "2025-07-28T14:32:02+00:00",
        "comment_author": "nikic",
        "comment_body": "Using TargetFolder is generally preferred. (The whole TargetFolder vs ConstantFolder is an annoying legacy split, that's unfortunately not entirely straightforward to remove.)",
        "pr_file_module": null
      },
      {
        "comment_id": "2236754252",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 150931,
        "pr_file": "llvm/include/llvm/Analysis/TargetFolder.h",
        "discussion_id": "2236229602",
        "commented_code": "@@ -189,6 +189,24 @@ class LLVM_ABI TargetFolder final : public IRBuilderFolder {\n     return nullptr;\n   }\n \n+  Value *FoldVectorInterleave(ArrayRef<Value *> Ops) const override {",
        "comment_created_at": "2025-07-28T14:35:15+00:00",
        "comment_author": "lukel97",
        "comment_body": "I guess we need a `llvm::ConstantFoldBinaryIntrinsic` in ConstantFolding.cpp, and call that from both ConstantFolder.h and InstructionSimplify.cpp's `ConstantFoldInstOperandsImpl`? That would bring it inline with the other the other instruction types.\n\nAnd we probably need to rename that to just ConstantFoldIntrinsic?",
        "pr_file_module": null
      },
      {
        "comment_id": "2236849031",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 150931,
        "pr_file": "llvm/include/llvm/Analysis/TargetFolder.h",
        "discussion_id": "2236229602",
        "commented_code": "@@ -189,6 +189,24 @@ class LLVM_ABI TargetFolder final : public IRBuilderFolder {\n     return nullptr;\n   }\n \n+  Value *FoldVectorInterleave(ArrayRef<Value *> Ops) const override {",
        "comment_created_at": "2025-07-28T15:00:15+00:00",
        "comment_author": "david-arm",
        "comment_body": "I don't think we can do that because llvm/include/llvm/IR/ConstantFolder.h only includes llvm/IR/ConstantFold.h, whereas I *think* what you're talking about is trying to reuse an intrinsic folding function in the Analysis directory.\r\n\r\nI'll abandon the constant folds for now, because if I only add support in the TargetFolder the only way I could test it is via unit tests, since both the loop vectoriser and the complex interleaving pass use the default IRBuilder, which uses ConstantFolder. I care more about adding the CreateVectorInterleave interface - I just saw an opportunity to tidy up the IR but it turns out to be far too complicated to do all in one patch.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2222115515",
    "pr_number": 148243,
    "pr_file": "llvm/include/llvm/Transforms/Utils/LoopRotationUtils.h",
    "created_at": "2025-07-22T10:34:49+00:00",
    "commented_code": "/// header. If the loop header's size exceeds the threshold, the loop rotation\n /// will give up. The flag IsUtilMode controls the heuristic used in the\n /// LoopRotation. If it is true, the profitability heuristic will be ignored.\n-LLVM_ABI bool LoopRotation(Loop *L, LoopInfo *LI,\n-                           const TargetTransformInfo *TTI, AssumptionCache *AC,\n-                           DominatorTree *DT, ScalarEvolution *SE,\n-                           MemorySSAUpdater *MSSAU, const SimplifyQuery &SQ,\n-                           bool RotationOnly, unsigned Threshold,\n-                           bool IsUtilMode, bool PrepareForLTO = false);\n+/// The ProfitabilityCheck function can override general profitability check.",
    "repo_full_name": "llvm/llvm-project",
    "discussion_comments": [
      {
        "comment_id": "2222115515",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148243,
        "pr_file": "llvm/include/llvm/Transforms/Utils/LoopRotationUtils.h",
        "discussion_id": "2222115515",
        "commented_code": "@@ -32,12 +33,14 @@ class TargetTransformInfo;\n /// header. If the loop header's size exceeds the threshold, the loop rotation\n /// will give up. The flag IsUtilMode controls the heuristic used in the\n /// LoopRotation. If it is true, the profitability heuristic will be ignored.\n-LLVM_ABI bool LoopRotation(Loop *L, LoopInfo *LI,\n-                           const TargetTransformInfo *TTI, AssumptionCache *AC,\n-                           DominatorTree *DT, ScalarEvolution *SE,\n-                           MemorySSAUpdater *MSSAU, const SimplifyQuery &SQ,\n-                           bool RotationOnly, unsigned Threshold,\n-                           bool IsUtilMode, bool PrepareForLTO = false);\n+/// The ProfitabilityCheck function can override general profitability check.",
        "comment_created_at": "2025-07-22T10:34:49+00:00",
        "comment_author": "fhahn",
        "comment_body": "```suggestion\r\n/// The ProfitabilityCheck function will override general profitability check.\r\n```\r\n\r\nWith the argument we only bail out if `ProfitabilityCheck` is true.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2205018137",
    "pr_number": 133672,
    "pr_file": "llvm/test/Transforms/LoopInterchange/profitability-vectorization-heuristic.ll",
    "created_at": "2025-07-14T13:57:39+00:00",
    "commented_code": "exit:\n   ret void\n }\n+\n+; Check that the below loops are exchanged to allow innermost loop\n+; vectorization. We cannot vectorize the j-loop because it has a lexically\n+; backward dependency, but the i-loop can be vectorized because all the\n+; loop-carried dependencies are lexically forward.",
    "repo_full_name": "llvm/llvm-project",
    "discussion_comments": [
      {
        "comment_id": "2205018137",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 133672,
        "pr_file": "llvm/test/Transforms/LoopInterchange/profitability-vectorization-heuristic.ll",
        "discussion_id": "2205018137",
        "commented_code": "@@ -103,3 +103,135 @@ for.i.inc:\n exit:\n   ret void\n }\n+\n+; Check that the below loops are exchanged to allow innermost loop\n+; vectorization. We cannot vectorize the j-loop because it has a lexically\n+; backward dependency, but the i-loop can be vectorized because all the\n+; loop-carried dependencies are lexically forward.",
        "comment_created_at": "2025-07-14T13:57:39+00:00",
        "comment_author": "Meinersbur",
        "comment_body": "One problem: The current `LoopVectorize` pass does not do outer loop vectorization.",
        "pr_file_module": null
      },
      {
        "comment_id": "2208188818",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 133672,
        "pr_file": "llvm/test/Transforms/LoopInterchange/profitability-vectorization-heuristic.ll",
        "discussion_id": "2205018137",
        "commented_code": "@@ -103,3 +103,135 @@ for.i.inc:\n exit:\n   ret void\n }\n+\n+; Check that the below loops are exchanged to allow innermost loop\n+; vectorization. We cannot vectorize the j-loop because it has a lexically\n+; backward dependency, but the i-loop can be vectorized because all the\n+; loop-carried dependencies are lexically forward.",
        "comment_created_at": "2025-07-15T17:44:29+00:00",
        "comment_author": "kasuga-fj",
        "comment_body": "I meant to continue with something like this (which I should have written): Therefore, interchanging the loops could help `LoopVectorize`.\r\n\r\n(But that also means we don\u2019t know whether the loop will actually be vectorized\u2026)",
        "pr_file_module": null
      },
      {
        "comment_id": "2219053804",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 133672,
        "pr_file": "llvm/test/Transforms/LoopInterchange/profitability-vectorization-heuristic.ll",
        "discussion_id": "2205018137",
        "commented_code": "@@ -103,3 +103,135 @@ for.i.inc:\n exit:\n   ret void\n }\n+\n+; Check that the below loops are exchanged to allow innermost loop\n+; vectorization. We cannot vectorize the j-loop because it has a lexically\n+; backward dependency, but the i-loop can be vectorized because all the\n+; loop-carried dependencies are lexically forward.",
        "comment_created_at": "2025-07-21T12:26:50+00:00",
        "comment_author": "Meinersbur",
        "comment_body": "I think I got confused because it sounds like it was about removing the backward dependency, but its right in the first sentence.\r\n\r\nProposal\r\n```suggestion\r\n; backward dependency, but the i-loop can be vectorized because all the\r\n; loop-carried dependencies are lexically forward. LoopVectorize currently \r\n; only vectorizes innermost loop, hence move the i-loop to that position.\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2228038727",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 133672,
        "pr_file": "llvm/test/Transforms/LoopInterchange/profitability-vectorization-heuristic.ll",
        "discussion_id": "2205018137",
        "commented_code": "@@ -103,3 +103,135 @@ for.i.inc:\n exit:\n   ret void\n }\n+\n+; Check that the below loops are exchanged to allow innermost loop\n+; vectorization. We cannot vectorize the j-loop because it has a lexically\n+; backward dependency, but the i-loop can be vectorized because all the\n+; loop-carried dependencies are lexically forward.",
        "comment_created_at": "2025-07-24T09:52:20+00:00",
        "comment_author": "kasuga-fj",
        "comment_body": "Done.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2014821680",
    "pr_number": 128938,
    "pr_file": "llvm/test/Transforms/VectorCombine/X86/shuffle-of-shuffles.ll",
    "created_at": "2025-03-26T18:53:43+00:00",
    "commented_code": "; broadcast loads are free on AVX (and blends are much cheap than general 2-operand shuffles)\n \n define  <4 x double> @blend_broadcasts_v4f64(ptr %p0, ptr %p1)  {\n-; SSE-LABEL: define <4 x double> @blend_broadcasts_v4f64(\n-; SSE-SAME: ptr [[P0:%.*]], ptr [[P1:%.*]]) #[[ATTR0]] {\n-; SSE-NEXT:    [[LD0:%.*]] = load <4 x double>, ptr [[P0]], align 32\n-; SSE-NEXT:    [[LD1:%.*]] = load <4 x double>, ptr [[P1]], align 32\n-; SSE-NEXT:    [[BLEND:%.*]] = shufflevector <4 x double> [[LD0]], <4 x double> [[LD1]], <4 x i32> <i32 0, i32 4, i32 4, i32 0>\n-; SSE-NEXT:    ret <4 x double> [[BLEND]]\n-;\n-; AVX-LABEL: define <4 x double> @blend_broadcasts_v4f64(\n-; AVX-SAME: ptr [[P0:%.*]], ptr [[P1:%.*]]) #[[ATTR0]] {\n-; AVX-NEXT:    [[LD0:%.*]] = load <4 x double>, ptr [[P0]], align 32\n-; AVX-NEXT:    [[LD1:%.*]] = load <4 x double>, ptr [[P1]], align 32\n-; AVX-NEXT:    [[BCST0:%.*]] = shufflevector <4 x double> [[LD0]], <4 x double> undef, <4 x i32> zeroinitializer\n-; AVX-NEXT:    [[BCST1:%.*]] = shufflevector <4 x double> [[LD1]], <4 x double> undef, <4 x i32> zeroinitializer\n-; AVX-NEXT:    [[BLEND:%.*]] = shufflevector <4 x double> [[BCST0]], <4 x double> [[BCST1]], <4 x i32> <i32 0, i32 5, i32 6, i32 3>\n-; AVX-NEXT:    ret <4 x double> [[BLEND]]\n+; CHECK-LABEL: define <4 x double> @blend_broadcasts_v4f64(\n+; CHECK-SAME: ptr [[P0:%.*]], ptr [[P1:%.*]]) #[[ATTR0]] {\n+; CHECK-NEXT:    [[TMP1:%.*]] = load <1 x double>, ptr [[P0]], align 32\n+; CHECK-NEXT:    [[TMP2:%.*]] = load <1 x double>, ptr [[P1]], align 32\n+; CHECK-NEXT:    [[BLEND:%.*]] = shufflevector <1 x double> [[TMP1]], <1 x double> [[TMP2]], <4 x i32> <i32 0, i32 1, i32 1, i32 0>\n+; CHECK-NEXT:    ret <4 x double> [[BLEND]]\n ;",
    "repo_full_name": "llvm/llvm-project",
    "discussion_comments": [
      {
        "comment_id": "2014821680",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 128938,
        "pr_file": "llvm/test/Transforms/VectorCombine/X86/shuffle-of-shuffles.ll",
        "discussion_id": "2014821680",
        "commented_code": "@@ -47,21 +47,12 @@ define <8 x i32> @concat_extract_subvectors_poison(<8 x i32> %x) {\n ; broadcast loads are free on AVX (and blends are much cheap than general 2-operand shuffles)\n \n define  <4 x double> @blend_broadcasts_v4f64(ptr %p0, ptr %p1)  {\n-; SSE-LABEL: define <4 x double> @blend_broadcasts_v4f64(\n-; SSE-SAME: ptr [[P0:%.*]], ptr [[P1:%.*]]) #[[ATTR0]] {\n-; SSE-NEXT:    [[LD0:%.*]] = load <4 x double>, ptr [[P0]], align 32\n-; SSE-NEXT:    [[LD1:%.*]] = load <4 x double>, ptr [[P1]], align 32\n-; SSE-NEXT:    [[BLEND:%.*]] = shufflevector <4 x double> [[LD0]], <4 x double> [[LD1]], <4 x i32> <i32 0, i32 4, i32 4, i32 0>\n-; SSE-NEXT:    ret <4 x double> [[BLEND]]\n-;\n-; AVX-LABEL: define <4 x double> @blend_broadcasts_v4f64(\n-; AVX-SAME: ptr [[P0:%.*]], ptr [[P1:%.*]]) #[[ATTR0]] {\n-; AVX-NEXT:    [[LD0:%.*]] = load <4 x double>, ptr [[P0]], align 32\n-; AVX-NEXT:    [[LD1:%.*]] = load <4 x double>, ptr [[P1]], align 32\n-; AVX-NEXT:    [[BCST0:%.*]] = shufflevector <4 x double> [[LD0]], <4 x double> undef, <4 x i32> zeroinitializer\n-; AVX-NEXT:    [[BCST1:%.*]] = shufflevector <4 x double> [[LD1]], <4 x double> undef, <4 x i32> zeroinitializer\n-; AVX-NEXT:    [[BLEND:%.*]] = shufflevector <4 x double> [[BCST0]], <4 x double> [[BCST1]], <4 x i32> <i32 0, i32 5, i32 6, i32 3>\n-; AVX-NEXT:    ret <4 x double> [[BLEND]]\n+; CHECK-LABEL: define <4 x double> @blend_broadcasts_v4f64(\n+; CHECK-SAME: ptr [[P0:%.*]], ptr [[P1:%.*]]) #[[ATTR0]] {\n+; CHECK-NEXT:    [[TMP1:%.*]] = load <1 x double>, ptr [[P0]], align 32\n+; CHECK-NEXT:    [[TMP2:%.*]] = load <1 x double>, ptr [[P1]], align 32\n+; CHECK-NEXT:    [[BLEND:%.*]] = shufflevector <1 x double> [[TMP1]], <1 x double> [[TMP2]], <4 x i32> <i32 0, i32 1, i32 1, i32 0>\n+; CHECK-NEXT:    ret <4 x double> [[BLEND]]\n ;",
        "comment_created_at": "2025-03-26T18:53:43+00:00",
        "comment_author": "RKSimon",
        "comment_body": "https://clang.godbolt.org/z/Kv7cT4PdP - this is a definite regression",
        "pr_file_module": null
      },
      {
        "comment_id": "2022563502",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 128938,
        "pr_file": "llvm/test/Transforms/VectorCombine/X86/shuffle-of-shuffles.ll",
        "discussion_id": "2014821680",
        "commented_code": "@@ -47,21 +47,12 @@ define <8 x i32> @concat_extract_subvectors_poison(<8 x i32> %x) {\n ; broadcast loads are free on AVX (and blends are much cheap than general 2-operand shuffles)\n \n define  <4 x double> @blend_broadcasts_v4f64(ptr %p0, ptr %p1)  {\n-; SSE-LABEL: define <4 x double> @blend_broadcasts_v4f64(\n-; SSE-SAME: ptr [[P0:%.*]], ptr [[P1:%.*]]) #[[ATTR0]] {\n-; SSE-NEXT:    [[LD0:%.*]] = load <4 x double>, ptr [[P0]], align 32\n-; SSE-NEXT:    [[LD1:%.*]] = load <4 x double>, ptr [[P1]], align 32\n-; SSE-NEXT:    [[BLEND:%.*]] = shufflevector <4 x double> [[LD0]], <4 x double> [[LD1]], <4 x i32> <i32 0, i32 4, i32 4, i32 0>\n-; SSE-NEXT:    ret <4 x double> [[BLEND]]\n-;\n-; AVX-LABEL: define <4 x double> @blend_broadcasts_v4f64(\n-; AVX-SAME: ptr [[P0:%.*]], ptr [[P1:%.*]]) #[[ATTR0]] {\n-; AVX-NEXT:    [[LD0:%.*]] = load <4 x double>, ptr [[P0]], align 32\n-; AVX-NEXT:    [[LD1:%.*]] = load <4 x double>, ptr [[P1]], align 32\n-; AVX-NEXT:    [[BCST0:%.*]] = shufflevector <4 x double> [[LD0]], <4 x double> undef, <4 x i32> zeroinitializer\n-; AVX-NEXT:    [[BCST1:%.*]] = shufflevector <4 x double> [[LD1]], <4 x double> undef, <4 x i32> zeroinitializer\n-; AVX-NEXT:    [[BLEND:%.*]] = shufflevector <4 x double> [[BCST0]], <4 x double> [[BCST1]], <4 x i32> <i32 0, i32 5, i32 6, i32 3>\n-; AVX-NEXT:    ret <4 x double> [[BLEND]]\n+; CHECK-LABEL: define <4 x double> @blend_broadcasts_v4f64(\n+; CHECK-SAME: ptr [[P0:%.*]], ptr [[P1:%.*]]) #[[ATTR0]] {\n+; CHECK-NEXT:    [[TMP1:%.*]] = load <1 x double>, ptr [[P0]], align 32\n+; CHECK-NEXT:    [[TMP2:%.*]] = load <1 x double>, ptr [[P1]], align 32\n+; CHECK-NEXT:    [[BLEND:%.*]] = shufflevector <1 x double> [[TMP1]], <1 x double> [[TMP2]], <4 x i32> <i32 0, i32 1, i32 1, i32 0>\n+; CHECK-NEXT:    ret <4 x double> [[BLEND]]\n ;",
        "comment_created_at": "2025-04-01T10:11:05+00:00",
        "comment_author": "PeddleSpam",
        "comment_body": "The blend gets folded in `VectorCombine::foldShuffleOfShuffles`. It thinks the cost of this transform is lower.\r\nIs there a way to improve the cost modelling here, and should it be a separate patch?",
        "pr_file_module": null
      },
      {
        "comment_id": "2043806022",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 128938,
        "pr_file": "llvm/test/Transforms/VectorCombine/X86/shuffle-of-shuffles.ll",
        "discussion_id": "2014821680",
        "commented_code": "@@ -47,21 +47,12 @@ define <8 x i32> @concat_extract_subvectors_poison(<8 x i32> %x) {\n ; broadcast loads are free on AVX (and blends are much cheap than general 2-operand shuffles)\n \n define  <4 x double> @blend_broadcasts_v4f64(ptr %p0, ptr %p1)  {\n-; SSE-LABEL: define <4 x double> @blend_broadcasts_v4f64(\n-; SSE-SAME: ptr [[P0:%.*]], ptr [[P1:%.*]]) #[[ATTR0]] {\n-; SSE-NEXT:    [[LD0:%.*]] = load <4 x double>, ptr [[P0]], align 32\n-; SSE-NEXT:    [[LD1:%.*]] = load <4 x double>, ptr [[P1]], align 32\n-; SSE-NEXT:    [[BLEND:%.*]] = shufflevector <4 x double> [[LD0]], <4 x double> [[LD1]], <4 x i32> <i32 0, i32 4, i32 4, i32 0>\n-; SSE-NEXT:    ret <4 x double> [[BLEND]]\n-;\n-; AVX-LABEL: define <4 x double> @blend_broadcasts_v4f64(\n-; AVX-SAME: ptr [[P0:%.*]], ptr [[P1:%.*]]) #[[ATTR0]] {\n-; AVX-NEXT:    [[LD0:%.*]] = load <4 x double>, ptr [[P0]], align 32\n-; AVX-NEXT:    [[LD1:%.*]] = load <4 x double>, ptr [[P1]], align 32\n-; AVX-NEXT:    [[BCST0:%.*]] = shufflevector <4 x double> [[LD0]], <4 x double> undef, <4 x i32> zeroinitializer\n-; AVX-NEXT:    [[BCST1:%.*]] = shufflevector <4 x double> [[LD1]], <4 x double> undef, <4 x i32> zeroinitializer\n-; AVX-NEXT:    [[BLEND:%.*]] = shufflevector <4 x double> [[BCST0]], <4 x double> [[BCST1]], <4 x i32> <i32 0, i32 5, i32 6, i32 3>\n-; AVX-NEXT:    ret <4 x double> [[BLEND]]\n+; CHECK-LABEL: define <4 x double> @blend_broadcasts_v4f64(\n+; CHECK-SAME: ptr [[P0:%.*]], ptr [[P1:%.*]]) #[[ATTR0]] {\n+; CHECK-NEXT:    [[TMP1:%.*]] = load <1 x double>, ptr [[P0]], align 32\n+; CHECK-NEXT:    [[TMP2:%.*]] = load <1 x double>, ptr [[P1]], align 32\n+; CHECK-NEXT:    [[BLEND:%.*]] = shufflevector <1 x double> [[TMP1]], <1 x double> [[TMP2]], <4 x i32> <i32 0, i32 1, i32 1, i32 0>\n+; CHECK-NEXT:    ret <4 x double> [[BLEND]]\n ;",
        "comment_created_at": "2025-04-15T07:05:54+00:00",
        "comment_author": "PeddleSpam",
        "comment_body": "I've created #135753 to fix this regression.",
        "pr_file_module": null
      }
    ]
  }
]