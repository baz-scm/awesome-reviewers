[
  {
    "discussion_id": "2211614024",
    "pr_number": 148013,
    "pr_file": "llvm/tools/llvm-profgen/ProfiledBinary.cpp",
    "created_at": "2025-07-16T21:07:19+00:00",
    "commented_code": "return CallStack;\n }\n \n+StringRef ProfiledBinary::symbolizeDataAddress(uint64_t Address) {\n+  DIGlobal DataDIGlobal = unwrapOrError(\n+      Symbolizer->symbolizeData(SymbolizerPath.str(), {Address, 0}),",
    "repo_full_name": "llvm/llvm-project",
    "discussion_comments": [
      {
        "comment_id": "2211614024",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148013,
        "pr_file": "llvm/tools/llvm-profgen/ProfiledBinary.cpp",
        "discussion_id": "2211614024",
        "commented_code": "@@ -946,6 +978,14 @@ SampleContextFrameVector ProfiledBinary::symbolize(const InstructionPointer &IP,\n   return CallStack;\n }\n \n+StringRef ProfiledBinary::symbolizeDataAddress(uint64_t Address) {\n+  DIGlobal DataDIGlobal = unwrapOrError(\n+      Symbolizer->symbolizeData(SymbolizerPath.str(), {Address, 0}),",
        "comment_created_at": "2025-07-16T21:07:19+00:00",
        "comment_author": "snehasish",
        "comment_body": "Whats the 0 passed as a the second param in the tuple?",
        "pr_file_module": null
      },
      {
        "comment_id": "2216760381",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148013,
        "pr_file": "llvm/tools/llvm-profgen/ProfiledBinary.cpp",
        "discussion_id": "2211614024",
        "commented_code": "@@ -946,6 +978,14 @@ SampleContextFrameVector ProfiledBinary::symbolize(const InstructionPointer &IP,\n   return CallStack;\n }\n \n+StringRef ProfiledBinary::symbolizeDataAddress(uint64_t Address) {\n+  DIGlobal DataDIGlobal = unwrapOrError(\n+      Symbolizer->symbolizeData(SymbolizerPath.str(), {Address, 0}),",
        "comment_created_at": "2025-07-18T19:09:53+00:00",
        "comment_author": "mingmingl-llvm",
        "comment_body": "LLVMSymbolizer's symbolize* interfaces [1]  require a struct of `object::SectionedAddress` [2] to symbolize an address, like, they don't take an integer of address alone. Chasing down the calls  [3], `sectionIndex` field isn't used so its value doesn't matter [4].\n\nUpon this question, it's better to use `UndefSection`  [5] here. Added a static helper function `getSectionedAddress` for this purpose, and use it for both code and data inside `ProfiledBinary` class.\n\n\n[1] for [data](https://github.com/llvm/llvm-project/blob/13f7786f72d13a84dfc3d49d87a70e6a05f21fd4/llvm/include/llvm/DebugInfo/Symbolize/Symbolize.h#L98-L104) and [code](https://github.com/llvm/llvm-project/blob/13f7786f72d13a84dfc3d49d87a70e6a05f21fd4/llvm/include/llvm/DebugInfo/Symbolize/Symbolize.h#L80-L87)\n\n[2] \n\nhttps://github.com/llvm/llvm-project/blob/13f7786f72d13a84dfc3d49d87a70e6a05f21fd4/llvm/include/llvm/Object/ObjectFile.h#L146-L151\n\n[3] https://github.com/llvm/llvm-project/blob/13f7786f72d13a84dfc3d49d87a70e6a05f21fd4/llvm/lib/DebugInfo/Symbolize/Symbolize.cpp#L155-L178 \n\n[4] https://github.com/llvm/llvm-project/blob/13f7786f72d13a84dfc3d49d87a70e6a05f21fd4/llvm/lib/DebugInfo/DWARF/DWARFContext.cpp#L1753-L1766\n\n[5] https://github.com/llvm/llvm-project/blob/13f7786f72d13a84dfc3d49d87a70e6a05f21fd4/llvm/include/llvm/Object/ObjectFile.h#L146-L147\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2222493406",
    "pr_number": 148257,
    "pr_file": "mlir/lib/Conversion/MemRefToEmitC/MemRefToEmitCPass.cpp",
    "created_at": "2025-07-22T13:13:26+00:00",
    "commented_code": ": public impl::ConvertMemRefToEmitCBase<ConvertMemRefToEmitCPass> {\n   void runOnOperation() override {\n     TypeConverter converter;\n+    mlir::ModuleOp module = getOperation();\n+    module.walk([&](mlir::Operation *op) {\n+      if (llvm::isa<mlir::memref::AllocOp, mlir::memref::CopyOp>(op)) {\n+        OpBuilder builder(module.getBody(), module.getBody()->begin());\n+        builder.create<emitc::IncludeOp>(module.getLoc(),\n+                                         builder.getStringAttr(\"stdlib.h\"));",
    "repo_full_name": "llvm/llvm-project",
    "discussion_comments": [
      {
        "comment_id": "2222493406",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148257,
        "pr_file": "mlir/lib/Conversion/MemRefToEmitC/MemRefToEmitCPass.cpp",
        "discussion_id": "2222493406",
        "commented_code": "@@ -30,6 +30,16 @@ struct ConvertMemRefToEmitCPass\n     : public impl::ConvertMemRefToEmitCBase<ConvertMemRefToEmitCPass> {\n   void runOnOperation() override {\n     TypeConverter converter;\n+    mlir::ModuleOp module = getOperation();\n+    module.walk([&](mlir::Operation *op) {\n+      if (llvm::isa<mlir::memref::AllocOp, mlir::memref::CopyOp>(op)) {\n+        OpBuilder builder(module.getBody(), module.getBody()->begin());\n+        builder.create<emitc::IncludeOp>(module.getLoc(),\n+                                         builder.getStringAttr(\"stdlib.h\"));",
        "comment_created_at": "2025-07-22T13:13:26+00:00",
        "comment_author": "marbre",
        "comment_body": "If one wants to generate C++ code this would need to be\r\n```suggestion\r\n                                         builder.getStringAttr(\"cstdlib\"));\r\n```\r\nMaybe it is worth to add an optional flag to determine if the pass should lower to C or C++.\r\n\r\nFurthermore, this should probably have the `is_standard_include` attribute set (https://mlir.llvm.org/docs/Dialects/EmitC/#attributes-14).\r\n\r\nis_standard_include\t",
        "pr_file_module": null
      },
      {
        "comment_id": "2225151642",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148257,
        "pr_file": "mlir/lib/Conversion/MemRefToEmitC/MemRefToEmitCPass.cpp",
        "discussion_id": "2222493406",
        "commented_code": "@@ -30,6 +30,16 @@ struct ConvertMemRefToEmitCPass\n     : public impl::ConvertMemRefToEmitCBase<ConvertMemRefToEmitCPass> {\n   void runOnOperation() override {\n     TypeConverter converter;\n+    mlir::ModuleOp module = getOperation();\n+    module.walk([&](mlir::Operation *op) {\n+      if (llvm::isa<mlir::memref::AllocOp, mlir::memref::CopyOp>(op)) {\n+        OpBuilder builder(module.getBody(), module.getBody()->begin());\n+        builder.create<emitc::IncludeOp>(module.getLoc(),\n+                                         builder.getStringAttr(\"stdlib.h\"));",
        "comment_created_at": "2025-07-23T10:53:03+00:00",
        "comment_author": "aniragil",
        "comment_body": "IIUC C-style `#include \"stdlib.h\"` works for C++, only difference is that functions are placed in the global namespace rather `std`.\r\nI'm +1 on adding a flag, not sure it should be part of this commit as it should enforce unrelated C++ restrictions, e.g. multiple return values and tensor types. Can we leave a TODO here for when we have such a flag?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2228532084",
    "pr_number": 148877,
    "pr_file": "lldb/source/Expression/IRExecutionUnit.cpp",
    "created_at": "2025-07-24T13:30:03+00:00",
    "commented_code": "lldb::addr_t m_best_internal_load_address = LLDB_INVALID_ADDRESS;\n };\n \n+/// Returns address of the function referred to by the special function call\n+/// label \\c label.\n+///\n+/// \\param[in] label Function call label encoding the unique location of the\n+/// function to look up.\n+///                  Assumes that the \\c FunctionCallLabelPrefix has been\n+///                  stripped from the front of the label.\n+static llvm::Expected<lldb::addr_t>\n+ResolveFunctionCallLabel(llvm::StringRef name,\n+                         const lldb_private::SymbolContext &sc,\n+                         bool &symbol_was_missing_weak) {\n+  symbol_was_missing_weak = false;\n+\n+  if (!sc.target_sp)\n+    return llvm::createStringError(\"target not available.\");\n+\n+  auto ts_or_err = sc.target_sp->GetScratchTypeSystemForLanguage(\n+      lldb::eLanguageTypeC_plus_plus);",
    "repo_full_name": "llvm/llvm-project",
    "discussion_comments": [
      {
        "comment_id": "2228532084",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148877,
        "pr_file": "lldb/source/Expression/IRExecutionUnit.cpp",
        "discussion_id": "2228532084",
        "commented_code": "@@ -771,6 +774,63 @@ class LoadAddressResolver {\n   lldb::addr_t m_best_internal_load_address = LLDB_INVALID_ADDRESS;\n };\n \n+/// Returns address of the function referred to by the special function call\n+/// label \\c label.\n+///\n+/// \\param[in] label Function call label encoding the unique location of the\n+/// function to look up.\n+///                  Assumes that the \\c FunctionCallLabelPrefix has been\n+///                  stripped from the front of the label.\n+static llvm::Expected<lldb::addr_t>\n+ResolveFunctionCallLabel(llvm::StringRef name,\n+                         const lldb_private::SymbolContext &sc,\n+                         bool &symbol_was_missing_weak) {\n+  symbol_was_missing_weak = false;\n+\n+  if (!sc.target_sp)\n+    return llvm::createStringError(\"target not available.\");\n+\n+  auto ts_or_err = sc.target_sp->GetScratchTypeSystemForLanguage(\n+      lldb::eLanguageTypeC_plus_plus);",
        "comment_created_at": "2025-07-24T13:30:03+00:00",
        "comment_author": "labath",
        "comment_body": "I'm not sure it makes sense to involve the type system here. At this point, do you even know if you're running a c++ expression?\r\n\r\nIs there any harm in making this mangling scheme global? We can always change it or even add some language identifier if needed.\r\n\r\nAlternatively, we could make each module responsible for its own mangling scheme. We could just parse out the module ID here and then pass the rest of the string verbatim.",
        "pr_file_module": null
      },
      {
        "comment_id": "2230490387",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148877,
        "pr_file": "lldb/source/Expression/IRExecutionUnit.cpp",
        "discussion_id": "2228532084",
        "commented_code": "@@ -771,6 +774,63 @@ class LoadAddressResolver {\n   lldb::addr_t m_best_internal_load_address = LLDB_INVALID_ADDRESS;\n };\n \n+/// Returns address of the function referred to by the special function call\n+/// label \\c label.\n+///\n+/// \\param[in] label Function call label encoding the unique location of the\n+/// function to look up.\n+///                  Assumes that the \\c FunctionCallLabelPrefix has been\n+///                  stripped from the front of the label.\n+static llvm::Expected<lldb::addr_t>\n+ResolveFunctionCallLabel(llvm::StringRef name,\n+                         const lldb_private::SymbolContext &sc,\n+                         bool &symbol_was_missing_weak) {\n+  symbol_was_missing_weak = false;\n+\n+  if (!sc.target_sp)\n+    return llvm::createStringError(\"target not available.\");\n+\n+  auto ts_or_err = sc.target_sp->GetScratchTypeSystemForLanguage(\n+      lldb::eLanguageTypeC_plus_plus);",
        "comment_created_at": "2025-07-25T08:23:57+00:00",
        "comment_author": "Michael137",
        "comment_body": "The reason I made it `TypeSystemClang` specific is that in the follow-up patch to support constructor/destructor variants (https://github.com/llvm/llvm-project/pull/149827) I plan to put a Clang type into the `FunctionCallLabel` structure. Of course I could avoid pulling Clang in by using plain integers instead of (`clang::CXXCtorType`/`clang::CXXDtorType`). Not sure if we get here outside of expression evaluation, but happy to hoist this to somewhere more global.\r\n\r\nDo you prefer me move this out of `TypeSystem` and into `Expression` (or something similar). And we can refactor it if needed for the constructor/destructor patch?",
        "pr_file_module": null
      },
      {
        "comment_id": "2230792555",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148877,
        "pr_file": "lldb/source/Expression/IRExecutionUnit.cpp",
        "discussion_id": "2228532084",
        "commented_code": "@@ -771,6 +774,63 @@ class LoadAddressResolver {\n   lldb::addr_t m_best_internal_load_address = LLDB_INVALID_ADDRESS;\n };\n \n+/// Returns address of the function referred to by the special function call\n+/// label \\c label.\n+///\n+/// \\param[in] label Function call label encoding the unique location of the\n+/// function to look up.\n+///                  Assumes that the \\c FunctionCallLabelPrefix has been\n+///                  stripped from the front of the label.\n+static llvm::Expected<lldb::addr_t>\n+ResolveFunctionCallLabel(llvm::StringRef name,\n+                         const lldb_private::SymbolContext &sc,\n+                         bool &symbol_was_missing_weak) {\n+  symbol_was_missing_weak = false;\n+\n+  if (!sc.target_sp)\n+    return llvm::createStringError(\"target not available.\");\n+\n+  auto ts_or_err = sc.target_sp->GetScratchTypeSystemForLanguage(\n+      lldb::eLanguageTypeC_plus_plus);",
        "comment_created_at": "2025-07-25T10:55:16+00:00",
        "comment_author": "labath",
        "comment_body": "I don't think we want to put clang-specific types into the generic FunctionCallLabel structure. If you want that, then the struct itself should by plugin-specific. I think that'd would be doable if you make the generic code treat the label.. generically (as a string I guess). The parsing would then happen inside the SymbolFile, which can know the encoding scheme used, the language and what not. In this world, it may make sense for this code to live in the type system, but then I'd make sure it's called from the SymbolFile class, and not directly from generic code.\r\n\r\nHowever, I think that keeping the struct generic is also a viable option. We just need to avoid language and plugin-specific terms. For the structor type field, we could just say we have an additional \"discriminator\" field which the plugin can use to discriminate different \"variants\" of the given function. In this world, the label parsing should not be in a plugin. It could be just a method defined in Expression.h, next to the struct definition.",
        "pr_file_module": null
      },
      {
        "comment_id": "2231535069",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 148877,
        "pr_file": "lldb/source/Expression/IRExecutionUnit.cpp",
        "discussion_id": "2228532084",
        "commented_code": "@@ -771,6 +774,63 @@ class LoadAddressResolver {\n   lldb::addr_t m_best_internal_load_address = LLDB_INVALID_ADDRESS;\n };\n \n+/// Returns address of the function referred to by the special function call\n+/// label \\c label.\n+///\n+/// \\param[in] label Function call label encoding the unique location of the\n+/// function to look up.\n+///                  Assumes that the \\c FunctionCallLabelPrefix has been\n+///                  stripped from the front of the label.\n+static llvm::Expected<lldb::addr_t>\n+ResolveFunctionCallLabel(llvm::StringRef name,\n+                         const lldb_private::SymbolContext &sc,\n+                         bool &symbol_was_missing_weak) {\n+  symbol_was_missing_weak = false;\n+\n+  if (!sc.target_sp)\n+    return llvm::createStringError(\"target not available.\");\n+\n+  auto ts_or_err = sc.target_sp->GetScratchTypeSystemForLanguage(\n+      lldb::eLanguageTypeC_plus_plus);",
        "comment_created_at": "2025-07-25T16:13:45+00:00",
        "comment_author": "Michael137",
        "comment_body": "Yea happy to do that instead. That was what my first iteration of the patch did. I'll add a \"uint64_t discriminator\" field here instead. And pass the `FunctionCallLabel` structure into the SymbolFile instead of the individual components. Makes things much simpler",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2124241865",
    "pr_number": 142541,
    "pr_file": "clang/lib/AST/ExprObjC.cpp",
    "created_at": "2025-06-03T15:27:37+00:00",
    "commented_code": "return Ctx.getReferenceQualifiedType(this);\n }\n \n+std::pair<const NamedDecl *, const Attr *>",
    "repo_full_name": "llvm/llvm-project",
    "discussion_comments": [
      {
        "comment_id": "2124241865",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 142541,
        "pr_file": "clang/lib/AST/ExprObjC.cpp",
        "discussion_id": "2124241865",
        "commented_code": "@@ -272,6 +273,26 @@ QualType ObjCMessageExpr::getCallReturnType(ASTContext &Ctx) const {\n   return Ctx.getReferenceQualifiedType(this);\n }\n \n+std::pair<const NamedDecl *, const Attr *>",
        "comment_created_at": "2025-06-03T15:27:37+00:00",
        "comment_author": "erichkeane",
        "comment_body": "Since we're casting back and forth always, should this be:\r\n```suggestion\r\nstd::pair<const NamedDecl *, const WarnUnusedResultAttr *>\r\n```\r\n?",
        "pr_file_module": null
      },
      {
        "comment_id": "2131387754",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 142541,
        "pr_file": "clang/lib/AST/ExprObjC.cpp",
        "discussion_id": "2124241865",
        "commented_code": "@@ -272,6 +273,26 @@ QualType ObjCMessageExpr::getCallReturnType(ASTContext &Ctx) const {\n   return Ctx.getReferenceQualifiedType(this);\n }\n \n+std::pair<const NamedDecl *, const Attr *>",
        "comment_created_at": "2025-06-06T02:42:18+00:00",
        "comment_author": "halbi2",
        "comment_body": "It is this way in CallExpr::getUnusedResultAttr too. I would change it in both places?\r\nMaybe is this way so that different Attrs can be supported in the future, not just WarnUnusedResultAttrs.",
        "pr_file_module": null
      },
      {
        "comment_id": "2132141253",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 142541,
        "pr_file": "clang/lib/AST/ExprObjC.cpp",
        "discussion_id": "2124241865",
        "commented_code": "@@ -272,6 +273,26 @@ QualType ObjCMessageExpr::getCallReturnType(ASTContext &Ctx) const {\n   return Ctx.getReferenceQualifiedType(this);\n }\n \n+std::pair<const NamedDecl *, const Attr *>",
        "comment_created_at": "2025-06-06T12:51:44+00:00",
        "comment_author": "erichkeane",
        "comment_body": "I think we're decades past 'maybe we'll support other kinds some day' :D  \r\n\r\nIf you're willing to do the change on `CallExpr` at the same time, please do.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2198250199",
    "pr_number": 147961,
    "pr_file": "mlir/lib/Dialect/Linalg/Transforms/TransposeMatmul.cpp",
    "created_at": "2025-07-10T16:58:20+00:00",
    "commented_code": "dynamicDims);\n   auto transposeOp = rewriter.create<linalg::TransposeOp>(\n       loc, input, empty, ArrayRef<int64_t>{1, 0});\n-  Operation *newMatmulOp;\n+  Value newLHS, newRHS;\n+  AffineMap mapLHS, mapRHS, mapOut;\n+  AffineExpr d0, d1, d2;\n+  auto context = rewriter.getContext();\n+  bindDims(context, d0, d1, d2);\n   if (transposeLHS) {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeAOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{transposeOp->getResult(0), matmulOp.getInputs()[1]},\n-        matmulOp.getOutputs());\n+    newLHS = transposeOp->getResult(0);\n+    newRHS = matmulOp.getInputs()[1];\n+    mapLHS = AffineMap::get(3, 0, {d2, d0}, context);\n+    mapRHS = AffineMap::get(3, 0, {d2, d1}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);\n   } else {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeBOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{matmulOp.getInputs()[0], transposeOp->getResult(0)},\n-        matmulOp.getOutputs());\n+    newLHS = matmulOp.getInputs()[0];\n+    newRHS = transposeOp->getResult(0);\n+    mapLHS = AffineMap::get(3, 0, {d0, d2}, context);\n+    mapRHS = AffineMap::get(3, 0, {d1, d2}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);",
    "repo_full_name": "llvm/llvm-project",
    "discussion_comments": [
      {
        "comment_id": "2198250199",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 147961,
        "pr_file": "mlir/lib/Dialect/Linalg/Transforms/TransposeMatmul.cpp",
        "discussion_id": "2198250199",
        "commented_code": "@@ -57,18 +58,31 @@ FailureOr<Operation *> mlir::linalg::transposeMatmul(RewriterBase &rewriter,\n       dynamicDims);\n   auto transposeOp = rewriter.create<linalg::TransposeOp>(\n       loc, input, empty, ArrayRef<int64_t>{1, 0});\n-  Operation *newMatmulOp;\n+  Value newLHS, newRHS;\n+  AffineMap mapLHS, mapRHS, mapOut;\n+  AffineExpr d0, d1, d2;\n+  auto context = rewriter.getContext();\n+  bindDims(context, d0, d1, d2);\n   if (transposeLHS) {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeAOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{transposeOp->getResult(0), matmulOp.getInputs()[1]},\n-        matmulOp.getOutputs());\n+    newLHS = transposeOp->getResult(0);\n+    newRHS = matmulOp.getInputs()[1];\n+    mapLHS = AffineMap::get(3, 0, {d2, d0}, context);\n+    mapRHS = AffineMap::get(3, 0, {d2, d1}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);\n   } else {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeBOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{matmulOp.getInputs()[0], transposeOp->getResult(0)},\n-        matmulOp.getOutputs());\n+    newLHS = matmulOp.getInputs()[0];\n+    newRHS = transposeOp->getResult(0);\n+    mapLHS = AffineMap::get(3, 0, {d0, d2}, context);\n+    mapRHS = AffineMap::get(3, 0, {d1, d2}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);",
        "comment_created_at": "2025-07-10T16:58:20+00:00",
        "comment_author": "qedawkins",
        "comment_body": "Rather than requiring all builders to be replaced everywhere, we can add C++ specializations as intermediate replacements similar to ConstantIndexOp: https://github.com/llvm/llvm-project/blob/9a0e03f430dec4634086fe8315c4c3b730bd7c66/mlir/include/mlir/Dialect/Arith/IR/Arith.h#L96-L109",
        "pr_file_module": null
      },
      {
        "comment_id": "2198251603",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 147961,
        "pr_file": "mlir/lib/Dialect/Linalg/Transforms/TransposeMatmul.cpp",
        "discussion_id": "2198250199",
        "commented_code": "@@ -57,18 +58,31 @@ FailureOr<Operation *> mlir::linalg::transposeMatmul(RewriterBase &rewriter,\n       dynamicDims);\n   auto transposeOp = rewriter.create<linalg::TransposeOp>(\n       loc, input, empty, ArrayRef<int64_t>{1, 0});\n-  Operation *newMatmulOp;\n+  Value newLHS, newRHS;\n+  AffineMap mapLHS, mapRHS, mapOut;\n+  AffineExpr d0, d1, d2;\n+  auto context = rewriter.getContext();\n+  bindDims(context, d0, d1, d2);\n   if (transposeLHS) {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeAOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{transposeOp->getResult(0), matmulOp.getInputs()[1]},\n-        matmulOp.getOutputs());\n+    newLHS = transposeOp->getResult(0);\n+    newRHS = matmulOp.getInputs()[1];\n+    mapLHS = AffineMap::get(3, 0, {d2, d0}, context);\n+    mapRHS = AffineMap::get(3, 0, {d2, d1}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);\n   } else {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeBOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{matmulOp.getInputs()[0], transposeOp->getResult(0)},\n-        matmulOp.getOutputs());\n+    newLHS = matmulOp.getInputs()[0];\n+    newRHS = transposeOp->getResult(0);\n+    mapLHS = AffineMap::get(3, 0, {d0, d2}, context);\n+    mapRHS = AffineMap::get(3, 0, {d1, d2}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);",
        "comment_created_at": "2025-07-10T16:59:12+00:00",
        "comment_author": "qedawkins",
        "comment_body": "Pattern matching can't be replaced as easily, but we can add bespoke C++ for it like `matchMatmulTransposeB`",
        "pr_file_module": null
      },
      {
        "comment_id": "2198309692",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 147961,
        "pr_file": "mlir/lib/Dialect/Linalg/Transforms/TransposeMatmul.cpp",
        "discussion_id": "2198250199",
        "commented_code": "@@ -57,18 +58,31 @@ FailureOr<Operation *> mlir::linalg::transposeMatmul(RewriterBase &rewriter,\n       dynamicDims);\n   auto transposeOp = rewriter.create<linalg::TransposeOp>(\n       loc, input, empty, ArrayRef<int64_t>{1, 0});\n-  Operation *newMatmulOp;\n+  Value newLHS, newRHS;\n+  AffineMap mapLHS, mapRHS, mapOut;\n+  AffineExpr d0, d1, d2;\n+  auto context = rewriter.getContext();\n+  bindDims(context, d0, d1, d2);\n   if (transposeLHS) {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeAOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{transposeOp->getResult(0), matmulOp.getInputs()[1]},\n-        matmulOp.getOutputs());\n+    newLHS = transposeOp->getResult(0);\n+    newRHS = matmulOp.getInputs()[1];\n+    mapLHS = AffineMap::get(3, 0, {d2, d0}, context);\n+    mapRHS = AffineMap::get(3, 0, {d2, d1}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);\n   } else {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeBOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{matmulOp.getInputs()[0], transposeOp->getResult(0)},\n-        matmulOp.getOutputs());\n+    newLHS = matmulOp.getInputs()[0];\n+    newRHS = transposeOp->getResult(0);\n+    mapLHS = AffineMap::get(3, 0, {d0, d2}, context);\n+    mapRHS = AffineMap::get(3, 0, {d1, d2}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);",
        "comment_created_at": "2025-07-10T17:34:53+00:00",
        "comment_author": "rengolin",
        "comment_body": "Good point. Or we could actually just add a new builder with an affine map attribute?\r\n\r\nOn the pattern matching, I'm looking into something like this to help:\r\nhttps://github.com/libxsmm/tpp-mlir/blob/main/lib/TPP/IR/StructuredOpMatcher.cpp",
        "pr_file_module": null
      },
      {
        "comment_id": "2198394019",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 147961,
        "pr_file": "mlir/lib/Dialect/Linalg/Transforms/TransposeMatmul.cpp",
        "discussion_id": "2198250199",
        "commented_code": "@@ -57,18 +58,31 @@ FailureOr<Operation *> mlir::linalg::transposeMatmul(RewriterBase &rewriter,\n       dynamicDims);\n   auto transposeOp = rewriter.create<linalg::TransposeOp>(\n       loc, input, empty, ArrayRef<int64_t>{1, 0});\n-  Operation *newMatmulOp;\n+  Value newLHS, newRHS;\n+  AffineMap mapLHS, mapRHS, mapOut;\n+  AffineExpr d0, d1, d2;\n+  auto context = rewriter.getContext();\n+  bindDims(context, d0, d1, d2);\n   if (transposeLHS) {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeAOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{transposeOp->getResult(0), matmulOp.getInputs()[1]},\n-        matmulOp.getOutputs());\n+    newLHS = transposeOp->getResult(0);\n+    newRHS = matmulOp.getInputs()[1];\n+    mapLHS = AffineMap::get(3, 0, {d2, d0}, context);\n+    mapRHS = AffineMap::get(3, 0, {d2, d1}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);\n   } else {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeBOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{matmulOp.getInputs()[0], transposeOp->getResult(0)},\n-        matmulOp.getOutputs());\n+    newLHS = matmulOp.getInputs()[0];\n+    newRHS = transposeOp->getResult(0);\n+    mapLHS = AffineMap::get(3, 0, {d0, d2}, context);\n+    mapRHS = AffineMap::get(3, 0, {d1, d2}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);",
        "comment_created_at": "2025-07-10T18:17:26+00:00",
        "comment_author": "qedawkins",
        "comment_body": "The point of adding a specialization would be to skip the need for callers to construct affine maps. IOW no C++ changes at the point of operation construction, only the underlying IR generated.",
        "pr_file_module": null
      },
      {
        "comment_id": "2198602691",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 147961,
        "pr_file": "mlir/lib/Dialect/Linalg/Transforms/TransposeMatmul.cpp",
        "discussion_id": "2198250199",
        "commented_code": "@@ -57,18 +58,31 @@ FailureOr<Operation *> mlir::linalg::transposeMatmul(RewriterBase &rewriter,\n       dynamicDims);\n   auto transposeOp = rewriter.create<linalg::TransposeOp>(\n       loc, input, empty, ArrayRef<int64_t>{1, 0});\n-  Operation *newMatmulOp;\n+  Value newLHS, newRHS;\n+  AffineMap mapLHS, mapRHS, mapOut;\n+  AffineExpr d0, d1, d2;\n+  auto context = rewriter.getContext();\n+  bindDims(context, d0, d1, d2);\n   if (transposeLHS) {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeAOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{transposeOp->getResult(0), matmulOp.getInputs()[1]},\n-        matmulOp.getOutputs());\n+    newLHS = transposeOp->getResult(0);\n+    newRHS = matmulOp.getInputs()[1];\n+    mapLHS = AffineMap::get(3, 0, {d2, d0}, context);\n+    mapRHS = AffineMap::get(3, 0, {d2, d1}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);\n   } else {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeBOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{matmulOp.getInputs()[0], transposeOp->getResult(0)},\n-        matmulOp.getOutputs());\n+    newLHS = matmulOp.getInputs()[0];\n+    newRHS = transposeOp->getResult(0);\n+    mapLHS = AffineMap::get(3, 0, {d0, d2}, context);\n+    mapRHS = AffineMap::get(3, 0, {d1, d2}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);",
        "comment_created_at": "2025-07-10T19:57:36+00:00",
        "comment_author": "rengolin",
        "comment_body": "Right. _\"Technically\"_, users can pass whatever affine maps (that make sense), but you're right that we don't want people to have to remember all variations and have them on the code like that.\r\n\r\nLast year we discuss an attribute like `transpose_a` and `transpose_b`. That was not a good idea, because the affine map is mandatory and cover all those cases. But we can still have it in a builder, right? Like an enum that can work across all `matmul` variants (but not `contract`)?\r\n\r\n```C++\r\n  builder.create<linalg::MatmulOp>(..., transpose_a | broadcast_b);\r\n```\r\n\r\nI'm trying to avoid creating a specialization to all combinations, if you notice. :smile: ",
        "pr_file_module": null
      },
      {
        "comment_id": "2198679051",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 147961,
        "pr_file": "mlir/lib/Dialect/Linalg/Transforms/TransposeMatmul.cpp",
        "discussion_id": "2198250199",
        "commented_code": "@@ -57,18 +58,31 @@ FailureOr<Operation *> mlir::linalg::transposeMatmul(RewriterBase &rewriter,\n       dynamicDims);\n   auto transposeOp = rewriter.create<linalg::TransposeOp>(\n       loc, input, empty, ArrayRef<int64_t>{1, 0});\n-  Operation *newMatmulOp;\n+  Value newLHS, newRHS;\n+  AffineMap mapLHS, mapRHS, mapOut;\n+  AffineExpr d0, d1, d2;\n+  auto context = rewriter.getContext();\n+  bindDims(context, d0, d1, d2);\n   if (transposeLHS) {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeAOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{transposeOp->getResult(0), matmulOp.getInputs()[1]},\n-        matmulOp.getOutputs());\n+    newLHS = transposeOp->getResult(0);\n+    newRHS = matmulOp.getInputs()[1];\n+    mapLHS = AffineMap::get(3, 0, {d2, d0}, context);\n+    mapRHS = AffineMap::get(3, 0, {d2, d1}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);\n   } else {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeBOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{matmulOp.getInputs()[0], transposeOp->getResult(0)},\n-        matmulOp.getOutputs());\n+    newLHS = matmulOp.getInputs()[0];\n+    newRHS = transposeOp->getResult(0);\n+    mapLHS = AffineMap::get(3, 0, {d0, d2}, context);\n+    mapRHS = AffineMap::get(3, 0, {d1, d2}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);",
        "comment_created_at": "2025-07-10T20:37:57+00:00",
        "comment_author": "qedawkins",
        "comment_body": "> builder.create<linalg::MatmulOp>(..., transpose_a | broadcast_b);\r\n\r\nThis sounds good too. I mainly want to minimize the number of places downstream users need to setup affine maps. A specialization would be completely no change, but enums would be pretty lightweight (I suspect every frontend will end up redesigning the same \"map generator\" util if we don't provide it).",
        "pr_file_module": null
      },
      {
        "comment_id": "2198812948",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 147961,
        "pr_file": "mlir/lib/Dialect/Linalg/Transforms/TransposeMatmul.cpp",
        "discussion_id": "2198250199",
        "commented_code": "@@ -57,18 +58,31 @@ FailureOr<Operation *> mlir::linalg::transposeMatmul(RewriterBase &rewriter,\n       dynamicDims);\n   auto transposeOp = rewriter.create<linalg::TransposeOp>(\n       loc, input, empty, ArrayRef<int64_t>{1, 0});\n-  Operation *newMatmulOp;\n+  Value newLHS, newRHS;\n+  AffineMap mapLHS, mapRHS, mapOut;\n+  AffineExpr d0, d1, d2;\n+  auto context = rewriter.getContext();\n+  bindDims(context, d0, d1, d2);\n   if (transposeLHS) {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeAOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{transposeOp->getResult(0), matmulOp.getInputs()[1]},\n-        matmulOp.getOutputs());\n+    newLHS = transposeOp->getResult(0);\n+    newRHS = matmulOp.getInputs()[1];\n+    mapLHS = AffineMap::get(3, 0, {d2, d0}, context);\n+    mapRHS = AffineMap::get(3, 0, {d2, d1}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);\n   } else {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeBOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{matmulOp.getInputs()[0], transposeOp->getResult(0)},\n-        matmulOp.getOutputs());\n+    newLHS = matmulOp.getInputs()[0];\n+    newRHS = transposeOp->getResult(0);\n+    mapLHS = AffineMap::get(3, 0, {d0, d2}, context);\n+    mapRHS = AffineMap::get(3, 0, {d1, d2}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);",
        "comment_created_at": "2025-07-10T21:43:48+00:00",
        "comment_author": "rengolin",
        "comment_body": "Even the enum for the \"more generic\" case and specialization (using the enums) for the existing cases would be the least churn.\r\n\r\nEdit: I'll start with the specialization for the ones we had, and then we think about the future.",
        "pr_file_module": null
      },
      {
        "comment_id": "2201357887",
        "repo_full_name": "llvm/llvm-project",
        "pr_number": 147961,
        "pr_file": "mlir/lib/Dialect/Linalg/Transforms/TransposeMatmul.cpp",
        "discussion_id": "2198250199",
        "commented_code": "@@ -57,18 +58,31 @@ FailureOr<Operation *> mlir::linalg::transposeMatmul(RewriterBase &rewriter,\n       dynamicDims);\n   auto transposeOp = rewriter.create<linalg::TransposeOp>(\n       loc, input, empty, ArrayRef<int64_t>{1, 0});\n-  Operation *newMatmulOp;\n+  Value newLHS, newRHS;\n+  AffineMap mapLHS, mapRHS, mapOut;\n+  AffineExpr d0, d1, d2;\n+  auto context = rewriter.getContext();\n+  bindDims(context, d0, d1, d2);\n   if (transposeLHS) {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeAOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{transposeOp->getResult(0), matmulOp.getInputs()[1]},\n-        matmulOp.getOutputs());\n+    newLHS = transposeOp->getResult(0);\n+    newRHS = matmulOp.getInputs()[1];\n+    mapLHS = AffineMap::get(3, 0, {d2, d0}, context);\n+    mapRHS = AffineMap::get(3, 0, {d2, d1}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);\n   } else {\n-    newMatmulOp = rewriter.create<linalg::MatmulTransposeBOp>(\n-        loc, matmulOp.getResultTypes(),\n-        ValueRange{matmulOp.getInputs()[0], transposeOp->getResult(0)},\n-        matmulOp.getOutputs());\n+    newLHS = matmulOp.getInputs()[0];\n+    newRHS = transposeOp->getResult(0);\n+    mapLHS = AffineMap::get(3, 0, {d0, d2}, context);\n+    mapRHS = AffineMap::get(3, 0, {d1, d2}, context);\n+    mapOut = AffineMap::get(3, 0, {d0, d1}, context);",
        "comment_created_at": "2025-07-11T17:12:27+00:00",
        "comment_author": "rengolin",
        "comment_body": "Ok, turns out the specializations make the changes in `TransposeMatmul.cpp` moot, so I reverted and it's not back to the original file. This means anyone using the builders out there will continue to have the same behaviour. \r\n\r\nSo we're down to two problems: previous IR that needs regex-changing, and the pattern matchers. The IR changes are specific to each downstream, so better done in there as a one off. The pattern matchers will also be specific to usage and additional attributes, so can be on the downstreams until we figure a generic way to hold them all.",
        "pr_file_module": null
      }
    ]
  }
]