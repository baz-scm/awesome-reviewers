[
  {
    "discussion_id": "2234864169",
    "pr_number": 1166,
    "pr_file": "lmcache/v1/rpc_utils.py",
    "created_at": "2025-07-28T06:33:49+00:00",
    "commented_code": "# Third Party\n     import vllm.envs as envs\n \n+    if vllm_config is None or vllm_config.kv_transfer_config is None:\n+        raise ValueError(\"vllm_config with kv_transfer_config is required to determine the engine_id.\")\n+\n     base_url = envs.VLLM_RPC_BASE_PATH\n \n+    engine_id = vllm_config.kv_transfer_config.engine_id\n+\n     if isinstance(rpc_port, str):\n         rpc_port = rpc_port + str(tp_rank)\n     else:\n         rpc_port += tp_rank\n \n-    logger.debug(\"Base URL: %s, RPC Port: %s\", base_url, rpc_port)\n-    return f\"ipc://{base_url}/lmcache_rpc_port_{rpc_port}\"\n+    logger.debug(\"Base URL: %s, Engine: %d, RPC Port: %s\", base_url, engine_id, rpc_port)",
    "repo_full_name": "LMCache/LMCache",
    "discussion_comments": [
      {
        "comment_id": "2234864169",
        "repo_full_name": "LMCache/LMCache",
        "pr_number": 1166,
        "pr_file": "lmcache/v1/rpc_utils.py",
        "discussion_id": "2234864169",
        "commented_code": "@@ -94,12 +94,17 @@ def get_zmq_rpc_path_lmcache(\n     # Third Party\n     import vllm.envs as envs\n \n+    if vllm_config is None or vllm_config.kv_transfer_config is None:\n+        raise ValueError(\"vllm_config with kv_transfer_config is required to determine the engine_id.\")\n+\n     base_url = envs.VLLM_RPC_BASE_PATH\n \n+    engine_id = vllm_config.kv_transfer_config.engine_id\n+\n     if isinstance(rpc_port, str):\n         rpc_port = rpc_port + str(tp_rank)\n     else:\n         rpc_port += tp_rank\n \n-    logger.debug(\"Base URL: %s, RPC Port: %s\", base_url, rpc_port)\n-    return f\"ipc://{base_url}/lmcache_rpc_port_{rpc_port}\"\n+    logger.debug(\"Base URL: %s, Engine: %d, RPC Port: %s\", base_url, engine_id, rpc_port)",
        "comment_created_at": "2025-07-28T06:33:49+00:00",
        "comment_author": "maobaolong",
        "comment_body": "@Foreverythin  The root cause of this issue is that you didn't set the `rpc_port`, so each instance use the same `rpc_port`.\r\n\r\nI know it is not easy to use to set the `lmcache_rpc_port` while starting vLLM. So It indeed need a better way to instead of.\r\n\r\nSo I think your improvement is better than the original `lmcache_rpc_port`, so let's wait for the confirm from @ApostaC .\r\n\r\nApart from that, this LGTM. ",
        "pr_file_module": null
      },
      {
        "comment_id": "2237354123",
        "repo_full_name": "LMCache/LMCache",
        "pr_number": 1166,
        "pr_file": "lmcache/v1/rpc_utils.py",
        "discussion_id": "2234864169",
        "commented_code": "@@ -94,12 +94,17 @@ def get_zmq_rpc_path_lmcache(\n     # Third Party\n     import vllm.envs as envs\n \n+    if vllm_config is None or vllm_config.kv_transfer_config is None:\n+        raise ValueError(\"vllm_config with kv_transfer_config is required to determine the engine_id.\")\n+\n     base_url = envs.VLLM_RPC_BASE_PATH\n \n+    engine_id = vllm_config.kv_transfer_config.engine_id\n+\n     if isinstance(rpc_port, str):\n         rpc_port = rpc_port + str(tp_rank)\n     else:\n         rpc_port += tp_rank\n \n-    logger.debug(\"Base URL: %s, RPC Port: %s\", base_url, rpc_port)\n-    return f\"ipc://{base_url}/lmcache_rpc_port_{rpc_port}\"\n+    logger.debug(\"Base URL: %s, Engine: %d, RPC Port: %s\", base_url, engine_id, rpc_port)",
        "comment_created_at": "2025-07-28T17:21:52+00:00",
        "comment_author": "sammshen",
        "comment_body": "would it be correct that we can get rid of `rpc_port` if we are using the `engine_id` now? ",
        "pr_file_module": null
      },
      {
        "comment_id": "2238249942",
        "repo_full_name": "LMCache/LMCache",
        "pr_number": 1166,
        "pr_file": "lmcache/v1/rpc_utils.py",
        "discussion_id": "2234864169",
        "commented_code": "@@ -94,12 +94,17 @@ def get_zmq_rpc_path_lmcache(\n     # Third Party\n     import vllm.envs as envs\n \n+    if vllm_config is None or vllm_config.kv_transfer_config is None:\n+        raise ValueError(\"vllm_config with kv_transfer_config is required to determine the engine_id.\")\n+\n     base_url = envs.VLLM_RPC_BASE_PATH\n \n+    engine_id = vllm_config.kv_transfer_config.engine_id\n+\n     if isinstance(rpc_port, str):\n         rpc_port = rpc_port + str(tp_rank)\n     else:\n         rpc_port += tp_rank\n \n-    logger.debug(\"Base URL: %s, RPC Port: %s\", base_url, rpc_port)\n-    return f\"ipc://{base_url}/lmcache_rpc_port_{rpc_port}\"\n+    logger.debug(\"Base URL: %s, Engine: %d, RPC Port: %s\", base_url, engine_id, rpc_port)",
        "comment_created_at": "2025-07-29T02:47:41+00:00",
        "comment_author": "Foreverythin",
        "comment_body": "> would it be correct that we can get rid of `rpc_port` if we are using the `engine_id` now?\r\n\r\nYes, we can get rid of using `rpc_port`, but we need modify more codes.\r\n\r\nThe function of `get_zmq_rpc_path_lmcache` is called by `LMCacheLookupClient`, `LMCacheLookupServer` and `ZMQOffloadServer`.  To expand on this, the core issue is that `LMCacheLookupServer` (for handling lookups) and `ZMQOffloadServer` (for handling offloading) are two distinct services. They must use separate, isolated communication channels to avoid conflicts, as they handle different message types.\r\n\r\nPreviously, this separation was achieved by having them use different `rpc_port` values (e.g., a default of 0 for lookup and 100 for offload). If we just remove `port` in the socket_path, then there will be a conflict between `LMCacheLookupServer` and `ZMQOffloadServer` .\r\n\r\nMy proposed solution is to replace the numeric `rpc_port` with a descriptive string identifier for each service. This makes the distinction explicit within the code and completely removes the need for any user-facing port configuration.\r\n\r\n1. Remove the parameter `rpc_port`;\r\n2. Add a new parameter `service_name` (\"lookup\", \"offload\");\r\n3. Change socket_path to `f\"ipc://{base_url}/engine_{engine_id}_service_{service_name}_tp_rank_{tp_rank}\"`;\r\n4. Modify the way function `get_zmq_rpc_path_lmcache` is called.\r\n\r\nI have given a solution and updated the codes (48e3198). And it LGTM. So, should we avoid using rpc_port? I believe that avoiding the use of rpc_port will make it easier for users and reduce user configuration. @maobaolong @sammshen ",
        "pr_file_module": null
      },
      {
        "comment_id": "2238348573",
        "repo_full_name": "LMCache/LMCache",
        "pr_number": 1166,
        "pr_file": "lmcache/v1/rpc_utils.py",
        "discussion_id": "2234864169",
        "commented_code": "@@ -94,12 +94,17 @@ def get_zmq_rpc_path_lmcache(\n     # Third Party\n     import vllm.envs as envs\n \n+    if vllm_config is None or vllm_config.kv_transfer_config is None:\n+        raise ValueError(\"vllm_config with kv_transfer_config is required to determine the engine_id.\")\n+\n     base_url = envs.VLLM_RPC_BASE_PATH\n \n+    engine_id = vllm_config.kv_transfer_config.engine_id\n+\n     if isinstance(rpc_port, str):\n         rpc_port = rpc_port + str(tp_rank)\n     else:\n         rpc_port += tp_rank\n \n-    logger.debug(\"Base URL: %s, RPC Port: %s\", base_url, rpc_port)\n-    return f\"ipc://{base_url}/lmcache_rpc_port_{rpc_port}\"\n+    logger.debug(\"Base URL: %s, Engine: %d, RPC Port: %s\", base_url, engine_id, rpc_port)",
        "comment_created_at": "2025-07-29T03:41:32+00:00",
        "comment_author": "maobaolong",
        "comment_body": "@Foreverythin I'd prefer to remove the `lmcache_rpc_port` initially, but after search the existing usage, i'm ok you keep it to keep consistency.\r\n\r\n<img width=\"1338\" height=\"692\" alt=\"image\" src=\"https://github.com/user-attachments/assets/4e3523c0-537e-4c7f-b41e-f6a5151eadaa\" />\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2052304573",
    "pr_number": 465,
    "pr_file": "lmcache/experimental/storage_backend/connector/nixl_connector_v2.py",
    "created_at": "2025-04-21T11:51:04+00:00",
    "commented_code": "+# Copyright 2024-2025 LMCache Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import abc\n+import pickle\n+import threading\n+import time\n+import uuid\n+from dataclasses import dataclass\n+from typing import Callable, Optional, Union\n+\n+import torch\n+import zmq\n+from nixl._api import nixl_agent\n+\n+from lmcache.experimental.memory_management import (MemoryAllocatorInterface,\n+                                                    MemoryFormat, MemoryObj,\n+                                                    MemoryObjMetadata,\n+                                                    TensorMemoryObj)\n+from lmcache.experimental.storage_backend.connector.nixl_connector import (\n+    NixlConfig, NixlRole)\n+from lmcache.logging import init_logger\n+from lmcache.utils import CacheEngineKey\n+\n+logger = init_logger(__name__)\n+\n+\n+class NixlBufferAllocator(MemoryAllocatorInterface):\n+    \"\"\"The memory allocator on NIXL transfer buffer.\n+    \"\"\"\n+\n+    def __init__(self, nixl_pipe: \"NixlPipe\"):\n+        self.nixl_pipe = nixl_pipe\n+        self.buffer = nixl_pipe._buffer\n+        self.capacity = nixl_pipe.nixl_config.buffer_size\n+\n+        self.allocated_size = 0\n+\n+    def _flush(self):\n+        self.nixl_pipe.flush()\n+        self.allocated_size = 0\n+\n+    def allocate(\n+        self,\n+        shape: Union[torch.Size, tuple[int, ...]],\n+        dtype: Optional[torch.dtype],\n+        fmt: MemoryFormat = MemoryFormat.KV_BLOB,\n+    ) -> Optional[MemoryObj]:\n+        \"\"\"\n+        Allocates the memory to hold a tensor of the given shape.\n+\n+        :param torch.Size shape: The shape of the tensor to allocate.\n+        :param torch.dtype dtype: The dtype of the tensor to allocate.\n+        :param MemoryFormat fmt: The format of the memory to allocate.\n+        \n+        :return: A MemoryObj wrapping the allocated memory. Returns\n+            None if the allocation failed.\n+\n+        :rtype: Optional[MemoryObj]\n+        \"\"\"\n+        metadata = self.dry_allocate(shape, dtype, fmt)\n+        metadata.address = self.allocated_size\n+\n+        # check the size and capacity\n+        required_size = metadata.get_size()\n+        assert required_size < self.capacity, \\\n+            \"The object size is larger than the NIXL buffer capacity\"\n+\n+        if self.allocated_size + required_size > self.capacity:\n+            # If no enough space, try to flush\n+            self._flush()\n+\n+        # allocate the memory\n+        raw_tensor = self.buffer[self.allocated_size : self.allocated_size\\\n+                + required_size]\n+        ret = TensorMemoryObj(raw_data=raw_tensor, metadata=metadata)\n+        self.allocated_size += required_size\n+        return ret\n+\n+    def dry_allocate(\n+        self,\n+        shape: torch.Size,\n+        dtype: Optional[torch.dtype],\n+        fmt: MemoryFormat = MemoryFormat.KV_BLOB,\n+    ) -> MemoryObjMetadata:\n+        \"\"\"Dry allocate the memory and return the metadata.\n+\n+        Note: `address` is not valid in the dry allocation.\n+        \"\"\"\n+        metadata = MemoryObjMetadata(shape,\n+                                     dtype,\n+                                     address=0,\n+                                     phy_size=0,\n+                                     ref_count=1,\n+                                     fmt=fmt)\n+        metadata.phy_size = metadata.get_size()\n+        return metadata\n+\n+    def free(self, obj: MemoryObj):\n+        \"\"\"Free the memory object.\n+        \"\"\"\n+        pass\n+\n+    def ref_count_up(self, obj: MemoryObj):\n+        \"\"\"Increase the reference count of the memory object.\n+        \"\"\"\n+        pass\n+\n+    def ref_count_down(self, obj: MemoryObj):\n+        \"\"\"Decrease the reference count of the memory object.\n+        \"\"\"\n+        pass\n+\n+    def get_ref_count(self, obj: MemoryObj) -> int:\n+        \"\"\"Get the reference count of the memory object.\n+        \"\"\"\n+        raise NotImplementedError\n+\n+    ### For NIXL Pipe to call\n+    def num_bytes_allocated(self) -> int:\n+        \"\"\"Get the number of bytes allocated.\n+\n+        Returns:\n+            The number of bytes allocated.\n+        \"\"\"\n+        return self.allocated_size\n+\n+    def reset_allocated_size(self):\n+        \"\"\"Reset the allocated size to 0.\n+        \"\"\"\n+        self.allocated_size = 0\n+\n+\n+@dataclass\n+class NixlRequest:\n+    \"\"\"\n+    A dataclass to represent a request received from the remote peer.\n+    This can be used to encapsulate the request information.\n+    \"\"\"\n+    keys: list[CacheEngineKey]\n+    metadatas: list[MemoryObjMetadata]\n+\n+    def serialize(self) -> bytes:\n+        return pickle.dumps(self)\n+\n+    @staticmethod\n+    def deserialize(s: bytes) -> \"NixlRequest\":\n+        return pickle.loads(s)\n+\n+\n+class NixlPipe:\n+    \"\"\"An one-directional pipe to send the data from the sender to the receiver.\n+    \"\"\"\n+    TRANSFER_BUFFER_SIZE = 128 * 1024 * 1024\n+\n+    def __init__(self, nixl_config: NixlConfig,\n+                 side_channel: zmq.Socket):  # type: ignore\n+        self.nixl_config = nixl_config\n+        self.side_channel = side_channel\n+\n+        if nixl_config.buffer_size > NixlPipe.TRANSFER_BUFFER_SIZE:\n+            assert \\\n+                nixl_config.buffer_size % NixlPipe.TRANSFER_BUFFER_SIZE == 0, \\\n+                f\"Buffer size must be a multiple of \"\\\n+                f\"{NixlPipe.TRANSFER_BUFFER_SIZE}\"\n+\n+        self._buffer = torch.empty(nixl_config.buffer_size,\n+                                   device=nixl_config.buffer_device,\n+                                   dtype=torch.uint8)\n+\n+        self._transfer_buffers = torch.split(self._buffer,\n+                                             NixlPipe.TRANSFER_BUFFER_SIZE,\n+                                             dim=0)\n+\n+        # allocator (should be initialized after self._buffer)\n+        self._allocator = NixlBufferAllocator(self)\n+\n+        self._agent = nixl_agent(str(nixl_config.role))\n+        self._reg_descs = self._agent.register_memory(self._transfer_buffers)\n+        self._local_xfer_descs = self._reg_descs.trim()\n+        self._remote_xfer_descs = None\n+        self._local_xfer_handlers = None\n+        self._remote_xfer_handlers = None\n+\n+        local_meta = self._agent.get_agent_metadata()\n+        if nixl_config.role == NixlRole.SENDER:\n+            self.side_channel.send(local_meta)\n+            remote_meta = self.side_channel.recv()\n+            self.peer_name = self._agent.add_remote_agent(remote_meta).decode(\n+                \"utf-8\")\n+        else:\n+            remote_meta = self.side_channel.recv()\n+            self.peer_name = self._agent.add_remote_agent(remote_meta).decode(\n+                \"utf-8\")\n+            self.side_channel.send(local_meta)\n+\n+        # Exchange the reg_descs\n+        if nixl_config.role == NixlRole.SENDER:\n+            msg = self.side_channel.recv()\n+            self._remote_xfer_descs = self._agent.deserialize_descs(msg)\n+            logger.info(\"Received remote transfer descriptors\")\n+\n+            # Prepare the local and remote xfer_dlist_handler\n+            self._local_xfer_handlers = self._agent.prep_xfer_dlist(\n+                \"\", self._local_xfer_descs)\n+            self._remote_xfer_handlers = self._agent.prep_xfer_dlist(\n+                self.peer_name, self._remote_xfer_descs)\n+        else:\n+            # Receiver side, send the local descriptors\n+            self.side_channel.send(\n+                self._agent.get_serialized_descs(self._local_xfer_descs))\n+            logger.info(\"Sent local transfer descriptors to sender\")\n+\n+        # UUID for communication\n+        self._uuid = None\n+        if nixl_config.role == NixlRole.RECEIVER:\n+            # Receiver send an initial uuid to sender\n+            self._uuid = uuid.uuid4().hex\n+            self.ack_receive()\n+\n+    def _spin_check_for_ack(self) -> str:\n+        \"\"\"\n+        Spin until receives an ack from the peer.\n+\n+        Returns:\n+            The uuid extracted from the ack message.\n+        \"\"\"\n+        receiver_ready = False\n+        while not receiver_ready:\n+            notifs = self._agent.get_new_notifs()\n+            if self.peer_name not in notifs:\n+                time.sleep(0.001)\n+                continue\n+\n+            for notif in notifs[self.peer_name]:\n+                decoded_uuid = message_to_uuid(notif.decode(\"utf-8\"))\n+                if decoded_uuid is not None:\n+                    return decoded_uuid\n+            time.sleep(0.001)  # Avoid busy waiting\n+\n+        raise RuntimeError(\"Failed to receive ACK from remote peer\")\n+\n+    def _commit_write(self, write_size: int, uid: str):\n+        \"\"\"A blocking function that ensures the write buffer is delivered to\n+        the receiver.\n+        \n+        The transfer is initialized with the uuid.\n+        \n+        Args:\n+            write_size: the size of the data that is written into the buffer\n+            uuid: the uuid of the transfer\n+\n+        Raises:\n+            RuntimeError: if the transfer fails\n+        \"\"\"\n+        # Send the data to the remote peer\n+        num_transfers = (write_size - 1) // NixlPipe.TRANSFER_BUFFER_SIZE + 1\n+        desc_indexes = list(range(num_transfers))\n+        logger.debug(f\"Committing write of {write_size / 1024 / 1024} \"\n+                     f\"MB with {num_transfers} transfers\")\n+\n+        t1 = time.perf_counter()\n+        handle = self._agent.make_prepped_xfer(\"WRITE\",",
    "repo_full_name": "LMCache/LMCache",
    "discussion_comments": [
      {
        "comment_id": "2052304573",
        "repo_full_name": "LMCache/LMCache",
        "pr_number": 465,
        "pr_file": "lmcache/experimental/storage_backend/connector/nixl_connector_v2.py",
        "discussion_id": "2052304573",
        "commented_code": "@@ -0,0 +1,691 @@\n+# Copyright 2024-2025 LMCache Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import abc\n+import pickle\n+import threading\n+import time\n+import uuid\n+from dataclasses import dataclass\n+from typing import Callable, Optional, Union\n+\n+import torch\n+import zmq\n+from nixl._api import nixl_agent\n+\n+from lmcache.experimental.memory_management import (MemoryAllocatorInterface,\n+                                                    MemoryFormat, MemoryObj,\n+                                                    MemoryObjMetadata,\n+                                                    TensorMemoryObj)\n+from lmcache.experimental.storage_backend.connector.nixl_connector import (\n+    NixlConfig, NixlRole)\n+from lmcache.logging import init_logger\n+from lmcache.utils import CacheEngineKey\n+\n+logger = init_logger(__name__)\n+\n+\n+class NixlBufferAllocator(MemoryAllocatorInterface):\n+    \"\"\"The memory allocator on NIXL transfer buffer.\n+    \"\"\"\n+\n+    def __init__(self, nixl_pipe: \"NixlPipe\"):\n+        self.nixl_pipe = nixl_pipe\n+        self.buffer = nixl_pipe._buffer\n+        self.capacity = nixl_pipe.nixl_config.buffer_size\n+\n+        self.allocated_size = 0\n+\n+    def _flush(self):\n+        self.nixl_pipe.flush()\n+        self.allocated_size = 0\n+\n+    def allocate(\n+        self,\n+        shape: Union[torch.Size, tuple[int, ...]],\n+        dtype: Optional[torch.dtype],\n+        fmt: MemoryFormat = MemoryFormat.KV_BLOB,\n+    ) -> Optional[MemoryObj]:\n+        \"\"\"\n+        Allocates the memory to hold a tensor of the given shape.\n+\n+        :param torch.Size shape: The shape of the tensor to allocate.\n+        :param torch.dtype dtype: The dtype of the tensor to allocate.\n+        :param MemoryFormat fmt: The format of the memory to allocate.\n+        \n+        :return: A MemoryObj wrapping the allocated memory. Returns\n+            None if the allocation failed.\n+\n+        :rtype: Optional[MemoryObj]\n+        \"\"\"\n+        metadata = self.dry_allocate(shape, dtype, fmt)\n+        metadata.address = self.allocated_size\n+\n+        # check the size and capacity\n+        required_size = metadata.get_size()\n+        assert required_size < self.capacity, \\\n+            \"The object size is larger than the NIXL buffer capacity\"\n+\n+        if self.allocated_size + required_size > self.capacity:\n+            # If no enough space, try to flush\n+            self._flush()\n+\n+        # allocate the memory\n+        raw_tensor = self.buffer[self.allocated_size : self.allocated_size\\\n+                + required_size]\n+        ret = TensorMemoryObj(raw_data=raw_tensor, metadata=metadata)\n+        self.allocated_size += required_size\n+        return ret\n+\n+    def dry_allocate(\n+        self,\n+        shape: torch.Size,\n+        dtype: Optional[torch.dtype],\n+        fmt: MemoryFormat = MemoryFormat.KV_BLOB,\n+    ) -> MemoryObjMetadata:\n+        \"\"\"Dry allocate the memory and return the metadata.\n+\n+        Note: `address` is not valid in the dry allocation.\n+        \"\"\"\n+        metadata = MemoryObjMetadata(shape,\n+                                     dtype,\n+                                     address=0,\n+                                     phy_size=0,\n+                                     ref_count=1,\n+                                     fmt=fmt)\n+        metadata.phy_size = metadata.get_size()\n+        return metadata\n+\n+    def free(self, obj: MemoryObj):\n+        \"\"\"Free the memory object.\n+        \"\"\"\n+        pass\n+\n+    def ref_count_up(self, obj: MemoryObj):\n+        \"\"\"Increase the reference count of the memory object.\n+        \"\"\"\n+        pass\n+\n+    def ref_count_down(self, obj: MemoryObj):\n+        \"\"\"Decrease the reference count of the memory object.\n+        \"\"\"\n+        pass\n+\n+    def get_ref_count(self, obj: MemoryObj) -> int:\n+        \"\"\"Get the reference count of the memory object.\n+        \"\"\"\n+        raise NotImplementedError\n+\n+    ### For NIXL Pipe to call\n+    def num_bytes_allocated(self) -> int:\n+        \"\"\"Get the number of bytes allocated.\n+\n+        Returns:\n+            The number of bytes allocated.\n+        \"\"\"\n+        return self.allocated_size\n+\n+    def reset_allocated_size(self):\n+        \"\"\"Reset the allocated size to 0.\n+        \"\"\"\n+        self.allocated_size = 0\n+\n+\n+@dataclass\n+class NixlRequest:\n+    \"\"\"\n+    A dataclass to represent a request received from the remote peer.\n+    This can be used to encapsulate the request information.\n+    \"\"\"\n+    keys: list[CacheEngineKey]\n+    metadatas: list[MemoryObjMetadata]\n+\n+    def serialize(self) -> bytes:\n+        return pickle.dumps(self)\n+\n+    @staticmethod\n+    def deserialize(s: bytes) -> \"NixlRequest\":\n+        return pickle.loads(s)\n+\n+\n+class NixlPipe:\n+    \"\"\"An one-directional pipe to send the data from the sender to the receiver.\n+    \"\"\"\n+    TRANSFER_BUFFER_SIZE = 128 * 1024 * 1024\n+\n+    def __init__(self, nixl_config: NixlConfig,\n+                 side_channel: zmq.Socket):  # type: ignore\n+        self.nixl_config = nixl_config\n+        self.side_channel = side_channel\n+\n+        if nixl_config.buffer_size > NixlPipe.TRANSFER_BUFFER_SIZE:\n+            assert \\\n+                nixl_config.buffer_size % NixlPipe.TRANSFER_BUFFER_SIZE == 0, \\\n+                f\"Buffer size must be a multiple of \"\\\n+                f\"{NixlPipe.TRANSFER_BUFFER_SIZE}\"\n+\n+        self._buffer = torch.empty(nixl_config.buffer_size,\n+                                   device=nixl_config.buffer_device,\n+                                   dtype=torch.uint8)\n+\n+        self._transfer_buffers = torch.split(self._buffer,\n+                                             NixlPipe.TRANSFER_BUFFER_SIZE,\n+                                             dim=0)\n+\n+        # allocator (should be initialized after self._buffer)\n+        self._allocator = NixlBufferAllocator(self)\n+\n+        self._agent = nixl_agent(str(nixl_config.role))\n+        self._reg_descs = self._agent.register_memory(self._transfer_buffers)\n+        self._local_xfer_descs = self._reg_descs.trim()\n+        self._remote_xfer_descs = None\n+        self._local_xfer_handlers = None\n+        self._remote_xfer_handlers = None\n+\n+        local_meta = self._agent.get_agent_metadata()\n+        if nixl_config.role == NixlRole.SENDER:\n+            self.side_channel.send(local_meta)\n+            remote_meta = self.side_channel.recv()\n+            self.peer_name = self._agent.add_remote_agent(remote_meta).decode(\n+                \"utf-8\")\n+        else:\n+            remote_meta = self.side_channel.recv()\n+            self.peer_name = self._agent.add_remote_agent(remote_meta).decode(\n+                \"utf-8\")\n+            self.side_channel.send(local_meta)\n+\n+        # Exchange the reg_descs\n+        if nixl_config.role == NixlRole.SENDER:\n+            msg = self.side_channel.recv()\n+            self._remote_xfer_descs = self._agent.deserialize_descs(msg)\n+            logger.info(\"Received remote transfer descriptors\")\n+\n+            # Prepare the local and remote xfer_dlist_handler\n+            self._local_xfer_handlers = self._agent.prep_xfer_dlist(\n+                \"\", self._local_xfer_descs)\n+            self._remote_xfer_handlers = self._agent.prep_xfer_dlist(\n+                self.peer_name, self._remote_xfer_descs)\n+        else:\n+            # Receiver side, send the local descriptors\n+            self.side_channel.send(\n+                self._agent.get_serialized_descs(self._local_xfer_descs))\n+            logger.info(\"Sent local transfer descriptors to sender\")\n+\n+        # UUID for communication\n+        self._uuid = None\n+        if nixl_config.role == NixlRole.RECEIVER:\n+            # Receiver send an initial uuid to sender\n+            self._uuid = uuid.uuid4().hex\n+            self.ack_receive()\n+\n+    def _spin_check_for_ack(self) -> str:\n+        \"\"\"\n+        Spin until receives an ack from the peer.\n+\n+        Returns:\n+            The uuid extracted from the ack message.\n+        \"\"\"\n+        receiver_ready = False\n+        while not receiver_ready:\n+            notifs = self._agent.get_new_notifs()\n+            if self.peer_name not in notifs:\n+                time.sleep(0.001)\n+                continue\n+\n+            for notif in notifs[self.peer_name]:\n+                decoded_uuid = message_to_uuid(notif.decode(\"utf-8\"))\n+                if decoded_uuid is not None:\n+                    return decoded_uuid\n+            time.sleep(0.001)  # Avoid busy waiting\n+\n+        raise RuntimeError(\"Failed to receive ACK from remote peer\")\n+\n+    def _commit_write(self, write_size: int, uid: str):\n+        \"\"\"A blocking function that ensures the write buffer is delivered to\n+        the receiver.\n+        \n+        The transfer is initialized with the uuid.\n+        \n+        Args:\n+            write_size: the size of the data that is written into the buffer\n+            uuid: the uuid of the transfer\n+\n+        Raises:\n+            RuntimeError: if the transfer fails\n+        \"\"\"\n+        # Send the data to the remote peer\n+        num_transfers = (write_size - 1) // NixlPipe.TRANSFER_BUFFER_SIZE + 1\n+        desc_indexes = list(range(num_transfers))\n+        logger.debug(f\"Committing write of {write_size / 1024 / 1024} \"\n+                     f\"MB with {num_transfers} transfers\")\n+\n+        t1 = time.perf_counter()\n+        handle = self._agent.make_prepped_xfer(\"WRITE\",",
        "comment_created_at": "2025-04-21T11:51:04+00:00",
        "comment_author": "robertgshaw2-redhat",
        "comment_body": "If you add a `notify_msg` here like https://github.com/vllm-project/vllm/pull/16124/files#diff-876efa5533f5dcff3fba850e8684a47d53c112e287988957c115b11691374f4bR302, it will automatically send the self._agent.send_notif() message when the txn is done which allows you to remove line 297\r\n\r\nThis will make it easy to do the optimization you describe below (of not spinning until the txn is done) but rather waiting until the next transfer",
        "pr_file_module": null
      },
      {
        "comment_id": "2052305240",
        "repo_full_name": "LMCache/LMCache",
        "pr_number": 465,
        "pr_file": "lmcache/experimental/storage_backend/connector/nixl_connector_v2.py",
        "discussion_id": "2052304573",
        "commented_code": "@@ -0,0 +1,691 @@\n+# Copyright 2024-2025 LMCache Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import abc\n+import pickle\n+import threading\n+import time\n+import uuid\n+from dataclasses import dataclass\n+from typing import Callable, Optional, Union\n+\n+import torch\n+import zmq\n+from nixl._api import nixl_agent\n+\n+from lmcache.experimental.memory_management import (MemoryAllocatorInterface,\n+                                                    MemoryFormat, MemoryObj,\n+                                                    MemoryObjMetadata,\n+                                                    TensorMemoryObj)\n+from lmcache.experimental.storage_backend.connector.nixl_connector import (\n+    NixlConfig, NixlRole)\n+from lmcache.logging import init_logger\n+from lmcache.utils import CacheEngineKey\n+\n+logger = init_logger(__name__)\n+\n+\n+class NixlBufferAllocator(MemoryAllocatorInterface):\n+    \"\"\"The memory allocator on NIXL transfer buffer.\n+    \"\"\"\n+\n+    def __init__(self, nixl_pipe: \"NixlPipe\"):\n+        self.nixl_pipe = nixl_pipe\n+        self.buffer = nixl_pipe._buffer\n+        self.capacity = nixl_pipe.nixl_config.buffer_size\n+\n+        self.allocated_size = 0\n+\n+    def _flush(self):\n+        self.nixl_pipe.flush()\n+        self.allocated_size = 0\n+\n+    def allocate(\n+        self,\n+        shape: Union[torch.Size, tuple[int, ...]],\n+        dtype: Optional[torch.dtype],\n+        fmt: MemoryFormat = MemoryFormat.KV_BLOB,\n+    ) -> Optional[MemoryObj]:\n+        \"\"\"\n+        Allocates the memory to hold a tensor of the given shape.\n+\n+        :param torch.Size shape: The shape of the tensor to allocate.\n+        :param torch.dtype dtype: The dtype of the tensor to allocate.\n+        :param MemoryFormat fmt: The format of the memory to allocate.\n+        \n+        :return: A MemoryObj wrapping the allocated memory. Returns\n+            None if the allocation failed.\n+\n+        :rtype: Optional[MemoryObj]\n+        \"\"\"\n+        metadata = self.dry_allocate(shape, dtype, fmt)\n+        metadata.address = self.allocated_size\n+\n+        # check the size and capacity\n+        required_size = metadata.get_size()\n+        assert required_size < self.capacity, \\\n+            \"The object size is larger than the NIXL buffer capacity\"\n+\n+        if self.allocated_size + required_size > self.capacity:\n+            # If no enough space, try to flush\n+            self._flush()\n+\n+        # allocate the memory\n+        raw_tensor = self.buffer[self.allocated_size : self.allocated_size\\\n+                + required_size]\n+        ret = TensorMemoryObj(raw_data=raw_tensor, metadata=metadata)\n+        self.allocated_size += required_size\n+        return ret\n+\n+    def dry_allocate(\n+        self,\n+        shape: torch.Size,\n+        dtype: Optional[torch.dtype],\n+        fmt: MemoryFormat = MemoryFormat.KV_BLOB,\n+    ) -> MemoryObjMetadata:\n+        \"\"\"Dry allocate the memory and return the metadata.\n+\n+        Note: `address` is not valid in the dry allocation.\n+        \"\"\"\n+        metadata = MemoryObjMetadata(shape,\n+                                     dtype,\n+                                     address=0,\n+                                     phy_size=0,\n+                                     ref_count=1,\n+                                     fmt=fmt)\n+        metadata.phy_size = metadata.get_size()\n+        return metadata\n+\n+    def free(self, obj: MemoryObj):\n+        \"\"\"Free the memory object.\n+        \"\"\"\n+        pass\n+\n+    def ref_count_up(self, obj: MemoryObj):\n+        \"\"\"Increase the reference count of the memory object.\n+        \"\"\"\n+        pass\n+\n+    def ref_count_down(self, obj: MemoryObj):\n+        \"\"\"Decrease the reference count of the memory object.\n+        \"\"\"\n+        pass\n+\n+    def get_ref_count(self, obj: MemoryObj) -> int:\n+        \"\"\"Get the reference count of the memory object.\n+        \"\"\"\n+        raise NotImplementedError\n+\n+    ### For NIXL Pipe to call\n+    def num_bytes_allocated(self) -> int:\n+        \"\"\"Get the number of bytes allocated.\n+\n+        Returns:\n+            The number of bytes allocated.\n+        \"\"\"\n+        return self.allocated_size\n+\n+    def reset_allocated_size(self):\n+        \"\"\"Reset the allocated size to 0.\n+        \"\"\"\n+        self.allocated_size = 0\n+\n+\n+@dataclass\n+class NixlRequest:\n+    \"\"\"\n+    A dataclass to represent a request received from the remote peer.\n+    This can be used to encapsulate the request information.\n+    \"\"\"\n+    keys: list[CacheEngineKey]\n+    metadatas: list[MemoryObjMetadata]\n+\n+    def serialize(self) -> bytes:\n+        return pickle.dumps(self)\n+\n+    @staticmethod\n+    def deserialize(s: bytes) -> \"NixlRequest\":\n+        return pickle.loads(s)\n+\n+\n+class NixlPipe:\n+    \"\"\"An one-directional pipe to send the data from the sender to the receiver.\n+    \"\"\"\n+    TRANSFER_BUFFER_SIZE = 128 * 1024 * 1024\n+\n+    def __init__(self, nixl_config: NixlConfig,\n+                 side_channel: zmq.Socket):  # type: ignore\n+        self.nixl_config = nixl_config\n+        self.side_channel = side_channel\n+\n+        if nixl_config.buffer_size > NixlPipe.TRANSFER_BUFFER_SIZE:\n+            assert \\\n+                nixl_config.buffer_size % NixlPipe.TRANSFER_BUFFER_SIZE == 0, \\\n+                f\"Buffer size must be a multiple of \"\\\n+                f\"{NixlPipe.TRANSFER_BUFFER_SIZE}\"\n+\n+        self._buffer = torch.empty(nixl_config.buffer_size,\n+                                   device=nixl_config.buffer_device,\n+                                   dtype=torch.uint8)\n+\n+        self._transfer_buffers = torch.split(self._buffer,\n+                                             NixlPipe.TRANSFER_BUFFER_SIZE,\n+                                             dim=0)\n+\n+        # allocator (should be initialized after self._buffer)\n+        self._allocator = NixlBufferAllocator(self)\n+\n+        self._agent = nixl_agent(str(nixl_config.role))\n+        self._reg_descs = self._agent.register_memory(self._transfer_buffers)\n+        self._local_xfer_descs = self._reg_descs.trim()\n+        self._remote_xfer_descs = None\n+        self._local_xfer_handlers = None\n+        self._remote_xfer_handlers = None\n+\n+        local_meta = self._agent.get_agent_metadata()\n+        if nixl_config.role == NixlRole.SENDER:\n+            self.side_channel.send(local_meta)\n+            remote_meta = self.side_channel.recv()\n+            self.peer_name = self._agent.add_remote_agent(remote_meta).decode(\n+                \"utf-8\")\n+        else:\n+            remote_meta = self.side_channel.recv()\n+            self.peer_name = self._agent.add_remote_agent(remote_meta).decode(\n+                \"utf-8\")\n+            self.side_channel.send(local_meta)\n+\n+        # Exchange the reg_descs\n+        if nixl_config.role == NixlRole.SENDER:\n+            msg = self.side_channel.recv()\n+            self._remote_xfer_descs = self._agent.deserialize_descs(msg)\n+            logger.info(\"Received remote transfer descriptors\")\n+\n+            # Prepare the local and remote xfer_dlist_handler\n+            self._local_xfer_handlers = self._agent.prep_xfer_dlist(\n+                \"\", self._local_xfer_descs)\n+            self._remote_xfer_handlers = self._agent.prep_xfer_dlist(\n+                self.peer_name, self._remote_xfer_descs)\n+        else:\n+            # Receiver side, send the local descriptors\n+            self.side_channel.send(\n+                self._agent.get_serialized_descs(self._local_xfer_descs))\n+            logger.info(\"Sent local transfer descriptors to sender\")\n+\n+        # UUID for communication\n+        self._uuid = None\n+        if nixl_config.role == NixlRole.RECEIVER:\n+            # Receiver send an initial uuid to sender\n+            self._uuid = uuid.uuid4().hex\n+            self.ack_receive()\n+\n+    def _spin_check_for_ack(self) -> str:\n+        \"\"\"\n+        Spin until receives an ack from the peer.\n+\n+        Returns:\n+            The uuid extracted from the ack message.\n+        \"\"\"\n+        receiver_ready = False\n+        while not receiver_ready:\n+            notifs = self._agent.get_new_notifs()\n+            if self.peer_name not in notifs:\n+                time.sleep(0.001)\n+                continue\n+\n+            for notif in notifs[self.peer_name]:\n+                decoded_uuid = message_to_uuid(notif.decode(\"utf-8\"))\n+                if decoded_uuid is not None:\n+                    return decoded_uuid\n+            time.sleep(0.001)  # Avoid busy waiting\n+\n+        raise RuntimeError(\"Failed to receive ACK from remote peer\")\n+\n+    def _commit_write(self, write_size: int, uid: str):\n+        \"\"\"A blocking function that ensures the write buffer is delivered to\n+        the receiver.\n+        \n+        The transfer is initialized with the uuid.\n+        \n+        Args:\n+            write_size: the size of the data that is written into the buffer\n+            uuid: the uuid of the transfer\n+\n+        Raises:\n+            RuntimeError: if the transfer fails\n+        \"\"\"\n+        # Send the data to the remote peer\n+        num_transfers = (write_size - 1) // NixlPipe.TRANSFER_BUFFER_SIZE + 1\n+        desc_indexes = list(range(num_transfers))\n+        logger.debug(f\"Committing write of {write_size / 1024 / 1024} \"\n+                     f\"MB with {num_transfers} transfers\")\n+\n+        t1 = time.perf_counter()\n+        handle = self._agent.make_prepped_xfer(\"WRITE\",",
        "comment_created_at": "2025-04-21T11:52:02+00:00",
        "comment_author": "robertgshaw2-redhat",
        "comment_body": "This is critical for making the sending happen async relative to the vLLM engine",
        "pr_file_module": null
      },
      {
        "comment_id": "2052313846",
        "repo_full_name": "LMCache/LMCache",
        "pr_number": 465,
        "pr_file": "lmcache/experimental/storage_backend/connector/nixl_connector_v2.py",
        "discussion_id": "2052304573",
        "commented_code": "@@ -0,0 +1,691 @@\n+# Copyright 2024-2025 LMCache Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import abc\n+import pickle\n+import threading\n+import time\n+import uuid\n+from dataclasses import dataclass\n+from typing import Callable, Optional, Union\n+\n+import torch\n+import zmq\n+from nixl._api import nixl_agent\n+\n+from lmcache.experimental.memory_management import (MemoryAllocatorInterface,\n+                                                    MemoryFormat, MemoryObj,\n+                                                    MemoryObjMetadata,\n+                                                    TensorMemoryObj)\n+from lmcache.experimental.storage_backend.connector.nixl_connector import (\n+    NixlConfig, NixlRole)\n+from lmcache.logging import init_logger\n+from lmcache.utils import CacheEngineKey\n+\n+logger = init_logger(__name__)\n+\n+\n+class NixlBufferAllocator(MemoryAllocatorInterface):\n+    \"\"\"The memory allocator on NIXL transfer buffer.\n+    \"\"\"\n+\n+    def __init__(self, nixl_pipe: \"NixlPipe\"):\n+        self.nixl_pipe = nixl_pipe\n+        self.buffer = nixl_pipe._buffer\n+        self.capacity = nixl_pipe.nixl_config.buffer_size\n+\n+        self.allocated_size = 0\n+\n+    def _flush(self):\n+        self.nixl_pipe.flush()\n+        self.allocated_size = 0\n+\n+    def allocate(\n+        self,\n+        shape: Union[torch.Size, tuple[int, ...]],\n+        dtype: Optional[torch.dtype],\n+        fmt: MemoryFormat = MemoryFormat.KV_BLOB,\n+    ) -> Optional[MemoryObj]:\n+        \"\"\"\n+        Allocates the memory to hold a tensor of the given shape.\n+\n+        :param torch.Size shape: The shape of the tensor to allocate.\n+        :param torch.dtype dtype: The dtype of the tensor to allocate.\n+        :param MemoryFormat fmt: The format of the memory to allocate.\n+        \n+        :return: A MemoryObj wrapping the allocated memory. Returns\n+            None if the allocation failed.\n+\n+        :rtype: Optional[MemoryObj]\n+        \"\"\"\n+        metadata = self.dry_allocate(shape, dtype, fmt)\n+        metadata.address = self.allocated_size\n+\n+        # check the size and capacity\n+        required_size = metadata.get_size()\n+        assert required_size < self.capacity, \\\n+            \"The object size is larger than the NIXL buffer capacity\"\n+\n+        if self.allocated_size + required_size > self.capacity:\n+            # If no enough space, try to flush\n+            self._flush()\n+\n+        # allocate the memory\n+        raw_tensor = self.buffer[self.allocated_size : self.allocated_size\\\n+                + required_size]\n+        ret = TensorMemoryObj(raw_data=raw_tensor, metadata=metadata)\n+        self.allocated_size += required_size\n+        return ret\n+\n+    def dry_allocate(\n+        self,\n+        shape: torch.Size,\n+        dtype: Optional[torch.dtype],\n+        fmt: MemoryFormat = MemoryFormat.KV_BLOB,\n+    ) -> MemoryObjMetadata:\n+        \"\"\"Dry allocate the memory and return the metadata.\n+\n+        Note: `address` is not valid in the dry allocation.\n+        \"\"\"\n+        metadata = MemoryObjMetadata(shape,\n+                                     dtype,\n+                                     address=0,\n+                                     phy_size=0,\n+                                     ref_count=1,\n+                                     fmt=fmt)\n+        metadata.phy_size = metadata.get_size()\n+        return metadata\n+\n+    def free(self, obj: MemoryObj):\n+        \"\"\"Free the memory object.\n+        \"\"\"\n+        pass\n+\n+    def ref_count_up(self, obj: MemoryObj):\n+        \"\"\"Increase the reference count of the memory object.\n+        \"\"\"\n+        pass\n+\n+    def ref_count_down(self, obj: MemoryObj):\n+        \"\"\"Decrease the reference count of the memory object.\n+        \"\"\"\n+        pass\n+\n+    def get_ref_count(self, obj: MemoryObj) -> int:\n+        \"\"\"Get the reference count of the memory object.\n+        \"\"\"\n+        raise NotImplementedError\n+\n+    ### For NIXL Pipe to call\n+    def num_bytes_allocated(self) -> int:\n+        \"\"\"Get the number of bytes allocated.\n+\n+        Returns:\n+            The number of bytes allocated.\n+        \"\"\"\n+        return self.allocated_size\n+\n+    def reset_allocated_size(self):\n+        \"\"\"Reset the allocated size to 0.\n+        \"\"\"\n+        self.allocated_size = 0\n+\n+\n+@dataclass\n+class NixlRequest:\n+    \"\"\"\n+    A dataclass to represent a request received from the remote peer.\n+    This can be used to encapsulate the request information.\n+    \"\"\"\n+    keys: list[CacheEngineKey]\n+    metadatas: list[MemoryObjMetadata]\n+\n+    def serialize(self) -> bytes:\n+        return pickle.dumps(self)\n+\n+    @staticmethod\n+    def deserialize(s: bytes) -> \"NixlRequest\":\n+        return pickle.loads(s)\n+\n+\n+class NixlPipe:\n+    \"\"\"An one-directional pipe to send the data from the sender to the receiver.\n+    \"\"\"\n+    TRANSFER_BUFFER_SIZE = 128 * 1024 * 1024\n+\n+    def __init__(self, nixl_config: NixlConfig,\n+                 side_channel: zmq.Socket):  # type: ignore\n+        self.nixl_config = nixl_config\n+        self.side_channel = side_channel\n+\n+        if nixl_config.buffer_size > NixlPipe.TRANSFER_BUFFER_SIZE:\n+            assert \\\n+                nixl_config.buffer_size % NixlPipe.TRANSFER_BUFFER_SIZE == 0, \\\n+                f\"Buffer size must be a multiple of \"\\\n+                f\"{NixlPipe.TRANSFER_BUFFER_SIZE}\"\n+\n+        self._buffer = torch.empty(nixl_config.buffer_size,\n+                                   device=nixl_config.buffer_device,\n+                                   dtype=torch.uint8)\n+\n+        self._transfer_buffers = torch.split(self._buffer,\n+                                             NixlPipe.TRANSFER_BUFFER_SIZE,\n+                                             dim=0)\n+\n+        # allocator (should be initialized after self._buffer)\n+        self._allocator = NixlBufferAllocator(self)\n+\n+        self._agent = nixl_agent(str(nixl_config.role))\n+        self._reg_descs = self._agent.register_memory(self._transfer_buffers)\n+        self._local_xfer_descs = self._reg_descs.trim()\n+        self._remote_xfer_descs = None\n+        self._local_xfer_handlers = None\n+        self._remote_xfer_handlers = None\n+\n+        local_meta = self._agent.get_agent_metadata()\n+        if nixl_config.role == NixlRole.SENDER:\n+            self.side_channel.send(local_meta)\n+            remote_meta = self.side_channel.recv()\n+            self.peer_name = self._agent.add_remote_agent(remote_meta).decode(\n+                \"utf-8\")\n+        else:\n+            remote_meta = self.side_channel.recv()\n+            self.peer_name = self._agent.add_remote_agent(remote_meta).decode(\n+                \"utf-8\")\n+            self.side_channel.send(local_meta)\n+\n+        # Exchange the reg_descs\n+        if nixl_config.role == NixlRole.SENDER:\n+            msg = self.side_channel.recv()\n+            self._remote_xfer_descs = self._agent.deserialize_descs(msg)\n+            logger.info(\"Received remote transfer descriptors\")\n+\n+            # Prepare the local and remote xfer_dlist_handler\n+            self._local_xfer_handlers = self._agent.prep_xfer_dlist(\n+                \"\", self._local_xfer_descs)\n+            self._remote_xfer_handlers = self._agent.prep_xfer_dlist(\n+                self.peer_name, self._remote_xfer_descs)\n+        else:\n+            # Receiver side, send the local descriptors\n+            self.side_channel.send(\n+                self._agent.get_serialized_descs(self._local_xfer_descs))\n+            logger.info(\"Sent local transfer descriptors to sender\")\n+\n+        # UUID for communication\n+        self._uuid = None\n+        if nixl_config.role == NixlRole.RECEIVER:\n+            # Receiver send an initial uuid to sender\n+            self._uuid = uuid.uuid4().hex\n+            self.ack_receive()\n+\n+    def _spin_check_for_ack(self) -> str:\n+        \"\"\"\n+        Spin until receives an ack from the peer.\n+\n+        Returns:\n+            The uuid extracted from the ack message.\n+        \"\"\"\n+        receiver_ready = False\n+        while not receiver_ready:\n+            notifs = self._agent.get_new_notifs()\n+            if self.peer_name not in notifs:\n+                time.sleep(0.001)\n+                continue\n+\n+            for notif in notifs[self.peer_name]:\n+                decoded_uuid = message_to_uuid(notif.decode(\"utf-8\"))\n+                if decoded_uuid is not None:\n+                    return decoded_uuid\n+            time.sleep(0.001)  # Avoid busy waiting\n+\n+        raise RuntimeError(\"Failed to receive ACK from remote peer\")\n+\n+    def _commit_write(self, write_size: int, uid: str):\n+        \"\"\"A blocking function that ensures the write buffer is delivered to\n+        the receiver.\n+        \n+        The transfer is initialized with the uuid.\n+        \n+        Args:\n+            write_size: the size of the data that is written into the buffer\n+            uuid: the uuid of the transfer\n+\n+        Raises:\n+            RuntimeError: if the transfer fails\n+        \"\"\"\n+        # Send the data to the remote peer\n+        num_transfers = (write_size - 1) // NixlPipe.TRANSFER_BUFFER_SIZE + 1\n+        desc_indexes = list(range(num_transfers))\n+        logger.debug(f\"Committing write of {write_size / 1024 / 1024} \"\n+                     f\"MB with {num_transfers} transfers\")\n+\n+        t1 = time.perf_counter()\n+        handle = self._agent.make_prepped_xfer(\"WRITE\",",
        "comment_created_at": "2025-04-21T12:03:54+00:00",
        "comment_author": "robertgshaw2-redhat",
        "comment_body": "See https://github.com/ApostaC/LMCache/pull/1",
        "pr_file_module": null
      },
      {
        "comment_id": "2052744793",
        "repo_full_name": "LMCache/LMCache",
        "pr_number": 465,
        "pr_file": "lmcache/experimental/storage_backend/connector/nixl_connector_v2.py",
        "discussion_id": "2052304573",
        "commented_code": "@@ -0,0 +1,691 @@\n+# Copyright 2024-2025 LMCache Authors.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import abc\n+import pickle\n+import threading\n+import time\n+import uuid\n+from dataclasses import dataclass\n+from typing import Callable, Optional, Union\n+\n+import torch\n+import zmq\n+from nixl._api import nixl_agent\n+\n+from lmcache.experimental.memory_management import (MemoryAllocatorInterface,\n+                                                    MemoryFormat, MemoryObj,\n+                                                    MemoryObjMetadata,\n+                                                    TensorMemoryObj)\n+from lmcache.experimental.storage_backend.connector.nixl_connector import (\n+    NixlConfig, NixlRole)\n+from lmcache.logging import init_logger\n+from lmcache.utils import CacheEngineKey\n+\n+logger = init_logger(__name__)\n+\n+\n+class NixlBufferAllocator(MemoryAllocatorInterface):\n+    \"\"\"The memory allocator on NIXL transfer buffer.\n+    \"\"\"\n+\n+    def __init__(self, nixl_pipe: \"NixlPipe\"):\n+        self.nixl_pipe = nixl_pipe\n+        self.buffer = nixl_pipe._buffer\n+        self.capacity = nixl_pipe.nixl_config.buffer_size\n+\n+        self.allocated_size = 0\n+\n+    def _flush(self):\n+        self.nixl_pipe.flush()\n+        self.allocated_size = 0\n+\n+    def allocate(\n+        self,\n+        shape: Union[torch.Size, tuple[int, ...]],\n+        dtype: Optional[torch.dtype],\n+        fmt: MemoryFormat = MemoryFormat.KV_BLOB,\n+    ) -> Optional[MemoryObj]:\n+        \"\"\"\n+        Allocates the memory to hold a tensor of the given shape.\n+\n+        :param torch.Size shape: The shape of the tensor to allocate.\n+        :param torch.dtype dtype: The dtype of the tensor to allocate.\n+        :param MemoryFormat fmt: The format of the memory to allocate.\n+        \n+        :return: A MemoryObj wrapping the allocated memory. Returns\n+            None if the allocation failed.\n+\n+        :rtype: Optional[MemoryObj]\n+        \"\"\"\n+        metadata = self.dry_allocate(shape, dtype, fmt)\n+        metadata.address = self.allocated_size\n+\n+        # check the size and capacity\n+        required_size = metadata.get_size()\n+        assert required_size < self.capacity, \\\n+            \"The object size is larger than the NIXL buffer capacity\"\n+\n+        if self.allocated_size + required_size > self.capacity:\n+            # If no enough space, try to flush\n+            self._flush()\n+\n+        # allocate the memory\n+        raw_tensor = self.buffer[self.allocated_size : self.allocated_size\\\n+                + required_size]\n+        ret = TensorMemoryObj(raw_data=raw_tensor, metadata=metadata)\n+        self.allocated_size += required_size\n+        return ret\n+\n+    def dry_allocate(\n+        self,\n+        shape: torch.Size,\n+        dtype: Optional[torch.dtype],\n+        fmt: MemoryFormat = MemoryFormat.KV_BLOB,\n+    ) -> MemoryObjMetadata:\n+        \"\"\"Dry allocate the memory and return the metadata.\n+\n+        Note: `address` is not valid in the dry allocation.\n+        \"\"\"\n+        metadata = MemoryObjMetadata(shape,\n+                                     dtype,\n+                                     address=0,\n+                                     phy_size=0,\n+                                     ref_count=1,\n+                                     fmt=fmt)\n+        metadata.phy_size = metadata.get_size()\n+        return metadata\n+\n+    def free(self, obj: MemoryObj):\n+        \"\"\"Free the memory object.\n+        \"\"\"\n+        pass\n+\n+    def ref_count_up(self, obj: MemoryObj):\n+        \"\"\"Increase the reference count of the memory object.\n+        \"\"\"\n+        pass\n+\n+    def ref_count_down(self, obj: MemoryObj):\n+        \"\"\"Decrease the reference count of the memory object.\n+        \"\"\"\n+        pass\n+\n+    def get_ref_count(self, obj: MemoryObj) -> int:\n+        \"\"\"Get the reference count of the memory object.\n+        \"\"\"\n+        raise NotImplementedError\n+\n+    ### For NIXL Pipe to call\n+    def num_bytes_allocated(self) -> int:\n+        \"\"\"Get the number of bytes allocated.\n+\n+        Returns:\n+            The number of bytes allocated.\n+        \"\"\"\n+        return self.allocated_size\n+\n+    def reset_allocated_size(self):\n+        \"\"\"Reset the allocated size to 0.\n+        \"\"\"\n+        self.allocated_size = 0\n+\n+\n+@dataclass\n+class NixlRequest:\n+    \"\"\"\n+    A dataclass to represent a request received from the remote peer.\n+    This can be used to encapsulate the request information.\n+    \"\"\"\n+    keys: list[CacheEngineKey]\n+    metadatas: list[MemoryObjMetadata]\n+\n+    def serialize(self) -> bytes:\n+        return pickle.dumps(self)\n+\n+    @staticmethod\n+    def deserialize(s: bytes) -> \"NixlRequest\":\n+        return pickle.loads(s)\n+\n+\n+class NixlPipe:\n+    \"\"\"An one-directional pipe to send the data from the sender to the receiver.\n+    \"\"\"\n+    TRANSFER_BUFFER_SIZE = 128 * 1024 * 1024\n+\n+    def __init__(self, nixl_config: NixlConfig,\n+                 side_channel: zmq.Socket):  # type: ignore\n+        self.nixl_config = nixl_config\n+        self.side_channel = side_channel\n+\n+        if nixl_config.buffer_size > NixlPipe.TRANSFER_BUFFER_SIZE:\n+            assert \\\n+                nixl_config.buffer_size % NixlPipe.TRANSFER_BUFFER_SIZE == 0, \\\n+                f\"Buffer size must be a multiple of \"\\\n+                f\"{NixlPipe.TRANSFER_BUFFER_SIZE}\"\n+\n+        self._buffer = torch.empty(nixl_config.buffer_size,\n+                                   device=nixl_config.buffer_device,\n+                                   dtype=torch.uint8)\n+\n+        self._transfer_buffers = torch.split(self._buffer,\n+                                             NixlPipe.TRANSFER_BUFFER_SIZE,\n+                                             dim=0)\n+\n+        # allocator (should be initialized after self._buffer)\n+        self._allocator = NixlBufferAllocator(self)\n+\n+        self._agent = nixl_agent(str(nixl_config.role))\n+        self._reg_descs = self._agent.register_memory(self._transfer_buffers)\n+        self._local_xfer_descs = self._reg_descs.trim()\n+        self._remote_xfer_descs = None\n+        self._local_xfer_handlers = None\n+        self._remote_xfer_handlers = None\n+\n+        local_meta = self._agent.get_agent_metadata()\n+        if nixl_config.role == NixlRole.SENDER:\n+            self.side_channel.send(local_meta)\n+            remote_meta = self.side_channel.recv()\n+            self.peer_name = self._agent.add_remote_agent(remote_meta).decode(\n+                \"utf-8\")\n+        else:\n+            remote_meta = self.side_channel.recv()\n+            self.peer_name = self._agent.add_remote_agent(remote_meta).decode(\n+                \"utf-8\")\n+            self.side_channel.send(local_meta)\n+\n+        # Exchange the reg_descs\n+        if nixl_config.role == NixlRole.SENDER:\n+            msg = self.side_channel.recv()\n+            self._remote_xfer_descs = self._agent.deserialize_descs(msg)\n+            logger.info(\"Received remote transfer descriptors\")\n+\n+            # Prepare the local and remote xfer_dlist_handler\n+            self._local_xfer_handlers = self._agent.prep_xfer_dlist(\n+                \"\", self._local_xfer_descs)\n+            self._remote_xfer_handlers = self._agent.prep_xfer_dlist(\n+                self.peer_name, self._remote_xfer_descs)\n+        else:\n+            # Receiver side, send the local descriptors\n+            self.side_channel.send(\n+                self._agent.get_serialized_descs(self._local_xfer_descs))\n+            logger.info(\"Sent local transfer descriptors to sender\")\n+\n+        # UUID for communication\n+        self._uuid = None\n+        if nixl_config.role == NixlRole.RECEIVER:\n+            # Receiver send an initial uuid to sender\n+            self._uuid = uuid.uuid4().hex\n+            self.ack_receive()\n+\n+    def _spin_check_for_ack(self) -> str:\n+        \"\"\"\n+        Spin until receives an ack from the peer.\n+\n+        Returns:\n+            The uuid extracted from the ack message.\n+        \"\"\"\n+        receiver_ready = False\n+        while not receiver_ready:\n+            notifs = self._agent.get_new_notifs()\n+            if self.peer_name not in notifs:\n+                time.sleep(0.001)\n+                continue\n+\n+            for notif in notifs[self.peer_name]:\n+                decoded_uuid = message_to_uuid(notif.decode(\"utf-8\"))\n+                if decoded_uuid is not None:\n+                    return decoded_uuid\n+            time.sleep(0.001)  # Avoid busy waiting\n+\n+        raise RuntimeError(\"Failed to receive ACK from remote peer\")\n+\n+    def _commit_write(self, write_size: int, uid: str):\n+        \"\"\"A blocking function that ensures the write buffer is delivered to\n+        the receiver.\n+        \n+        The transfer is initialized with the uuid.\n+        \n+        Args:\n+            write_size: the size of the data that is written into the buffer\n+            uuid: the uuid of the transfer\n+\n+        Raises:\n+            RuntimeError: if the transfer fails\n+        \"\"\"\n+        # Send the data to the remote peer\n+        num_transfers = (write_size - 1) // NixlPipe.TRANSFER_BUFFER_SIZE + 1\n+        desc_indexes = list(range(num_transfers))\n+        logger.debug(f\"Committing write of {write_size / 1024 / 1024} \"\n+                     f\"MB with {num_transfers} transfers\")\n+\n+        t1 = time.perf_counter()\n+        handle = self._agent.make_prepped_xfer(\"WRITE\",",
        "comment_created_at": "2025-04-21T17:23:52+00:00",
        "comment_author": "ApostaC",
        "comment_body": "Actually, this won't work. When testing locally using nvlink, we found that the notif message will arrive at the receiver side before the data transmission is finished. \r\nWe have tried Dynamo on NVLink and saw wrong outputs (highly likely because of this problem)",
        "pr_file_module": null
      }
    ]
  }
]