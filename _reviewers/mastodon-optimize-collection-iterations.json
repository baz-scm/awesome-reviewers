[
  {
    "discussion_id": "2072315161",
    "pr_number": 34595,
    "pr_file": "app/services/activitypub/synchronize_followers_service.rb",
    "created_at": "2025-05-03T04:22:53+00:00",
    "commented_code": "# Only returns true if the whole collection has been processed\n   def process_collection!(collection_uri, max_pages: MAX_COLLECTION_PAGES)\n-    collection = fetch_collection(collection_uri)\n+    collection = fetch_collection(collection_uri, reference_uri: @account.uri)",
    "repo_full_name": "mastodon/mastodon",
    "discussion_comments": [
      {
        "comment_id": "2072315161",
        "repo_full_name": "mastodon/mastodon",
        "pr_number": 34595,
        "pr_file": "app/services/activitypub/synchronize_followers_service.rb",
        "discussion_id": "2072315161",
        "commented_code": "@@ -63,10 +63,10 @@ def build_undo_follow_json(follow)\n \n   # Only returns true if the whole collection has been processed\n   def process_collection!(collection_uri, max_pages: MAX_COLLECTION_PAGES)\n-    collection = fetch_collection(collection_uri)\n+    collection = fetch_collection(collection_uri, reference_uri: @account.uri)",
        "comment_created_at": "2025-05-03T04:22:53+00:00",
        "comment_author": "sneakers-the-rat",
        "comment_body": "this class still partially duplicates iteration over a collection because it processes each page as it gets it. we may want to have some callback function that can be provided to do this in the main iterator. in discord shadow jonathan also linked to some fancy sidekiq iterator thing. tried to keep things equivalent in this PR but we can explore that later",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2024386434",
    "pr_number": 34349,
    "pr_file": "app/lib/activitypub/tag_manager.rb",
    "created_at": "2025-04-02T08:53:05+00:00",
    "commented_code": "path_params[param]\n   end\n \n+  def uri_to_local_account_params(uri)\n+    return unless local_uri?(uri)\n+\n+    path_params = Rails.application.routes.recognize_path(uri)\n+\n+    # TODO: handle numeric IDs\n+    case path_params[:controller]\n+    when 'accounts'\n+      [:username, path_params[:username]]\n+    when 'instance_actors'\n+      [:id, -99]\n+    end\n+  end\n+\n+  def uri_to_local_account(uri)\n+    param, value = uri_to_local_account_params(uri)\n+\n+    case param\n+    when :username\n+      Account.find_local(value)\n+    when :id\n+      Account.find_by(id: value)\n+    end\n+  end\n+\n+  def uris_to_local_accounts(uris)\n+    params = uris.filter_map { |uri| uri_to_local_account_params(uri) }\n+    usernames = params.filter_map { |param, value| value.downcase if param == :username }\n+    ids = params.filter_map { |param, value| value if param == :id }",
    "repo_full_name": "mastodon/mastodon",
    "discussion_comments": [
      {
        "comment_id": "2024386434",
        "repo_full_name": "mastodon/mastodon",
        "pr_number": 34349,
        "pr_file": "app/lib/activitypub/tag_manager.rb",
        "discussion_id": "2024386434",
        "commented_code": "@@ -203,6 +203,39 @@ def uri_to_local_id(uri, param = :id)\n     path_params[param]\n   end\n \n+  def uri_to_local_account_params(uri)\n+    return unless local_uri?(uri)\n+\n+    path_params = Rails.application.routes.recognize_path(uri)\n+\n+    # TODO: handle numeric IDs\n+    case path_params[:controller]\n+    when 'accounts'\n+      [:username, path_params[:username]]\n+    when 'instance_actors'\n+      [:id, -99]\n+    end\n+  end\n+\n+  def uri_to_local_account(uri)\n+    param, value = uri_to_local_account_params(uri)\n+\n+    case param\n+    when :username\n+      Account.find_local(value)\n+    when :id\n+      Account.find_by(id: value)\n+    end\n+  end\n+\n+  def uris_to_local_accounts(uris)\n+    params = uris.filter_map { |uri| uri_to_local_account_params(uri) }\n+    usernames = params.filter_map { |param, value| value.downcase if param == :username }\n+    ids = params.filter_map { |param, value| value if param == :id }",
        "comment_created_at": "2025-04-02T08:53:05+00:00",
        "comment_author": "oneiros",
        "comment_body": "I am not a big fan of having three separate array traversals here. I think it should be possible to iterate over `uris` once and gather the `usernames` and `ids` along the way. The resulting code may be a bit more verbose, but might also be clearer and perform better.",
        "pr_file_module": null
      },
      {
        "comment_id": "2024443245",
        "repo_full_name": "mastodon/mastodon",
        "pr_number": 34349,
        "pr_file": "app/lib/activitypub/tag_manager.rb",
        "discussion_id": "2024386434",
        "commented_code": "@@ -203,6 +203,39 @@ def uri_to_local_id(uri, param = :id)\n     path_params[param]\n   end\n \n+  def uri_to_local_account_params(uri)\n+    return unless local_uri?(uri)\n+\n+    path_params = Rails.application.routes.recognize_path(uri)\n+\n+    # TODO: handle numeric IDs\n+    case path_params[:controller]\n+    when 'accounts'\n+      [:username, path_params[:username]]\n+    when 'instance_actors'\n+      [:id, -99]\n+    end\n+  end\n+\n+  def uri_to_local_account(uri)\n+    param, value = uri_to_local_account_params(uri)\n+\n+    case param\n+    when :username\n+      Account.find_local(value)\n+    when :id\n+      Account.find_by(id: value)\n+    end\n+  end\n+\n+  def uris_to_local_accounts(uris)\n+    params = uris.filter_map { |uri| uri_to_local_account_params(uri) }\n+    usernames = params.filter_map { |param, value| value.downcase if param == :username }\n+    ids = params.filter_map { |param, value| value if param == :id }",
        "comment_created_at": "2025-04-02T09:23:58+00:00",
        "comment_author": "ClearlyClaire",
        "comment_body": "Hm\u2026 maybe something like the following? It seems to perform about the same, but is much more verbose:\r\n```suggestion\r\n    usernames = []\r\n    ids = []\r\n\r\n    uris.each do |uri|\r\n      param, value = uri_to_local_account_params(uri)\r\n\r\n      case param\r\n      when :username\r\n        usernames << value.downcase\r\n      when :id\r\n        ids << value\r\n      end\r\n    end\r\n\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2024506936",
        "repo_full_name": "mastodon/mastodon",
        "pr_number": 34349,
        "pr_file": "app/lib/activitypub/tag_manager.rb",
        "discussion_id": "2024386434",
        "commented_code": "@@ -203,6 +203,39 @@ def uri_to_local_id(uri, param = :id)\n     path_params[param]\n   end\n \n+  def uri_to_local_account_params(uri)\n+    return unless local_uri?(uri)\n+\n+    path_params = Rails.application.routes.recognize_path(uri)\n+\n+    # TODO: handle numeric IDs\n+    case path_params[:controller]\n+    when 'accounts'\n+      [:username, path_params[:username]]\n+    when 'instance_actors'\n+      [:id, -99]\n+    end\n+  end\n+\n+  def uri_to_local_account(uri)\n+    param, value = uri_to_local_account_params(uri)\n+\n+    case param\n+    when :username\n+      Account.find_local(value)\n+    when :id\n+      Account.find_by(id: value)\n+    end\n+  end\n+\n+  def uris_to_local_accounts(uris)\n+    params = uris.filter_map { |uri| uri_to_local_account_params(uri) }\n+    usernames = params.filter_map { |param, value| value.downcase if param == :username }\n+    ids = params.filter_map { |param, value| value if param == :id }",
        "comment_created_at": "2025-04-02T09:59:31+00:00",
        "comment_author": "oneiros",
        "comment_body": "Yes, I think that is a lot clearer.\r\n\r\nIf you worry about the verbosity, here are a couple of ideas:\r\n\r\n1. Using postfix `if` statements would replace the `case` statement with two lines.\r\n2. This could be a use-case for \"pattern matching\":\r\n    ```ruby\r\n    case uri_to_local_account_params(uri)\r\n    in [:username, value]\r\n      usernames << value.downcase\r\n    in [:id, value]\r\n      ids << value\r\n    end\r\n    ```\r\n    (Fun fact: I have *never* actually used pattern matching before, mainly because I never encountered - or probably rather never recognized - a proper use-case. This is the first time.)\r\n3. Use `Array#inject` and do something very fancy like `usernames, ids = uris.inject([[], []]) do |memo, param| #...`. But I think that would be a lot less readable.",
        "pr_file_module": null
      },
      {
        "comment_id": "2024517607",
        "repo_full_name": "mastodon/mastodon",
        "pr_number": 34349,
        "pr_file": "app/lib/activitypub/tag_manager.rb",
        "discussion_id": "2024386434",
        "commented_code": "@@ -203,6 +203,39 @@ def uri_to_local_id(uri, param = :id)\n     path_params[param]\n   end\n \n+  def uri_to_local_account_params(uri)\n+    return unless local_uri?(uri)\n+\n+    path_params = Rails.application.routes.recognize_path(uri)\n+\n+    # TODO: handle numeric IDs\n+    case path_params[:controller]\n+    when 'accounts'\n+      [:username, path_params[:username]]\n+    when 'instance_actors'\n+      [:id, -99]\n+    end\n+  end\n+\n+  def uri_to_local_account(uri)\n+    param, value = uri_to_local_account_params(uri)\n+\n+    case param\n+    when :username\n+      Account.find_local(value)\n+    when :id\n+      Account.find_by(id: value)\n+    end\n+  end\n+\n+  def uris_to_local_accounts(uris)\n+    params = uris.filter_map { |uri| uri_to_local_account_params(uri) }\n+    usernames = params.filter_map { |param, value| value.downcase if param == :username }\n+    ids = params.filter_map { |param, value| value if param == :id }",
        "comment_created_at": "2025-04-02T10:06:23+00:00",
        "comment_author": "ClearlyClaire",
        "comment_body": "Yeah I suppose the following is ok:\r\n```suggestion\r\n    usernames = []\r\n    ids = []\r\n\r\n    uris.each do |uri|\r\n      param, value = uri_to_local_account_params(uri)\r\n      usernames << value.downcase if param == :username\r\n      ids << value if param == :id\r\n    end\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1925252001",
    "pr_number": 32615,
    "pr_file": "app/workers/activitypub/fetch_all_replies_worker.rb",
    "created_at": "2025-01-22T12:38:53+00:00",
    "commented_code": "+# frozen_string_literal: true\n+\n+# Fetch all replies to a status, querying recursively through\n+# ActivityPub replies collections, fetching any statuses that\n+# we either don't already have or we haven't checked for new replies\n+# in the Status::FETCH_REPLIES_COOLDOWN_MINUTES interval\n+class ActivityPub::FetchAllRepliesWorker\n+  include Sidekiq::Worker\n+  include ExponentialBackoff\n+  include JsonLdHelper\n+\n+  sidekiq_options queue: 'pull', retry: 3\n+\n+  # Global max replies to fetch per request (all replies, recursively)\n+  MAX_REPLIES = (ENV['FETCH_REPLIES_MAX_GLOBAL'] || 1000).to_i\n+  MAX_PAGES = (ENV['FETCH_REPLIES_MAX_PAGES'] || 500).to_i\n+\n+  def perform(parent_status_id, options = {})\n+    @parent_status = Status.find(parent_status_id)\n+    return unless @parent_status.should_fetch_replies?\n+\n+    @parent_status.touch(:fetched_replies_at)\n+    Rails.logger.debug { \"FetchAllRepliesWorker - #{@parent_status.uri}: Fetching all replies for status: #{@parent_status}\" }\n+\n+    uris_to_fetch, n_pages = get_replies(@parent_status.uri, MAX_PAGES, options)\n+    return if uris_to_fetch.nil?\n+\n+    fetched_uris = uris_to_fetch.clone.to_set\n+\n+    until uris_to_fetch.empty? || fetched_uris.length >= MAX_REPLIES || n_pages >= MAX_PAGES\n+      next_reply = uris_to_fetch.pop\n+      next if next_reply.nil?\n+\n+      new_reply_uris, new_n_pages = get_replies(next_reply, MAX_PAGES - n_pages, options)\n+      next if new_reply_uris.nil?\n+\n+      new_reply_uris = new_reply_uris.reject { |uri| fetched_uris.include?(uri) }\n+\n+      uris_to_fetch.concat(new_reply_uris)\n+      fetched_uris = fetched_uris.merge(new_reply_uris)\n+      n_pages += new_n_pages\n+    end",
    "repo_full_name": "mastodon/mastodon",
    "discussion_comments": [
      {
        "comment_id": "1925252001",
        "repo_full_name": "mastodon/mastodon",
        "pr_number": 32615,
        "pr_file": "app/workers/activitypub/fetch_all_replies_worker.rb",
        "discussion_id": "1925252001",
        "commented_code": "@@ -0,0 +1,77 @@\n+# frozen_string_literal: true\n+\n+# Fetch all replies to a status, querying recursively through\n+# ActivityPub replies collections, fetching any statuses that\n+# we either don't already have or we haven't checked for new replies\n+# in the Status::FETCH_REPLIES_COOLDOWN_MINUTES interval\n+class ActivityPub::FetchAllRepliesWorker\n+  include Sidekiq::Worker\n+  include ExponentialBackoff\n+  include JsonLdHelper\n+\n+  sidekiq_options queue: 'pull', retry: 3\n+\n+  # Global max replies to fetch per request (all replies, recursively)\n+  MAX_REPLIES = (ENV['FETCH_REPLIES_MAX_GLOBAL'] || 1000).to_i\n+  MAX_PAGES = (ENV['FETCH_REPLIES_MAX_PAGES'] || 500).to_i\n+\n+  def perform(parent_status_id, options = {})\n+    @parent_status = Status.find(parent_status_id)\n+    return unless @parent_status.should_fetch_replies?\n+\n+    @parent_status.touch(:fetched_replies_at)\n+    Rails.logger.debug { \"FetchAllRepliesWorker - #{@parent_status.uri}: Fetching all replies for status: #{@parent_status}\" }\n+\n+    uris_to_fetch, n_pages = get_replies(@parent_status.uri, MAX_PAGES, options)\n+    return if uris_to_fetch.nil?\n+\n+    fetched_uris = uris_to_fetch.clone.to_set\n+\n+    until uris_to_fetch.empty? || fetched_uris.length >= MAX_REPLIES || n_pages >= MAX_PAGES\n+      next_reply = uris_to_fetch.pop\n+      next if next_reply.nil?\n+\n+      new_reply_uris, new_n_pages = get_replies(next_reply, MAX_PAGES - n_pages, options)\n+      next if new_reply_uris.nil?\n+\n+      new_reply_uris = new_reply_uris.reject { |uri| fetched_uris.include?(uri) }\n+\n+      uris_to_fetch.concat(new_reply_uris)\n+      fetched_uris = fetched_uris.merge(new_reply_uris)\n+      n_pages += new_n_pages\n+    end",
        "comment_created_at": "2025-01-22T12:38:53+00:00",
        "comment_author": "ClearlyClaire",
        "comment_body": "If I understand correctly, this will recursively fetch posts even if those have already been fetched recently? I mean, the `should_fetch_replies?` is only fetched for the root post in the recursive crawling. So basically, if you check the context for a post *then* for its parent post, you'd end up doing the work twice.",
        "pr_file_module": null
      },
      {
        "comment_id": "1926036154",
        "repo_full_name": "mastodon/mastodon",
        "pr_number": 32615,
        "pr_file": "app/workers/activitypub/fetch_all_replies_worker.rb",
        "discussion_id": "1925252001",
        "commented_code": "@@ -0,0 +1,77 @@\n+# frozen_string_literal: true\n+\n+# Fetch all replies to a status, querying recursively through\n+# ActivityPub replies collections, fetching any statuses that\n+# we either don't already have or we haven't checked for new replies\n+# in the Status::FETCH_REPLIES_COOLDOWN_MINUTES interval\n+class ActivityPub::FetchAllRepliesWorker\n+  include Sidekiq::Worker\n+  include ExponentialBackoff\n+  include JsonLdHelper\n+\n+  sidekiq_options queue: 'pull', retry: 3\n+\n+  # Global max replies to fetch per request (all replies, recursively)\n+  MAX_REPLIES = (ENV['FETCH_REPLIES_MAX_GLOBAL'] || 1000).to_i\n+  MAX_PAGES = (ENV['FETCH_REPLIES_MAX_PAGES'] || 500).to_i\n+\n+  def perform(parent_status_id, options = {})\n+    @parent_status = Status.find(parent_status_id)\n+    return unless @parent_status.should_fetch_replies?\n+\n+    @parent_status.touch(:fetched_replies_at)\n+    Rails.logger.debug { \"FetchAllRepliesWorker - #{@parent_status.uri}: Fetching all replies for status: #{@parent_status}\" }\n+\n+    uris_to_fetch, n_pages = get_replies(@parent_status.uri, MAX_PAGES, options)\n+    return if uris_to_fetch.nil?\n+\n+    fetched_uris = uris_to_fetch.clone.to_set\n+\n+    until uris_to_fetch.empty? || fetched_uris.length >= MAX_REPLIES || n_pages >= MAX_PAGES\n+      next_reply = uris_to_fetch.pop\n+      next if next_reply.nil?\n+\n+      new_reply_uris, new_n_pages = get_replies(next_reply, MAX_PAGES - n_pages, options)\n+      next if new_reply_uris.nil?\n+\n+      new_reply_uris = new_reply_uris.reject { |uri| fetched_uris.include?(uri) }\n+\n+      uris_to_fetch.concat(new_reply_uris)\n+      fetched_uris = fetched_uris.merge(new_reply_uris)\n+      n_pages += new_n_pages\n+    end",
        "comment_created_at": "2025-01-22T22:00:17+00:00",
        "comment_author": "sneakers-the-rat",
        "comment_body": "Removing recently fetched replies happens in the filtered replies method: https://github.com/mastodon/mastodon/blob/93f95e10cdd52f2c21160fb122273b6aa143a78c/app/services/activitypub/fetch_all_replies_service.rb#L54\r\n\r\nAnd then updating the last fetched timestamp happens (before workers are dispatched) in the next line to avoid race conditions from e.g. if we updated that timestamp when the status was actually fetched\r\n\r\nThis is bc within the worker we operate only on URIs, and it is unknown for each whether we have it in the DB or not. That method seemed like the obvious place to put it: fetch all URIs from the collection, then as soon as we have it filter it to be the collection we want to fetch, dispatch workers, return to parent worker what we've done. Makes fetching replies under a single status contained in the service, and the parent worker is just for iteration/limiting.\r\n\r\nWe could do it up here if that would be better!",
        "pr_file_module": null
      },
      {
        "comment_id": "1926054940",
        "repo_full_name": "mastodon/mastodon",
        "pr_number": 32615,
        "pr_file": "app/workers/activitypub/fetch_all_replies_worker.rb",
        "discussion_id": "1925252001",
        "commented_code": "@@ -0,0 +1,77 @@\n+# frozen_string_literal: true\n+\n+# Fetch all replies to a status, querying recursively through\n+# ActivityPub replies collections, fetching any statuses that\n+# we either don't already have or we haven't checked for new replies\n+# in the Status::FETCH_REPLIES_COOLDOWN_MINUTES interval\n+class ActivityPub::FetchAllRepliesWorker\n+  include Sidekiq::Worker\n+  include ExponentialBackoff\n+  include JsonLdHelper\n+\n+  sidekiq_options queue: 'pull', retry: 3\n+\n+  # Global max replies to fetch per request (all replies, recursively)\n+  MAX_REPLIES = (ENV['FETCH_REPLIES_MAX_GLOBAL'] || 1000).to_i\n+  MAX_PAGES = (ENV['FETCH_REPLIES_MAX_PAGES'] || 500).to_i\n+\n+  def perform(parent_status_id, options = {})\n+    @parent_status = Status.find(parent_status_id)\n+    return unless @parent_status.should_fetch_replies?\n+\n+    @parent_status.touch(:fetched_replies_at)\n+    Rails.logger.debug { \"FetchAllRepliesWorker - #{@parent_status.uri}: Fetching all replies for status: #{@parent_status}\" }\n+\n+    uris_to_fetch, n_pages = get_replies(@parent_status.uri, MAX_PAGES, options)\n+    return if uris_to_fetch.nil?\n+\n+    fetched_uris = uris_to_fetch.clone.to_set\n+\n+    until uris_to_fetch.empty? || fetched_uris.length >= MAX_REPLIES || n_pages >= MAX_PAGES\n+      next_reply = uris_to_fetch.pop\n+      next if next_reply.nil?\n+\n+      new_reply_uris, new_n_pages = get_replies(next_reply, MAX_PAGES - n_pages, options)\n+      next if new_reply_uris.nil?\n+\n+      new_reply_uris = new_reply_uris.reject { |uri| fetched_uris.include?(uri) }\n+\n+      uris_to_fetch.concat(new_reply_uris)\n+      fetched_uris = fetched_uris.merge(new_reply_uris)\n+      n_pages += new_n_pages\n+    end",
        "comment_created_at": "2025-01-22T22:20:29+00:00",
        "comment_author": "sneakers-the-rat",
        "comment_body": "This tests for not re-fetching recently fetched statuses, but I could add a specific integration test for the worker that is \"fetch the child, then fetch the parent, confirm the child is not fetched again\"\r\n\r\nhttps://github.com/mastodon/mastodon/blob/93f95e10cdd52f2c21160fb122273b6aa143a78c/spec/services/activitypub/fetch_all_replies_service_spec.rb#L45-L57",
        "pr_file_module": null
      }
    ]
  }
]