[
  {
    "discussion_id": "2143172031",
    "pr_number": 4493,
    "pr_file": "packages/zero-client/src/client/context.ts",
    "created_at": "2025-06-12T16:22:46+00:00",
    "commented_code": "duration,\n       );\n     }\n+\n+    // Add a histogram for the materialization duration.\n+    let histogram = this.#materializeHistograms.get(hash);\n+    if (histogram === undefined) {\n+      histogram = new LogarithmicHistogram();\n+      this.#materializeHistograms.set(hash, histogram);\n+    }",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "2143172031",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4493,
        "pr_file": "packages/zero-client/src/client/context.ts",
        "discussion_id": "2143172031",
        "commented_code": "@@ -123,6 +135,14 @@ export class ZeroContext implements QueryDelegate {\n         duration,\n       );\n     }\n+\n+    // Add a histogram for the materialization duration.\n+    let histogram = this.#materializeHistograms.get(hash);\n+    if (histogram === undefined) {\n+      histogram = new LogarithmicHistogram();\n+      this.#materializeHistograms.set(hash, histogram);\n+    }",
        "comment_created_at": "2025-06-12T16:22:46+00:00",
        "comment_author": "tantaman",
        "comment_body": "where do the histograms get cleaned up?",
        "pr_file_module": null
      },
      {
        "comment_id": "2143461291",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4493,
        "pr_file": "packages/zero-client/src/client/context.ts",
        "discussion_id": "2143172031",
        "commented_code": "@@ -123,6 +135,14 @@ export class ZeroContext implements QueryDelegate {\n         duration,\n       );\n     }\n+\n+    // Add a histogram for the materialization duration.\n+    let histogram = this.#materializeHistograms.get(hash);\n+    if (histogram === undefined) {\n+      histogram = new LogarithmicHistogram();\n+      this.#materializeHistograms.set(hash, histogram);\n+    }",
        "comment_created_at": "2025-06-12T19:23:27+00:00",
        "comment_author": "arv",
        "comment_body": "They do not get cleaned up. They are in kept memory. One of the benefits of histograms is that they have a very small memory and runtime footprint.",
        "pr_file_module": null
      },
      {
        "comment_id": "2145159999",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4493,
        "pr_file": "packages/zero-client/src/client/context.ts",
        "discussion_id": "2143172031",
        "commented_code": "@@ -123,6 +135,14 @@ export class ZeroContext implements QueryDelegate {\n         duration,\n       );\n     }\n+\n+    // Add a histogram for the materialization duration.\n+    let histogram = this.#materializeHistograms.get(hash);\n+    if (histogram === undefined) {\n+      histogram = new LogarithmicHistogram();\n+      this.#materializeHistograms.set(hash, histogram);\n+    }",
        "comment_created_at": "2025-06-13T13:56:04+00:00",
        "comment_author": "tantaman",
        "comment_body": "but when someone is using a typeahead there will be 1 histogram per keystroke. Feels like there should be some bound on how many we keep.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2122420202",
    "pr_number": 4434,
    "pr_file": "packages/zero-cache/src/db/pg-copy.ts",
    "created_at": "2025-06-03T01:23:14+00:00",
    "commented_code": "switch (ch) {\n           case 0x5c: // '\\'\n             // flush segment\n-            l < r && (this.#currVal += text.substring(l, r));\n+            l < r && (this.#currVal += chunk.subarray(l, r).toString('utf8'));",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "2122420202",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4434,
        "pr_file": "packages/zero-cache/src/db/pg-copy.ts",
        "discussion_id": "2122420202",
        "commented_code": "@@ -47,15 +45,15 @@ export class TextTransform extends Transform {\n         switch (ch) {\n           case 0x5c: // '\\'\n             // flush segment\n-            l < r && (this.#currVal += text.substring(l, r));\n+            l < r && (this.#currVal += chunk.subarray(l, r).toString('utf8'));",
        "comment_created_at": "2025-06-03T01:23:14+00:00",
        "comment_author": "aboodman",
        "comment_body": "These repeated `toString('utf8')` calls look sus to me. You could try pushing the string segments onto an array and joining. But otoh they aren't stressing the mac.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1993637868",
    "pr_number": 3935,
    "pr_file": "packages/zero-cache/src/services/replicator/change-processor.ts",
    "created_at": "2025-03-13T14:20:35+00:00",
    "commented_code": "return must(this.#tableSpecs.get(name), `Unknown table ${name}`);\n   }\n \n+  #getKey(\n+    {row, numCols}: {row: LiteRow; numCols: number},\n+    {relation}: {relation: MessageRelation},\n+  ): LiteRowKey {\n+    const keyColumns =\n+      relation.replicaIdentity !== 'full'\n+        ? relation.keyColumns // already a suitable key\n+        : this.#tableSpec(liteTableName(relation)).primaryKey;\n+    if (!keyColumns?.length) {\n+      throw new Error(\n+        `Cannot replicate table \"${relation.name}\" without a PRIMARY KEY or UNIQUE INDEX`,\n+      );\n+    }\n+    // For the common case (replica identity default), the row is already the\n+    // key for deletes and updates, in which case a new object can be avoided.\n+    return numCols === keyColumns.length\n+      ? row\n+      : Object.fromEntries(keyColumns.map(col => [col, row[col]]));",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "1993637868",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 3935,
        "pr_file": "packages/zero-cache/src/services/replicator/change-processor.ts",
        "discussion_id": "1993637868",
        "commented_code": "@@ -323,11 +338,31 @@ class TransactionProcessor {\n     return must(this.#tableSpecs.get(name), `Unknown table ${name}`);\n   }\n \n+  #getKey(\n+    {row, numCols}: {row: LiteRow; numCols: number},\n+    {relation}: {relation: MessageRelation},\n+  ): LiteRowKey {\n+    const keyColumns =\n+      relation.replicaIdentity !== 'full'\n+        ? relation.keyColumns // already a suitable key\n+        : this.#tableSpec(liteTableName(relation)).primaryKey;\n+    if (!keyColumns?.length) {\n+      throw new Error(\n+        `Cannot replicate table \"${relation.name}\" without a PRIMARY KEY or UNIQUE INDEX`,\n+      );\n+    }\n+    // For the common case (replica identity default), the row is already the\n+    // key for deletes and updates, in which case a new object can be avoided.\n+    return numCols === keyColumns.length\n+      ? row\n+      : Object.fromEntries(keyColumns.map(col => [col, row[col]]));",
        "comment_created_at": "2025-03-13T14:20:35+00:00",
        "comment_author": "tantaman",
        "comment_body": "nit: \r\n\r\n```ts\r\nkeyColumns.reduce((l, r) => l[r] = row[r], {});\r\n```\r\n\r\nwould be less allocations in what I assume to be a hot path.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1878832164",
    "pr_number": 3257,
    "pr_file": "packages/zqlite/src/table-source.ts",
    "created_at": "2024-12-10T20:46:37+00:00",
    "commented_code": "return input;\n   }\n \n+  toSQLiteRow(row: Row): Row {\n+    return Object.fromEntries(\n+      Object.entries(row).map(([key, value]) => [\n+        key,\n+        toSQLiteType(value, this.#columns[key].type),\n+      ]),\n+    ) as Row;\n+  }",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "1878832164",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 3257,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1878832164",
        "commented_code": "@@ -239,6 +239,15 @@ export class TableSource implements Source {\n     return input;\n   }\n \n+  toSQLiteRow(row: Row): Row {\n+    return Object.fromEntries(\n+      Object.entries(row).map(([key, value]) => [\n+        key,\n+        toSQLiteType(value, this.#columns[key].type),\n+      ]),\n+    ) as Row;\n+  }",
        "comment_created_at": "2024-12-10T20:46:37+00:00",
        "comment_author": "arv",
        "comment_body": "Lots of GC churn here. This is probably going to be hot \ud83d\udd25 \r\n\r\n```js\r\nconst newRow: Writable<Row> = {};\r\nfor (const k in row) {\r\n  newRow[k] = row[k];\r\n}\r\nreturn newRow;\r\n```\r\n\r\nBut maybe we can do this on a higher level where we know exactly which columns need to be converted and wether we can completely skip the cloning.\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "1880817270",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 3257,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1878832164",
        "commented_code": "@@ -239,6 +239,15 @@ export class TableSource implements Source {\n     return input;\n   }\n \n+  toSQLiteRow(row: Row): Row {\n+    return Object.fromEntries(\n+      Object.entries(row).map(([key, value]) => [\n+        key,\n+        toSQLiteType(value, this.#columns[key].type),\n+      ]),\n+    ) as Row;\n+  }",
        "comment_created_at": "2024-12-11T19:42:04+00:00",
        "comment_author": "darkgnotic",
        "comment_body": "Is this method used?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1869781661",
    "pr_number": 3183,
    "pr_file": "packages/zql/src/ivm/memory-source.ts",
    "created_at": "2024-12-04T15:24:26+00:00",
    "commented_code": "switch (change.type) {\n       case 'add':\n-        if (data.has(change.row)) {\n-          throw new Error(`Row already exists ${JSON.stringify(change)}`);\n-        }\n+        assert(\n+          !data.has(change.row),\n+          () => `Row already exists ${JSON.stringify(change)}`,",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "1869781661",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 3183,
        "pr_file": "packages/zql/src/ivm/memory-source.ts",
        "discussion_id": "1869781661",
        "commented_code": "@@ -354,19 +354,22 @@ export class MemorySource implements Source {\n \n     switch (change.type) {\n       case 'add':\n-        if (data.has(change.row)) {\n-          throw new Error(`Row already exists ${JSON.stringify(change)}`);\n-        }\n+        assert(\n+          !data.has(change.row),\n+          () => `Row already exists ${JSON.stringify(change)}`,",
        "comment_created_at": "2024-12-04T15:24:26+00:00",
        "comment_author": "tantaman",
        "comment_body": "What's the overhead of lambda creation?\r\n\r\nCurious since I would have done a format string to make this lazy --\r\n\r\n```ts\r\nassert(x, 'Row already exists %j', change)\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1870311075",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 3183,
        "pr_file": "packages/zql/src/ivm/memory-source.ts",
        "discussion_id": "1869781661",
        "commented_code": "@@ -354,19 +354,22 @@ export class MemorySource implements Source {\n \n     switch (change.type) {\n       case 'add':\n-        if (data.has(change.row)) {\n-          throw new Error(`Row already exists ${JSON.stringify(change)}`);\n-        }\n+        assert(\n+          !data.has(change.row),\n+          () => `Row already exists ${JSON.stringify(change)}`,",
        "comment_created_at": "2024-12-04T21:36:23+00:00",
        "comment_author": "arv",
        "comment_body": "I don't think we want format strings in general.\r\n\r\nThere is not too much overhead to create a function object but maybe we should just undo this and use if statements for the few cases where we think we do not want to pay the price of creating the error message for the common case?",
        "pr_file_module": null
      }
    ]
  }
]