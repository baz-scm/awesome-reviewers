[
  {
    "discussion_id": "2193678800",
    "pr_number": 4550,
    "pr_file": "packages/zero-pg/src/custom.ts",
    "created_at": "2025-07-09T00:42:30+00:00",
    "commented_code": "await tx.query(stmt.text, stmt.values);\n     },\n     async update(this: WithHiddenTxAndSchema, value) {\n-      value = removeUndefined(value);\n+      const updateWithDefaults = addDefaultToOptionalFields({\n+        value,\n+        schema,\n+        type: 'update',\n+      });\n       const serverTableSchema = this[serverSchemaSymbol][serverName(schema)];\n-      const targetedColumns = origAndServerNamesFor(Object.keys(value), schema);\n+      const targetedColumns = origAndServerNamesFor(\n+        Object.keys(updateWithDefaults),\n+        schema,\n+      );\n       const stmt = formatPgInternalConvert(\n         sql`UPDATE ${sql.ident(serverName(schema))} SET ${sql.join(\n           targetedColumns.map(\n             ([origName, serverName]) =>\n-              sql`${sql.ident(serverName)} = ${sqlInsertValue(value[origName], serverTableSchema[serverName])}`,\n+              sql`${sql.ident(serverName)} = ${sqlInsertValue(updateWithDefaults[origName], serverTableSchema[serverName])}`,\n           ),\n           ', ',\n-        )} WHERE ${primaryKeyClause(schema, serverTableSchema, value)}`,\n+        )} WHERE ${primaryKeyClause(schema, serverTableSchema, updateWithDefaults)}`,\n       );\n       const tx = this[dbTxSymbol];\n       await tx.query(stmt.text, stmt.values);\n     },\n     async delete(this: WithHiddenTxAndSchema, value) {\n-      value = removeUndefined(value);\n+      const deleteWithDefaults = addDefaultToOptionalFields({",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "2193678800",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4550,
        "pr_file": "packages/zero-pg/src/custom.ts",
        "discussion_id": "2193678800",
        "commented_code": "@@ -221,28 +279,38 @@ function makeTableCRUD(schema: TableSchema): TableCRUD<TableSchema> {\n       await tx.query(stmt.text, stmt.values);\n     },\n     async update(this: WithHiddenTxAndSchema, value) {\n-      value = removeUndefined(value);\n+      const updateWithDefaults = addDefaultToOptionalFields({\n+        value,\n+        schema,\n+        type: 'update',\n+      });\n       const serverTableSchema = this[serverSchemaSymbol][serverName(schema)];\n-      const targetedColumns = origAndServerNamesFor(Object.keys(value), schema);\n+      const targetedColumns = origAndServerNamesFor(\n+        Object.keys(updateWithDefaults),\n+        schema,\n+      );\n       const stmt = formatPgInternalConvert(\n         sql`UPDATE ${sql.ident(serverName(schema))} SET ${sql.join(\n           targetedColumns.map(\n             ([origName, serverName]) =>\n-              sql`${sql.ident(serverName)} = ${sqlInsertValue(value[origName], serverTableSchema[serverName])}`,\n+              sql`${sql.ident(serverName)} = ${sqlInsertValue(updateWithDefaults[origName], serverTableSchema[serverName])}`,\n           ),\n           ', ',\n-        )} WHERE ${primaryKeyClause(schema, serverTableSchema, value)}`,\n+        )} WHERE ${primaryKeyClause(schema, serverTableSchema, updateWithDefaults)}`,\n       );\n       const tx = this[dbTxSymbol];\n       await tx.query(stmt.text, stmt.values);\n     },\n     async delete(this: WithHiddenTxAndSchema, value) {\n-      value = removeUndefined(value);\n+      const deleteWithDefaults = addDefaultToOptionalFields({",
        "comment_created_at": "2025-07-09T00:42:30+00:00",
        "comment_author": "aboodman",
        "comment_body": "I do not believe that PK fields are allowed to be optional in Zero. Can you verify this and if so remove this part?",
        "pr_file_module": null
      },
      {
        "comment_id": "2196106220",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4550,
        "pr_file": "packages/zero-pg/src/custom.ts",
        "discussion_id": "2193678800",
        "commented_code": "@@ -221,28 +279,38 @@ function makeTableCRUD(schema: TableSchema): TableCRUD<TableSchema> {\n       await tx.query(stmt.text, stmt.values);\n     },\n     async update(this: WithHiddenTxAndSchema, value) {\n-      value = removeUndefined(value);\n+      const updateWithDefaults = addDefaultToOptionalFields({\n+        value,\n+        schema,\n+        type: 'update',\n+      });\n       const serverTableSchema = this[serverSchemaSymbol][serverName(schema)];\n-      const targetedColumns = origAndServerNamesFor(Object.keys(value), schema);\n+      const targetedColumns = origAndServerNamesFor(\n+        Object.keys(updateWithDefaults),\n+        schema,\n+      );\n       const stmt = formatPgInternalConvert(\n         sql`UPDATE ${sql.ident(serverName(schema))} SET ${sql.join(\n           targetedColumns.map(\n             ([origName, serverName]) =>\n-              sql`${sql.ident(serverName)} = ${sqlInsertValue(value[origName], serverTableSchema[serverName])}`,\n+              sql`${sql.ident(serverName)} = ${sqlInsertValue(updateWithDefaults[origName], serverTableSchema[serverName])}`,\n           ),\n           ', ',\n-        )} WHERE ${primaryKeyClause(schema, serverTableSchema, value)}`,\n+        )} WHERE ${primaryKeyClause(schema, serverTableSchema, updateWithDefaults)}`,\n       );\n       const tx = this[dbTxSymbol];\n       await tx.query(stmt.text, stmt.values);\n     },\n     async delete(this: WithHiddenTxAndSchema, value) {\n-      value = removeUndefined(value);\n+      const deleteWithDefaults = addDefaultToOptionalFields({",
        "comment_created_at": "2025-07-09T22:24:54+00:00",
        "comment_author": "0xcadams",
        "comment_body": "Yes - confirmed that this function wasn't doing anything (`primaryKeyClause` would behave the same regardless of whether undefined keys are filtered), so removed this.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2143580720",
    "pr_number": 4498,
    "pr_file": "packages/zero-cache/src/services/view-syncer/cvr-store.ts",
    "created_at": "2025-06-12T20:13:16+00:00",
    "commented_code": "putQuery(query: QueryRecord): void {\n     const change: QueriesRow = queryRecordToQueryRow(this.#id, query);\n+    // ${JSON.stringify(change.queryArgs)}::text::json is used because postgres.js\n+    // gets confused if the input is `[boolean]` and throws an error saying a bool\n+    // cannot be converted to json.\n+    // https://github.com/porsager/postgres/issues/386\n     this.#writes.add({\n       stats: {queries: 1},\n-      write: tx => tx`INSERT INTO ${this.#cvr('queries')} ${tx(change)}\n+      write: tx => tx`INSERT INTO ${this.#cvr('queries')} (\n+        \"clientGroupID\",\n+        \"queryHash\",\n+        \"clientAST\",\n+        \"queryName\",\n+        \"queryArgs\",\n+        \"patchVersion\",\n+        \"transformationHash\",\n+        \"transformationVersion\",\n+        \"internal\",\n+        \"deleted\"\n+      ) VALUES (\n+        ${change.clientGroupID},\n+        ${change.queryHash},\n+        ${change.clientAST},\n+        ${change.queryName},\n+        ${change.queryArgs === undefined ? null : JSON.stringify(change.queryArgs)}::text::json,\n+        ${change.patchVersion},\n+        ${change.transformationHash ?? null},\n+        ${change.transformationVersion ?? null},\n+        ${change.internal},\n+        ${change.deleted ?? false}\n+      )\n       ON CONFLICT (\"clientGroupID\", \"queryHash\")\n-      DO UPDATE SET ${tx(change)}`,\n+      DO UPDATE SET",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "2143580720",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4498,
        "pr_file": "packages/zero-cache/src/services/view-syncer/cvr-store.ts",
        "discussion_id": "2143580720",
        "commented_code": "@@ -421,11 +421,45 @@ export class CVRStore {\n \n   putQuery(query: QueryRecord): void {\n     const change: QueriesRow = queryRecordToQueryRow(this.#id, query);\n+    // ${JSON.stringify(change.queryArgs)}::text::json is used because postgres.js\n+    // gets confused if the input is `[boolean]` and throws an error saying a bool\n+    // cannot be converted to json.\n+    // https://github.com/porsager/postgres/issues/386\n     this.#writes.add({\n       stats: {queries: 1},\n-      write: tx => tx`INSERT INTO ${this.#cvr('queries')} ${tx(change)}\n+      write: tx => tx`INSERT INTO ${this.#cvr('queries')} (\n+        \"clientGroupID\",\n+        \"queryHash\",\n+        \"clientAST\",\n+        \"queryName\",\n+        \"queryArgs\",\n+        \"patchVersion\",\n+        \"transformationHash\",\n+        \"transformationVersion\",\n+        \"internal\",\n+        \"deleted\"\n+      ) VALUES (\n+        ${change.clientGroupID},\n+        ${change.queryHash},\n+        ${change.clientAST},\n+        ${change.queryName},\n+        ${change.queryArgs === undefined ? null : JSON.stringify(change.queryArgs)}::text::json,\n+        ${change.patchVersion},\n+        ${change.transformationHash ?? null},\n+        ${change.transformationVersion ?? null},\n+        ${change.internal},\n+        ${change.deleted ?? false}\n+      )\n       ON CONFLICT (\"clientGroupID\", \"queryHash\")\n-      DO UPDATE SET ${tx(change)}`,\n+      DO UPDATE SET ",
        "comment_created_at": "2025-06-12T20:13:16+00:00",
        "comment_author": "darkgnotic",
        "comment_body": "FYI, if you want to avoid the duplication and keep the query string like it was before, I believe you can achieve this by creating a new object to pass into for substitution:\r\n\r\n```ts\r\nconst row = {\r\n  ...change,\r\n  queryArgs: ...\r\n  transformationHash: ...\r\n  transformationVersion: ...\r\n  deleted: ...\r\n};\r\n\r\nwrite: tx => tx`INSERT INTO ${this.#cvr('queries')} ${tx(row)} ... DO UPDATE SET ${tx(row)} ...`\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2143611275",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4498,
        "pr_file": "packages/zero-cache/src/services/view-syncer/cvr-store.ts",
        "discussion_id": "2143580720",
        "commented_code": "@@ -421,11 +421,45 @@ export class CVRStore {\n \n   putQuery(query: QueryRecord): void {\n     const change: QueriesRow = queryRecordToQueryRow(this.#id, query);\n+    // ${JSON.stringify(change.queryArgs)}::text::json is used because postgres.js\n+    // gets confused if the input is `[boolean]` and throws an error saying a bool\n+    // cannot be converted to json.\n+    // https://github.com/porsager/postgres/issues/386\n     this.#writes.add({\n       stats: {queries: 1},\n-      write: tx => tx`INSERT INTO ${this.#cvr('queries')} ${tx(change)}\n+      write: tx => tx`INSERT INTO ${this.#cvr('queries')} (\n+        \"clientGroupID\",\n+        \"queryHash\",\n+        \"clientAST\",\n+        \"queryName\",\n+        \"queryArgs\",\n+        \"patchVersion\",\n+        \"transformationHash\",\n+        \"transformationVersion\",\n+        \"internal\",\n+        \"deleted\"\n+      ) VALUES (\n+        ${change.clientGroupID},\n+        ${change.queryHash},\n+        ${change.clientAST},\n+        ${change.queryName},\n+        ${change.queryArgs === undefined ? null : JSON.stringify(change.queryArgs)}::text::json,\n+        ${change.patchVersion},\n+        ${change.transformationHash ?? null},\n+        ${change.transformationVersion ?? null},\n+        ${change.internal},\n+        ${change.deleted ?? false}\n+      )\n       ON CONFLICT (\"clientGroupID\", \"queryHash\")\n-      DO UPDATE SET ${tx(change)}`,\n+      DO UPDATE SET ",
        "comment_created_at": "2025-06-12T20:34:14+00:00",
        "comment_author": "tantaman",
        "comment_body": "how will it handle the casting then?",
        "pr_file_module": null
      },
      {
        "comment_id": "2143988472",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4498,
        "pr_file": "packages/zero-cache/src/services/view-syncer/cvr-store.ts",
        "discussion_id": "2143580720",
        "commented_code": "@@ -421,11 +421,45 @@ export class CVRStore {\n \n   putQuery(query: QueryRecord): void {\n     const change: QueriesRow = queryRecordToQueryRow(this.#id, query);\n+    // ${JSON.stringify(change.queryArgs)}::text::json is used because postgres.js\n+    // gets confused if the input is `[boolean]` and throws an error saying a bool\n+    // cannot be converted to json.\n+    // https://github.com/porsager/postgres/issues/386\n     this.#writes.add({\n       stats: {queries: 1},\n-      write: tx => tx`INSERT INTO ${this.#cvr('queries')} ${tx(change)}\n+      write: tx => tx`INSERT INTO ${this.#cvr('queries')} (\n+        \"clientGroupID\",\n+        \"queryHash\",\n+        \"clientAST\",\n+        \"queryName\",\n+        \"queryArgs\",\n+        \"patchVersion\",\n+        \"transformationHash\",\n+        \"transformationVersion\",\n+        \"internal\",\n+        \"deleted\"\n+      ) VALUES (\n+        ${change.clientGroupID},\n+        ${change.queryHash},\n+        ${change.clientAST},\n+        ${change.queryName},\n+        ${change.queryArgs === undefined ? null : JSON.stringify(change.queryArgs)}::text::json,\n+        ${change.patchVersion},\n+        ${change.transformationHash ?? null},\n+        ${change.transformationVersion ?? null},\n+        ${change.internal},\n+        ${change.deleted ?? false}\n+      )\n       ON CONFLICT (\"clientGroupID\", \"queryHash\")\n-      DO UPDATE SET ${tx(change)}`,\n+      DO UPDATE SET ",
        "comment_created_at": "2025-06-13T00:39:35+00:00",
        "comment_author": "darkgnotic",
        "comment_body": "ah, i totally missed that. sorry.  \ud83d\ude05 \r\n\r\ni guess you have to expand it all out to cast, unless this works:\r\n\r\n```ts\r\nconst row = {\r\n  ...change,\r\n  queryArgs: tx.json(change.queryArgs === undefined ? null : change.queryArgs),\r\n  transformationHash: ...\r\n  transformationVersion: ...\r\n  deleted: ...\r\n};\r\n```\r\n\r\nbut i remember you saying that the `json()` helper wasn't working for some reason.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2094255385",
    "pr_number": 4385,
    "pr_file": "packages/zero-cache/src/services/view-syncer/schema/cvr.ts",
    "created_at": "2025-05-18T00:26:18+00:00",
    "commented_code": "return `\n CREATE TABLE ${schema(shard)}.queries (\n   \"clientGroupID\"         TEXT,\n-  \"queryHash\"             TEXT,\n-  \"clientAST\"             JSONB NOT NULL,\n+  \"queryHash\"             TEXT, -- this is the hash of the client query AST\n+  \"clientAST\"             JSONB, -- this is nullable as custom queries will not persist an AST\n+  \"queryName\"             TEXT, -- the name of the query if it is a custom query\n+  \"queryArgs\"             JSONB, -- the arguments of the query if it is a custom query",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "2094255385",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4385,
        "pr_file": "packages/zero-cache/src/services/view-syncer/schema/cvr.ts",
        "discussion_id": "2094255385",
        "commented_code": "@@ -108,8 +110,10 @@ function createQueriesTable(shard: ShardID) {\n   return `\n CREATE TABLE ${schema(shard)}.queries (\n   \"clientGroupID\"         TEXT,\n-  \"queryHash\"             TEXT,\n-  \"clientAST\"             JSONB NOT NULL,\n+  \"queryHash\"             TEXT, -- this is the hash of the client query AST\n+  \"clientAST\"             JSONB, -- this is nullable as custom queries will not persist an AST\n+  \"queryName\"             TEXT, -- the name of the query if it is a custom query\n+  \"queryArgs\"             JSONB, -- the arguments of the query if it is a custom query",
        "comment_created_at": "2025-05-18T00:26:18+00:00",
        "comment_author": "darkgnotic",
        "comment_body": "Probably not an issue, here, but a couple of caveats about storing data as `JSONB`:\r\n- Fields are reordered, so the dev won't be able to rely on the fact that they object that they send on the wire comes out with the fields in the same order on the api-server\r\n- The NULL byte is not allowed in `JSONB`.\r\n\r\nThe latter issue was actually a problem for downstream replication, where a user had NULL bytes in their JSON field that needed to be preserved: https://github.com/rocicorp/mono/pull/3810\r\n\r\nNot sure if it will ever matter for custom queries args, but it's not impossible.\r\n\r\nSo I guess my take is that, unless we need specific JSONB properties (indexing, etc.), it might be better to store things as `JSON`, so that we preserve the original data to the greatest extent possible.",
        "pr_file_module": null
      },
      {
        "comment_id": "2098456291",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4385,
        "pr_file": "packages/zero-cache/src/services/view-syncer/schema/cvr.ts",
        "discussion_id": "2094255385",
        "commented_code": "@@ -108,8 +110,10 @@ function createQueriesTable(shard: ShardID) {\n   return `\n CREATE TABLE ${schema(shard)}.queries (\n   \"clientGroupID\"         TEXT,\n-  \"queryHash\"             TEXT,\n-  \"clientAST\"             JSONB NOT NULL,\n+  \"queryHash\"             TEXT, -- this is the hash of the client query AST\n+  \"clientAST\"             JSONB, -- this is nullable as custom queries will not persist an AST\n+  \"queryName\"             TEXT, -- the name of the query if it is a custom query\n+  \"queryArgs\"             JSONB, -- the arguments of the query if it is a custom query",
        "comment_created_at": "2025-05-20T16:53:54+00:00",
        "comment_author": "tantaman",
        "comment_body": "Thanks for calling that out. Will switch to `json`.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2040089766",
    "pr_number": 4216,
    "pr_file": "packages/z2s/src/compiler.ts",
    "created_at": "2025-04-11T18:24:41+00:00",
    "commented_code": "this.#nameMapper.columnName(table, column)\n       ];\n     const serverType = serverColumnSchema.type;\n-    if (\n-      !serverColumnSchema.isEnum &&\n-      (serverType === 'date' ||\n+    if (!serverColumnSchema.isEnum) {\n+      if (\n+        serverType === 'date' ||\n         serverType === 'timestamp' ||\n+        serverType === 'timestamp without time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;\n+      } else if (\n         serverType === 'timestamptz' ||\n-        serverType === 'timestamp with time zone' ||\n-        serverType === 'timestamp without time zone')\n-    ) {\n-      return sql`EXTRACT(EPOCH FROM ${sql.ident(\n-        table,\n-      )}.${this.#mapColumnNoAlias(\n-        table,\n-        column,\n-      )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;\n+        serverType === 'timestamp with time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp) * 1000 as ${sql.ident(column)}`;",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "2040089766",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4216,
        "pr_file": "packages/z2s/src/compiler.ts",
        "discussion_id": "2040089766",
        "commented_code": "@@ -596,20 +596,29 @@ export class Compiler {\n         this.#nameMapper.columnName(table, column)\n       ];\n     const serverType = serverColumnSchema.type;\n-    if (\n-      !serverColumnSchema.isEnum &&\n-      (serverType === 'date' ||\n+    if (!serverColumnSchema.isEnum) {\n+      if (\n+        serverType === 'date' ||\n         serverType === 'timestamp' ||\n+        serverType === 'timestamp without time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;\n+      } else if (\n         serverType === 'timestamptz' ||\n-        serverType === 'timestamp with time zone' ||\n-        serverType === 'timestamp without time zone')\n-    ) {\n-      return sql`EXTRACT(EPOCH FROM ${sql.ident(\n-        table,\n-      )}.${this.#mapColumnNoAlias(\n-        table,\n-        column,\n-      )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;\n+        serverType === 'timestamp with time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp) * 1000 as ${sql.ident(column)}`;",
        "comment_created_at": "2025-04-11T18:24:41+00:00",
        "comment_author": "tantaman",
        "comment_body": "I think this should just be:\r\n\r\n```suggestion\r\n        return sql`EXTRACT(EPOCH FROM ${sql.ident(\r\n          table,\r\n        )}.${this.#mapColumnNoAlias(\r\n          table,\r\n          column,\r\n        )}) * 1000 as ${sql.ident(column)}`;\r\n```\r\n\r\nas that round-trips correctly (1744392199 in and 1744392199 out):\r\n\r\n```\r\nuser@127.0.0.1:postgres> create table foo (a timestamp with time zone);\r\nCREATE TABLE\r\nTime: 0.028s\r\nuser@127.0.0.1:postgres> INSERT INTO foo VALUES (to_timestamp(1744392199));\r\nINSERT 0 1\r\nTime: 0.004s\r\nuser@127.0.0.1:postgres> select * from foo;\r\n+------------------------+\r\n| a                      |\r\n|------------------------|\r\n| 2025-04-11 12:23:19-05 |\r\n+------------------------+\r\nSELECT 1\r\nTime: 0.006s\r\nuser@127.0.0.1:postgres> SELECT EXTRACT(EPOCH FROM \"a\") FROM foo;\r\n+-------------------+\r\n| extract           |\r\n|-------------------|\r\n| 1744392199.000000 |\r\n+-------------------+\r\nSELECT 1\r\nTime: 0.008s\r\nuser@127.0.0.1:postgres>\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2040209779",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4216,
        "pr_file": "packages/z2s/src/compiler.ts",
        "discussion_id": "2040089766",
        "commented_code": "@@ -596,20 +596,29 @@ export class Compiler {\n         this.#nameMapper.columnName(table, column)\n       ];\n     const serverType = serverColumnSchema.type;\n-    if (\n-      !serverColumnSchema.isEnum &&\n-      (serverType === 'date' ||\n+    if (!serverColumnSchema.isEnum) {\n+      if (\n+        serverType === 'date' ||\n         serverType === 'timestamp' ||\n+        serverType === 'timestamp without time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;\n+      } else if (\n         serverType === 'timestamptz' ||\n-        serverType === 'timestamp with time zone' ||\n-        serverType === 'timestamp without time zone')\n-    ) {\n-      return sql`EXTRACT(EPOCH FROM ${sql.ident(\n-        table,\n-      )}.${this.#mapColumnNoAlias(\n-        table,\n-        column,\n-      )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;\n+        serverType === 'timestamp with time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp) * 1000 as ${sql.ident(column)}`;",
        "comment_created_at": "2025-04-11T19:37:42+00:00",
        "comment_author": "tjenkinson",
        "comment_body": "this is just because the `::timestamp` cast is redundant?",
        "pr_file_module": null
      },
      {
        "comment_id": "2040215142",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4216,
        "pr_file": "packages/z2s/src/compiler.ts",
        "discussion_id": "2040089766",
        "commented_code": "@@ -596,20 +596,29 @@ export class Compiler {\n         this.#nameMapper.columnName(table, column)\n       ];\n     const serverType = serverColumnSchema.type;\n-    if (\n-      !serverColumnSchema.isEnum &&\n-      (serverType === 'date' ||\n+    if (!serverColumnSchema.isEnum) {\n+      if (\n+        serverType === 'date' ||\n         serverType === 'timestamp' ||\n+        serverType === 'timestamp without time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;\n+      } else if (\n         serverType === 'timestamptz' ||\n-        serverType === 'timestamp with time zone' ||\n-        serverType === 'timestamp without time zone')\n-    ) {\n-      return sql`EXTRACT(EPOCH FROM ${sql.ident(\n-        table,\n-      )}.${this.#mapColumnNoAlias(\n-        table,\n-        column,\n-      )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;\n+        serverType === 'timestamp with time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp) * 1000 as ${sql.ident(column)}`;",
        "comment_created_at": "2025-04-11T19:41:19+00:00",
        "comment_author": "tjenkinson",
        "comment_body": "and I guess `EPOCH FROM` with a `timestamp` just treats it as UTC",
        "pr_file_module": null
      },
      {
        "comment_id": "2040219444",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4216,
        "pr_file": "packages/z2s/src/compiler.ts",
        "discussion_id": "2040089766",
        "commented_code": "@@ -596,20 +596,29 @@ export class Compiler {\n         this.#nameMapper.columnName(table, column)\n       ];\n     const serverType = serverColumnSchema.type;\n-    if (\n-      !serverColumnSchema.isEnum &&\n-      (serverType === 'date' ||\n+    if (!serverColumnSchema.isEnum) {\n+      if (\n+        serverType === 'date' ||\n         serverType === 'timestamp' ||\n+        serverType === 'timestamp without time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;\n+      } else if (\n         serverType === 'timestamptz' ||\n-        serverType === 'timestamp with time zone' ||\n-        serverType === 'timestamp without time zone')\n-    ) {\n-      return sql`EXTRACT(EPOCH FROM ${sql.ident(\n-        table,\n-      )}.${this.#mapColumnNoAlias(\n-        table,\n-        column,\n-      )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;\n+        serverType === 'timestamp with time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp) * 1000 as ${sql.ident(column)}`;",
        "comment_created_at": "2025-04-11T19:44:49+00:00",
        "comment_author": "tjenkinson",
        "comment_body": "sorry read it again. This was a `timestamptz`, and the cast was stripping the tz, and then we were treating it as local time and converting that to utc",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2040094028",
    "pr_number": 4216,
    "pr_file": "packages/z2s/src/compiler.ts",
    "created_at": "2025-04-11T18:28:12+00:00",
    "commented_code": "this.#nameMapper.columnName(table, column)\n       ];\n     const serverType = serverColumnSchema.type;\n-    if (\n-      !serverColumnSchema.isEnum &&\n-      (serverType === 'date' ||\n+    if (!serverColumnSchema.isEnum) {\n+      if (\n+        serverType === 'date' ||\n         serverType === 'timestamp' ||\n+        serverType === 'timestamp without time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "2040094028",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4216,
        "pr_file": "packages/z2s/src/compiler.ts",
        "discussion_id": "2040094028",
        "commented_code": "@@ -596,20 +596,29 @@ export class Compiler {\n         this.#nameMapper.columnName(table, column)\n       ];\n     const serverType = serverColumnSchema.type;\n-    if (\n-      !serverColumnSchema.isEnum &&\n-      (serverType === 'date' ||\n+    if (!serverColumnSchema.isEnum) {\n+      if (\n+        serverType === 'date' ||\n         serverType === 'timestamp' ||\n+        serverType === 'timestamp without time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;",
        "comment_created_at": "2025-04-11T18:28:12+00:00",
        "comment_author": "tantaman",
        "comment_body": "Should be:\r\n\r\n```suggestion\r\n        return sql`EXTRACT(EPOCH FROM ${sql.ident(\r\n          table,\r\n        )}.${this.#mapColumnNoAlias(\r\n          table,\r\n          column,\r\n        )}) * 1000 as ${sql.ident(column)}`;\r\n```\r\n\r\nround-trips correctly:\r\n\r\n```\r\nuser@127.0.0.1:postgres> CREATE TABLE bar (a timestamp without time zone);\r\nCREATE TABLE\r\nTime: 0.028s\r\nuser@127.0.0.1:postgres> INSERT INTO bar VALUES(to_timestamp(1744392199) AT TIME ZONE 'UTC');\r\nINSERT 0 1\r\nTime: 0.011s\r\nuser@127.0.0.1:postgres> SELECT * FROM bar;\r\n+---------------------+\r\n| a                   |\r\n|---------------------|\r\n| 2025-04-11 17:23:19 |\r\n+---------------------+\r\nSELECT 1\r\nTime: 0.004s\r\nuser@127.0.0.1:postgres> SELECT EXTRACT(EPOCH FROM \"a\") FROM bar;\r\n+-------------------+\r\n| extract           |\r\n|-------------------|\r\n| 1744392199.000000 |\r\n+-------------------+\r\nSELECT 1\r\nTime: 0.005s\r\nuser@127.0.0.1:postgres>\r\n```\r\n\r\nThe reason is that `EXTRACT(EPOCH FROM` is already returning an epoch time which is at UTC.",
        "pr_file_module": null
      },
      {
        "comment_id": "2040210184",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4216,
        "pr_file": "packages/z2s/src/compiler.ts",
        "discussion_id": "2040094028",
        "commented_code": "@@ -596,20 +596,29 @@ export class Compiler {\n         this.#nameMapper.columnName(table, column)\n       ];\n     const serverType = serverColumnSchema.type;\n-    if (\n-      !serverColumnSchema.isEnum &&\n-      (serverType === 'date' ||\n+    if (!serverColumnSchema.isEnum) {\n+      if (\n+        serverType === 'date' ||\n         serverType === 'timestamp' ||\n+        serverType === 'timestamp without time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;",
        "comment_created_at": "2025-04-11T19:37:57+00:00",
        "comment_author": "tjenkinson",
        "comment_body": "ah yeh so this one the `::timestamp` cast was stripping the timezone, so then it was being treated as local timezone and converted to UTC, and the epoch taken from that /0\\",
        "pr_file_module": null
      },
      {
        "comment_id": "2040217888",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4216,
        "pr_file": "packages/z2s/src/compiler.ts",
        "discussion_id": "2040094028",
        "commented_code": "@@ -596,20 +596,29 @@ export class Compiler {\n         this.#nameMapper.columnName(table, column)\n       ];\n     const serverType = serverColumnSchema.type;\n-    if (\n-      !serverColumnSchema.isEnum &&\n-      (serverType === 'date' ||\n+    if (!serverColumnSchema.isEnum) {\n+      if (\n+        serverType === 'date' ||\n         serverType === 'timestamp' ||\n+        serverType === 'timestamp without time zone'\n+      ) {\n+        return sql`EXTRACT(EPOCH FROM ${sql.ident(\n+          table,\n+        )}.${this.#mapColumnNoAlias(\n+          table,\n+          column,\n+        )}::timestamp AT TIME ZONE 'UTC') * 1000 as ${sql.ident(column)}`;",
        "comment_created_at": "2025-04-11T19:43:18+00:00",
        "comment_author": "tjenkinson",
        "comment_body": "wait no there was no timezone, so that converted it to a `timestamptz`, interpreting as a timestamp in the user local timezone \ud83e\udd2f ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2022958539",
    "pr_number": 4152,
    "pr_file": "packages/zero-pg/src/schema.ts",
    "created_at": "2025-04-01T14:16:43+00:00",
    "commented_code": "+import type {ServerSchema} from '../../z2s/src/schema.ts';\n+import {formatPg, sql} from '../../z2s/src/sql.ts';\n+import type {Schema} from '../../zero-schema/src/builder/schema-builder.ts';\n+import type {DBTransaction} from '../../zql/src/mutate/custom.ts';\n+\n+export type ServerSchemaRow = {\n+  schema: string;\n+  table: string;\n+  column: string;\n+  type: string;\n+  enum: string;\n+};\n+\n+export async function getServerSchema<S extends Schema>(\n+  dbTransaction: DBTransaction<unknown>,\n+  schema: S,\n+): Promise<ServerSchema> {\n+  const serverToClient: Record<string, string> = {};\n+  const schemaTablePairs: [string, string][] = [];\n+  for (const {name, serverName} of Object.values(schema.tables)) {\n+    let schemaTablePair: [string, string] = ['public', serverName ?? name];\n+    if (serverName) {\n+      const firstPeriod = serverName.indexOf('.');\n+      if (firstPeriod > -1) {\n+        schemaTablePair = [\n+          serverName.substring(0, firstPeriod),\n+          serverName.substring(firstPeriod + 1, serverName.length),\n+        ];\n+      }\n+    }\n+    schemaTablePairs.push(schemaTablePair);\n+    serverToClient[`${schemaTablePair[0]}.${schemaTablePair[1]}`] = name;\n+  }\n+\n+  if (schemaTablePairs.length === 0) {\n+    return {}; // No pairs to query for\n+  }\n+  const inClause = sql.join(\n+    schemaTablePairs.map(\n+      ([schema, table]) => sql`(${schema}::text, ${table})::text`,\n+    ),\n+    ',',\n+  );\n+\n+  const query = sql`\n+      SELECT\n+          c.table_schema::text as schema,\n+          c.table_name::text as table,\n+          c.column_name::text as column,\n+          c.data_type::text AS type,\n+          t.typtype = 'e'::text as enum\n+      FROM\n+          information_schema.columns c\n+      JOIN\n+          pg_catalog.pg_type t ON c.udt_name = t.typname\n+      JOIN\n+          pg_catalog.pg_namespace n ON t.typnamespace = n.oid\n+      WHERE\n+          (c.table_schema, c.table_name) IN (${inClause})\n+    `;\n+  const {text, values} = formatPg(query);\n+  const results: Iterable<ServerSchemaRow> = (await dbTransaction.query(\n+    text,\n+    values,\n+  )) as Iterable<ServerSchemaRow>;\n+\n+  const serverSchema: ServerSchema = {};\n+  for (const row of results) {\n+    serverSchema[\n+      row.schema === 'public' ? row.table : `${row.schema}.${row.table}`\n+    ] = {\n+      [row.column]: {\n+        type: row.type,\n+        isEnum: row.enum.toLowerCase().startsWith('f'),",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "2022958539",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4152,
        "pr_file": "packages/zero-pg/src/schema.ts",
        "discussion_id": "2022958539",
        "commented_code": "@@ -0,0 +1,82 @@\n+import type {ServerSchema} from '../../z2s/src/schema.ts';\n+import {formatPg, sql} from '../../z2s/src/sql.ts';\n+import type {Schema} from '../../zero-schema/src/builder/schema-builder.ts';\n+import type {DBTransaction} from '../../zql/src/mutate/custom.ts';\n+\n+export type ServerSchemaRow = {\n+  schema: string;\n+  table: string;\n+  column: string;\n+  type: string;\n+  enum: string;\n+};\n+\n+export async function getServerSchema<S extends Schema>(\n+  dbTransaction: DBTransaction<unknown>,\n+  schema: S,\n+): Promise<ServerSchema> {\n+  const serverToClient: Record<string, string> = {};\n+  const schemaTablePairs: [string, string][] = [];\n+  for (const {name, serverName} of Object.values(schema.tables)) {\n+    let schemaTablePair: [string, string] = ['public', serverName ?? name];\n+    if (serverName) {\n+      const firstPeriod = serverName.indexOf('.');\n+      if (firstPeriod > -1) {\n+        schemaTablePair = [\n+          serverName.substring(0, firstPeriod),\n+          serverName.substring(firstPeriod + 1, serverName.length),\n+        ];\n+      }\n+    }\n+    schemaTablePairs.push(schemaTablePair);\n+    serverToClient[`${schemaTablePair[0]}.${schemaTablePair[1]}`] = name;\n+  }\n+\n+  if (schemaTablePairs.length === 0) {\n+    return {}; // No pairs to query for\n+  }\n+  const inClause = sql.join(\n+    schemaTablePairs.map(\n+      ([schema, table]) => sql`(${schema}::text, ${table})::text`,\n+    ),\n+    ',',\n+  );\n+\n+  const query = sql`\n+      SELECT\n+          c.table_schema::text as schema,\n+          c.table_name::text as table,\n+          c.column_name::text as column,\n+          c.data_type::text AS type,\n+          t.typtype = 'e'::text as enum\n+      FROM\n+          information_schema.columns c\n+      JOIN\n+          pg_catalog.pg_type t ON c.udt_name = t.typname\n+      JOIN\n+          pg_catalog.pg_namespace n ON t.typnamespace = n.oid\n+      WHERE\n+          (c.table_schema, c.table_name) IN (${inClause})\n+    `;\n+  const {text, values} = formatPg(query);\n+  const results: Iterable<ServerSchemaRow> = (await dbTransaction.query(\n+    text,\n+    values,\n+  )) as Iterable<ServerSchemaRow>;\n+\n+  const serverSchema: ServerSchema = {};\n+  for (const row of results) {\n+    serverSchema[\n+      row.schema === 'public' ? row.table : `${row.schema}.${row.table}`\n+    ] = {\n+      [row.column]: {\n+        type: row.type,\n+        isEnum: row.enum.toLowerCase().startsWith('f'),",
        "comment_created_at": "2025-04-01T14:16:43+00:00",
        "comment_author": "tantaman",
        "comment_body": "shouldn't this be `row.enum.toLowerCase().startsWith('t')`?",
        "pr_file_module": null
      },
      {
        "comment_id": "2023064912",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4152,
        "pr_file": "packages/zero-pg/src/schema.ts",
        "discussion_id": "2022958539",
        "commented_code": "@@ -0,0 +1,82 @@\n+import type {ServerSchema} from '../../z2s/src/schema.ts';\n+import {formatPg, sql} from '../../z2s/src/sql.ts';\n+import type {Schema} from '../../zero-schema/src/builder/schema-builder.ts';\n+import type {DBTransaction} from '../../zql/src/mutate/custom.ts';\n+\n+export type ServerSchemaRow = {\n+  schema: string;\n+  table: string;\n+  column: string;\n+  type: string;\n+  enum: string;\n+};\n+\n+export async function getServerSchema<S extends Schema>(\n+  dbTransaction: DBTransaction<unknown>,\n+  schema: S,\n+): Promise<ServerSchema> {\n+  const serverToClient: Record<string, string> = {};\n+  const schemaTablePairs: [string, string][] = [];\n+  for (const {name, serverName} of Object.values(schema.tables)) {\n+    let schemaTablePair: [string, string] = ['public', serverName ?? name];\n+    if (serverName) {\n+      const firstPeriod = serverName.indexOf('.');\n+      if (firstPeriod > -1) {\n+        schemaTablePair = [\n+          serverName.substring(0, firstPeriod),\n+          serverName.substring(firstPeriod + 1, serverName.length),\n+        ];\n+      }\n+    }\n+    schemaTablePairs.push(schemaTablePair);\n+    serverToClient[`${schemaTablePair[0]}.${schemaTablePair[1]}`] = name;\n+  }\n+\n+  if (schemaTablePairs.length === 0) {\n+    return {}; // No pairs to query for\n+  }\n+  const inClause = sql.join(\n+    schemaTablePairs.map(\n+      ([schema, table]) => sql`(${schema}::text, ${table})::text`,\n+    ),\n+    ',',\n+  );\n+\n+  const query = sql`\n+      SELECT\n+          c.table_schema::text as schema,\n+          c.table_name::text as table,\n+          c.column_name::text as column,\n+          c.data_type::text AS type,\n+          t.typtype = 'e'::text as enum\n+      FROM\n+          information_schema.columns c\n+      JOIN\n+          pg_catalog.pg_type t ON c.udt_name = t.typname\n+      JOIN\n+          pg_catalog.pg_namespace n ON t.typnamespace = n.oid\n+      WHERE\n+          (c.table_schema, c.table_name) IN (${inClause})\n+    `;\n+  const {text, values} = formatPg(query);\n+  const results: Iterable<ServerSchemaRow> = (await dbTransaction.query(\n+    text,\n+    values,\n+  )) as Iterable<ServerSchemaRow>;\n+\n+  const serverSchema: ServerSchema = {};\n+  for (const row of results) {\n+    serverSchema[\n+      row.schema === 'public' ? row.table : `${row.schema}.${row.table}`\n+    ] = {\n+      [row.column]: {\n+        type: row.type,\n+        isEnum: row.enum.toLowerCase().startsWith('f'),",
        "comment_created_at": "2025-04-01T15:12:32+00:00",
        "comment_author": "grgbkr",
        "comment_body": "you are correct",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2022997062",
    "pr_number": 4152,
    "pr_file": "packages/z2s/src/compiler.ts",
    "created_at": "2025-04-01T14:36:44+00:00",
    "commented_code": "}\n \n   distinctFrom(condition: SimpleCondition, table: string): SQLQuery {\n-    return sql`${this.valuePosition(condition.left, table, this.#extractType(table, condition.left, condition.right), false)} ${\n+    return sql`${this.valuePosition(condition.left, table, condition.right, false)} ${\n       condition.op === 'IS' ? sql`IS NOT DISTINCT FROM` : sql`IS DISTINCT FROM`\n-    } ${this.valuePosition(condition.right, table, this.#extractType(table, condition.right, condition.left), false)}`;\n+    } ${this.valuePosition(condition.right, table, condition.left, false)}`;\n   }\n \n   any(condition: SimpleCondition, table: string): SQLQuery {\n-    return sql`${this.valuePosition(condition.left, table, this.#extractType(table, condition.left, condition.right), false)} ${\n+    return sql`${this.valuePosition(condition.left, table, condition.right, false)} ${\n       condition.op === 'IN' ? sql`= ANY` : sql`!= ANY`\n-    } (${this.valuePosition(condition.right, table, this.#extractType(table, condition.right, condition.left), true)})`;\n+    } (${this.valuePosition(condition.right, table, condition.left, true)})`;\n   }\n \n   valuePosition(\n-    value: ValuePosition,\n+    valuePos: ValuePosition,\n     table: string,\n-    valueType: ValueType,\n+    otherValuePos: ValuePosition,\n     plural: boolean,\n   ): SQLQuery {\n-    switch (value.type) {\n+    const valuePosType = valuePos.type;\n+    switch (valuePosType) {\n       case 'column':\n-        return this.#mapColumnNoAlias(table, value.name);\n+        return this.#mapColumnNoAlias(table, valuePos.name);\n       case 'literal':\n-        return sqlConvertArgUnsafe(valueType, value.value, plural);\n+        return this.#literalValuePosition(\n+          valuePos,\n+          table,\n+          otherValuePos,\n+          plural,\n+        );\n       case 'static':\n         throw new Error(\n           'Static parameters must be bound to a value before compiling to SQL',\n         );\n+      default:\n+        unreachable(valuePosType);\n+        break;\n+    }\n+  }\n+\n+  #literalValuePosition(\n+    valuePos: LiteralReference,\n+    table: string,\n+    otherValuePos: ValuePosition,\n+    plural: boolean,\n+  ) {\n+    {\n+      const otherType = otherValuePos.type;\n+      switch (otherType) {\n+        case 'column':\n+          return sqlConvertColumnArg(\n+            this.#serverSchema[this.#nameMapper.tableName(table)][\n+              this.#nameMapper.columnName(table, otherValuePos.name)\n+            ],\n+            valuePos.value,\n+            plural,\n+          );\n+        case 'literal': {\n+          assert(plural === Array.isArray(valuePos.value));\n+          if (Array.isArray(valuePos.value)) {\n+            if (valuePos.value.length > 0) {\n+              return sqlConvertPluralLiteralArg(",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "2022997062",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4152,
        "pr_file": "packages/z2s/src/compiler.ts",
        "discussion_id": "2022997062",
        "commented_code": "@@ -369,32 +377,101 @@ export class Compiler {\n   }\n \n   distinctFrom(condition: SimpleCondition, table: string): SQLQuery {\n-    return sql`${this.valuePosition(condition.left, table, this.#extractType(table, condition.left, condition.right), false)} ${\n+    return sql`${this.valuePosition(condition.left, table, condition.right, false)} ${\n       condition.op === 'IS' ? sql`IS NOT DISTINCT FROM` : sql`IS DISTINCT FROM`\n-    } ${this.valuePosition(condition.right, table, this.#extractType(table, condition.right, condition.left), false)}`;\n+    } ${this.valuePosition(condition.right, table, condition.left, false)}`;\n   }\n \n   any(condition: SimpleCondition, table: string): SQLQuery {\n-    return sql`${this.valuePosition(condition.left, table, this.#extractType(table, condition.left, condition.right), false)} ${\n+    return sql`${this.valuePosition(condition.left, table, condition.right, false)} ${\n       condition.op === 'IN' ? sql`= ANY` : sql`!= ANY`\n-    } (${this.valuePosition(condition.right, table, this.#extractType(table, condition.right, condition.left), true)})`;\n+    } (${this.valuePosition(condition.right, table, condition.left, true)})`;\n   }\n \n   valuePosition(\n-    value: ValuePosition,\n+    valuePos: ValuePosition,\n     table: string,\n-    valueType: ValueType,\n+    otherValuePos: ValuePosition,\n     plural: boolean,\n   ): SQLQuery {\n-    switch (value.type) {\n+    const valuePosType = valuePos.type;\n+    switch (valuePosType) {\n       case 'column':\n-        return this.#mapColumnNoAlias(table, value.name);\n+        return this.#mapColumnNoAlias(table, valuePos.name);\n       case 'literal':\n-        return sqlConvertArgUnsafe(valueType, value.value, plural);\n+        return this.#literalValuePosition(\n+          valuePos,\n+          table,\n+          otherValuePos,\n+          plural,\n+        );\n       case 'static':\n         throw new Error(\n           'Static parameters must be bound to a value before compiling to SQL',\n         );\n+      default:\n+        unreachable(valuePosType);\n+        break;\n+    }\n+  }\n+\n+  #literalValuePosition(\n+    valuePos: LiteralReference,\n+    table: string,\n+    otherValuePos: ValuePosition,\n+    plural: boolean,\n+  ) {\n+    {\n+      const otherType = otherValuePos.type;\n+      switch (otherType) {\n+        case 'column':\n+          return sqlConvertColumnArg(\n+            this.#serverSchema[this.#nameMapper.tableName(table)][\n+              this.#nameMapper.columnName(table, otherValuePos.name)\n+            ],\n+            valuePos.value,\n+            plural,\n+          );\n+        case 'literal': {\n+          assert(plural === Array.isArray(valuePos.value));\n+          if (Array.isArray(valuePos.value)) {\n+            if (valuePos.value.length > 0) {\n+              return sqlConvertPluralLiteralArg(",
        "comment_created_at": "2025-04-01T14:36:44+00:00",
        "comment_author": "tantaman",
        "comment_body": "We do not support comparing JSON columns yet but if we did idk how a JSON field would show up here if someone passed it an array as the payload.\r\n\r\nif the user does something like:\r\n\r\n```ts\r\nuser.where('metadata', '=', ['foo', 'bar']);\r\n```\r\n\r\nThat is a crazy comparison but it is something a user could do if they really want an exact JSON match. This is technically singular where the singular value is a JSON array.",
        "pr_file_module": null
      },
      {
        "comment_id": "2023112132",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4152,
        "pr_file": "packages/z2s/src/compiler.ts",
        "discussion_id": "2022997062",
        "commented_code": "@@ -369,32 +377,101 @@ export class Compiler {\n   }\n \n   distinctFrom(condition: SimpleCondition, table: string): SQLQuery {\n-    return sql`${this.valuePosition(condition.left, table, this.#extractType(table, condition.left, condition.right), false)} ${\n+    return sql`${this.valuePosition(condition.left, table, condition.right, false)} ${\n       condition.op === 'IS' ? sql`IS NOT DISTINCT FROM` : sql`IS DISTINCT FROM`\n-    } ${this.valuePosition(condition.right, table, this.#extractType(table, condition.right, condition.left), false)}`;\n+    } ${this.valuePosition(condition.right, table, condition.left, false)}`;\n   }\n \n   any(condition: SimpleCondition, table: string): SQLQuery {\n-    return sql`${this.valuePosition(condition.left, table, this.#extractType(table, condition.left, condition.right), false)} ${\n+    return sql`${this.valuePosition(condition.left, table, condition.right, false)} ${\n       condition.op === 'IN' ? sql`= ANY` : sql`!= ANY`\n-    } (${this.valuePosition(condition.right, table, this.#extractType(table, condition.right, condition.left), true)})`;\n+    } (${this.valuePosition(condition.right, table, condition.left, true)})`;\n   }\n \n   valuePosition(\n-    value: ValuePosition,\n+    valuePos: ValuePosition,\n     table: string,\n-    valueType: ValueType,\n+    otherValuePos: ValuePosition,\n     plural: boolean,\n   ): SQLQuery {\n-    switch (value.type) {\n+    const valuePosType = valuePos.type;\n+    switch (valuePosType) {\n       case 'column':\n-        return this.#mapColumnNoAlias(table, value.name);\n+        return this.#mapColumnNoAlias(table, valuePos.name);\n       case 'literal':\n-        return sqlConvertArgUnsafe(valueType, value.value, plural);\n+        return this.#literalValuePosition(\n+          valuePos,\n+          table,\n+          otherValuePos,\n+          plural,\n+        );\n       case 'static':\n         throw new Error(\n           'Static parameters must be bound to a value before compiling to SQL',\n         );\n+      default:\n+        unreachable(valuePosType);\n+        break;\n+    }\n+  }\n+\n+  #literalValuePosition(\n+    valuePos: LiteralReference,\n+    table: string,\n+    otherValuePos: ValuePosition,\n+    plural: boolean,\n+  ) {\n+    {\n+      const otherType = otherValuePos.type;\n+      switch (otherType) {\n+        case 'column':\n+          return sqlConvertColumnArg(\n+            this.#serverSchema[this.#nameMapper.tableName(table)][\n+              this.#nameMapper.columnName(table, otherValuePos.name)\n+            ],\n+            valuePos.value,\n+            plural,\n+          );\n+        case 'literal': {\n+          assert(plural === Array.isArray(valuePos.value));\n+          if (Array.isArray(valuePos.value)) {\n+            if (valuePos.value.length > 0) {\n+              return sqlConvertPluralLiteralArg(",
        "comment_created_at": "2025-04-01T15:35:59+00:00",
        "comment_author": "grgbkr",
        "comment_body": "Maybe we address it when the feature gets added. \r\n\r\nIf we add handling for it, would be hard to test since our types don't allow for it now.",
        "pr_file_module": null
      },
      {
        "comment_id": "2023113544",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 4152,
        "pr_file": "packages/z2s/src/compiler.ts",
        "discussion_id": "2022997062",
        "commented_code": "@@ -369,32 +377,101 @@ export class Compiler {\n   }\n \n   distinctFrom(condition: SimpleCondition, table: string): SQLQuery {\n-    return sql`${this.valuePosition(condition.left, table, this.#extractType(table, condition.left, condition.right), false)} ${\n+    return sql`${this.valuePosition(condition.left, table, condition.right, false)} ${\n       condition.op === 'IS' ? sql`IS NOT DISTINCT FROM` : sql`IS DISTINCT FROM`\n-    } ${this.valuePosition(condition.right, table, this.#extractType(table, condition.right, condition.left), false)}`;\n+    } ${this.valuePosition(condition.right, table, condition.left, false)}`;\n   }\n \n   any(condition: SimpleCondition, table: string): SQLQuery {\n-    return sql`${this.valuePosition(condition.left, table, this.#extractType(table, condition.left, condition.right), false)} ${\n+    return sql`${this.valuePosition(condition.left, table, condition.right, false)} ${\n       condition.op === 'IN' ? sql`= ANY` : sql`!= ANY`\n-    } (${this.valuePosition(condition.right, table, this.#extractType(table, condition.right, condition.left), true)})`;\n+    } (${this.valuePosition(condition.right, table, condition.left, true)})`;\n   }\n \n   valuePosition(\n-    value: ValuePosition,\n+    valuePos: ValuePosition,\n     table: string,\n-    valueType: ValueType,\n+    otherValuePos: ValuePosition,\n     plural: boolean,\n   ): SQLQuery {\n-    switch (value.type) {\n+    const valuePosType = valuePos.type;\n+    switch (valuePosType) {\n       case 'column':\n-        return this.#mapColumnNoAlias(table, value.name);\n+        return this.#mapColumnNoAlias(table, valuePos.name);\n       case 'literal':\n-        return sqlConvertArgUnsafe(valueType, value.value, plural);\n+        return this.#literalValuePosition(\n+          valuePos,\n+          table,\n+          otherValuePos,\n+          plural,\n+        );\n       case 'static':\n         throw new Error(\n           'Static parameters must be bound to a value before compiling to SQL',\n         );\n+      default:\n+        unreachable(valuePosType);\n+        break;\n+    }\n+  }\n+\n+  #literalValuePosition(\n+    valuePos: LiteralReference,\n+    table: string,\n+    otherValuePos: ValuePosition,\n+    plural: boolean,\n+  ) {\n+    {\n+      const otherType = otherValuePos.type;\n+      switch (otherType) {\n+        case 'column':\n+          return sqlConvertColumnArg(\n+            this.#serverSchema[this.#nameMapper.tableName(table)][\n+              this.#nameMapper.columnName(table, otherValuePos.name)\n+            ],\n+            valuePos.value,\n+            plural,\n+          );\n+        case 'literal': {\n+          assert(plural === Array.isArray(valuePos.value));\n+          if (Array.isArray(valuePos.value)) {\n+            if (valuePos.value.length > 0) {\n+              return sqlConvertPluralLiteralArg(",
        "comment_created_at": "2025-04-01T15:36:54+00:00",
        "comment_author": "grgbkr",
        "comment_body": "Also the above example would go in the column case above, this branch is literal compared to literal.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1822899584",
    "pr_number": 2880,
    "pr_file": "packages/zqlite/src/table-source.ts",
    "created_at": "2024-10-30T15:41:39+00:00",
    "commented_code": "function toSQLiteTypes(\n   columns: readonly string[],\n   row: Row,\n+  columnTypes: Record<string, SchemaValue>,\n ): readonly unknown[] {\n-  return columns.map(col => toSQLiteType(row[col]));\n+  return columns.map(col => toSQLiteType(row[col], columnTypes[col].type));\n }\n \n function pickColumns(columns: readonly string[], row: Row): readonly Value[] {\n   return columns.map(col => row[col]);\n }\n \n-function toSQLiteType(v: unknown): unknown {\n-  return v === false ? 0 : v === true ? 1 : v ?? null;\n+function toSQLiteType(v: unknown, type: ValueType): unknown {\n+  switch (type) {\n+    case 'boolean':\n+      return v === null ? null : v ? 1 : 0;\n+    case 'number':\n+    case 'string':\n+    case 'null':\n+      return v;\n+    case 'json':\n+      return JSON.stringify(v);",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "1822899584",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 2880,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1822899584",
        "commented_code": "@@ -582,16 +640,26 @@ function assertPrimaryKeyMatch(\n function toSQLiteTypes(\n   columns: readonly string[],\n   row: Row,\n+  columnTypes: Record<string, SchemaValue>,\n ): readonly unknown[] {\n-  return columns.map(col => toSQLiteType(row[col]));\n+  return columns.map(col => toSQLiteType(row[col], columnTypes[col].type));\n }\n \n function pickColumns(columns: readonly string[], row: Row): readonly Value[] {\n   return columns.map(col => row[col]);\n }\n \n-function toSQLiteType(v: unknown): unknown {\n-  return v === false ? 0 : v === true ? 1 : v ?? null;\n+function toSQLiteType(v: unknown, type: ValueType): unknown {\n+  switch (type) {\n+    case 'boolean':\n+      return v === null ? null : v ? 1 : 0;\n+    case 'number':\n+    case 'string':\n+    case 'null':\n+      return v;\n+    case 'json':\n+      return JSON.stringify(v);",
        "comment_created_at": "2024-10-30T15:41:39+00:00",
        "comment_author": "arv",
        "comment_body": "Why do we not use json or jsonb here?",
        "pr_file_module": null
      },
      {
        "comment_id": "1822931085",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 2880,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1822899584",
        "commented_code": "@@ -582,16 +640,26 @@ function assertPrimaryKeyMatch(\n function toSQLiteTypes(\n   columns: readonly string[],\n   row: Row,\n+  columnTypes: Record<string, SchemaValue>,\n ): readonly unknown[] {\n-  return columns.map(col => toSQLiteType(row[col]));\n+  return columns.map(col => toSQLiteType(row[col], columnTypes[col].type));\n }\n \n function pickColumns(columns: readonly string[], row: Row): readonly Value[] {\n   return columns.map(col => row[col]);\n }\n \n-function toSQLiteType(v: unknown): unknown {\n-  return v === false ? 0 : v === true ? 1 : v ?? null;\n+function toSQLiteType(v: unknown, type: ValueType): unknown {\n+  switch (type) {\n+    case 'boolean':\n+      return v === null ? null : v ? 1 : 0;\n+    case 'number':\n+    case 'string':\n+    case 'null':\n+      return v;\n+    case 'json':\n+      return JSON.stringify(v);",
        "comment_created_at": "2024-10-30T16:00:06+00:00",
        "comment_author": "tantaman",
        "comment_body": "SQLite stores JSON as `blob` or `text` and doesn't have a specific `JSON` data type.\r\n\r\nhttps://www.sqlite.org/datatype3.html",
        "pr_file_module": null
      },
      {
        "comment_id": "1824776835",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 2880,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1822899584",
        "commented_code": "@@ -582,16 +640,26 @@ function assertPrimaryKeyMatch(\n function toSQLiteTypes(\n   columns: readonly string[],\n   row: Row,\n+  columnTypes: Record<string, SchemaValue>,\n ): readonly unknown[] {\n-  return columns.map(col => toSQLiteType(row[col]));\n+  return columns.map(col => toSQLiteType(row[col], columnTypes[col].type));\n }\n \n function pickColumns(columns: readonly string[], row: Row): readonly Value[] {\n   return columns.map(col => row[col]);\n }\n \n-function toSQLiteType(v: unknown): unknown {\n-  return v === false ? 0 : v === true ? 1 : v ?? null;\n+function toSQLiteType(v: unknown, type: ValueType): unknown {\n+  switch (type) {\n+    case 'boolean':\n+      return v === null ? null : v ? 1 : 0;\n+    case 'number':\n+    case 'string':\n+    case 'null':\n+      return v;\n+    case 'json':\n+      return JSON.stringify(v);",
        "comment_created_at": "2024-10-31T16:23:02+00:00",
        "comment_author": "tantaman",
        "comment_body": "and we'll need to stringify it to get it into the SQL statement in any case. If SQLite's JSONB format was something we could serialize to externally from SQLite... You know we could expose SQLite's `jsonb` function directly to JS, call it, then bind the returned blob. Or maybe even bind the returned pointer: https://www.sqlite.org/c3ref/bind_blob.html",
        "pr_file_module": null
      },
      {
        "comment_id": "1824780214",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 2880,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1822899584",
        "commented_code": "@@ -582,16 +640,26 @@ function assertPrimaryKeyMatch(\n function toSQLiteTypes(\n   columns: readonly string[],\n   row: Row,\n+  columnTypes: Record<string, SchemaValue>,\n ): readonly unknown[] {\n-  return columns.map(col => toSQLiteType(row[col]));\n+  return columns.map(col => toSQLiteType(row[col], columnTypes[col].type));\n }\n \n function pickColumns(columns: readonly string[], row: Row): readonly Value[] {\n   return columns.map(col => row[col]);\n }\n \n-function toSQLiteType(v: unknown): unknown {\n-  return v === false ? 0 : v === true ? 1 : v ?? null;\n+function toSQLiteType(v: unknown, type: ValueType): unknown {\n+  switch (type) {\n+    case 'boolean':\n+      return v === null ? null : v ? 1 : 0;\n+    case 'number':\n+    case 'string':\n+    case 'null':\n+      return v;\n+    case 'json':\n+      return JSON.stringify(v);",
        "comment_created_at": "2024-10-31T16:25:32+00:00",
        "comment_author": "tantaman",
        "comment_body": "eh, even in the case of exposing `jsonb` we still have to stringify the json first. ",
        "pr_file_module": null
      },
      {
        "comment_id": "1824810690",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 2880,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1822899584",
        "commented_code": "@@ -582,16 +640,26 @@ function assertPrimaryKeyMatch(\n function toSQLiteTypes(\n   columns: readonly string[],\n   row: Row,\n+  columnTypes: Record<string, SchemaValue>,\n ): readonly unknown[] {\n-  return columns.map(col => toSQLiteType(row[col]));\n+  return columns.map(col => toSQLiteType(row[col], columnTypes[col].type));\n }\n \n function pickColumns(columns: readonly string[], row: Row): readonly Value[] {\n   return columns.map(col => row[col]);\n }\n \n-function toSQLiteType(v: unknown): unknown {\n-  return v === false ? 0 : v === true ? 1 : v ?? null;\n+function toSQLiteType(v: unknown, type: ValueType): unknown {\n+  switch (type) {\n+    case 'boolean':\n+      return v === null ? null : v ? 1 : 0;\n+    case 'number':\n+    case 'string':\n+    case 'null':\n+      return v;\n+    case 'json':\n+      return JSON.stringify(v);",
        "comment_created_at": "2024-10-31T16:43:43+00:00",
        "comment_author": "darkgnotic",
        "comment_body": "Yeah, I think the best we would do is store it in SQLite as a BLOB so that json operators (when implemented in zqlite) are faster, but it's probably best to continue treating it as a string when it comes out of SQLite.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1823015217",
    "pr_number": 2880,
    "pr_file": "packages/zqlite/src/table-source.ts",
    "created_at": "2024-10-30T16:41:22+00:00",
    "commented_code": "}",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "1823015217",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 2880,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1823015217",
        "commented_code": "@@ -352,6 +352,14 @@ export class TableSource implements Source {\n     }",
        "comment_created_at": "2024-10-30T16:41:22+00:00",
        "comment_author": "tantaman",
        "comment_body": "@darkgnotic  - given the `pipelineDriver` reads from SQLite to get the row data, do we need the existence check here?\r\n\r\n\r\nIf we can move the existence check out of here it'll let us move `fromSQLiteTypes` to the `pipelineDriver` which is a better fit.",
        "pr_file_module": null
      },
      {
        "comment_id": "1823115559",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 2880,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1823015217",
        "commented_code": "@@ -352,6 +352,14 @@ export class TableSource implements Source {\n     }",
        "comment_created_at": "2024-10-30T17:41:42+00:00",
        "comment_author": "darkgnotic",
        "comment_body": "I do think we can get rid of the existence check since `pipelineDriver` already does this.\r\n\r\nHowever, my opinion is that the zql-type conversion is better consolidated in TableSource; it has to do so for hydrates already, so it made sense for it to do so for push data.\r\n\r\nAt one point we did have a version where `pipelineDriver` was doing the (equivalent of) fromSQLiteTypes for pushes and it felt strange to need the conversion logic in two places. There's some discussion of this in https://github.com/rocicorp/mono/pull/2299",
        "pr_file_module": null
      },
      {
        "comment_id": "1878742492",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 2880,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1823015217",
        "commented_code": "@@ -352,6 +352,14 @@ export class TableSource implements Source {\n     }",
        "comment_created_at": "2024-12-10T19:54:22+00:00",
        "comment_author": "tantaman",
        "comment_body": "It seems like we need another layer around table source to deal with type conversions -- https://bugs.rocicorp.dev/issue/3215\r\n\r\nTableSource exposes the same interface as MemorySource but its contract for `push` is completely different as it expects the pushed types to be SQLite types. Concretely: booleans converted to integers, JSON converted to string.",
        "pr_file_module": null
      },
      {
        "comment_id": "1879084579",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 2880,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1823015217",
        "commented_code": "@@ -352,6 +352,14 @@ export class TableSource implements Source {\n     }",
        "comment_created_at": "2024-12-10T23:43:23+00:00",
        "comment_author": "darkgnotic",
        "comment_body": "I see. Another way of thinking about it is that we can clamp conversion logic to be only / always done when reading out of the replica. So it would be fetches in TableSource, and the advancements in the Snapshotter.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1844991137",
    "pr_number": 3025,
    "pr_file": "packages/zqlite/src/table-source.ts",
    "created_at": "2024-11-16T14:47:25+00:00",
    "commented_code": "}\n }\n \n+export function toSQLiteTypeName(type: ValueType) {",
    "repo_full_name": "rocicorp/mono",
    "discussion_comments": [
      {
        "comment_id": "1844991137",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 3025,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1844991137",
        "commented_code": "@@ -697,6 +697,21 @@ function toSQLiteType(v: unknown, type: ValueType): unknown {\n   }\n }\n \n+export function toSQLiteTypeName(type: ValueType) {",
        "comment_created_at": "2024-11-16T14:47:25+00:00",
        "comment_author": "tantaman",
        "comment_body": "@darkgnotic - do we not have this already?",
        "pr_file_module": null
      },
      {
        "comment_id": "1845564876",
        "repo_full_name": "rocicorp/mono",
        "pr_number": 3025,
        "pr_file": "packages/zqlite/src/table-source.ts",
        "discussion_id": "1844991137",
        "commented_code": "@@ -697,6 +697,21 @@ function toSQLiteType(v: unknown, type: ValueType): unknown {\n   }\n }\n \n+export function toSQLiteTypeName(type: ValueType) {",
        "comment_created_at": "2024-11-17T19:13:42+00:00",
        "comment_author": "darkgnotic",
        "comment_body": "Looks like not directly. What we currently have deals with conversion of values, but not the production of a basic SQLite data type name.\r\n\r\nhttps://github.com/rocicorp/mono/blob/main/packages/zero-cache/src/types/lite.ts#L53\r\n\r\nIn fact, we store the original postgres type as the replica column type so that we can know how to perform migrations on the data if necessary. ",
        "pr_file_module": null
      }
    ]
  }
]