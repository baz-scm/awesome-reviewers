---
title: Consistent API documentation
description: 'Maintain high-quality, consistent documentation as a critical component
  of API design. Documentation should feature:


  1. Correct grammar and spelling, including proper punctuation and sentence structure'
repository: apache/mxnet
label: API
language: Markdown
comments_count: 2
repository_stars: 20801
---

Maintain high-quality, consistent documentation as a critical component of API design. Documentation should feature:

1. Correct grammar and spelling, including proper punctuation and sentence structure
2. Consistent terminology throughout, especially for parameter names and technical terms
3. Clear explanations of parameter usage and behavior differences

Example:
```python
# GOOD: Clear, consistent documentation with proper terminology
"""
Returns a uniform distribution array.

Parameters:
----------
low : float, optional
    Lower boundary of the output interval. Default is 0.
high : float, optional
    Upper boundary of the output interval. Default is 1.
size : tuple, optional
    Output shape. Default is None.
"""

# BAD: Inconsistent terminology and grammatical errors
"""
Returns uniform distribution array.
Parameters:
----------
low : float, optional
    lower boundary of output interval. Default is 0
high : float, optional
    upper boundary of the output interval. Default is 1
shape : tuple, optional
    Output size. Default is None.
"""
```

Consistent documentation reduces developer confusion and improves API adoption. It serves as the primary interface between your API and its users, making it as important as the implementation itself.


[
  {
    "discussion_id": "694324561",
    "pr_number": 20473,
    "pr_file": "docs/python_docs/python/tutorials/getting-started/gluon_migration_guide.md",
    "created_at": "2021-08-23T21:33:34+00:00",
    "commented_code": "<!--- Licensed to the Apache Software Foundation (ASF) under one -->\n<!--- or more contributor license agreements.  See the NOTICE file -->\n<!--- distributed with this work for additional information -->\n<!--- regarding copyright ownership.  The ASF licenses this file -->\n<!--- to you under the Apache License, Version 2.0 (the -->\n<!--- \"License\"); you may not use this file except in compliance -->\n<!--- with the License.  You may obtain a copy of the License at -->\n\n<!---   http://www.apache.org/licenses/LICENSE-2.0 -->\n\n<!--- Unless required by applicable law or agreed to in writing, -->\n<!--- software distributed under the License is distributed on an -->\n<!--- \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->\n<!--- KIND, either express or implied.  See the License for the -->\n<!--- specific language governing permissions and limitations -->\n<!--- under the License. -->\n\n\n# Gluon2.0: Migration Guide\n\n## Overview\nSince the introduction of the Gluon API in MXNet 1.x, it has superceded commonly used symbolic, module and model APIs for model development. In fact, Gluon was the first in deep learning community to unify the flexibility of imperative programming with the performance benefits of symbolic programming, through just-in-time compilation. \n\nIn Gluon2.0, we extend the support to MXNet numpy and numpy extension with simplified interface and new functionalities: \n\n- **Simplified hybridization with deferred compute and tracing**: Deferred compute allows the imperative execution to be used for graph construction, which allows us to unify the historic divergence of NDArray and Symbol. Hybridization now works in a simplified hybrid forward interface. Users only need to specify the computation through imperative programming. Hybridization also works through tracing, i.e. tracing the data flow of the first input data to create graph.\n\n- **Data 2.0**: The new design for data loading in Gluon allows hybridizing and deploying data processing pipeline in the same way as model hybridization. The new C++ data loader improves data loading efficiency on CIFAR 10 by 50%.\n\n- **Distributed 2.0**: The new distributed-training design in Gluon 2.0 provides a unified distributed data parallel interface across native Parameter Server, BytePS, and Horovod, and is extensible for supporting custom distributed training libraries.\n\n- **Gluon Probability**: parameterizable probability distributions and sampling functions to facilitate more areas of research such as Baysian methods and AutoML.\n\n- **Gluon Metrics** and **Optimizers**: refactored with MXNet numpy interface and addressed legacy issues.\n\nAdopting these new functionalities may or may not require modifications on your models. But don't worry, this migration guide will go through a high-level mapping from old functionality to new APIs and make Gluon2.0 migration a hassle-free experience.  \n\n## Data Pipeline\n**What's new**: In Gluon2.0, `MultithreadingDataLoader` is introduced to speed up the data loading pipeline. It will use the pure MXNet C++ implementation of dataloader, datasets and batchify functions. So, you can use either MXNet internal multithreading mode dataloader or python multiprocessing mode dataloader in Gluon2.0. \n\n**Migration Guide**: Users can continue with the traditional gluon.data.Dataloader and the C++ backend will be applied automatically. \n\n[Gluon2.0 dataloader](../../api/gluon/data/index.rst#mxnet.gluon.data.DataLoader) will provide a new parameter called `try_nopython`. This parameter takes default value of None; when set to `True` the dataloader will compile python dataloading pipeline into pure MXNet c++ implementation. The compilation is not guaranteed to support all use cases, but it will fallback to python in case of failure: \n\n- The dataset is not fully [supported by backend](../../api/gluon/data/index.rst#mxnet.gluon.data.Dataset)(e.g., there are custom python datasets).\n\n- Transform is not fully hybridizable. \n\n- Bachify is not fully [supported by backend](https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/data/batchify.py). \n\n\nYou can refer to [Step5 in Crash Course](https://mxnet.apache.org/versions/master/api/python/docs/tutorials/getting-started/crash-course/5-datasets.html#New-in-MXNet-2.0:-faster-C++-backend-dataloaders) for a detailed performance increase with C++ backend. \n## Modeling\nIn Gluon2.0, users will have a brand new modeling experience with NumPy-compatible APIs and deferred compute mechanism. \n\n- **NumPy-compatible programing experience**: users can build their models with MXNet implementation with NumPy array library, NumPy-compatible math operators and some neural network extension operators. \n\n- **Imperative-only coding experience**: with deferred compute and tracing being introduced, users only need to specify the computation through imperative coding but can still make hybridization work. Users will no longer need to interact with symbol APIs. \n\nTo help users migrate smoothly to use these simplified interface, we will provide the following guidance on how to replace legacy operators with NumPy-compatible operators, how to build models with `forward` instead of `hybrid_forward` and how to use `Parameter` class to register your parameters. \n\n\n### NumPy-compatible Programming Experience\n#### NumPy Arrays\nMXNet [NumPy ndarray(i.e. `mx.np.ndarray`)](../../api/np/arrays.ndarray.html) is a multidimensional container of items of the same type and size. Most of its properties and attributes are the same as legacy NDArrays(i.e. `mx.nd.ndarray`), so users can use NumPy array library just as they did with legacy NDArrays. But, there are still some changes and deprecations that needs attention, as mentioned below. \n**Migration Guide**: \n\n1. Currently, NumPy ndarray only supports `default` storage type, other storage types, like `row_sparse`, `csr` are not supported. Also, `tostype()` attribute is deprecated. \n\n2. Users can use `as_np_ndarray` attribute to switch from a legacy NDArray to NumPy ndarray just like this:\n    ```{.python}\n    import mxnet as mx\n    nd_array = mx.ones((5,3))\n    np_array = nd_array.as_np_ndarray()\n    ```\n\n3. Compared with legacy NDArray, some attributes are deprecated in NumPy ndarray. Listed below are some of the deprecated APIs and their corresponding replacements in NumPy ndarray, others can be found in [**Appendix/NumPy Array Deprecated Attributes**](#NumPy-Array-Deprecated-Attributes).\n    |                   Deprecated Attributes               |    NumPy ndarray Equivalent    |\n    | ----------------------------------------------------- | ------------------------------ |\n    |                   `a.asscalar()`                      |         `a.item()`         |\n    |                 `a.as_in_context()`                   |      `a.as_in_ctx()`       |\n    |                    `a.context`                        |          `a.ctx`           |\n    |                   `a.reshape_like(b)`                 |    `a.reshape(b.shape)`    |\n    |                    `a.zeros_like(b)`                  |   `mx.np.zeros_like(b)`  |\n    |                    `a.ones_like(b)`                   |   `mx.np.ones_like(b)`   |\n\n4. Compared with legacy NDArray, some attributes will have different behaviors and take different inputs. \n    |          Attribute            | Legacy Inputs | NumPy Inputs |\n    | ----------------------------- | ------------------------ | -------- |\n    | `a.reshape(*args, **kwargs)`  | **shape**: Some dimensions of the shape can take special values from the set {0, -1, -2, -3, -4}. <br> The significance of each is explained below: <br>  ``0``  copy this dimension from the input to the output shape. <br>  ``-1`` infers the dimension of the output shape by using the remainder of the input dimensions. <br> ``-2`` copy all/remainder of the input dimensions to the output shape. <br> ``-3`` use the product of two consecutive dimensions of the input shape as the output dimension. <br> ``-4`` split one dimension of the input into two dimensions passed subsequent to -4 in shape (can contain -1). <br> **reverse**: If set to 1, then the special values are inferred from right to left | **shape**: shape parameter will be **positional argument** rather than key-word argument. <br> Some dimensions of the shape can take special values from the set {-1, -2, -3, -4, -5, -6}. <br> The significance of each is explained below: <br>  ``-1`` infers the dimension of the output shape by using the remainder of the input dimensions. <br> ``-2`` copy this dimension from the input to the output shape. <br> ``-3`` will skip current dimension if and only if the current dim size is one. <br> ``-4`` copy all remain of the input dimensions to the output shape. <br> ``-5`` use the product of two consecutive dimensions of the input shape as the output. <br> ``-6`` split one dimension of the input into two dimensions passed subsequent to -6 in the new shape. <br> **reverse**: No **reverse** parameter for `np.reshape` but for `npx.reshape`. <br> **order**: Read the elements of `a` using this index order, and place the elements into the reshaped array using this index order. |\n\n\n#### NumPy and NumPy-extension Operators\nMost of the legacy NDArray operators(`mx.nd.op`) have the equivalent ones in np/npx namespace, users can just repalce them with `mx.np.op` or `mx.npx.op` to migrate. Some of the operators will have different inputs and behaviors as listed in the table below.",
    "repo_full_name": "apache/mxnet",
    "discussion_comments": [
      {
        "comment_id": "694324561",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20473,
        "pr_file": "docs/python_docs/python/tutorials/getting-started/gluon_migration_guide.md",
        "discussion_id": "694324561",
        "commented_code": "@@ -0,0 +1,453 @@\n+<!--- Licensed to the Apache Software Foundation (ASF) under one -->\n+<!--- or more contributor license agreements.  See the NOTICE file -->\n+<!--- distributed with this work for additional information -->\n+<!--- regarding copyright ownership.  The ASF licenses this file -->\n+<!--- to you under the Apache License, Version 2.0 (the -->\n+<!--- \"License\"); you may not use this file except in compliance -->\n+<!--- with the License.  You may obtain a copy of the License at -->\n+\n+<!---   http://www.apache.org/licenses/LICENSE-2.0 -->\n+\n+<!--- Unless required by applicable law or agreed to in writing, -->\n+<!--- software distributed under the License is distributed on an -->\n+<!--- \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->\n+<!--- KIND, either express or implied.  See the License for the -->\n+<!--- specific language governing permissions and limitations -->\n+<!--- under the License. -->\n+\n+\n+# Gluon2.0: Migration Guide\n+\n+## Overview\n+Since the introduction of the Gluon API in MXNet 1.x, it has superceded commonly used symbolic, module and model APIs for model development. In fact, Gluon was the first in deep learning community to unify the flexibility of imperative programming with the performance benefits of symbolic programming, through just-in-time compilation. \n+\n+In Gluon2.0, we extend the support to MXNet numpy and numpy extension with simplified interface and new functionalities: \n+\n+- **Simplified hybridization with deferred compute and tracing**: Deferred compute allows the imperative execution to be used for graph construction, which allows us to unify the historic divergence of NDArray and Symbol. Hybridization now works in a simplified hybrid forward interface. Users only need to specify the computation through imperative programming. Hybridization also works through tracing, i.e. tracing the data flow of the first input data to create graph.\n+\n+- **Data 2.0**: The new design for data loading in Gluon allows hybridizing and deploying data processing pipeline in the same way as model hybridization. The new C++ data loader improves data loading efficiency on CIFAR 10 by 50%.\n+\n+- **Distributed 2.0**: The new distributed-training design in Gluon 2.0 provides a unified distributed data parallel interface across native Parameter Server, BytePS, and Horovod, and is extensible for supporting custom distributed training libraries.\n+\n+- **Gluon Probability**: parameterizable probability distributions and sampling functions to facilitate more areas of research such as Baysian methods and AutoML.\n+\n+- **Gluon Metrics** and **Optimizers**: refactored with MXNet numpy interface and addressed legacy issues.\n+\n+Adopting these new functionalities may or may not require modifications on your models. But don't worry, this migration guide will go through a high-level mapping from old functionality to new APIs and make Gluon2.0 migration a hassle-free experience.  \n+\n+## Data Pipeline\n+**What's new**: In Gluon2.0, `MultithreadingDataLoader` is introduced to speed up the data loading pipeline. It will use the pure MXNet C++ implementation of dataloader, datasets and batchify functions. So, you can use either MXNet internal multithreading mode dataloader or python multiprocessing mode dataloader in Gluon2.0. \n+\n+**Migration Guide**: Users can continue with the traditional gluon.data.Dataloader and the C++ backend will be applied automatically. \n+\n+[Gluon2.0 dataloader](../../api/gluon/data/index.rst#mxnet.gluon.data.DataLoader) will provide a new parameter called `try_nopython`. This parameter takes default value of None; when set to `True` the dataloader will compile python dataloading pipeline into pure MXNet c++ implementation. The compilation is not guaranteed to support all use cases, but it will fallback to python in case of failure: \n+\n+- The dataset is not fully [supported by backend](../../api/gluon/data/index.rst#mxnet.gluon.data.Dataset)(e.g., there are custom python datasets).\n+\n+- Transform is not fully hybridizable. \n+\n+- Bachify is not fully [supported by backend](https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/data/batchify.py). \n+\n+\n+You can refer to [Step5 in Crash Course](https://mxnet.apache.org/versions/master/api/python/docs/tutorials/getting-started/crash-course/5-datasets.html#New-in-MXNet-2.0:-faster-C++-backend-dataloaders) for a detailed performance increase with C++ backend. \n+## Modeling\n+In Gluon2.0, users will have a brand new modeling experience with NumPy-compatible APIs and deferred compute mechanism. \n+\n+- **NumPy-compatible programing experience**: users can build their models with MXNet implementation with NumPy array library, NumPy-compatible math operators and some neural network extension operators. \n+\n+- **Imperative-only coding experience**: with deferred compute and tracing being introduced, users only need to specify the computation through imperative coding but can still make hybridization work. Users will no longer need to interact with symbol APIs. \n+\n+To help users migrate smoothly to use these simplified interface, we will provide the following guidance on how to replace legacy operators with NumPy-compatible operators, how to build models with `forward` instead of `hybrid_forward` and how to use `Parameter` class to register your parameters. \n+\n+\n+### NumPy-compatible Programming Experience\n+#### NumPy Arrays\n+MXNet [NumPy ndarray(i.e. `mx.np.ndarray`)](../../api/np/arrays.ndarray.html) is a multidimensional container of items of the same type and size. Most of its properties and attributes are the same as legacy NDArrays(i.e. `mx.nd.ndarray`), so users can use NumPy array library just as they did with legacy NDArrays. But, there are still some changes and deprecations that needs attention, as mentioned below. \n+**Migration Guide**: \n+\n+1. Currently, NumPy ndarray only supports `default` storage type, other storage types, like `row_sparse`, `csr` are not supported. Also, `tostype()` attribute is deprecated. \n+\n+2. Users can use `as_np_ndarray` attribute to switch from a legacy NDArray to NumPy ndarray just like this:\n+    ```{.python}\n+    import mxnet as mx\n+    nd_array = mx.ones((5,3))\n+    np_array = nd_array.as_np_ndarray()\n+    ```\n+\n+3. Compared with legacy NDArray, some attributes are deprecated in NumPy ndarray. Listed below are some of the deprecated APIs and their corresponding replacements in NumPy ndarray, others can be found in [**Appendix/NumPy Array Deprecated Attributes**](#NumPy-Array-Deprecated-Attributes).\n+    |                   Deprecated Attributes               |    NumPy ndarray Equivalent    |\n+    | ----------------------------------------------------- | ------------------------------ |\n+    |                   `a.asscalar()`                      |         `a.item()`         |\n+    |                 `a.as_in_context()`                   |      `a.as_in_ctx()`       |\n+    |                    `a.context`                        |          `a.ctx`           |\n+    |                   `a.reshape_like(b)`                 |    `a.reshape(b.shape)`    |\n+    |                    `a.zeros_like(b)`                  |   `mx.np.zeros_like(b)`  |\n+    |                    `a.ones_like(b)`                   |   `mx.np.ones_like(b)`   |\n+\n+4. Compared with legacy NDArray, some attributes will have different behaviors and take different inputs. \n+    |          Attribute            | Legacy Inputs | NumPy Inputs |\n+    | ----------------------------- | ------------------------ | -------- |\n+    | `a.reshape(*args, **kwargs)`  | **shape**: Some dimensions of the shape can take special values from the set {0, -1, -2, -3, -4}. <br> The significance of each is explained below: <br>  ``0``  copy this dimension from the input to the output shape. <br>  ``-1`` infers the dimension of the output shape by using the remainder of the input dimensions. <br> ``-2`` copy all/remainder of the input dimensions to the output shape. <br> ``-3`` use the product of two consecutive dimensions of the input shape as the output dimension. <br> ``-4`` split one dimension of the input into two dimensions passed subsequent to -4 in shape (can contain -1). <br> **reverse**: If set to 1, then the special values are inferred from right to left | **shape**: shape parameter will be **positional argument** rather than key-word argument. <br> Some dimensions of the shape can take special values from the set {-1, -2, -3, -4, -5, -6}. <br> The significance of each is explained below: <br>  ``-1`` infers the dimension of the output shape by using the remainder of the input dimensions. <br> ``-2`` copy this dimension from the input to the output shape. <br> ``-3`` will skip current dimension if and only if the current dim size is one. <br> ``-4`` copy all remain of the input dimensions to the output shape. <br> ``-5`` use the product of two consecutive dimensions of the input shape as the output. <br> ``-6`` split one dimension of the input into two dimensions passed subsequent to -6 in the new shape. <br> **reverse**: No **reverse** parameter for `np.reshape` but for `npx.reshape`. <br> **order**: Read the elements of `a` using this index order, and place the elements into the reshaped array using this index order. |\n+\n+\n+#### NumPy and NumPy-extension Operators\n+Most of the legacy NDArray operators(`mx.nd.op`) have the equivalent ones in np/npx namespace, users can just repalce them with `mx.np.op` or `mx.npx.op` to migrate. Some of the operators will have different inputs and behaviors as listed in the table below. ",
        "comment_created_at": "2021-08-23T21:33:34+00:00",
        "comment_author": "szha",
        "comment_body": "```suggestion\r\nMost of the legacy NDArray operators(`mx.nd.op`) have the equivalent ones in np/npx namespace. Users can just replace them with `mx.np.op` or `mx.npx.op` to migrate. Some of the operators will have different inputs and behaviors as listed in the table below. \r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "694324761",
    "pr_number": 20473,
    "pr_file": "docs/python_docs/python/tutorials/getting-started/gluon_migration_guide.md",
    "created_at": "2021-08-23T21:34:00+00:00",
    "commented_code": "<!--- Licensed to the Apache Software Foundation (ASF) under one -->\n<!--- or more contributor license agreements.  See the NOTICE file -->\n<!--- distributed with this work for additional information -->\n<!--- regarding copyright ownership.  The ASF licenses this file -->\n<!--- to you under the Apache License, Version 2.0 (the -->\n<!--- \"License\"); you may not use this file except in compliance -->\n<!--- with the License.  You may obtain a copy of the License at -->\n\n<!---   http://www.apache.org/licenses/LICENSE-2.0 -->\n\n<!--- Unless required by applicable law or agreed to in writing, -->\n<!--- software distributed under the License is distributed on an -->\n<!--- \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->\n<!--- KIND, either express or implied.  See the License for the -->\n<!--- specific language governing permissions and limitations -->\n<!--- under the License. -->\n\n\n# Gluon2.0: Migration Guide\n\n## Overview\nSince the introduction of the Gluon API in MXNet 1.x, it has superceded commonly used symbolic, module and model APIs for model development. In fact, Gluon was the first in deep learning community to unify the flexibility of imperative programming with the performance benefits of symbolic programming, through just-in-time compilation. \n\nIn Gluon2.0, we extend the support to MXNet numpy and numpy extension with simplified interface and new functionalities: \n\n- **Simplified hybridization with deferred compute and tracing**: Deferred compute allows the imperative execution to be used for graph construction, which allows us to unify the historic divergence of NDArray and Symbol. Hybridization now works in a simplified hybrid forward interface. Users only need to specify the computation through imperative programming. Hybridization also works through tracing, i.e. tracing the data flow of the first input data to create graph.\n\n- **Data 2.0**: The new design for data loading in Gluon allows hybridizing and deploying data processing pipeline in the same way as model hybridization. The new C++ data loader improves data loading efficiency on CIFAR 10 by 50%.\n\n- **Distributed 2.0**: The new distributed-training design in Gluon 2.0 provides a unified distributed data parallel interface across native Parameter Server, BytePS, and Horovod, and is extensible for supporting custom distributed training libraries.\n\n- **Gluon Probability**: parameterizable probability distributions and sampling functions to facilitate more areas of research such as Baysian methods and AutoML.\n\n- **Gluon Metrics** and **Optimizers**: refactored with MXNet numpy interface and addressed legacy issues.\n\nAdopting these new functionalities may or may not require modifications on your models. But don't worry, this migration guide will go through a high-level mapping from old functionality to new APIs and make Gluon2.0 migration a hassle-free experience.  \n\n## Data Pipeline\n**What's new**: In Gluon2.0, `MultithreadingDataLoader` is introduced to speed up the data loading pipeline. It will use the pure MXNet C++ implementation of dataloader, datasets and batchify functions. So, you can use either MXNet internal multithreading mode dataloader or python multiprocessing mode dataloader in Gluon2.0. \n\n**Migration Guide**: Users can continue with the traditional gluon.data.Dataloader and the C++ backend will be applied automatically. \n\n[Gluon2.0 dataloader](../../api/gluon/data/index.rst#mxnet.gluon.data.DataLoader) will provide a new parameter called `try_nopython`. This parameter takes default value of None; when set to `True` the dataloader will compile python dataloading pipeline into pure MXNet c++ implementation. The compilation is not guaranteed to support all use cases, but it will fallback to python in case of failure: \n\n- The dataset is not fully [supported by backend](../../api/gluon/data/index.rst#mxnet.gluon.data.Dataset)(e.g., there are custom python datasets).\n\n- Transform is not fully hybridizable. \n\n- Bachify is not fully [supported by backend](https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/data/batchify.py). \n\n\nYou can refer to [Step5 in Crash Course](https://mxnet.apache.org/versions/master/api/python/docs/tutorials/getting-started/crash-course/5-datasets.html#New-in-MXNet-2.0:-faster-C++-backend-dataloaders) for a detailed performance increase with C++ backend. \n## Modeling\nIn Gluon2.0, users will have a brand new modeling experience with NumPy-compatible APIs and deferred compute mechanism. \n\n- **NumPy-compatible programing experience**: users can build their models with MXNet implementation with NumPy array library, NumPy-compatible math operators and some neural network extension operators. \n\n- **Imperative-only coding experience**: with deferred compute and tracing being introduced, users only need to specify the computation through imperative coding but can still make hybridization work. Users will no longer need to interact with symbol APIs. \n\nTo help users migrate smoothly to use these simplified interface, we will provide the following guidance on how to replace legacy operators with NumPy-compatible operators, how to build models with `forward` instead of `hybrid_forward` and how to use `Parameter` class to register your parameters. \n\n\n### NumPy-compatible Programming Experience\n#### NumPy Arrays\nMXNet [NumPy ndarray(i.e. `mx.np.ndarray`)](../../api/np/arrays.ndarray.html) is a multidimensional container of items of the same type and size. Most of its properties and attributes are the same as legacy NDArrays(i.e. `mx.nd.ndarray`), so users can use NumPy array library just as they did with legacy NDArrays. But, there are still some changes and deprecations that needs attention, as mentioned below. \n**Migration Guide**: \n\n1. Currently, NumPy ndarray only supports `default` storage type, other storage types, like `row_sparse`, `csr` are not supported. Also, `tostype()` attribute is deprecated. \n\n2. Users can use `as_np_ndarray` attribute to switch from a legacy NDArray to NumPy ndarray just like this:\n    ```{.python}\n    import mxnet as mx\n    nd_array = mx.ones((5,3))\n    np_array = nd_array.as_np_ndarray()\n    ```\n\n3. Compared with legacy NDArray, some attributes are deprecated in NumPy ndarray. Listed below are some of the deprecated APIs and their corresponding replacements in NumPy ndarray, others can be found in [**Appendix/NumPy Array Deprecated Attributes**](#NumPy-Array-Deprecated-Attributes).\n    |                   Deprecated Attributes               |    NumPy ndarray Equivalent    |\n    | ----------------------------------------------------- | ------------------------------ |\n    |                   `a.asscalar()`                      |         `a.item()`         |\n    |                 `a.as_in_context()`                   |      `a.as_in_ctx()`       |\n    |                    `a.context`                        |          `a.ctx`           |\n    |                   `a.reshape_like(b)`                 |    `a.reshape(b.shape)`    |\n    |                    `a.zeros_like(b)`                  |   `mx.np.zeros_like(b)`  |\n    |                    `a.ones_like(b)`                   |   `mx.np.ones_like(b)`   |\n\n4. Compared with legacy NDArray, some attributes will have different behaviors and take different inputs. \n    |          Attribute            | Legacy Inputs | NumPy Inputs |\n    | ----------------------------- | ------------------------ | -------- |\n    | `a.reshape(*args, **kwargs)`  | **shape**: Some dimensions of the shape can take special values from the set {0, -1, -2, -3, -4}. <br> The significance of each is explained below: <br>  ``0``  copy this dimension from the input to the output shape. <br>  ``-1`` infers the dimension of the output shape by using the remainder of the input dimensions. <br> ``-2`` copy all/remainder of the input dimensions to the output shape. <br> ``-3`` use the product of two consecutive dimensions of the input shape as the output dimension. <br> ``-4`` split one dimension of the input into two dimensions passed subsequent to -4 in shape (can contain -1). <br> **reverse**: If set to 1, then the special values are inferred from right to left | **shape**: shape parameter will be **positional argument** rather than key-word argument. <br> Some dimensions of the shape can take special values from the set {-1, -2, -3, -4, -5, -6}. <br> The significance of each is explained below: <br>  ``-1`` infers the dimension of the output shape by using the remainder of the input dimensions. <br> ``-2`` copy this dimension from the input to the output shape. <br> ``-3`` will skip current dimension if and only if the current dim size is one. <br> ``-4`` copy all remain of the input dimensions to the output shape. <br> ``-5`` use the product of two consecutive dimensions of the input shape as the output. <br> ``-6`` split one dimension of the input into two dimensions passed subsequent to -6 in the new shape. <br> **reverse**: No **reverse** parameter for `np.reshape` but for `npx.reshape`. <br> **order**: Read the elements of `a` using this index order, and place the elements into the reshaped array using this index order. |\n\n\n#### NumPy and NumPy-extension Operators\nMost of the legacy NDArray operators(`mx.nd.op`) have the equivalent ones in np/npx namespace, users can just repalce them with `mx.np.op` or `mx.npx.op` to migrate. Some of the operators will have different inputs and behaviors as listed in the table below. \n**Migration Guide**:\n\n1. Operators migration with name/inputs changes\n    |                   Legacy Operators               |    NumPy Operators Equivalent    |   Changes  |\n    | ----------------------------------------------------- | ------------------------------ | ------------------- |\n    |       `mx.nd.flatten(*args, **kwargs)`                |            `mx.npx.batch_flatten(*args, **kwargs)`                    |                moved to `npx` namespace with new name `batch_flatten`            |\n    |       `mx.nd.concat(a, b, c)`                |            `mx.np.concatenate([a, b, c])`                    |              - moved to `np` namespace with new name `concatenate`. <br> - use list of ndarrays as input rather than positional ndarrays           |\n    |        `mx.nd.stack(a, b, c)`                 |            `mx.np.stack([a, b, c])`                    |              - moved to `np` namespace. <br> - use list of ndarrays as input rather than positional ndarrays           |\n    |      `mx.nd.SliceChannel(*args, **kwargs)`              |            `mx.npx.slice_channel(*args, **kwargs)`                 |              - moved to `npx` namespace with new name `slice_channel`.          |\n    |      `mx.nd.FullyConnected(*args, **kwargs)`              |            `mx.npx.fully_connected(*args, **kwargs)`                 |              - moved to `npx` namespace with new name `fully_connected`.          |\n    |      `mx.nd.Activation(*args, **kwargs)`              |            `mx.npx.activation(*args, **kwargs)`                 |              - moved to `npx` namespace with new name `activation`.          |\n    |      `mx.nd.Activation(*args, **kwargs)`              |            `mx.npx.activation(*args, **kwargs)`                 |              - moved to `npx` namespace with new name `activation`.          |\n    |      `mx.nd.elemwise_add(a, b)`              |            `a + b`                 |              - Just use ndarray python operator.          |\n    |      `mx.nd.elemwise_mul(a, b)`              |            `mx.np.multiply(a, b)`                 |              - Use `multiply` operator in `np` namespace.          |\n\n2. Operators migration with multiple steps: `mx.nd.mean` -> `mx.np.mean`:\n```{.python}\nimport mxnet as mx\n# Legacy: calculate mean value with reduction on axis 1\n#         with `exclude` option on \nnd_mean = mx.nd.mean(data, axis=1, exclude=1)\n\n# Numpy: no exclude option to users, but user can perform steps as follow\naxes = list(range(data.ndim))\ndel axes[1]\nnp_mean = mx.np.mean(data, axis=axes)\n```\n\n3. Random Operators\n    |                   Legacy Operators               |    NumPy Operators Equivalent    |   Changes  |\n    | ----------------------------------------------------- | ------------------------------ | ---------------------------- |\n    |       `mx.random.uniform(-1.0, 1.0, shape=(2, 3))` <br> `mx.nd.random.uniform(-1.0, 1.0, shape=(2, 3))`                |            `mx.np.random.uniform(-1.0, 1.0, size=(2, 3))`                    |                For all the NumPy random operators, use **size** key word instead of **shape**           |",
    "repo_full_name": "apache/mxnet",
    "discussion_comments": [
      {
        "comment_id": "694324761",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20473,
        "pr_file": "docs/python_docs/python/tutorials/getting-started/gluon_migration_guide.md",
        "discussion_id": "694324761",
        "commented_code": "@@ -0,0 +1,453 @@\n+<!--- Licensed to the Apache Software Foundation (ASF) under one -->\n+<!--- or more contributor license agreements.  See the NOTICE file -->\n+<!--- distributed with this work for additional information -->\n+<!--- regarding copyright ownership.  The ASF licenses this file -->\n+<!--- to you under the Apache License, Version 2.0 (the -->\n+<!--- \"License\"); you may not use this file except in compliance -->\n+<!--- with the License.  You may obtain a copy of the License at -->\n+\n+<!---   http://www.apache.org/licenses/LICENSE-2.0 -->\n+\n+<!--- Unless required by applicable law or agreed to in writing, -->\n+<!--- software distributed under the License is distributed on an -->\n+<!--- \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY -->\n+<!--- KIND, either express or implied.  See the License for the -->\n+<!--- specific language governing permissions and limitations -->\n+<!--- under the License. -->\n+\n+\n+# Gluon2.0: Migration Guide\n+\n+## Overview\n+Since the introduction of the Gluon API in MXNet 1.x, it has superceded commonly used symbolic, module and model APIs for model development. In fact, Gluon was the first in deep learning community to unify the flexibility of imperative programming with the performance benefits of symbolic programming, through just-in-time compilation. \n+\n+In Gluon2.0, we extend the support to MXNet numpy and numpy extension with simplified interface and new functionalities: \n+\n+- **Simplified hybridization with deferred compute and tracing**: Deferred compute allows the imperative execution to be used for graph construction, which allows us to unify the historic divergence of NDArray and Symbol. Hybridization now works in a simplified hybrid forward interface. Users only need to specify the computation through imperative programming. Hybridization also works through tracing, i.e. tracing the data flow of the first input data to create graph.\n+\n+- **Data 2.0**: The new design for data loading in Gluon allows hybridizing and deploying data processing pipeline in the same way as model hybridization. The new C++ data loader improves data loading efficiency on CIFAR 10 by 50%.\n+\n+- **Distributed 2.0**: The new distributed-training design in Gluon 2.0 provides a unified distributed data parallel interface across native Parameter Server, BytePS, and Horovod, and is extensible for supporting custom distributed training libraries.\n+\n+- **Gluon Probability**: parameterizable probability distributions and sampling functions to facilitate more areas of research such as Baysian methods and AutoML.\n+\n+- **Gluon Metrics** and **Optimizers**: refactored with MXNet numpy interface and addressed legacy issues.\n+\n+Adopting these new functionalities may or may not require modifications on your models. But don't worry, this migration guide will go through a high-level mapping from old functionality to new APIs and make Gluon2.0 migration a hassle-free experience.  \n+\n+## Data Pipeline\n+**What's new**: In Gluon2.0, `MultithreadingDataLoader` is introduced to speed up the data loading pipeline. It will use the pure MXNet C++ implementation of dataloader, datasets and batchify functions. So, you can use either MXNet internal multithreading mode dataloader or python multiprocessing mode dataloader in Gluon2.0. \n+\n+**Migration Guide**: Users can continue with the traditional gluon.data.Dataloader and the C++ backend will be applied automatically. \n+\n+[Gluon2.0 dataloader](../../api/gluon/data/index.rst#mxnet.gluon.data.DataLoader) will provide a new parameter called `try_nopython`. This parameter takes default value of None; when set to `True` the dataloader will compile python dataloading pipeline into pure MXNet c++ implementation. The compilation is not guaranteed to support all use cases, but it will fallback to python in case of failure: \n+\n+- The dataset is not fully [supported by backend](../../api/gluon/data/index.rst#mxnet.gluon.data.Dataset)(e.g., there are custom python datasets).\n+\n+- Transform is not fully hybridizable. \n+\n+- Bachify is not fully [supported by backend](https://github.com/apache/incubator-mxnet/blob/master/python/mxnet/gluon/data/batchify.py). \n+\n+\n+You can refer to [Step5 in Crash Course](https://mxnet.apache.org/versions/master/api/python/docs/tutorials/getting-started/crash-course/5-datasets.html#New-in-MXNet-2.0:-faster-C++-backend-dataloaders) for a detailed performance increase with C++ backend. \n+## Modeling\n+In Gluon2.0, users will have a brand new modeling experience with NumPy-compatible APIs and deferred compute mechanism. \n+\n+- **NumPy-compatible programing experience**: users can build their models with MXNet implementation with NumPy array library, NumPy-compatible math operators and some neural network extension operators. \n+\n+- **Imperative-only coding experience**: with deferred compute and tracing being introduced, users only need to specify the computation through imperative coding but can still make hybridization work. Users will no longer need to interact with symbol APIs. \n+\n+To help users migrate smoothly to use these simplified interface, we will provide the following guidance on how to replace legacy operators with NumPy-compatible operators, how to build models with `forward` instead of `hybrid_forward` and how to use `Parameter` class to register your parameters. \n+\n+\n+### NumPy-compatible Programming Experience\n+#### NumPy Arrays\n+MXNet [NumPy ndarray(i.e. `mx.np.ndarray`)](../../api/np/arrays.ndarray.html) is a multidimensional container of items of the same type and size. Most of its properties and attributes are the same as legacy NDArrays(i.e. `mx.nd.ndarray`), so users can use NumPy array library just as they did with legacy NDArrays. But, there are still some changes and deprecations that needs attention, as mentioned below. \n+**Migration Guide**: \n+\n+1. Currently, NumPy ndarray only supports `default` storage type, other storage types, like `row_sparse`, `csr` are not supported. Also, `tostype()` attribute is deprecated. \n+\n+2. Users can use `as_np_ndarray` attribute to switch from a legacy NDArray to NumPy ndarray just like this:\n+    ```{.python}\n+    import mxnet as mx\n+    nd_array = mx.ones((5,3))\n+    np_array = nd_array.as_np_ndarray()\n+    ```\n+\n+3. Compared with legacy NDArray, some attributes are deprecated in NumPy ndarray. Listed below are some of the deprecated APIs and their corresponding replacements in NumPy ndarray, others can be found in [**Appendix/NumPy Array Deprecated Attributes**](#NumPy-Array-Deprecated-Attributes).\n+    |                   Deprecated Attributes               |    NumPy ndarray Equivalent    |\n+    | ----------------------------------------------------- | ------------------------------ |\n+    |                   `a.asscalar()`                      |         `a.item()`         |\n+    |                 `a.as_in_context()`                   |      `a.as_in_ctx()`       |\n+    |                    `a.context`                        |          `a.ctx`           |\n+    |                   `a.reshape_like(b)`                 |    `a.reshape(b.shape)`    |\n+    |                    `a.zeros_like(b)`                  |   `mx.np.zeros_like(b)`  |\n+    |                    `a.ones_like(b)`                   |   `mx.np.ones_like(b)`   |\n+\n+4. Compared with legacy NDArray, some attributes will have different behaviors and take different inputs. \n+    |          Attribute            | Legacy Inputs | NumPy Inputs |\n+    | ----------------------------- | ------------------------ | -------- |\n+    | `a.reshape(*args, **kwargs)`  | **shape**: Some dimensions of the shape can take special values from the set {0, -1, -2, -3, -4}. <br> The significance of each is explained below: <br>  ``0``  copy this dimension from the input to the output shape. <br>  ``-1`` infers the dimension of the output shape by using the remainder of the input dimensions. <br> ``-2`` copy all/remainder of the input dimensions to the output shape. <br> ``-3`` use the product of two consecutive dimensions of the input shape as the output dimension. <br> ``-4`` split one dimension of the input into two dimensions passed subsequent to -4 in shape (can contain -1). <br> **reverse**: If set to 1, then the special values are inferred from right to left | **shape**: shape parameter will be **positional argument** rather than key-word argument. <br> Some dimensions of the shape can take special values from the set {-1, -2, -3, -4, -5, -6}. <br> The significance of each is explained below: <br>  ``-1`` infers the dimension of the output shape by using the remainder of the input dimensions. <br> ``-2`` copy this dimension from the input to the output shape. <br> ``-3`` will skip current dimension if and only if the current dim size is one. <br> ``-4`` copy all remain of the input dimensions to the output shape. <br> ``-5`` use the product of two consecutive dimensions of the input shape as the output. <br> ``-6`` split one dimension of the input into two dimensions passed subsequent to -6 in the new shape. <br> **reverse**: No **reverse** parameter for `np.reshape` but for `npx.reshape`. <br> **order**: Read the elements of `a` using this index order, and place the elements into the reshaped array using this index order. |\n+\n+\n+#### NumPy and NumPy-extension Operators\n+Most of the legacy NDArray operators(`mx.nd.op`) have the equivalent ones in np/npx namespace, users can just repalce them with `mx.np.op` or `mx.npx.op` to migrate. Some of the operators will have different inputs and behaviors as listed in the table below. \n+**Migration Guide**:\n+\n+1. Operators migration with name/inputs changes\n+    |                   Legacy Operators               |    NumPy Operators Equivalent    |   Changes  |\n+    | ----------------------------------------------------- | ------------------------------ | ------------------- |\n+    |       `mx.nd.flatten(*args, **kwargs)`                |            `mx.npx.batch_flatten(*args, **kwargs)`                    |                moved to `npx` namespace with new name `batch_flatten`            |\n+    |       `mx.nd.concat(a, b, c)`                |            `mx.np.concatenate([a, b, c])`                    |              - moved to `np` namespace with new name `concatenate`. <br> - use list of ndarrays as input rather than positional ndarrays           |\n+    |        `mx.nd.stack(a, b, c)`                 |            `mx.np.stack([a, b, c])`                    |              - moved to `np` namespace. <br> - use list of ndarrays as input rather than positional ndarrays           |\n+    |      `mx.nd.SliceChannel(*args, **kwargs)`              |            `mx.npx.slice_channel(*args, **kwargs)`                 |              - moved to `npx` namespace with new name `slice_channel`.          |\n+    |      `mx.nd.FullyConnected(*args, **kwargs)`              |            `mx.npx.fully_connected(*args, **kwargs)`                 |              - moved to `npx` namespace with new name `fully_connected`.          |\n+    |      `mx.nd.Activation(*args, **kwargs)`              |            `mx.npx.activation(*args, **kwargs)`                 |              - moved to `npx` namespace with new name `activation`.          |\n+    |      `mx.nd.Activation(*args, **kwargs)`              |            `mx.npx.activation(*args, **kwargs)`                 |              - moved to `npx` namespace with new name `activation`.          |\n+    |      `mx.nd.elemwise_add(a, b)`              |            `a + b`                 |              - Just use ndarray python operator.          |\n+    |      `mx.nd.elemwise_mul(a, b)`              |            `mx.np.multiply(a, b)`                 |              - Use `multiply` operator in `np` namespace.          |\n+\n+2. Operators migration with multiple steps: `mx.nd.mean` -> `mx.np.mean`:\n+```{.python}\n+import mxnet as mx\n+# Legacy: calculate mean value with reduction on axis 1\n+#         with `exclude` option on \n+nd_mean = mx.nd.mean(data, axis=1, exclude=1)\n+\n+# Numpy: no exclude option to users, but user can perform steps as follow\n+axes = list(range(data.ndim))\n+del axes[1]\n+np_mean = mx.np.mean(data, axis=axes)\n+```\n+\n+3. Random Operators\n+    |                   Legacy Operators               |    NumPy Operators Equivalent    |   Changes  |\n+    | ----------------------------------------------------- | ------------------------------ | ---------------------------- |\n+    |       `mx.random.uniform(-1.0, 1.0, shape=(2, 3))` <br> `mx.nd.random.uniform(-1.0, 1.0, shape=(2, 3))`                |            `mx.np.random.uniform(-1.0, 1.0, size=(2, 3))`                    |                For all the NumPy random operators, use **size** key word instead of **shape**           |",
        "comment_created_at": "2021-08-23T21:34:00+00:00",
        "comment_author": "szha",
        "comment_body": "```suggestion\r\n    |       `mx.random.uniform(-1.0, 1.0, shape=(2, 3))` <br> `mx.nd.random.uniform(-1.0, 1.0, shape=(2, 3))`                |            `mx.np.random.uniform(-1.0, 1.0, size=(2, 3))`                    |                For all the NumPy random operators, use **size** keyword instead of **shape**           |\r\n```",
        "pr_file_module": null
      }
    ]
  }
]
