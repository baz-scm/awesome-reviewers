---
title: Document environment variables
description: All environment variables must be documented in the central env_var.md
  file with clear descriptions of their purpose, acceptable values, and effects. Use
  consistent naming patterns that reflect the subsystem they configure (e.g., MXNET_CUDNN_*,
  MXNET_MKLDNN_*) and avoid introducing new variables when existing ones can serve
  the same purpose.
repository: apache/mxnet
label: Configurations
language: Other
comments_count: 3
repository_stars: 20801
---

All environment variables must be documented in the central env_var.md file with clear descriptions of their purpose, acceptable values, and effects. Use consistent naming patterns that reflect the subsystem they configure (e.g., MXNET_CUDNN_*, MXNET_MKLDNN_*) and avoid introducing new variables when existing ones can serve the same purpose.

Example:
```cpp
// Good - Uses consistent naming and is documented
// In code:
const bool brgemm_disabled = dmlc::GetEnv("MXNET_MKLDNN_DISABLE_BRGEMM_FC", true);

// In docs/static_site/src/pages/api/faq/env_var.md:
// MXNET_MKLDNN_DISABLE_BRGEMM_FC=[true|false] - Disable BRGEMM algorithm in fully connected layers when using MKLDNN backend. Default is true.

// Bad - Introduces new variable without documentation
static bool use_new_dep_engine = dmlc::GetEnv("MXNET_ASYNC_GPU_ENGINE", false);
// Instead, reuse existing variable:
// static bool use_new_dep_engine = (dmlc::GetEnv("MXNET_ENGINE_TYPE", "") == "AsyncGPU");
```

When adding new configuration options:
1. Check if an existing variable can be extended instead of creating a new one
2. Follow the subsystem naming prefix pattern (MXNET_[SUBSYSTEM]_*)
3. Document the variable in env_var.md with its default value and purpose
4. For enum-like options, document all valid values and their effects


[
  {
    "discussion_id": "744069231",
    "pr_number": 20635,
    "pr_file": "src/operator/cudnn_ops.cc",
    "created_at": "2021-11-06T03:30:04+00:00",
    "commented_code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\n/*!\n * Copyright (c) 2021 by Contributors\n * \\file  cudnn_ops.cc\n * \\brief cuDNN v8 ops\n */\n\n#include \"cudnn_ops.h\"\n\n#include <mxnet/base.h>\n#if MXNET_USE_CUDNN == 1\n\n#include <dmlc/parameter.h>\n\n#include <algorithm>\n#include <cstdlib>\n#include <iomanip>\n#include <iterator>\n#include <limits>\n#include <numeric>\n#include <sstream>\n#include <string>\n#include <utility>\n\nnamespace mxnet {\nnamespace op {\n\nusing cudnn_cxx::Descriptor;\nusing cudnn_cxx::GetAttr;\nusing cudnn_cxx::GetSomeAttrs;\nusing cudnn_cxx::IsCompatible;\nusing cudnn_cxx::MakeAvgSampler;\nusing cudnn_cxx::MakeFinalized;\nusing cudnn_cxx::PackedStrides;\nusing cudnn_cxx::PlanStr;\n\nnamespace cudnn {\n\ncudnnDataType_t CudnnType(mshadow::TypeFlag dtype) {\n  static std::unordered_map<mshadow::TypeFlag, cudnnDataType_t> type_map {\n    {mshadow::kFloat32, CUDNN_DATA_FLOAT}, {mshadow::kFloat64, CUDNN_DATA_DOUBLE},\n        {mshadow::kFloat16, CUDNN_DATA_HALF}, {mshadow::kUint8, CUDNN_DATA_UINT8},\n        {mshadow::kInt8, CUDNN_DATA_INT8}, {mshadow::kInt32, CUDNN_DATA_INT32},\n#if CUDNN_VERSION >= 8100\n        {mshadow::kInt64, CUDNN_DATA_INT64},\n#endif  // CUDNN_VERSION >= 8100\n  };\n  auto it = type_map.find(dtype);\n  CHECK(it != type_map.end()) << \"Unsupported type: \" << dtype;\n  return it->second;\n}\n\nstd::vector<size_t> LayoutInfo::Order() const {\n  std::vector<size_t> ret(n_space_dims + 2);\n  std::iota(ret.begin(), ret.end(), 0);\n  if (channel_last)\n    std::rotate(ret.begin() + 1, ret.begin() + 2, ret.end());\n  return ret;\n}\n\nsize_t LayoutInfo::ChannelIdx() const {\n  return channel_last ? 1 + n_space_dims : 1;\n}\n\nstd::vector<int64_t> LayoutInfo::Strides(const std::vector<int64_t>& dims) const {\n  return PackedStrides(Order(), dims);\n}\n\nLayoutInfo GetLayoutInfo(mshadow::LayoutFlag layout) {\n  static std::unordered_map<mshadow::LayoutFlag, LayoutInfo> layout_map{\n      {mshadow::kNCW, {1, false}},\n      {mshadow::kNWC, {1, true}},\n      {mshadow::kNCHW, {2, false}},\n      {mshadow::kNHWC, {2, true}},\n      {mshadow::kNCDHW, {3, false}},\n      {mshadow::kNDHWC, {3, true}},\n  };\n  auto it = layout_map.find(layout);\n  CHECK(it != layout_map.end()) << \"Unsupported layout: \" << layout;\n  return it->second;\n}\n\nTShape ExpandChannelDims(mshadow::LayoutFlag layout, int c) {\n  auto li = GetLayoutInfo(layout);\n  std::vector<int> dims(li.n_space_dims + 2, 1);\n  dims[li.ChannelIdx()] = c;\n  return TShape(dims.begin(), dims.end());\n}\n\nstd::vector<size_t> ReverseOrder(const std::vector<size_t>& o) {\n  std::vector<size_t> ret(o.size());\n  for (size_t i = 0; i < ret.size(); ++i)\n    ret[o[i]] = i;\n  return ret;\n}\n\nstd::vector<cudnnBackendNumericalNote_t> RequireNumerics() {\n  std::vector<cudnnBackendNumericalNote_t> ret;\n  return ret;\n}\n\nstd::vector<cudnnBackendNumericalNote_t> ExcludeNumerics() {\n  std::vector<cudnnBackendNumericalNote_t> ret;\n  if (!dmlc::GetEnv(\"MXNET_CUDA_ALLOW_TENSOR_CORE\", true))\n    ret.push_back(CUDNN_NUMERICAL_NOTE_TENSOR_CORE);\n  if (!dmlc::GetEnv(\"MXNET_CUDA_TENSOR_OP_MATH_ALLOW_CONVERSION\", false))\n    ret.push_back(CUDNN_NUMERICAL_NOTE_DOWN_CONVERT_INPUTS);\n  if (!dmlc::GetEnv(\"MXNET_CUDNN_ALLOW_REDUCED_PRECISION_REDUCTION\", true))\n    ret.push_back(CUDNN_NUMERICAL_NOTE_REDUCED_PRECISION_REDUCTION);\n  if (!dmlc::GetEnv(\"MXNET_CUDNN_ALLOW_FFT\", true))\n    ret.push_back(CUDNN_NUMERICAL_NOTE_FFT);\n  if (dmlc::GetEnv(\"MXNET_ENFORCE_DETERMINISM\", false))\n    ret.push_back(CUDNN_NUMERICAL_NOTE_NONDETERMINISTIC);\n  if (!dmlc::GetEnv(\"MXNET_CUDNN_ALLOW_WINOGRAD\", true))\n    ret.push_back(CUDNN_NUMERICAL_NOTE_WINOGRAD);\n  return ret;\n}\n\nDescriptor MakeTensorDesc(int64_t uid,\n                          cudnnDataType_t dtype,\n                          const std::vector<int64_t>& dims,\n                          const std::vector<int64_t>& strides,\n                          bool is_virtual) {\n  int64_t alignment = 16;  // TODO(vcherepanov): ?\n  return MakeFinalized(CUDNN_BACKEND_TENSOR_DESCRIPTOR,\n                       CUDNN_ATTR_TENSOR_UNIQUE_ID,\n                       uid,\n                       CUDNN_ATTR_TENSOR_DATA_TYPE,\n                       dtype,\n                       CUDNN_ATTR_TENSOR_BYTE_ALIGNMENT,\n                       alignment,\n                       CUDNN_ATTR_TENSOR_DIMENSIONS,\n                       dims,\n                       CUDNN_ATTR_TENSOR_STRIDES,\n                       strides,\n                       CUDNN_ATTR_TENSOR_IS_VIRTUAL,\n                       is_virtual);\n}\n\nDescriptor MakeTensorDesc(int64_t uid,\n                          const TBlob& blob,\n                          const LayoutInfo& li,\n                          bool expand_1d,\n                          bool is_virtual) {\n  std::vector<int64_t> dims(blob.shape_.ndim());\n  CHECK_EQ(dims.size(), li.n_space_dims + 2);\n  auto rev_order = ReverseOrder(li.Order());\n  for (size_t i = 0; i < dims.size(); ++i)\n    dims[i] = blob.shape_[rev_order[i]];\n  auto strides = li.Strides(dims);\n  if (li.n_space_dims == 1 && expand_1d) {\n    dims.insert(dims.begin() + 2, 1);\n    std::vector<size_t> order(dims.size());\n    std::iota(order.begin(), order.end(), 0);\n    if (li.channel_last)\n      std::rotate(order.begin() + 1, order.begin() + 2, order.end());\n    strides = PackedStrides(order, dims);\n  }\n  return MakeTensorDesc(\n      uid, CudnnType(static_cast<mshadow::TypeFlag>(blob.type_flag_)), dims, strides, is_virtual);\n}\n\nDescriptor MakeCTensorDescExpandDims(int64_t uid,\n                                     const TBlob& b,\n                                     const LayoutInfo& li,\n                                     bool is_virtual) {\n  std::vector<int64_t> dims(li.n_space_dims + 2, 1);\n  dims[1]    = b.shape_[0];\n  auto dtype = CudnnType(static_cast<mshadow::TypeFlag>(b.type_flag_));\n  return MakeTensorDesc(uid, dtype, dims, li.Strides(dims), is_virtual);\n}\n\nDescriptor MakeConvDesc(const ConvParam& param, mshadow::TypeFlag dtype) {\n  int64_t sdims = param.kernel.ndim();\n  std::vector<int64_t> stride(param.stride.begin(), param.stride.end());\n  std::vector<int64_t> dilate(param.dilate.begin(), param.dilate.end());\n  std::vector<int64_t> pad(param.pad.begin(), param.pad.end());\n\n  auto comp_type = CudnnType(dtype);\n  if (comp_type == CUDNN_DATA_HALF)\n    comp_type = CUDNN_DATA_FLOAT;\n\n  if (sdims == 1) {\n    // TODO(vcherepanov): remove this once cuDNN properly supports 1D convolutions.\n    // For now, making spacial dims 2D: 1 x W.\n    ++sdims;\n    stride.insert(stride.begin(), 1);\n    dilate.insert(dilate.begin(), 1);\n    pad.insert(pad.begin(), 0);\n  }\n  return MakeFinalized(CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR,\n                       CUDNN_ATTR_CONVOLUTION_SPATIAL_DIMS,\n                       sdims,\n                       CUDNN_ATTR_CONVOLUTION_COMP_TYPE,\n                       comp_type,\n                       CUDNN_ATTR_CONVOLUTION_CONV_MODE,\n                       CUDNN_CROSS_CORRELATION,\n                       CUDNN_ATTR_CONVOLUTION_FILTER_STRIDES,\n                       stride,\n                       CUDNN_ATTR_CONVOLUTION_DILATIONS,\n                       dilate,\n                       CUDNN_ATTR_CONVOLUTION_PRE_PADDINGS,\n                       pad,\n                       CUDNN_ATTR_CONVOLUTION_POST_PADDINGS,\n                       pad);\n}\n\nDescriptor MakeConvFwdOp(const Descriptor& conv,\n                         const Descriptor& x,\n                         const Descriptor& w,\n                         const Descriptor& y,\n                         bool add_to) {\n  auto ret = Make(CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR,\n                  CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_CONV_DESC,\n                  conv,\n                  CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_X,\n                  x,\n                  CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_W,\n                  w,\n                  CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_Y,\n                  y);\n  if (GetAttr<cudnnDataType_t>(x, CUDNN_ATTR_TENSOR_DATA_TYPE) == CUDNN_DATA_DOUBLE) {\n    SetAttrs(ret,\n             CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_ALPHA,\n             1.0,\n             CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_BETA,\n             add_to ? 1.0 : 0.0);\n  } else {\n    SetAttrs(ret,\n             CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_ALPHA,\n             1.0f,\n             CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_BETA,\n             add_to ? 1.0f : 0.0f);\n  }\n  CUDNN_CALL(cudnnBackendFinalize(ret.get()));\n  return ret;\n}\n\nDescriptor MakeConvDgradOp(const Descriptor& conv,\n                           const Descriptor& w,\n                           const Descriptor& dy,\n                           const Descriptor& dx,\n                           bool add_to) {\n  auto ret = Make(CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR,\n                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_CONV_DESC,\n                  conv,\n                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_W,\n                  w,\n                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_DY,\n                  dy,\n                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_DX,\n                  dx);\n  if (GetAttr<cudnnDataType_t>(w, CUDNN_ATTR_TENSOR_DATA_TYPE) == CUDNN_DATA_DOUBLE) {\n    SetAttrs(ret,\n             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_ALPHA,\n             1.0,\n             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_BETA,\n             add_to ? 1.0 : 0.0);\n  } else {\n    SetAttrs(ret,\n             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_ALPHA,\n             1.0f,\n             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_BETA,\n             add_to ? 1.0f : 0.0f);\n  }\n  CUDNN_CALL(cudnnBackendFinalize(ret.get()));\n  return ret;\n}\n\nDescriptor MakeConvWgradOp(const Descriptor& conv,\n                           const Descriptor& x,\n                           const Descriptor& dy,\n                           const Descriptor& dw,\n                           bool add_to) {\n  auto ret = Make(CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR,\n                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_CONV_DESC,\n                  conv,\n                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_X,\n                  x,\n                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_DY,\n                  dy,\n                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_DW,\n                  dw);\n  if (GetAttr<cudnnDataType_t>(x, CUDNN_ATTR_TENSOR_DATA_TYPE) == CUDNN_DATA_DOUBLE) {\n    SetAttrs(ret,\n             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_ALPHA,\n             1.0,\n             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_BETA,\n             add_to ? 1.0 : 0.0);\n  } else {\n    SetAttrs(ret,\n             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_ALPHA,\n             1.0f,\n             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_BETA,\n             add_to ? 1.0f : 0.0f);\n  }\n  CUDNN_CALL(cudnnBackendFinalize(ret.get()));\n  return ret;\n}\n\nDescriptor MakeOpGraph(cudnnHandle_t handle, const std::vector<Descriptor>& ops) {\n  return MakeFinalized(CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR,\n                       CUDNN_ATTR_OPERATIONGRAPH_HANDLE,\n                       handle,\n                       CUDNN_ATTR_OPERATIONGRAPH_OPS,\n                       ops);\n}\n\nConvParam::ConvParam(const ConvolutionParam& p, bool add_to)\n    : kernel(p.kernel),\n      stride(p.stride),\n      dilate(p.dilate),\n      pad(p.pad),\n      num_filter(p.num_filter),\n      num_group(p.num_group),\n      workspace(p.workspace),\n      cudnn_tune(p.cudnn_tune),\n      layout(p.layout),\n      add_to(add_to) {}\n\nConvParam::ConvParam(const DeconvolutionParam& p, bool add_to)\n    : kernel(p.kernel),\n      stride(p.stride),\n      dilate(p.dilate),\n      pad(p.pad),\n      num_filter(p.num_filter),\n      num_group(p.num_group),\n      workspace(p.workspace),\n      cudnn_tune(p.cudnn_tune),\n      layout(p.layout),\n      add_to(add_to) {}\n\nvoid TuneWarnOnce() {\n  thread_local bool done = false;\n  if (!done) {\n    LOG(INFO) << \"Auto-tuning cuDNN op, set MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable\";\n    done = true;\n  }\n}\n\nstd::vector<Descriptor> MakeFallbackPlans(\n    const std::vector<int64_t>& ixs,\n    cudnnHandle_t handle,\n    const Descriptor& op_graph,\n    size_t workspace_limit,\n    size_t* max_workspace,\n    const std::unordered_set<int64_t>& excl_engines,\n    const std::vector<cudnnBackendNumericalNote_t>& req_numeric,\n    const std::vector<cudnnBackendNumericalNote_t>& excl_numeric\n#if CUDNN_VERSION >= 8200\n    ,\n    const std::vector<cudnnBackendBehaviorNote_t>& req_behavior,\n    const std::vector<cudnnBackendBehaviorNote_t>& excl_behavior\n#endif  // CUDNN_VERSION >= 8200\n) {\n  std::vector<Descriptor> plans;\n  if (max_workspace)\n    *max_workspace = 0;\n  for (auto ix : ixs) {\n    if (excl_engines.count(ix))\n      continue;\n    auto engine = Make(CUDNN_BACKEND_ENGINE_DESCRIPTOR,\n                       CUDNN_ATTR_ENGINE_OPERATION_GRAPH,\n                       op_graph,\n                       CUDNN_ATTR_ENGINE_GLOBAL_INDEX,\n                       ix);\n    auto err    = cudnnBackendFinalize(engine.get());\n    if (err == CUDNN_STATUS_NOT_SUPPORTED || err == CUDNN_STATUS_ARCH_MISMATCH)\n      continue;\n    if (err != CUDNN_STATUS_SUCCESS) {\n      LOG(WARNING) << \"Unexpected cuDNN status: \" << err << \": \" << cudnnGetErrorString(err);\n      continue;\n    }\n    auto cfg =\n        MakeFinalized(CUDNN_BACKEND_ENGINECFG_DESCRIPTOR, CUDNN_ATTR_ENGINECFG_ENGINE, engine);\n    auto plan = Make(CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR,\n                     CUDNN_ATTR_EXECUTION_PLAN_HANDLE,\n                     handle,\n                     CUDNN_ATTR_EXECUTION_PLAN_ENGINE_CONFIG,\n                     cfg);\n    err       = cudnnBackendFinalize(plan.get());\n    if (err == CUDNN_STATUS_NOT_SUPPORTED || err == CUDNN_STATUS_ARCH_MISMATCH)\n      continue;\n    if (err != CUDNN_STATUS_SUCCESS) {\n      LOG(WARNING) << \"Unexpected cuDNN status: \" << err << \": \" << cudnnGetErrorString(err);\n      continue;\n    }\n    auto workspace = GetAttr<int64_t>(plan, CUDNN_ATTR_EXECUTION_PLAN_WORKSPACE_SIZE);\n    if (workspace > workspace_limit)\n      continue;\n    auto numerical = GetSomeAttrs<cudnnBackendNumericalNote_t>(\n        CUDNN_NUMERICAL_NOTE_TYPE_COUNT, engine, CUDNN_ATTR_ENGINE_NUMERICAL_NOTE);\n    if (!IsCompatible(numerical, req_numeric, excl_numeric))\n      continue;\n#if CUDNN_VERSION >= 8200\n    auto behavior = GetSomeAttrs<cudnnBackendBehaviorNote_t>(\n        CUDNN_BEHAVIOR_NOTE_TYPE_COUNT, engine, CUDNN_ATTR_ENGINE_BEHAVIOR_NOTE);\n    if (!IsCompatible(behavior, req_behavior, excl_behavior))\n      continue;\n#endif  // CUDNN_VERSION >= 8200\n    plans.push_back(std::move(plan));\n    if (max_workspace)\n      *max_workspace = std::max(*max_workspace, static_cast<size_t>(workspace));\n  }\n  return plans;\n}\n\ncudnnBackendHeurMode_t HeurMode() {\n#if CUDNN_VERSION >= 8100\n  auto minor       = cudnnGetVersion() / 100 % 10;\n  int default_mode = minor < 2 ? CUDNN_HEUR_MODE_INSTANT : CUDNN_HEUR_MODE_B;\n#else\n  int default_mode = CUDNN_HEUR_MODE_INSTANT;\n#endif  // CUDNN_VERSION >= 8100\n  return static_cast<cudnnBackendHeurMode_t>(dmlc::GetEnv(\"MXNET_CUDNN_HEUR_MODE\", default_mode));",
    "repo_full_name": "apache/mxnet",
    "discussion_comments": [
      {
        "comment_id": "744069231",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20635,
        "pr_file": "src/operator/cudnn_ops.cc",
        "discussion_id": "744069231",
        "commented_code": "@@ -0,0 +1,765 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+/*!\n+ * Copyright (c) 2021 by Contributors\n+ * \\file  cudnn_ops.cc\n+ * \\brief cuDNN v8 ops\n+ */\n+\n+#include \"cudnn_ops.h\"\n+\n+#include <mxnet/base.h>\n+#if MXNET_USE_CUDNN == 1\n+\n+#include <dmlc/parameter.h>\n+\n+#include <algorithm>\n+#include <cstdlib>\n+#include <iomanip>\n+#include <iterator>\n+#include <limits>\n+#include <numeric>\n+#include <sstream>\n+#include <string>\n+#include <utility>\n+\n+namespace mxnet {\n+namespace op {\n+\n+using cudnn_cxx::Descriptor;\n+using cudnn_cxx::GetAttr;\n+using cudnn_cxx::GetSomeAttrs;\n+using cudnn_cxx::IsCompatible;\n+using cudnn_cxx::MakeAvgSampler;\n+using cudnn_cxx::MakeFinalized;\n+using cudnn_cxx::PackedStrides;\n+using cudnn_cxx::PlanStr;\n+\n+namespace cudnn {\n+\n+cudnnDataType_t CudnnType(mshadow::TypeFlag dtype) {\n+  static std::unordered_map<mshadow::TypeFlag, cudnnDataType_t> type_map {\n+    {mshadow::kFloat32, CUDNN_DATA_FLOAT}, {mshadow::kFloat64, CUDNN_DATA_DOUBLE},\n+        {mshadow::kFloat16, CUDNN_DATA_HALF}, {mshadow::kUint8, CUDNN_DATA_UINT8},\n+        {mshadow::kInt8, CUDNN_DATA_INT8}, {mshadow::kInt32, CUDNN_DATA_INT32},\n+#if CUDNN_VERSION >= 8100\n+        {mshadow::kInt64, CUDNN_DATA_INT64},\n+#endif  // CUDNN_VERSION >= 8100\n+  };\n+  auto it = type_map.find(dtype);\n+  CHECK(it != type_map.end()) << \"Unsupported type: \" << dtype;\n+  return it->second;\n+}\n+\n+std::vector<size_t> LayoutInfo::Order() const {\n+  std::vector<size_t> ret(n_space_dims + 2);\n+  std::iota(ret.begin(), ret.end(), 0);\n+  if (channel_last)\n+    std::rotate(ret.begin() + 1, ret.begin() + 2, ret.end());\n+  return ret;\n+}\n+\n+size_t LayoutInfo::ChannelIdx() const {\n+  return channel_last ? 1 + n_space_dims : 1;\n+}\n+\n+std::vector<int64_t> LayoutInfo::Strides(const std::vector<int64_t>& dims) const {\n+  return PackedStrides(Order(), dims);\n+}\n+\n+LayoutInfo GetLayoutInfo(mshadow::LayoutFlag layout) {\n+  static std::unordered_map<mshadow::LayoutFlag, LayoutInfo> layout_map{\n+      {mshadow::kNCW, {1, false}},\n+      {mshadow::kNWC, {1, true}},\n+      {mshadow::kNCHW, {2, false}},\n+      {mshadow::kNHWC, {2, true}},\n+      {mshadow::kNCDHW, {3, false}},\n+      {mshadow::kNDHWC, {3, true}},\n+  };\n+  auto it = layout_map.find(layout);\n+  CHECK(it != layout_map.end()) << \"Unsupported layout: \" << layout;\n+  return it->second;\n+}\n+\n+TShape ExpandChannelDims(mshadow::LayoutFlag layout, int c) {\n+  auto li = GetLayoutInfo(layout);\n+  std::vector<int> dims(li.n_space_dims + 2, 1);\n+  dims[li.ChannelIdx()] = c;\n+  return TShape(dims.begin(), dims.end());\n+}\n+\n+std::vector<size_t> ReverseOrder(const std::vector<size_t>& o) {\n+  std::vector<size_t> ret(o.size());\n+  for (size_t i = 0; i < ret.size(); ++i)\n+    ret[o[i]] = i;\n+  return ret;\n+}\n+\n+std::vector<cudnnBackendNumericalNote_t> RequireNumerics() {\n+  std::vector<cudnnBackendNumericalNote_t> ret;\n+  return ret;\n+}\n+\n+std::vector<cudnnBackendNumericalNote_t> ExcludeNumerics() {\n+  std::vector<cudnnBackendNumericalNote_t> ret;\n+  if (!dmlc::GetEnv(\"MXNET_CUDA_ALLOW_TENSOR_CORE\", true))\n+    ret.push_back(CUDNN_NUMERICAL_NOTE_TENSOR_CORE);\n+  if (!dmlc::GetEnv(\"MXNET_CUDA_TENSOR_OP_MATH_ALLOW_CONVERSION\", false))\n+    ret.push_back(CUDNN_NUMERICAL_NOTE_DOWN_CONVERT_INPUTS);\n+  if (!dmlc::GetEnv(\"MXNET_CUDNN_ALLOW_REDUCED_PRECISION_REDUCTION\", true))\n+    ret.push_back(CUDNN_NUMERICAL_NOTE_REDUCED_PRECISION_REDUCTION);\n+  if (!dmlc::GetEnv(\"MXNET_CUDNN_ALLOW_FFT\", true))\n+    ret.push_back(CUDNN_NUMERICAL_NOTE_FFT);\n+  if (dmlc::GetEnv(\"MXNET_ENFORCE_DETERMINISM\", false))\n+    ret.push_back(CUDNN_NUMERICAL_NOTE_NONDETERMINISTIC);\n+  if (!dmlc::GetEnv(\"MXNET_CUDNN_ALLOW_WINOGRAD\", true))\n+    ret.push_back(CUDNN_NUMERICAL_NOTE_WINOGRAD);\n+  return ret;\n+}\n+\n+Descriptor MakeTensorDesc(int64_t uid,\n+                          cudnnDataType_t dtype,\n+                          const std::vector<int64_t>& dims,\n+                          const std::vector<int64_t>& strides,\n+                          bool is_virtual) {\n+  int64_t alignment = 16;  // TODO(vcherepanov): ?\n+  return MakeFinalized(CUDNN_BACKEND_TENSOR_DESCRIPTOR,\n+                       CUDNN_ATTR_TENSOR_UNIQUE_ID,\n+                       uid,\n+                       CUDNN_ATTR_TENSOR_DATA_TYPE,\n+                       dtype,\n+                       CUDNN_ATTR_TENSOR_BYTE_ALIGNMENT,\n+                       alignment,\n+                       CUDNN_ATTR_TENSOR_DIMENSIONS,\n+                       dims,\n+                       CUDNN_ATTR_TENSOR_STRIDES,\n+                       strides,\n+                       CUDNN_ATTR_TENSOR_IS_VIRTUAL,\n+                       is_virtual);\n+}\n+\n+Descriptor MakeTensorDesc(int64_t uid,\n+                          const TBlob& blob,\n+                          const LayoutInfo& li,\n+                          bool expand_1d,\n+                          bool is_virtual) {\n+  std::vector<int64_t> dims(blob.shape_.ndim());\n+  CHECK_EQ(dims.size(), li.n_space_dims + 2);\n+  auto rev_order = ReverseOrder(li.Order());\n+  for (size_t i = 0; i < dims.size(); ++i)\n+    dims[i] = blob.shape_[rev_order[i]];\n+  auto strides = li.Strides(dims);\n+  if (li.n_space_dims == 1 && expand_1d) {\n+    dims.insert(dims.begin() + 2, 1);\n+    std::vector<size_t> order(dims.size());\n+    std::iota(order.begin(), order.end(), 0);\n+    if (li.channel_last)\n+      std::rotate(order.begin() + 1, order.begin() + 2, order.end());\n+    strides = PackedStrides(order, dims);\n+  }\n+  return MakeTensorDesc(\n+      uid, CudnnType(static_cast<mshadow::TypeFlag>(blob.type_flag_)), dims, strides, is_virtual);\n+}\n+\n+Descriptor MakeCTensorDescExpandDims(int64_t uid,\n+                                     const TBlob& b,\n+                                     const LayoutInfo& li,\n+                                     bool is_virtual) {\n+  std::vector<int64_t> dims(li.n_space_dims + 2, 1);\n+  dims[1]    = b.shape_[0];\n+  auto dtype = CudnnType(static_cast<mshadow::TypeFlag>(b.type_flag_));\n+  return MakeTensorDesc(uid, dtype, dims, li.Strides(dims), is_virtual);\n+}\n+\n+Descriptor MakeConvDesc(const ConvParam& param, mshadow::TypeFlag dtype) {\n+  int64_t sdims = param.kernel.ndim();\n+  std::vector<int64_t> stride(param.stride.begin(), param.stride.end());\n+  std::vector<int64_t> dilate(param.dilate.begin(), param.dilate.end());\n+  std::vector<int64_t> pad(param.pad.begin(), param.pad.end());\n+\n+  auto comp_type = CudnnType(dtype);\n+  if (comp_type == CUDNN_DATA_HALF)\n+    comp_type = CUDNN_DATA_FLOAT;\n+\n+  if (sdims == 1) {\n+    // TODO(vcherepanov): remove this once cuDNN properly supports 1D convolutions.\n+    // For now, making spacial dims 2D: 1 x W.\n+    ++sdims;\n+    stride.insert(stride.begin(), 1);\n+    dilate.insert(dilate.begin(), 1);\n+    pad.insert(pad.begin(), 0);\n+  }\n+  return MakeFinalized(CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR,\n+                       CUDNN_ATTR_CONVOLUTION_SPATIAL_DIMS,\n+                       sdims,\n+                       CUDNN_ATTR_CONVOLUTION_COMP_TYPE,\n+                       comp_type,\n+                       CUDNN_ATTR_CONVOLUTION_CONV_MODE,\n+                       CUDNN_CROSS_CORRELATION,\n+                       CUDNN_ATTR_CONVOLUTION_FILTER_STRIDES,\n+                       stride,\n+                       CUDNN_ATTR_CONVOLUTION_DILATIONS,\n+                       dilate,\n+                       CUDNN_ATTR_CONVOLUTION_PRE_PADDINGS,\n+                       pad,\n+                       CUDNN_ATTR_CONVOLUTION_POST_PADDINGS,\n+                       pad);\n+}\n+\n+Descriptor MakeConvFwdOp(const Descriptor& conv,\n+                         const Descriptor& x,\n+                         const Descriptor& w,\n+                         const Descriptor& y,\n+                         bool add_to) {\n+  auto ret = Make(CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_CONV_DESC,\n+                  conv,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_X,\n+                  x,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_W,\n+                  w,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_Y,\n+                  y);\n+  if (GetAttr<cudnnDataType_t>(x, CUDNN_ATTR_TENSOR_DATA_TYPE) == CUDNN_DATA_DOUBLE) {\n+    SetAttrs(ret,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_ALPHA,\n+             1.0,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_BETA,\n+             add_to ? 1.0 : 0.0);\n+  } else {\n+    SetAttrs(ret,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_ALPHA,\n+             1.0f,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_BETA,\n+             add_to ? 1.0f : 0.0f);\n+  }\n+  CUDNN_CALL(cudnnBackendFinalize(ret.get()));\n+  return ret;\n+}\n+\n+Descriptor MakeConvDgradOp(const Descriptor& conv,\n+                           const Descriptor& w,\n+                           const Descriptor& dy,\n+                           const Descriptor& dx,\n+                           bool add_to) {\n+  auto ret = Make(CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_CONV_DESC,\n+                  conv,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_W,\n+                  w,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_DY,\n+                  dy,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_DX,\n+                  dx);\n+  if (GetAttr<cudnnDataType_t>(w, CUDNN_ATTR_TENSOR_DATA_TYPE) == CUDNN_DATA_DOUBLE) {\n+    SetAttrs(ret,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_ALPHA,\n+             1.0,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_BETA,\n+             add_to ? 1.0 : 0.0);\n+  } else {\n+    SetAttrs(ret,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_ALPHA,\n+             1.0f,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_BETA,\n+             add_to ? 1.0f : 0.0f);\n+  }\n+  CUDNN_CALL(cudnnBackendFinalize(ret.get()));\n+  return ret;\n+}\n+\n+Descriptor MakeConvWgradOp(const Descriptor& conv,\n+                           const Descriptor& x,\n+                           const Descriptor& dy,\n+                           const Descriptor& dw,\n+                           bool add_to) {\n+  auto ret = Make(CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_CONV_DESC,\n+                  conv,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_X,\n+                  x,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_DY,\n+                  dy,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_DW,\n+                  dw);\n+  if (GetAttr<cudnnDataType_t>(x, CUDNN_ATTR_TENSOR_DATA_TYPE) == CUDNN_DATA_DOUBLE) {\n+    SetAttrs(ret,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_ALPHA,\n+             1.0,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_BETA,\n+             add_to ? 1.0 : 0.0);\n+  } else {\n+    SetAttrs(ret,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_ALPHA,\n+             1.0f,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_BETA,\n+             add_to ? 1.0f : 0.0f);\n+  }\n+  CUDNN_CALL(cudnnBackendFinalize(ret.get()));\n+  return ret;\n+}\n+\n+Descriptor MakeOpGraph(cudnnHandle_t handle, const std::vector<Descriptor>& ops) {\n+  return MakeFinalized(CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR,\n+                       CUDNN_ATTR_OPERATIONGRAPH_HANDLE,\n+                       handle,\n+                       CUDNN_ATTR_OPERATIONGRAPH_OPS,\n+                       ops);\n+}\n+\n+ConvParam::ConvParam(const ConvolutionParam& p, bool add_to)\n+    : kernel(p.kernel),\n+      stride(p.stride),\n+      dilate(p.dilate),\n+      pad(p.pad),\n+      num_filter(p.num_filter),\n+      num_group(p.num_group),\n+      workspace(p.workspace),\n+      cudnn_tune(p.cudnn_tune),\n+      layout(p.layout),\n+      add_to(add_to) {}\n+\n+ConvParam::ConvParam(const DeconvolutionParam& p, bool add_to)\n+    : kernel(p.kernel),\n+      stride(p.stride),\n+      dilate(p.dilate),\n+      pad(p.pad),\n+      num_filter(p.num_filter),\n+      num_group(p.num_group),\n+      workspace(p.workspace),\n+      cudnn_tune(p.cudnn_tune),\n+      layout(p.layout),\n+      add_to(add_to) {}\n+\n+void TuneWarnOnce() {\n+  thread_local bool done = false;\n+  if (!done) {\n+    LOG(INFO) << \"Auto-tuning cuDNN op, set MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable\";\n+    done = true;\n+  }\n+}\n+\n+std::vector<Descriptor> MakeFallbackPlans(\n+    const std::vector<int64_t>& ixs,\n+    cudnnHandle_t handle,\n+    const Descriptor& op_graph,\n+    size_t workspace_limit,\n+    size_t* max_workspace,\n+    const std::unordered_set<int64_t>& excl_engines,\n+    const std::vector<cudnnBackendNumericalNote_t>& req_numeric,\n+    const std::vector<cudnnBackendNumericalNote_t>& excl_numeric\n+#if CUDNN_VERSION >= 8200\n+    ,\n+    const std::vector<cudnnBackendBehaviorNote_t>& req_behavior,\n+    const std::vector<cudnnBackendBehaviorNote_t>& excl_behavior\n+#endif  // CUDNN_VERSION >= 8200\n+) {\n+  std::vector<Descriptor> plans;\n+  if (max_workspace)\n+    *max_workspace = 0;\n+  for (auto ix : ixs) {\n+    if (excl_engines.count(ix))\n+      continue;\n+    auto engine = Make(CUDNN_BACKEND_ENGINE_DESCRIPTOR,\n+                       CUDNN_ATTR_ENGINE_OPERATION_GRAPH,\n+                       op_graph,\n+                       CUDNN_ATTR_ENGINE_GLOBAL_INDEX,\n+                       ix);\n+    auto err    = cudnnBackendFinalize(engine.get());\n+    if (err == CUDNN_STATUS_NOT_SUPPORTED || err == CUDNN_STATUS_ARCH_MISMATCH)\n+      continue;\n+    if (err != CUDNN_STATUS_SUCCESS) {\n+      LOG(WARNING) << \"Unexpected cuDNN status: \" << err << \": \" << cudnnGetErrorString(err);\n+      continue;\n+    }\n+    auto cfg =\n+        MakeFinalized(CUDNN_BACKEND_ENGINECFG_DESCRIPTOR, CUDNN_ATTR_ENGINECFG_ENGINE, engine);\n+    auto plan = Make(CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR,\n+                     CUDNN_ATTR_EXECUTION_PLAN_HANDLE,\n+                     handle,\n+                     CUDNN_ATTR_EXECUTION_PLAN_ENGINE_CONFIG,\n+                     cfg);\n+    err       = cudnnBackendFinalize(plan.get());\n+    if (err == CUDNN_STATUS_NOT_SUPPORTED || err == CUDNN_STATUS_ARCH_MISMATCH)\n+      continue;\n+    if (err != CUDNN_STATUS_SUCCESS) {\n+      LOG(WARNING) << \"Unexpected cuDNN status: \" << err << \": \" << cudnnGetErrorString(err);\n+      continue;\n+    }\n+    auto workspace = GetAttr<int64_t>(plan, CUDNN_ATTR_EXECUTION_PLAN_WORKSPACE_SIZE);\n+    if (workspace > workspace_limit)\n+      continue;\n+    auto numerical = GetSomeAttrs<cudnnBackendNumericalNote_t>(\n+        CUDNN_NUMERICAL_NOTE_TYPE_COUNT, engine, CUDNN_ATTR_ENGINE_NUMERICAL_NOTE);\n+    if (!IsCompatible(numerical, req_numeric, excl_numeric))\n+      continue;\n+#if CUDNN_VERSION >= 8200\n+    auto behavior = GetSomeAttrs<cudnnBackendBehaviorNote_t>(\n+        CUDNN_BEHAVIOR_NOTE_TYPE_COUNT, engine, CUDNN_ATTR_ENGINE_BEHAVIOR_NOTE);\n+    if (!IsCompatible(behavior, req_behavior, excl_behavior))\n+      continue;\n+#endif  // CUDNN_VERSION >= 8200\n+    plans.push_back(std::move(plan));\n+    if (max_workspace)\n+      *max_workspace = std::max(*max_workspace, static_cast<size_t>(workspace));\n+  }\n+  return plans;\n+}\n+\n+cudnnBackendHeurMode_t HeurMode() {\n+#if CUDNN_VERSION >= 8100\n+  auto minor       = cudnnGetVersion() / 100 % 10;\n+  int default_mode = minor < 2 ? CUDNN_HEUR_MODE_INSTANT : CUDNN_HEUR_MODE_B;\n+#else\n+  int default_mode = CUDNN_HEUR_MODE_INSTANT;\n+#endif  // CUDNN_VERSION >= 8100\n+  return static_cast<cudnnBackendHeurMode_t>(dmlc::GetEnv(\"MXNET_CUDNN_HEUR_MODE\", default_mode));",
        "comment_created_at": "2021-11-06T03:30:04+00:00",
        "comment_author": "DickJC123",
        "comment_body": "Again, please add a description of MXNET_CUDNN_HEUR_MODE in the env_var.md file.\r\n\r\nI'm OK to leave it as an int tied to the cudnn.h definitions.  But technically, that ties constants that users will put in training scripts to those definitions, which could change I suppose.  An alternative would be for you to parse the env var as a string, e.g. if set via:\r\n```\r\nexport MXNET_CUDNN_HEUR_MODE=\"B\"\r\n```\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "745831518",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20635,
        "pr_file": "src/operator/cudnn_ops.cc",
        "discussion_id": "744069231",
        "commented_code": "@@ -0,0 +1,765 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+/*!\n+ * Copyright (c) 2021 by Contributors\n+ * \\file  cudnn_ops.cc\n+ * \\brief cuDNN v8 ops\n+ */\n+\n+#include \"cudnn_ops.h\"\n+\n+#include <mxnet/base.h>\n+#if MXNET_USE_CUDNN == 1\n+\n+#include <dmlc/parameter.h>\n+\n+#include <algorithm>\n+#include <cstdlib>\n+#include <iomanip>\n+#include <iterator>\n+#include <limits>\n+#include <numeric>\n+#include <sstream>\n+#include <string>\n+#include <utility>\n+\n+namespace mxnet {\n+namespace op {\n+\n+using cudnn_cxx::Descriptor;\n+using cudnn_cxx::GetAttr;\n+using cudnn_cxx::GetSomeAttrs;\n+using cudnn_cxx::IsCompatible;\n+using cudnn_cxx::MakeAvgSampler;\n+using cudnn_cxx::MakeFinalized;\n+using cudnn_cxx::PackedStrides;\n+using cudnn_cxx::PlanStr;\n+\n+namespace cudnn {\n+\n+cudnnDataType_t CudnnType(mshadow::TypeFlag dtype) {\n+  static std::unordered_map<mshadow::TypeFlag, cudnnDataType_t> type_map {\n+    {mshadow::kFloat32, CUDNN_DATA_FLOAT}, {mshadow::kFloat64, CUDNN_DATA_DOUBLE},\n+        {mshadow::kFloat16, CUDNN_DATA_HALF}, {mshadow::kUint8, CUDNN_DATA_UINT8},\n+        {mshadow::kInt8, CUDNN_DATA_INT8}, {mshadow::kInt32, CUDNN_DATA_INT32},\n+#if CUDNN_VERSION >= 8100\n+        {mshadow::kInt64, CUDNN_DATA_INT64},\n+#endif  // CUDNN_VERSION >= 8100\n+  };\n+  auto it = type_map.find(dtype);\n+  CHECK(it != type_map.end()) << \"Unsupported type: \" << dtype;\n+  return it->second;\n+}\n+\n+std::vector<size_t> LayoutInfo::Order() const {\n+  std::vector<size_t> ret(n_space_dims + 2);\n+  std::iota(ret.begin(), ret.end(), 0);\n+  if (channel_last)\n+    std::rotate(ret.begin() + 1, ret.begin() + 2, ret.end());\n+  return ret;\n+}\n+\n+size_t LayoutInfo::ChannelIdx() const {\n+  return channel_last ? 1 + n_space_dims : 1;\n+}\n+\n+std::vector<int64_t> LayoutInfo::Strides(const std::vector<int64_t>& dims) const {\n+  return PackedStrides(Order(), dims);\n+}\n+\n+LayoutInfo GetLayoutInfo(mshadow::LayoutFlag layout) {\n+  static std::unordered_map<mshadow::LayoutFlag, LayoutInfo> layout_map{\n+      {mshadow::kNCW, {1, false}},\n+      {mshadow::kNWC, {1, true}},\n+      {mshadow::kNCHW, {2, false}},\n+      {mshadow::kNHWC, {2, true}},\n+      {mshadow::kNCDHW, {3, false}},\n+      {mshadow::kNDHWC, {3, true}},\n+  };\n+  auto it = layout_map.find(layout);\n+  CHECK(it != layout_map.end()) << \"Unsupported layout: \" << layout;\n+  return it->second;\n+}\n+\n+TShape ExpandChannelDims(mshadow::LayoutFlag layout, int c) {\n+  auto li = GetLayoutInfo(layout);\n+  std::vector<int> dims(li.n_space_dims + 2, 1);\n+  dims[li.ChannelIdx()] = c;\n+  return TShape(dims.begin(), dims.end());\n+}\n+\n+std::vector<size_t> ReverseOrder(const std::vector<size_t>& o) {\n+  std::vector<size_t> ret(o.size());\n+  for (size_t i = 0; i < ret.size(); ++i)\n+    ret[o[i]] = i;\n+  return ret;\n+}\n+\n+std::vector<cudnnBackendNumericalNote_t> RequireNumerics() {\n+  std::vector<cudnnBackendNumericalNote_t> ret;\n+  return ret;\n+}\n+\n+std::vector<cudnnBackendNumericalNote_t> ExcludeNumerics() {\n+  std::vector<cudnnBackendNumericalNote_t> ret;\n+  if (!dmlc::GetEnv(\"MXNET_CUDA_ALLOW_TENSOR_CORE\", true))\n+    ret.push_back(CUDNN_NUMERICAL_NOTE_TENSOR_CORE);\n+  if (!dmlc::GetEnv(\"MXNET_CUDA_TENSOR_OP_MATH_ALLOW_CONVERSION\", false))\n+    ret.push_back(CUDNN_NUMERICAL_NOTE_DOWN_CONVERT_INPUTS);\n+  if (!dmlc::GetEnv(\"MXNET_CUDNN_ALLOW_REDUCED_PRECISION_REDUCTION\", true))\n+    ret.push_back(CUDNN_NUMERICAL_NOTE_REDUCED_PRECISION_REDUCTION);\n+  if (!dmlc::GetEnv(\"MXNET_CUDNN_ALLOW_FFT\", true))\n+    ret.push_back(CUDNN_NUMERICAL_NOTE_FFT);\n+  if (dmlc::GetEnv(\"MXNET_ENFORCE_DETERMINISM\", false))\n+    ret.push_back(CUDNN_NUMERICAL_NOTE_NONDETERMINISTIC);\n+  if (!dmlc::GetEnv(\"MXNET_CUDNN_ALLOW_WINOGRAD\", true))\n+    ret.push_back(CUDNN_NUMERICAL_NOTE_WINOGRAD);\n+  return ret;\n+}\n+\n+Descriptor MakeTensorDesc(int64_t uid,\n+                          cudnnDataType_t dtype,\n+                          const std::vector<int64_t>& dims,\n+                          const std::vector<int64_t>& strides,\n+                          bool is_virtual) {\n+  int64_t alignment = 16;  // TODO(vcherepanov): ?\n+  return MakeFinalized(CUDNN_BACKEND_TENSOR_DESCRIPTOR,\n+                       CUDNN_ATTR_TENSOR_UNIQUE_ID,\n+                       uid,\n+                       CUDNN_ATTR_TENSOR_DATA_TYPE,\n+                       dtype,\n+                       CUDNN_ATTR_TENSOR_BYTE_ALIGNMENT,\n+                       alignment,\n+                       CUDNN_ATTR_TENSOR_DIMENSIONS,\n+                       dims,\n+                       CUDNN_ATTR_TENSOR_STRIDES,\n+                       strides,\n+                       CUDNN_ATTR_TENSOR_IS_VIRTUAL,\n+                       is_virtual);\n+}\n+\n+Descriptor MakeTensorDesc(int64_t uid,\n+                          const TBlob& blob,\n+                          const LayoutInfo& li,\n+                          bool expand_1d,\n+                          bool is_virtual) {\n+  std::vector<int64_t> dims(blob.shape_.ndim());\n+  CHECK_EQ(dims.size(), li.n_space_dims + 2);\n+  auto rev_order = ReverseOrder(li.Order());\n+  for (size_t i = 0; i < dims.size(); ++i)\n+    dims[i] = blob.shape_[rev_order[i]];\n+  auto strides = li.Strides(dims);\n+  if (li.n_space_dims == 1 && expand_1d) {\n+    dims.insert(dims.begin() + 2, 1);\n+    std::vector<size_t> order(dims.size());\n+    std::iota(order.begin(), order.end(), 0);\n+    if (li.channel_last)\n+      std::rotate(order.begin() + 1, order.begin() + 2, order.end());\n+    strides = PackedStrides(order, dims);\n+  }\n+  return MakeTensorDesc(\n+      uid, CudnnType(static_cast<mshadow::TypeFlag>(blob.type_flag_)), dims, strides, is_virtual);\n+}\n+\n+Descriptor MakeCTensorDescExpandDims(int64_t uid,\n+                                     const TBlob& b,\n+                                     const LayoutInfo& li,\n+                                     bool is_virtual) {\n+  std::vector<int64_t> dims(li.n_space_dims + 2, 1);\n+  dims[1]    = b.shape_[0];\n+  auto dtype = CudnnType(static_cast<mshadow::TypeFlag>(b.type_flag_));\n+  return MakeTensorDesc(uid, dtype, dims, li.Strides(dims), is_virtual);\n+}\n+\n+Descriptor MakeConvDesc(const ConvParam& param, mshadow::TypeFlag dtype) {\n+  int64_t sdims = param.kernel.ndim();\n+  std::vector<int64_t> stride(param.stride.begin(), param.stride.end());\n+  std::vector<int64_t> dilate(param.dilate.begin(), param.dilate.end());\n+  std::vector<int64_t> pad(param.pad.begin(), param.pad.end());\n+\n+  auto comp_type = CudnnType(dtype);\n+  if (comp_type == CUDNN_DATA_HALF)\n+    comp_type = CUDNN_DATA_FLOAT;\n+\n+  if (sdims == 1) {\n+    // TODO(vcherepanov): remove this once cuDNN properly supports 1D convolutions.\n+    // For now, making spacial dims 2D: 1 x W.\n+    ++sdims;\n+    stride.insert(stride.begin(), 1);\n+    dilate.insert(dilate.begin(), 1);\n+    pad.insert(pad.begin(), 0);\n+  }\n+  return MakeFinalized(CUDNN_BACKEND_CONVOLUTION_DESCRIPTOR,\n+                       CUDNN_ATTR_CONVOLUTION_SPATIAL_DIMS,\n+                       sdims,\n+                       CUDNN_ATTR_CONVOLUTION_COMP_TYPE,\n+                       comp_type,\n+                       CUDNN_ATTR_CONVOLUTION_CONV_MODE,\n+                       CUDNN_CROSS_CORRELATION,\n+                       CUDNN_ATTR_CONVOLUTION_FILTER_STRIDES,\n+                       stride,\n+                       CUDNN_ATTR_CONVOLUTION_DILATIONS,\n+                       dilate,\n+                       CUDNN_ATTR_CONVOLUTION_PRE_PADDINGS,\n+                       pad,\n+                       CUDNN_ATTR_CONVOLUTION_POST_PADDINGS,\n+                       pad);\n+}\n+\n+Descriptor MakeConvFwdOp(const Descriptor& conv,\n+                         const Descriptor& x,\n+                         const Descriptor& w,\n+                         const Descriptor& y,\n+                         bool add_to) {\n+  auto ret = Make(CUDNN_BACKEND_OPERATION_CONVOLUTION_FORWARD_DESCRIPTOR,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_CONV_DESC,\n+                  conv,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_X,\n+                  x,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_W,\n+                  w,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_Y,\n+                  y);\n+  if (GetAttr<cudnnDataType_t>(x, CUDNN_ATTR_TENSOR_DATA_TYPE) == CUDNN_DATA_DOUBLE) {\n+    SetAttrs(ret,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_ALPHA,\n+             1.0,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_BETA,\n+             add_to ? 1.0 : 0.0);\n+  } else {\n+    SetAttrs(ret,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_ALPHA,\n+             1.0f,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_FORWARD_BETA,\n+             add_to ? 1.0f : 0.0f);\n+  }\n+  CUDNN_CALL(cudnnBackendFinalize(ret.get()));\n+  return ret;\n+}\n+\n+Descriptor MakeConvDgradOp(const Descriptor& conv,\n+                           const Descriptor& w,\n+                           const Descriptor& dy,\n+                           const Descriptor& dx,\n+                           bool add_to) {\n+  auto ret = Make(CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_DATA_DESCRIPTOR,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_CONV_DESC,\n+                  conv,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_W,\n+                  w,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_DY,\n+                  dy,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_DX,\n+                  dx);\n+  if (GetAttr<cudnnDataType_t>(w, CUDNN_ATTR_TENSOR_DATA_TYPE) == CUDNN_DATA_DOUBLE) {\n+    SetAttrs(ret,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_ALPHA,\n+             1.0,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_BETA,\n+             add_to ? 1.0 : 0.0);\n+  } else {\n+    SetAttrs(ret,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_ALPHA,\n+             1.0f,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_DATA_BETA,\n+             add_to ? 1.0f : 0.0f);\n+  }\n+  CUDNN_CALL(cudnnBackendFinalize(ret.get()));\n+  return ret;\n+}\n+\n+Descriptor MakeConvWgradOp(const Descriptor& conv,\n+                           const Descriptor& x,\n+                           const Descriptor& dy,\n+                           const Descriptor& dw,\n+                           bool add_to) {\n+  auto ret = Make(CUDNN_BACKEND_OPERATION_CONVOLUTION_BACKWARD_FILTER_DESCRIPTOR,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_CONV_DESC,\n+                  conv,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_X,\n+                  x,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_DY,\n+                  dy,\n+                  CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_DW,\n+                  dw);\n+  if (GetAttr<cudnnDataType_t>(x, CUDNN_ATTR_TENSOR_DATA_TYPE) == CUDNN_DATA_DOUBLE) {\n+    SetAttrs(ret,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_ALPHA,\n+             1.0,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_BETA,\n+             add_to ? 1.0 : 0.0);\n+  } else {\n+    SetAttrs(ret,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_ALPHA,\n+             1.0f,\n+             CUDNN_ATTR_OPERATION_CONVOLUTION_BWD_FILTER_BETA,\n+             add_to ? 1.0f : 0.0f);\n+  }\n+  CUDNN_CALL(cudnnBackendFinalize(ret.get()));\n+  return ret;\n+}\n+\n+Descriptor MakeOpGraph(cudnnHandle_t handle, const std::vector<Descriptor>& ops) {\n+  return MakeFinalized(CUDNN_BACKEND_OPERATIONGRAPH_DESCRIPTOR,\n+                       CUDNN_ATTR_OPERATIONGRAPH_HANDLE,\n+                       handle,\n+                       CUDNN_ATTR_OPERATIONGRAPH_OPS,\n+                       ops);\n+}\n+\n+ConvParam::ConvParam(const ConvolutionParam& p, bool add_to)\n+    : kernel(p.kernel),\n+      stride(p.stride),\n+      dilate(p.dilate),\n+      pad(p.pad),\n+      num_filter(p.num_filter),\n+      num_group(p.num_group),\n+      workspace(p.workspace),\n+      cudnn_tune(p.cudnn_tune),\n+      layout(p.layout),\n+      add_to(add_to) {}\n+\n+ConvParam::ConvParam(const DeconvolutionParam& p, bool add_to)\n+    : kernel(p.kernel),\n+      stride(p.stride),\n+      dilate(p.dilate),\n+      pad(p.pad),\n+      num_filter(p.num_filter),\n+      num_group(p.num_group),\n+      workspace(p.workspace),\n+      cudnn_tune(p.cudnn_tune),\n+      layout(p.layout),\n+      add_to(add_to) {}\n+\n+void TuneWarnOnce() {\n+  thread_local bool done = false;\n+  if (!done) {\n+    LOG(INFO) << \"Auto-tuning cuDNN op, set MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable\";\n+    done = true;\n+  }\n+}\n+\n+std::vector<Descriptor> MakeFallbackPlans(\n+    const std::vector<int64_t>& ixs,\n+    cudnnHandle_t handle,\n+    const Descriptor& op_graph,\n+    size_t workspace_limit,\n+    size_t* max_workspace,\n+    const std::unordered_set<int64_t>& excl_engines,\n+    const std::vector<cudnnBackendNumericalNote_t>& req_numeric,\n+    const std::vector<cudnnBackendNumericalNote_t>& excl_numeric\n+#if CUDNN_VERSION >= 8200\n+    ,\n+    const std::vector<cudnnBackendBehaviorNote_t>& req_behavior,\n+    const std::vector<cudnnBackendBehaviorNote_t>& excl_behavior\n+#endif  // CUDNN_VERSION >= 8200\n+) {\n+  std::vector<Descriptor> plans;\n+  if (max_workspace)\n+    *max_workspace = 0;\n+  for (auto ix : ixs) {\n+    if (excl_engines.count(ix))\n+      continue;\n+    auto engine = Make(CUDNN_BACKEND_ENGINE_DESCRIPTOR,\n+                       CUDNN_ATTR_ENGINE_OPERATION_GRAPH,\n+                       op_graph,\n+                       CUDNN_ATTR_ENGINE_GLOBAL_INDEX,\n+                       ix);\n+    auto err    = cudnnBackendFinalize(engine.get());\n+    if (err == CUDNN_STATUS_NOT_SUPPORTED || err == CUDNN_STATUS_ARCH_MISMATCH)\n+      continue;\n+    if (err != CUDNN_STATUS_SUCCESS) {\n+      LOG(WARNING) << \"Unexpected cuDNN status: \" << err << \": \" << cudnnGetErrorString(err);\n+      continue;\n+    }\n+    auto cfg =\n+        MakeFinalized(CUDNN_BACKEND_ENGINECFG_DESCRIPTOR, CUDNN_ATTR_ENGINECFG_ENGINE, engine);\n+    auto plan = Make(CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR,\n+                     CUDNN_ATTR_EXECUTION_PLAN_HANDLE,\n+                     handle,\n+                     CUDNN_ATTR_EXECUTION_PLAN_ENGINE_CONFIG,\n+                     cfg);\n+    err       = cudnnBackendFinalize(plan.get());\n+    if (err == CUDNN_STATUS_NOT_SUPPORTED || err == CUDNN_STATUS_ARCH_MISMATCH)\n+      continue;\n+    if (err != CUDNN_STATUS_SUCCESS) {\n+      LOG(WARNING) << \"Unexpected cuDNN status: \" << err << \": \" << cudnnGetErrorString(err);\n+      continue;\n+    }\n+    auto workspace = GetAttr<int64_t>(plan, CUDNN_ATTR_EXECUTION_PLAN_WORKSPACE_SIZE);\n+    if (workspace > workspace_limit)\n+      continue;\n+    auto numerical = GetSomeAttrs<cudnnBackendNumericalNote_t>(\n+        CUDNN_NUMERICAL_NOTE_TYPE_COUNT, engine, CUDNN_ATTR_ENGINE_NUMERICAL_NOTE);\n+    if (!IsCompatible(numerical, req_numeric, excl_numeric))\n+      continue;\n+#if CUDNN_VERSION >= 8200\n+    auto behavior = GetSomeAttrs<cudnnBackendBehaviorNote_t>(\n+        CUDNN_BEHAVIOR_NOTE_TYPE_COUNT, engine, CUDNN_ATTR_ENGINE_BEHAVIOR_NOTE);\n+    if (!IsCompatible(behavior, req_behavior, excl_behavior))\n+      continue;\n+#endif  // CUDNN_VERSION >= 8200\n+    plans.push_back(std::move(plan));\n+    if (max_workspace)\n+      *max_workspace = std::max(*max_workspace, static_cast<size_t>(workspace));\n+  }\n+  return plans;\n+}\n+\n+cudnnBackendHeurMode_t HeurMode() {\n+#if CUDNN_VERSION >= 8100\n+  auto minor       = cudnnGetVersion() / 100 % 10;\n+  int default_mode = minor < 2 ? CUDNN_HEUR_MODE_INSTANT : CUDNN_HEUR_MODE_B;\n+#else\n+  int default_mode = CUDNN_HEUR_MODE_INSTANT;\n+#endif  // CUDNN_VERSION >= 8100\n+  return static_cast<cudnnBackendHeurMode_t>(dmlc::GetEnv(\"MXNET_CUDNN_HEUR_MODE\", default_mode));",
        "comment_created_at": "2021-11-09T17:09:16+00:00",
        "comment_author": "DickJC123",
        "comment_body": "The conclusion here is that it's simpler to define this as integers that align with the current definition.  If future versions of cudnn*.h invalidate this, we can choose to insert a remapping function at that time if we feel it's important to maintain backward compatibility.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "664135001",
    "pr_number": 20331,
    "pr_file": "src/engine/threaded_engine.cc",
    "created_at": "2021-07-05T21:43:39+00:00",
    "commented_code": "OprBlock::Delete(opr_block);\n}\n\nvoid ThreadedEngine::OnStartStatic(Engine *engine, void *opr_block,\n                                   const dmlc::Error* error) {\n  // no-op\n}\n\n#if MXNET_USE_CUDA\nstatic inline void AddEventHelper(\n  std::unordered_map<cudaStream_t, EventInfo>* events_per_stream,\n  const EventInfo& cuda_event) {\n  auto event_stream = cuda_event.stream;\n  if (events_per_stream->count(event_stream) > 0) {\n    if ((*events_per_stream)[event_stream].pool_index < cuda_event.pool_index) {\n      (*events_per_stream)[event_stream] = cuda_event;\n    }\n  } else {\n    (*events_per_stream).emplace(event_stream, cuda_event);\n  }\n}\n\nvoid ThreadedEngine::OnStartCPU(Engine *engine, void *opr_block,\n                        const dmlc::Error* error) {\n  static bool use_new_dep_engine = dmlc::GetEnv(\"MXNET_ASYNC_GPU_ENGINE\", false);",
    "repo_full_name": "apache/mxnet",
    "discussion_comments": [
      {
        "comment_id": "664135001",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20331,
        "pr_file": "src/engine/threaded_engine.cc",
        "discussion_id": "664135001",
        "commented_code": "@@ -523,5 +543,206 @@ void ThreadedEngine::OnCompleteStatic(Engine *engine, void *opr_block_,\n   OprBlock::Delete(opr_block);\n }\n \n+void ThreadedEngine::OnStartStatic(Engine *engine, void *opr_block,\n+                                   const dmlc::Error* error) {\n+  // no-op\n+}\n+\n+#if MXNET_USE_CUDA\n+static inline void AddEventHelper(\n+  std::unordered_map<cudaStream_t, EventInfo>* events_per_stream,\n+  const EventInfo& cuda_event) {\n+  auto event_stream = cuda_event.stream;\n+  if (events_per_stream->count(event_stream) > 0) {\n+    if ((*events_per_stream)[event_stream].pool_index < cuda_event.pool_index) {\n+      (*events_per_stream)[event_stream] = cuda_event;\n+    }\n+  } else {\n+    (*events_per_stream).emplace(event_stream, cuda_event);\n+  }\n+}\n+\n+void ThreadedEngine::OnStartCPU(Engine *engine, void *opr_block,\n+                        const dmlc::Error* error) {\n+  static bool use_new_dep_engine = dmlc::GetEnv(\"MXNET_ASYNC_GPU_ENGINE\", false);",
        "comment_created_at": "2021-07-05T21:43:39+00:00",
        "comment_author": "szha",
        "comment_body": "We already have `MXNET_ENGINE_TYPE` which decides whether `NaiveEngine` (i.e. synchronous scheduler) is used, so unless there's a strong reason I'd prefer not to introduce new environment variables here.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "670376928",
    "pr_number": 20450,
    "pr_file": "src/operator/nn/mkldnn/mkldnn_base-inl.h",
    "created_at": "2021-07-15T11:29:29+00:00",
    "commented_code": "for (size_t i = 0; i < dims.size(); i++) dims[i] = arr.shape()[i];\n  auto format = mkldnn::memory::format_tag::any;\n  // for batch 256 alexnet benchmark test\n  if (dims.size() == 2) {\n  const bool brgemm_disabled = dmlc::GetEnv(\"MXNET_DISABLE_ONEDNN_BRGEMM_FC\", true);",
    "repo_full_name": "apache/mxnet",
    "discussion_comments": [
      {
        "comment_id": "670376928",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20450,
        "pr_file": "src/operator/nn/mkldnn/mkldnn_base-inl.h",
        "discussion_id": "670376928",
        "commented_code": "@@ -312,7 +312,8 @@ inline static mkldnn::memory::desc GetFCWeightDesc(const NDArray &arr, int dtype\n   for (size_t i = 0; i < dims.size(); i++) dims[i] = arr.shape()[i];\n   auto format = mkldnn::memory::format_tag::any;\n   // for batch 256 alexnet benchmark test\n-  if (dims.size() == 2) {\n+  const bool brgemm_disabled = dmlc::GetEnv(\"MXNET_DISABLE_ONEDNN_BRGEMM_FC\", true);",
        "comment_created_at": "2021-07-15T11:29:29+00:00",
        "comment_author": "anko-intel",
        "comment_body": "It will be good to add description to docs/static_site/src/pages/api/faq/env_var.md\r\nAlso I am not sure if for 1.x branch the name have to include ONEDNN ?\r\nso maybe MXNET_MKLDNN_DISABLE_BRGEMM_FC",
        "pr_file_module": null
      }
    ]
  }
]
