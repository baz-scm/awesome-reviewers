---
title: Graph traversal optimization
description: 'When working with graph structures, avoid performing redundant depth-first
  search (DFS) traversals as each traversal incurs an O(V+E) complexity cost. Instead,
  consider:'
repository: apache/mxnet
label: Algorithms
language: Other
comments_count: 4
repository_stars: 20801
---

When working with graph structures, avoid performing redundant depth-first search (DFS) traversals as each traversal incurs an O(V+E) complexity cost. Instead, consider:

1. **Label nodes during initial traversal** to maintain state information for subsequent operations
2. **Cache traversal order** to avoid repeating the same path exploration
3. **Batch related operations** that can be performed in a single pass
4. **Create graph copies** when modifications might affect future traversals

For example, instead of:

```cpp
// Multiple independent DFS calls on the same graph structure
for (auto pattern : patterns) {
  DFSVisit(sym.outputs, [&](const nnvm::ObjectPtr &node) {
    if (node->is_variable()) return;
    // Find nodes matching pattern
  });
}
```

Consider:

```cpp
// Single traversal with collected state
std::vector<nnvm::ObjectPtr> traversal_order;
std::unordered_map<nnvm::ObjectPtr, int> node_labels;

DFSVisit(sym.outputs, [&](const nnvm::ObjectPtr &node) {
  if (node->is_variable()) return;
  traversal_order.push_back(node);
  // Label nodes as needed
});

// Now use cached traversal for pattern matching without repeating DFS
for (auto pattern : patterns) {
  for (const auto& node : traversal_order) {
    // Match against patterns
  }
}
```

This approach significantly reduces computational complexity when multiple operations or pattern matching need to be performed on the same graph structure.


[
  {
    "discussion_id": "664297807",
    "pr_number": 20400,
    "pr_file": "src/operator/subgraph/mkldnn/mkldnn_fc_sum_fuse.h",
    "created_at": "2021-07-06T07:19:38+00:00",
    "commented_code": "/*\n * Licensed to the Apache Software Foundation (ASF) under one\n * or more contributor license agreements.  See the NOTICE file\n * distributed with this work for additional information\n * regarding copyright ownership.  The ASF licenses this file\n * to you under the Apache License, Version 2.0 (the\n * \"License\"); you may not use this file except in compliance\n * with the License.  You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing,\n * software distributed under the License is distributed on an\n * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n * KIND, either express or implied.  See the License for the\n * specific language governing permissions and limitations\n * under the License.\n */\n\n/*\n  \\brief It fuses FC + SUM for floating point output in second post quantization pass\n*/\n\n#ifndef MXNET_OPERATOR_SUBGRAPH_MKLDNN_MKLDNN_FC_SUM_FUSE_H_\n#define MXNET_OPERATOR_SUBGRAPH_MKLDNN_MKLDNN_FC_SUM_FUSE_H_\n#if MXNET_USE_MKLDNN == 1\n\n#include <string>\n#include <vector>\n#include <memory>\n#include <unordered_set>\n#include <utility>\n#include \"../common.h\"\n#include \"../../tensor/matrix_op-inl.h\"\n#include \"mkldnn_subgraph_base-inl.h\"\n#include \"mkldnn_fc-inl.h\"\n\nnamespace mxnet {\nnamespace op {\n\nclass SgMKLDNNFCSumFuseSelector : public SubgraphSelector {\n public:\n  /*! \\brief pattern match status */\n  enum SelectStatus {\n    kFail = 0,\n    kStart,\n    kSuccess,\n  };\n\n private:\n  bool quantized_;\n  SelectStatus status_;\n  std::vector<const nnvm::Node *> matched_list_;\n\n public:\n  explicit SgMKLDNNFCSumFuseSelector(bool quantized) :\n      quantized_(quantized) {}\n\n  bool Select(const nnvm::Node &n, const std::shared_ptr<NodeAttr>& node_attr) override {\n    if (n.op() == Op::Get(\"_sg_mkldnn_fully_connected\") && SupportMKLDNNAttr(node_attr)) {\n      auto const &fc_param = nnvm::get<MKLDNNFCFullParam>(n.attrs.parsed);\n      // TODO(anko) remove fc_param.mkldnn_param.quantized from if below\n      //            to fuse even for not quantized?\n      if (fc_param.mkldnn_param.enable_float_output && fc_param.mkldnn_param.quantized) {\n        status_ = kStart;\n        matched_list_.clear();\n        matched_list_.push_back(&n);\n        return true;\n      }\n    }\n    return false;\n  }\n\n  bool SelectInput(const nnvm::Node &n, const nnvm::Node &new_node) override {\n    return false;\n  }\n\n  bool SelectOutput(const nnvm::Node &n, const nnvm::Node &new_node) override {\n    if (status_ == kFail || status_ == kSuccess || new_node.is_variable())\n      return false;\n    // If n isn't the last matched node, then we encoutered a internal\n    // branch, we should pop out the node behind n and stop fusion.\n    if (matched_list_.back() != &n) {\n      if (std::find(matched_list_.begin(), matched_list_.end(), &n) !=\n        matched_list_.end()) {\n        while (matched_list_.back() != &n) {\n          matched_list_.pop_back();\n        }\n      }\n      status_ = kSuccess;\n      return false;\n    }\n\n    switch (status_) {\n      case kStart:\n        if (new_node.op()->name == \"elemwise_add\") {\n          matched_list_.push_back(&new_node);\n          status_ = kSuccess;\n          return true;\n        }\n      default:\n        status_ = kSuccess;\n        return false;\n    }\n  }\n\n  std::vector<nnvm::Node *> Filter(\n      const std::vector<nnvm::Node *> &candidates) override {\n    if (status_ == kFail) {\n      return std::vector<nnvm::Node *>(0);\n    } else {\n      std::vector<nnvm::Node *> ret;\n      for (auto i : matched_list_) {\n        auto non_const_i = const_cast<nnvm::Node *>(i);\n        if (std::find(candidates.begin(), candidates.end(), non_const_i) !=\n            candidates.end()) {\n          ret.push_back(non_const_i);\n        }\n      }\n      return candidates;\n    }\n  }\n\n  void Reset() override {\n    CHECK_GE(matched_list_.size(), 1);\n    auto new_selector = SgMKLDNNFCSumFuseSelector(quantized_);\n    new_selector.Select(*matched_list_[0], nullptr);\n    *this = new_selector;\n  }\n};\n\nclass SgMKLDNNFCSumFuseProperty : public SubgraphProperty {\n public:\n  SgMKLDNNFCSumFuseProperty() {}\n\n  static SubgraphPropertyPtr Create() {\n    static const std::string &name = \"MKLDNN FullyConnected post quantization second pass\";\n    auto property = std::make_shared<SgMKLDNNFCSumFuseProperty>();\n    property->SetAttr<std::string>(\"property_name\", name);\n    property->SetAttr<bool>(\"inference_only\", true);\n    if (dmlc::GetEnv(\"MXNET_DISABLE_MKLDNN_FC_SUM\", 0)) {\n      property->SetAttr<bool>(\"disable\", true);\n    }\n    return property;\n  }\n\n  nnvm::ObjectPtr CreateSubgraphNode(const nnvm::Symbol &sym,\n                                   const int subgraph_id = 0) const override {\n    nnvm::ObjectPtr fc_node = nullptr;\n    nnvm::ObjectPtr ew_add_node = nullptr;\n\n    DFSVisit(sym.outputs, [&](const nnvm::ObjectPtr &node) {\n      if (node->is_variable()) return;\n      auto &sub_name = node->op()->name;\n      if (sub_name == \"_sg_mkldnn_fully_connected\") {\n        fc_node = node;\n      } else if (sub_name == \"elemwise_add\") {\n        ew_add_node = node;\n      }\n    });\n\n    CHECK_NOTNULL(fc_node);\n    if (ew_add_node != nullptr) {\n      CHECK_NOTNULL(fc_node->attrs.subgraphs[0]);\n      auto fc_orginal = fc_node->attrs.subgraphs[0]->outputs[0].node;\n      if (fc_orginal->op() == Op::Get(\"FullyConnected\")) {\n        nnvm::Symbol new_sym;\n        nnvm::NodeEntry &ew_input_with_fc = (ew_add_node->inputs[1].node == fc_node) ?\n                                        ew_add_node->inputs[1] :\n                                        ew_add_node->inputs[0];\n        ew_input_with_fc.node = fc_orginal;\n        new_sym.outputs.emplace_back(ew_add_node);\n        fc_node->attrs.subgraphs.clear();\n        fc_node->attrs.subgraphs.emplace_back(std::make_shared<nnvm::Symbol>(new_sym));\n        fc_node->attrs.dict[\"with_sum\"] = \"True\";\n        fc_node->op()->attr_parser(&(fc_node->attrs));\n      }\n    }\n    return fc_node;\n  }\n\n  SubgraphSelectorPtr CreateSubgraphSelector() const override {\n    bool quantized = HasAttr(\"quantize\") ? GetAttr<bool>(\"quantize\") : false;\n    auto selector =\n      std::make_shared<SgMKLDNNFCSumFuseSelector>(quantized);\n    return selector;\n  }\n\n  void ConnectSubgraphOutputs(\n      const nnvm::ObjectPtr n,\n      std::vector<nnvm::NodeEntry *> *output_entries) const override {\n    // Connect all extern output entries to output[0]\n    for (size_t i = 0; i < output_entries->size(); ++i) {\n      auto entry_ptr = output_entries->at(i);\n      *entry_ptr = nnvm::NodeEntry{n, entry_ptr->index, 0};\n    }\n  }\n\n  void ConnectSubgraphInputs(\n      const nnvm::ObjectPtr n, std::vector<nnvm::NodeEntry *> *input_entries,\n      std::vector<nnvm::NodeEntry> *orig_input_entries) const override {\n    auto sym = n->attrs.subgraphs[0];\n    auto const &fc_param = nnvm::get<MKLDNNFCFullParam>(n->attrs.parsed);\n    std::unordered_set<const nnvm::Node *> node_sets;\n    DFSVisit(sym->outputs, [&](const nnvm::ObjectPtr &node) {",
    "repo_full_name": "apache/mxnet",
    "discussion_comments": [
      {
        "comment_id": "664297807",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20400,
        "pr_file": "src/operator/subgraph/mkldnn/mkldnn_fc_sum_fuse.h",
        "discussion_id": "664297807",
        "commented_code": "@@ -0,0 +1,240 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+/*\n+  \\brief It fuses FC + SUM for floating point output in second post quantization pass\n+*/\n+\n+#ifndef MXNET_OPERATOR_SUBGRAPH_MKLDNN_MKLDNN_FC_SUM_FUSE_H_\n+#define MXNET_OPERATOR_SUBGRAPH_MKLDNN_MKLDNN_FC_SUM_FUSE_H_\n+#if MXNET_USE_MKLDNN == 1\n+\n+#include <string>\n+#include <vector>\n+#include <memory>\n+#include <unordered_set>\n+#include <utility>\n+#include \"../common.h\"\n+#include \"../../tensor/matrix_op-inl.h\"\n+#include \"mkldnn_subgraph_base-inl.h\"\n+#include \"mkldnn_fc-inl.h\"\n+\n+namespace mxnet {\n+namespace op {\n+\n+class SgMKLDNNFCSumFuseSelector : public SubgraphSelector {\n+ public:\n+  /*! \\brief pattern match status */\n+  enum SelectStatus {\n+    kFail = 0,\n+    kStart,\n+    kSuccess,\n+  };\n+\n+ private:\n+  bool quantized_;\n+  SelectStatus status_;\n+  std::vector<const nnvm::Node *> matched_list_;\n+\n+ public:\n+  explicit SgMKLDNNFCSumFuseSelector(bool quantized) :\n+      quantized_(quantized) {}\n+\n+  bool Select(const nnvm::Node &n, const std::shared_ptr<NodeAttr>& node_attr) override {\n+    if (n.op() == Op::Get(\"_sg_mkldnn_fully_connected\") && SupportMKLDNNAttr(node_attr)) {\n+      auto const &fc_param = nnvm::get<MKLDNNFCFullParam>(n.attrs.parsed);\n+      // TODO(anko) remove fc_param.mkldnn_param.quantized from if below\n+      //            to fuse even for not quantized?\n+      if (fc_param.mkldnn_param.enable_float_output && fc_param.mkldnn_param.quantized) {\n+        status_ = kStart;\n+        matched_list_.clear();\n+        matched_list_.push_back(&n);\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  bool SelectInput(const nnvm::Node &n, const nnvm::Node &new_node) override {\n+    return false;\n+  }\n+\n+  bool SelectOutput(const nnvm::Node &n, const nnvm::Node &new_node) override {\n+    if (status_ == kFail || status_ == kSuccess || new_node.is_variable())\n+      return false;\n+    // If n isn't the last matched node, then we encoutered a internal\n+    // branch, we should pop out the node behind n and stop fusion.\n+    if (matched_list_.back() != &n) {\n+      if (std::find(matched_list_.begin(), matched_list_.end(), &n) !=\n+        matched_list_.end()) {\n+        while (matched_list_.back() != &n) {\n+          matched_list_.pop_back();\n+        }\n+      }\n+      status_ = kSuccess;\n+      return false;\n+    }\n+\n+    switch (status_) {\n+      case kStart:\n+        if (new_node.op()->name == \"elemwise_add\") {\n+          matched_list_.push_back(&new_node);\n+          status_ = kSuccess;\n+          return true;\n+        }\n+      default:\n+        status_ = kSuccess;\n+        return false;\n+    }\n+  }\n+\n+  std::vector<nnvm::Node *> Filter(\n+      const std::vector<nnvm::Node *> &candidates) override {\n+    if (status_ == kFail) {\n+      return std::vector<nnvm::Node *>(0);\n+    } else {\n+      std::vector<nnvm::Node *> ret;\n+      for (auto i : matched_list_) {\n+        auto non_const_i = const_cast<nnvm::Node *>(i);\n+        if (std::find(candidates.begin(), candidates.end(), non_const_i) !=\n+            candidates.end()) {\n+          ret.push_back(non_const_i);\n+        }\n+      }\n+      return candidates;\n+    }\n+  }\n+\n+  void Reset() override {\n+    CHECK_GE(matched_list_.size(), 1);\n+    auto new_selector = SgMKLDNNFCSumFuseSelector(quantized_);\n+    new_selector.Select(*matched_list_[0], nullptr);\n+    *this = new_selector;\n+  }\n+};\n+\n+class SgMKLDNNFCSumFuseProperty : public SubgraphProperty {\n+ public:\n+  SgMKLDNNFCSumFuseProperty() {}\n+\n+  static SubgraphPropertyPtr Create() {\n+    static const std::string &name = \"MKLDNN FullyConnected post quantization second pass\";\n+    auto property = std::make_shared<SgMKLDNNFCSumFuseProperty>();\n+    property->SetAttr<std::string>(\"property_name\", name);\n+    property->SetAttr<bool>(\"inference_only\", true);\n+    if (dmlc::GetEnv(\"MXNET_DISABLE_MKLDNN_FC_SUM\", 0)) {\n+      property->SetAttr<bool>(\"disable\", true);\n+    }\n+    return property;\n+  }\n+\n+  nnvm::ObjectPtr CreateSubgraphNode(const nnvm::Symbol &sym,\n+                                   const int subgraph_id = 0) const override {\n+    nnvm::ObjectPtr fc_node = nullptr;\n+    nnvm::ObjectPtr ew_add_node = nullptr;\n+\n+    DFSVisit(sym.outputs, [&](const nnvm::ObjectPtr &node) {\n+      if (node->is_variable()) return;\n+      auto &sub_name = node->op()->name;\n+      if (sub_name == \"_sg_mkldnn_fully_connected\") {\n+        fc_node = node;\n+      } else if (sub_name == \"elemwise_add\") {\n+        ew_add_node = node;\n+      }\n+    });\n+\n+    CHECK_NOTNULL(fc_node);\n+    if (ew_add_node != nullptr) {\n+      CHECK_NOTNULL(fc_node->attrs.subgraphs[0]);\n+      auto fc_orginal = fc_node->attrs.subgraphs[0]->outputs[0].node;\n+      if (fc_orginal->op() == Op::Get(\"FullyConnected\")) {\n+        nnvm::Symbol new_sym;\n+        nnvm::NodeEntry &ew_input_with_fc = (ew_add_node->inputs[1].node == fc_node) ?\n+                                        ew_add_node->inputs[1] :\n+                                        ew_add_node->inputs[0];\n+        ew_input_with_fc.node = fc_orginal;\n+        new_sym.outputs.emplace_back(ew_add_node);\n+        fc_node->attrs.subgraphs.clear();\n+        fc_node->attrs.subgraphs.emplace_back(std::make_shared<nnvm::Symbol>(new_sym));\n+        fc_node->attrs.dict[\"with_sum\"] = \"True\";\n+        fc_node->op()->attr_parser(&(fc_node->attrs));\n+      }\n+    }\n+    return fc_node;\n+  }\n+\n+  SubgraphSelectorPtr CreateSubgraphSelector() const override {\n+    bool quantized = HasAttr(\"quantize\") ? GetAttr<bool>(\"quantize\") : false;\n+    auto selector =\n+      std::make_shared<SgMKLDNNFCSumFuseSelector>(quantized);\n+    return selector;\n+  }\n+\n+  void ConnectSubgraphOutputs(\n+      const nnvm::ObjectPtr n,\n+      std::vector<nnvm::NodeEntry *> *output_entries) const override {\n+    // Connect all extern output entries to output[0]\n+    for (size_t i = 0; i < output_entries->size(); ++i) {\n+      auto entry_ptr = output_entries->at(i);\n+      *entry_ptr = nnvm::NodeEntry{n, entry_ptr->index, 0};\n+    }\n+  }\n+\n+  void ConnectSubgraphInputs(\n+      const nnvm::ObjectPtr n, std::vector<nnvm::NodeEntry *> *input_entries,\n+      std::vector<nnvm::NodeEntry> *orig_input_entries) const override {\n+    auto sym = n->attrs.subgraphs[0];\n+    auto const &fc_param = nnvm::get<MKLDNNFCFullParam>(n->attrs.parsed);\n+    std::unordered_set<const nnvm::Node *> node_sets;\n+    DFSVisit(sym->outputs, [&](const nnvm::ObjectPtr &node) {",
        "comment_created_at": "2021-07-06T07:19:38+00:00",
        "comment_author": "mozga-intel",
        "comment_body": "Could you please tell me whether there is possible to prevent calling DFS multiple time (for every pattern)?",
        "pr_file_module": null
      },
      {
        "comment_id": "664386233",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20400,
        "pr_file": "src/operator/subgraph/mkldnn/mkldnn_fc_sum_fuse.h",
        "discussion_id": "664297807",
        "commented_code": "@@ -0,0 +1,240 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+/*\n+  \\brief It fuses FC + SUM for floating point output in second post quantization pass\n+*/\n+\n+#ifndef MXNET_OPERATOR_SUBGRAPH_MKLDNN_MKLDNN_FC_SUM_FUSE_H_\n+#define MXNET_OPERATOR_SUBGRAPH_MKLDNN_MKLDNN_FC_SUM_FUSE_H_\n+#if MXNET_USE_MKLDNN == 1\n+\n+#include <string>\n+#include <vector>\n+#include <memory>\n+#include <unordered_set>\n+#include <utility>\n+#include \"../common.h\"\n+#include \"../../tensor/matrix_op-inl.h\"\n+#include \"mkldnn_subgraph_base-inl.h\"\n+#include \"mkldnn_fc-inl.h\"\n+\n+namespace mxnet {\n+namespace op {\n+\n+class SgMKLDNNFCSumFuseSelector : public SubgraphSelector {\n+ public:\n+  /*! \\brief pattern match status */\n+  enum SelectStatus {\n+    kFail = 0,\n+    kStart,\n+    kSuccess,\n+  };\n+\n+ private:\n+  bool quantized_;\n+  SelectStatus status_;\n+  std::vector<const nnvm::Node *> matched_list_;\n+\n+ public:\n+  explicit SgMKLDNNFCSumFuseSelector(bool quantized) :\n+      quantized_(quantized) {}\n+\n+  bool Select(const nnvm::Node &n, const std::shared_ptr<NodeAttr>& node_attr) override {\n+    if (n.op() == Op::Get(\"_sg_mkldnn_fully_connected\") && SupportMKLDNNAttr(node_attr)) {\n+      auto const &fc_param = nnvm::get<MKLDNNFCFullParam>(n.attrs.parsed);\n+      // TODO(anko) remove fc_param.mkldnn_param.quantized from if below\n+      //            to fuse even for not quantized?\n+      if (fc_param.mkldnn_param.enable_float_output && fc_param.mkldnn_param.quantized) {\n+        status_ = kStart;\n+        matched_list_.clear();\n+        matched_list_.push_back(&n);\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  bool SelectInput(const nnvm::Node &n, const nnvm::Node &new_node) override {\n+    return false;\n+  }\n+\n+  bool SelectOutput(const nnvm::Node &n, const nnvm::Node &new_node) override {\n+    if (status_ == kFail || status_ == kSuccess || new_node.is_variable())\n+      return false;\n+    // If n isn't the last matched node, then we encoutered a internal\n+    // branch, we should pop out the node behind n and stop fusion.\n+    if (matched_list_.back() != &n) {\n+      if (std::find(matched_list_.begin(), matched_list_.end(), &n) !=\n+        matched_list_.end()) {\n+        while (matched_list_.back() != &n) {\n+          matched_list_.pop_back();\n+        }\n+      }\n+      status_ = kSuccess;\n+      return false;\n+    }\n+\n+    switch (status_) {\n+      case kStart:\n+        if (new_node.op()->name == \"elemwise_add\") {\n+          matched_list_.push_back(&new_node);\n+          status_ = kSuccess;\n+          return true;\n+        }\n+      default:\n+        status_ = kSuccess;\n+        return false;\n+    }\n+  }\n+\n+  std::vector<nnvm::Node *> Filter(\n+      const std::vector<nnvm::Node *> &candidates) override {\n+    if (status_ == kFail) {\n+      return std::vector<nnvm::Node *>(0);\n+    } else {\n+      std::vector<nnvm::Node *> ret;\n+      for (auto i : matched_list_) {\n+        auto non_const_i = const_cast<nnvm::Node *>(i);\n+        if (std::find(candidates.begin(), candidates.end(), non_const_i) !=\n+            candidates.end()) {\n+          ret.push_back(non_const_i);\n+        }\n+      }\n+      return candidates;\n+    }\n+  }\n+\n+  void Reset() override {\n+    CHECK_GE(matched_list_.size(), 1);\n+    auto new_selector = SgMKLDNNFCSumFuseSelector(quantized_);\n+    new_selector.Select(*matched_list_[0], nullptr);\n+    *this = new_selector;\n+  }\n+};\n+\n+class SgMKLDNNFCSumFuseProperty : public SubgraphProperty {\n+ public:\n+  SgMKLDNNFCSumFuseProperty() {}\n+\n+  static SubgraphPropertyPtr Create() {\n+    static const std::string &name = \"MKLDNN FullyConnected post quantization second pass\";\n+    auto property = std::make_shared<SgMKLDNNFCSumFuseProperty>();\n+    property->SetAttr<std::string>(\"property_name\", name);\n+    property->SetAttr<bool>(\"inference_only\", true);\n+    if (dmlc::GetEnv(\"MXNET_DISABLE_MKLDNN_FC_SUM\", 0)) {\n+      property->SetAttr<bool>(\"disable\", true);\n+    }\n+    return property;\n+  }\n+\n+  nnvm::ObjectPtr CreateSubgraphNode(const nnvm::Symbol &sym,\n+                                   const int subgraph_id = 0) const override {\n+    nnvm::ObjectPtr fc_node = nullptr;\n+    nnvm::ObjectPtr ew_add_node = nullptr;\n+\n+    DFSVisit(sym.outputs, [&](const nnvm::ObjectPtr &node) {\n+      if (node->is_variable()) return;\n+      auto &sub_name = node->op()->name;\n+      if (sub_name == \"_sg_mkldnn_fully_connected\") {\n+        fc_node = node;\n+      } else if (sub_name == \"elemwise_add\") {\n+        ew_add_node = node;\n+      }\n+    });\n+\n+    CHECK_NOTNULL(fc_node);\n+    if (ew_add_node != nullptr) {\n+      CHECK_NOTNULL(fc_node->attrs.subgraphs[0]);\n+      auto fc_orginal = fc_node->attrs.subgraphs[0]->outputs[0].node;\n+      if (fc_orginal->op() == Op::Get(\"FullyConnected\")) {\n+        nnvm::Symbol new_sym;\n+        nnvm::NodeEntry &ew_input_with_fc = (ew_add_node->inputs[1].node == fc_node) ?\n+                                        ew_add_node->inputs[1] :\n+                                        ew_add_node->inputs[0];\n+        ew_input_with_fc.node = fc_orginal;\n+        new_sym.outputs.emplace_back(ew_add_node);\n+        fc_node->attrs.subgraphs.clear();\n+        fc_node->attrs.subgraphs.emplace_back(std::make_shared<nnvm::Symbol>(new_sym));\n+        fc_node->attrs.dict[\"with_sum\"] = \"True\";\n+        fc_node->op()->attr_parser(&(fc_node->attrs));\n+      }\n+    }\n+    return fc_node;\n+  }\n+\n+  SubgraphSelectorPtr CreateSubgraphSelector() const override {\n+    bool quantized = HasAttr(\"quantize\") ? GetAttr<bool>(\"quantize\") : false;\n+    auto selector =\n+      std::make_shared<SgMKLDNNFCSumFuseSelector>(quantized);\n+    return selector;\n+  }\n+\n+  void ConnectSubgraphOutputs(\n+      const nnvm::ObjectPtr n,\n+      std::vector<nnvm::NodeEntry *> *output_entries) const override {\n+    // Connect all extern output entries to output[0]\n+    for (size_t i = 0; i < output_entries->size(); ++i) {\n+      auto entry_ptr = output_entries->at(i);\n+      *entry_ptr = nnvm::NodeEntry{n, entry_ptr->index, 0};\n+    }\n+  }\n+\n+  void ConnectSubgraphInputs(\n+      const nnvm::ObjectPtr n, std::vector<nnvm::NodeEntry *> *input_entries,\n+      std::vector<nnvm::NodeEntry> *orig_input_entries) const override {\n+    auto sym = n->attrs.subgraphs[0];\n+    auto const &fc_param = nnvm::get<MKLDNNFCFullParam>(n->attrs.parsed);\n+    std::unordered_set<const nnvm::Node *> node_sets;\n+    DFSVisit(sym->outputs, [&](const nnvm::ObjectPtr &node) {",
        "comment_created_at": "2021-07-06T09:20:20+00:00",
        "comment_author": "anko-intel",
        "comment_body": "I think so, but I think it is to big change in this moment.",
        "pr_file_module": null
      },
      {
        "comment_id": "664396171",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20400,
        "pr_file": "src/operator/subgraph/mkldnn/mkldnn_fc_sum_fuse.h",
        "discussion_id": "664297807",
        "commented_code": "@@ -0,0 +1,240 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+/*\n+  \\brief It fuses FC + SUM for floating point output in second post quantization pass\n+*/\n+\n+#ifndef MXNET_OPERATOR_SUBGRAPH_MKLDNN_MKLDNN_FC_SUM_FUSE_H_\n+#define MXNET_OPERATOR_SUBGRAPH_MKLDNN_MKLDNN_FC_SUM_FUSE_H_\n+#if MXNET_USE_MKLDNN == 1\n+\n+#include <string>\n+#include <vector>\n+#include <memory>\n+#include <unordered_set>\n+#include <utility>\n+#include \"../common.h\"\n+#include \"../../tensor/matrix_op-inl.h\"\n+#include \"mkldnn_subgraph_base-inl.h\"\n+#include \"mkldnn_fc-inl.h\"\n+\n+namespace mxnet {\n+namespace op {\n+\n+class SgMKLDNNFCSumFuseSelector : public SubgraphSelector {\n+ public:\n+  /*! \\brief pattern match status */\n+  enum SelectStatus {\n+    kFail = 0,\n+    kStart,\n+    kSuccess,\n+  };\n+\n+ private:\n+  bool quantized_;\n+  SelectStatus status_;\n+  std::vector<const nnvm::Node *> matched_list_;\n+\n+ public:\n+  explicit SgMKLDNNFCSumFuseSelector(bool quantized) :\n+      quantized_(quantized) {}\n+\n+  bool Select(const nnvm::Node &n, const std::shared_ptr<NodeAttr>& node_attr) override {\n+    if (n.op() == Op::Get(\"_sg_mkldnn_fully_connected\") && SupportMKLDNNAttr(node_attr)) {\n+      auto const &fc_param = nnvm::get<MKLDNNFCFullParam>(n.attrs.parsed);\n+      // TODO(anko) remove fc_param.mkldnn_param.quantized from if below\n+      //            to fuse even for not quantized?\n+      if (fc_param.mkldnn_param.enable_float_output && fc_param.mkldnn_param.quantized) {\n+        status_ = kStart;\n+        matched_list_.clear();\n+        matched_list_.push_back(&n);\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  bool SelectInput(const nnvm::Node &n, const nnvm::Node &new_node) override {\n+    return false;\n+  }\n+\n+  bool SelectOutput(const nnvm::Node &n, const nnvm::Node &new_node) override {\n+    if (status_ == kFail || status_ == kSuccess || new_node.is_variable())\n+      return false;\n+    // If n isn't the last matched node, then we encoutered a internal\n+    // branch, we should pop out the node behind n and stop fusion.\n+    if (matched_list_.back() != &n) {\n+      if (std::find(matched_list_.begin(), matched_list_.end(), &n) !=\n+        matched_list_.end()) {\n+        while (matched_list_.back() != &n) {\n+          matched_list_.pop_back();\n+        }\n+      }\n+      status_ = kSuccess;\n+      return false;\n+    }\n+\n+    switch (status_) {\n+      case kStart:\n+        if (new_node.op()->name == \"elemwise_add\") {\n+          matched_list_.push_back(&new_node);\n+          status_ = kSuccess;\n+          return true;\n+        }\n+      default:\n+        status_ = kSuccess;\n+        return false;\n+    }\n+  }\n+\n+  std::vector<nnvm::Node *> Filter(\n+      const std::vector<nnvm::Node *> &candidates) override {\n+    if (status_ == kFail) {\n+      return std::vector<nnvm::Node *>(0);\n+    } else {\n+      std::vector<nnvm::Node *> ret;\n+      for (auto i : matched_list_) {\n+        auto non_const_i = const_cast<nnvm::Node *>(i);\n+        if (std::find(candidates.begin(), candidates.end(), non_const_i) !=\n+            candidates.end()) {\n+          ret.push_back(non_const_i);\n+        }\n+      }\n+      return candidates;\n+    }\n+  }\n+\n+  void Reset() override {\n+    CHECK_GE(matched_list_.size(), 1);\n+    auto new_selector = SgMKLDNNFCSumFuseSelector(quantized_);\n+    new_selector.Select(*matched_list_[0], nullptr);\n+    *this = new_selector;\n+  }\n+};\n+\n+class SgMKLDNNFCSumFuseProperty : public SubgraphProperty {\n+ public:\n+  SgMKLDNNFCSumFuseProperty() {}\n+\n+  static SubgraphPropertyPtr Create() {\n+    static const std::string &name = \"MKLDNN FullyConnected post quantization second pass\";\n+    auto property = std::make_shared<SgMKLDNNFCSumFuseProperty>();\n+    property->SetAttr<std::string>(\"property_name\", name);\n+    property->SetAttr<bool>(\"inference_only\", true);\n+    if (dmlc::GetEnv(\"MXNET_DISABLE_MKLDNN_FC_SUM\", 0)) {\n+      property->SetAttr<bool>(\"disable\", true);\n+    }\n+    return property;\n+  }\n+\n+  nnvm::ObjectPtr CreateSubgraphNode(const nnvm::Symbol &sym,\n+                                   const int subgraph_id = 0) const override {\n+    nnvm::ObjectPtr fc_node = nullptr;\n+    nnvm::ObjectPtr ew_add_node = nullptr;\n+\n+    DFSVisit(sym.outputs, [&](const nnvm::ObjectPtr &node) {\n+      if (node->is_variable()) return;\n+      auto &sub_name = node->op()->name;\n+      if (sub_name == \"_sg_mkldnn_fully_connected\") {\n+        fc_node = node;\n+      } else if (sub_name == \"elemwise_add\") {\n+        ew_add_node = node;\n+      }\n+    });\n+\n+    CHECK_NOTNULL(fc_node);\n+    if (ew_add_node != nullptr) {\n+      CHECK_NOTNULL(fc_node->attrs.subgraphs[0]);\n+      auto fc_orginal = fc_node->attrs.subgraphs[0]->outputs[0].node;\n+      if (fc_orginal->op() == Op::Get(\"FullyConnected\")) {\n+        nnvm::Symbol new_sym;\n+        nnvm::NodeEntry &ew_input_with_fc = (ew_add_node->inputs[1].node == fc_node) ?\n+                                        ew_add_node->inputs[1] :\n+                                        ew_add_node->inputs[0];\n+        ew_input_with_fc.node = fc_orginal;\n+        new_sym.outputs.emplace_back(ew_add_node);\n+        fc_node->attrs.subgraphs.clear();\n+        fc_node->attrs.subgraphs.emplace_back(std::make_shared<nnvm::Symbol>(new_sym));\n+        fc_node->attrs.dict[\"with_sum\"] = \"True\";\n+        fc_node->op()->attr_parser(&(fc_node->attrs));\n+      }\n+    }\n+    return fc_node;\n+  }\n+\n+  SubgraphSelectorPtr CreateSubgraphSelector() const override {\n+    bool quantized = HasAttr(\"quantize\") ? GetAttr<bool>(\"quantize\") : false;\n+    auto selector =\n+      std::make_shared<SgMKLDNNFCSumFuseSelector>(quantized);\n+    return selector;\n+  }\n+\n+  void ConnectSubgraphOutputs(\n+      const nnvm::ObjectPtr n,\n+      std::vector<nnvm::NodeEntry *> *output_entries) const override {\n+    // Connect all extern output entries to output[0]\n+    for (size_t i = 0; i < output_entries->size(); ++i) {\n+      auto entry_ptr = output_entries->at(i);\n+      *entry_ptr = nnvm::NodeEntry{n, entry_ptr->index, 0};\n+    }\n+  }\n+\n+  void ConnectSubgraphInputs(\n+      const nnvm::ObjectPtr n, std::vector<nnvm::NodeEntry *> *input_entries,\n+      std::vector<nnvm::NodeEntry> *orig_input_entries) const override {\n+    auto sym = n->attrs.subgraphs[0];\n+    auto const &fc_param = nnvm::get<MKLDNNFCFullParam>(n->attrs.parsed);\n+    std::unordered_set<const nnvm::Node *> node_sets;\n+    DFSVisit(sym->outputs, [&](const nnvm::ObjectPtr &node) {",
        "comment_created_at": "2021-07-06T09:33:23+00:00",
        "comment_author": "sfraczek",
        "comment_body": "@anko-intel Is this iterating through just subgraph fc->elementwise_add or entire graph?",
        "pr_file_module": null
      },
      {
        "comment_id": "664618631",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20400,
        "pr_file": "src/operator/subgraph/mkldnn/mkldnn_fc_sum_fuse.h",
        "discussion_id": "664297807",
        "commented_code": "@@ -0,0 +1,240 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+/*\n+  \\brief It fuses FC + SUM for floating point output in second post quantization pass\n+*/\n+\n+#ifndef MXNET_OPERATOR_SUBGRAPH_MKLDNN_MKLDNN_FC_SUM_FUSE_H_\n+#define MXNET_OPERATOR_SUBGRAPH_MKLDNN_MKLDNN_FC_SUM_FUSE_H_\n+#if MXNET_USE_MKLDNN == 1\n+\n+#include <string>\n+#include <vector>\n+#include <memory>\n+#include <unordered_set>\n+#include <utility>\n+#include \"../common.h\"\n+#include \"../../tensor/matrix_op-inl.h\"\n+#include \"mkldnn_subgraph_base-inl.h\"\n+#include \"mkldnn_fc-inl.h\"\n+\n+namespace mxnet {\n+namespace op {\n+\n+class SgMKLDNNFCSumFuseSelector : public SubgraphSelector {\n+ public:\n+  /*! \\brief pattern match status */\n+  enum SelectStatus {\n+    kFail = 0,\n+    kStart,\n+    kSuccess,\n+  };\n+\n+ private:\n+  bool quantized_;\n+  SelectStatus status_;\n+  std::vector<const nnvm::Node *> matched_list_;\n+\n+ public:\n+  explicit SgMKLDNNFCSumFuseSelector(bool quantized) :\n+      quantized_(quantized) {}\n+\n+  bool Select(const nnvm::Node &n, const std::shared_ptr<NodeAttr>& node_attr) override {\n+    if (n.op() == Op::Get(\"_sg_mkldnn_fully_connected\") && SupportMKLDNNAttr(node_attr)) {\n+      auto const &fc_param = nnvm::get<MKLDNNFCFullParam>(n.attrs.parsed);\n+      // TODO(anko) remove fc_param.mkldnn_param.quantized from if below\n+      //            to fuse even for not quantized?\n+      if (fc_param.mkldnn_param.enable_float_output && fc_param.mkldnn_param.quantized) {\n+        status_ = kStart;\n+        matched_list_.clear();\n+        matched_list_.push_back(&n);\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  bool SelectInput(const nnvm::Node &n, const nnvm::Node &new_node) override {\n+    return false;\n+  }\n+\n+  bool SelectOutput(const nnvm::Node &n, const nnvm::Node &new_node) override {\n+    if (status_ == kFail || status_ == kSuccess || new_node.is_variable())\n+      return false;\n+    // If n isn't the last matched node, then we encoutered a internal\n+    // branch, we should pop out the node behind n and stop fusion.\n+    if (matched_list_.back() != &n) {\n+      if (std::find(matched_list_.begin(), matched_list_.end(), &n) !=\n+        matched_list_.end()) {\n+        while (matched_list_.back() != &n) {\n+          matched_list_.pop_back();\n+        }\n+      }\n+      status_ = kSuccess;\n+      return false;\n+    }\n+\n+    switch (status_) {\n+      case kStart:\n+        if (new_node.op()->name == \"elemwise_add\") {\n+          matched_list_.push_back(&new_node);\n+          status_ = kSuccess;\n+          return true;\n+        }\n+      default:\n+        status_ = kSuccess;\n+        return false;\n+    }\n+  }\n+\n+  std::vector<nnvm::Node *> Filter(\n+      const std::vector<nnvm::Node *> &candidates) override {\n+    if (status_ == kFail) {\n+      return std::vector<nnvm::Node *>(0);\n+    } else {\n+      std::vector<nnvm::Node *> ret;\n+      for (auto i : matched_list_) {\n+        auto non_const_i = const_cast<nnvm::Node *>(i);\n+        if (std::find(candidates.begin(), candidates.end(), non_const_i) !=\n+            candidates.end()) {\n+          ret.push_back(non_const_i);\n+        }\n+      }\n+      return candidates;\n+    }\n+  }\n+\n+  void Reset() override {\n+    CHECK_GE(matched_list_.size(), 1);\n+    auto new_selector = SgMKLDNNFCSumFuseSelector(quantized_);\n+    new_selector.Select(*matched_list_[0], nullptr);\n+    *this = new_selector;\n+  }\n+};\n+\n+class SgMKLDNNFCSumFuseProperty : public SubgraphProperty {\n+ public:\n+  SgMKLDNNFCSumFuseProperty() {}\n+\n+  static SubgraphPropertyPtr Create() {\n+    static const std::string &name = \"MKLDNN FullyConnected post quantization second pass\";\n+    auto property = std::make_shared<SgMKLDNNFCSumFuseProperty>();\n+    property->SetAttr<std::string>(\"property_name\", name);\n+    property->SetAttr<bool>(\"inference_only\", true);\n+    if (dmlc::GetEnv(\"MXNET_DISABLE_MKLDNN_FC_SUM\", 0)) {\n+      property->SetAttr<bool>(\"disable\", true);\n+    }\n+    return property;\n+  }\n+\n+  nnvm::ObjectPtr CreateSubgraphNode(const nnvm::Symbol &sym,\n+                                   const int subgraph_id = 0) const override {\n+    nnvm::ObjectPtr fc_node = nullptr;\n+    nnvm::ObjectPtr ew_add_node = nullptr;\n+\n+    DFSVisit(sym.outputs, [&](const nnvm::ObjectPtr &node) {\n+      if (node->is_variable()) return;\n+      auto &sub_name = node->op()->name;\n+      if (sub_name == \"_sg_mkldnn_fully_connected\") {\n+        fc_node = node;\n+      } else if (sub_name == \"elemwise_add\") {\n+        ew_add_node = node;\n+      }\n+    });\n+\n+    CHECK_NOTNULL(fc_node);\n+    if (ew_add_node != nullptr) {\n+      CHECK_NOTNULL(fc_node->attrs.subgraphs[0]);\n+      auto fc_orginal = fc_node->attrs.subgraphs[0]->outputs[0].node;\n+      if (fc_orginal->op() == Op::Get(\"FullyConnected\")) {\n+        nnvm::Symbol new_sym;\n+        nnvm::NodeEntry &ew_input_with_fc = (ew_add_node->inputs[1].node == fc_node) ?\n+                                        ew_add_node->inputs[1] :\n+                                        ew_add_node->inputs[0];\n+        ew_input_with_fc.node = fc_orginal;\n+        new_sym.outputs.emplace_back(ew_add_node);\n+        fc_node->attrs.subgraphs.clear();\n+        fc_node->attrs.subgraphs.emplace_back(std::make_shared<nnvm::Symbol>(new_sym));\n+        fc_node->attrs.dict[\"with_sum\"] = \"True\";\n+        fc_node->op()->attr_parser(&(fc_node->attrs));\n+      }\n+    }\n+    return fc_node;\n+  }\n+\n+  SubgraphSelectorPtr CreateSubgraphSelector() const override {\n+    bool quantized = HasAttr(\"quantize\") ? GetAttr<bool>(\"quantize\") : false;\n+    auto selector =\n+      std::make_shared<SgMKLDNNFCSumFuseSelector>(quantized);\n+    return selector;\n+  }\n+\n+  void ConnectSubgraphOutputs(\n+      const nnvm::ObjectPtr n,\n+      std::vector<nnvm::NodeEntry *> *output_entries) const override {\n+    // Connect all extern output entries to output[0]\n+    for (size_t i = 0; i < output_entries->size(); ++i) {\n+      auto entry_ptr = output_entries->at(i);\n+      *entry_ptr = nnvm::NodeEntry{n, entry_ptr->index, 0};\n+    }\n+  }\n+\n+  void ConnectSubgraphInputs(\n+      const nnvm::ObjectPtr n, std::vector<nnvm::NodeEntry *> *input_entries,\n+      std::vector<nnvm::NodeEntry> *orig_input_entries) const override {\n+    auto sym = n->attrs.subgraphs[0];\n+    auto const &fc_param = nnvm::get<MKLDNNFCFullParam>(n->attrs.parsed);\n+    std::unordered_set<const nnvm::Node *> node_sets;\n+    DFSVisit(sym->outputs, [&](const nnvm::ObjectPtr &node) {",
        "comment_created_at": "2021-07-06T14:40:31+00:00",
        "comment_author": "mozga-intel",
        "comment_body": "@anko-intel Thanks, How about talking it over? \r\n\r\n## Problem statement ##\r\nIf the structure of a graph is still the same all the time (apart of fusing). Then we can try to avoid running DFS algorithm multiple times.  For brevity, those calls force us to pay a penalty: O(V + E). If we assume that `n` represents a total number of patterns, then the summary cost of that is equal n * O(V +E). Even more, for a few operators (i.e this one) DFS might be run twice or more, if any ~ then we got mn * O(V +E). \r\n\r\n## Solution - short description  [Future plan] ##\r\nReduce overall time of using DFS to a minimum: nice to have just O(V +E), by labelling nodes and keeping traversal order. Pattern matching is applied after that ~ on a traversal order vector (maybe LCA knowledge is needed).",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "647723370",
    "pr_number": 20262,
    "pr_file": "src/imperative/imperative.cc",
    "created_at": "2021-06-08T19:10:31+00:00",
    "commented_code": "<< \"must have a deferred compute history associated with them.\";\n    s.outputs.emplace_back(ndoutput->deferredcompute_entry_);\n  }\n  nnvm::DFSVisit(s.outputs, [&](const nnvm::ObjectPtr& n) {",
    "repo_full_name": "apache/mxnet",
    "discussion_comments": [
      {
        "comment_id": "647723370",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20262,
        "pr_file": "src/imperative/imperative.cc",
        "discussion_id": "647723370",
        "commented_code": "@@ -350,6 +350,15 @@ nnvm::Symbol Imperative::GetDeferredComputeSymbol(const std::vector<NDArray *> &\n         << \"must have a deferred compute history associated with them.\";\n     s.outputs.emplace_back(ndoutput->deferredcompute_entry_);\n   }\n+  nnvm::DFSVisit(s.outputs, [&](const nnvm::ObjectPtr& n) {",
        "comment_created_at": "2021-06-08T19:10:31+00:00",
        "comment_author": "leezu",
        "comment_body": "I think this needs to run on a copy of the graph, because in general there can still be a call to `Compute` after `GetDeferredComputeSymbol`. ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "766527196",
    "pr_number": 20767,
    "pr_file": "src/operator/subgraph/dnnl/dnnl_identity_property.h",
    "created_at": "2021-12-10T09:52:32+00:00",
    "commented_code": "}\n\n  bool SelectInput(const BiDirectedNode& n, const BiDirectedNode& input_node) override {\n    if (input_node.node->is_variable()) {\n    if (pattern_found || input_node.node->is_variable()) {",
    "repo_full_name": "apache/mxnet",
    "discussion_comments": [
      {
        "comment_id": "766527196",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20767,
        "pr_file": "src/operator/subgraph/dnnl/dnnl_identity_property.h",
        "discussion_id": "766527196",
        "commented_code": "@@ -65,10 +66,11 @@ class SgDNNLIdentitySelector : public SubgraphSelectorV2 {\n   }\n \n   bool SelectInput(const BiDirectedNode& n, const BiDirectedNode& input_node) override {\n-    if (input_node.node->is_variable()) {\n+    if (pattern_found || input_node.node->is_variable()) {",
        "comment_created_at": "2021-12-10T09:52:32+00:00",
        "comment_author": "PawelGlomski-Intel",
        "comment_body": "You could use `matched_list_` like you did in the `Filter` function.\r\n```suggestion\r\n    if (matched_list_.size() == 2 || input_node.node->is_variable()) {\r\n```\r\nIf not, then I would also use `pattern_found` in the `Filter` function, to show, that these conditions are connected.\r\nhttps://github.com/apache/incubator-mxnet/blob/7e163157cf789d7ec5e7272532e04495e57bd0ba/src/operator/subgraph/dnnl/dnnl_identity_property.h#L85\r\nChange to :\r\n```\r\n    if (pattern_found && candidates.size() == matched_list_.size()) { \r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "770310841",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20767,
        "pr_file": "src/operator/subgraph/dnnl/dnnl_identity_property.h",
        "discussion_id": "766527196",
        "commented_code": "@@ -65,10 +66,11 @@ class SgDNNLIdentitySelector : public SubgraphSelectorV2 {\n   }\n \n   bool SelectInput(const BiDirectedNode& n, const BiDirectedNode& input_node) override {\n-    if (input_node.node->is_variable()) {\n+    if (pattern_found || input_node.node->is_variable()) {",
        "comment_created_at": "2021-12-16T08:19:20+00:00",
        "comment_author": "bgawrych",
        "comment_body": "Done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "820816070",
    "pr_number": 20753,
    "pr_file": "src/nnvm/low_precision_pass.cc",
    "created_at": "2022-03-07T15:26:58+00:00",
    "commented_code": "#include <mxnet/base.h>\n#include <algorithm>\n#include <functional>\n#include \"../operator/operator_common.h\"\n\nnamespace mxnet {\nusing nnvm::Graph;\nusing nnvm::Node;\nusing nnvm::NodeEntry;\nusing nnvm::ObjectPtr;\nusing nnvm::Symbol;\n\n// create a node for operator : op_name with name : node_name\nstatic ObjectPtr CreateNode(std::string op_name, std::string node_name) {\n  ObjectPtr node   = Node::Create();\n  node->attrs.name = node_name;\n  if (op_name == \"nullptr\") {\n    node->attrs.op = nullptr;\n    // ugly workaround because VariableParam is not exposed\n    node->attrs.parsed =\n        nnvm::Symbol::CreateVariable(node->attrs.name).outputs[0].node->attrs.parsed;\n  } else {\n    node->attrs.op = Op::Get(op_name);\n  }\n  return node;\n}\n\nstatic ObjectPtr InsertNode(std::string op_name,\n                            std::string node_name,\n                            ObjectPtr current,\n                            NodeEntry previous) {\n  ObjectPtr node = CreateNode(op_name, node_name);\n  node->inputs.emplace_back(previous);\n  if (current)\n    current->inputs.emplace_back(NodeEntry{node, 0, 0});\n  return node;\nbool is_cast_op(const nnvm::Op* const op) {\n  return op && (op == Op::Get(\"amp_cast\") || op == Op::Get(\"Cast\"));\n}\n\n// get suffix for a node entry so that it can be used for amp_cast/amp_multicast node name\nstatic std::string GetSuffix(const nnvm::NodeEntry& node_entry,\n                             const std::unordered_map<Node*, ObjectPtr>& mirror_map) {\n  static const auto& flist_outputs = nnvm::Op::GetAttr<nnvm::FListOutputNames>(\"FListOutputNames\");\n  std::string suffix               = \"\";\n  ObjectPtr mirror_node            = mirror_map.at(node_entry.node.get());\n  if (mirror_node->op() != nullptr) {\n    auto list_output_names_func = flist_outputs.get(node_entry.node->op(), nullptr);\n    if (list_output_names_func != nullptr) {\n      std::vector<std::string> names = list_output_names_func(node_entry.node->attrs);\n      suffix                         = \"_\" + names[node_entry.index];\n    } else {\n      suffix = \"_\" + std::to_string(node_entry.index);\nclass MappedNodeEntry {\n public:\n  MappedNodeEntry(NodeEntry node_entry, const int original_dtype)\n      : entry(std::move(node_entry)), original_dtype(original_dtype) {\n    dtype = original_dtype;\n  }\n\n  void convert(const int new_dtype) {\n    CHECK_EQ(dtype, original_dtype);  // dtype should be changed only once\n    dtype = new_dtype;\n  }\n\n  const NodeEntry& as_original() {\n    return as_type(original_dtype);\n  }\n\n  const NodeEntry& as_type(const int target_dtype) {\n    if (dtype == target_dtype) {\n      return entry;\n    }\n    NodeEntry& cast_entry = casts[target_dtype];\n    if (cast_entry.node == nullptr) {\n      cast_entry = cast(target_dtype);\n      CHECK(cast_entry.node);\n    }\n    return cast_entry;\n  }\n  return suffix;\n}\n\n// add amp_cast node between curr_node and input\nstatic void AddCastNode(const nnvm::NodeEntry& e,\n                        const std::string& suffix,\n                        const nnvm::NodeEntry& input,\n                        const std::string dtype,\n                        nnvm::NodeEntryMap<NodeEntry>* mirror_entry_map,\n                        ObjectPtr curr_node) {\n  ObjectPtr cast_node =\n      InsertNode(\"amp_cast\", e.node->attrs.name + suffix + \"_amp_cast_\" + dtype, curr_node, input);\n  cast_node->attrs.dict[\"dtype\"] = dtype;\n  cast_node->op()->attr_parser(&(cast_node->attrs));\n  (*mirror_entry_map)[e] = NodeEntry{std::move(cast_node), 0, e.version};\n  return;\n}\n  bool has_dtype_entry(const int target_dtype) const {\n    return dtype == target_dtype || casts.count(target_dtype) > 0;\n  }\n\n  bool can_be_cast_offline_to(const int target_dtype) const {",
    "repo_full_name": "apache/mxnet",
    "discussion_comments": [
      {
        "comment_id": "820816070",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20753,
        "pr_file": "src/nnvm/low_precision_pass.cc",
        "discussion_id": "820816070",
        "commented_code": "@@ -29,374 +29,322 @@\n #include <mxnet/base.h>\n #include <algorithm>\n #include <functional>\n+#include \"../operator/operator_common.h\"\n \n namespace mxnet {\n using nnvm::Graph;\n using nnvm::Node;\n using nnvm::NodeEntry;\n using nnvm::ObjectPtr;\n-using nnvm::Symbol;\n-\n-// create a node for operator : op_name with name : node_name\n-static ObjectPtr CreateNode(std::string op_name, std::string node_name) {\n-  ObjectPtr node   = Node::Create();\n-  node->attrs.name = node_name;\n-  if (op_name == \"nullptr\") {\n-    node->attrs.op = nullptr;\n-    // ugly workaround because VariableParam is not exposed\n-    node->attrs.parsed =\n-        nnvm::Symbol::CreateVariable(node->attrs.name).outputs[0].node->attrs.parsed;\n-  } else {\n-    node->attrs.op = Op::Get(op_name);\n-  }\n-  return node;\n-}\n \n-static ObjectPtr InsertNode(std::string op_name,\n-                            std::string node_name,\n-                            ObjectPtr current,\n-                            NodeEntry previous) {\n-  ObjectPtr node = CreateNode(op_name, node_name);\n-  node->inputs.emplace_back(previous);\n-  if (current)\n-    current->inputs.emplace_back(NodeEntry{node, 0, 0});\n-  return node;\n+bool is_cast_op(const nnvm::Op* const op) {\n+  return op && (op == Op::Get(\"amp_cast\") || op == Op::Get(\"Cast\"));\n }\n \n-// get suffix for a node entry so that it can be used for amp_cast/amp_multicast node name\n-static std::string GetSuffix(const nnvm::NodeEntry& node_entry,\n-                             const std::unordered_map<Node*, ObjectPtr>& mirror_map) {\n-  static const auto& flist_outputs = nnvm::Op::GetAttr<nnvm::FListOutputNames>(\"FListOutputNames\");\n-  std::string suffix               = \"\";\n-  ObjectPtr mirror_node            = mirror_map.at(node_entry.node.get());\n-  if (mirror_node->op() != nullptr) {\n-    auto list_output_names_func = flist_outputs.get(node_entry.node->op(), nullptr);\n-    if (list_output_names_func != nullptr) {\n-      std::vector<std::string> names = list_output_names_func(node_entry.node->attrs);\n-      suffix                         = \"_\" + names[node_entry.index];\n-    } else {\n-      suffix = \"_\" + std::to_string(node_entry.index);\n+class MappedNodeEntry {\n+ public:\n+  MappedNodeEntry(NodeEntry node_entry, const int original_dtype)\n+      : entry(std::move(node_entry)), original_dtype(original_dtype) {\n+    dtype = original_dtype;\n+  }\n+\n+  void convert(const int new_dtype) {\n+    CHECK_EQ(dtype, original_dtype);  // dtype should be changed only once\n+    dtype = new_dtype;\n+  }\n+\n+  const NodeEntry& as_original() {\n+    return as_type(original_dtype);\n+  }\n+\n+  const NodeEntry& as_type(const int target_dtype) {\n+    if (dtype == target_dtype) {\n+      return entry;\n+    }\n+    NodeEntry& cast_entry = casts[target_dtype];\n+    if (cast_entry.node == nullptr) {\n+      cast_entry = cast(target_dtype);\n+      CHECK(cast_entry.node);\n     }\n+    return cast_entry;\n   }\n-  return suffix;\n-}\n \n-// add amp_cast node between curr_node and input\n-static void AddCastNode(const nnvm::NodeEntry& e,\n-                        const std::string& suffix,\n-                        const nnvm::NodeEntry& input,\n-                        const std::string dtype,\n-                        nnvm::NodeEntryMap<NodeEntry>* mirror_entry_map,\n-                        ObjectPtr curr_node) {\n-  ObjectPtr cast_node =\n-      InsertNode(\"amp_cast\", e.node->attrs.name + suffix + \"_amp_cast_\" + dtype, curr_node, input);\n-  cast_node->attrs.dict[\"dtype\"] = dtype;\n-  cast_node->op()->attr_parser(&(cast_node->attrs));\n-  (*mirror_entry_map)[e] = NodeEntry{std::move(cast_node), 0, e.version};\n-  return;\n-}\n+  bool has_dtype_entry(const int target_dtype) const {\n+    return dtype == target_dtype || casts.count(target_dtype) > 0;\n+  }\n+\n+  bool can_be_cast_offline_to(const int target_dtype) const {",
        "comment_created_at": "2022-03-07T15:26:58+00:00",
        "comment_author": "bartekkuncer",
        "comment_body": "Why amount of casts to a particular dtype determines whether casting to this dtype can be performed offline?",
        "pr_file_module": null
      },
      {
        "comment_id": "820851332",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20753,
        "pr_file": "src/nnvm/low_precision_pass.cc",
        "discussion_id": "820816070",
        "commented_code": "@@ -29,374 +29,322 @@\n #include <mxnet/base.h>\n #include <algorithm>\n #include <functional>\n+#include \"../operator/operator_common.h\"\n \n namespace mxnet {\n using nnvm::Graph;\n using nnvm::Node;\n using nnvm::NodeEntry;\n using nnvm::ObjectPtr;\n-using nnvm::Symbol;\n-\n-// create a node for operator : op_name with name : node_name\n-static ObjectPtr CreateNode(std::string op_name, std::string node_name) {\n-  ObjectPtr node   = Node::Create();\n-  node->attrs.name = node_name;\n-  if (op_name == \"nullptr\") {\n-    node->attrs.op = nullptr;\n-    // ugly workaround because VariableParam is not exposed\n-    node->attrs.parsed =\n-        nnvm::Symbol::CreateVariable(node->attrs.name).outputs[0].node->attrs.parsed;\n-  } else {\n-    node->attrs.op = Op::Get(op_name);\n-  }\n-  return node;\n-}\n \n-static ObjectPtr InsertNode(std::string op_name,\n-                            std::string node_name,\n-                            ObjectPtr current,\n-                            NodeEntry previous) {\n-  ObjectPtr node = CreateNode(op_name, node_name);\n-  node->inputs.emplace_back(previous);\n-  if (current)\n-    current->inputs.emplace_back(NodeEntry{node, 0, 0});\n-  return node;\n+bool is_cast_op(const nnvm::Op* const op) {\n+  return op && (op == Op::Get(\"amp_cast\") || op == Op::Get(\"Cast\"));\n }\n \n-// get suffix for a node entry so that it can be used for amp_cast/amp_multicast node name\n-static std::string GetSuffix(const nnvm::NodeEntry& node_entry,\n-                             const std::unordered_map<Node*, ObjectPtr>& mirror_map) {\n-  static const auto& flist_outputs = nnvm::Op::GetAttr<nnvm::FListOutputNames>(\"FListOutputNames\");\n-  std::string suffix               = \"\";\n-  ObjectPtr mirror_node            = mirror_map.at(node_entry.node.get());\n-  if (mirror_node->op() != nullptr) {\n-    auto list_output_names_func = flist_outputs.get(node_entry.node->op(), nullptr);\n-    if (list_output_names_func != nullptr) {\n-      std::vector<std::string> names = list_output_names_func(node_entry.node->attrs);\n-      suffix                         = \"_\" + names[node_entry.index];\n-    } else {\n-      suffix = \"_\" + std::to_string(node_entry.index);\n+class MappedNodeEntry {\n+ public:\n+  MappedNodeEntry(NodeEntry node_entry, const int original_dtype)\n+      : entry(std::move(node_entry)), original_dtype(original_dtype) {\n+    dtype = original_dtype;\n+  }\n+\n+  void convert(const int new_dtype) {\n+    CHECK_EQ(dtype, original_dtype);  // dtype should be changed only once\n+    dtype = new_dtype;\n+  }\n+\n+  const NodeEntry& as_original() {\n+    return as_type(original_dtype);\n+  }\n+\n+  const NodeEntry& as_type(const int target_dtype) {\n+    if (dtype == target_dtype) {\n+      return entry;\n+    }\n+    NodeEntry& cast_entry = casts[target_dtype];\n+    if (cast_entry.node == nullptr) {\n+      cast_entry = cast(target_dtype);\n+      CHECK(cast_entry.node);\n     }\n+    return cast_entry;\n   }\n-  return suffix;\n-}\n \n-// add amp_cast node between curr_node and input\n-static void AddCastNode(const nnvm::NodeEntry& e,\n-                        const std::string& suffix,\n-                        const nnvm::NodeEntry& input,\n-                        const std::string dtype,\n-                        nnvm::NodeEntryMap<NodeEntry>* mirror_entry_map,\n-                        ObjectPtr curr_node) {\n-  ObjectPtr cast_node =\n-      InsertNode(\"amp_cast\", e.node->attrs.name + suffix + \"_amp_cast_\" + dtype, curr_node, input);\n-  cast_node->attrs.dict[\"dtype\"] = dtype;\n-  cast_node->op()->attr_parser(&(cast_node->attrs));\n-  (*mirror_entry_map)[e] = NodeEntry{std::move(cast_node), 0, e.version};\n-  return;\n-}\n+  bool has_dtype_entry(const int target_dtype) const {\n+    return dtype == target_dtype || casts.count(target_dtype) > 0;\n+  }\n+\n+  bool can_be_cast_offline_to(const int target_dtype) const {",
        "comment_created_at": "2022-03-07T16:01:08+00:00",
        "comment_author": "PawelGlomski-Intel",
        "comment_body": "`casts` is an unordered map, thus the count returns whether the cast to this dtype exists or not. A parameter should be cast offline only if there is a need for it - there is at least one operator using it through a cast.",
        "pr_file_module": null
      }
    ]
  }
]
