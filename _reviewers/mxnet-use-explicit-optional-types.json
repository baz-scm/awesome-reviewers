[
  {
    "discussion_id": "793919904",
    "pr_number": 20852,
    "pr_file": "perl-package/AI-MXNet/lib/AI/MXNet/Metric.pm",
    "created_at": "2022-01-27T19:10:52+00:00",
    "commented_code": "has 'name'       => (is => 'rw', isa => 'Str');\nhas 'num'        => (is => 'rw', isa => 'Int');\nhas 'num_inst'   => (is => 'rw', isa => 'Maybe[Int|ArrayRef[Int]]');\nhas 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]]');\nhas 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]|PDL]');",
    "repo_full_name": "apache/mxnet",
    "discussion_comments": [
      {
        "comment_id": "793919904",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20852,
        "pr_file": "perl-package/AI-MXNet/lib/AI/MXNet/Metric.pm",
        "discussion_id": "793919904",
        "commented_code": "@@ -79,7 +79,7 @@ use overload '\"\"' => sub {\n has 'name'       => (is => 'rw', isa => 'Str');\n has 'num'        => (is => 'rw', isa => 'Int');\n has 'num_inst'   => (is => 'rw', isa => 'Maybe[Int|ArrayRef[Int]]');\n-has 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]]');\n+has 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]|PDL]');",
        "comment_created_at": "2022-01-27T19:10:52+00:00",
        "comment_author": "sergeykolychev",
        "comment_body": "Why is this needed ? Is $pdl->sum (and other similar methods) produce pdl object now ? This change is a bit radical and will require additional tests to see of something that is not covered by the CI is not broken.",
        "pr_file_module": null
      },
      {
        "comment_id": "793925590",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20852,
        "pr_file": "perl-package/AI-MXNet/lib/AI/MXNet/Metric.pm",
        "discussion_id": "793919904",
        "commented_code": "@@ -79,7 +79,7 @@ use overload '\"\"' => sub {\n has 'name'       => (is => 'rw', isa => 'Str');\n has 'num'        => (is => 'rw', isa => 'Int');\n has 'num_inst'   => (is => 'rw', isa => 'Maybe[Int|ArrayRef[Int]]');\n-has 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]]');\n+has 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]|PDL]');",
        "comment_created_at": "2022-01-27T19:18:39+00:00",
        "comment_author": "zmughal",
        "comment_body": "Yes, that is correct, they return a PDL ndarray (of zero rank) now (since PDL v2.056). This is to make sure that types such as complex numbers and BAD values can be correctly returned. To get a single Perl scalar out of a PDL, you can do `$pdl->sclr`. Though for many situations, this should work like a Perl scalar due to operator overloading.",
        "pr_file_module": null
      },
      {
        "comment_id": "793930850",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20852,
        "pr_file": "perl-package/AI-MXNet/lib/AI/MXNet/Metric.pm",
        "discussion_id": "793919904",
        "commented_code": "@@ -79,7 +79,7 @@ use overload '\"\"' => sub {\n has 'name'       => (is => 'rw', isa => 'Str');\n has 'num'        => (is => 'rw', isa => 'Int');\n has 'num_inst'   => (is => 'rw', isa => 'Maybe[Int|ArrayRef[Int]]');\n-has 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]]');\n+has 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]|PDL]');",
        "comment_created_at": "2022-01-27T19:26:17+00:00",
        "comment_author": "zmughal",
        "comment_body": "What type of tests would you like to see?",
        "pr_file_module": null
      },
      {
        "comment_id": "793936355",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20852,
        "pr_file": "perl-package/AI-MXNet/lib/AI/MXNet/Metric.pm",
        "discussion_id": "793919904",
        "commented_code": "@@ -79,7 +79,7 @@ use overload '\"\"' => sub {\n has 'name'       => (is => 'rw', isa => 'Str');\n has 'num'        => (is => 'rw', isa => 'Int');\n has 'num_inst'   => (is => 'rw', isa => 'Maybe[Int|ArrayRef[Int]]');\n-has 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]]');\n+has 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]|PDL]');",
        "comment_created_at": "2022-01-27T19:33:51+00:00",
        "comment_author": "sergeykolychev",
        "comment_body": "May I ask you locally run scripts from AI-MXNet/examples/ and see if they run and produce sane output ?",
        "pr_file_module": null
      },
      {
        "comment_id": "794252536",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20852,
        "pr_file": "perl-package/AI-MXNet/lib/AI/MXNet/Metric.pm",
        "discussion_id": "793919904",
        "commented_code": "@@ -79,7 +79,7 @@ use overload '\"\"' => sub {\n has 'name'       => (is => 'rw', isa => 'Str');\n has 'num'        => (is => 'rw', isa => 'Int');\n has 'num_inst'   => (is => 'rw', isa => 'Maybe[Int|ArrayRef[Int]]');\n-has 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]]');\n+has 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]|PDL]');",
        "comment_created_at": "2022-01-28T07:15:57+00:00",
        "comment_author": "zmughal",
        "comment_body": "\r\n== examples/calculator.pl ==\r\n\r\n```\r\nfullyconnected4_bias -> [0.675975]\r\nfullyconnected4_weight -> \r\n[\r\n [ 1.00116 0.999985]\r\n]\r\n\r\nfullyconnected5_bias -> [4.85674e-05]\r\nfullyconnected5_weight -> \r\n[\r\n [0.000844207 0.000230625    0.508509]\r\n]\r\n\r\nfullyconnected6_bias -> [0.385759]\r\nfullyconnected6_weight -> \r\n[\r\n [      1      -1]\r\n]\r\n\r\nfullyconnected7_bias -> [-2.62715e-06]\r\nfullyconnected7_weight -> \r\n[\r\n [-1.31198e-05  8.74287e-06     0.679938]\r\n]\r\n\r\n12345 + 54321 ≈ 66742.1796875\r\n188 - 88 ≈ 99.8591766357422\r\n250 * 2 ≈ 503.255798339844\r\n250 / 2 ≈ 124.998970031738\r\n```\r\n\r\n== examples/mnist.pl ==\r\n\r\n```\r\nEpoch[4] Batch [200]\tSpeed: 59678.68 samples/sec\tTrain-accuracy=0.974726\r\nEpoch[4] Batch [400]\tSpeed: 57716.06 samples/sec\tTrain-accuracy=0.973350\r\nEpoch[4] Train-accuracy=0.974233\r\nEpoch[4] Time cost=1.057\r\nEpoch[4] Validation-accuracy=0.967800\r\nEpoch[5] Batch [200]\tSpeed: 52405.81 samples/sec\tTrain-accuracy=0.977214\r\nEpoch[5] Batch [400]\tSpeed: 57804.15 samples/sec\tTrain-accuracy=0.976100\r\nEpoch[5] Train-accuracy=0.976950\r\nEpoch[5] Time cost=1.079\r\nEpoch[5] Validation-accuracy=0.966500\r\nEpoch[6] Batch [200]\tSpeed: 57043.78 samples/sec\tTrain-accuracy=0.977015\r\nEpoch[6] Batch [400]\tSpeed: 57357.53 samples/sec\tTrain-accuracy=0.975800\r\nEpoch[6] Train-accuracy=0.976433\r\nEpoch[6] Time cost=1.052\r\nEpoch[6] Validation-accuracy=0.963000\r\nEpoch[7] Batch [200]\tSpeed: 45378.31 samples/sec\tTrain-accuracy=0.977711\r\nEpoch[7] Batch [400]\tSpeed: 55753.34 samples/sec\tTrain-accuracy=0.976350\r\nEpoch[7] Train-accuracy=0.977467\r\nEpoch[7] Time cost=1.144\r\nEpoch[7] Validation-accuracy=0.963700\r\nEpoch[8] Batch [200]\tSpeed: 54546.75 samples/sec\tTrain-accuracy=0.980448\r\nEpoch[8] Batch [400]\tSpeed: 55774.47 samples/sec\tTrain-accuracy=0.980000\r\nEpoch[8] Train-accuracy=0.980217\r\nEpoch[8] Time cost=1.090\r\nEpoch[8] Validation-accuracy=0.962900\r\nEpoch[9] Batch [200]\tSpeed: 48810.85 samples/sec\tTrain-accuracy=0.980050\r\nEpoch[9] Batch [400]\tSpeed: 54945.51 samples/sec\tTrain-accuracy=0.982550\r\nEpoch[9] Train-accuracy=0.981850\r\nEpoch[9] Time cost=1.115\r\nEpoch[9] Validation-accuracy=0.969500\r\n```\r\n\r\n== examples/sparse/matrix_factorization/train.pl ==\r\n\r\n```\r\nEpoch[2] Batch [60300]\tSpeed: 50291.13 samples/sec\tTrain-mse=0.706833\r\nEpoch[2] Batch [60400]\tSpeed: 54047.43 samples/sec\tTrain-mse=0.723078\r\nEpoch[2] Batch [60500]\tSpeed: 53646.70 samples/sec\tTrain-mse=0.741219\r\nEpoch[2] Batch [60600]\tSpeed: 52929.93 samples/sec\tTrain-mse=0.706861\r\nEpoch[2] Batch [60700]\tSpeed: 53583.14 samples/sec\tTrain-mse=0.734509\r\nEpoch[2] Batch [60800]\tSpeed: 50907.01 samples/sec\tTrain-mse=0.735880\r\nEpoch[2] Batch [60900]\tSpeed: 39899.38 samples/sec\tTrain-mse=0.758780\r\nEpoch[2] Batch [61000]\tSpeed: 48115.77 samples/sec\tTrain-mse=0.693772\r\nEpoch[2] Batch [61100]\tSpeed: 53833.52 samples/sec\tTrain-mse=0.714911\r\nEpoch[2] Batch [61200]\tSpeed: 53998.88 samples/sec\tTrain-mse=0.731971\r\nEpoch[2] Batch [61300]\tSpeed: 51153.75 samples/sec\tTrain-mse=0.732873\r\nEpoch[2] Batch [61400]\tSpeed: 51454.19 samples/sec\tTrain-mse=0.715944\r\nEpoch[2] Batch [61500]\tSpeed: 51353.83 samples/sec\tTrain-mse=0.715877\r\nEpoch[2] Batch [61600]\tSpeed: 53121.93 samples/sec\tTrain-mse=0.703896\r\nEpoch[2] Batch [61700]\tSpeed: 53345.31 samples/sec\tTrain-mse=0.700082\r\nEpoch[2] Batch [61800]\tSpeed: 48247.09 samples/sec\tTrain-mse=0.734545\r\nEpoch[2] Batch [61900]\tSpeed: 42918.29 samples/sec\tTrain-mse=0.714020\r\nEpoch[2] Batch [62000]\tSpeed: 49330.02 samples/sec\tTrain-mse=0.722819\r\nEpoch[2] Batch [62100]\tSpeed: 53999.32 samples/sec\tTrain-mse=0.736258\r\nEpoch[2] Batch [62200]\tSpeed: 51953.96 samples/sec\tTrain-mse=0.737786\r\nEpoch[2] Batch [62300]\tSpeed: 51416.39 samples/sec\tTrain-mse=0.698692\r\nEpoch[2] Batch [62400]\tSpeed: 53206.32 samples/sec\tTrain-mse=0.716579\r\nEpoch[2] Batch [62500]\tSpeed: 52938.28 samples/sec\tTrain-mse=0.733243\r\nPreparing data iterators for ./data/ml-10M100K/r1.train ... \r\nPreparing data iterators for ./data/ml-10M100K/r1.test ... \r\nTraining started ...\r\nepoch 0, eval MSE = 0.99958598613739 \r\nepoch 1, eval MSE = 1.03603255748749 \r\nepoch 2, eval MSE = 1.07017529010773 \r\nTraining completed.\r\n```\r\n\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "794693489",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20852,
        "pr_file": "perl-package/AI-MXNet/lib/AI/MXNet/Metric.pm",
        "discussion_id": "793919904",
        "commented_code": "@@ -79,7 +79,7 @@ use overload '\"\"' => sub {\n has 'name'       => (is => 'rw', isa => 'Str');\n has 'num'        => (is => 'rw', isa => 'Int');\n has 'num_inst'   => (is => 'rw', isa => 'Maybe[Int|ArrayRef[Int]]');\n-has 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]]');\n+has 'sum_metric' => (is => 'rw', isa => 'Maybe[Num|ArrayRef[Num]|PDL]');",
        "comment_created_at": "2022-01-28T17:06:01+00:00",
        "comment_author": "sergeykolychev",
        "comment_body": "Looks good",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "688373879",
    "pr_number": 20514,
    "pr_file": "src/operator/quantization/quantize_v2-inl.h",
    "created_at": "2021-08-13T09:23:55+00:00",
    "commented_code": "int out_type;\n  dmlc::optional<float> min_calib_range;\n  dmlc::optional<float> max_calib_range;\n  dmlc::optional<bool> shifted;\n  dmlc::optional<bool> shifted_output;",
    "repo_full_name": "apache/mxnet",
    "discussion_comments": [
      {
        "comment_id": "688373879",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20514,
        "pr_file": "src/operator/quantization/quantize_v2-inl.h",
        "discussion_id": "688373879",
        "commented_code": "@@ -41,7 +41,7 @@ struct QuantizeV2Param : public dmlc::Parameter<QuantizeV2Param> {\n   int out_type;\n   dmlc::optional<float> min_calib_range;\n   dmlc::optional<float> max_calib_range;\n-  dmlc::optional<bool> shifted;\n+  dmlc::optional<bool> shifted_output;",
        "comment_created_at": "2021-08-13T09:23:55+00:00",
        "comment_author": "mozga-intel",
        "comment_body": "The dmlc::optional<T> is found a use for representing a value that may or may not be present. The std::optional was introduced in C++17, so it means that we can try to replace this one by a new one. Unfortunately, there is a bunch of branches have not supported C++17 yet.  An exceptation is the master branch that supports c++17, well, maybe is worth making an internal wrapper. On second thoughts, it could be looks like: [proposition]\r\n```cpp\r\n#define MXNET_HAS_OPTIONAL() 0\r\n#if __cplusplus >= 201703L\r\n#  ifdef __has_include\r\n#    if __has_include(<optional>)\r\n#      include <optional>\r\n#      undef MXNET_HAS_OPTIONAL\r\n#      define MXNET_HAS_OPTIONAL() 1\r\n#    endif\r\n#  endif\r\n#endif\r\n\r\n#if MXNET_HAS_OPTIONAL()\r\n#warning \"optional\"\r\n// Please use std::optional<T>\r\n#else\r\n#warning \"no optional\"\r\n// Please use dmlc::optional<T>\r\n#endif\r\n```\r\nWhat are the advantages of using it?",
        "pr_file_module": null
      },
      {
        "comment_id": "688415411",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20514,
        "pr_file": "src/operator/quantization/quantize_v2-inl.h",
        "discussion_id": "688373879",
        "commented_code": "@@ -41,7 +41,7 @@ struct QuantizeV2Param : public dmlc::Parameter<QuantizeV2Param> {\n   int out_type;\n   dmlc::optional<float> min_calib_range;\n   dmlc::optional<float> max_calib_range;\n-  dmlc::optional<bool> shifted;\n+  dmlc::optional<bool> shifted_output;",
        "comment_created_at": "2021-08-13T10:35:38+00:00",
        "comment_author": "sfraczek",
        "comment_body": "I think v1.x is more strongly backward compatibility oriented. I think it would be better to keep such change only to master. dmlc::optional is used in a lot of places as well as other functions so it might be hard to justify rewriting parts of it.  I don't know what are advantages of either implementations. \r\nAlso, in this PR I would prefer to keep consistency with what is already used in operators.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "763881978",
    "pr_number": 20745,
    "pr_file": "src/operator/tensor/indexing_op.cc",
    "created_at": "2021-12-07T11:04:38+00:00",
    "commented_code": "}\n};\n\ntemplate <bool clip = true>\nstruct TakeNonzeroAxisCPU {\n  /*!\n   * \\brief Map function for take operator\n   * \\param i                 global thread id\n   * \\param out_data          ptr to output buffer\n   * \\param in_data           ptr to input buffer\n   * \\param idx               ptr to indices buffer\n   * \\param outer_dim_stride  stride of dimension before axis\n   * \\param axis_dim_stride   stride of axis dimension\n   * \\param idx_size          size of the indices tensor\n   * \\param axis_dim          dim size of the axis dimension\n   * \\param axis              axis id\n   */\n  template <typename DType, typename IType>\n  MSHADOW_XINLINE static void Map(index_t i,\n                                  DType* out_data,\n                                  const DType* in_data,\n                                  const IType* indices,\n                                  const index_t outer_dim_stride,\n                                  const index_t axis_dim_stride,\n                                  const int idx_size,\n                                  const int axis_dim,\n                                  const int axis) {\n    for (index_t j = 0; j < static_cast<index_t>(idx_size); ++j) {\n      int index = indices[j];\n      if (clip) {\n        index = (index < 0) ? 0 : index;",
    "repo_full_name": "apache/mxnet",
    "discussion_comments": [
      {
        "comment_id": "763881978",
        "repo_full_name": "apache/mxnet",
        "pr_number": 20745,
        "pr_file": "src/operator/tensor/indexing_op.cc",
        "discussion_id": "763881978",
        "commented_code": "@@ -60,6 +60,51 @@ struct TakeZeroAxisCPU {\n   }\n };\n \n+template <bool clip = true>\n+struct TakeNonzeroAxisCPU {\n+  /*!\n+   * \\brief Map function for take operator\n+   * \\param i                 global thread id\n+   * \\param out_data          ptr to output buffer\n+   * \\param in_data           ptr to input buffer\n+   * \\param idx               ptr to indices buffer\n+   * \\param outer_dim_stride  stride of dimension before axis\n+   * \\param axis_dim_stride   stride of axis dimension\n+   * \\param idx_size          size of the indices tensor\n+   * \\param axis_dim          dim size of the axis dimension\n+   * \\param axis              axis id\n+   */\n+  template <typename DType, typename IType>\n+  MSHADOW_XINLINE static void Map(index_t i,\n+                                  DType* out_data,\n+                                  const DType* in_data,\n+                                  const IType* indices,\n+                                  const index_t outer_dim_stride,\n+                                  const index_t axis_dim_stride,\n+                                  const int idx_size,\n+                                  const int axis_dim,\n+                                  const int axis) {\n+    for (index_t j = 0; j < static_cast<index_t>(idx_size); ++j) {\n+      int index = indices[j];\n+      if (clip) {\n+        index = (index < 0) ? 0 : index;",
        "comment_created_at": "2021-12-07T11:04:38+00:00",
        "comment_author": "bartekkuncer",
        "comment_body": "Maybe use max(0,index)?",
        "pr_file_module": null
      }
    ]
  }
]