[
  {
    "discussion_id": "2225544384",
    "pr_number": 17585,
    "pr_file": "packages/workflow/src/workflow.ts",
    "created_at": "2025-07-23T13:04:58+00:00",
    "commented_code": "visited.add(nodeName);\n \n-\t\t\t// Check all connection types for this node\n-\t\t\tconst allConnectionTypes = [\n-\t\t\t\tNodeConnectionTypes.Main,\n-\t\t\t\tNodeConnectionTypes.AiTool,\n-\t\t\t\tNodeConnectionTypes.AiMemory,\n-\t\t\t\tNodeConnectionTypes.AiDocument,\n-\t\t\t\tNodeConnectionTypes.AiVectorStore,\n-\t\t\t];\n-\n-\t\t\tfor (const connectionType of allConnectionTypes) {\n+\t\t\t// Get connection types that actually exist in this workflow\n+\t\t\tconst connectionTypes = new Set<NodeConnectionType>();",
    "repo_full_name": "n8n-io/n8n",
    "discussion_comments": [
      {
        "comment_id": "2225544384",
        "repo_full_name": "n8n-io/n8n",
        "pr_number": 17585,
        "pr_file": "packages/workflow/src/workflow.ts",
        "discussion_id": "2225544384",
        "commented_code": "@@ -1032,16 +1032,24 @@ export class Workflow {\n \n \t\t\tvisited.add(nodeName);\n \n-\t\t\t// Check all connection types for this node\n-\t\t\tconst allConnectionTypes = [\n-\t\t\t\tNodeConnectionTypes.Main,\n-\t\t\t\tNodeConnectionTypes.AiTool,\n-\t\t\t\tNodeConnectionTypes.AiMemory,\n-\t\t\t\tNodeConnectionTypes.AiDocument,\n-\t\t\t\tNodeConnectionTypes.AiVectorStore,\n-\t\t\t];\n-\n-\t\t\tfor (const connectionType of allConnectionTypes) {\n+\t\t\t// Get connection types that actually exist in this workflow\n+\t\t\tconst connectionTypes = new Set<NodeConnectionType>();",
        "comment_created_at": "2025-07-23T13:04:58+00:00",
        "comment_author": "cubic-dev-ai[bot]",
        "comment_body": "<!-- metadata:{\"confidence\":8,\"steps\":[{\"text\":\"\",\"toolCalls\":[{\"args\":{\"command\":\"grep -n \\\"hasPath(fromNodeName\\\" -n packages/workflow/src/workflow.ts\"},\"toolName\":\"executeCommand\"}]},{\"text\":\"\",\"toolCalls\":[{\"args\":{\"command\":\"grep -n -A5 -B5 \\\"connectionTypes = new Set\\\" packages/workflow/src/workflow.ts\"},\"toolName\":\"executeCommand\"}]},{\"text\":\"\",\"toolCalls\":[{\"args\":{\"command\":\"grep -n -B5 -A10 \\\"visited.add(nodeName);\\\" packages/workflow/src/workflow.ts\"},\"toolName\":\"executeCommand\"}]},{\"text\":\"\",\"toolCalls\":[{\"args\":{\"command\":\"grep -R \\\"export type NodeConnectionType\\\" -n packages/workflow/src | head\"},\"toolName\":\"executeCommand\"}]},{\"text\":\"\",\"toolCalls\":[{\"args\":{\"command\":\"grep -n \\\"enum NodeConnectionTypes\\\" -R packages/workflow/src | head\"},\"toolName\":\"executeCommand\"}]}]} -->\n`connectionTypes` is recomputed on every BFS iteration, iterating over the entire connection map each time and causing avoidable O(N\u00b2) overhead; compute it once outside the while-loop instead.\n\n<details>\n<summary>Prompt for AI agents</summary>\n\n```\nAddress the following comment on packages/workflow/src/workflow.ts at line 1036:\n\n<comment>`connectionTypes` is recomputed on every BFS iteration, iterating over the entire connection map each time and causing avoidable O(N\u00b2) overhead; compute it once outside the while-loop instead.</comment>\n\n<file context>\n@@ -1032,16 +1032,24 @@ export class Workflow {\n \n \t\t\tvisited.add(nodeName);\n \n-\t\t\t// Check all connection types for this node\n-\t\t\tconst allConnectionTypes = [\n-\t\t\t\tNodeConnectionTypes.Main,\n-\t\t\t\tNodeConnectionTypes.AiTool,\n-\t\t\t\tNodeConnectionTypes.AiMemory,\n-\t\t\t\tNodeConnectionTypes.AiDocument,\n</file context>\n```\n\n</details>",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2221466602",
    "pr_number": 17404,
    "pr_file": "packages/cli/src/evaluation.ee/test-runner/test-runner.service.ee.ts",
    "created_at": "2025-07-22T07:18:25+00:00",
    "commented_code": "return triggerOutput;\n \t}\n \n+\tprivate getEvaluationData(\n+\t\texecution: IRun,\n+\t\tworkflow: IWorkflowBase,\n+\t\toperation: 'setInputs' | 'setOutputs',\n+\t): IDataObject {\n+\t\tconst evalNodes = TestRunnerService.getEvaluationNodes(workflow, operation);\n+\n+\t\treturn evalNodes.reduce((accu: IDataObject, node: INode) => {\n+\t\t\tconst runs = execution.data.resultData.runData[node.name];\n+\t\t\tconst data = runs?.[0]?.data?.[NodeConnectionTypes.Main]?.[0]?.[0]?.evaluationData ?? {};\n+\n+\t\t\treturn {\n+\t\t\t\t...accu,\n+\t\t\t\t...data,\n+\t\t\t};\n+\t\t}, {} as IDataObject);",
    "repo_full_name": "n8n-io/n8n",
    "discussion_comments": [
      {
        "comment_id": "2221466602",
        "repo_full_name": "n8n-io/n8n",
        "pr_number": 17404,
        "pr_file": "packages/cli/src/evaluation.ee/test-runner/test-runner.service.ee.ts",
        "discussion_id": "2221466602",
        "commented_code": "@@ -401,6 +414,24 @@ export class TestRunnerService {\n \t\treturn triggerOutput;\n \t}\n \n+\tprivate getEvaluationData(\n+\t\texecution: IRun,\n+\t\tworkflow: IWorkflowBase,\n+\t\toperation: 'setInputs' | 'setOutputs',\n+\t): IDataObject {\n+\t\tconst evalNodes = TestRunnerService.getEvaluationNodes(workflow, operation);\n+\n+\t\treturn evalNodes.reduce((accu: IDataObject, node: INode) => {\n+\t\t\tconst runs = execution.data.resultData.runData[node.name];\n+\t\t\tconst data = runs?.[0]?.data?.[NodeConnectionTypes.Main]?.[0]?.[0]?.evaluationData ?? {};\n+\n+\t\t\treturn {\n+\t\t\t\t...accu,\n+\t\t\t\t...data,\n+\t\t\t};\n+\t\t}, {} as IDataObject);",
        "comment_created_at": "2025-07-22T07:18:25+00:00",
        "comment_author": "ivov",
        "comment_body": "1. `reduce` takes a [generic](https://share.cleanshot.com/hs6RTy69) to type the accumulator, so no need to type it in the first arg to the callback and in the second arg.\r\n2. The second arg to the `reduce` callback is inferrable from `evalNodes`.\r\n3. Can we avoid using `IDataObject` please?\r\n4. How much data is `evaluationData`? If not little, I typically avoid using `reduce` with spreads like this as it can generate a lot of garbage to collect, as opposed to mutating the accumulator.",
        "pr_file_module": null
      },
      {
        "comment_id": "2222586865",
        "repo_full_name": "n8n-io/n8n",
        "pr_number": 17404,
        "pr_file": "packages/cli/src/evaluation.ee/test-runner/test-runner.service.ee.ts",
        "discussion_id": "2221466602",
        "commented_code": "@@ -401,6 +414,24 @@ export class TestRunnerService {\n \t\treturn triggerOutput;\n \t}\n \n+\tprivate getEvaluationData(\n+\t\texecution: IRun,\n+\t\tworkflow: IWorkflowBase,\n+\t\toperation: 'setInputs' | 'setOutputs',\n+\t): IDataObject {\n+\t\tconst evalNodes = TestRunnerService.getEvaluationNodes(workflow, operation);\n+\n+\t\treturn evalNodes.reduce((accu: IDataObject, node: INode) => {\n+\t\t\tconst runs = execution.data.resultData.runData[node.name];\n+\t\t\tconst data = runs?.[0]?.data?.[NodeConnectionTypes.Main]?.[0]?.[0]?.evaluationData ?? {};\n+\n+\t\t\treturn {\n+\t\t\t\t...accu,\n+\t\t\t\t...data,\n+\t\t\t};\n+\t\t}, {} as IDataObject);",
        "comment_created_at": "2025-07-22T13:43:25+00:00",
        "comment_author": "mutdmour",
        "comment_body": "1. Will update once we agree on a type. That's good feedback.\r\n4. However much data the user deems important to record for evalutations.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2212455729",
    "pr_number": 14947,
    "pr_file": "packages/nodes-base/nodes/Kafka/KafkaTrigger.node.ts",
    "created_at": "2025-07-17T06:57:35+00:00",
    "commented_code": "if (useSchemaRegistry) {\n \t\t\t\t\t\ttry {\n-\t\t\t\t\t\t\tconst registry = new SchemaRegistry({ host: schemaRegistryUrl });\n+\t\t\t\t\t\t\tlet registry: SchemaRegistry;\n+\t\t\t\t\t\t\tif (schemaRegistryUsername && schemaRegistryPassword) {\n+\t\t\t\t\t\t\t\tregistry = new SchemaRegistry({",
    "repo_full_name": "n8n-io/n8n",
    "discussion_comments": [
      {
        "comment_id": "2212455729",
        "repo_full_name": "n8n-io/n8n",
        "pr_number": 14947,
        "pr_file": "packages/nodes-base/nodes/Kafka/KafkaTrigger.node.ts",
        "discussion_id": "2212455729",
        "commented_code": "@@ -259,7 +290,18 @@ export class KafkaTrigger implements INodeType {\n \n \t\t\t\t\tif (useSchemaRegistry) {\n \t\t\t\t\t\ttry {\n-\t\t\t\t\t\t\tconst registry = new SchemaRegistry({ host: schemaRegistryUrl });\n+\t\t\t\t\t\t\tlet registry: SchemaRegistry;\n+\t\t\t\t\t\t\tif (schemaRegistryUsername && schemaRegistryPassword) {\n+\t\t\t\t\t\t\t\tregistry = new SchemaRegistry({",
        "comment_created_at": "2025-07-17T06:57:35+00:00",
        "comment_author": "cubic-dev-ai[bot]",
        "comment_body": "<!-- metadata:{\"confidence\":7,\"steps\":[]} -->\nA new SchemaRegistry instance is created inside the eachMessage loop, resulting in a fresh connection object for every single Kafka message. This imposes avoidable CPU and memory overhead and can quickly degrade performance under high-throughput workloads. Instantiate the registry once (e.g., before consumer.run) and reuse it across messages.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2217937507",
    "pr_number": 17423,
    "pr_file": "packages/@n8n/ai-workflow-builder.ee/src/tools/engines/node-search-engine.ts",
    "created_at": "2025-07-20T19:56:29+00:00",
    "commented_code": "+import type { INodeTypeDescription, NodeConnectionType } from 'n8n-workflow';\n+import { NodeConnectionTypes } from 'n8n-workflow';\n+\n+import type { NodeSearchResult } from '../../types/nodes';\n+\n+/**\n+ * Scoring weights for different match types\n+ */\n+export const SCORE_WEIGHTS = {\n+\tNAME_CONTAINS: 10,\n+\tDISPLAY_NAME_CONTAINS: 8,\n+\tDESCRIPTION_CONTAINS: 5,\n+\tALIAS_CONTAINS: 8,\n+\tNAME_EXACT: 20,\n+\tDISPLAY_NAME_EXACT: 15,\n+\tCONNECTION_EXACT: 100,\n+\tCONNECTION_IN_EXPRESSION: 50,\n+} as const;\n+\n+/**\n+ * Pure business logic for searching nodes\n+ * Separated from tool infrastructure for better testability\n+ */\n+export class NodeSearchEngine {\n+\tconstructor(private readonly nodeTypes: INodeTypeDescription[]) {}\n+\n+\t/**\n+\t * Search nodes by name, display name, or description\n+\t * @param query - The search query string\n+\t * @param limit - Maximum number of results to return\n+\t * @returns Array of matching nodes sorted by relevance\n+\t */\n+\tsearchByName(query: string, limit: number = 20): NodeSearchResult[] {\n+\t\tconst normalizedQuery = query.toLowerCase();\n+\t\tconst results: NodeSearchResult[] = [];\n+\n+\t\tfor (const nodeType of this.nodeTypes) {\n+\t\t\ttry {\n+\t\t\t\tconst score = this.calculateNameScore(nodeType, normalizedQuery);\n+\t\t\t\tif (score > 0) {\n+\t\t\t\t\tresults.push(this.createSearchResult(nodeType, score));\n+\t\t\t\t}\n+\t\t\t} catch (error) {\n+\t\t\t\t// Ignore errors for now\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn this.sortAndLimit(results, limit);\n+\t}\n+\n+\t/**\n+\t * Search for sub-nodes that output a specific connection type\n+\t * @param connectionType - The connection type to search for\n+\t * @param limit - Maximum number of results\n+\t * @param nameFilter - Optional name filter\n+\t * @returns Array of matching sub-nodes\n+\t */\n+\tsearchByConnectionType(\n+\t\tconnectionType: NodeConnectionType,\n+\t\tlimit: number = 20,\n+\t\tnameFilter?: string,\n+\t): NodeSearchResult[] {\n+\t\tconst results: NodeSearchResult[] = [];\n+\t\tconst normalizedFilter = nameFilter?.toLowerCase();\n+\n+\t\tfor (const nodeType of this.nodeTypes) {\n+\t\t\ttry {\n+\t\t\t\tconst connectionScore = this.getConnectionScore(nodeType, connectionType);\n+\t\t\t\tif (connectionScore > 0) {\n+\t\t\t\t\t// Apply name filter if provided\n+\t\t\t\t\tconst nameScore = normalizedFilter\n+\t\t\t\t\t\t? this.calculateNameScore(nodeType, normalizedFilter)\n+\t\t\t\t\t\t: 0;\n+\n+\t\t\t\t\tif (!normalizedFilter || nameScore > 0) {\n+\t\t\t\t\t\tconst totalScore = connectionScore + nameScore;\n+\t\t\t\t\t\tresults.push(this.createSearchResult(nodeType, totalScore));\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t} catch (error) {\n+\t\t\t\t// Ignore errors for now\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn this.sortAndLimit(results, limit);\n+\t}\n+\n+\t/**\n+\t * Format search results for tool output\n+\t * @param result - Single search result\n+\t * @returns XML-formatted string\n+\t */\n+\tformatResult(result: NodeSearchResult): string {\n+\t\treturn `\n+\t\t<node>\n+\t\t\t<node_name>${result.name}</node_name>\n+\t\t\t<node_description>${result.description}</node_description>\n+\t\t\t<node_inputs>${typeof result.inputs === 'object' ? JSON.stringify(result.inputs) : result.inputs}</node_inputs>\n+\t\t\t<node_outputs>${typeof result.outputs === 'object' ? JSON.stringify(result.outputs) : result.outputs}</node_outputs>\n+\t\t</node>`;\n+\t}\n+\n+\t/**\n+\t * Calculate score based on name matches\n+\t * @param nodeType - Node type to score\n+\t * @param normalizedQuery - Lowercase search query\n+\t * @returns Numeric score\n+\t */\n+\tprivate calculateNameScore(nodeType: INodeTypeDescription, normalizedQuery: string): number {\n+\t\tlet score = 0;\n+\n+\t\t// Check name match\n+\t\tif (nodeType.name.toLowerCase().includes(normalizedQuery)) {",
    "repo_full_name": "n8n-io/n8n",
    "discussion_comments": [
      {
        "comment_id": "2217937507",
        "repo_full_name": "n8n-io/n8n",
        "pr_number": 17423,
        "pr_file": "packages/@n8n/ai-workflow-builder.ee/src/tools/engines/node-search-engine.ts",
        "discussion_id": "2217937507",
        "commented_code": "@@ -0,0 +1,215 @@\n+import type { INodeTypeDescription, NodeConnectionType } from 'n8n-workflow';\n+import { NodeConnectionTypes } from 'n8n-workflow';\n+\n+import type { NodeSearchResult } from '../../types/nodes';\n+\n+/**\n+ * Scoring weights for different match types\n+ */\n+export const SCORE_WEIGHTS = {\n+\tNAME_CONTAINS: 10,\n+\tDISPLAY_NAME_CONTAINS: 8,\n+\tDESCRIPTION_CONTAINS: 5,\n+\tALIAS_CONTAINS: 8,\n+\tNAME_EXACT: 20,\n+\tDISPLAY_NAME_EXACT: 15,\n+\tCONNECTION_EXACT: 100,\n+\tCONNECTION_IN_EXPRESSION: 50,\n+} as const;\n+\n+/**\n+ * Pure business logic for searching nodes\n+ * Separated from tool infrastructure for better testability\n+ */\n+export class NodeSearchEngine {\n+\tconstructor(private readonly nodeTypes: INodeTypeDescription[]) {}\n+\n+\t/**\n+\t * Search nodes by name, display name, or description\n+\t * @param query - The search query string\n+\t * @param limit - Maximum number of results to return\n+\t * @returns Array of matching nodes sorted by relevance\n+\t */\n+\tsearchByName(query: string, limit: number = 20): NodeSearchResult[] {\n+\t\tconst normalizedQuery = query.toLowerCase();\n+\t\tconst results: NodeSearchResult[] = [];\n+\n+\t\tfor (const nodeType of this.nodeTypes) {\n+\t\t\ttry {\n+\t\t\t\tconst score = this.calculateNameScore(nodeType, normalizedQuery);\n+\t\t\t\tif (score > 0) {\n+\t\t\t\t\tresults.push(this.createSearchResult(nodeType, score));\n+\t\t\t\t}\n+\t\t\t} catch (error) {\n+\t\t\t\t// Ignore errors for now\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn this.sortAndLimit(results, limit);\n+\t}\n+\n+\t/**\n+\t * Search for sub-nodes that output a specific connection type\n+\t * @param connectionType - The connection type to search for\n+\t * @param limit - Maximum number of results\n+\t * @param nameFilter - Optional name filter\n+\t * @returns Array of matching sub-nodes\n+\t */\n+\tsearchByConnectionType(\n+\t\tconnectionType: NodeConnectionType,\n+\t\tlimit: number = 20,\n+\t\tnameFilter?: string,\n+\t): NodeSearchResult[] {\n+\t\tconst results: NodeSearchResult[] = [];\n+\t\tconst normalizedFilter = nameFilter?.toLowerCase();\n+\n+\t\tfor (const nodeType of this.nodeTypes) {\n+\t\t\ttry {\n+\t\t\t\tconst connectionScore = this.getConnectionScore(nodeType, connectionType);\n+\t\t\t\tif (connectionScore > 0) {\n+\t\t\t\t\t// Apply name filter if provided\n+\t\t\t\t\tconst nameScore = normalizedFilter\n+\t\t\t\t\t\t? this.calculateNameScore(nodeType, normalizedFilter)\n+\t\t\t\t\t\t: 0;\n+\n+\t\t\t\t\tif (!normalizedFilter || nameScore > 0) {\n+\t\t\t\t\t\tconst totalScore = connectionScore + nameScore;\n+\t\t\t\t\t\tresults.push(this.createSearchResult(nodeType, totalScore));\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t} catch (error) {\n+\t\t\t\t// Ignore errors for now\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn this.sortAndLimit(results, limit);\n+\t}\n+\n+\t/**\n+\t * Format search results for tool output\n+\t * @param result - Single search result\n+\t * @returns XML-formatted string\n+\t */\n+\tformatResult(result: NodeSearchResult): string {\n+\t\treturn `\n+\t\t<node>\n+\t\t\t<node_name>${result.name}</node_name>\n+\t\t\t<node_description>${result.description}</node_description>\n+\t\t\t<node_inputs>${typeof result.inputs === 'object' ? JSON.stringify(result.inputs) : result.inputs}</node_inputs>\n+\t\t\t<node_outputs>${typeof result.outputs === 'object' ? JSON.stringify(result.outputs) : result.outputs}</node_outputs>\n+\t\t</node>`;\n+\t}\n+\n+\t/**\n+\t * Calculate score based on name matches\n+\t * @param nodeType - Node type to score\n+\t * @param normalizedQuery - Lowercase search query\n+\t * @returns Numeric score\n+\t */\n+\tprivate calculateNameScore(nodeType: INodeTypeDescription, normalizedQuery: string): number {\n+\t\tlet score = 0;\n+\n+\t\t// Check name match\n+\t\tif (nodeType.name.toLowerCase().includes(normalizedQuery)) {",
        "comment_created_at": "2025-07-20T19:56:29+00:00",
        "comment_author": "burivuhster",
        "comment_body": "We may pre-calculate lowercased name and other strings when we load node types, and then use them here",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2179816996",
    "pr_number": 16891,
    "pr_file": "packages/frontend/editor-ui/src/stores/focusPanel.store.ts",
    "created_at": "2025-07-02T11:29:50+00:00",
    "commented_code": "import { STORES } from '@n8n/stores';\n import { defineStore } from 'pinia';\n-import { ref } from 'vue';\n+import { computed, ref } from 'vue';\n+import get from 'lodash/get';\n \n-import type { INodeProperties } from 'n8n-workflow';\n+import { type NodeParameterValueType, type INode, type INodeProperties } from 'n8n-workflow';\n+import { useWorkflowsStore } from './workflows.store';\n \n type FocusedNodeParameter = {\n-\tnodeName: string;\n+\tnodeId: string;\n \tparameter: INodeProperties;\n \tparameterPath: string;\n-\tvalue: string;\n+};\n+\n+export type RichFocusedNodeParameter = FocusedNodeParameter & {\n+\tnode: INode;\n+\tvalue: NodeParameterValueType;\n };\n \n export const useFocusPanelStore = defineStore(STORES.FOCUS_PANEL, () => {\n+\tconst workflowsStore = useWorkflowsStore();\n+\n \tconst focusPanelActive = ref(false);\n-\tconst focusedNodeParameters = ref<FocusedNodeParameter[]>([]);\n+\tconst _focusedNodeParameters = ref<FocusedNodeParameter[]>([]);\n+\n+\t// An unenriched parameter indicates a missing nodeId\n+\tconst focusedNodeParameters = computed<Array<RichFocusedNodeParameter | FocusedNodeParameter>>(",
    "repo_full_name": "n8n-io/n8n",
    "discussion_comments": [
      {
        "comment_id": "2179816996",
        "repo_full_name": "n8n-io/n8n",
        "pr_number": 16891,
        "pr_file": "packages/frontend/editor-ui/src/stores/focusPanel.store.ts",
        "discussion_id": "2179816996",
        "commented_code": "@@ -1,22 +1,45 @@\n import { STORES } from '@n8n/stores';\n import { defineStore } from 'pinia';\n-import { ref } from 'vue';\n+import { computed, ref } from 'vue';\n+import get from 'lodash/get';\n \n-import type { INodeProperties } from 'n8n-workflow';\n+import { type NodeParameterValueType, type INode, type INodeProperties } from 'n8n-workflow';\n+import { useWorkflowsStore } from './workflows.store';\n \n type FocusedNodeParameter = {\n-\tnodeName: string;\n+\tnodeId: string;\n \tparameter: INodeProperties;\n \tparameterPath: string;\n-\tvalue: string;\n+};\n+\n+export type RichFocusedNodeParameter = FocusedNodeParameter & {\n+\tnode: INode;\n+\tvalue: NodeParameterValueType;\n };\n \n export const useFocusPanelStore = defineStore(STORES.FOCUS_PANEL, () => {\n+\tconst workflowsStore = useWorkflowsStore();\n+\n \tconst focusPanelActive = ref(false);\n-\tconst focusedNodeParameters = ref<FocusedNodeParameter[]>([]);\n+\tconst _focusedNodeParameters = ref<FocusedNodeParameter[]>([]);\n+\n+\t// An unenriched parameter indicates a missing nodeId\n+\tconst focusedNodeParameters = computed<Array<RichFocusedNodeParameter | FocusedNodeParameter>>(",
        "comment_created_at": "2025-07-02T11:29:50+00:00",
        "comment_author": "MiloradFilipovic",
        "comment_body": "I wonder if there is more efficient way to get parameter value here instead of iterating over parameters and getting full node from the store in every iteration.",
        "pr_file_module": null
      },
      {
        "comment_id": "2179838196",
        "repo_full_name": "n8n-io/n8n",
        "pr_number": 16891,
        "pr_file": "packages/frontend/editor-ui/src/stores/focusPanel.store.ts",
        "discussion_id": "2179816996",
        "commented_code": "@@ -1,22 +1,45 @@\n import { STORES } from '@n8n/stores';\n import { defineStore } from 'pinia';\n-import { ref } from 'vue';\n+import { computed, ref } from 'vue';\n+import get from 'lodash/get';\n \n-import type { INodeProperties } from 'n8n-workflow';\n+import { type NodeParameterValueType, type INode, type INodeProperties } from 'n8n-workflow';\n+import { useWorkflowsStore } from './workflows.store';\n \n type FocusedNodeParameter = {\n-\tnodeName: string;\n+\tnodeId: string;\n \tparameter: INodeProperties;\n \tparameterPath: string;\n-\tvalue: string;\n+};\n+\n+export type RichFocusedNodeParameter = FocusedNodeParameter & {\n+\tnode: INode;\n+\tvalue: NodeParameterValueType;\n };\n \n export const useFocusPanelStore = defineStore(STORES.FOCUS_PANEL, () => {\n+\tconst workflowsStore = useWorkflowsStore();\n+\n \tconst focusPanelActive = ref(false);\n-\tconst focusedNodeParameters = ref<FocusedNodeParameter[]>([]);\n+\tconst _focusedNodeParameters = ref<FocusedNodeParameter[]>([]);\n+\n+\t// An unenriched parameter indicates a missing nodeId\n+\tconst focusedNodeParameters = computed<Array<RichFocusedNodeParameter | FocusedNodeParameter>>(",
        "comment_created_at": "2025-07-02T11:41:22+00:00",
        "comment_author": "dariacodes",
        "comment_body": "In P0 we will only have one focused parameter. Maybe in P1, where we're gonna introduce tabs, we could update this to have `active` property and get the full node only for it. What do you think?",
        "pr_file_module": null
      }
    ]
  }
]