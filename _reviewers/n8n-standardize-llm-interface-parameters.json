[
  {
    "discussion_id": "2216132189",
    "pr_number": 17423,
    "pr_file": "packages/@n8n/ai-workflow-builder.ee/src/ai-workflow-builder-agent.service.ts",
    "created_at": "2025-07-18T14:07:16+00:00",
    "commented_code": "+import type { BaseChatModel } from '@langchain/core/language_models/chat_models';\n+import { LangChainTracer } from '@langchain/core/tracers/tracer_langchain';\n+import { MemorySaver } from '@langchain/langgraph';\n+import { Logger } from '@n8n/backend-common';\n+import { Service } from '@n8n/di';\n+import { AiAssistantClient } from '@n8n_io/ai-assistant-sdk';\n+import { Client } from 'langsmith';\n+import { INodeTypes } from 'n8n-workflow';\n+import type { IUser, INodeTypeDescription, IRunExecutionData } from 'n8n-workflow';\n+\n+import { LLMServiceError } from './errors';\n+import { anthropicClaudeSonnet4, gpt41mini } from './llm-config';\n+import { WorkflowBuilderAgent, type ChatPayload } from './workflow-builder-agent';\n+\n+@Service()\n+export class AiWorkflowBuilderService {\n+\tprivate parsedNodeTypes: INodeTypeDescription[] = [];\n+\n+\tprivate llmSimpleTask: BaseChatModel | undefined;\n+\n+\tprivate llmComplexTask: BaseChatModel | undefined;\n+\n+\tprivate tracingClient: Client | undefined;\n+\n+\tprivate checkpointer = new MemorySaver();\n+\n+\tprivate agent: WorkflowBuilderAgent | undefined;\n+\n+\tconstructor(\n+\t\tprivate readonly nodeTypes: INodeTypes,\n+\t\tprivate readonly client?: AiAssistantClient,\n+\t\tprivate readonly logger?: Logger,\n+\t) {\n+\t\tthis.parsedNodeTypes = this.getNodeTypes();\n+\t}\n+\n+\tprivate async setupModels(user?: IUser) {\n+\t\ttry {\n+\t\t\tif (this.llmSimpleTask && this.llmComplexTask) {\n+\t\t\t\treturn;\n+\t\t\t}\n+\n+\t\t\t// If client is provided, use it for API proxy\n+\t\t\tif (this.client && user) {\n+\t\t\t\tconst authHeaders = await this.client.generateApiProxyCredentials(user);\n+\t\t\t\t// Extract baseUrl from client configuration\n+\t\t\t\tconst baseUrl = this.client.getApiProxyBaseUrl();\n+\n+\t\t\t\tthis.llmSimpleTask = await gpt41mini({\n+\t\t\t\t\tbaseUrl: baseUrl + '/openai',\n+\t\t\t\t\t// When using api-proxy the key will be populated automatically, we just need to pass a placeholder\n+\t\t\t\t\tapiKey: '-',\n+\t\t\t\t\theaders: {\n+\t\t\t\t\t\tAuthorization: authHeaders.apiKey,\n+\t\t\t\t\t},\n+\t\t\t\t});\n+\t\t\t\tthis.llmComplexTask = await anthropicClaudeSonnet4({\n+\t\t\t\t\tbaseUrl: baseUrl + '/anthropic',\n+\t\t\t\t\tapiKey: '-',\n+\t\t\t\t\theaders: {\n+\t\t\t\t\t\tAuthorization: authHeaders.apiKey,\n+\t\t\t\t\t\t'anthropic-beta': 'prompt-caching-2024-07-31',\n+\t\t\t\t\t},\n+\t\t\t\t});\n+\n+\t\t\t\tthis.tracingClient = new Client({\n+\t\t\t\t\tapiKey: '-',\n+\t\t\t\t\tapiUrl: baseUrl + '/langsmith',\n+\t\t\t\t\tautoBatchTracing: false,\n+\t\t\t\t\ttraceBatchConcurrency: 1,\n+\t\t\t\t\tfetchOptions: {\n+\t\t\t\t\t\theaders: {\n+\t\t\t\t\t\t\tAuthorization: authHeaders.apiKey,\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t});\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t\t// If base URL is not set, use environment variables\n+\t\t\tthis.llmSimpleTask = await gpt41mini({\n+\t\t\t\tapiKey: process.env.N8N_AI_OPENAI_API_KEY ?? '',\n+\t\t\t});\n+\n+\t\t\tthis.llmComplexTask = await anthropicClaudeSonnet4({\n+\t\t\t\tapiKey: process.env.N8N_AI_ANTHROPIC_KEY ?? '',\n+\t\t\t\theaders: {\n+\t\t\t\t\t'anthropic-beta': 'prompt-caching-2024-07-31',\n+\t\t\t\t},\n+\t\t\t});\n+\t\t} catch (error) {\n+\t\t\tconst llmError = new LLMServiceError('Failed to setup LLM models', {\n+\t\t\t\tcause: error,\n+\t\t\t\ttags: {\n+\t\t\t\t\thasClient: !!this.client,\n+\t\t\t\t\thasUser: !!user,\n+\t\t\t\t},\n+\t\t\t});\n+\t\t\tthrow llmError;\n+\t\t}\n+\t}\n+\n+\tprivate getNodeTypes(): INodeTypeDescription[] {\n+\t\t// These types are ignored because they tend to cause issues when generating workflows\n+\t\tconst ignoredTypes = [\n+\t\t\t'@n8n/n8n-nodes-langchain.toolVectorStore',\n+\t\t\t'@n8n/n8n-nodes-langchain.documentGithubLoader',\n+\t\t\t'@n8n/n8n-nodes-langchain.code',\n+\t\t];\n+\t\tconst nodeTypesKeys = Object.keys(this.nodeTypes.getKnownTypes());\n+\n+\t\tconst nodeTypes = nodeTypesKeys\n+\t\t\t.filter((nodeType) => !ignoredTypes.includes(nodeType))\n+\t\t\t.map((nodeName) => {\n+\t\t\t\ttry {\n+\t\t\t\t\treturn { ...this.nodeTypes.getByNameAndVersion(nodeName).description, name: nodeName };\n+\t\t\t\t} catch (error) {\n+\t\t\t\t\tthis.logger?.error('Error getting node type', {\n+\t\t\t\t\t\tnodeName,\n+\t\t\t\t\t\terror: error instanceof Error ? error.message : 'Unknown error',\n+\t\t\t\t\t});\n+\t\t\t\t\treturn undefined;\n+\t\t\t\t}\n+\t\t\t})\n+\t\t\t.filter(\n+\t\t\t\t(nodeType): nodeType is INodeTypeDescription =>\n+\t\t\t\t\tnodeType !== undefined && nodeType.hidden !== true,\n+\t\t\t)\n+\t\t\t.map((nodeType, _index, nodeTypes: INodeTypeDescription[]) => {\n+\t\t\t\t// If the node type is a tool, we need to find the corresponding non-tool node type\n+\t\t\t\t// and merge the two node types to get the full node type description.\n+\t\t\t\tconst isTool = nodeType.name.endsWith('Tool');\n+\t\t\t\tif (!isTool) return nodeType;\n+\n+\t\t\t\tconst nonToolNode = nodeTypes.find((nt) => nt.name === nodeType.name.replace('Tool', ''));\n+\t\t\t\tif (!nonToolNode) return nodeType;\n+\n+\t\t\t\treturn {\n+\t\t\t\t\t...nonToolNode,\n+\t\t\t\t\t...nodeType,\n+\t\t\t\t};\n+\t\t\t});\n+\n+\t\treturn nodeTypes;\n+\t}\n+\n+\tprivate async getAgent(user?: IUser) {\n+\t\tif (!this.llmComplexTask || !this.llmSimpleTask) {\n+\t\t\tawait this.setupModels(user);\n+\t\t}\n+\n+\t\tif (!this.llmComplexTask || !this.llmSimpleTask) {\n+\t\t\tthrow new LLMServiceError('Failed to initialize LLM models');\n+\t\t}\n+\n+\t\tthis.agent ??= new WorkflowBuilderAgent({\n+\t\t\tparsedNodeTypes: this.parsedNodeTypes,\n+\t\t\t// We use Sonnet both for simple and complex tasks\n+\t\t\tllmSimpleTask: this.llmComplexTask,",
    "repo_full_name": "n8n-io/n8n",
    "discussion_comments": [
      {
        "comment_id": "2216132189",
        "repo_full_name": "n8n-io/n8n",
        "pr_number": 17423,
        "pr_file": "packages/@n8n/ai-workflow-builder.ee/src/ai-workflow-builder-agent.service.ts",
        "discussion_id": "2216132189",
        "commented_code": "@@ -0,0 +1,197 @@\n+import type { BaseChatModel } from '@langchain/core/language_models/chat_models';\n+import { LangChainTracer } from '@langchain/core/tracers/tracer_langchain';\n+import { MemorySaver } from '@langchain/langgraph';\n+import { Logger } from '@n8n/backend-common';\n+import { Service } from '@n8n/di';\n+import { AiAssistantClient } from '@n8n_io/ai-assistant-sdk';\n+import { Client } from 'langsmith';\n+import { INodeTypes } from 'n8n-workflow';\n+import type { IUser, INodeTypeDescription, IRunExecutionData } from 'n8n-workflow';\n+\n+import { LLMServiceError } from './errors';\n+import { anthropicClaudeSonnet4, gpt41mini } from './llm-config';\n+import { WorkflowBuilderAgent, type ChatPayload } from './workflow-builder-agent';\n+\n+@Service()\n+export class AiWorkflowBuilderService {\n+\tprivate parsedNodeTypes: INodeTypeDescription[] = [];\n+\n+\tprivate llmSimpleTask: BaseChatModel | undefined;\n+\n+\tprivate llmComplexTask: BaseChatModel | undefined;\n+\n+\tprivate tracingClient: Client | undefined;\n+\n+\tprivate checkpointer = new MemorySaver();\n+\n+\tprivate agent: WorkflowBuilderAgent | undefined;\n+\n+\tconstructor(\n+\t\tprivate readonly nodeTypes: INodeTypes,\n+\t\tprivate readonly client?: AiAssistantClient,\n+\t\tprivate readonly logger?: Logger,\n+\t) {\n+\t\tthis.parsedNodeTypes = this.getNodeTypes();\n+\t}\n+\n+\tprivate async setupModels(user?: IUser) {\n+\t\ttry {\n+\t\t\tif (this.llmSimpleTask && this.llmComplexTask) {\n+\t\t\t\treturn;\n+\t\t\t}\n+\n+\t\t\t// If client is provided, use it for API proxy\n+\t\t\tif (this.client && user) {\n+\t\t\t\tconst authHeaders = await this.client.generateApiProxyCredentials(user);\n+\t\t\t\t// Extract baseUrl from client configuration\n+\t\t\t\tconst baseUrl = this.client.getApiProxyBaseUrl();\n+\n+\t\t\t\tthis.llmSimpleTask = await gpt41mini({\n+\t\t\t\t\tbaseUrl: baseUrl + '/openai',\n+\t\t\t\t\t// When using api-proxy the key will be populated automatically, we just need to pass a placeholder\n+\t\t\t\t\tapiKey: '-',\n+\t\t\t\t\theaders: {\n+\t\t\t\t\t\tAuthorization: authHeaders.apiKey,\n+\t\t\t\t\t},\n+\t\t\t\t});\n+\t\t\t\tthis.llmComplexTask = await anthropicClaudeSonnet4({\n+\t\t\t\t\tbaseUrl: baseUrl + '/anthropic',\n+\t\t\t\t\tapiKey: '-',\n+\t\t\t\t\theaders: {\n+\t\t\t\t\t\tAuthorization: authHeaders.apiKey,\n+\t\t\t\t\t\t'anthropic-beta': 'prompt-caching-2024-07-31',\n+\t\t\t\t\t},\n+\t\t\t\t});\n+\n+\t\t\t\tthis.tracingClient = new Client({\n+\t\t\t\t\tapiKey: '-',\n+\t\t\t\t\tapiUrl: baseUrl + '/langsmith',\n+\t\t\t\t\tautoBatchTracing: false,\n+\t\t\t\t\ttraceBatchConcurrency: 1,\n+\t\t\t\t\tfetchOptions: {\n+\t\t\t\t\t\theaders: {\n+\t\t\t\t\t\t\tAuthorization: authHeaders.apiKey,\n+\t\t\t\t\t\t},\n+\t\t\t\t\t},\n+\t\t\t\t});\n+\t\t\t\treturn;\n+\t\t\t}\n+\t\t\t// If base URL is not set, use environment variables\n+\t\t\tthis.llmSimpleTask = await gpt41mini({\n+\t\t\t\tapiKey: process.env.N8N_AI_OPENAI_API_KEY ?? '',\n+\t\t\t});\n+\n+\t\t\tthis.llmComplexTask = await anthropicClaudeSonnet4({\n+\t\t\t\tapiKey: process.env.N8N_AI_ANTHROPIC_KEY ?? '',\n+\t\t\t\theaders: {\n+\t\t\t\t\t'anthropic-beta': 'prompt-caching-2024-07-31',\n+\t\t\t\t},\n+\t\t\t});\n+\t\t} catch (error) {\n+\t\t\tconst llmError = new LLMServiceError('Failed to setup LLM models', {\n+\t\t\t\tcause: error,\n+\t\t\t\ttags: {\n+\t\t\t\t\thasClient: !!this.client,\n+\t\t\t\t\thasUser: !!user,\n+\t\t\t\t},\n+\t\t\t});\n+\t\t\tthrow llmError;\n+\t\t}\n+\t}\n+\n+\tprivate getNodeTypes(): INodeTypeDescription[] {\n+\t\t// These types are ignored because they tend to cause issues when generating workflows\n+\t\tconst ignoredTypes = [\n+\t\t\t'@n8n/n8n-nodes-langchain.toolVectorStore',\n+\t\t\t'@n8n/n8n-nodes-langchain.documentGithubLoader',\n+\t\t\t'@n8n/n8n-nodes-langchain.code',\n+\t\t];\n+\t\tconst nodeTypesKeys = Object.keys(this.nodeTypes.getKnownTypes());\n+\n+\t\tconst nodeTypes = nodeTypesKeys\n+\t\t\t.filter((nodeType) => !ignoredTypes.includes(nodeType))\n+\t\t\t.map((nodeName) => {\n+\t\t\t\ttry {\n+\t\t\t\t\treturn { ...this.nodeTypes.getByNameAndVersion(nodeName).description, name: nodeName };\n+\t\t\t\t} catch (error) {\n+\t\t\t\t\tthis.logger?.error('Error getting node type', {\n+\t\t\t\t\t\tnodeName,\n+\t\t\t\t\t\terror: error instanceof Error ? error.message : 'Unknown error',\n+\t\t\t\t\t});\n+\t\t\t\t\treturn undefined;\n+\t\t\t\t}\n+\t\t\t})\n+\t\t\t.filter(\n+\t\t\t\t(nodeType): nodeType is INodeTypeDescription =>\n+\t\t\t\t\tnodeType !== undefined && nodeType.hidden !== true,\n+\t\t\t)\n+\t\t\t.map((nodeType, _index, nodeTypes: INodeTypeDescription[]) => {\n+\t\t\t\t// If the node type is a tool, we need to find the corresponding non-tool node type\n+\t\t\t\t// and merge the two node types to get the full node type description.\n+\t\t\t\tconst isTool = nodeType.name.endsWith('Tool');\n+\t\t\t\tif (!isTool) return nodeType;\n+\n+\t\t\t\tconst nonToolNode = nodeTypes.find((nt) => nt.name === nodeType.name.replace('Tool', ''));\n+\t\t\t\tif (!nonToolNode) return nodeType;\n+\n+\t\t\t\treturn {\n+\t\t\t\t\t...nonToolNode,\n+\t\t\t\t\t...nodeType,\n+\t\t\t\t};\n+\t\t\t});\n+\n+\t\treturn nodeTypes;\n+\t}\n+\n+\tprivate async getAgent(user?: IUser) {\n+\t\tif (!this.llmComplexTask || !this.llmSimpleTask) {\n+\t\t\tawait this.setupModels(user);\n+\t\t}\n+\n+\t\tif (!this.llmComplexTask || !this.llmSimpleTask) {\n+\t\t\tthrow new LLMServiceError('Failed to initialize LLM models');\n+\t\t}\n+\n+\t\tthis.agent ??= new WorkflowBuilderAgent({\n+\t\t\tparsedNodeTypes: this.parsedNodeTypes,\n+\t\t\t// We use Sonnet both for simple and complex tasks\n+\t\t\tllmSimpleTask: this.llmComplexTask,",
        "comment_created_at": "2025-07-18T14:07:16+00:00",
        "comment_author": "burivuhster",
        "comment_body": "Maybe we can leave the 2-model-solution in `WorkflowBuilderAgent` for future use, but clean this up in this file and only create one LLM instance?\r\nSomething like\r\n```\r\nllmSimpleTask: this.llm,\r\nllmComplexTask: this.llm\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2194048561",
    "pr_number": 16863,
    "pr_file": "packages/@n8n/nodes-langchain/nodes/vendors/GoogleGemini/actions/document/analyze.operation.ts",
    "created_at": "2025-07-09T05:27:15+00:00",
    "commented_code": "+import type { IExecuteFunctions, INodeExecutionData, INodeProperties } from 'n8n-workflow';\n+import { updateDisplayOptions } from 'n8n-workflow';\n+\n+import { baseAnalyze } from '../../helpers/baseAnalyze';\n+import { modelRLC } from '../descriptions';\n+\n+const properties: INodeProperties[] = [\n+\tmodelRLC('modelSearch'),\n+\t{\n+\t\tdisplayName: 'Text Input',\n+\t\tname: 'text',\n+\t\ttype: 'string',\n+\t\tplaceholder: \"e.g. What's in this document?\",\n+\t\tdefault: \"What's in this document?\",\n+\t\ttypeOptions: {\n+\t\t\trows: 2,\n+\t\t},\n+\t},\n+\t{\n+\t\tdisplayName: 'Input Type',\n+\t\tname: 'inputType',\n+\t\ttype: 'options',\n+\t\tdefault: 'url',\n+\t\toptions: [\n+\t\t\t{\n+\t\t\t\tname: 'Document URL(s)',\n+\t\t\t\tvalue: 'url',\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\tname: 'Binary File(s)',\n+\t\t\t\tvalue: 'binary',\n+\t\t\t},\n+\t\t],\n+\t},\n+\t{\n+\t\tdisplayName: 'URL(s)',\n+\t\tname: 'documentUrls',\n+\t\ttype: 'string',\n+\t\tplaceholder: 'e.g. https://example.com/document.pdf',\n+\t\tdescription:\n+\t\t\t'URL(s) of the document(s) to analyze, multiple URLs can be added separated by comma',\n+\t\tdefault: '',\n+\t\tdisplayOptions: {\n+\t\t\tshow: {\n+\t\t\t\tinputType: ['url'],\n+\t\t\t},\n+\t\t},\n+\t},\n+\t{\n+\t\tdisplayName: 'Input Data Field Name(s)',\n+\t\tname: 'binaryPropertyName',\n+\t\ttype: 'string',\n+\t\tdefault: 'data',\n+\t\tplaceholder: 'e.g. data',\n+\t\thint: 'The name of the input field containing the binary file data to be processed',\n+\t\tdescription:\n+\t\t\t'Name of the binary field(s) which contains the document(s), seperate multiple field names with commas',\n+\t\tdisplayOptions: {\n+\t\t\tshow: {\n+\t\t\t\tinputType: ['binary'],\n+\t\t\t},\n+\t\t},\n+\t},\n+\t{\n+\t\tdisplayName: 'Simplify Output',\n+\t\tname: 'simplify',\n+\t\ttype: 'boolean',\n+\t\tdefault: true,\n+\t\tdescription: 'Whether to simplify the response or not',\n+\t},\n+\t{\n+\t\tdisplayName: 'Options',\n+\t\tname: 'options',\n+\t\tplaceholder: 'Add Option',\n+\t\ttype: 'collection',\n+\t\tdefault: {},\n+\t\toptions: [\n+\t\t\t{\n+\t\t\t\tdisplayName: 'Length of Description (Max Tokens)',\n+\t\t\t\tdescription: 'Fewer tokens will result in shorter, less detailed image description',",
    "repo_full_name": "n8n-io/n8n",
    "discussion_comments": [
      {
        "comment_id": "2194072231",
        "repo_full_name": "n8n-io/n8n",
        "pr_number": 16863,
        "pr_file": "packages/@n8n/nodes-langchain/nodes/vendors/GoogleGemini/actions/document/analyze.operation.ts",
        "discussion_id": "2194048561",
        "commented_code": "@@ -0,0 +1,103 @@\n+import type { IExecuteFunctions, INodeExecutionData, INodeProperties } from 'n8n-workflow';\n+import { updateDisplayOptions } from 'n8n-workflow';\n+\n+import { baseAnalyze } from '../../helpers/baseAnalyze';\n+import { modelRLC } from '../descriptions';\n+\n+const properties: INodeProperties[] = [\n+\tmodelRLC('modelSearch'),\n+\t{\n+\t\tdisplayName: 'Text Input',\n+\t\tname: 'text',\n+\t\ttype: 'string',\n+\t\tplaceholder: \"e.g. What's in this document?\",\n+\t\tdefault: \"What's in this document?\",\n+\t\ttypeOptions: {\n+\t\t\trows: 2,\n+\t\t},\n+\t},\n+\t{\n+\t\tdisplayName: 'Input Type',\n+\t\tname: 'inputType',\n+\t\ttype: 'options',\n+\t\tdefault: 'url',\n+\t\toptions: [\n+\t\t\t{\n+\t\t\t\tname: 'Document URL(s)',\n+\t\t\t\tvalue: 'url',\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\tname: 'Binary File(s)',\n+\t\t\t\tvalue: 'binary',\n+\t\t\t},\n+\t\t],\n+\t},\n+\t{\n+\t\tdisplayName: 'URL(s)',\n+\t\tname: 'documentUrls',\n+\t\ttype: 'string',\n+\t\tplaceholder: 'e.g. https://example.com/document.pdf',\n+\t\tdescription:\n+\t\t\t'URL(s) of the document(s) to analyze, multiple URLs can be added separated by comma',\n+\t\tdefault: '',\n+\t\tdisplayOptions: {\n+\t\t\tshow: {\n+\t\t\t\tinputType: ['url'],\n+\t\t\t},\n+\t\t},\n+\t},\n+\t{\n+\t\tdisplayName: 'Input Data Field Name(s)',\n+\t\tname: 'binaryPropertyName',\n+\t\ttype: 'string',\n+\t\tdefault: 'data',\n+\t\tplaceholder: 'e.g. data',\n+\t\thint: 'The name of the input field containing the binary file data to be processed',\n+\t\tdescription:\n+\t\t\t'Name of the binary field(s) which contains the document(s), seperate multiple field names with commas',\n+\t\tdisplayOptions: {\n+\t\t\tshow: {\n+\t\t\t\tinputType: ['binary'],\n+\t\t\t},\n+\t\t},\n+\t},\n+\t{\n+\t\tdisplayName: 'Simplify Output',\n+\t\tname: 'simplify',\n+\t\ttype: 'boolean',\n+\t\tdefault: true,\n+\t\tdescription: 'Whether to simplify the response or not',\n+\t},\n+\t{\n+\t\tdisplayName: 'Options',\n+\t\tname: 'options',\n+\t\tplaceholder: 'Add Option',\n+\t\ttype: 'collection',\n+\t\tdefault: {},\n+\t\toptions: [\n+\t\t\t{\n+\t\t\t\tdisplayName: 'Length of Description (Max Tokens)',\n+\t\t\t\tdescription: 'Fewer tokens will result in shorter, less detailed image description',",
        "comment_created_at": "2025-07-09T05:44:25+00:00",
        "comment_author": "RomanDavydchuk",
        "comment_body": "Fixed",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2194048601",
    "pr_number": 16863,
    "pr_file": "packages/@n8n/nodes-langchain/nodes/vendors/GoogleGemini/actions/file/upload.operation.ts",
    "created_at": "2025-07-09T05:27:15+00:00",
    "commented_code": "+import type { IExecuteFunctions, INodeExecutionData, INodeProperties } from 'n8n-workflow';\n+import { updateDisplayOptions } from 'n8n-workflow';\n+\n+import { downloadFile, uploadFile } from '../../helpers/utils';\n+\n+export const properties: INodeProperties[] = [\n+\t{\n+\t\tdisplayName: 'Input Type',\n+\t\tname: 'inputType',\n+\t\ttype: 'options',\n+\t\tdefault: 'url',\n+\t\toptions: [\n+\t\t\t{\n+\t\t\t\tname: 'File URL',\n+\t\t\t\tvalue: 'url',\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\tname: 'Binary File',\n+\t\t\t\tvalue: 'binary',\n+\t\t\t},\n+\t\t],\n+\t},\n+\t{\n+\t\tdisplayName: 'URL',\n+\t\tname: 'fileUrl',\n+\t\ttype: 'string',\n+\t\tplaceholder: 'e.g. https://example.com/file.pdf',\n+\t\tdescription: 'URL of the file to upload',\n+\t\tdefault: '',\n+\t\tdisplayOptions: {\n+\t\t\tshow: {\n+\t\t\t\tinputType: ['url'],\n+\t\t\t},\n+\t\t},\n+\t},\n+\t{\n+\t\tdisplayName: 'Input Data Field Name',\n+\t\tname: 'binaryPropertyName',\n+\t\ttype: 'string',\n+\t\tdefault: 'data',\n+\t\tplaceholder: 'e.g. data',\n+\t\thint: 'The name of the input field containing the binary file data to be processed',\n+\t\tdescription: 'Name of the binary property which contains the file',\n+\t\tdisplayOptions: {\n+\t\t\tshow: {\n+\t\t\t\tinputType: ['binary'],\n+\t\t\t},\n+\t\t},\n+\t},\n+];\n+\n+const displayOptions = {\n+\tshow: {\n+\t\toperation: ['upload'],\n+\t\tresource: ['file'],\n+\t},\n+};\n+\n+export const description = updateDisplayOptions(displayOptions, properties);\n+\n+export async function execute(this: IExecuteFunctions, i: number): Promise<INodeExecutionData[]> {\n+\tconst inputType = this.getNodeParameter('inputType', i, 'url') as string;\n+\tif (inputType === 'url') {\n+\t\tconst fileUrl = this.getNodeParameter('fileUrl', i, '') as string;\n+\t\tconst { fileContent, mimeType } = await downloadFile.call(this, fileUrl);\n+\t\tconst response = await uploadFile.call(this, fileContent, mimeType);",
    "repo_full_name": "n8n-io/n8n",
    "discussion_comments": [
      {
        "comment_id": "2194075143",
        "repo_full_name": "n8n-io/n8n",
        "pr_number": 16863,
        "pr_file": "packages/@n8n/nodes-langchain/nodes/vendors/GoogleGemini/actions/file/upload.operation.ts",
        "discussion_id": "2194048601",
        "commented_code": "@@ -0,0 +1,89 @@\n+import type { IExecuteFunctions, INodeExecutionData, INodeProperties } from 'n8n-workflow';\n+import { updateDisplayOptions } from 'n8n-workflow';\n+\n+import { downloadFile, uploadFile } from '../../helpers/utils';\n+\n+export const properties: INodeProperties[] = [\n+\t{\n+\t\tdisplayName: 'Input Type',\n+\t\tname: 'inputType',\n+\t\ttype: 'options',\n+\t\tdefault: 'url',\n+\t\toptions: [\n+\t\t\t{\n+\t\t\t\tname: 'File URL',\n+\t\t\t\tvalue: 'url',\n+\t\t\t},\n+\t\t\t{\n+\t\t\t\tname: 'Binary File',\n+\t\t\t\tvalue: 'binary',\n+\t\t\t},\n+\t\t],\n+\t},\n+\t{\n+\t\tdisplayName: 'URL',\n+\t\tname: 'fileUrl',\n+\t\ttype: 'string',\n+\t\tplaceholder: 'e.g. https://example.com/file.pdf',\n+\t\tdescription: 'URL of the file to upload',\n+\t\tdefault: '',\n+\t\tdisplayOptions: {\n+\t\t\tshow: {\n+\t\t\t\tinputType: ['url'],\n+\t\t\t},\n+\t\t},\n+\t},\n+\t{\n+\t\tdisplayName: 'Input Data Field Name',\n+\t\tname: 'binaryPropertyName',\n+\t\ttype: 'string',\n+\t\tdefault: 'data',\n+\t\tplaceholder: 'e.g. data',\n+\t\thint: 'The name of the input field containing the binary file data to be processed',\n+\t\tdescription: 'Name of the binary property which contains the file',\n+\t\tdisplayOptions: {\n+\t\t\tshow: {\n+\t\t\t\tinputType: ['binary'],\n+\t\t\t},\n+\t\t},\n+\t},\n+];\n+\n+const displayOptions = {\n+\tshow: {\n+\t\toperation: ['upload'],\n+\t\tresource: ['file'],\n+\t},\n+};\n+\n+export const description = updateDisplayOptions(displayOptions, properties);\n+\n+export async function execute(this: IExecuteFunctions, i: number): Promise<INodeExecutionData[]> {\n+\tconst inputType = this.getNodeParameter('inputType', i, 'url') as string;\n+\tif (inputType === 'url') {\n+\t\tconst fileUrl = this.getNodeParameter('fileUrl', i, '') as string;\n+\t\tconst { fileContent, mimeType } = await downloadFile.call(this, fileUrl);\n+\t\tconst response = await uploadFile.call(this, fileContent, mimeType);",
        "comment_created_at": "2025-07-09T05:46:59+00:00",
        "comment_author": "RomanDavydchuk",
        "comment_body": "Fixed by passing the `fallbackMimeType` to `downloadFile`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2182345556",
    "pr_number": 16888,
    "pr_file": "packages/@n8n/nodes-langchain/nodes/llms/N8nLlmTracing.ts",
    "created_at": "2025-07-03T09:43:52+00:00",
    "commented_code": "options = {\n \t\t// Default(OpenAI format) parser\n-\t\ttokensUsageParser: (llmOutput: LLMResult['llmOutput']) => {\n-\t\t\tconst completionTokens = (llmOutput?.tokenUsage?.completionTokens as number) ?? 0;\n-\t\t\tconst promptTokens = (llmOutput?.tokenUsage?.promptTokens as number) ?? 0;\n+\t\ttokensUsageParser: (llmOutput: LLMResult) => {\n+\t\t\tconst completionTokens = (llmOutput?.llmOutput?.tokenUsage?.completionTokens as number) ?? 0;\n+\t\t\tconst promptTokens = (llmOutput?.llmOutput?.tokenUsage?.promptTokens as number) ?? 0;",
    "repo_full_name": "n8n-io/n8n",
    "discussion_comments": [
      {
        "comment_id": "2182345556",
        "repo_full_name": "n8n-io/n8n",
        "pr_number": 16888,
        "pr_file": "packages/@n8n/nodes-langchain/nodes/llms/N8nLlmTracing.ts",
        "discussion_id": "2182345556",
        "commented_code": "@@ -53,9 +53,9 @@ export class N8nLlmTracing extends BaseCallbackHandler {\n \n \toptions = {\n \t\t// Default(OpenAI format) parser\n-\t\ttokensUsageParser: (llmOutput: LLMResult['llmOutput']) => {\n-\t\t\tconst completionTokens = (llmOutput?.tokenUsage?.completionTokens as number) ?? 0;\n-\t\t\tconst promptTokens = (llmOutput?.tokenUsage?.promptTokens as number) ?? 0;\n+\t\ttokensUsageParser: (llmOutput: LLMResult) => {\n+\t\t\tconst completionTokens = (llmOutput?.llmOutput?.tokenUsage?.completionTokens as number) ?? 0;\n+\t\t\tconst promptTokens = (llmOutput?.llmOutput?.tokenUsage?.promptTokens as number) ?? 0;",
        "comment_created_at": "2025-07-03T09:43:52+00:00",
        "comment_author": "burivuhster",
        "comment_body": "```suggestion\r\n\t\ttokensUsageParser: (llmResult: LLMResult) => {\r\n\t\t\tconst completionTokens = (llmResult?.llmOutput?.tokenUsage?.completionTokens as number) ?? 0;\r\n\t\t\tconst promptTokens = (llmResult?.llmOutput?.tokenUsage?.promptTokens as number) ?? 0;\r\n```",
        "pr_file_module": null
      }
    ]
  }
]