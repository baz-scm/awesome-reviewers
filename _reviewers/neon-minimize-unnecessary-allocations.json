[
  {
    "discussion_id": "2192522726",
    "pr_number": 12469,
    "pr_file": "pageserver/client_grpc/src/split.rs",
    "created_at": "2025-07-08T13:22:36+00:00",
    "commented_code": "+use std::collections::HashMap;\n+\n+use bytes::Bytes;\n+\n+use pageserver_api::key::rel_block_to_key;\n+use pageserver_api::shard::{ShardStripeSize, key_to_shard_number};\n+use pageserver_page_api as page_api;\n+use utils::shard::{ShardCount, ShardIndex};\n+\n+/// Splits GetPageRequests that straddle shard boundaries and assembles the responses.\n+/// TODO: add tests for this.\n+pub struct GetPageSplitter {\n+    /// The original request ID. Used for all shard requests.\n+    request_id: page_api::RequestID,\n+    /// Split requests by shard index.\n+    requests: HashMap<ShardIndex, page_api::GetPageRequest>,\n+    /// Maps the offset in `GetPageRequest::block_numbers` to the owning shard. Used to assemble\n+    /// the response pages in the same order as the original request.\n+    block_shards: Vec<ShardIndex>,\n+    /// Page responses by shard index. Will be assembled into a single response.\n+    responses: HashMap<ShardIndex, Vec<Bytes>>,\n+}\n+\n+impl GetPageSplitter {\n+    /// Checks if the given request only touches a single shard, and returns the shard ID. This is\n+    /// the common case, so we check first in order to avoid unnecessary allocations and overhead.\n+    /// The caller must ensure that the request has at least one block number, or this will panic.\n+    pub fn is_single_shard(\n+        req: &page_api::GetPageRequest,\n+        count: ShardCount,\n+        stripe_size: ShardStripeSize,\n+    ) -> Option<ShardIndex> {\n+        // Fast path: unsharded tenant.\n+        if count.is_unsharded() {\n+            return Some(ShardIndex::unsharded());\n+        }\n+\n+        // Find the base shard index for the first page, and compare with the rest.\n+        let key = rel_block_to_key(req.rel, *req.block_numbers.first().expect(\"no pages\"));\n+        let shard_number = key_to_shard_number(count, stripe_size, &key);\n+\n+        req.block_numbers\n+            .iter()\n+            .skip(1) // computed above\n+            .all(|&blkno| {\n+                let key = rel_block_to_key(req.rel, blkno);\n+                key_to_shard_number(count, stripe_size, &key) == shard_number\n+            })\n+            .then_some(ShardIndex::new(shard_number, count))\n+    }\n+\n+    /// Splits the given request.\n+    pub fn split(\n+        req: page_api::GetPageRequest,\n+        count: ShardCount,\n+        stripe_size: ShardStripeSize,\n+    ) -> Self {\n+        // The caller should make sure we don't split requests unnecessarily.\n+        debug_assert!(\n+            Self::is_single_shard(&req, count, stripe_size).is_none(),\n+            \"unnecessary request split\"\n+        );\n+\n+        // Split the requests by shard index.\n+        let mut requests = HashMap::with_capacity(2); // common case\n+        let mut block_shards = Vec::with_capacity(req.block_numbers.len());\n+        for blkno in req.block_numbers {\n+            let key = rel_block_to_key(req.rel, blkno);\n+            let shard_number = key_to_shard_number(count, stripe_size, &key);\n+            let shard_id = ShardIndex::new(shard_number, count);\n+\n+            let shard_req = requests\n+                .entry(shard_id)\n+                .or_insert_with(|| page_api::GetPageRequest {\n+                    request_id: req.request_id,\n+                    request_class: req.request_class,\n+                    rel: req.rel,\n+                    read_lsn: req.read_lsn,\n+                    block_numbers: Vec::new(),\n+                });\n+            shard_req.block_numbers.push(blkno);\n+            block_shards.push(shard_id);\n+        }\n+\n+        Self {\n+            request_id: req.request_id,\n+            responses: HashMap::with_capacity(requests.len()),\n+            requests,\n+            block_shards,\n+        }\n+    }\n+\n+    /// Drains the per-shard requests, moving them out of the hashmap to avoid extra allocations.\n+    pub fn drain_requests(\n+        &mut self,\n+    ) -> impl Iterator<Item = (ShardIndex, page_api::GetPageRequest)> {\n+        self.requests.drain()\n+    }\n+\n+    /// Adds a response from the given shard.\n+    #[allow(clippy::result_large_err)]\n+    pub fn add_response(\n+        &mut self,\n+        shard_id: ShardIndex,\n+        response: page_api::GetPageResponse,\n+    ) -> tonic::Result<()> {\n+        // The caller should already have converted status codes into tonic::Status.\n+        assert_eq!(response.status_code, page_api::GetPageStatusCode::Ok);\n+\n+        // Make sure the response matches the request ID.\n+        if response.request_id != self.request_id {\n+            return Err(tonic::Status::internal(format!(\n+                \"response ID {} does not match request ID {}\",\n+                response.request_id, self.request_id\n+            )));\n+        }\n+\n+        // Add the response data to the map.\n+        let old = self.responses.insert(shard_id, response.page_images);\n+\n+        if old.is_some() {\n+            return Err(tonic::Status::internal(format!(\n+                \"duplicate response for shard {shard_id}\",\n+            )));\n+        }\n+\n+        Ok(())\n+    }\n+\n+    /// Assembles the shard responses into a single response. Responses must be present for all\n+    /// relevant shards, and the total number of pages must match the original request.\n+    #[allow(clippy::result_large_err)]\n+    pub fn assemble_response(self) -> tonic::Result<page_api::GetPageResponse> {\n+        let mut response = page_api::GetPageResponse {\n+            request_id: self.request_id,\n+            status_code: page_api::GetPageStatusCode::Ok,\n+            reason: None,\n+            page_images: Vec::with_capacity(self.block_shards.len()),\n+        };\n+\n+        // Set up per-shard page iterators we can pull from.\n+        let mut shard_responses = HashMap::with_capacity(self.responses.len());\n+        for (shard_id, responses) in self.responses {\n+            shard_responses.insert(shard_id, responses.into_iter());\n+        }",
    "repo_full_name": "neondatabase/neon",
    "discussion_comments": [
      {
        "comment_id": "2192522726",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 12469,
        "pr_file": "pageserver/client_grpc/src/split.rs",
        "discussion_id": "2192522726",
        "commented_code": "@@ -0,0 +1,172 @@\n+use std::collections::HashMap;\n+\n+use bytes::Bytes;\n+\n+use pageserver_api::key::rel_block_to_key;\n+use pageserver_api::shard::{ShardStripeSize, key_to_shard_number};\n+use pageserver_page_api as page_api;\n+use utils::shard::{ShardCount, ShardIndex};\n+\n+/// Splits GetPageRequests that straddle shard boundaries and assembles the responses.\n+/// TODO: add tests for this.\n+pub struct GetPageSplitter {\n+    /// The original request ID. Used for all shard requests.\n+    request_id: page_api::RequestID,\n+    /// Split requests by shard index.\n+    requests: HashMap<ShardIndex, page_api::GetPageRequest>,\n+    /// Maps the offset in `GetPageRequest::block_numbers` to the owning shard. Used to assemble\n+    /// the response pages in the same order as the original request.\n+    block_shards: Vec<ShardIndex>,\n+    /// Page responses by shard index. Will be assembled into a single response.\n+    responses: HashMap<ShardIndex, Vec<Bytes>>,\n+}\n+\n+impl GetPageSplitter {\n+    /// Checks if the given request only touches a single shard, and returns the shard ID. This is\n+    /// the common case, so we check first in order to avoid unnecessary allocations and overhead.\n+    /// The caller must ensure that the request has at least one block number, or this will panic.\n+    pub fn is_single_shard(\n+        req: &page_api::GetPageRequest,\n+        count: ShardCount,\n+        stripe_size: ShardStripeSize,\n+    ) -> Option<ShardIndex> {\n+        // Fast path: unsharded tenant.\n+        if count.is_unsharded() {\n+            return Some(ShardIndex::unsharded());\n+        }\n+\n+        // Find the base shard index for the first page, and compare with the rest.\n+        let key = rel_block_to_key(req.rel, *req.block_numbers.first().expect(\"no pages\"));\n+        let shard_number = key_to_shard_number(count, stripe_size, &key);\n+\n+        req.block_numbers\n+            .iter()\n+            .skip(1) // computed above\n+            .all(|&blkno| {\n+                let key = rel_block_to_key(req.rel, blkno);\n+                key_to_shard_number(count, stripe_size, &key) == shard_number\n+            })\n+            .then_some(ShardIndex::new(shard_number, count))\n+    }\n+\n+    /// Splits the given request.\n+    pub fn split(\n+        req: page_api::GetPageRequest,\n+        count: ShardCount,\n+        stripe_size: ShardStripeSize,\n+    ) -> Self {\n+        // The caller should make sure we don't split requests unnecessarily.\n+        debug_assert!(\n+            Self::is_single_shard(&req, count, stripe_size).is_none(),\n+            \"unnecessary request split\"\n+        );\n+\n+        // Split the requests by shard index.\n+        let mut requests = HashMap::with_capacity(2); // common case\n+        let mut block_shards = Vec::with_capacity(req.block_numbers.len());\n+        for blkno in req.block_numbers {\n+            let key = rel_block_to_key(req.rel, blkno);\n+            let shard_number = key_to_shard_number(count, stripe_size, &key);\n+            let shard_id = ShardIndex::new(shard_number, count);\n+\n+            let shard_req = requests\n+                .entry(shard_id)\n+                .or_insert_with(|| page_api::GetPageRequest {\n+                    request_id: req.request_id,\n+                    request_class: req.request_class,\n+                    rel: req.rel,\n+                    read_lsn: req.read_lsn,\n+                    block_numbers: Vec::new(),\n+                });\n+            shard_req.block_numbers.push(blkno);\n+            block_shards.push(shard_id);\n+        }\n+\n+        Self {\n+            request_id: req.request_id,\n+            responses: HashMap::with_capacity(requests.len()),\n+            requests,\n+            block_shards,\n+        }\n+    }\n+\n+    /// Drains the per-shard requests, moving them out of the hashmap to avoid extra allocations.\n+    pub fn drain_requests(\n+        &mut self,\n+    ) -> impl Iterator<Item = (ShardIndex, page_api::GetPageRequest)> {\n+        self.requests.drain()\n+    }\n+\n+    /// Adds a response from the given shard.\n+    #[allow(clippy::result_large_err)]\n+    pub fn add_response(\n+        &mut self,\n+        shard_id: ShardIndex,\n+        response: page_api::GetPageResponse,\n+    ) -> tonic::Result<()> {\n+        // The caller should already have converted status codes into tonic::Status.\n+        assert_eq!(response.status_code, page_api::GetPageStatusCode::Ok);\n+\n+        // Make sure the response matches the request ID.\n+        if response.request_id != self.request_id {\n+            return Err(tonic::Status::internal(format!(\n+                \"response ID {} does not match request ID {}\",\n+                response.request_id, self.request_id\n+            )));\n+        }\n+\n+        // Add the response data to the map.\n+        let old = self.responses.insert(shard_id, response.page_images);\n+\n+        if old.is_some() {\n+            return Err(tonic::Status::internal(format!(\n+                \"duplicate response for shard {shard_id}\",\n+            )));\n+        }\n+\n+        Ok(())\n+    }\n+\n+    /// Assembles the shard responses into a single response. Responses must be present for all\n+    /// relevant shards, and the total number of pages must match the original request.\n+    #[allow(clippy::result_large_err)]\n+    pub fn assemble_response(self) -> tonic::Result<page_api::GetPageResponse> {\n+        let mut response = page_api::GetPageResponse {\n+            request_id: self.request_id,\n+            status_code: page_api::GetPageStatusCode::Ok,\n+            reason: None,\n+            page_images: Vec::with_capacity(self.block_shards.len()),\n+        };\n+\n+        // Set up per-shard page iterators we can pull from.\n+        let mut shard_responses = HashMap::with_capacity(self.responses.len());\n+        for (shard_id, responses) in self.responses {\n+            shard_responses.insert(shard_id, responses.into_iter());\n+        }",
        "comment_created_at": "2025-07-08T13:22:36+00:00",
        "comment_author": "VladLazar",
        "comment_body": "Would be good to avoid an extra allocation here. Could track the block number in `Self::response` and put everything in the right place with `Vec::spare_capacity_mut`.",
        "pr_file_module": null
      },
      {
        "comment_id": "2192793187",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 12469,
        "pr_file": "pageserver/client_grpc/src/split.rs",
        "discussion_id": "2192522726",
        "commented_code": "@@ -0,0 +1,172 @@\n+use std::collections::HashMap;\n+\n+use bytes::Bytes;\n+\n+use pageserver_api::key::rel_block_to_key;\n+use pageserver_api::shard::{ShardStripeSize, key_to_shard_number};\n+use pageserver_page_api as page_api;\n+use utils::shard::{ShardCount, ShardIndex};\n+\n+/// Splits GetPageRequests that straddle shard boundaries and assembles the responses.\n+/// TODO: add tests for this.\n+pub struct GetPageSplitter {\n+    /// The original request ID. Used for all shard requests.\n+    request_id: page_api::RequestID,\n+    /// Split requests by shard index.\n+    requests: HashMap<ShardIndex, page_api::GetPageRequest>,\n+    /// Maps the offset in `GetPageRequest::block_numbers` to the owning shard. Used to assemble\n+    /// the response pages in the same order as the original request.\n+    block_shards: Vec<ShardIndex>,\n+    /// Page responses by shard index. Will be assembled into a single response.\n+    responses: HashMap<ShardIndex, Vec<Bytes>>,\n+}\n+\n+impl GetPageSplitter {\n+    /// Checks if the given request only touches a single shard, and returns the shard ID. This is\n+    /// the common case, so we check first in order to avoid unnecessary allocations and overhead.\n+    /// The caller must ensure that the request has at least one block number, or this will panic.\n+    pub fn is_single_shard(\n+        req: &page_api::GetPageRequest,\n+        count: ShardCount,\n+        stripe_size: ShardStripeSize,\n+    ) -> Option<ShardIndex> {\n+        // Fast path: unsharded tenant.\n+        if count.is_unsharded() {\n+            return Some(ShardIndex::unsharded());\n+        }\n+\n+        // Find the base shard index for the first page, and compare with the rest.\n+        let key = rel_block_to_key(req.rel, *req.block_numbers.first().expect(\"no pages\"));\n+        let shard_number = key_to_shard_number(count, stripe_size, &key);\n+\n+        req.block_numbers\n+            .iter()\n+            .skip(1) // computed above\n+            .all(|&blkno| {\n+                let key = rel_block_to_key(req.rel, blkno);\n+                key_to_shard_number(count, stripe_size, &key) == shard_number\n+            })\n+            .then_some(ShardIndex::new(shard_number, count))\n+    }\n+\n+    /// Splits the given request.\n+    pub fn split(\n+        req: page_api::GetPageRequest,\n+        count: ShardCount,\n+        stripe_size: ShardStripeSize,\n+    ) -> Self {\n+        // The caller should make sure we don't split requests unnecessarily.\n+        debug_assert!(\n+            Self::is_single_shard(&req, count, stripe_size).is_none(),\n+            \"unnecessary request split\"\n+        );\n+\n+        // Split the requests by shard index.\n+        let mut requests = HashMap::with_capacity(2); // common case\n+        let mut block_shards = Vec::with_capacity(req.block_numbers.len());\n+        for blkno in req.block_numbers {\n+            let key = rel_block_to_key(req.rel, blkno);\n+            let shard_number = key_to_shard_number(count, stripe_size, &key);\n+            let shard_id = ShardIndex::new(shard_number, count);\n+\n+            let shard_req = requests\n+                .entry(shard_id)\n+                .or_insert_with(|| page_api::GetPageRequest {\n+                    request_id: req.request_id,\n+                    request_class: req.request_class,\n+                    rel: req.rel,\n+                    read_lsn: req.read_lsn,\n+                    block_numbers: Vec::new(),\n+                });\n+            shard_req.block_numbers.push(blkno);\n+            block_shards.push(shard_id);\n+        }\n+\n+        Self {\n+            request_id: req.request_id,\n+            responses: HashMap::with_capacity(requests.len()),\n+            requests,\n+            block_shards,\n+        }\n+    }\n+\n+    /// Drains the per-shard requests, moving them out of the hashmap to avoid extra allocations.\n+    pub fn drain_requests(\n+        &mut self,\n+    ) -> impl Iterator<Item = (ShardIndex, page_api::GetPageRequest)> {\n+        self.requests.drain()\n+    }\n+\n+    /// Adds a response from the given shard.\n+    #[allow(clippy::result_large_err)]\n+    pub fn add_response(\n+        &mut self,\n+        shard_id: ShardIndex,\n+        response: page_api::GetPageResponse,\n+    ) -> tonic::Result<()> {\n+        // The caller should already have converted status codes into tonic::Status.\n+        assert_eq!(response.status_code, page_api::GetPageStatusCode::Ok);\n+\n+        // Make sure the response matches the request ID.\n+        if response.request_id != self.request_id {\n+            return Err(tonic::Status::internal(format!(\n+                \"response ID {} does not match request ID {}\",\n+                response.request_id, self.request_id\n+            )));\n+        }\n+\n+        // Add the response data to the map.\n+        let old = self.responses.insert(shard_id, response.page_images);\n+\n+        if old.is_some() {\n+            return Err(tonic::Status::internal(format!(\n+                \"duplicate response for shard {shard_id}\",\n+            )));\n+        }\n+\n+        Ok(())\n+    }\n+\n+    /// Assembles the shard responses into a single response. Responses must be present for all\n+    /// relevant shards, and the total number of pages must match the original request.\n+    #[allow(clippy::result_large_err)]\n+    pub fn assemble_response(self) -> tonic::Result<page_api::GetPageResponse> {\n+        let mut response = page_api::GetPageResponse {\n+            request_id: self.request_id,\n+            status_code: page_api::GetPageStatusCode::Ok,\n+            reason: None,\n+            page_images: Vec::with_capacity(self.block_shards.len()),\n+        };\n+\n+        // Set up per-shard page iterators we can pull from.\n+        let mut shard_responses = HashMap::with_capacity(self.responses.len());\n+        for (shard_id, responses) in self.responses {\n+            shard_responses.insert(shard_id, responses.into_iter());\n+        }",
        "comment_created_at": "2025-07-08T15:10:31+00:00",
        "comment_author": "erikgrinaker",
        "comment_body": "Idk. It would be possible to avoid an allocation by using a smallvec to track the response index by shard or something, but I don't think we care that much about it. This is a rare path (batch crossing shard bounds), we're already doing a bunch of network and disk IO, and there's a ton of allocations inherent in every page we're processing here.\r\n\r\nGiven that this code is rarely triggered, and important for correctness, I'd much rather try to keep it relatively simple than to squeeze out an allocation that probably doesn't matter. But let's revisit if it turns up in profiles.",
        "pr_file_module": null
      },
      {
        "comment_id": "2193184071",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 12469,
        "pr_file": "pageserver/client_grpc/src/split.rs",
        "discussion_id": "2192522726",
        "commented_code": "@@ -0,0 +1,172 @@\n+use std::collections::HashMap;\n+\n+use bytes::Bytes;\n+\n+use pageserver_api::key::rel_block_to_key;\n+use pageserver_api::shard::{ShardStripeSize, key_to_shard_number};\n+use pageserver_page_api as page_api;\n+use utils::shard::{ShardCount, ShardIndex};\n+\n+/// Splits GetPageRequests that straddle shard boundaries and assembles the responses.\n+/// TODO: add tests for this.\n+pub struct GetPageSplitter {\n+    /// The original request ID. Used for all shard requests.\n+    request_id: page_api::RequestID,\n+    /// Split requests by shard index.\n+    requests: HashMap<ShardIndex, page_api::GetPageRequest>,\n+    /// Maps the offset in `GetPageRequest::block_numbers` to the owning shard. Used to assemble\n+    /// the response pages in the same order as the original request.\n+    block_shards: Vec<ShardIndex>,\n+    /// Page responses by shard index. Will be assembled into a single response.\n+    responses: HashMap<ShardIndex, Vec<Bytes>>,\n+}\n+\n+impl GetPageSplitter {\n+    /// Checks if the given request only touches a single shard, and returns the shard ID. This is\n+    /// the common case, so we check first in order to avoid unnecessary allocations and overhead.\n+    /// The caller must ensure that the request has at least one block number, or this will panic.\n+    pub fn is_single_shard(\n+        req: &page_api::GetPageRequest,\n+        count: ShardCount,\n+        stripe_size: ShardStripeSize,\n+    ) -> Option<ShardIndex> {\n+        // Fast path: unsharded tenant.\n+        if count.is_unsharded() {\n+            return Some(ShardIndex::unsharded());\n+        }\n+\n+        // Find the base shard index for the first page, and compare with the rest.\n+        let key = rel_block_to_key(req.rel, *req.block_numbers.first().expect(\"no pages\"));\n+        let shard_number = key_to_shard_number(count, stripe_size, &key);\n+\n+        req.block_numbers\n+            .iter()\n+            .skip(1) // computed above\n+            .all(|&blkno| {\n+                let key = rel_block_to_key(req.rel, blkno);\n+                key_to_shard_number(count, stripe_size, &key) == shard_number\n+            })\n+            .then_some(ShardIndex::new(shard_number, count))\n+    }\n+\n+    /// Splits the given request.\n+    pub fn split(\n+        req: page_api::GetPageRequest,\n+        count: ShardCount,\n+        stripe_size: ShardStripeSize,\n+    ) -> Self {\n+        // The caller should make sure we don't split requests unnecessarily.\n+        debug_assert!(\n+            Self::is_single_shard(&req, count, stripe_size).is_none(),\n+            \"unnecessary request split\"\n+        );\n+\n+        // Split the requests by shard index.\n+        let mut requests = HashMap::with_capacity(2); // common case\n+        let mut block_shards = Vec::with_capacity(req.block_numbers.len());\n+        for blkno in req.block_numbers {\n+            let key = rel_block_to_key(req.rel, blkno);\n+            let shard_number = key_to_shard_number(count, stripe_size, &key);\n+            let shard_id = ShardIndex::new(shard_number, count);\n+\n+            let shard_req = requests\n+                .entry(shard_id)\n+                .or_insert_with(|| page_api::GetPageRequest {\n+                    request_id: req.request_id,\n+                    request_class: req.request_class,\n+                    rel: req.rel,\n+                    read_lsn: req.read_lsn,\n+                    block_numbers: Vec::new(),\n+                });\n+            shard_req.block_numbers.push(blkno);\n+            block_shards.push(shard_id);\n+        }\n+\n+        Self {\n+            request_id: req.request_id,\n+            responses: HashMap::with_capacity(requests.len()),\n+            requests,\n+            block_shards,\n+        }\n+    }\n+\n+    /// Drains the per-shard requests, moving them out of the hashmap to avoid extra allocations.\n+    pub fn drain_requests(\n+        &mut self,\n+    ) -> impl Iterator<Item = (ShardIndex, page_api::GetPageRequest)> {\n+        self.requests.drain()\n+    }\n+\n+    /// Adds a response from the given shard.\n+    #[allow(clippy::result_large_err)]\n+    pub fn add_response(\n+        &mut self,\n+        shard_id: ShardIndex,\n+        response: page_api::GetPageResponse,\n+    ) -> tonic::Result<()> {\n+        // The caller should already have converted status codes into tonic::Status.\n+        assert_eq!(response.status_code, page_api::GetPageStatusCode::Ok);\n+\n+        // Make sure the response matches the request ID.\n+        if response.request_id != self.request_id {\n+            return Err(tonic::Status::internal(format!(\n+                \"response ID {} does not match request ID {}\",\n+                response.request_id, self.request_id\n+            )));\n+        }\n+\n+        // Add the response data to the map.\n+        let old = self.responses.insert(shard_id, response.page_images);\n+\n+        if old.is_some() {\n+            return Err(tonic::Status::internal(format!(\n+                \"duplicate response for shard {shard_id}\",\n+            )));\n+        }\n+\n+        Ok(())\n+    }\n+\n+    /// Assembles the shard responses into a single response. Responses must be present for all\n+    /// relevant shards, and the total number of pages must match the original request.\n+    #[allow(clippy::result_large_err)]\n+    pub fn assemble_response(self) -> tonic::Result<page_api::GetPageResponse> {\n+        let mut response = page_api::GetPageResponse {\n+            request_id: self.request_id,\n+            status_code: page_api::GetPageStatusCode::Ok,\n+            reason: None,\n+            page_images: Vec::with_capacity(self.block_shards.len()),\n+        };\n+\n+        // Set up per-shard page iterators we can pull from.\n+        let mut shard_responses = HashMap::with_capacity(self.responses.len());\n+        for (shard_id, responses) in self.responses {\n+            shard_responses.insert(shard_id, responses.into_iter());\n+        }",
        "comment_created_at": "2025-07-08T18:24:43+00:00",
        "comment_author": "VladLazar",
        "comment_body": "Sounds good. Can optimize later if needed.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2164160811",
    "pr_number": 12317,
    "pr_file": "libs/postgres_versioninfo/src/lib.rs",
    "created_at": "2025-06-24T14:19:45+00:00",
    "commented_code": "+use serde::ser::SerializeTuple;\n+use serde::{Deserialize, Deserializer, Serialize, Serializer};\n+use serde_repr::{Deserialize_repr, Serialize_repr};\n+use std::fmt::{Display, Formatter};\n+use std::str::FromStr;\n+\n+/// An enum with one variant for each major version of PostgreSQL that we support.\n+///\n+#[derive(Debug, Clone, Copy, Ord, PartialOrd, Eq, PartialEq, Deserialize_repr, Serialize_repr)]\n+#[repr(u32)]\n+pub enum PgMajorVersion {\n+    PG14 = 14,\n+    PG15 = 15,\n+    PG16 = 16,\n+    PG17 = 17,\n+    // !!! When you add a new PgMajorVersion, don't forget to update PgMajorVersion::ALL\n+}\n+\n+/// A full PostgreSQL version ID, in MMmmbb numerical format (Major/minor/bugfix)\n+#[derive(Debug, Copy, Clone, Ord, PartialOrd, Eq, PartialEq)]\n+#[repr(transparent)]\n+pub struct PgVersionId(u32);\n+\n+impl PgVersionId {\n+    pub const UNKNOWN: PgVersionId = PgVersionId(0);\n+\n+    pub fn from_full_pg_version(version: u32) -> PgVersionId {\n+        match version {\n+            0 => PgVersionId(version), // unknown version\n+            140000..180000 => PgVersionId(version),\n+            _ => panic!(\"Invalid full PostgreSQL version ID {version}\"),\n+        }\n+    }\n+}\n+\n+impl Display for PgVersionId {\n+    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {\n+        u32::fmt(&self.0, f)\n+    }\n+}\n+\n+impl Serialize for PgVersionId {\n+    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n+    where\n+        S: Serializer,\n+    {\n+        u32::serialize(&self.0, serializer)\n+    }\n+}\n+\n+impl<'de> Deserialize<'de> for PgVersionId {\n+    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n+    where\n+        D: Deserializer<'de>,\n+    {\n+        u32::deserialize(deserializer).map(PgVersionId)\n+    }\n+\n+    fn deserialize_in_place<D>(deserializer: D, place: &mut Self) -> Result<(), D::Error>\n+    where\n+        D: Deserializer<'de>,\n+    {\n+        u32::deserialize_in_place(deserializer, &mut place.0)\n+    }\n+}\n+\n+impl PgMajorVersion {\n+    /// Get the numerical representation of the represented Major Version\n+    pub const fn major_version_num(&self) -> u32 {\n+        match self {\n+            PgMajorVersion::PG14 => 14,\n+            PgMajorVersion::PG15 => 15,\n+            PgMajorVersion::PG16 => 16,\n+            PgMajorVersion::PG17 => 17,\n+        }\n+    }\n+\n+    /// Get the contents of this version's PG_VERSION file.\n+    ///\n+    /// The PG_VERSION file is used to determine the PostgreSQL version that currently\n+    /// owns the data in a PostgreSQL data directory.\n+    pub fn versionfile_string(&self) -> String {\n+        match self {\n+            PgMajorVersion::PG17 => \"17\\x0A\".to_string(),\n+            PgMajorVersion::PG16 => \"16\\x0A\".to_string(),\n+            PgMajorVersion::PG15 => \"15\".to_string(),\n+            PgMajorVersion::PG14 => \"14\".to_string(),\n+        }\n+    }\n+\n+    /// Get the v{version} string of this major PostgreSQL version.\n+    ///\n+    /// Because this was hand-coded in various places, this was moved into a shared\n+    /// implementation.\n+    pub fn v_str(&self) -> String {\n+        match self {\n+            PgMajorVersion::PG17 => \"v17\".to_string(),\n+            PgMajorVersion::PG16 => \"v16\".to_string(),\n+            PgMajorVersion::PG15 => \"v15\".to_string(),\n+            PgMajorVersion::PG14 => \"v14\".to_string(),",
    "repo_full_name": "neondatabase/neon",
    "discussion_comments": [
      {
        "comment_id": "2164160811",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 12317,
        "pr_file": "libs/postgres_versioninfo/src/lib.rs",
        "discussion_id": "2164160811",
        "commented_code": "@@ -0,0 +1,185 @@\n+use serde::ser::SerializeTuple;\n+use serde::{Deserialize, Deserializer, Serialize, Serializer};\n+use serde_repr::{Deserialize_repr, Serialize_repr};\n+use std::fmt::{Display, Formatter};\n+use std::str::FromStr;\n+\n+/// An enum with one variant for each major version of PostgreSQL that we support.\n+///\n+#[derive(Debug, Clone, Copy, Ord, PartialOrd, Eq, PartialEq, Deserialize_repr, Serialize_repr)]\n+#[repr(u32)]\n+pub enum PgMajorVersion {\n+    PG14 = 14,\n+    PG15 = 15,\n+    PG16 = 16,\n+    PG17 = 17,\n+    // !!! When you add a new PgMajorVersion, don't forget to update PgMajorVersion::ALL\n+}\n+\n+/// A full PostgreSQL version ID, in MMmmbb numerical format (Major/minor/bugfix)\n+#[derive(Debug, Copy, Clone, Ord, PartialOrd, Eq, PartialEq)]\n+#[repr(transparent)]\n+pub struct PgVersionId(u32);\n+\n+impl PgVersionId {\n+    pub const UNKNOWN: PgVersionId = PgVersionId(0);\n+\n+    pub fn from_full_pg_version(version: u32) -> PgVersionId {\n+        match version {\n+            0 => PgVersionId(version), // unknown version\n+            140000..180000 => PgVersionId(version),\n+            _ => panic!(\"Invalid full PostgreSQL version ID {version}\"),\n+        }\n+    }\n+}\n+\n+impl Display for PgVersionId {\n+    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {\n+        u32::fmt(&self.0, f)\n+    }\n+}\n+\n+impl Serialize for PgVersionId {\n+    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n+    where\n+        S: Serializer,\n+    {\n+        u32::serialize(&self.0, serializer)\n+    }\n+}\n+\n+impl<'de> Deserialize<'de> for PgVersionId {\n+    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n+    where\n+        D: Deserializer<'de>,\n+    {\n+        u32::deserialize(deserializer).map(PgVersionId)\n+    }\n+\n+    fn deserialize_in_place<D>(deserializer: D, place: &mut Self) -> Result<(), D::Error>\n+    where\n+        D: Deserializer<'de>,\n+    {\n+        u32::deserialize_in_place(deserializer, &mut place.0)\n+    }\n+}\n+\n+impl PgMajorVersion {\n+    /// Get the numerical representation of the represented Major Version\n+    pub const fn major_version_num(&self) -> u32 {\n+        match self {\n+            PgMajorVersion::PG14 => 14,\n+            PgMajorVersion::PG15 => 15,\n+            PgMajorVersion::PG16 => 16,\n+            PgMajorVersion::PG17 => 17,\n+        }\n+    }\n+\n+    /// Get the contents of this version's PG_VERSION file.\n+    ///\n+    /// The PG_VERSION file is used to determine the PostgreSQL version that currently\n+    /// owns the data in a PostgreSQL data directory.\n+    pub fn versionfile_string(&self) -> String {\n+        match self {\n+            PgMajorVersion::PG17 => \"17\\x0A\".to_string(),\n+            PgMajorVersion::PG16 => \"16\\x0A\".to_string(),\n+            PgMajorVersion::PG15 => \"15\".to_string(),\n+            PgMajorVersion::PG14 => \"14\".to_string(),\n+        }\n+    }\n+\n+    /// Get the v{version} string of this major PostgreSQL version.\n+    ///\n+    /// Because this was hand-coded in various places, this was moved into a shared\n+    /// implementation.\n+    pub fn v_str(&self) -> String {\n+        match self {\n+            PgMajorVersion::PG17 => \"v17\".to_string(),\n+            PgMajorVersion::PG16 => \"v16\".to_string(),\n+            PgMajorVersion::PG15 => \"v15\".to_string(),\n+            PgMajorVersion::PG14 => \"v14\".to_string(),",
        "comment_created_at": "2025-06-24T14:19:45+00:00",
        "comment_author": "tristan957",
        "comment_body": "Seems like it would be easier to implement this function in terms of `major_version_num()`, but I'll leave it up to you!",
        "pr_file_module": null
      },
      {
        "comment_id": "2164180513",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 12317,
        "pr_file": "libs/postgres_versioninfo/src/lib.rs",
        "discussion_id": "2164160811",
        "commented_code": "@@ -0,0 +1,185 @@\n+use serde::ser::SerializeTuple;\n+use serde::{Deserialize, Deserializer, Serialize, Serializer};\n+use serde_repr::{Deserialize_repr, Serialize_repr};\n+use std::fmt::{Display, Formatter};\n+use std::str::FromStr;\n+\n+/// An enum with one variant for each major version of PostgreSQL that we support.\n+///\n+#[derive(Debug, Clone, Copy, Ord, PartialOrd, Eq, PartialEq, Deserialize_repr, Serialize_repr)]\n+#[repr(u32)]\n+pub enum PgMajorVersion {\n+    PG14 = 14,\n+    PG15 = 15,\n+    PG16 = 16,\n+    PG17 = 17,\n+    // !!! When you add a new PgMajorVersion, don't forget to update PgMajorVersion::ALL\n+}\n+\n+/// A full PostgreSQL version ID, in MMmmbb numerical format (Major/minor/bugfix)\n+#[derive(Debug, Copy, Clone, Ord, PartialOrd, Eq, PartialEq)]\n+#[repr(transparent)]\n+pub struct PgVersionId(u32);\n+\n+impl PgVersionId {\n+    pub const UNKNOWN: PgVersionId = PgVersionId(0);\n+\n+    pub fn from_full_pg_version(version: u32) -> PgVersionId {\n+        match version {\n+            0 => PgVersionId(version), // unknown version\n+            140000..180000 => PgVersionId(version),\n+            _ => panic!(\"Invalid full PostgreSQL version ID {version}\"),\n+        }\n+    }\n+}\n+\n+impl Display for PgVersionId {\n+    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {\n+        u32::fmt(&self.0, f)\n+    }\n+}\n+\n+impl Serialize for PgVersionId {\n+    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n+    where\n+        S: Serializer,\n+    {\n+        u32::serialize(&self.0, serializer)\n+    }\n+}\n+\n+impl<'de> Deserialize<'de> for PgVersionId {\n+    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n+    where\n+        D: Deserializer<'de>,\n+    {\n+        u32::deserialize(deserializer).map(PgVersionId)\n+    }\n+\n+    fn deserialize_in_place<D>(deserializer: D, place: &mut Self) -> Result<(), D::Error>\n+    where\n+        D: Deserializer<'de>,\n+    {\n+        u32::deserialize_in_place(deserializer, &mut place.0)\n+    }\n+}\n+\n+impl PgMajorVersion {\n+    /// Get the numerical representation of the represented Major Version\n+    pub const fn major_version_num(&self) -> u32 {\n+        match self {\n+            PgMajorVersion::PG14 => 14,\n+            PgMajorVersion::PG15 => 15,\n+            PgMajorVersion::PG16 => 16,\n+            PgMajorVersion::PG17 => 17,\n+        }\n+    }\n+\n+    /// Get the contents of this version's PG_VERSION file.\n+    ///\n+    /// The PG_VERSION file is used to determine the PostgreSQL version that currently\n+    /// owns the data in a PostgreSQL data directory.\n+    pub fn versionfile_string(&self) -> String {\n+        match self {\n+            PgMajorVersion::PG17 => \"17\\x0A\".to_string(),\n+            PgMajorVersion::PG16 => \"16\\x0A\".to_string(),\n+            PgMajorVersion::PG15 => \"15\".to_string(),\n+            PgMajorVersion::PG14 => \"14\".to_string(),\n+        }\n+    }\n+\n+    /// Get the v{version} string of this major PostgreSQL version.\n+    ///\n+    /// Because this was hand-coded in various places, this was moved into a shared\n+    /// implementation.\n+    pub fn v_str(&self) -> String {\n+        match self {\n+            PgMajorVersion::PG17 => \"v17\".to_string(),\n+            PgMajorVersion::PG16 => \"v16\".to_string(),\n+            PgMajorVersion::PG15 => \"v15\".to_string(),\n+            PgMajorVersion::PG14 => \"v14\".to_string(),",
        "comment_created_at": "2025-06-24T14:27:56+00:00",
        "comment_author": "MMeent",
        "comment_body": "True, but that'd add a `format!()` overhead, and I'd rather prevent that. |\r\n\r\nThis allows 'static Strings, also further reducing alloc overhead.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2136685655",
    "pr_number": 12111,
    "pr_file": "pageserver/page_api/src/client.rs",
    "created_at": "2025-06-09T23:57:24+00:00",
    "commented_code": "+use std::convert::TryInto;\n+use std::io::Error;\n+use std::io::ErrorKind;\n+\n+use bytes::Bytes;\n+use futures::StreamExt;\n+use futures_core::Stream;\n+use tonic::metadata::AsciiMetadataValue;\n+use tonic::metadata::errors::InvalidMetadataValue;\n+use tonic::transport::Channel;\n+use tonic::{Request, Streaming};\n+\n+use utils::id::TenantId;\n+use utils::id::TimelineId;\n+use utils::shard::ShardIndex;\n+\n+use anyhow::Result;\n+\n+use crate::model;\n+use crate::proto;\n+#[derive(Clone)]\n+struct AuthInterceptor {\n+    tenant_id: AsciiMetadataValue,\n+    shard_id: Option<AsciiMetadataValue>,\n+    timeline_id: AsciiMetadataValue,\n+    auth_header: Option<AsciiMetadataValue>, // including \"Bearer \" prefix\n+}\n+\n+impl AuthInterceptor {\n+    fn new(\n+        tenant_id: TenantId,\n+        timeline_id: TimelineId,\n+        auth_token: Option<String>,\n+        shard_id: ShardIndex,\n+    ) -> Result<Self, InvalidMetadataValue> {\n+        let tenant_ascii: AsciiMetadataValue = tenant_id.to_string().try_into()?;\n+        let timeline_ascii: AsciiMetadataValue = timeline_id.to_string().try_into()?;\n+        let shard_ascii: AsciiMetadataValue = shard_id.clone().to_string().try_into()?;",
    "repo_full_name": "neondatabase/neon",
    "discussion_comments": [
      {
        "comment_id": "2136685655",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 12111,
        "pr_file": "pageserver/page_api/src/client.rs",
        "discussion_id": "2136685655",
        "commented_code": "@@ -0,0 +1,186 @@\n+use std::convert::TryInto;\n+use std::io::Error;\n+use std::io::ErrorKind;\n+\n+use bytes::Bytes;\n+use futures::StreamExt;\n+use futures_core::Stream;\n+use tonic::metadata::AsciiMetadataValue;\n+use tonic::metadata::errors::InvalidMetadataValue;\n+use tonic::transport::Channel;\n+use tonic::{Request, Streaming};\n+\n+use utils::id::TenantId;\n+use utils::id::TimelineId;\n+use utils::shard::ShardIndex;\n+\n+use anyhow::Result;\n+\n+use crate::model;\n+use crate::proto;\n+#[derive(Clone)]\n+struct AuthInterceptor {\n+    tenant_id: AsciiMetadataValue,\n+    shard_id: Option<AsciiMetadataValue>,\n+    timeline_id: AsciiMetadataValue,\n+    auth_header: Option<AsciiMetadataValue>, // including \"Bearer \" prefix\n+}\n+\n+impl AuthInterceptor {\n+    fn new(\n+        tenant_id: TenantId,\n+        timeline_id: TimelineId,\n+        auth_token: Option<String>,\n+        shard_id: ShardIndex,\n+    ) -> Result<Self, InvalidMetadataValue> {\n+        let tenant_ascii: AsciiMetadataValue = tenant_id.to_string().try_into()?;\n+        let timeline_ascii: AsciiMetadataValue = timeline_id.to_string().try_into()?;\n+        let shard_ascii: AsciiMetadataValue = shard_id.clone().to_string().try_into()?;",
        "comment_created_at": "2025-06-09T23:57:24+00:00",
        "comment_author": "erikgrinaker",
        "comment_body": "nit: `.clone()` is unnecessary here.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2112300910",
    "pr_number": 12044,
    "pr_file": "pageserver/page_api/src/model.rs",
    "created_at": "2025-05-28T16:24:24+00:00",
    "commented_code": "}\n }\n \n+impl From<&ReadLsn> for proto::ReadLsn {",
    "repo_full_name": "neondatabase/neon",
    "discussion_comments": [
      {
        "comment_id": "2112300910",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 12044,
        "pr_file": "pageserver/page_api/src/model.rs",
        "discussion_id": "2112300910",
        "commented_code": "@@ -102,6 +102,15 @@ impl TryFrom<ReadLsn> for proto::ReadLsn {\n     }\n }\n \n+impl From<&ReadLsn> for proto::ReadLsn {",
        "comment_created_at": "2025-05-28T16:24:24+00:00",
        "comment_author": "erikgrinaker",
        "comment_body": "Let's drop these `From<&>` implementations. We should generally only convert owned types to avoid unnecessary heap allocations, and the caller can copy or clone if necessary.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2077471210",
    "pr_number": 11811,
    "pr_file": "compute_tools/src/compute.rs",
    "created_at": "2025-05-07T12:02:25+00:00",
    "commented_code": "tokio::spawn(conn);\n \n         // TODO: support other types of grants apart from schemas?\n-        let query = format!(\n-            \"GRANT {} ON SCHEMA {} TO {}\",\n-            privileges\n-                .iter()\n-                // should not be quoted as it's part of the command.\n-                // is already sanitized so it's ok\n-                .map(|p| p.as_str())\n-                .collect::<Vec<&'static str>>()\n-                .join(\", \"),\n-            // quote the schema and role name as identifiers to sanitize them.\n-            schema_name.pg_quote(),\n-            role_name.pg_quote(),\n-        );\n+\n+        // check the role grants first - to gracefully handle read-replicas.\n+        let select = \"SELECT privilege_type\n+            FROM pg_namespace\n+                JOIN LATERAL (SELECT * FROM aclexplode(nspacl) AS x) acl ON true\n+                JOIN pg_user users ON acl.grantee = users.usesysid\n+            WHERE users.usename = $1\n+                AND nspname = $2\";\n+        let rows = db_client\n+            .query(select, &[role_name, schema_name])\n+            .await\n+            .with_context(|| format!(\"Failed to execute query: {select}\"))?;\n+\n+        let mut already_granted = HashSet::new();\n+        for row in rows {\n+            let grant: String = row.get(0);\n+            already_granted.insert(grant);\n+        }\n+\n+        // check if all privileges are granted.\n+        if privileges\n+            .iter()\n+            .all(|g| already_granted.contains(g.as_str()))\n+        {\n+            return Ok(());\n+        }\n+\n+        let grants = privileges\n+            .iter()\n+            // should not be quoted as it's part of the command.\n+            // is already sanitized so it's ok\n+            .map(|p| p.as_str())\n+            .collect::<Vec<&'static str>>()",
    "repo_full_name": "neondatabase/neon",
    "discussion_comments": [
      {
        "comment_id": "2077471210",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 11811,
        "pr_file": "compute_tools/src/compute.rs",
        "discussion_id": "2077471210",
        "commented_code": "@@ -1937,19 +1937,46 @@ LIMIT 100\",\n         tokio::spawn(conn);\n \n         // TODO: support other types of grants apart from schemas?\n-        let query = format!(\n-            \"GRANT {} ON SCHEMA {} TO {}\",\n-            privileges\n-                .iter()\n-                // should not be quoted as it's part of the command.\n-                // is already sanitized so it's ok\n-                .map(|p| p.as_str())\n-                .collect::<Vec<&'static str>>()\n-                .join(\", \"),\n-            // quote the schema and role name as identifiers to sanitize them.\n-            schema_name.pg_quote(),\n-            role_name.pg_quote(),\n-        );\n+\n+        // check the role grants first - to gracefully handle read-replicas.\n+        let select = \"SELECT privilege_type\n+            FROM pg_namespace\n+                JOIN LATERAL (SELECT * FROM aclexplode(nspacl) AS x) acl ON true\n+                JOIN pg_user users ON acl.grantee = users.usesysid\n+            WHERE users.usename = $1\n+                AND nspname = $2\";\n+        let rows = db_client\n+            .query(select, &[role_name, schema_name])\n+            .await\n+            .with_context(|| format!(\"Failed to execute query: {select}\"))?;\n+\n+        let mut already_granted = HashSet::new();\n+        for row in rows {\n+            let grant: String = row.get(0);\n+            already_granted.insert(grant);\n+        }\n+\n+        // check if all privileges are granted.\n+        if privileges\n+            .iter()\n+            .all(|g| already_granted.contains(g.as_str()))\n+        {\n+            return Ok(());\n+        }\n+\n+        let grants = privileges\n+            .iter()\n+            // should not be quoted as it's part of the command.\n+            // is already sanitized so it's ok\n+            .map(|p| p.as_str())\n+            .collect::<Vec<&'static str>>()",
        "comment_created_at": "2025-05-07T12:02:25+00:00",
        "comment_author": "myrrc",
        "comment_body": "nit: May we use `itertools::join` here to avoid constructing a separate Vec?",
        "pr_file_module": null
      },
      {
        "comment_id": "2077482672",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 11811,
        "pr_file": "compute_tools/src/compute.rs",
        "discussion_id": "2077471210",
        "commented_code": "@@ -1937,19 +1937,46 @@ LIMIT 100\",\n         tokio::spawn(conn);\n \n         // TODO: support other types of grants apart from schemas?\n-        let query = format!(\n-            \"GRANT {} ON SCHEMA {} TO {}\",\n-            privileges\n-                .iter()\n-                // should not be quoted as it's part of the command.\n-                // is already sanitized so it's ok\n-                .map(|p| p.as_str())\n-                .collect::<Vec<&'static str>>()\n-                .join(\", \"),\n-            // quote the schema and role name as identifiers to sanitize them.\n-            schema_name.pg_quote(),\n-            role_name.pg_quote(),\n-        );\n+\n+        // check the role grants first - to gracefully handle read-replicas.\n+        let select = \"SELECT privilege_type\n+            FROM pg_namespace\n+                JOIN LATERAL (SELECT * FROM aclexplode(nspacl) AS x) acl ON true\n+                JOIN pg_user users ON acl.grantee = users.usesysid\n+            WHERE users.usename = $1\n+                AND nspname = $2\";\n+        let rows = db_client\n+            .query(select, &[role_name, schema_name])\n+            .await\n+            .with_context(|| format!(\"Failed to execute query: {select}\"))?;\n+\n+        let mut already_granted = HashSet::new();\n+        for row in rows {\n+            let grant: String = row.get(0);\n+            already_granted.insert(grant);\n+        }\n+\n+        // check if all privileges are granted.\n+        if privileges\n+            .iter()\n+            .all(|g| already_granted.contains(g.as_str()))\n+        {\n+            return Ok(());\n+        }\n+\n+        let grants = privileges\n+            .iter()\n+            // should not be quoted as it's part of the command.\n+            // is already sanitized so it's ok\n+            .map(|p| p.as_str())\n+            .collect::<Vec<&'static str>>()",
        "comment_created_at": "2025-05-07T12:09:42+00:00",
        "comment_author": "myrrc",
        "comment_body": "Also nit: if some of privileges may already be granted, maybe we should \r\n1. Take an iter of privileges\r\n2. Filter out those contained in `already_granted`?\r\n3. If iterator is non-empty, join using itertools and grant?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2070652758",
    "pr_number": 11550,
    "pr_file": "compute_tools/src/compute.rs",
    "created_at": "2025-05-01T18:49:56+00:00",
    "commented_code": "info!(\"Pageserver config changed\");\n         }\n     }\n+\n+    // If prewarm failed, we want to get overall number of segments as well as done ones.\n+    // However, this function should be reliable even if querying postgres failed.\n+    pub async fn prewarm_status(&self) -> PrewarmStatus {\n+        info!(\"requesting LFC prewarm status from postgres\");\n+        let mut status = PrewarmStatus::default();\n+        {\n+            let state = &self.state.lock().unwrap().prewarm_state;\n+            status.status = state.status;\n+            status.error = state.error.clone();\n+        }\n+\n+        let res = match ComputeNode::get_maintenance_client(&self.tokio_conn_conf).await {\n+            Ok(res) => res,\n+            Err(err) => {\n+                error!(%err, \"connecting to postgres\");\n+                return status;\n+            }\n+        };\n+        let row = match res.query_one(\"select * from get_prewarm_info()\", &[]).await {\n+            Ok(row) => row,\n+            Err(err) => {\n+                error!(%err, \"querying LFC prewarm status\");\n+                return status;\n+            }\n+        };\n+        status.total = row.try_get(0).unwrap_or_default();\n+        status.prewarmed = row.try_get(1).unwrap_or_default();\n+        status.skipped = row.try_get(2).unwrap_or_default();\n+\n+        status\n+    }\n+\n+    pub async fn prewarm_offload_status(&self) -> PrewarmOffloadState {\n+        self.state.lock().unwrap().prewarm_offload_state.clone()\n+    }\n+\n+    pub async fn prewarm(self: &Arc<Self>, pair: EndpointStoragePair) -> bool {\n+        crate::metrics::LFC_PREWARM_REQUESTS.inc();\n+        use compute_api::responses::PrewarmStatus::*;\n+        {\n+            let status = &mut self.state.lock().unwrap().prewarm_state.status;\n+            if *status == Prewarming {\n+                return false;\n+            }\n+            *status = Prewarming;\n+        }\n+\n+        let cloned = self.clone();",
    "repo_full_name": "neondatabase/neon",
    "discussion_comments": [
      {
        "comment_id": "2070652758",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 11550,
        "pr_file": "compute_tools/src/compute.rs",
        "discussion_id": "2070652758",
        "commented_code": "@@ -2123,6 +2216,158 @@ LIMIT 100\",\n             info!(\"Pageserver config changed\");\n         }\n     }\n+\n+    // If prewarm failed, we want to get overall number of segments as well as done ones.\n+    // However, this function should be reliable even if querying postgres failed.\n+    pub async fn prewarm_status(&self) -> PrewarmStatus {\n+        info!(\"requesting LFC prewarm status from postgres\");\n+        let mut status = PrewarmStatus::default();\n+        {\n+            let state = &self.state.lock().unwrap().prewarm_state;\n+            status.status = state.status;\n+            status.error = state.error.clone();\n+        }\n+\n+        let res = match ComputeNode::get_maintenance_client(&self.tokio_conn_conf).await {\n+            Ok(res) => res,\n+            Err(err) => {\n+                error!(%err, \"connecting to postgres\");\n+                return status;\n+            }\n+        };\n+        let row = match res.query_one(\"select * from get_prewarm_info()\", &[]).await {\n+            Ok(row) => row,\n+            Err(err) => {\n+                error!(%err, \"querying LFC prewarm status\");\n+                return status;\n+            }\n+        };\n+        status.total = row.try_get(0).unwrap_or_default();\n+        status.prewarmed = row.try_get(1).unwrap_or_default();\n+        status.skipped = row.try_get(2).unwrap_or_default();\n+\n+        status\n+    }\n+\n+    pub async fn prewarm_offload_status(&self) -> PrewarmOffloadState {\n+        self.state.lock().unwrap().prewarm_offload_state.clone()\n+    }\n+\n+    pub async fn prewarm(self: &Arc<Self>, pair: EndpointStoragePair) -> bool {\n+        crate::metrics::LFC_PREWARM_REQUESTS.inc();\n+        use compute_api::responses::PrewarmStatus::*;\n+        {\n+            let status = &mut self.state.lock().unwrap().prewarm_state.status;\n+            if *status == Prewarming {\n+                return false;\n+            }\n+            *status = Prewarming;\n+        }\n+\n+        let cloned = self.clone();",
        "comment_created_at": "2025-05-01T18:49:56+00:00",
        "comment_author": "tristan957",
        "comment_body": "This is very strange to me. At the previous call site that I reviewed, we already spawned and cloned, and now we are doing it again. Please avoid that. Then you can probably inline the `impl` version of the function.",
        "pr_file_module": null
      },
      {
        "comment_id": "2072605385",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 11550,
        "pr_file": "compute_tools/src/compute.rs",
        "discussion_id": "2070652758",
        "commented_code": "@@ -2123,6 +2216,158 @@ LIMIT 100\",\n             info!(\"Pageserver config changed\");\n         }\n     }\n+\n+    // If prewarm failed, we want to get overall number of segments as well as done ones.\n+    // However, this function should be reliable even if querying postgres failed.\n+    pub async fn prewarm_status(&self) -> PrewarmStatus {\n+        info!(\"requesting LFC prewarm status from postgres\");\n+        let mut status = PrewarmStatus::default();\n+        {\n+            let state = &self.state.lock().unwrap().prewarm_state;\n+            status.status = state.status;\n+            status.error = state.error.clone();\n+        }\n+\n+        let res = match ComputeNode::get_maintenance_client(&self.tokio_conn_conf).await {\n+            Ok(res) => res,\n+            Err(err) => {\n+                error!(%err, \"connecting to postgres\");\n+                return status;\n+            }\n+        };\n+        let row = match res.query_one(\"select * from get_prewarm_info()\", &[]).await {\n+            Ok(row) => row,\n+            Err(err) => {\n+                error!(%err, \"querying LFC prewarm status\");\n+                return status;\n+            }\n+        };\n+        status.total = row.try_get(0).unwrap_or_default();\n+        status.prewarmed = row.try_get(1).unwrap_or_default();\n+        status.skipped = row.try_get(2).unwrap_or_default();\n+\n+        status\n+    }\n+\n+    pub async fn prewarm_offload_status(&self) -> PrewarmOffloadState {\n+        self.state.lock().unwrap().prewarm_offload_state.clone()\n+    }\n+\n+    pub async fn prewarm(self: &Arc<Self>, pair: EndpointStoragePair) -> bool {\n+        crate::metrics::LFC_PREWARM_REQUESTS.inc();\n+        use compute_api::responses::PrewarmStatus::*;\n+        {\n+            let status = &mut self.state.lock().unwrap().prewarm_state.status;\n+            if *status == Prewarming {\n+                return false;\n+            }\n+            *status = Prewarming;\n+        }\n+\n+        let cloned = self.clone();",
        "comment_created_at": "2025-05-04T12:28:58+00:00",
        "comment_author": "myrrc",
        "comment_body": "Fixed",
        "pr_file_module": null
      }
    ]
  }
]