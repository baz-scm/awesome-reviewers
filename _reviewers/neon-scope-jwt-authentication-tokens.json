[
  {
    "discussion_id": "2003206709",
    "pr_number": 11294,
    "pr_file": "docs/rfcs/2025-03-17-compute-prewarm.md",
    "created_at": "2025-03-19T12:25:37+00:00",
    "commented_code": "+# Compute rolling restart with prewarm\n+\n+Created on 2025-03-17\n+Implemented on _TBD_\n+Author: Alexey Kondratov (@ololobus)\n+\n+## Summary\n+\n+This RFC describes an approach to reduce performance degradation due to missing caches after compute node restart, i.e.:\n+\n+1. Rolling restart of the running instance via 'warm' replica.\n+2. Auto-prewarm compute caches after unplanned restart or scale-to-zero.\n+\n+## Motivation\n+\n+Neon currently implements several features that guarantee high uptime of compute nodes:\n+\n+1. Storage high-availability (HA), i.e. each tenant shard has a secondary pageserver location, so we can quickly switch over compute to it in case of primary pageserver failure.\n+2. Fast compute provisioning, i.e. we have a fleet of pre-created empty computes, that are ready to serve workload, so restarting unresponsive compute is very fast.\n+3. Preemptive NeonVM compute provisioning in case of k8s node unavailability.\n+\n+This helps us to be well-within the uptime SLO of 99.95% most of the time. Problems begin when we go up to multi-TB workloads and 32-64 CU computes.\n+During restart, compute looses all caches: LFC, shared buffers, file system cache. Depending on the workload, it can take a lot of time to warm up the caches,\n+so that performance could be degraded and might be even unacceptable for certain workloads. The latter means that although current approach works well for small to\n+medium workloads, we still have to do some additional work to avoid performance degradation after restart of large instances.\n+\n+## Non Goals\n+\n+- Details of the persistence storage for prewarm data are out of scope, there is a separate RFC for that: <https://github.com/neondatabase/neon/pull/9661>.\n+- Complete compute/Postgres HA setup and flow. Although it was originally in scope of this RFC, during preliminary research it appeared to be a rabbit hole, so it's worth of a separate RFC.\n+- Low-level implementation details for Postgres replica-to-primary promotion. There are a lot of things to think and care about: how to start walproposer, [logical replication failover](https://www.postgresql.org/docs/current/logical-replication-failover.html), and so on, but it's worth of at least a separate one-pager design document if not RFC.\n+\n+## Impacted components\n+\n+Postgres, compute_ctl, Control plane, S3 proxy for unlogged storage of compute files.\n+\n+## Proposed implementation\n+\n+### compute_ctl spec changes and auto-prewarm\n+\n+We are going to extend the current compute spec with the following attributes\n+\n+```rust\n+struct ComputeSpec {\n+    /// [All existing attributes]\n+    ...\n+    /// Whether to do auto-prewarm at start or not.\n+    /// Default to `false`.\n+    pub lfc_auto_prewarm: bool\n+    /// Interval in seconds between automatic dumps of\n+    /// LFC state into S3. Default `None`, which means 'off'.\n+    pub lfc_dump_interval_sec: Option<i32>\n+}\n+```\n+\n+When `lfc_dump_interval_sec` is set to `N`, `compute_ctl` will periodically dump the LFC state\n+and store it in S3, so that it could be used either for auto-prewarm after restart or by replica\n+during the rolling restart.\n+\n+When `lfc_auto_prewarm` is set to `true`, `compute_ctl` will start prewarming the LFC upon restart\n+iif some of the previous states is present in S3.\n+\n+### compute_ctl API\n+\n+1. `POST /store_lfc_state` -- dump LFC state using Postgres SQL interface and store result in S3.\n+    This has to be a blocking call, i.e. it will return only after the state is stored in S3.\n+    If there is any concurrent request in progress, we should return `429 Too Many Requests`,\n+    and let the caller to retry.\n+\n+2. `GET /dump_lfc_state` -- dump LFC state using Postgres SQL interface and return it as is\n+    in text format suitable for the future restore/prewarm. This API is not strictly needed at\n+    the end state, but could be useful for a faster prototyping of a complete rolling restart flow\n+    with prewarm, as it doesn't require persistent for LFC state storage.\n+\n+3. `POST /restore_lfc_state` -- restore/prewarm LFC state with request\n+\n+    ```yaml\n+    RestoreLFCStateRequest:\n+      oneOf:\n+        - type: object\n+          required:\n+            - lfc_state\n+          properties:\n+            lfc_state:\n+              type: string\n+              description: Raw LFC content dumped with GET `/dump_lfc_state`\n+        - type: object\n+          required:\n+            - lfc_cache_key\n+          properties:\n+            lfc_cache_key:\n+              type: string\n+              description: |\n+                endpoint_id of the source endpoint on the same branch\n+                to use as a 'donor' for LFC content. Compute will look up\n+                LFC content dump in S3 using this key and do prewarm.\n+    ```\n+\n+    where `lfc_state` and `lfc_cache_key` are mutually exclusive.\n+\n+    The actual prewarming will happen asynchronously, so the caller need to check the\n+    prewarm status using the compute's standard `GET /status` API.\n+\n+4. `GET /status` -- extend existing API with following attributes\n+\n+    ```rust\n+    struct ComputeStatusResponse {\n+        // [All existing attributes]\n+        ...\n+        pub prewarm_state: PrewarmState\n+    }\n+\n+    /// Compute prewarm state. Will be stored in the shared Compute state\n+    //. in compute_ctl\n+    struct PrewarmState {\n+        pub status: PrewarmStatus\n+        /// Prewarm progress in the range [0, 1]\n+        pub progress: f32\n+        /// Optional prewarm error\n+        pub error: Option<String>\n+    }\n+\n+    pub enum PrewarmStatus {\n+        /// Prewarming was never requested on this compute\n+        Off,\n+        /// Prewarming was requested, but not started yet\n+        Pending,\n+        /// Prewarming is in progress. The caller should follow\n+        /// `PrewarmState::progress`.\n+        InProgress,\n+        /// Prewarming has been successfully completed\n+        Completed,\n+        /// Prewarming failed. The caller should look at\n+        /// `PrewarmState::error` for the reason.\n+        Failed,\n+        /// It is intended to be used by auto-prewarm if none of\n+        /// the previous LFC states is available in S3.\n+        /// This is a distinct state from the `Failed` because\n+        /// technically it's not a failure and could happen if\n+        /// compute was restart before it dumped anything into S3,\n+        /// or just after the initial rollout of the feature.\n+        Skipped,\n+    }\n+    ```\n+\n+5. `POST /promote` -- this is a **blocking** API call to promote compute replica into primary.\n+    - If promotion is done successfully, it will return `200 OK`.\n+    - If compute is already primary, the call will be no-op and `compute_ctl`\n+      will return `412 Precondition Failed`.\n+    - If, for some reason, second request reaches compute that is in progress of promotion,\n+      it will respond with `429 Too Many Requests`.\n+    - If compute hit any permanent failure during promotion `500 Internal Server Error`\n+      will be returned.\n+\n+### Control plane operations\n+\n+The complete flow will be present as a sequence diagram in the next section, but here\n+we just want to list some important steps that have to be done by control plane during\n+the rolling restart via warm replica, but without much of low-level implementation details.\n+\n+1. Register the 'intent' of the instance restart, but not yet interrupt any workload at\n+    primary and also accept new connections. This may require some endpoint state machine\n+    changes, e.g. introduction of the `pending_restart` state. Being in this state also\n+    **mustn't prevent any other operations except restart**: suspend, live-reconfiguration\n+    (e.g. due to notify-attach call from the storage controller), deletion.\n+\n+2. Start new replica compute on the same timeline and start prewarming it. This process\n+    may take quite a while, so the same concurrency considerations as in 1. should be applied\n+    here as well.\n+\n+3. When warm replica is ready, control plane should:\n+\n+    3.1. Terminate the primary compute. Starting from here, **this is a critical section**,\n+        if anything goes off, the only option is to start the primary normally and proceed\n+        with auto-prewarm.\n+\n+    3.2. Send cache invalidation message to all proxies, notifying them that all new connections\n+        should request and wait for the new connection details.\n+\n+    3.3. Attach warm replica compute to the primary endpoint inside control plane metadata\n+        database.\n+\n+    3.4. Promote replica to primary.\n+\n+    3.5. When everything is done, finalize the endpoint state to be just `active`.\n+\n+### Complete rolling restart flow\n+\n+```mermaid\n+  sequenceDiagram\n+\n+  autonumber\n+\n+  participant proxy as Neon proxy\n+\n+  participant cplane as Control plane\n+\n+  participant primary as Compute (primary)\n+  box Compute (replica)\n+    participant ctl as compute_ctl\n+    participant pg as Postgres\n+  end\n+\n+  box Endpoint unlogged storage\n+    participant s3proxy as S3 proxy\n+    participant s3 as S3\n+  end\n+\n+\n+  cplane ->> primary: POST /store_lfc_state\n+  primary -->> cplane: 200 OK\n+\n+  cplane ->> ctl: POST /restore_lfc_state\n+  activate ctl\n+  ctl -->> cplane: 202 Accepted\n+\n+  activate cplane\n+  cplane ->> ctl: GET /status: poll prewarm status\n+  ctl ->> s3proxy: GET /read_file\n+  s3proxy ->> s3: read file\n+  s3 -->> s3proxy: file content\n+  s3proxy -->> ctl: 200 OK: file content\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+  cplane -->> proxy: 200 OK: old primary conninfo\n+\n+  ctl ->> pg: prewarm LFC\n+  activate pg\n+  pg -->> ctl: prewarm is completed\n+  deactivate pg\n+\n+  ctl -->> cplane: 200 OK: prewarm is completed\n+  deactivate ctl\n+  deactivate cplane\n+\n+  cplane -->> cplane: reassign replica compute to endpoint,<br>start terminating the old primary compute\n+  activate cplane\n+  cplane ->> proxy: invalidate caches\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+\n+  cplane -x primary: POST /terminate\n+  primary -->> cplane: 200 OK\n+  note over primary: old primary<br>compute terminated\n+\n+  cplane ->> ctl: POST /promote\n+  activate ctl\n+  ctl ->> pg: pg_ctl promote\n+  activate pg\n+  pg -->> ctl: done\n+  deactivate pg\n+  ctl -->> cplane: 200 OK\n+  deactivate ctl\n+\n+  cplane -->> cplane: finalize operation\n+  cplane -->> proxy: 200 OK: new primary conninfo\n+  deactivate cplane\n+```\n+\n+### Reliability, failure modes and corner cases\n+\n+We consider following failures while implementing this RFC:\n+\n+1. Compute got interrupted/crashed/restarted during prewarm. The caller -- control plane -- should\n+    detect that and start prewarm from the beginning.\n+\n+2. Control plane promotion request timed out or hit network issues. If it never reached the\n+    compute, control plane should just repeat it. If it did reach the compute, then during\n+    retry control plane can hit `409` as previous request triggered the promotion already.\n+    In this case, control plane need to retry until either `200` or\n+    permanent error `500` is returned.\n+\n+3. Compute got interrupted/crashed/restarted during promotion. At restart it will ask for\n+    a spec from control plane, and its content should signal compute to start as **primary**,\n+    so it's expected that control plane will continue polling for certain period of time and\n+    will discover that compute is ready to accept connections if restart is fast enough.\n+\n+4. Any other unexpected failure or timeout during prewarming. This **failure mustn't be fatal**,\n+    control plane has to report failure, terminate replica and keep primary running.\n+\n+5. Any other unexpected failure or timeout during promotion. Unfortunately, at this moment\n+    we already have the primary node stopped, so the only option is to start primary again\n+    and proceed with auto-prewarm.\n+\n+6. Any unexpected failure during auto-prewarm. This **failure mustn't be fatal**,\n+    `compute_ctl` has to report the failure, but do not crash the compute.\n+\n+### Security implications\n+\n+There are two security implications to consider:\n+\n+1. Access to `compute_ctl` API. It has to be accessible from the outside of compute, so all\n+    new API methods have to be exposed on the **external** HTTP port and **must** be authenticated\n+    with JWT.\n+\n+2. Read/write only your own LFC state data in S3. Although it's not really a security concern,\n+    since LFC state is just a mapping of blocks present in LFC at certain moment in time;\n+    it still has to be highly restricted, so that i) only computes on the same timeline can\n+    read S3 state; ii) each compute can only write to the path that contains it's `endpoint_id`.\n+    Both of this must be validated by S3 proxy and JWT token used by `compute_ctl`.",
    "repo_full_name": "neondatabase/neon",
    "discussion_comments": [
      {
        "comment_id": "2003206709",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 11294,
        "pr_file": "docs/rfcs/2025-03-17-compute-prewarm.md",
        "discussion_id": "2003206709",
        "commented_code": "@@ -0,0 +1,345 @@\n+# Compute rolling restart with prewarm\n+\n+Created on 2025-03-17\n+Implemented on _TBD_\n+Author: Alexey Kondratov (@ololobus)\n+\n+## Summary\n+\n+This RFC describes an approach to reduce performance degradation due to missing caches after compute node restart, i.e.:\n+\n+1. Rolling restart of the running instance via 'warm' replica.\n+2. Auto-prewarm compute caches after unplanned restart or scale-to-zero.\n+\n+## Motivation\n+\n+Neon currently implements several features that guarantee high uptime of compute nodes:\n+\n+1. Storage high-availability (HA), i.e. each tenant shard has a secondary pageserver location, so we can quickly switch over compute to it in case of primary pageserver failure.\n+2. Fast compute provisioning, i.e. we have a fleet of pre-created empty computes, that are ready to serve workload, so restarting unresponsive compute is very fast.\n+3. Preemptive NeonVM compute provisioning in case of k8s node unavailability.\n+\n+This helps us to be well-within the uptime SLO of 99.95% most of the time. Problems begin when we go up to multi-TB workloads and 32-64 CU computes.\n+During restart, compute looses all caches: LFC, shared buffers, file system cache. Depending on the workload, it can take a lot of time to warm up the caches,\n+so that performance could be degraded and might be even unacceptable for certain workloads. The latter means that although current approach works well for small to\n+medium workloads, we still have to do some additional work to avoid performance degradation after restart of large instances.\n+\n+## Non Goals\n+\n+- Details of the persistence storage for prewarm data are out of scope, there is a separate RFC for that: <https://github.com/neondatabase/neon/pull/9661>.\n+- Complete compute/Postgres HA setup and flow. Although it was originally in scope of this RFC, during preliminary research it appeared to be a rabbit hole, so it's worth of a separate RFC.\n+- Low-level implementation details for Postgres replica-to-primary promotion. There are a lot of things to think and care about: how to start walproposer, [logical replication failover](https://www.postgresql.org/docs/current/logical-replication-failover.html), and so on, but it's worth of at least a separate one-pager design document if not RFC.\n+\n+## Impacted components\n+\n+Postgres, compute_ctl, Control plane, S3 proxy for unlogged storage of compute files.\n+\n+## Proposed implementation\n+\n+### compute_ctl spec changes and auto-prewarm\n+\n+We are going to extend the current compute spec with the following attributes\n+\n+```rust\n+struct ComputeSpec {\n+    /// [All existing attributes]\n+    ...\n+    /// Whether to do auto-prewarm at start or not.\n+    /// Default to `false`.\n+    pub lfc_auto_prewarm: bool\n+    /// Interval in seconds between automatic dumps of\n+    /// LFC state into S3. Default `None`, which means 'off'.\n+    pub lfc_dump_interval_sec: Option<i32>\n+}\n+```\n+\n+When `lfc_dump_interval_sec` is set to `N`, `compute_ctl` will periodically dump the LFC state\n+and store it in S3, so that it could be used either for auto-prewarm after restart or by replica\n+during the rolling restart.\n+\n+When `lfc_auto_prewarm` is set to `true`, `compute_ctl` will start prewarming the LFC upon restart\n+iif some of the previous states is present in S3.\n+\n+### compute_ctl API\n+\n+1. `POST /store_lfc_state` -- dump LFC state using Postgres SQL interface and store result in S3.\n+    This has to be a blocking call, i.e. it will return only after the state is stored in S3.\n+    If there is any concurrent request in progress, we should return `429 Too Many Requests`,\n+    and let the caller to retry.\n+\n+2. `GET /dump_lfc_state` -- dump LFC state using Postgres SQL interface and return it as is\n+    in text format suitable for the future restore/prewarm. This API is not strictly needed at\n+    the end state, but could be useful for a faster prototyping of a complete rolling restart flow\n+    with prewarm, as it doesn't require persistent for LFC state storage.\n+\n+3. `POST /restore_lfc_state` -- restore/prewarm LFC state with request\n+\n+    ```yaml\n+    RestoreLFCStateRequest:\n+      oneOf:\n+        - type: object\n+          required:\n+            - lfc_state\n+          properties:\n+            lfc_state:\n+              type: string\n+              description: Raw LFC content dumped with GET `/dump_lfc_state`\n+        - type: object\n+          required:\n+            - lfc_cache_key\n+          properties:\n+            lfc_cache_key:\n+              type: string\n+              description: |\n+                endpoint_id of the source endpoint on the same branch\n+                to use as a 'donor' for LFC content. Compute will look up\n+                LFC content dump in S3 using this key and do prewarm.\n+    ```\n+\n+    where `lfc_state` and `lfc_cache_key` are mutually exclusive.\n+\n+    The actual prewarming will happen asynchronously, so the caller need to check the\n+    prewarm status using the compute's standard `GET /status` API.\n+\n+4. `GET /status` -- extend existing API with following attributes\n+\n+    ```rust\n+    struct ComputeStatusResponse {\n+        // [All existing attributes]\n+        ...\n+        pub prewarm_state: PrewarmState\n+    }\n+\n+    /// Compute prewarm state. Will be stored in the shared Compute state\n+    //. in compute_ctl\n+    struct PrewarmState {\n+        pub status: PrewarmStatus\n+        /// Prewarm progress in the range [0, 1]\n+        pub progress: f32\n+        /// Optional prewarm error\n+        pub error: Option<String>\n+    }\n+\n+    pub enum PrewarmStatus {\n+        /// Prewarming was never requested on this compute\n+        Off,\n+        /// Prewarming was requested, but not started yet\n+        Pending,\n+        /// Prewarming is in progress. The caller should follow\n+        /// `PrewarmState::progress`.\n+        InProgress,\n+        /// Prewarming has been successfully completed\n+        Completed,\n+        /// Prewarming failed. The caller should look at\n+        /// `PrewarmState::error` for the reason.\n+        Failed,\n+        /// It is intended to be used by auto-prewarm if none of\n+        /// the previous LFC states is available in S3.\n+        /// This is a distinct state from the `Failed` because\n+        /// technically it's not a failure and could happen if\n+        /// compute was restart before it dumped anything into S3,\n+        /// or just after the initial rollout of the feature.\n+        Skipped,\n+    }\n+    ```\n+\n+5. `POST /promote` -- this is a **blocking** API call to promote compute replica into primary.\n+    - If promotion is done successfully, it will return `200 OK`.\n+    - If compute is already primary, the call will be no-op and `compute_ctl`\n+      will return `412 Precondition Failed`.\n+    - If, for some reason, second request reaches compute that is in progress of promotion,\n+      it will respond with `429 Too Many Requests`.\n+    - If compute hit any permanent failure during promotion `500 Internal Server Error`\n+      will be returned.\n+\n+### Control plane operations\n+\n+The complete flow will be present as a sequence diagram in the next section, but here\n+we just want to list some important steps that have to be done by control plane during\n+the rolling restart via warm replica, but without much of low-level implementation details.\n+\n+1. Register the 'intent' of the instance restart, but not yet interrupt any workload at\n+    primary and also accept new connections. This may require some endpoint state machine\n+    changes, e.g. introduction of the `pending_restart` state. Being in this state also\n+    **mustn't prevent any other operations except restart**: suspend, live-reconfiguration\n+    (e.g. due to notify-attach call from the storage controller), deletion.\n+\n+2. Start new replica compute on the same timeline and start prewarming it. This process\n+    may take quite a while, so the same concurrency considerations as in 1. should be applied\n+    here as well.\n+\n+3. When warm replica is ready, control plane should:\n+\n+    3.1. Terminate the primary compute. Starting from here, **this is a critical section**,\n+        if anything goes off, the only option is to start the primary normally and proceed\n+        with auto-prewarm.\n+\n+    3.2. Send cache invalidation message to all proxies, notifying them that all new connections\n+        should request and wait for the new connection details.\n+\n+    3.3. Attach warm replica compute to the primary endpoint inside control plane metadata\n+        database.\n+\n+    3.4. Promote replica to primary.\n+\n+    3.5. When everything is done, finalize the endpoint state to be just `active`.\n+\n+### Complete rolling restart flow\n+\n+```mermaid\n+  sequenceDiagram\n+\n+  autonumber\n+\n+  participant proxy as Neon proxy\n+\n+  participant cplane as Control plane\n+\n+  participant primary as Compute (primary)\n+  box Compute (replica)\n+    participant ctl as compute_ctl\n+    participant pg as Postgres\n+  end\n+\n+  box Endpoint unlogged storage\n+    participant s3proxy as S3 proxy\n+    participant s3 as S3\n+  end\n+\n+\n+  cplane ->> primary: POST /store_lfc_state\n+  primary -->> cplane: 200 OK\n+\n+  cplane ->> ctl: POST /restore_lfc_state\n+  activate ctl\n+  ctl -->> cplane: 202 Accepted\n+\n+  activate cplane\n+  cplane ->> ctl: GET /status: poll prewarm status\n+  ctl ->> s3proxy: GET /read_file\n+  s3proxy ->> s3: read file\n+  s3 -->> s3proxy: file content\n+  s3proxy -->> ctl: 200 OK: file content\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+  cplane -->> proxy: 200 OK: old primary conninfo\n+\n+  ctl ->> pg: prewarm LFC\n+  activate pg\n+  pg -->> ctl: prewarm is completed\n+  deactivate pg\n+\n+  ctl -->> cplane: 200 OK: prewarm is completed\n+  deactivate ctl\n+  deactivate cplane\n+\n+  cplane -->> cplane: reassign replica compute to endpoint,<br>start terminating the old primary compute\n+  activate cplane\n+  cplane ->> proxy: invalidate caches\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+\n+  cplane -x primary: POST /terminate\n+  primary -->> cplane: 200 OK\n+  note over primary: old primary<br>compute terminated\n+\n+  cplane ->> ctl: POST /promote\n+  activate ctl\n+  ctl ->> pg: pg_ctl promote\n+  activate pg\n+  pg -->> ctl: done\n+  deactivate pg\n+  ctl -->> cplane: 200 OK\n+  deactivate ctl\n+\n+  cplane -->> cplane: finalize operation\n+  cplane -->> proxy: 200 OK: new primary conninfo\n+  deactivate cplane\n+```\n+\n+### Reliability, failure modes and corner cases\n+\n+We consider following failures while implementing this RFC:\n+\n+1. Compute got interrupted/crashed/restarted during prewarm. The caller -- control plane -- should\n+    detect that and start prewarm from the beginning.\n+\n+2. Control plane promotion request timed out or hit network issues. If it never reached the\n+    compute, control plane should just repeat it. If it did reach the compute, then during\n+    retry control plane can hit `409` as previous request triggered the promotion already.\n+    In this case, control plane need to retry until either `200` or\n+    permanent error `500` is returned.\n+\n+3. Compute got interrupted/crashed/restarted during promotion. At restart it will ask for\n+    a spec from control plane, and its content should signal compute to start as **primary**,\n+    so it's expected that control plane will continue polling for certain period of time and\n+    will discover that compute is ready to accept connections if restart is fast enough.\n+\n+4. Any other unexpected failure or timeout during prewarming. This **failure mustn't be fatal**,\n+    control plane has to report failure, terminate replica and keep primary running.\n+\n+5. Any other unexpected failure or timeout during promotion. Unfortunately, at this moment\n+    we already have the primary node stopped, so the only option is to start primary again\n+    and proceed with auto-prewarm.\n+\n+6. Any unexpected failure during auto-prewarm. This **failure mustn't be fatal**,\n+    `compute_ctl` has to report the failure, but do not crash the compute.\n+\n+### Security implications\n+\n+There are two security implications to consider:\n+\n+1. Access to `compute_ctl` API. It has to be accessible from the outside of compute, so all\n+    new API methods have to be exposed on the **external** HTTP port and **must** be authenticated\n+    with JWT.\n+\n+2. Read/write only your own LFC state data in S3. Although it's not really a security concern,\n+    since LFC state is just a mapping of blocks present in LFC at certain moment in time;\n+    it still has to be highly restricted, so that i) only computes on the same timeline can\n+    read S3 state; ii) each compute can only write to the path that contains it's `endpoint_id`.\n+    Both of this must be validated by S3 proxy and JWT token used by `compute_ctl`.",
        "comment_created_at": "2025-03-19T12:25:37+00:00",
        "comment_author": "MMeent",
        "comment_body": "The RFC for this storage service https://github.com/neondatabase/neon/pull/9661 implies that compute's tokens won't contain information about which endpoint it is, so the \"S3 proxy\" (which isn't just that, and thus probably shouldn't be called that) **can't** validate that the request came from a compute with the right endpoint_id.",
        "pr_file_module": null
      },
      {
        "comment_id": "2003880956",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 11294,
        "pr_file": "docs/rfcs/2025-03-17-compute-prewarm.md",
        "discussion_id": "2003206709",
        "commented_code": "@@ -0,0 +1,345 @@\n+# Compute rolling restart with prewarm\n+\n+Created on 2025-03-17\n+Implemented on _TBD_\n+Author: Alexey Kondratov (@ololobus)\n+\n+## Summary\n+\n+This RFC describes an approach to reduce performance degradation due to missing caches after compute node restart, i.e.:\n+\n+1. Rolling restart of the running instance via 'warm' replica.\n+2. Auto-prewarm compute caches after unplanned restart or scale-to-zero.\n+\n+## Motivation\n+\n+Neon currently implements several features that guarantee high uptime of compute nodes:\n+\n+1. Storage high-availability (HA), i.e. each tenant shard has a secondary pageserver location, so we can quickly switch over compute to it in case of primary pageserver failure.\n+2. Fast compute provisioning, i.e. we have a fleet of pre-created empty computes, that are ready to serve workload, so restarting unresponsive compute is very fast.\n+3. Preemptive NeonVM compute provisioning in case of k8s node unavailability.\n+\n+This helps us to be well-within the uptime SLO of 99.95% most of the time. Problems begin when we go up to multi-TB workloads and 32-64 CU computes.\n+During restart, compute looses all caches: LFC, shared buffers, file system cache. Depending on the workload, it can take a lot of time to warm up the caches,\n+so that performance could be degraded and might be even unacceptable for certain workloads. The latter means that although current approach works well for small to\n+medium workloads, we still have to do some additional work to avoid performance degradation after restart of large instances.\n+\n+## Non Goals\n+\n+- Details of the persistence storage for prewarm data are out of scope, there is a separate RFC for that: <https://github.com/neondatabase/neon/pull/9661>.\n+- Complete compute/Postgres HA setup and flow. Although it was originally in scope of this RFC, during preliminary research it appeared to be a rabbit hole, so it's worth of a separate RFC.\n+- Low-level implementation details for Postgres replica-to-primary promotion. There are a lot of things to think and care about: how to start walproposer, [logical replication failover](https://www.postgresql.org/docs/current/logical-replication-failover.html), and so on, but it's worth of at least a separate one-pager design document if not RFC.\n+\n+## Impacted components\n+\n+Postgres, compute_ctl, Control plane, S3 proxy for unlogged storage of compute files.\n+\n+## Proposed implementation\n+\n+### compute_ctl spec changes and auto-prewarm\n+\n+We are going to extend the current compute spec with the following attributes\n+\n+```rust\n+struct ComputeSpec {\n+    /// [All existing attributes]\n+    ...\n+    /// Whether to do auto-prewarm at start or not.\n+    /// Default to `false`.\n+    pub lfc_auto_prewarm: bool\n+    /// Interval in seconds between automatic dumps of\n+    /// LFC state into S3. Default `None`, which means 'off'.\n+    pub lfc_dump_interval_sec: Option<i32>\n+}\n+```\n+\n+When `lfc_dump_interval_sec` is set to `N`, `compute_ctl` will periodically dump the LFC state\n+and store it in S3, so that it could be used either for auto-prewarm after restart or by replica\n+during the rolling restart.\n+\n+When `lfc_auto_prewarm` is set to `true`, `compute_ctl` will start prewarming the LFC upon restart\n+iif some of the previous states is present in S3.\n+\n+### compute_ctl API\n+\n+1. `POST /store_lfc_state` -- dump LFC state using Postgres SQL interface and store result in S3.\n+    This has to be a blocking call, i.e. it will return only after the state is stored in S3.\n+    If there is any concurrent request in progress, we should return `429 Too Many Requests`,\n+    and let the caller to retry.\n+\n+2. `GET /dump_lfc_state` -- dump LFC state using Postgres SQL interface and return it as is\n+    in text format suitable for the future restore/prewarm. This API is not strictly needed at\n+    the end state, but could be useful for a faster prototyping of a complete rolling restart flow\n+    with prewarm, as it doesn't require persistent for LFC state storage.\n+\n+3. `POST /restore_lfc_state` -- restore/prewarm LFC state with request\n+\n+    ```yaml\n+    RestoreLFCStateRequest:\n+      oneOf:\n+        - type: object\n+          required:\n+            - lfc_state\n+          properties:\n+            lfc_state:\n+              type: string\n+              description: Raw LFC content dumped with GET `/dump_lfc_state`\n+        - type: object\n+          required:\n+            - lfc_cache_key\n+          properties:\n+            lfc_cache_key:\n+              type: string\n+              description: |\n+                endpoint_id of the source endpoint on the same branch\n+                to use as a 'donor' for LFC content. Compute will look up\n+                LFC content dump in S3 using this key and do prewarm.\n+    ```\n+\n+    where `lfc_state` and `lfc_cache_key` are mutually exclusive.\n+\n+    The actual prewarming will happen asynchronously, so the caller need to check the\n+    prewarm status using the compute's standard `GET /status` API.\n+\n+4. `GET /status` -- extend existing API with following attributes\n+\n+    ```rust\n+    struct ComputeStatusResponse {\n+        // [All existing attributes]\n+        ...\n+        pub prewarm_state: PrewarmState\n+    }\n+\n+    /// Compute prewarm state. Will be stored in the shared Compute state\n+    //. in compute_ctl\n+    struct PrewarmState {\n+        pub status: PrewarmStatus\n+        /// Prewarm progress in the range [0, 1]\n+        pub progress: f32\n+        /// Optional prewarm error\n+        pub error: Option<String>\n+    }\n+\n+    pub enum PrewarmStatus {\n+        /// Prewarming was never requested on this compute\n+        Off,\n+        /// Prewarming was requested, but not started yet\n+        Pending,\n+        /// Prewarming is in progress. The caller should follow\n+        /// `PrewarmState::progress`.\n+        InProgress,\n+        /// Prewarming has been successfully completed\n+        Completed,\n+        /// Prewarming failed. The caller should look at\n+        /// `PrewarmState::error` for the reason.\n+        Failed,\n+        /// It is intended to be used by auto-prewarm if none of\n+        /// the previous LFC states is available in S3.\n+        /// This is a distinct state from the `Failed` because\n+        /// technically it's not a failure and could happen if\n+        /// compute was restart before it dumped anything into S3,\n+        /// or just after the initial rollout of the feature.\n+        Skipped,\n+    }\n+    ```\n+\n+5. `POST /promote` -- this is a **blocking** API call to promote compute replica into primary.\n+    - If promotion is done successfully, it will return `200 OK`.\n+    - If compute is already primary, the call will be no-op and `compute_ctl`\n+      will return `412 Precondition Failed`.\n+    - If, for some reason, second request reaches compute that is in progress of promotion,\n+      it will respond with `429 Too Many Requests`.\n+    - If compute hit any permanent failure during promotion `500 Internal Server Error`\n+      will be returned.\n+\n+### Control plane operations\n+\n+The complete flow will be present as a sequence diagram in the next section, but here\n+we just want to list some important steps that have to be done by control plane during\n+the rolling restart via warm replica, but without much of low-level implementation details.\n+\n+1. Register the 'intent' of the instance restart, but not yet interrupt any workload at\n+    primary and also accept new connections. This may require some endpoint state machine\n+    changes, e.g. introduction of the `pending_restart` state. Being in this state also\n+    **mustn't prevent any other operations except restart**: suspend, live-reconfiguration\n+    (e.g. due to notify-attach call from the storage controller), deletion.\n+\n+2. Start new replica compute on the same timeline and start prewarming it. This process\n+    may take quite a while, so the same concurrency considerations as in 1. should be applied\n+    here as well.\n+\n+3. When warm replica is ready, control plane should:\n+\n+    3.1. Terminate the primary compute. Starting from here, **this is a critical section**,\n+        if anything goes off, the only option is to start the primary normally and proceed\n+        with auto-prewarm.\n+\n+    3.2. Send cache invalidation message to all proxies, notifying them that all new connections\n+        should request and wait for the new connection details.\n+\n+    3.3. Attach warm replica compute to the primary endpoint inside control plane metadata\n+        database.\n+\n+    3.4. Promote replica to primary.\n+\n+    3.5. When everything is done, finalize the endpoint state to be just `active`.\n+\n+### Complete rolling restart flow\n+\n+```mermaid\n+  sequenceDiagram\n+\n+  autonumber\n+\n+  participant proxy as Neon proxy\n+\n+  participant cplane as Control plane\n+\n+  participant primary as Compute (primary)\n+  box Compute (replica)\n+    participant ctl as compute_ctl\n+    participant pg as Postgres\n+  end\n+\n+  box Endpoint unlogged storage\n+    participant s3proxy as S3 proxy\n+    participant s3 as S3\n+  end\n+\n+\n+  cplane ->> primary: POST /store_lfc_state\n+  primary -->> cplane: 200 OK\n+\n+  cplane ->> ctl: POST /restore_lfc_state\n+  activate ctl\n+  ctl -->> cplane: 202 Accepted\n+\n+  activate cplane\n+  cplane ->> ctl: GET /status: poll prewarm status\n+  ctl ->> s3proxy: GET /read_file\n+  s3proxy ->> s3: read file\n+  s3 -->> s3proxy: file content\n+  s3proxy -->> ctl: 200 OK: file content\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+  cplane -->> proxy: 200 OK: old primary conninfo\n+\n+  ctl ->> pg: prewarm LFC\n+  activate pg\n+  pg -->> ctl: prewarm is completed\n+  deactivate pg\n+\n+  ctl -->> cplane: 200 OK: prewarm is completed\n+  deactivate ctl\n+  deactivate cplane\n+\n+  cplane -->> cplane: reassign replica compute to endpoint,<br>start terminating the old primary compute\n+  activate cplane\n+  cplane ->> proxy: invalidate caches\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+\n+  cplane -x primary: POST /terminate\n+  primary -->> cplane: 200 OK\n+  note over primary: old primary<br>compute terminated\n+\n+  cplane ->> ctl: POST /promote\n+  activate ctl\n+  ctl ->> pg: pg_ctl promote\n+  activate pg\n+  pg -->> ctl: done\n+  deactivate pg\n+  ctl -->> cplane: 200 OK\n+  deactivate ctl\n+\n+  cplane -->> cplane: finalize operation\n+  cplane -->> proxy: 200 OK: new primary conninfo\n+  deactivate cplane\n+```\n+\n+### Reliability, failure modes and corner cases\n+\n+We consider following failures while implementing this RFC:\n+\n+1. Compute got interrupted/crashed/restarted during prewarm. The caller -- control plane -- should\n+    detect that and start prewarm from the beginning.\n+\n+2. Control plane promotion request timed out or hit network issues. If it never reached the\n+    compute, control plane should just repeat it. If it did reach the compute, then during\n+    retry control plane can hit `409` as previous request triggered the promotion already.\n+    In this case, control plane need to retry until either `200` or\n+    permanent error `500` is returned.\n+\n+3. Compute got interrupted/crashed/restarted during promotion. At restart it will ask for\n+    a spec from control plane, and its content should signal compute to start as **primary**,\n+    so it's expected that control plane will continue polling for certain period of time and\n+    will discover that compute is ready to accept connections if restart is fast enough.\n+\n+4. Any other unexpected failure or timeout during prewarming. This **failure mustn't be fatal**,\n+    control plane has to report failure, terminate replica and keep primary running.\n+\n+5. Any other unexpected failure or timeout during promotion. Unfortunately, at this moment\n+    we already have the primary node stopped, so the only option is to start primary again\n+    and proceed with auto-prewarm.\n+\n+6. Any unexpected failure during auto-prewarm. This **failure mustn't be fatal**,\n+    `compute_ctl` has to report the failure, but do not crash the compute.\n+\n+### Security implications\n+\n+There are two security implications to consider:\n+\n+1. Access to `compute_ctl` API. It has to be accessible from the outside of compute, so all\n+    new API methods have to be exposed on the **external** HTTP port and **must** be authenticated\n+    with JWT.\n+\n+2. Read/write only your own LFC state data in S3. Although it's not really a security concern,\n+    since LFC state is just a mapping of blocks present in LFC at certain moment in time;\n+    it still has to be highly restricted, so that i) only computes on the same timeline can\n+    read S3 state; ii) each compute can only write to the path that contains it's `endpoint_id`.\n+    Both of this must be validated by S3 proxy and JWT token used by `compute_ctl`.",
        "comment_created_at": "2025-03-19T17:23:49+00:00",
        "comment_author": "ololobus",
        "comment_body": "I think we need to add endpoint_id to the token. It won't hurt to have this extra protection to ensure that endpoints cannot write to each other sub-paths. Any problems with adding it?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2005389023",
    "pr_number": 11294,
    "pr_file": "docs/rfcs/2025-03-17-compute-prewarm.md",
    "created_at": "2025-03-20T11:26:11+00:00",
    "commented_code": "+# Compute rolling restart with prewarm\n+\n+Created on 2025-03-17\n+Implemented on _TBD_\n+Author: Alexey Kondratov (@ololobus)\n+\n+## Summary\n+\n+This RFC describes an approach to reduce performance degradation due to missing caches after compute node restart, i.e.:\n+\n+1. Rolling restart of the running instance via 'warm' replica.\n+2. Auto-prewarm compute caches after unplanned restart or scale-to-zero.\n+\n+## Motivation\n+\n+Neon currently implements several features that guarantee high uptime of compute nodes:\n+\n+1. Storage high-availability (HA), i.e. each tenant shard has a secondary pageserver location, so we can quickly switch over compute to it in case of primary pageserver failure.\n+2. Fast compute provisioning, i.e. we have a fleet of pre-created empty computes, that are ready to serve workload, so restarting unresponsive compute is very fast.\n+3. Preemptive NeonVM compute provisioning in case of k8s node unavailability.\n+\n+This helps us to be well-within the uptime SLO of 99.95% most of the time. Problems begin when we go up to multi-TB workloads and 32-64 CU computes.\n+During restart, compute loses all caches: LFC, shared buffers, file system cache. Depending on the workload, it can take a lot of time to warm up the caches,\n+so that performance could be degraded and might be even unacceptable for certain workloads. The latter means that although current approach works well for small to\n+medium workloads, we still have to do some additional work to avoid performance degradation after restart of large instances.\n+\n+## Non Goals\n+\n+- Details of the persistence storage for prewarm data are out of scope, there is a separate RFC for that: <https://github.com/neondatabase/neon/pull/9661>.\n+- Complete compute/Postgres HA setup and flow. Although it was originally in scope of this RFC, during preliminary research it appeared to be a rabbit hole, so it's worth of a separate RFC.\n+- Low-level implementation details for Postgres replica-to-primary promotion. There are a lot of things to think and care about: how to start walproposer, [logical replication failover](https://www.postgresql.org/docs/current/logical-replication-failover.html), and so on, but it's worth of at least a separate one-pager design document if not RFC.\n+\n+## Impacted components\n+\n+Postgres, compute_ctl, Control plane, Object storage proxy for unlogged storage of compute files.\n+For the latter, we will need to implement a uniform abstraction layer on top of S3, ABS, etc., but\n+S3 is used in text interchangeably with 'object storage' for simplicity.\n+\n+## Proposed implementation\n+\n+### compute_ctl spec changes and auto-prewarm\n+\n+We are going to extend the current compute spec with the following attributes\n+\n+```rust\n+struct ComputeSpec {\n+    /// [All existing attributes]\n+    ...\n+    /// Whether to do auto-prewarm at start or not.\n+    /// Default to `false`.\n+    pub lfc_auto_prewarm: bool\n+    /// Interval in seconds between automatic dumps of\n+    /// LFC state into S3. Default `None`, which means 'off'.\n+    pub lfc_dump_interval_sec: Option<i32>\n+}\n+```\n+\n+When `lfc_dump_interval_sec` is set to `N`, `compute_ctl` will periodically dump the LFC state\n+and store it in S3, so that it could be used either for auto-prewarm after restart or by replica\n+during the rolling restart. For enabling periodic dumping, we should consider the following value\n+`lfc_dump_interval_sec=300` (5 minutes), same as in the upstream's `pg_prewarm.autoprewarm_interval`.\n+\n+When `lfc_auto_prewarm` is set to `true`, `compute_ctl` will start prewarming the LFC upon restart\n+iif some of the previous states is present in S3.\n+\n+### compute_ctl API\n+\n+1. `POST /store_lfc_state` -- dump LFC state using Postgres SQL interface and store result in S3.\n+    This has to be a blocking call, i.e. it will return only after the state is stored in S3.\n+    If there is any concurrent request in progress, we should return `429 Too Many Requests`,\n+    and let the caller to retry.\n+\n+2. `GET /dump_lfc_state` -- dump LFC state using Postgres SQL interface and return it as is\n+    in text format suitable for the future restore/prewarm. This API is not strictly needed at\n+    the end state, but could be useful for a faster prototyping of a complete rolling restart flow\n+    with prewarm, as it doesn't require persistent for LFC state storage.\n+\n+3. `POST /restore_lfc_state` -- restore/prewarm LFC state with request\n+\n+    ```yaml\n+    RestoreLFCStateRequest:\n+      oneOf:\n+        - type: object\n+          required:\n+            - lfc_state\n+          properties:\n+            lfc_state:\n+              type: string\n+              description: Raw LFC content dumped with GET `/dump_lfc_state`\n+        - type: object\n+          required:\n+            - lfc_cache_key\n+          properties:\n+            lfc_cache_key:\n+              type: string\n+              description: |\n+                endpoint_id of the source endpoint on the same branch\n+                to use as a 'donor' for LFC content. Compute will look up\n+                LFC content dump in S3 using this key and do prewarm.\n+    ```\n+\n+    where `lfc_state` and `lfc_cache_key` are mutually exclusive.\n+\n+    The actual prewarming will happen asynchronously, so the caller need to check the\n+    prewarm status using the compute's standard `GET /status` API.\n+\n+4. `GET /status` -- extend existing API with following attributes\n+\n+    ```rust\n+    struct ComputeStatusResponse {\n+        // [All existing attributes]\n+        ...\n+        pub prewarm_state: PrewarmState\n+    }\n+\n+    /// Compute prewarm state. Will be stored in the shared Compute state\n+    /// in compute_ctl\n+    struct PrewarmState {\n+        pub status: PrewarmStatus\n+        /// Total number of pages to prewarm\n+        pub pages_total: i64\n+        /// Number of pages prewarmed so far\n+        pub pages_processed: i64\n+        /// Optional prewarm error\n+        pub error: Option<String>\n+    }\n+\n+    pub enum PrewarmStatus {\n+        /// Prewarming was never requested on this compute\n+        Off,\n+        /// Prewarming was requested, but not started yet\n+        Pending,\n+        /// Prewarming is in progress. The caller should follow\n+        /// `PrewarmState::progress`.\n+        InProgress,\n+        /// Prewarming has been successfully completed\n+        Completed,\n+        /// Prewarming failed. The caller should look at\n+        /// `PrewarmState::error` for the reason.\n+        Failed,\n+        /// It is intended to be used by auto-prewarm if none of\n+        /// the previous LFC states is available in S3.\n+        /// This is a distinct state from the `Failed` because\n+        /// technically it's not a failure and could happen if\n+        /// compute was restart before it dumped anything into S3,\n+        /// or just after the initial rollout of the feature.\n+        Skipped,\n+    }\n+    ```\n+\n+5. `POST /promote` -- this is a **blocking** API call to promote compute replica into primary.\n+    This API should be very similar to the existing `POST /configure` API, i.e. accept the\n+    spec (primary spec, because originally compute was started as replica). It's a distinct\n+    API method because semantics and response codes are different:\n+\n+    - If promotion is done successfully, it will return `200 OK`.\n+    - If compute is already primary, the call will be no-op and `compute_ctl`\n+      will return `412 Precondition Failed`.\n+    - If, for some reason, second request reaches compute that is in progress of promotion,\n+      it will respond with `429 Too Many Requests`.\n+    - If compute hit any permanent failure during promotion `500 Internal Server Error`\n+      will be returned.\n+\n+### Control plane operations\n+\n+The complete flow will be present as a sequence diagram in the next section, but here\n+we just want to list some important steps that have to be done by control plane during\n+the rolling restart via warm replica, but without much of low-level implementation details.\n+\n+1. Register the 'intent' of the instance restart, but not yet interrupt any workload at\n+    primary and also accept new connections. This may require some endpoint state machine\n+    changes, e.g. introduction of the `pending_restart` state. Being in this state also\n+    **mustn't prevent any other operations except restart**: suspend, live-reconfiguration\n+    (e.g. due to notify-attach call from the storage controller), deletion.\n+\n+2. Start new replica compute on the same timeline and start prewarming it. This process\n+    may take quite a while, so the same concurrency considerations as in 1. should be applied\n+    here as well.\n+\n+3. When warm replica is ready, control plane should:\n+\n+    3.1. Terminate the primary compute. Starting from here, **this is a critical section**,\n+        if anything goes off, the only option is to start the primary normally and proceed\n+        with auto-prewarm.\n+\n+    3.2. Send cache invalidation message to all proxies, notifying them that all new connections\n+        should request and wait for the new connection details. At this stage, proxy has to also\n+        drop any existing connections to the old primary, so they didn't do stale reads.\n+\n+    3.3. Attach warm replica compute to the primary endpoint inside control plane metadata\n+        database.\n+\n+    3.4. Promote replica to primary.\n+\n+    3.5. When everything is done, finalize the endpoint state to be just `active`.\n+\n+### Complete rolling restart flow\n+\n+```mermaid\n+  sequenceDiagram\n+\n+  autonumber\n+\n+  participant proxy as Neon proxy\n+\n+  participant cplane as Control plane\n+\n+  participant primary as Compute (primary)\n+  box Compute (replica)\n+    participant ctl as compute_ctl\n+    participant pg as Postgres\n+  end\n+\n+  box Endpoint unlogged storage\n+    participant s3proxy as Object storage proxy\n+    participant s3 as S3/ABS/etc\n+  end\n+\n+\n+  cplane ->> primary: POST /store_lfc_state\n+  primary -->> cplane: 200 OK\n+\n+  cplane ->> ctl: POST /restore_lfc_state\n+  activate ctl\n+  ctl -->> cplane: 202 Accepted\n+\n+  activate cplane\n+  cplane ->> ctl: GET /status: poll prewarm status\n+  ctl ->> s3proxy: GET /read_file\n+  s3proxy ->> s3: read file\n+  s3 -->> s3proxy: file content\n+  s3proxy -->> ctl: 200 OK: file content\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+  cplane -->> proxy: 200 OK: old primary conninfo\n+\n+  ctl ->> pg: prewarm LFC\n+  activate pg\n+  pg -->> ctl: prewarm is completed\n+  deactivate pg\n+\n+  ctl -->> cplane: 200 OK: prewarm is completed\n+  deactivate ctl\n+  deactivate cplane\n+\n+  cplane -->> cplane: reassign replica compute to endpoint,<br>start terminating the old primary compute\n+  activate cplane\n+  cplane ->> proxy: invalidate caches\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+\n+  cplane -x primary: POST /terminate\n+  primary -->> cplane: 200 OK\n+  note over primary: old primary<br>compute terminated\n+\n+  cplane ->> ctl: POST /promote\n+  activate ctl\n+  ctl ->> pg: pg_ctl promote\n+  activate pg\n+  pg -->> ctl: done\n+  deactivate pg\n+  ctl -->> cplane: 200 OK\n+  deactivate ctl\n+\n+  cplane -->> cplane: finalize operation\n+  cplane -->> proxy: 200 OK: new primary conninfo\n+  deactivate cplane\n+```\n+\n+### Reliability, failure modes and corner cases\n+\n+We consider following failures while implementing this RFC:\n+\n+1. Compute got interrupted/crashed/restarted during prewarm. The caller -- control plane -- should\n+    detect that and start prewarm from the beginning.\n+\n+2. Control plane promotion request timed out or hit network issues. If it never reached the\n+    compute, control plane should just repeat it. If it did reach the compute, then during\n+    retry control plane can hit `409` as previous request triggered the promotion already.\n+    In this case, control plane need to retry until either `200` or\n+    permanent error `500` is returned.\n+\n+3. Compute got interrupted/crashed/restarted during promotion. At restart it will ask for\n+    a spec from control plane, and its content should signal compute to start as **primary**,\n+    so it's expected that control plane will continue polling for certain period of time and\n+    will discover that compute is ready to accept connections if restart is fast enough.\n+\n+4. Any other unexpected failure or timeout during prewarming. This **failure mustn't be fatal**,\n+    control plane has to report failure, terminate replica and keep primary running.\n+\n+5. Any other unexpected failure or timeout during promotion. Unfortunately, at this moment\n+    we already have the primary node stopped, so the only option is to start primary again\n+    and proceed with auto-prewarm.\n+\n+6. Any unexpected failure during auto-prewarm. This **failure mustn't be fatal**,\n+    `compute_ctl` has to report the failure, but do not crash the compute.\n+\n+7. Control plane failed to confirm that old primary has terminated. This can happen, especially\n+    in the future HA setup. In this case, control plane has to ensure that it sent VM deletion\n+    and pod termination requests to k8s, so long-term we do not have two running primaries\n+    on the same timeline.\n+\n+### Security implications\n+\n+There are two security implications to consider:\n+\n+1. Access to `compute_ctl` API. It has to be accessible from the outside of compute, so all\n+    new API methods have to be exposed on the **external** HTTP port and **must** be authenticated\n+    with JWT.\n+\n+2. Read/write only your own LFC state data in S3. Although it's not really a security concern,\n+    since LFC state is just a mapping of blocks present in LFC at certain moment in time;\n+    it still has to be highly restricted, so that i) only computes on the same timeline can\n+    read S3 state; ii) each compute can only write to the path that contains it's `endpoint_id`.\n+    Both of this must be validated by S3 proxy and JWT token used by `compute_ctl`.\n+\n+### Unresolved questions\n+",
    "repo_full_name": "neondatabase/neon",
    "discussion_comments": [
      {
        "comment_id": "2005389023",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 11294,
        "pr_file": "docs/rfcs/2025-03-17-compute-prewarm.md",
        "discussion_id": "2005389023",
        "commented_code": "@@ -0,0 +1,379 @@\n+# Compute rolling restart with prewarm\n+\n+Created on 2025-03-17\n+Implemented on _TBD_\n+Author: Alexey Kondratov (@ololobus)\n+\n+## Summary\n+\n+This RFC describes an approach to reduce performance degradation due to missing caches after compute node restart, i.e.:\n+\n+1. Rolling restart of the running instance via 'warm' replica.\n+2. Auto-prewarm compute caches after unplanned restart or scale-to-zero.\n+\n+## Motivation\n+\n+Neon currently implements several features that guarantee high uptime of compute nodes:\n+\n+1. Storage high-availability (HA), i.e. each tenant shard has a secondary pageserver location, so we can quickly switch over compute to it in case of primary pageserver failure.\n+2. Fast compute provisioning, i.e. we have a fleet of pre-created empty computes, that are ready to serve workload, so restarting unresponsive compute is very fast.\n+3. Preemptive NeonVM compute provisioning in case of k8s node unavailability.\n+\n+This helps us to be well-within the uptime SLO of 99.95% most of the time. Problems begin when we go up to multi-TB workloads and 32-64 CU computes.\n+During restart, compute loses all caches: LFC, shared buffers, file system cache. Depending on the workload, it can take a lot of time to warm up the caches,\n+so that performance could be degraded and might be even unacceptable for certain workloads. The latter means that although current approach works well for small to\n+medium workloads, we still have to do some additional work to avoid performance degradation after restart of large instances.\n+\n+## Non Goals\n+\n+- Details of the persistence storage for prewarm data are out of scope, there is a separate RFC for that: <https://github.com/neondatabase/neon/pull/9661>.\n+- Complete compute/Postgres HA setup and flow. Although it was originally in scope of this RFC, during preliminary research it appeared to be a rabbit hole, so it's worth of a separate RFC.\n+- Low-level implementation details for Postgres replica-to-primary promotion. There are a lot of things to think and care about: how to start walproposer, [logical replication failover](https://www.postgresql.org/docs/current/logical-replication-failover.html), and so on, but it's worth of at least a separate one-pager design document if not RFC.\n+\n+## Impacted components\n+\n+Postgres, compute_ctl, Control plane, Object storage proxy for unlogged storage of compute files.\n+For the latter, we will need to implement a uniform abstraction layer on top of S3, ABS, etc., but\n+S3 is used in text interchangeably with 'object storage' for simplicity.\n+\n+## Proposed implementation\n+\n+### compute_ctl spec changes and auto-prewarm\n+\n+We are going to extend the current compute spec with the following attributes\n+\n+```rust\n+struct ComputeSpec {\n+    /// [All existing attributes]\n+    ...\n+    /// Whether to do auto-prewarm at start or not.\n+    /// Default to `false`.\n+    pub lfc_auto_prewarm: bool\n+    /// Interval in seconds between automatic dumps of\n+    /// LFC state into S3. Default `None`, which means 'off'.\n+    pub lfc_dump_interval_sec: Option<i32>\n+}\n+```\n+\n+When `lfc_dump_interval_sec` is set to `N`, `compute_ctl` will periodically dump the LFC state\n+and store it in S3, so that it could be used either for auto-prewarm after restart or by replica\n+during the rolling restart. For enabling periodic dumping, we should consider the following value\n+`lfc_dump_interval_sec=300` (5 minutes), same as in the upstream's `pg_prewarm.autoprewarm_interval`.\n+\n+When `lfc_auto_prewarm` is set to `true`, `compute_ctl` will start prewarming the LFC upon restart\n+iif some of the previous states is present in S3.\n+\n+### compute_ctl API\n+\n+1. `POST /store_lfc_state` -- dump LFC state using Postgres SQL interface and store result in S3.\n+    This has to be a blocking call, i.e. it will return only after the state is stored in S3.\n+    If there is any concurrent request in progress, we should return `429 Too Many Requests`,\n+    and let the caller to retry.\n+\n+2. `GET /dump_lfc_state` -- dump LFC state using Postgres SQL interface and return it as is\n+    in text format suitable for the future restore/prewarm. This API is not strictly needed at\n+    the end state, but could be useful for a faster prototyping of a complete rolling restart flow\n+    with prewarm, as it doesn't require persistent for LFC state storage.\n+\n+3. `POST /restore_lfc_state` -- restore/prewarm LFC state with request\n+\n+    ```yaml\n+    RestoreLFCStateRequest:\n+      oneOf:\n+        - type: object\n+          required:\n+            - lfc_state\n+          properties:\n+            lfc_state:\n+              type: string\n+              description: Raw LFC content dumped with GET `/dump_lfc_state`\n+        - type: object\n+          required:\n+            - lfc_cache_key\n+          properties:\n+            lfc_cache_key:\n+              type: string\n+              description: |\n+                endpoint_id of the source endpoint on the same branch\n+                to use as a 'donor' for LFC content. Compute will look up\n+                LFC content dump in S3 using this key and do prewarm.\n+    ```\n+\n+    where `lfc_state` and `lfc_cache_key` are mutually exclusive.\n+\n+    The actual prewarming will happen asynchronously, so the caller need to check the\n+    prewarm status using the compute's standard `GET /status` API.\n+\n+4. `GET /status` -- extend existing API with following attributes\n+\n+    ```rust\n+    struct ComputeStatusResponse {\n+        // [All existing attributes]\n+        ...\n+        pub prewarm_state: PrewarmState\n+    }\n+\n+    /// Compute prewarm state. Will be stored in the shared Compute state\n+    /// in compute_ctl\n+    struct PrewarmState {\n+        pub status: PrewarmStatus\n+        /// Total number of pages to prewarm\n+        pub pages_total: i64\n+        /// Number of pages prewarmed so far\n+        pub pages_processed: i64\n+        /// Optional prewarm error\n+        pub error: Option<String>\n+    }\n+\n+    pub enum PrewarmStatus {\n+        /// Prewarming was never requested on this compute\n+        Off,\n+        /// Prewarming was requested, but not started yet\n+        Pending,\n+        /// Prewarming is in progress. The caller should follow\n+        /// `PrewarmState::progress`.\n+        InProgress,\n+        /// Prewarming has been successfully completed\n+        Completed,\n+        /// Prewarming failed. The caller should look at\n+        /// `PrewarmState::error` for the reason.\n+        Failed,\n+        /// It is intended to be used by auto-prewarm if none of\n+        /// the previous LFC states is available in S3.\n+        /// This is a distinct state from the `Failed` because\n+        /// technically it's not a failure and could happen if\n+        /// compute was restart before it dumped anything into S3,\n+        /// or just after the initial rollout of the feature.\n+        Skipped,\n+    }\n+    ```\n+\n+5. `POST /promote` -- this is a **blocking** API call to promote compute replica into primary.\n+    This API should be very similar to the existing `POST /configure` API, i.e. accept the\n+    spec (primary spec, because originally compute was started as replica). It's a distinct\n+    API method because semantics and response codes are different:\n+\n+    - If promotion is done successfully, it will return `200 OK`.\n+    - If compute is already primary, the call will be no-op and `compute_ctl`\n+      will return `412 Precondition Failed`.\n+    - If, for some reason, second request reaches compute that is in progress of promotion,\n+      it will respond with `429 Too Many Requests`.\n+    - If compute hit any permanent failure during promotion `500 Internal Server Error`\n+      will be returned.\n+\n+### Control plane operations\n+\n+The complete flow will be present as a sequence diagram in the next section, but here\n+we just want to list some important steps that have to be done by control plane during\n+the rolling restart via warm replica, but without much of low-level implementation details.\n+\n+1. Register the 'intent' of the instance restart, but not yet interrupt any workload at\n+    primary and also accept new connections. This may require some endpoint state machine\n+    changes, e.g. introduction of the `pending_restart` state. Being in this state also\n+    **mustn't prevent any other operations except restart**: suspend, live-reconfiguration\n+    (e.g. due to notify-attach call from the storage controller), deletion.\n+\n+2. Start new replica compute on the same timeline and start prewarming it. This process\n+    may take quite a while, so the same concurrency considerations as in 1. should be applied\n+    here as well.\n+\n+3. When warm replica is ready, control plane should:\n+\n+    3.1. Terminate the primary compute. Starting from here, **this is a critical section**,\n+        if anything goes off, the only option is to start the primary normally and proceed\n+        with auto-prewarm.\n+\n+    3.2. Send cache invalidation message to all proxies, notifying them that all new connections\n+        should request and wait for the new connection details. At this stage, proxy has to also\n+        drop any existing connections to the old primary, so they didn't do stale reads.\n+\n+    3.3. Attach warm replica compute to the primary endpoint inside control plane metadata\n+        database.\n+\n+    3.4. Promote replica to primary.\n+\n+    3.5. When everything is done, finalize the endpoint state to be just `active`.\n+\n+### Complete rolling restart flow\n+\n+```mermaid\n+  sequenceDiagram\n+\n+  autonumber\n+\n+  participant proxy as Neon proxy\n+\n+  participant cplane as Control plane\n+\n+  participant primary as Compute (primary)\n+  box Compute (replica)\n+    participant ctl as compute_ctl\n+    participant pg as Postgres\n+  end\n+\n+  box Endpoint unlogged storage\n+    participant s3proxy as Object storage proxy\n+    participant s3 as S3/ABS/etc\n+  end\n+\n+\n+  cplane ->> primary: POST /store_lfc_state\n+  primary -->> cplane: 200 OK\n+\n+  cplane ->> ctl: POST /restore_lfc_state\n+  activate ctl\n+  ctl -->> cplane: 202 Accepted\n+\n+  activate cplane\n+  cplane ->> ctl: GET /status: poll prewarm status\n+  ctl ->> s3proxy: GET /read_file\n+  s3proxy ->> s3: read file\n+  s3 -->> s3proxy: file content\n+  s3proxy -->> ctl: 200 OK: file content\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+  cplane -->> proxy: 200 OK: old primary conninfo\n+\n+  ctl ->> pg: prewarm LFC\n+  activate pg\n+  pg -->> ctl: prewarm is completed\n+  deactivate pg\n+\n+  ctl -->> cplane: 200 OK: prewarm is completed\n+  deactivate ctl\n+  deactivate cplane\n+\n+  cplane -->> cplane: reassign replica compute to endpoint,<br>start terminating the old primary compute\n+  activate cplane\n+  cplane ->> proxy: invalidate caches\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+\n+  cplane -x primary: POST /terminate\n+  primary -->> cplane: 200 OK\n+  note over primary: old primary<br>compute terminated\n+\n+  cplane ->> ctl: POST /promote\n+  activate ctl\n+  ctl ->> pg: pg_ctl promote\n+  activate pg\n+  pg -->> ctl: done\n+  deactivate pg\n+  ctl -->> cplane: 200 OK\n+  deactivate ctl\n+\n+  cplane -->> cplane: finalize operation\n+  cplane -->> proxy: 200 OK: new primary conninfo\n+  deactivate cplane\n+```\n+\n+### Reliability, failure modes and corner cases\n+\n+We consider following failures while implementing this RFC:\n+\n+1. Compute got interrupted/crashed/restarted during prewarm. The caller -- control plane -- should\n+    detect that and start prewarm from the beginning.\n+\n+2. Control plane promotion request timed out or hit network issues. If it never reached the\n+    compute, control plane should just repeat it. If it did reach the compute, then during\n+    retry control plane can hit `409` as previous request triggered the promotion already.\n+    In this case, control plane need to retry until either `200` or\n+    permanent error `500` is returned.\n+\n+3. Compute got interrupted/crashed/restarted during promotion. At restart it will ask for\n+    a spec from control plane, and its content should signal compute to start as **primary**,\n+    so it's expected that control plane will continue polling for certain period of time and\n+    will discover that compute is ready to accept connections if restart is fast enough.\n+\n+4. Any other unexpected failure or timeout during prewarming. This **failure mustn't be fatal**,\n+    control plane has to report failure, terminate replica and keep primary running.\n+\n+5. Any other unexpected failure or timeout during promotion. Unfortunately, at this moment\n+    we already have the primary node stopped, so the only option is to start primary again\n+    and proceed with auto-prewarm.\n+\n+6. Any unexpected failure during auto-prewarm. This **failure mustn't be fatal**,\n+    `compute_ctl` has to report the failure, but do not crash the compute.\n+\n+7. Control plane failed to confirm that old primary has terminated. This can happen, especially\n+    in the future HA setup. In this case, control plane has to ensure that it sent VM deletion\n+    and pod termination requests to k8s, so long-term we do not have two running primaries\n+    on the same timeline.\n+\n+### Security implications\n+\n+There are two security implications to consider:\n+\n+1. Access to `compute_ctl` API. It has to be accessible from the outside of compute, so all\n+    new API methods have to be exposed on the **external** HTTP port and **must** be authenticated\n+    with JWT.\n+\n+2. Read/write only your own LFC state data in S3. Although it's not really a security concern,\n+    since LFC state is just a mapping of blocks present in LFC at certain moment in time;\n+    it still has to be highly restricted, so that i) only computes on the same timeline can\n+    read S3 state; ii) each compute can only write to the path that contains it's `endpoint_id`.\n+    Both of this must be validated by S3 proxy and JWT token used by `compute_ctl`.\n+\n+### Unresolved questions\n+",
        "comment_created_at": "2025-03-20T11:26:11+00:00",
        "comment_author": "myrrc",
        "comment_body": "```suggestion\r\n## Authentication and authorization\r\n1. Control plane should generate a JWT token which would be used by compute for authorizing requests\r\nto S3 proxy. This token should be passed in `/compute/api/v2/computes/{id}/spec` route,\r\nparsed by `compute_ctl` as an optional field (to preserve backward compatibility) and passed as-is\r\nto proxy requests during prewarm or prewarm offload. If no token is passed, requests to proxy\r\nshould return 505 Not Supported (other services have `--dev` flags which disable token check or\r\nconfig fields which bypass authentication when absent but that's error-prone) and log the error.\r\n\r\n2. S3 proxy should have `auth_public_key.pem` similar to pageserver\r\nfor spawning an https server for compute requests (this would also further help in getting\r\nPCI-DSS certification) and verifying compute requests. The pemfile should be supplied by\r\ninfra/. As with pageserver, S3 proxy should have `/reload_auth_validation_keys` endpoint\r\nto reload the pemfile from config should it change.\r\n\r\n## Metrics\r\n\r\nIn addition to changing `compute_ctl`'s /status, proxy should provide request duration\r\nmetrics along with result server codes as labels\r\n```\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2006512153",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 11294,
        "pr_file": "docs/rfcs/2025-03-17-compute-prewarm.md",
        "discussion_id": "2005389023",
        "commented_code": "@@ -0,0 +1,379 @@\n+# Compute rolling restart with prewarm\n+\n+Created on 2025-03-17\n+Implemented on _TBD_\n+Author: Alexey Kondratov (@ololobus)\n+\n+## Summary\n+\n+This RFC describes an approach to reduce performance degradation due to missing caches after compute node restart, i.e.:\n+\n+1. Rolling restart of the running instance via 'warm' replica.\n+2. Auto-prewarm compute caches after unplanned restart or scale-to-zero.\n+\n+## Motivation\n+\n+Neon currently implements several features that guarantee high uptime of compute nodes:\n+\n+1. Storage high-availability (HA), i.e. each tenant shard has a secondary pageserver location, so we can quickly switch over compute to it in case of primary pageserver failure.\n+2. Fast compute provisioning, i.e. we have a fleet of pre-created empty computes, that are ready to serve workload, so restarting unresponsive compute is very fast.\n+3. Preemptive NeonVM compute provisioning in case of k8s node unavailability.\n+\n+This helps us to be well-within the uptime SLO of 99.95% most of the time. Problems begin when we go up to multi-TB workloads and 32-64 CU computes.\n+During restart, compute loses all caches: LFC, shared buffers, file system cache. Depending on the workload, it can take a lot of time to warm up the caches,\n+so that performance could be degraded and might be even unacceptable for certain workloads. The latter means that although current approach works well for small to\n+medium workloads, we still have to do some additional work to avoid performance degradation after restart of large instances.\n+\n+## Non Goals\n+\n+- Details of the persistence storage for prewarm data are out of scope, there is a separate RFC for that: <https://github.com/neondatabase/neon/pull/9661>.\n+- Complete compute/Postgres HA setup and flow. Although it was originally in scope of this RFC, during preliminary research it appeared to be a rabbit hole, so it's worth of a separate RFC.\n+- Low-level implementation details for Postgres replica-to-primary promotion. There are a lot of things to think and care about: how to start walproposer, [logical replication failover](https://www.postgresql.org/docs/current/logical-replication-failover.html), and so on, but it's worth of at least a separate one-pager design document if not RFC.\n+\n+## Impacted components\n+\n+Postgres, compute_ctl, Control plane, Object storage proxy for unlogged storage of compute files.\n+For the latter, we will need to implement a uniform abstraction layer on top of S3, ABS, etc., but\n+S3 is used in text interchangeably with 'object storage' for simplicity.\n+\n+## Proposed implementation\n+\n+### compute_ctl spec changes and auto-prewarm\n+\n+We are going to extend the current compute spec with the following attributes\n+\n+```rust\n+struct ComputeSpec {\n+    /// [All existing attributes]\n+    ...\n+    /// Whether to do auto-prewarm at start or not.\n+    /// Default to `false`.\n+    pub lfc_auto_prewarm: bool\n+    /// Interval in seconds between automatic dumps of\n+    /// LFC state into S3. Default `None`, which means 'off'.\n+    pub lfc_dump_interval_sec: Option<i32>\n+}\n+```\n+\n+When `lfc_dump_interval_sec` is set to `N`, `compute_ctl` will periodically dump the LFC state\n+and store it in S3, so that it could be used either for auto-prewarm after restart or by replica\n+during the rolling restart. For enabling periodic dumping, we should consider the following value\n+`lfc_dump_interval_sec=300` (5 minutes), same as in the upstream's `pg_prewarm.autoprewarm_interval`.\n+\n+When `lfc_auto_prewarm` is set to `true`, `compute_ctl` will start prewarming the LFC upon restart\n+iif some of the previous states is present in S3.\n+\n+### compute_ctl API\n+\n+1. `POST /store_lfc_state` -- dump LFC state using Postgres SQL interface and store result in S3.\n+    This has to be a blocking call, i.e. it will return only after the state is stored in S3.\n+    If there is any concurrent request in progress, we should return `429 Too Many Requests`,\n+    and let the caller to retry.\n+\n+2. `GET /dump_lfc_state` -- dump LFC state using Postgres SQL interface and return it as is\n+    in text format suitable for the future restore/prewarm. This API is not strictly needed at\n+    the end state, but could be useful for a faster prototyping of a complete rolling restart flow\n+    with prewarm, as it doesn't require persistent for LFC state storage.\n+\n+3. `POST /restore_lfc_state` -- restore/prewarm LFC state with request\n+\n+    ```yaml\n+    RestoreLFCStateRequest:\n+      oneOf:\n+        - type: object\n+          required:\n+            - lfc_state\n+          properties:\n+            lfc_state:\n+              type: string\n+              description: Raw LFC content dumped with GET `/dump_lfc_state`\n+        - type: object\n+          required:\n+            - lfc_cache_key\n+          properties:\n+            lfc_cache_key:\n+              type: string\n+              description: |\n+                endpoint_id of the source endpoint on the same branch\n+                to use as a 'donor' for LFC content. Compute will look up\n+                LFC content dump in S3 using this key and do prewarm.\n+    ```\n+\n+    where `lfc_state` and `lfc_cache_key` are mutually exclusive.\n+\n+    The actual prewarming will happen asynchronously, so the caller need to check the\n+    prewarm status using the compute's standard `GET /status` API.\n+\n+4. `GET /status` -- extend existing API with following attributes\n+\n+    ```rust\n+    struct ComputeStatusResponse {\n+        // [All existing attributes]\n+        ...\n+        pub prewarm_state: PrewarmState\n+    }\n+\n+    /// Compute prewarm state. Will be stored in the shared Compute state\n+    /// in compute_ctl\n+    struct PrewarmState {\n+        pub status: PrewarmStatus\n+        /// Total number of pages to prewarm\n+        pub pages_total: i64\n+        /// Number of pages prewarmed so far\n+        pub pages_processed: i64\n+        /// Optional prewarm error\n+        pub error: Option<String>\n+    }\n+\n+    pub enum PrewarmStatus {\n+        /// Prewarming was never requested on this compute\n+        Off,\n+        /// Prewarming was requested, but not started yet\n+        Pending,\n+        /// Prewarming is in progress. The caller should follow\n+        /// `PrewarmState::progress`.\n+        InProgress,\n+        /// Prewarming has been successfully completed\n+        Completed,\n+        /// Prewarming failed. The caller should look at\n+        /// `PrewarmState::error` for the reason.\n+        Failed,\n+        /// It is intended to be used by auto-prewarm if none of\n+        /// the previous LFC states is available in S3.\n+        /// This is a distinct state from the `Failed` because\n+        /// technically it's not a failure and could happen if\n+        /// compute was restart before it dumped anything into S3,\n+        /// or just after the initial rollout of the feature.\n+        Skipped,\n+    }\n+    ```\n+\n+5. `POST /promote` -- this is a **blocking** API call to promote compute replica into primary.\n+    This API should be very similar to the existing `POST /configure` API, i.e. accept the\n+    spec (primary spec, because originally compute was started as replica). It's a distinct\n+    API method because semantics and response codes are different:\n+\n+    - If promotion is done successfully, it will return `200 OK`.\n+    - If compute is already primary, the call will be no-op and `compute_ctl`\n+      will return `412 Precondition Failed`.\n+    - If, for some reason, second request reaches compute that is in progress of promotion,\n+      it will respond with `429 Too Many Requests`.\n+    - If compute hit any permanent failure during promotion `500 Internal Server Error`\n+      will be returned.\n+\n+### Control plane operations\n+\n+The complete flow will be present as a sequence diagram in the next section, but here\n+we just want to list some important steps that have to be done by control plane during\n+the rolling restart via warm replica, but without much of low-level implementation details.\n+\n+1. Register the 'intent' of the instance restart, but not yet interrupt any workload at\n+    primary and also accept new connections. This may require some endpoint state machine\n+    changes, e.g. introduction of the `pending_restart` state. Being in this state also\n+    **mustn't prevent any other operations except restart**: suspend, live-reconfiguration\n+    (e.g. due to notify-attach call from the storage controller), deletion.\n+\n+2. Start new replica compute on the same timeline and start prewarming it. This process\n+    may take quite a while, so the same concurrency considerations as in 1. should be applied\n+    here as well.\n+\n+3. When warm replica is ready, control plane should:\n+\n+    3.1. Terminate the primary compute. Starting from here, **this is a critical section**,\n+        if anything goes off, the only option is to start the primary normally and proceed\n+        with auto-prewarm.\n+\n+    3.2. Send cache invalidation message to all proxies, notifying them that all new connections\n+        should request and wait for the new connection details. At this stage, proxy has to also\n+        drop any existing connections to the old primary, so they didn't do stale reads.\n+\n+    3.3. Attach warm replica compute to the primary endpoint inside control plane metadata\n+        database.\n+\n+    3.4. Promote replica to primary.\n+\n+    3.5. When everything is done, finalize the endpoint state to be just `active`.\n+\n+### Complete rolling restart flow\n+\n+```mermaid\n+  sequenceDiagram\n+\n+  autonumber\n+\n+  participant proxy as Neon proxy\n+\n+  participant cplane as Control plane\n+\n+  participant primary as Compute (primary)\n+  box Compute (replica)\n+    participant ctl as compute_ctl\n+    participant pg as Postgres\n+  end\n+\n+  box Endpoint unlogged storage\n+    participant s3proxy as Object storage proxy\n+    participant s3 as S3/ABS/etc\n+  end\n+\n+\n+  cplane ->> primary: POST /store_lfc_state\n+  primary -->> cplane: 200 OK\n+\n+  cplane ->> ctl: POST /restore_lfc_state\n+  activate ctl\n+  ctl -->> cplane: 202 Accepted\n+\n+  activate cplane\n+  cplane ->> ctl: GET /status: poll prewarm status\n+  ctl ->> s3proxy: GET /read_file\n+  s3proxy ->> s3: read file\n+  s3 -->> s3proxy: file content\n+  s3proxy -->> ctl: 200 OK: file content\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+  cplane -->> proxy: 200 OK: old primary conninfo\n+\n+  ctl ->> pg: prewarm LFC\n+  activate pg\n+  pg -->> ctl: prewarm is completed\n+  deactivate pg\n+\n+  ctl -->> cplane: 200 OK: prewarm is completed\n+  deactivate ctl\n+  deactivate cplane\n+\n+  cplane -->> cplane: reassign replica compute to endpoint,<br>start terminating the old primary compute\n+  activate cplane\n+  cplane ->> proxy: invalidate caches\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+\n+  cplane -x primary: POST /terminate\n+  primary -->> cplane: 200 OK\n+  note over primary: old primary<br>compute terminated\n+\n+  cplane ->> ctl: POST /promote\n+  activate ctl\n+  ctl ->> pg: pg_ctl promote\n+  activate pg\n+  pg -->> ctl: done\n+  deactivate pg\n+  ctl -->> cplane: 200 OK\n+  deactivate ctl\n+\n+  cplane -->> cplane: finalize operation\n+  cplane -->> proxy: 200 OK: new primary conninfo\n+  deactivate cplane\n+```\n+\n+### Reliability, failure modes and corner cases\n+\n+We consider following failures while implementing this RFC:\n+\n+1. Compute got interrupted/crashed/restarted during prewarm. The caller -- control plane -- should\n+    detect that and start prewarm from the beginning.\n+\n+2. Control plane promotion request timed out or hit network issues. If it never reached the\n+    compute, control plane should just repeat it. If it did reach the compute, then during\n+    retry control plane can hit `409` as previous request triggered the promotion already.\n+    In this case, control plane need to retry until either `200` or\n+    permanent error `500` is returned.\n+\n+3. Compute got interrupted/crashed/restarted during promotion. At restart it will ask for\n+    a spec from control plane, and its content should signal compute to start as **primary**,\n+    so it's expected that control plane will continue polling for certain period of time and\n+    will discover that compute is ready to accept connections if restart is fast enough.\n+\n+4. Any other unexpected failure or timeout during prewarming. This **failure mustn't be fatal**,\n+    control plane has to report failure, terminate replica and keep primary running.\n+\n+5. Any other unexpected failure or timeout during promotion. Unfortunately, at this moment\n+    we already have the primary node stopped, so the only option is to start primary again\n+    and proceed with auto-prewarm.\n+\n+6. Any unexpected failure during auto-prewarm. This **failure mustn't be fatal**,\n+    `compute_ctl` has to report the failure, but do not crash the compute.\n+\n+7. Control plane failed to confirm that old primary has terminated. This can happen, especially\n+    in the future HA setup. In this case, control plane has to ensure that it sent VM deletion\n+    and pod termination requests to k8s, so long-term we do not have two running primaries\n+    on the same timeline.\n+\n+### Security implications\n+\n+There are two security implications to consider:\n+\n+1. Access to `compute_ctl` API. It has to be accessible from the outside of compute, so all\n+    new API methods have to be exposed on the **external** HTTP port and **must** be authenticated\n+    with JWT.\n+\n+2. Read/write only your own LFC state data in S3. Although it's not really a security concern,\n+    since LFC state is just a mapping of blocks present in LFC at certain moment in time;\n+    it still has to be highly restricted, so that i) only computes on the same timeline can\n+    read S3 state; ii) each compute can only write to the path that contains it's `endpoint_id`.\n+    Both of this must be validated by S3 proxy and JWT token used by `compute_ctl`.\n+\n+### Unresolved questions\n+",
        "comment_created_at": "2025-03-20T21:53:15+00:00",
        "comment_author": "ololobus",
        "comment_body": "@myrrc looks mostly good to me, thanks, I only have minor comments. I suggest we put it into other PR -- https://github.com/neondatabase/neon/pull/9661 as it belongs to the unlogged storage/S3 proxy RFC, not just to prewarm flow specifically\r\n\r\ncc @MMeent ",
        "pr_file_module": null
      },
      {
        "comment_id": "2009304607",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 11294,
        "pr_file": "docs/rfcs/2025-03-17-compute-prewarm.md",
        "discussion_id": "2005389023",
        "commented_code": "@@ -0,0 +1,379 @@\n+# Compute rolling restart with prewarm\n+\n+Created on 2025-03-17\n+Implemented on _TBD_\n+Author: Alexey Kondratov (@ololobus)\n+\n+## Summary\n+\n+This RFC describes an approach to reduce performance degradation due to missing caches after compute node restart, i.e.:\n+\n+1. Rolling restart of the running instance via 'warm' replica.\n+2. Auto-prewarm compute caches after unplanned restart or scale-to-zero.\n+\n+## Motivation\n+\n+Neon currently implements several features that guarantee high uptime of compute nodes:\n+\n+1. Storage high-availability (HA), i.e. each tenant shard has a secondary pageserver location, so we can quickly switch over compute to it in case of primary pageserver failure.\n+2. Fast compute provisioning, i.e. we have a fleet of pre-created empty computes, that are ready to serve workload, so restarting unresponsive compute is very fast.\n+3. Preemptive NeonVM compute provisioning in case of k8s node unavailability.\n+\n+This helps us to be well-within the uptime SLO of 99.95% most of the time. Problems begin when we go up to multi-TB workloads and 32-64 CU computes.\n+During restart, compute loses all caches: LFC, shared buffers, file system cache. Depending on the workload, it can take a lot of time to warm up the caches,\n+so that performance could be degraded and might be even unacceptable for certain workloads. The latter means that although current approach works well for small to\n+medium workloads, we still have to do some additional work to avoid performance degradation after restart of large instances.\n+\n+## Non Goals\n+\n+- Details of the persistence storage for prewarm data are out of scope, there is a separate RFC for that: <https://github.com/neondatabase/neon/pull/9661>.\n+- Complete compute/Postgres HA setup and flow. Although it was originally in scope of this RFC, during preliminary research it appeared to be a rabbit hole, so it's worth of a separate RFC.\n+- Low-level implementation details for Postgres replica-to-primary promotion. There are a lot of things to think and care about: how to start walproposer, [logical replication failover](https://www.postgresql.org/docs/current/logical-replication-failover.html), and so on, but it's worth of at least a separate one-pager design document if not RFC.\n+\n+## Impacted components\n+\n+Postgres, compute_ctl, Control plane, Object storage proxy for unlogged storage of compute files.\n+For the latter, we will need to implement a uniform abstraction layer on top of S3, ABS, etc., but\n+S3 is used in text interchangeably with 'object storage' for simplicity.\n+\n+## Proposed implementation\n+\n+### compute_ctl spec changes and auto-prewarm\n+\n+We are going to extend the current compute spec with the following attributes\n+\n+```rust\n+struct ComputeSpec {\n+    /// [All existing attributes]\n+    ...\n+    /// Whether to do auto-prewarm at start or not.\n+    /// Default to `false`.\n+    pub lfc_auto_prewarm: bool\n+    /// Interval in seconds between automatic dumps of\n+    /// LFC state into S3. Default `None`, which means 'off'.\n+    pub lfc_dump_interval_sec: Option<i32>\n+}\n+```\n+\n+When `lfc_dump_interval_sec` is set to `N`, `compute_ctl` will periodically dump the LFC state\n+and store it in S3, so that it could be used either for auto-prewarm after restart or by replica\n+during the rolling restart. For enabling periodic dumping, we should consider the following value\n+`lfc_dump_interval_sec=300` (5 minutes), same as in the upstream's `pg_prewarm.autoprewarm_interval`.\n+\n+When `lfc_auto_prewarm` is set to `true`, `compute_ctl` will start prewarming the LFC upon restart\n+iif some of the previous states is present in S3.\n+\n+### compute_ctl API\n+\n+1. `POST /store_lfc_state` -- dump LFC state using Postgres SQL interface and store result in S3.\n+    This has to be a blocking call, i.e. it will return only after the state is stored in S3.\n+    If there is any concurrent request in progress, we should return `429 Too Many Requests`,\n+    and let the caller to retry.\n+\n+2. `GET /dump_lfc_state` -- dump LFC state using Postgres SQL interface and return it as is\n+    in text format suitable for the future restore/prewarm. This API is not strictly needed at\n+    the end state, but could be useful for a faster prototyping of a complete rolling restart flow\n+    with prewarm, as it doesn't require persistent for LFC state storage.\n+\n+3. `POST /restore_lfc_state` -- restore/prewarm LFC state with request\n+\n+    ```yaml\n+    RestoreLFCStateRequest:\n+      oneOf:\n+        - type: object\n+          required:\n+            - lfc_state\n+          properties:\n+            lfc_state:\n+              type: string\n+              description: Raw LFC content dumped with GET `/dump_lfc_state`\n+        - type: object\n+          required:\n+            - lfc_cache_key\n+          properties:\n+            lfc_cache_key:\n+              type: string\n+              description: |\n+                endpoint_id of the source endpoint on the same branch\n+                to use as a 'donor' for LFC content. Compute will look up\n+                LFC content dump in S3 using this key and do prewarm.\n+    ```\n+\n+    where `lfc_state` and `lfc_cache_key` are mutually exclusive.\n+\n+    The actual prewarming will happen asynchronously, so the caller need to check the\n+    prewarm status using the compute's standard `GET /status` API.\n+\n+4. `GET /status` -- extend existing API with following attributes\n+\n+    ```rust\n+    struct ComputeStatusResponse {\n+        // [All existing attributes]\n+        ...\n+        pub prewarm_state: PrewarmState\n+    }\n+\n+    /// Compute prewarm state. Will be stored in the shared Compute state\n+    /// in compute_ctl\n+    struct PrewarmState {\n+        pub status: PrewarmStatus\n+        /// Total number of pages to prewarm\n+        pub pages_total: i64\n+        /// Number of pages prewarmed so far\n+        pub pages_processed: i64\n+        /// Optional prewarm error\n+        pub error: Option<String>\n+    }\n+\n+    pub enum PrewarmStatus {\n+        /// Prewarming was never requested on this compute\n+        Off,\n+        /// Prewarming was requested, but not started yet\n+        Pending,\n+        /// Prewarming is in progress. The caller should follow\n+        /// `PrewarmState::progress`.\n+        InProgress,\n+        /// Prewarming has been successfully completed\n+        Completed,\n+        /// Prewarming failed. The caller should look at\n+        /// `PrewarmState::error` for the reason.\n+        Failed,\n+        /// It is intended to be used by auto-prewarm if none of\n+        /// the previous LFC states is available in S3.\n+        /// This is a distinct state from the `Failed` because\n+        /// technically it's not a failure and could happen if\n+        /// compute was restart before it dumped anything into S3,\n+        /// or just after the initial rollout of the feature.\n+        Skipped,\n+    }\n+    ```\n+\n+5. `POST /promote` -- this is a **blocking** API call to promote compute replica into primary.\n+    This API should be very similar to the existing `POST /configure` API, i.e. accept the\n+    spec (primary spec, because originally compute was started as replica). It's a distinct\n+    API method because semantics and response codes are different:\n+\n+    - If promotion is done successfully, it will return `200 OK`.\n+    - If compute is already primary, the call will be no-op and `compute_ctl`\n+      will return `412 Precondition Failed`.\n+    - If, for some reason, second request reaches compute that is in progress of promotion,\n+      it will respond with `429 Too Many Requests`.\n+    - If compute hit any permanent failure during promotion `500 Internal Server Error`\n+      will be returned.\n+\n+### Control plane operations\n+\n+The complete flow will be present as a sequence diagram in the next section, but here\n+we just want to list some important steps that have to be done by control plane during\n+the rolling restart via warm replica, but without much of low-level implementation details.\n+\n+1. Register the 'intent' of the instance restart, but not yet interrupt any workload at\n+    primary and also accept new connections. This may require some endpoint state machine\n+    changes, e.g. introduction of the `pending_restart` state. Being in this state also\n+    **mustn't prevent any other operations except restart**: suspend, live-reconfiguration\n+    (e.g. due to notify-attach call from the storage controller), deletion.\n+\n+2. Start new replica compute on the same timeline and start prewarming it. This process\n+    may take quite a while, so the same concurrency considerations as in 1. should be applied\n+    here as well.\n+\n+3. When warm replica is ready, control plane should:\n+\n+    3.1. Terminate the primary compute. Starting from here, **this is a critical section**,\n+        if anything goes off, the only option is to start the primary normally and proceed\n+        with auto-prewarm.\n+\n+    3.2. Send cache invalidation message to all proxies, notifying them that all new connections\n+        should request and wait for the new connection details. At this stage, proxy has to also\n+        drop any existing connections to the old primary, so they didn't do stale reads.\n+\n+    3.3. Attach warm replica compute to the primary endpoint inside control plane metadata\n+        database.\n+\n+    3.4. Promote replica to primary.\n+\n+    3.5. When everything is done, finalize the endpoint state to be just `active`.\n+\n+### Complete rolling restart flow\n+\n+```mermaid\n+  sequenceDiagram\n+\n+  autonumber\n+\n+  participant proxy as Neon proxy\n+\n+  participant cplane as Control plane\n+\n+  participant primary as Compute (primary)\n+  box Compute (replica)\n+    participant ctl as compute_ctl\n+    participant pg as Postgres\n+  end\n+\n+  box Endpoint unlogged storage\n+    participant s3proxy as Object storage proxy\n+    participant s3 as S3/ABS/etc\n+  end\n+\n+\n+  cplane ->> primary: POST /store_lfc_state\n+  primary -->> cplane: 200 OK\n+\n+  cplane ->> ctl: POST /restore_lfc_state\n+  activate ctl\n+  ctl -->> cplane: 202 Accepted\n+\n+  activate cplane\n+  cplane ->> ctl: GET /status: poll prewarm status\n+  ctl ->> s3proxy: GET /read_file\n+  s3proxy ->> s3: read file\n+  s3 -->> s3proxy: file content\n+  s3proxy -->> ctl: 200 OK: file content\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+  cplane -->> proxy: 200 OK: old primary conninfo\n+\n+  ctl ->> pg: prewarm LFC\n+  activate pg\n+  pg -->> ctl: prewarm is completed\n+  deactivate pg\n+\n+  ctl -->> cplane: 200 OK: prewarm is completed\n+  deactivate ctl\n+  deactivate cplane\n+\n+  cplane -->> cplane: reassign replica compute to endpoint,<br>start terminating the old primary compute\n+  activate cplane\n+  cplane ->> proxy: invalidate caches\n+\n+  proxy ->> cplane: GET /proxy_wake_compute\n+\n+  cplane -x primary: POST /terminate\n+  primary -->> cplane: 200 OK\n+  note over primary: old primary<br>compute terminated\n+\n+  cplane ->> ctl: POST /promote\n+  activate ctl\n+  ctl ->> pg: pg_ctl promote\n+  activate pg\n+  pg -->> ctl: done\n+  deactivate pg\n+  ctl -->> cplane: 200 OK\n+  deactivate ctl\n+\n+  cplane -->> cplane: finalize operation\n+  cplane -->> proxy: 200 OK: new primary conninfo\n+  deactivate cplane\n+```\n+\n+### Reliability, failure modes and corner cases\n+\n+We consider following failures while implementing this RFC:\n+\n+1. Compute got interrupted/crashed/restarted during prewarm. The caller -- control plane -- should\n+    detect that and start prewarm from the beginning.\n+\n+2. Control plane promotion request timed out or hit network issues. If it never reached the\n+    compute, control plane should just repeat it. If it did reach the compute, then during\n+    retry control plane can hit `409` as previous request triggered the promotion already.\n+    In this case, control plane need to retry until either `200` or\n+    permanent error `500` is returned.\n+\n+3. Compute got interrupted/crashed/restarted during promotion. At restart it will ask for\n+    a spec from control plane, and its content should signal compute to start as **primary**,\n+    so it's expected that control plane will continue polling for certain period of time and\n+    will discover that compute is ready to accept connections if restart is fast enough.\n+\n+4. Any other unexpected failure or timeout during prewarming. This **failure mustn't be fatal**,\n+    control plane has to report failure, terminate replica and keep primary running.\n+\n+5. Any other unexpected failure or timeout during promotion. Unfortunately, at this moment\n+    we already have the primary node stopped, so the only option is to start primary again\n+    and proceed with auto-prewarm.\n+\n+6. Any unexpected failure during auto-prewarm. This **failure mustn't be fatal**,\n+    `compute_ctl` has to report the failure, but do not crash the compute.\n+\n+7. Control plane failed to confirm that old primary has terminated. This can happen, especially\n+    in the future HA setup. In this case, control plane has to ensure that it sent VM deletion\n+    and pod termination requests to k8s, so long-term we do not have two running primaries\n+    on the same timeline.\n+\n+### Security implications\n+\n+There are two security implications to consider:\n+\n+1. Access to `compute_ctl` API. It has to be accessible from the outside of compute, so all\n+    new API methods have to be exposed on the **external** HTTP port and **must** be authenticated\n+    with JWT.\n+\n+2. Read/write only your own LFC state data in S3. Although it's not really a security concern,\n+    since LFC state is just a mapping of blocks present in LFC at certain moment in time;\n+    it still has to be highly restricted, so that i) only computes on the same timeline can\n+    read S3 state; ii) each compute can only write to the path that contains it's `endpoint_id`.\n+    Both of this must be validated by S3 proxy and JWT token used by `compute_ctl`.\n+\n+### Unresolved questions\n+",
        "comment_created_at": "2025-03-23T23:57:38+00:00",
        "comment_author": "myrrc",
        "comment_body": "I believe Matthias's RFC focuses more on the high-level overview, but ok, I'll copy the comments. Btw this will probably be split into tasks for https://github.com/neondatabase/cloud/issues/24225 (see sub-issues)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1831014515",
    "pr_number": 9661,
    "pr_file": "docs/rfcs/040-Endpoint-Persistent-Unlogged-Files-Storage.md",
    "created_at": "2024-11-06T13:25:26+00:00",
    "commented_code": "+# Memo: Endpoint Persistent Unlogged Files Storage\n+Created on 2024-11-05\n+Implemented on N/A\n+\n+## Summary\n+A design for a storage system that allows storage of files required to make\n+Neon's Endpoints have a better experience at or after a reboot.\n+\n+## Motivation\n+Several systems inside PostgreSQL (and Neon) need some persistent storage for\n+optimal workings across reboots and restarts, but still work without.\n+Examples are the cumulative statistics file in `pg_stat/global.stat`,\n+`pg_stat_statements`' `pg_stat/pg_stat_statements.stat`, and `pg_prewarm`'s\n+`autoprewarm.blocks`.  We need a storage system that can store and manage\n+these files for each Endpoint.\n+\n+## Goals\n+- Store known files for Endpoints with reasonable persistence.  \n+  _Data loss in this service, while annoying and bad for UX, won't lose any\n+  customer's data._\n+- \n+\n+## Non Goals (if relevant)\n+- This storage system does not need branching, file versioning, or other such\n+  features. The files are as ephemeral to the timeline of the data as the\n+  Endpoints that host the data.\n+- This storage system does not need to store _all_ user files, only 'known'\n+  user files.\n+- This storage system does not need to be hosted fully inside Computes.  \n+  _Instead, this will be a separate component similar to Pageserver,\n+  SafeKeeper, the S3 proxy used for dynamically loaded extensions, etc._\n+\n+## Impacted components (e.g. pageserver, safekeeper, console, etc)\n+- Compute needs new code to load and store these files in its lifetime.\n+- Console or Control Plane needs to consider this new storage system when\n+  signalling the deletion of an Endpoint, Timeline, or Tenant.\n+\n+A new service is created: the Endpoint Persistent Unlogged Files Storage\n+service.  This could be integrated in e.g. Pageserver or Control Plane, or a\n+separately hosted service.\n+\n+## Proposed implementation\n+Endpoint-related data files are managed by a newly designed service (which\n+optionally is integrated in an existing service like Pageserver or Control\n+Plane), which stores data directly into S3, and on the deletion of the\n+Endpoint this ephemeral data is dropped, too.\n+\n+### Reliability, failure modes and corner cases (if relevant)\n+Reliability is important, but not critical to the workings of Neon.  The data\n+stored in this service will, when lost, reduce performance, but won't be a\n+cause of permanent data loss - only operational metadata is stored.\n+\n+### Interaction/Sequence diagram (if relevant)\n+\n+In these diagrams you can replace S3 with any persistent storage device of\n+choice, but S3 is chosen as easiest method.\n+\n+Write data:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ep as EPUFS\n+    participant s3 as S3\n+\n+    co->>+ep: Store Unlogged Persistent File\n+    opt is authenticated\n+        ep->>s3: Write UPF to S3\n+    end\n+    ep->>-co: OK / Failure / Auth Failure\n+```\n+\n+Read data:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ep as EPUFS\n+    participant s3 as Storage\n+\n+    co->>+ep: Read Unlogged Persistent File\n+    opt is authenticated\n+        ep->>+s3: Request UPF from storage\n+        s3->>-ep: Receive UPF from storage\n+    end\n+    ep->>-co: OK(response) / Failure(storage, auth, ...)\n+```\n+\n+Compute Startup:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ps as Pageserver\n+    participant ep as EPUFS\n+    participant es as Extension server\n+\n+    note over co: Bind endpoint ep-xxx\n+    par Get basebackup\n+        co->>+ps: Request basebackup @ LSN\n+        ps-)ps: Construct basebackup\n+        ps->>-co: Receive basebackup TAR @ LSN\n+    and Get startup-critical Unlogged Persistent Files\n+        co->>+ep: Get all UPFs of endpoint ep-xxx\n+        ep-)ep: Retrieve and gather all UPFs\n+        ep->>-co: TAR of UPFs\n+    and Get startup-critical extensions\n+        loop For every startup-critical extension\n+            co->>es: Get critical extension\n+            es->>co: Receive critical extension\n+        end\n+    end\n+    note over co: Start compute\n+```\n+\n+CPlane ops:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant cp as Control Plane\n+    participant ep as EPUFS\n+    participant s3 as Storage\n+\n+    alt Tenant deleted\n+        cp-)ep: Tenant deleted\n+        loop\n+            ep->>s3: Remove data of deleted tenant from Storage",
    "repo_full_name": "neondatabase/neon",
    "discussion_comments": [
      {
        "comment_id": "1831014515",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 9661,
        "pr_file": "docs/rfcs/040-Endpoint-Persistent-Unlogged-Files-Storage.md",
        "discussion_id": "1831014515",
        "commented_code": "@@ -0,0 +1,177 @@\n+# Memo: Endpoint Persistent Unlogged Files Storage\n+Created on 2024-11-05\n+Implemented on N/A\n+\n+## Summary\n+A design for a storage system that allows storage of files required to make\n+Neon's Endpoints have a better experience at or after a reboot.\n+\n+## Motivation\n+Several systems inside PostgreSQL (and Neon) need some persistent storage for\n+optimal workings across reboots and restarts, but still work without.\n+Examples are the cumulative statistics file in `pg_stat/global.stat`,\n+`pg_stat_statements`' `pg_stat/pg_stat_statements.stat`, and `pg_prewarm`'s\n+`autoprewarm.blocks`.  We need a storage system that can store and manage\n+these files for each Endpoint.\n+\n+## Goals\n+- Store known files for Endpoints with reasonable persistence.  \n+  _Data loss in this service, while annoying and bad for UX, won't lose any\n+  customer's data._\n+- \n+\n+## Non Goals (if relevant)\n+- This storage system does not need branching, file versioning, or other such\n+  features. The files are as ephemeral to the timeline of the data as the\n+  Endpoints that host the data.\n+- This storage system does not need to store _all_ user files, only 'known'\n+  user files.\n+- This storage system does not need to be hosted fully inside Computes.  \n+  _Instead, this will be a separate component similar to Pageserver,\n+  SafeKeeper, the S3 proxy used for dynamically loaded extensions, etc._\n+\n+## Impacted components (e.g. pageserver, safekeeper, console, etc)\n+- Compute needs new code to load and store these files in its lifetime.\n+- Console or Control Plane needs to consider this new storage system when\n+  signalling the deletion of an Endpoint, Timeline, or Tenant.\n+\n+A new service is created: the Endpoint Persistent Unlogged Files Storage\n+service.  This could be integrated in e.g. Pageserver or Control Plane, or a\n+separately hosted service.\n+\n+## Proposed implementation\n+Endpoint-related data files are managed by a newly designed service (which\n+optionally is integrated in an existing service like Pageserver or Control\n+Plane), which stores data directly into S3, and on the deletion of the\n+Endpoint this ephemeral data is dropped, too.\n+\n+### Reliability, failure modes and corner cases (if relevant)\n+Reliability is important, but not critical to the workings of Neon.  The data\n+stored in this service will, when lost, reduce performance, but won't be a\n+cause of permanent data loss - only operational metadata is stored.\n+\n+### Interaction/Sequence diagram (if relevant)\n+\n+In these diagrams you can replace S3 with any persistent storage device of\n+choice, but S3 is chosen as easiest method.\n+\n+Write data:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ep as EPUFS\n+    participant s3 as S3\n+\n+    co->>+ep: Store Unlogged Persistent File\n+    opt is authenticated\n+        ep->>s3: Write UPF to S3\n+    end\n+    ep->>-co: OK / Failure / Auth Failure\n+```\n+\n+Read data:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ep as EPUFS\n+    participant s3 as Storage\n+\n+    co->>+ep: Read Unlogged Persistent File\n+    opt is authenticated\n+        ep->>+s3: Request UPF from storage\n+        s3->>-ep: Receive UPF from storage\n+    end\n+    ep->>-co: OK(response) / Failure(storage, auth, ...)\n+```\n+\n+Compute Startup:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ps as Pageserver\n+    participant ep as EPUFS\n+    participant es as Extension server\n+\n+    note over co: Bind endpoint ep-xxx\n+    par Get basebackup\n+        co->>+ps: Request basebackup @ LSN\n+        ps-)ps: Construct basebackup\n+        ps->>-co: Receive basebackup TAR @ LSN\n+    and Get startup-critical Unlogged Persistent Files\n+        co->>+ep: Get all UPFs of endpoint ep-xxx\n+        ep-)ep: Retrieve and gather all UPFs\n+        ep->>-co: TAR of UPFs\n+    and Get startup-critical extensions\n+        loop For every startup-critical extension\n+            co->>es: Get critical extension\n+            es->>co: Receive critical extension\n+        end\n+    end\n+    note over co: Start compute\n+```\n+\n+CPlane ops:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant cp as Control Plane\n+    participant ep as EPUFS\n+    participant s3 as Storage\n+\n+    alt Tenant deleted\n+        cp-)ep: Tenant deleted\n+        loop\n+            ep->>s3: Remove data of deleted tenant from Storage",
        "comment_created_at": "2024-11-06T13:25:26+00:00",
        "comment_author": "jcsp",
        "comment_body": "This implies that the S3 keys are tenant-prefixed, so that we can find them, right?  That makes sense, but would be good to have the RFC explicitly spell out how the S3 key structure will look.",
        "pr_file_module": null
      },
      {
        "comment_id": "1831016186",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 9661,
        "pr_file": "docs/rfcs/040-Endpoint-Persistent-Unlogged-Files-Storage.md",
        "discussion_id": "1831014515",
        "commented_code": "@@ -0,0 +1,177 @@\n+# Memo: Endpoint Persistent Unlogged Files Storage\n+Created on 2024-11-05\n+Implemented on N/A\n+\n+## Summary\n+A design for a storage system that allows storage of files required to make\n+Neon's Endpoints have a better experience at or after a reboot.\n+\n+## Motivation\n+Several systems inside PostgreSQL (and Neon) need some persistent storage for\n+optimal workings across reboots and restarts, but still work without.\n+Examples are the cumulative statistics file in `pg_stat/global.stat`,\n+`pg_stat_statements`' `pg_stat/pg_stat_statements.stat`, and `pg_prewarm`'s\n+`autoprewarm.blocks`.  We need a storage system that can store and manage\n+these files for each Endpoint.\n+\n+## Goals\n+- Store known files for Endpoints with reasonable persistence.  \n+  _Data loss in this service, while annoying and bad for UX, won't lose any\n+  customer's data._\n+- \n+\n+## Non Goals (if relevant)\n+- This storage system does not need branching, file versioning, or other such\n+  features. The files are as ephemeral to the timeline of the data as the\n+  Endpoints that host the data.\n+- This storage system does not need to store _all_ user files, only 'known'\n+  user files.\n+- This storage system does not need to be hosted fully inside Computes.  \n+  _Instead, this will be a separate component similar to Pageserver,\n+  SafeKeeper, the S3 proxy used for dynamically loaded extensions, etc._\n+\n+## Impacted components (e.g. pageserver, safekeeper, console, etc)\n+- Compute needs new code to load and store these files in its lifetime.\n+- Console or Control Plane needs to consider this new storage system when\n+  signalling the deletion of an Endpoint, Timeline, or Tenant.\n+\n+A new service is created: the Endpoint Persistent Unlogged Files Storage\n+service.  This could be integrated in e.g. Pageserver or Control Plane, or a\n+separately hosted service.\n+\n+## Proposed implementation\n+Endpoint-related data files are managed by a newly designed service (which\n+optionally is integrated in an existing service like Pageserver or Control\n+Plane), which stores data directly into S3, and on the deletion of the\n+Endpoint this ephemeral data is dropped, too.\n+\n+### Reliability, failure modes and corner cases (if relevant)\n+Reliability is important, but not critical to the workings of Neon.  The data\n+stored in this service will, when lost, reduce performance, but won't be a\n+cause of permanent data loss - only operational metadata is stored.\n+\n+### Interaction/Sequence diagram (if relevant)\n+\n+In these diagrams you can replace S3 with any persistent storage device of\n+choice, but S3 is chosen as easiest method.\n+\n+Write data:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ep as EPUFS\n+    participant s3 as S3\n+\n+    co->>+ep: Store Unlogged Persistent File\n+    opt is authenticated\n+        ep->>s3: Write UPF to S3\n+    end\n+    ep->>-co: OK / Failure / Auth Failure\n+```\n+\n+Read data:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ep as EPUFS\n+    participant s3 as Storage\n+\n+    co->>+ep: Read Unlogged Persistent File\n+    opt is authenticated\n+        ep->>+s3: Request UPF from storage\n+        s3->>-ep: Receive UPF from storage\n+    end\n+    ep->>-co: OK(response) / Failure(storage, auth, ...)\n+```\n+\n+Compute Startup:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ps as Pageserver\n+    participant ep as EPUFS\n+    participant es as Extension server\n+\n+    note over co: Bind endpoint ep-xxx\n+    par Get basebackup\n+        co->>+ps: Request basebackup @ LSN\n+        ps-)ps: Construct basebackup\n+        ps->>-co: Receive basebackup TAR @ LSN\n+    and Get startup-critical Unlogged Persistent Files\n+        co->>+ep: Get all UPFs of endpoint ep-xxx\n+        ep-)ep: Retrieve and gather all UPFs\n+        ep->>-co: TAR of UPFs\n+    and Get startup-critical extensions\n+        loop For every startup-critical extension\n+            co->>es: Get critical extension\n+            es->>co: Receive critical extension\n+        end\n+    end\n+    note over co: Start compute\n+```\n+\n+CPlane ops:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant cp as Control Plane\n+    participant ep as EPUFS\n+    participant s3 as Storage\n+\n+    alt Tenant deleted\n+        cp-)ep: Tenant deleted\n+        loop\n+            ep->>s3: Remove data of deleted tenant from Storage",
        "comment_created_at": "2024-11-06T13:26:32+00:00",
        "comment_author": "MMeent",
        "comment_body": "I'm not quite sure yet about the S3 design. \r\n\r\nYes, it'll have to be tenant-prefixed, and probably Endpoint-prefixed too, but I'm not yet 100% sure if it'll also be timeline-prefixed.",
        "pr_file_module": null
      },
      {
        "comment_id": "1837115511",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 9661,
        "pr_file": "docs/rfcs/040-Endpoint-Persistent-Unlogged-Files-Storage.md",
        "discussion_id": "1831014515",
        "commented_code": "@@ -0,0 +1,177 @@\n+# Memo: Endpoint Persistent Unlogged Files Storage\n+Created on 2024-11-05\n+Implemented on N/A\n+\n+## Summary\n+A design for a storage system that allows storage of files required to make\n+Neon's Endpoints have a better experience at or after a reboot.\n+\n+## Motivation\n+Several systems inside PostgreSQL (and Neon) need some persistent storage for\n+optimal workings across reboots and restarts, but still work without.\n+Examples are the cumulative statistics file in `pg_stat/global.stat`,\n+`pg_stat_statements`' `pg_stat/pg_stat_statements.stat`, and `pg_prewarm`'s\n+`autoprewarm.blocks`.  We need a storage system that can store and manage\n+these files for each Endpoint.\n+\n+## Goals\n+- Store known files for Endpoints with reasonable persistence.  \n+  _Data loss in this service, while annoying and bad for UX, won't lose any\n+  customer's data._\n+- \n+\n+## Non Goals (if relevant)\n+- This storage system does not need branching, file versioning, or other such\n+  features. The files are as ephemeral to the timeline of the data as the\n+  Endpoints that host the data.\n+- This storage system does not need to store _all_ user files, only 'known'\n+  user files.\n+- This storage system does not need to be hosted fully inside Computes.  \n+  _Instead, this will be a separate component similar to Pageserver,\n+  SafeKeeper, the S3 proxy used for dynamically loaded extensions, etc._\n+\n+## Impacted components (e.g. pageserver, safekeeper, console, etc)\n+- Compute needs new code to load and store these files in its lifetime.\n+- Console or Control Plane needs to consider this new storage system when\n+  signalling the deletion of an Endpoint, Timeline, or Tenant.\n+\n+A new service is created: the Endpoint Persistent Unlogged Files Storage\n+service.  This could be integrated in e.g. Pageserver or Control Plane, or a\n+separately hosted service.\n+\n+## Proposed implementation\n+Endpoint-related data files are managed by a newly designed service (which\n+optionally is integrated in an existing service like Pageserver or Control\n+Plane), which stores data directly into S3, and on the deletion of the\n+Endpoint this ephemeral data is dropped, too.\n+\n+### Reliability, failure modes and corner cases (if relevant)\n+Reliability is important, but not critical to the workings of Neon.  The data\n+stored in this service will, when lost, reduce performance, but won't be a\n+cause of permanent data loss - only operational metadata is stored.\n+\n+### Interaction/Sequence diagram (if relevant)\n+\n+In these diagrams you can replace S3 with any persistent storage device of\n+choice, but S3 is chosen as easiest method.\n+\n+Write data:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ep as EPUFS\n+    participant s3 as S3\n+\n+    co->>+ep: Store Unlogged Persistent File\n+    opt is authenticated\n+        ep->>s3: Write UPF to S3\n+    end\n+    ep->>-co: OK / Failure / Auth Failure\n+```\n+\n+Read data:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ep as EPUFS\n+    participant s3 as Storage\n+\n+    co->>+ep: Read Unlogged Persistent File\n+    opt is authenticated\n+        ep->>+s3: Request UPF from storage\n+        s3->>-ep: Receive UPF from storage\n+    end\n+    ep->>-co: OK(response) / Failure(storage, auth, ...)\n+```\n+\n+Compute Startup:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ps as Pageserver\n+    participant ep as EPUFS\n+    participant es as Extension server\n+\n+    note over co: Bind endpoint ep-xxx\n+    par Get basebackup\n+        co->>+ps: Request basebackup @ LSN\n+        ps-)ps: Construct basebackup\n+        ps->>-co: Receive basebackup TAR @ LSN\n+    and Get startup-critical Unlogged Persistent Files\n+        co->>+ep: Get all UPFs of endpoint ep-xxx\n+        ep-)ep: Retrieve and gather all UPFs\n+        ep->>-co: TAR of UPFs\n+    and Get startup-critical extensions\n+        loop For every startup-critical extension\n+            co->>es: Get critical extension\n+            es->>co: Receive critical extension\n+        end\n+    end\n+    note over co: Start compute\n+```\n+\n+CPlane ops:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant cp as Control Plane\n+    participant ep as EPUFS\n+    participant s3 as Storage\n+\n+    alt Tenant deleted\n+        cp-)ep: Tenant deleted\n+        loop\n+            ep->>s3: Remove data of deleted tenant from Storage",
        "comment_created_at": "2024-11-11T19:36:43+00:00",
        "comment_author": "ololobus",
        "comment_body": "If we make prefix like `/epufs/tenants/{tenant_id}/{endpoint_id|any_other_lower_level_key}/...`, we could decide whether to use tenant or tenant+endpoint pair. I think that from the security standpoint, the tenant should be enough as the tenant is our level of multi-tenancy, and we use it for storage auth already",
        "pr_file_module": null
      },
      {
        "comment_id": "1837147703",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 9661,
        "pr_file": "docs/rfcs/040-Endpoint-Persistent-Unlogged-Files-Storage.md",
        "discussion_id": "1831014515",
        "commented_code": "@@ -0,0 +1,177 @@\n+# Memo: Endpoint Persistent Unlogged Files Storage\n+Created on 2024-11-05\n+Implemented on N/A\n+\n+## Summary\n+A design for a storage system that allows storage of files required to make\n+Neon's Endpoints have a better experience at or after a reboot.\n+\n+## Motivation\n+Several systems inside PostgreSQL (and Neon) need some persistent storage for\n+optimal workings across reboots and restarts, but still work without.\n+Examples are the cumulative statistics file in `pg_stat/global.stat`,\n+`pg_stat_statements`' `pg_stat/pg_stat_statements.stat`, and `pg_prewarm`'s\n+`autoprewarm.blocks`.  We need a storage system that can store and manage\n+these files for each Endpoint.\n+\n+## Goals\n+- Store known files for Endpoints with reasonable persistence.  \n+  _Data loss in this service, while annoying and bad for UX, won't lose any\n+  customer's data._\n+- \n+\n+## Non Goals (if relevant)\n+- This storage system does not need branching, file versioning, or other such\n+  features. The files are as ephemeral to the timeline of the data as the\n+  Endpoints that host the data.\n+- This storage system does not need to store _all_ user files, only 'known'\n+  user files.\n+- This storage system does not need to be hosted fully inside Computes.  \n+  _Instead, this will be a separate component similar to Pageserver,\n+  SafeKeeper, the S3 proxy used for dynamically loaded extensions, etc._\n+\n+## Impacted components (e.g. pageserver, safekeeper, console, etc)\n+- Compute needs new code to load and store these files in its lifetime.\n+- Console or Control Plane needs to consider this new storage system when\n+  signalling the deletion of an Endpoint, Timeline, or Tenant.\n+\n+A new service is created: the Endpoint Persistent Unlogged Files Storage\n+service.  This could be integrated in e.g. Pageserver or Control Plane, or a\n+separately hosted service.\n+\n+## Proposed implementation\n+Endpoint-related data files are managed by a newly designed service (which\n+optionally is integrated in an existing service like Pageserver or Control\n+Plane), which stores data directly into S3, and on the deletion of the\n+Endpoint this ephemeral data is dropped, too.\n+\n+### Reliability, failure modes and corner cases (if relevant)\n+Reliability is important, but not critical to the workings of Neon.  The data\n+stored in this service will, when lost, reduce performance, but won't be a\n+cause of permanent data loss - only operational metadata is stored.\n+\n+### Interaction/Sequence diagram (if relevant)\n+\n+In these diagrams you can replace S3 with any persistent storage device of\n+choice, but S3 is chosen as easiest method.\n+\n+Write data:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ep as EPUFS\n+    participant s3 as S3\n+\n+    co->>+ep: Store Unlogged Persistent File\n+    opt is authenticated\n+        ep->>s3: Write UPF to S3\n+    end\n+    ep->>-co: OK / Failure / Auth Failure\n+```\n+\n+Read data:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ep as EPUFS\n+    participant s3 as Storage\n+\n+    co->>+ep: Read Unlogged Persistent File\n+    opt is authenticated\n+        ep->>+s3: Request UPF from storage\n+        s3->>-ep: Receive UPF from storage\n+    end\n+    ep->>-co: OK(response) / Failure(storage, auth, ...)\n+```\n+\n+Compute Startup:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ps as Pageserver\n+    participant ep as EPUFS\n+    participant es as Extension server\n+\n+    note over co: Bind endpoint ep-xxx\n+    par Get basebackup\n+        co->>+ps: Request basebackup @ LSN\n+        ps-)ps: Construct basebackup\n+        ps->>-co: Receive basebackup TAR @ LSN\n+    and Get startup-critical Unlogged Persistent Files\n+        co->>+ep: Get all UPFs of endpoint ep-xxx\n+        ep-)ep: Retrieve and gather all UPFs\n+        ep->>-co: TAR of UPFs\n+    and Get startup-critical extensions\n+        loop For every startup-critical extension\n+            co->>es: Get critical extension\n+            es->>co: Receive critical extension\n+        end\n+    end\n+    note over co: Start compute\n+```\n+\n+CPlane ops:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant cp as Control Plane\n+    participant ep as EPUFS\n+    participant s3 as Storage\n+\n+    alt Tenant deleted\n+        cp-)ep: Tenant deleted\n+        loop\n+            ep->>s3: Remove data of deleted tenant from Storage",
        "comment_created_at": "2024-11-11T20:15:53+00:00",
        "comment_author": "MMeent",
        "comment_body": "> I think that from the security standpoint, the tenant should be enough as the tenant is our level of multi-tenancy,\r\n\r\nI don't think that's good enough. Compute's tokens should be bound to (Tenant, Timeline, Lsn >/=), so it can't ask for data created on completely disjoint timelines in the same tenant (e.g. `a` branches into `b` and `c`; compute on `b` shouldn't be able to query data in `c`).\r\n\r\n> and we use it for storage auth already\r\n\r\nIMV that's a bad argument. Having a bad practice doesn't mean we should adapt it in new projects if we can prevent it.",
        "pr_file_module": null
      },
      {
        "comment_id": "1987717750",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 9661,
        "pr_file": "docs/rfcs/040-Endpoint-Persistent-Unlogged-Files-Storage.md",
        "discussion_id": "1831014515",
        "commented_code": "@@ -0,0 +1,177 @@\n+# Memo: Endpoint Persistent Unlogged Files Storage\n+Created on 2024-11-05\n+Implemented on N/A\n+\n+## Summary\n+A design for a storage system that allows storage of files required to make\n+Neon's Endpoints have a better experience at or after a reboot.\n+\n+## Motivation\n+Several systems inside PostgreSQL (and Neon) need some persistent storage for\n+optimal workings across reboots and restarts, but still work without.\n+Examples are the cumulative statistics file in `pg_stat/global.stat`,\n+`pg_stat_statements`' `pg_stat/pg_stat_statements.stat`, and `pg_prewarm`'s\n+`autoprewarm.blocks`.  We need a storage system that can store and manage\n+these files for each Endpoint.\n+\n+## Goals\n+- Store known files for Endpoints with reasonable persistence.  \n+  _Data loss in this service, while annoying and bad for UX, won't lose any\n+  customer's data._\n+- \n+\n+## Non Goals (if relevant)\n+- This storage system does not need branching, file versioning, or other such\n+  features. The files are as ephemeral to the timeline of the data as the\n+  Endpoints that host the data.\n+- This storage system does not need to store _all_ user files, only 'known'\n+  user files.\n+- This storage system does not need to be hosted fully inside Computes.  \n+  _Instead, this will be a separate component similar to Pageserver,\n+  SafeKeeper, the S3 proxy used for dynamically loaded extensions, etc._\n+\n+## Impacted components (e.g. pageserver, safekeeper, console, etc)\n+- Compute needs new code to load and store these files in its lifetime.\n+- Console or Control Plane needs to consider this new storage system when\n+  signalling the deletion of an Endpoint, Timeline, or Tenant.\n+\n+A new service is created: the Endpoint Persistent Unlogged Files Storage\n+service.  This could be integrated in e.g. Pageserver or Control Plane, or a\n+separately hosted service.\n+\n+## Proposed implementation\n+Endpoint-related data files are managed by a newly designed service (which\n+optionally is integrated in an existing service like Pageserver or Control\n+Plane), which stores data directly into S3, and on the deletion of the\n+Endpoint this ephemeral data is dropped, too.\n+\n+### Reliability, failure modes and corner cases (if relevant)\n+Reliability is important, but not critical to the workings of Neon.  The data\n+stored in this service will, when lost, reduce performance, but won't be a\n+cause of permanent data loss - only operational metadata is stored.\n+\n+### Interaction/Sequence diagram (if relevant)\n+\n+In these diagrams you can replace S3 with any persistent storage device of\n+choice, but S3 is chosen as easiest method.\n+\n+Write data:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ep as EPUFS\n+    participant s3 as S3\n+\n+    co->>+ep: Store Unlogged Persistent File\n+    opt is authenticated\n+        ep->>s3: Write UPF to S3\n+    end\n+    ep->>-co: OK / Failure / Auth Failure\n+```\n+\n+Read data:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ep as EPUFS\n+    participant s3 as Storage\n+\n+    co->>+ep: Read Unlogged Persistent File\n+    opt is authenticated\n+        ep->>+s3: Request UPF from storage\n+        s3->>-ep: Receive UPF from storage\n+    end\n+    ep->>-co: OK(response) / Failure(storage, auth, ...)\n+```\n+\n+Compute Startup:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant co as Compute\n+    participant ps as Pageserver\n+    participant ep as EPUFS\n+    participant es as Extension server\n+\n+    note over co: Bind endpoint ep-xxx\n+    par Get basebackup\n+        co->>+ps: Request basebackup @ LSN\n+        ps-)ps: Construct basebackup\n+        ps->>-co: Receive basebackup TAR @ LSN\n+    and Get startup-critical Unlogged Persistent Files\n+        co->>+ep: Get all UPFs of endpoint ep-xxx\n+        ep-)ep: Retrieve and gather all UPFs\n+        ep->>-co: TAR of UPFs\n+    and Get startup-critical extensions\n+        loop For every startup-critical extension\n+            co->>es: Get critical extension\n+            es->>co: Receive critical extension\n+        end\n+    end\n+    note over co: Start compute\n+```\n+\n+CPlane ops:\n+```mermaid\n+sequenceDiagram\n+    autonumber\n+    participant cp as Control Plane\n+    participant ep as EPUFS\n+    participant s3 as Storage\n+\n+    alt Tenant deleted\n+        cp-)ep: Tenant deleted\n+        loop\n+            ep->>s3: Remove data of deleted tenant from Storage",
        "comment_created_at": "2025-03-10T17:17:36+00:00",
        "comment_author": "ololobus",
        "comment_body": "This info was added in another section, so resolving",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1987709850",
    "pr_number": 9661,
    "pr_file": "docs/rfcs/040-Endpoint-Persistent-Unlogged-Files-Storage.md",
    "created_at": "2025-03-10T17:12:13+00:00",
    "commented_code": "+# Memo: Endpoint Persistent Unlogged Files Storage\n+Created on 2024-11-05\n+Implemented on N/A\n+\n+## Summary\n+A design for a storage system that allows storage of files required to make\n+Neon's Endpoints have a better experience at or after a reboot.\n+\n+## Motivation\n+Several systems inside PostgreSQL (and Neon) need some persistent storage for\n+optimal workings across reboots and restarts, but still work without.\n+Examples are the cumulative statistics file in `pg_stat/global.stat`,\n+`pg_stat_statements`' `pg_stat/pg_stat_statements.stat`, and `pg_prewarm`'s\n+`autoprewarm.blocks`.  We need a storage system that can store and manage\n+these files for each Endpoint, without granting users access to an unlimited\n+storage device.\n+\n+## Goals\n+- Store known files for Endpoints with reasonable persistence.  \n+  _Data loss in this service, while annoying and bad for UX, won't lose any\n+  customer's data._\n+\n+## Non Goals (if relevant)\n+- This storage system does not need branching, file versioning, or other such\n+  features. The files are as ephemeral to the timeline of the data as the\n+  Endpoints that host the data.\n+- This storage system does not need to store _all_ user files, only 'known'\n+  user files.\n+- This storage system does not need to be hosted fully inside Computes.  \n+  _Instead, this will be a separate component similar to Pageserver,\n+  SafeKeeper, the S3 proxy used for dynamically loaded extensions, etc._\n+\n+## Impacted components (e.g. pageserver, safekeeper, console, etc)\n+- Compute needs new code to load and store these files in its lifetime.\n+- Console or Control Plane needs to consider this new storage system when\n+  signalling the deletion of an Endpoint, Timeline, or Tenant.\n+\n+A new service is created: the Endpoint Persistent Unlogged Files Storage\n+service.  This could be integrated in e.g. Pageserver or Control Plane, or a\n+separately hosted service.\n+\n+## Proposed implementation\n+Endpoint-related data files are managed by a newly designed service (which\n+optionally is integrated in an existing service like Pageserver or Control\n+Plane), which stores data directly into S3 or any blob storage of choice.\n+\n+Upon deletion of the Endpoint, or reassignment of the endpoint to a different\n+branch, this ephemeral data is dropped: the data stored may not match the\n+state of the branch's data after reassignment, and on endpoint deletion the\n+data won't have any use to the user.\n+\n+Compute gets credentials which it can use to authenticate to this new service\n+and retrieve and store data associated with that endpoint.",
    "repo_full_name": "neondatabase/neon",
    "discussion_comments": [
      {
        "comment_id": "1987709850",
        "repo_full_name": "neondatabase/neon",
        "pr_number": 9661,
        "pr_file": "docs/rfcs/040-Endpoint-Persistent-Unlogged-Files-Storage.md",
        "discussion_id": "1987709850",
        "commented_code": "@@ -0,0 +1,288 @@\n+# Memo: Endpoint Persistent Unlogged Files Storage\n+Created on 2024-11-05\n+Implemented on N/A\n+\n+## Summary\n+A design for a storage system that allows storage of files required to make\n+Neon's Endpoints have a better experience at or after a reboot.\n+\n+## Motivation\n+Several systems inside PostgreSQL (and Neon) need some persistent storage for\n+optimal workings across reboots and restarts, but still work without.\n+Examples are the cumulative statistics file in `pg_stat/global.stat`,\n+`pg_stat_statements`' `pg_stat/pg_stat_statements.stat`, and `pg_prewarm`'s\n+`autoprewarm.blocks`.  We need a storage system that can store and manage\n+these files for each Endpoint, without granting users access to an unlimited\n+storage device.\n+\n+## Goals\n+- Store known files for Endpoints with reasonable persistence.  \n+  _Data loss in this service, while annoying and bad for UX, won't lose any\n+  customer's data._\n+\n+## Non Goals (if relevant)\n+- This storage system does not need branching, file versioning, or other such\n+  features. The files are as ephemeral to the timeline of the data as the\n+  Endpoints that host the data.\n+- This storage system does not need to store _all_ user files, only 'known'\n+  user files.\n+- This storage system does not need to be hosted fully inside Computes.  \n+  _Instead, this will be a separate component similar to Pageserver,\n+  SafeKeeper, the S3 proxy used for dynamically loaded extensions, etc._\n+\n+## Impacted components (e.g. pageserver, safekeeper, console, etc)\n+- Compute needs new code to load and store these files in its lifetime.\n+- Console or Control Plane needs to consider this new storage system when\n+  signalling the deletion of an Endpoint, Timeline, or Tenant.\n+\n+A new service is created: the Endpoint Persistent Unlogged Files Storage\n+service.  This could be integrated in e.g. Pageserver or Control Plane, or a\n+separately hosted service.\n+\n+## Proposed implementation\n+Endpoint-related data files are managed by a newly designed service (which\n+optionally is integrated in an existing service like Pageserver or Control\n+Plane), which stores data directly into S3 or any blob storage of choice.\n+\n+Upon deletion of the Endpoint, or reassignment of the endpoint to a different\n+branch, this ephemeral data is dropped: the data stored may not match the\n+state of the branch's data after reassignment, and on endpoint deletion the\n+data won't have any use to the user.\n+\n+Compute gets credentials which it can use to authenticate to this new service\n+and retrieve and store data associated with that endpoint.",
        "comment_created_at": "2025-03-10T17:12:13+00:00",
        "comment_author": "ololobus",
        "comment_body": "I think we could elaborate on that, i.e. that we will use JWTs with tenant+timeline IDs, which both provides good tenants isolation and adds an additional protection layer for different timelines to do not mess with each other data ",
        "pr_file_module": null
      }
    ]
  }
]