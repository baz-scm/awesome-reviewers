[
  {
    "discussion_id": "2120858665",
    "pr_number": 58125,
    "pr_file": "benchmark/source_map/source-map.js",
    "created_at": "2025-06-02T11:27:15+00:00",
    "commented_code": "+'use strict';\n+\n+const common = require('../common.js');\n+const assert = require('assert');\n+const fs = require('fs');\n+const path = require('path');\n+\n+const options = {\n+  flags: ['--expose-internals'],\n+};\n+\n+const bench = common.createBenchmark(\n+  main,\n+  {\n+    operation: [\n+      'parse',\n+      'parse-minified',\n+      'parse-sectioned',\n+      'parse-large',\n+      'findEntry',\n+      'findEntry-minified',\n+      'findEntry-sectioned',\n+      'findEntry-large',\n+      'findOrigin',\n+      'findOrigin-minified',\n+      'findOrigin-sectioned',\n+      'findOrigin-large',\n+    ],\n+    n: [1e5],\n+  },\n+  options,\n+);\n+\n+function main({ operation, n }) {\n+  const { SourceMap } = require('internal/source_map/source_map');\n+\n+  const samplePayload = JSON.parse(\n+    fs.readFileSync(\n+      path.resolve(__dirname, '../../test/fixtures/source-map/no-source.js.map'),\n+      'utf8',\n+    ),\n+  );\n+  const minifiedPayload = JSON.parse(\n+    fs.readFileSync(\n+      path.resolve(__dirname, '../../test/fixtures/source-map/enclosing-call-site.js.map'),\n+      'utf8',\n+    ),\n+  );\n+  const sectionedPayload = JSON.parse(\n+    fs.readFileSync(\n+      path.resolve(__dirname, '../../test/fixtures/source-map/disk-index.map'),\n+      'utf8',\n+    ),\n+  );\n+  const largePayload = JSON.parse(\n+    fs.readFileSync(\n+      path.resolve(__dirname, '../../test/fixtures/test-runner/source-maps/line-lengths/index.js.map'),\n+      'utf8',\n+    ),\n+  );\n+\n+  let sourceMap;\n+  switch (operation) {\n+    case 'parse':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(samplePayload);\n+      }\n+      bench.end(n);\n+      break;\n+\n+    case 'parse-minified':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(minifiedPayload);\n+      }\n+      bench.end(n);\n+      break;\n+\n+    case 'parse-sectioned':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(sectionedPayload);\n+      }\n+      bench.end(n);\n+      break;\n+\n+    case 'parse-large':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(largePayload);\n+      }\n+      bench.end(n);\n+      break;\n+\n+    case 'findEntry':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(samplePayload).findEntry(i, i);",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2120858665",
        "repo_full_name": "nodejs/node",
        "pr_number": 58125,
        "pr_file": "benchmark/source_map/source-map.js",
        "discussion_id": "2120858665",
        "commented_code": "@@ -0,0 +1,164 @@\n+'use strict';\n+\n+const common = require('../common.js');\n+const assert = require('assert');\n+const fs = require('fs');\n+const path = require('path');\n+\n+const options = {\n+  flags: ['--expose-internals'],\n+};\n+\n+const bench = common.createBenchmark(\n+  main,\n+  {\n+    operation: [\n+      'parse',\n+      'parse-minified',\n+      'parse-sectioned',\n+      'parse-large',\n+      'findEntry',\n+      'findEntry-minified',\n+      'findEntry-sectioned',\n+      'findEntry-large',\n+      'findOrigin',\n+      'findOrigin-minified',\n+      'findOrigin-sectioned',\n+      'findOrigin-large',\n+    ],\n+    n: [1e5],\n+  },\n+  options,\n+);\n+\n+function main({ operation, n }) {\n+  const { SourceMap } = require('internal/source_map/source_map');\n+\n+  const samplePayload = JSON.parse(\n+    fs.readFileSync(\n+      path.resolve(__dirname, '../../test/fixtures/source-map/no-source.js.map'),\n+      'utf8',\n+    ),\n+  );\n+  const minifiedPayload = JSON.parse(\n+    fs.readFileSync(\n+      path.resolve(__dirname, '../../test/fixtures/source-map/enclosing-call-site.js.map'),\n+      'utf8',\n+    ),\n+  );\n+  const sectionedPayload = JSON.parse(\n+    fs.readFileSync(\n+      path.resolve(__dirname, '../../test/fixtures/source-map/disk-index.map'),\n+      'utf8',\n+    ),\n+  );\n+  const largePayload = JSON.parse(\n+    fs.readFileSync(\n+      path.resolve(__dirname, '../../test/fixtures/test-runner/source-maps/line-lengths/index.js.map'),\n+      'utf8',\n+    ),\n+  );\n+\n+  let sourceMap;\n+  switch (operation) {\n+    case 'parse':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(samplePayload);\n+      }\n+      bench.end(n);\n+      break;\n+\n+    case 'parse-minified':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(minifiedPayload);\n+      }\n+      bench.end(n);\n+      break;\n+\n+    case 'parse-sectioned':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(sectionedPayload);\n+      }\n+      bench.end(n);\n+      break;\n+\n+    case 'parse-large':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(largePayload);\n+      }\n+      bench.end(n);\n+      break;\n+\n+    case 'findEntry':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(samplePayload).findEntry(i, i);",
        "comment_created_at": "2025-06-02T11:27:15+00:00",
        "comment_author": "legendecas",
        "comment_body": "If the intention here is to test `findEntry` function, the construction of `new SourceMap` should be moved out of the bench scope.",
        "pr_file_module": null
      },
      {
        "comment_id": "2128843883",
        "repo_full_name": "nodejs/node",
        "pr_number": 58125,
        "pr_file": "benchmark/source_map/source-map.js",
        "discussion_id": "2120858665",
        "commented_code": "@@ -0,0 +1,164 @@\n+'use strict';\n+\n+const common = require('../common.js');\n+const assert = require('assert');\n+const fs = require('fs');\n+const path = require('path');\n+\n+const options = {\n+  flags: ['--expose-internals'],\n+};\n+\n+const bench = common.createBenchmark(\n+  main,\n+  {\n+    operation: [\n+      'parse',\n+      'parse-minified',\n+      'parse-sectioned',\n+      'parse-large',\n+      'findEntry',\n+      'findEntry-minified',\n+      'findEntry-sectioned',\n+      'findEntry-large',\n+      'findOrigin',\n+      'findOrigin-minified',\n+      'findOrigin-sectioned',\n+      'findOrigin-large',\n+    ],\n+    n: [1e5],\n+  },\n+  options,\n+);\n+\n+function main({ operation, n }) {\n+  const { SourceMap } = require('internal/source_map/source_map');\n+\n+  const samplePayload = JSON.parse(\n+    fs.readFileSync(\n+      path.resolve(__dirname, '../../test/fixtures/source-map/no-source.js.map'),\n+      'utf8',\n+    ),\n+  );\n+  const minifiedPayload = JSON.parse(\n+    fs.readFileSync(\n+      path.resolve(__dirname, '../../test/fixtures/source-map/enclosing-call-site.js.map'),\n+      'utf8',\n+    ),\n+  );\n+  const sectionedPayload = JSON.parse(\n+    fs.readFileSync(\n+      path.resolve(__dirname, '../../test/fixtures/source-map/disk-index.map'),\n+      'utf8',\n+    ),\n+  );\n+  const largePayload = JSON.parse(\n+    fs.readFileSync(\n+      path.resolve(__dirname, '../../test/fixtures/test-runner/source-maps/line-lengths/index.js.map'),\n+      'utf8',\n+    ),\n+  );\n+\n+  let sourceMap;\n+  switch (operation) {\n+    case 'parse':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(samplePayload);\n+      }\n+      bench.end(n);\n+      break;\n+\n+    case 'parse-minified':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(minifiedPayload);\n+      }\n+      bench.end(n);\n+      break;\n+\n+    case 'parse-sectioned':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(sectionedPayload);\n+      }\n+      bench.end(n);\n+      break;\n+\n+    case 'parse-large':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(largePayload);\n+      }\n+      bench.end(n);\n+      break;\n+\n+    case 'findEntry':\n+      bench.start();\n+      for (let i = 0; i < n; i++) {\n+        sourceMap = new SourceMap(samplePayload).findEntry(i, i);",
        "comment_created_at": "2025-06-05T13:20:45+00:00",
        "comment_author": "miguelmarcondesf",
        "comment_body": "Good one, I'll fix that, thanks",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2161946096",
    "pr_number": 58125,
    "pr_file": "benchmark/source_map/source-map.js",
    "created_at": "2025-06-23T15:48:38+00:00",
    "commented_code": "+'use strict';\n+\n+const common = require('../common.js');\n+const assert = require('assert');\n+const fs = require('fs');\n+const path = require('path');\n+\n+const bench = common.createBenchmark(\n+  main,\n+  {\n+    operation: [\n+      'parse',\n+      'parse-sectioned',\n+      'findEntry',\n+      'findEntry-sectioned',\n+      'findOrigin',\n+      'findOrigin-sectioned',\n+    ],\n+    n: [1e5],",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2161946096",
        "repo_full_name": "nodejs/node",
        "pr_number": 58125,
        "pr_file": "benchmark/source_map/source-map.js",
        "discussion_id": "2161946096",
        "commented_code": "@@ -0,0 +1,97 @@\n+'use strict';\n+\n+const common = require('../common.js');\n+const assert = require('assert');\n+const fs = require('fs');\n+const path = require('path');\n+\n+const bench = common.createBenchmark(\n+  main,\n+  {\n+    operation: [\n+      'parse',\n+      'parse-sectioned',\n+      'findEntry',\n+      'findEntry-sectioned',\n+      'findOrigin',\n+      'findOrigin-sectioned',\n+    ],\n+    n: [1e5],",
        "comment_created_at": "2025-06-23T15:48:38+00:00",
        "comment_author": "RafaelGSS",
        "comment_body": "```suggestion\r\n    n: [1e5],\r\n```\r\n\r\nIs this an arbitrary number, or did you find that this is the curve where benchmark results do not change?",
        "pr_file_module": null
      },
      {
        "comment_id": "2162489458",
        "repo_full_name": "nodejs/node",
        "pr_number": 58125,
        "pr_file": "benchmark/source_map/source-map.js",
        "discussion_id": "2161946096",
        "commented_code": "@@ -0,0 +1,97 @@\n+'use strict';\n+\n+const common = require('../common.js');\n+const assert = require('assert');\n+const fs = require('fs');\n+const path = require('path');\n+\n+const bench = common.createBenchmark(\n+  main,\n+  {\n+    operation: [\n+      'parse',\n+      'parse-sectioned',\n+      'findEntry',\n+      'findEntry-sectioned',\n+      'findOrigin',\n+      'findOrigin-sectioned',\n+    ],\n+    n: [1e5],",
        "comment_created_at": "2025-06-23T20:37:36+00:00",
        "comment_author": "miguelmarcondesf",
        "comment_body": "So I had some testing for `10` up to `1e8` and it stabilizes around `1e5`.\r\n\r\nFor `source-map-cache`\r\n```md\r\nsource_map/source-map-cache.js n=10 operation=\"findSourceMap-valid\": 22,044.640396803527\r\nsource_map/source-map-cache.js n=100 operation=\"findSourceMap-valid\": 114,264.03676559647\r\nsource_map/source-map-cache.js n=1000 operation=\"findSourceMap-valid\": 135,848.8002852825\r\nsource_map/source-map-cache.js n=10000 operation=\"findSourceMap-valid\": 425,194.9252985665\r\nsource_map/source-map-cache.js n=100000 operation=\"findSourceMap-valid\": 661,039.200292227\r\nsource_map/source-map-cache.js n=1000000 operation=\"findSourceMap-valid\": 655,766.5874586097\r\nsource_map/source-map-cache.js n=10000000 operation=\"findSourceMap-valid\": 686,861.3520220064\r\nsource_map/source-map-cache.js n=100000000 operation=\"findSourceMap-valid\": 690,901.4430697807\r\n\r\nsource_map/source-map-cache.js n=10 operation=\"findSourceMap-generated-source\": 19,123.493785820694\r\nsource_map/source-map-cache.js n=100 operation=\"findSourceMap-generated-source\": 222,985.82479111804\r\nsource_map/source-map-cache.js n=1000 operation=\"findSourceMap-generated-source\": 1,262,360.0831642824\r\nsource_map/source-map-cache.js n=10000 operation=\"findSourceMap-generated-source\": 3,751,348.609825232\r\nsource_map/source-map-cache.js n=100000 operation=\"findSourceMap-generated-source\": 4,789,673.464011591\r\nsource_map/source-map-cache.js n=1000000 operation=\"findSourceMap-generated-source\": 5,322,983.097883862\r\nsource_map/source-map-cache.js n=10000000 operation=\"findSourceMap-generated-source\": 3,526,343.638308575\r\nsource_map/source-map-cache.js n=100000000 operation=\"findSourceMap-generated-source\": 5,725,883.259174296\r\n```\r\n\r\nFor `source-map`\r\n```md\r\nsource_map/source-map.js n=10 operation=\"parse\": 24,502.29709035222\r\nsource_map/source-map.js n=100 operation=\"parse\": 94,723.07236179667\r\nsource_map/source-map.js n=1000 operation=\"parse\": 172,707.84309492455\r\nsource_map/source-map.js n=10000 operation=\"parse\": 353,478.6719806294\r\nsource_map/source-map.js n=100000 operation=\"parse\": 454,661.1017299623\r\nsource_map/source-map.js n=1000000 operation=\"parse\": 502,081.0841701146\r\nsource_map/source-map.js n=10000000 operation=\"parse\": 503,396.77038754406\r\nsource_map/source-map.js n=100000000 operation=\"parse\": 500,985.0726477283\r\nsource_map/source-map.js n=10 operation=\"parse-sectioned\": 21,158.42369743454\r\nsource_map/source-map.js n=100 operation=\"parse-sectioned\": 28,618.788578127005\r\nsource_map/source-map.js n=1000 operation=\"parse-sectioned\": 121,799.59387143419\r\nsource_map/source-map.js n=10000 operation=\"parse-sectioned\": 230,234.37859741217\r\nsource_map/source-map.js n=100000 operation=\"parse-sectioned\": 310,112.7780007161\r\nsource_map/source-map.js n=1000000 operation=\"parse-sectioned\": 335,803.14216158056\r\nsource_map/source-map.js n=10000000 operation=\"parse-sectioned\": 323,348.8163390162\r\nsource_map/source-map.js n=100000000 operation=\"parse-sectioned\": 318,926.62476153404\r\nsource_map/source-map.js n=10 operation=\"findEntry\": 167,364.01673640168\r\nsource_map/source-map.js n=100 operation=\"findEntry\": 1,203,615.6614469867\r\nsource_map/source-map.js n=1000 operation=\"findEntry\": 2,766,573.156493977\r\nsource_map/source-map.js n=10000 operation=\"findEntry\": 6,595,762.22277187\r\nsource_map/source-map.js n=100000 operation=\"findEntry\": 34,166,132.82084134\r\nsource_map/source-map.js n=1000000 operation=\"findEntry\": 66,372,785.67112444\r\nsource_map/source-map.js n=10000000 operation=\"findEntry\": 69,998,661.2756031\r\nsource_map/source-map.js n=100000000 operation=\"findEntry\": 74,137,195.965463\r\nsource_map/source-map.js n=10 operation=\"findEntry-sectioned\": 157,895.56787140985\r\nsource_map/source-map.js n=100 operation=\"findEntry-sectioned\": 1,099,408.518217199\r\nsource_map/source-map.js n=1000 operation=\"findEntry-sectioned\": 3,204,265.518257905\r\nsource_map/source-map.js n=10000 operation=\"findEntry-sectioned\": 13,917,070.957577985\r\nsource_map/source-map.js n=100000 operation=\"findEntry-sectioned\": 32,089,851.58443642\r\nsource_map/source-map.js n=1000000 operation=\"findEntry-sectioned\": 62,772,341.727857664\r\nsource_map/source-map.js n=10000000 operation=\"findEntry-sectioned\": 68,942,219.52581541\r\nsource_map/source-map.js n=100000000 operation=\"findEntry-sectioned\": 66,538,906.42142866\r\nsource_map/source-map.js n=10 operation=\"findOrigin\": 129,379.49593748382\r\nsource_map/source-map.js n=100 operation=\"findOrigin\": 902,934.5372460497\r\nsource_map/source-map.js n=1000 operation=\"findOrigin\": 2,388,293.540382461\r\nsource_map/source-map.js n=10000 operation=\"findOrigin\": 12,155,586.646844957\r\nsource_map/source-map.js n=100000 operation=\"findOrigin\": 30,224,035.664362084\r\nsource_map/source-map.js n=1000000 operation=\"findOrigin\": 54,367,277.162258655\r\nsource_map/source-map.js n=10000000 operation=\"findOrigin\": 61,682,814.88834895\r\nsource_map/source-map.js n=100000000 operation=\"findOrigin\": 65,709,915.70638048\r\nsource_map/source-map.js n=10 operation=\"findOrigin-sectioned\": 133,184.16706621918\r\nsource_map/source-map.js n=100 operation=\"findOrigin-sectioned\": 766,530.2242867437\r\nsource_map/source-map.js n=1000 operation=\"findOrigin-sectioned\": 2,399,042.3023129166\r\nsource_map/source-map.js n=10000 operation=\"findOrigin-sectioned\": 5,187,171.295438972\r\nsource_map/source-map.js n=100000 operation=\"findOrigin-sectioned\": 16,531,884.963870391\r\nsource_map/source-map.js n=1000000 operation=\"findOrigin-sectioned\": 50,945,463.747131586\r\nsource_map/source-map.js n=10000000 operation=\"findOrigin-sectioned\": 41,329,287.598349184\r\nsource_map/source-map.js n=100000000 operation=\"findOrigin-sectioned\": 60,279,529.754421346\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2173500595",
    "pr_number": 58874,
    "pr_file": "lib/metrics.js",
    "created_at": "2025-06-28T19:24:59+00:00",
    "commented_code": "+/**\n+ * A metrics provider which reports to diagnostics_channel.\n+ *\n+ * # Metric Types\n+ *\n+ * - Counter: An increasing or decreasing value.\n+ * - Gauge: A snapshot of a single value in time.\n+ * - Meter: A number of events per interval.\n+ * - Timer: A duration in milliseconds.\n+ * - UniqueSet: A unique count of number of unique values seen.\n+ * - PeriodicGauge: A gauge which periodically updates its value by calling a function.\n+ *\n+ * # Exporting Metrics\n+ *\n+ * Several text format exporters are provided as streams:\n+ * - Statsd\n+ * - Dogstatsd\n+ * - Graphite\n+ * - Prometheus\n+ *\n+ * # TODO(qard):\n+ * - Histograms\n+ * - Distributions/Summaries\n+ */\n+\n+'use strict';\n+\n+const {\n+  ArrayPrototypeJoin,\n+  ArrayPrototypeMap,\n+  MathFloor,\n+  ObjectAssign,\n+  ObjectEntries,\n+  ObjectFreeze,\n+  ObjectKeys,\n+  SafeMap,\n+  SafeWeakSet,\n+  SymbolDispose,\n+} = primordials;\n+\n+const {\n+  codes: {\n+    ERR_INVALID_ARG_TYPE,\n+    ERR_INVALID_ARG_VALUE,\n+  },\n+} = require('internal/errors');\n+const { setInterval, clearInterval } = require('internal/timers');\n+\n+const {\n+  channel,\n+  hasChannel,\n+  subscribe,\n+  unsubscribe,\n+} = require('diagnostics_channel');\n+const { performance } = require('perf_hooks');\n+const { Transform } = require('stream');\n+\n+const newMetricChannel = channel('metrics:new');\n+\n+/**\n+ * Mix two metadata objects together.\n+ * @param {object} a The first metadata object.\n+ * @param {object} b The second metadata object.\n+ * @returns {object} The mixed metadata.\n+ * @private\n+ */\n+function mixMeta(a, b) {\n+  if (a === undefined) return b;\n+  if (b === undefined) return a;\n+  return ObjectAssign({}, a, b);\n+}\n+\n+/**\n+ * Represents a single reported metric.\n+ */\n+class MetricReport {\n+  /**\n+   * The type of metric.\n+   * @property {string} type\n+   */\n+\n+  /**\n+   * The name of the metric.\n+   * @property {string} name\n+   */\n+\n+  /**\n+   * The value of the metric.\n+   * @property {number} value\n+   */\n+\n+  /**\n+   * Additional metadata to include with the report.\n+   * @property {object} meta\n+   */\n+\n+  /**\n+   * Constructs a new metric report.\n+   * @param {string} type The type of metric.\n+   * @param {string} name The name of the metric.\n+   * @param {number} value The value of the metric.\n+   * @param {object} [meta] Additional metadata to include with the report.\n+   */\n+  constructor(type, name, value, meta) {\n+    this.type = type;\n+    this.name = name;\n+    this.value = value;\n+    this.meta = meta;\n+    this.time = performance.now();\n+    ObjectFreeze(this);\n+  }\n+\n+  /**\n+   * Convert the metric report to a statsd-compatible string.\n+   * @returns {string} The statsd-formatted metric report.\n+   */\n+  toStatsd() {\n+    const { type, name, value } = this;\n+    return `${name}:${value}|${this.#statsdType(type)}`;\n+  }\n+\n+  /*\n+   * Convert the metric type to a statsd type.\n+   *\n+   * @param {string} type The metric type.\n+   * @returns {string} The statsd type.\n+   * @private\n+   */\n+  #statsdType(type) {\n+    return {\n+      counter: 'c',\n+      gauge: 'g',\n+      meter: 'm',\n+      periodicGauge: 'g',\n+      timer: 'ms',\n+      uniqueSet: 's',\n+    }[type];\n+  }\n+\n+  /**\n+   * Convert the metric report to a Dogstatsd-compatible string.\n+   * @returns {string} The Dogstatsd-formatted metric report.\n+   */\n+  toDogStatsd() {\n+    return `${this.toStatsd()}${this.#dogstatsdTags()}`;\n+  }\n+\n+  /*\n+   * Pack metadata into Dogstatsd-compatible tags.\n+   *\n+   * @returns {string} The packed metadata.\n+   * @private\n+   */\n+  #dogstatsdTags() {\n+    const entries = ObjectEntries(this.meta);\n+    const pairs = ArrayPrototypeMap(entries, ({ 0: k, 1: v }) => `${k}:${v}`);\n+    const tags = ArrayPrototypeJoin(pairs, ',');\n+    return tags.length ? `|${tags}` : '';\n+  }\n+\n+  /**\n+   * Convert the metric report to a graphite-compatible string.\n+   * @returns {string} The graphite-formatted metric report.\n+   */\n+  toGraphite() {\n+    const { name, value, time } = this;\n+    return `${name} ${value} ${MathFloor(time / 1000)}`;\n+  }\n+\n+  /**\n+   * Convert the metric report to a Prometheus-compatible string.\n+   * @returns {string} The Prometheus-formatted metric report.\n+   */\n+  toPrometheus() {\n+    const { name, value, time } = this;\n+    return `${name}${this.#prometheusLabels()} ${value} ${time}`;\n+  }\n+\n+  /*\n+   * Pack metadata into Prometheus-compatible labels.\n+   *\n+   * @returns {string} The packed metadata.\n+   * @private\n+   */\n+  #prometheusLabels() {\n+    const entries = ObjectEntries(this.meta);\n+    const pairs = ArrayPrototypeMap(entries, ({ 0: k, 1: v }) => `${k}=\"${v}\"`);",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2173500595",
        "repo_full_name": "nodejs/node",
        "pr_number": 58874,
        "pr_file": "lib/metrics.js",
        "discussion_id": "2173500595",
        "commented_code": "@@ -0,0 +1,848 @@\n+/**\n+ * A metrics provider which reports to diagnostics_channel.\n+ *\n+ * # Metric Types\n+ *\n+ * - Counter: An increasing or decreasing value.\n+ * - Gauge: A snapshot of a single value in time.\n+ * - Meter: A number of events per interval.\n+ * - Timer: A duration in milliseconds.\n+ * - UniqueSet: A unique count of number of unique values seen.\n+ * - PeriodicGauge: A gauge which periodically updates its value by calling a function.\n+ *\n+ * # Exporting Metrics\n+ *\n+ * Several text format exporters are provided as streams:\n+ * - Statsd\n+ * - Dogstatsd\n+ * - Graphite\n+ * - Prometheus\n+ *\n+ * # TODO(qard):\n+ * - Histograms\n+ * - Distributions/Summaries\n+ */\n+\n+'use strict';\n+\n+const {\n+  ArrayPrototypeJoin,\n+  ArrayPrototypeMap,\n+  MathFloor,\n+  ObjectAssign,\n+  ObjectEntries,\n+  ObjectFreeze,\n+  ObjectKeys,\n+  SafeMap,\n+  SafeWeakSet,\n+  SymbolDispose,\n+} = primordials;\n+\n+const {\n+  codes: {\n+    ERR_INVALID_ARG_TYPE,\n+    ERR_INVALID_ARG_VALUE,\n+  },\n+} = require('internal/errors');\n+const { setInterval, clearInterval } = require('internal/timers');\n+\n+const {\n+  channel,\n+  hasChannel,\n+  subscribe,\n+  unsubscribe,\n+} = require('diagnostics_channel');\n+const { performance } = require('perf_hooks');\n+const { Transform } = require('stream');\n+\n+const newMetricChannel = channel('metrics:new');\n+\n+/**\n+ * Mix two metadata objects together.\n+ * @param {object} a The first metadata object.\n+ * @param {object} b The second metadata object.\n+ * @returns {object} The mixed metadata.\n+ * @private\n+ */\n+function mixMeta(a, b) {\n+  if (a === undefined) return b;\n+  if (b === undefined) return a;\n+  return ObjectAssign({}, a, b);\n+}\n+\n+/**\n+ * Represents a single reported metric.\n+ */\n+class MetricReport {\n+  /**\n+   * The type of metric.\n+   * @property {string} type\n+   */\n+\n+  /**\n+   * The name of the metric.\n+   * @property {string} name\n+   */\n+\n+  /**\n+   * The value of the metric.\n+   * @property {number} value\n+   */\n+\n+  /**\n+   * Additional metadata to include with the report.\n+   * @property {object} meta\n+   */\n+\n+  /**\n+   * Constructs a new metric report.\n+   * @param {string} type The type of metric.\n+   * @param {string} name The name of the metric.\n+   * @param {number} value The value of the metric.\n+   * @param {object} [meta] Additional metadata to include with the report.\n+   */\n+  constructor(type, name, value, meta) {\n+    this.type = type;\n+    this.name = name;\n+    this.value = value;\n+    this.meta = meta;\n+    this.time = performance.now();\n+    ObjectFreeze(this);\n+  }\n+\n+  /**\n+   * Convert the metric report to a statsd-compatible string.\n+   * @returns {string} The statsd-formatted metric report.\n+   */\n+  toStatsd() {\n+    const { type, name, value } = this;\n+    return `${name}:${value}|${this.#statsdType(type)}`;\n+  }\n+\n+  /*\n+   * Convert the metric type to a statsd type.\n+   *\n+   * @param {string} type The metric type.\n+   * @returns {string} The statsd type.\n+   * @private\n+   */\n+  #statsdType(type) {\n+    return {\n+      counter: 'c',\n+      gauge: 'g',\n+      meter: 'm',\n+      periodicGauge: 'g',\n+      timer: 'ms',\n+      uniqueSet: 's',\n+    }[type];\n+  }\n+\n+  /**\n+   * Convert the metric report to a Dogstatsd-compatible string.\n+   * @returns {string} The Dogstatsd-formatted metric report.\n+   */\n+  toDogStatsd() {\n+    return `${this.toStatsd()}${this.#dogstatsdTags()}`;\n+  }\n+\n+  /*\n+   * Pack metadata into Dogstatsd-compatible tags.\n+   *\n+   * @returns {string} The packed metadata.\n+   * @private\n+   */\n+  #dogstatsdTags() {\n+    const entries = ObjectEntries(this.meta);\n+    const pairs = ArrayPrototypeMap(entries, ({ 0: k, 1: v }) => `${k}:${v}`);\n+    const tags = ArrayPrototypeJoin(pairs, ',');\n+    return tags.length ? `|${tags}` : '';\n+  }\n+\n+  /**\n+   * Convert the metric report to a graphite-compatible string.\n+   * @returns {string} The graphite-formatted metric report.\n+   */\n+  toGraphite() {\n+    const { name, value, time } = this;\n+    return `${name} ${value} ${MathFloor(time / 1000)}`;\n+  }\n+\n+  /**\n+   * Convert the metric report to a Prometheus-compatible string.\n+   * @returns {string} The Prometheus-formatted metric report.\n+   */\n+  toPrometheus() {\n+    const { name, value, time } = this;\n+    return `${name}${this.#prometheusLabels()} ${value} ${time}`;\n+  }\n+\n+  /*\n+   * Pack metadata into Prometheus-compatible labels.\n+   *\n+   * @returns {string} The packed metadata.\n+   * @private\n+   */\n+  #prometheusLabels() {\n+    const entries = ObjectEntries(this.meta);\n+    const pairs = ArrayPrototypeMap(entries, ({ 0: k, 1: v }) => `${k}=\"${v}\"`);",
        "comment_created_at": "2025-06-28T19:24:59+00:00",
        "comment_author": "mcollina",
        "comment_body": "I would recommend to just a basic for loop, this would be called enough that the overhead of map would become visible",
        "pr_file_module": null
      },
      {
        "comment_id": "2173522795",
        "repo_full_name": "nodejs/node",
        "pr_number": 58874,
        "pr_file": "lib/metrics.js",
        "discussion_id": "2173500595",
        "commented_code": "@@ -0,0 +1,848 @@\n+/**\n+ * A metrics provider which reports to diagnostics_channel.\n+ *\n+ * # Metric Types\n+ *\n+ * - Counter: An increasing or decreasing value.\n+ * - Gauge: A snapshot of a single value in time.\n+ * - Meter: A number of events per interval.\n+ * - Timer: A duration in milliseconds.\n+ * - UniqueSet: A unique count of number of unique values seen.\n+ * - PeriodicGauge: A gauge which periodically updates its value by calling a function.\n+ *\n+ * # Exporting Metrics\n+ *\n+ * Several text format exporters are provided as streams:\n+ * - Statsd\n+ * - Dogstatsd\n+ * - Graphite\n+ * - Prometheus\n+ *\n+ * # TODO(qard):\n+ * - Histograms\n+ * - Distributions/Summaries\n+ */\n+\n+'use strict';\n+\n+const {\n+  ArrayPrototypeJoin,\n+  ArrayPrototypeMap,\n+  MathFloor,\n+  ObjectAssign,\n+  ObjectEntries,\n+  ObjectFreeze,\n+  ObjectKeys,\n+  SafeMap,\n+  SafeWeakSet,\n+  SymbolDispose,\n+} = primordials;\n+\n+const {\n+  codes: {\n+    ERR_INVALID_ARG_TYPE,\n+    ERR_INVALID_ARG_VALUE,\n+  },\n+} = require('internal/errors');\n+const { setInterval, clearInterval } = require('internal/timers');\n+\n+const {\n+  channel,\n+  hasChannel,\n+  subscribe,\n+  unsubscribe,\n+} = require('diagnostics_channel');\n+const { performance } = require('perf_hooks');\n+const { Transform } = require('stream');\n+\n+const newMetricChannel = channel('metrics:new');\n+\n+/**\n+ * Mix two metadata objects together.\n+ * @param {object} a The first metadata object.\n+ * @param {object} b The second metadata object.\n+ * @returns {object} The mixed metadata.\n+ * @private\n+ */\n+function mixMeta(a, b) {\n+  if (a === undefined) return b;\n+  if (b === undefined) return a;\n+  return ObjectAssign({}, a, b);\n+}\n+\n+/**\n+ * Represents a single reported metric.\n+ */\n+class MetricReport {\n+  /**\n+   * The type of metric.\n+   * @property {string} type\n+   */\n+\n+  /**\n+   * The name of the metric.\n+   * @property {string} name\n+   */\n+\n+  /**\n+   * The value of the metric.\n+   * @property {number} value\n+   */\n+\n+  /**\n+   * Additional metadata to include with the report.\n+   * @property {object} meta\n+   */\n+\n+  /**\n+   * Constructs a new metric report.\n+   * @param {string} type The type of metric.\n+   * @param {string} name The name of the metric.\n+   * @param {number} value The value of the metric.\n+   * @param {object} [meta] Additional metadata to include with the report.\n+   */\n+  constructor(type, name, value, meta) {\n+    this.type = type;\n+    this.name = name;\n+    this.value = value;\n+    this.meta = meta;\n+    this.time = performance.now();\n+    ObjectFreeze(this);\n+  }\n+\n+  /**\n+   * Convert the metric report to a statsd-compatible string.\n+   * @returns {string} The statsd-formatted metric report.\n+   */\n+  toStatsd() {\n+    const { type, name, value } = this;\n+    return `${name}:${value}|${this.#statsdType(type)}`;\n+  }\n+\n+  /*\n+   * Convert the metric type to a statsd type.\n+   *\n+   * @param {string} type The metric type.\n+   * @returns {string} The statsd type.\n+   * @private\n+   */\n+  #statsdType(type) {\n+    return {\n+      counter: 'c',\n+      gauge: 'g',\n+      meter: 'm',\n+      periodicGauge: 'g',\n+      timer: 'ms',\n+      uniqueSet: 's',\n+    }[type];\n+  }\n+\n+  /**\n+   * Convert the metric report to a Dogstatsd-compatible string.\n+   * @returns {string} The Dogstatsd-formatted metric report.\n+   */\n+  toDogStatsd() {\n+    return `${this.toStatsd()}${this.#dogstatsdTags()}`;\n+  }\n+\n+  /*\n+   * Pack metadata into Dogstatsd-compatible tags.\n+   *\n+   * @returns {string} The packed metadata.\n+   * @private\n+   */\n+  #dogstatsdTags() {\n+    const entries = ObjectEntries(this.meta);\n+    const pairs = ArrayPrototypeMap(entries, ({ 0: k, 1: v }) => `${k}:${v}`);\n+    const tags = ArrayPrototypeJoin(pairs, ',');\n+    return tags.length ? `|${tags}` : '';\n+  }\n+\n+  /**\n+   * Convert the metric report to a graphite-compatible string.\n+   * @returns {string} The graphite-formatted metric report.\n+   */\n+  toGraphite() {\n+    const { name, value, time } = this;\n+    return `${name} ${value} ${MathFloor(time / 1000)}`;\n+  }\n+\n+  /**\n+   * Convert the metric report to a Prometheus-compatible string.\n+   * @returns {string} The Prometheus-formatted metric report.\n+   */\n+  toPrometheus() {\n+    const { name, value, time } = this;\n+    return `${name}${this.#prometheusLabels()} ${value} ${time}`;\n+  }\n+\n+  /*\n+   * Pack metadata into Prometheus-compatible labels.\n+   *\n+   * @returns {string} The packed metadata.\n+   * @private\n+   */\n+  #prometheusLabels() {\n+    const entries = ObjectEntries(this.meta);\n+    const pairs = ArrayPrototypeMap(entries, ({ 0: k, 1: v }) => `${k}=\"${v}\"`);",
        "comment_created_at": "2025-06-28T20:53:12+00:00",
        "comment_author": "Qard",
        "comment_body": "Yep, or more likely removing the formatters entirely and leaving that up to userland. There's probably a bunch more in here than is actually needed. Just did a bunch of experimenting and pushed what I had. \ud83d\ude05",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1956960458",
    "pr_number": 57059,
    "pr_file": "lib/os.js",
    "created_at": "2025-02-15T00:53:01+00:00",
    "commented_code": "function cpus() {\n   // [] is a bugfix for a regression introduced in 51cea61\n   const data = getCPUs() || [];\n-  const result = [];\n+  const result = new Array(data.length / 7);\n   let i = 0;\n+  let resultIndex = 0;\n+\n   while (i < data.length) {\n-    ArrayPrototypePush(result, {\n+    result[resultIndex++] = {",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "1956960458",
        "repo_full_name": "nodejs/node",
        "pr_number": 57059,
        "pr_file": "lib/os.js",
        "discussion_id": "1956960458",
        "commented_code": "@@ -140,10 +141,12 @@ function loadavg() {\n function cpus() {\n   // [] is a bugfix for a regression introduced in 51cea61\n   const data = getCPUs() || [];\n-  const result = [];\n+  const result = new Array(data.length / 7);\n   let i = 0;\n+  let resultIndex = 0;\n+\n   while (i < data.length) {\n-    ArrayPrototypePush(result, {\n+    result[resultIndex++] = {",
        "comment_created_at": "2025-02-15T00:53:01+00:00",
        "comment_author": "juanarbol",
        "comment_body": "Why not use the Primordial as the rest of the codebase?",
        "pr_file_module": null
      },
      {
        "comment_id": "1956964243",
        "repo_full_name": "nodejs/node",
        "pr_number": 57059,
        "pr_file": "lib/os.js",
        "discussion_id": "1956960458",
        "commented_code": "@@ -140,10 +141,12 @@ function loadavg() {\n function cpus() {\n   // [] is a bugfix for a regression introduced in 51cea61\n   const data = getCPUs() || [];\n-  const result = [];\n+  const result = new Array(data.length / 7);\n   let i = 0;\n+  let resultIndex = 0;\n+\n   while (i < data.length) {\n-    ArrayPrototypePush(result, {\n+    result[resultIndex++] = {",
        "comment_created_at": "2025-02-15T01:05:05+00:00",
        "comment_author": "gurgunday",
        "comment_body": "Yeah so this is one of the smaller things I've seen in the codebase, sometimes we construct and push into arrays that we already know the size of\r\n\r\nPre-allocating the array with the size and filling it should be faster",
        "pr_file_module": null
      },
      {
        "comment_id": "1956976779",
        "repo_full_name": "nodejs/node",
        "pr_number": 57059,
        "pr_file": "lib/os.js",
        "discussion_id": "1956960458",
        "commented_code": "@@ -140,10 +141,12 @@ function loadavg() {\n function cpus() {\n   // [] is a bugfix for a regression introduced in 51cea61\n   const data = getCPUs() || [];\n-  const result = [];\n+  const result = new Array(data.length / 7);\n   let i = 0;\n+  let resultIndex = 0;\n+\n   while (i < data.length) {\n-    ArrayPrototypePush(result, {\n+    result[resultIndex++] = {",
        "comment_created_at": "2025-02-15T01:34:16+00:00",
        "comment_author": "juanarbol",
        "comment_body": "Yeah, I'm sorry for being like this, would you mid writing a simple benchmark then? V8 is a bit weird sometimes, it does not like common sense sometimes.",
        "pr_file_module": null
      },
      {
        "comment_id": "1957122488",
        "repo_full_name": "nodejs/node",
        "pr_number": 57059,
        "pr_file": "lib/os.js",
        "discussion_id": "1956960458",
        "commented_code": "@@ -140,10 +141,12 @@ function loadavg() {\n function cpus() {\n   // [] is a bugfix for a regression introduced in 51cea61\n   const data = getCPUs() || [];\n-  const result = [];\n+  const result = new Array(data.length / 7);\n   let i = 0;\n+  let resultIndex = 0;\n+\n   while (i < data.length) {\n-    ArrayPrototypePush(result, {\n+    result[resultIndex++] = {",
        "comment_created_at": "2025-02-15T13:55:05+00:00",
        "comment_author": "gurgunday",
        "comment_body": "Something like this?\r\n\r\n```js\r\nfunction bench(size) {\r\n    // Push method\r\n    let start = performance.now();\r\n    const arr1 = [];\r\n    for (let i = 0; i < size; i++) {\r\n        arr1.push(i);\r\n    }\r\n    console.log(`push: ${(performance.now() - start).toFixed(2)}ms`);\r\n\r\n    // Pre-allocated array\r\n    start = performance.now();\r\n    const arr2 = new Array(size);\r\n    for (let i = 0; i < size; i++) {\r\n        arr2[i] = i;\r\n    }\r\n    console.log(`pre-allocated: ${(performance.now() - start).toFixed(2)}ms`);\r\n}\r\n\r\n// Run benchmark with 1 million elements\r\nbench(10_000_000);\r\n```\r\n\r\nChrome 133\r\n\r\n```sh\r\nVM83:8 push: 54.10ms\r\nVM83:16 pre-allocated: 23.50ms\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1957122502",
        "repo_full_name": "nodejs/node",
        "pr_number": 57059,
        "pr_file": "lib/os.js",
        "discussion_id": "1956960458",
        "commented_code": "@@ -140,10 +141,12 @@ function loadavg() {\n function cpus() {\n   // [] is a bugfix for a regression introduced in 51cea61\n   const data = getCPUs() || [];\n-  const result = [];\n+  const result = new Array(data.length / 7);\n   let i = 0;\n+  let resultIndex = 0;\n+\n   while (i < data.length) {\n-    ArrayPrototypePush(result, {\n+    result[resultIndex++] = {",
        "comment_created_at": "2025-02-15T13:55:14+00:00",
        "comment_author": "gurgunday",
        "comment_body": "Or should I add a bench to Node.js?",
        "pr_file_module": null
      },
      {
        "comment_id": "1983914346",
        "repo_full_name": "nodejs/node",
        "pr_number": 57059,
        "pr_file": "lib/os.js",
        "discussion_id": "1956960458",
        "commented_code": "@@ -140,10 +141,12 @@ function loadavg() {\n function cpus() {\n   // [] is a bugfix for a regression introduced in 51cea61\n   const data = getCPUs() || [];\n-  const result = [];\n+  const result = new Array(data.length / 7);\n   let i = 0;\n+  let resultIndex = 0;\n+\n   while (i < data.length) {\n-    ArrayPrototypePush(result, {\n+    result[resultIndex++] = {",
        "comment_created_at": "2025-03-06T19:08:44+00:00",
        "comment_author": "joyeecheung",
        "comment_body": "I think a benchmark that iterates over the returned CPU data and do something with it, say doing `result &&= (cpus[i].speed > 2000)`, would be more realistic. Pre-allocating an array and making it holely can affect the performance of indexing due to change of element kinds.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2045190884",
    "pr_number": 54364,
    "pr_file": "lib/internal/code_integrity.js",
    "created_at": "2025-04-15T18:05:58+00:00",
    "commented_code": "+// Code integrity is a security feature which prevents unsigned\n+// code from executing. More information can be found in the docs\n+// doc/api/code_integrity.md\n+\n+'use strict';\n+\n+const { emitWarning } = require('internal/process/warning');\n+const { isWindows } = require('internal/util');\n+\n+let isCodeIntegrityEnforced;\n+let alreadyQueriedSystemCodeEnforcmentMode = false;\n+\n+// Binding stub for non-Windows platforms\n+let binding = {\n+  isFileTrustedBySystemCodeIntegrityPolicy: () => true,\n+  isInteractiveModeDisabledInternal: () => false,\n+  isSystemEnforcingCodeIntegrity: () => false,\n+};\n+// Load the actual binding if on Windows\n+if (isWindows) {\n+  binding = internalBinding('code_integrity');\n+}\n+\n+const {\n+  isFileTrustedBySystemCodeIntegrityPolicy,\n+  isInteractiveModeDisabledInternal,\n+  isSystemEnforcingCodeIntegrity,\n+} = binding;\n+\n+function isAllowedToExecuteFile(filepath) {\n+  // At the moment code integrity is only implemented on Windows\n+  if (!isWindows) {\n+    return true;\n+  }\n+\n+  if (!alreadyQueriedSystemCodeEnforcmentMode) {\n+    isCodeIntegrityEnforced = isSystemEnforcingCodeIntegrity();\n+\n+    if (isCodeIntegrityEnforced) {\n+      emitWarning(\n+        'Code integrity is being enforced by system policy.' +\n+      '\nCode integrity is an experimental feature.' +\n+      ' See docs for more info.',\n+        'ExperimentalWarning');\n+    }\n+\n+    alreadyQueriedSystemCodeEnforcmentMode = true;\n+  }\n+\n+  if (!isCodeIntegrityEnforced) {\n+    return true;\n+  }\n+\n+  return isFileTrustedBySystemCodeIntegrityPolicy(filepath);\n+}\n+\n+function isInteractiveModeDisabled() {\n+  if (!isWindows) {\n+    return false;\n+  }\n+  return isInteractiveModeDisabledInternal();",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2045190884",
        "repo_full_name": "nodejs/node",
        "pr_number": 54364,
        "pr_file": "lib/internal/code_integrity.js",
        "discussion_id": "2045190884",
        "commented_code": "@@ -0,0 +1,69 @@\n+// Code integrity is a security feature which prevents unsigned\n+// code from executing. More information can be found in the docs\n+// doc/api/code_integrity.md\n+\n+'use strict';\n+\n+const { emitWarning } = require('internal/process/warning');\n+const { isWindows } = require('internal/util');\n+\n+let isCodeIntegrityEnforced;\n+let alreadyQueriedSystemCodeEnforcmentMode = false;\n+\n+// Binding stub for non-Windows platforms\n+let binding = {\n+  isFileTrustedBySystemCodeIntegrityPolicy: () => true,\n+  isInteractiveModeDisabledInternal: () => false,\n+  isSystemEnforcingCodeIntegrity: () => false,\n+};\n+// Load the actual binding if on Windows\n+if (isWindows) {\n+  binding = internalBinding('code_integrity');\n+}\n+\n+const {\n+  isFileTrustedBySystemCodeIntegrityPolicy,\n+  isInteractiveModeDisabledInternal,\n+  isSystemEnforcingCodeIntegrity,\n+} = binding;\n+\n+function isAllowedToExecuteFile(filepath) {\n+  // At the moment code integrity is only implemented on Windows\n+  if (!isWindows) {\n+    return true;\n+  }\n+\n+  if (!alreadyQueriedSystemCodeEnforcmentMode) {\n+    isCodeIntegrityEnforced = isSystemEnforcingCodeIntegrity();\n+\n+    if (isCodeIntegrityEnforced) {\n+      emitWarning(\n+        'Code integrity is being enforced by system policy.' +\n+      '\\nCode integrity is an experimental feature.' +\n+      ' See docs for more info.',\n+        'ExperimentalWarning');\n+    }\n+\n+    alreadyQueriedSystemCodeEnforcmentMode = true;\n+  }\n+\n+  if (!isCodeIntegrityEnforced) {\n+    return true;\n+  }\n+\n+  return isFileTrustedBySystemCodeIntegrityPolicy(filepath);\n+}\n+\n+function isInteractiveModeDisabled() {\n+  if (!isWindows) {\n+    return false;\n+  }\n+  return isInteractiveModeDisabledInternal();",
        "comment_created_at": "2025-04-15T18:05:58+00:00",
        "comment_author": "anonrig",
        "comment_body": "this adds an additional item to the stack trace whenever this function is called. we should not call this method on non-windows to avoid polluting the stack trace.",
        "pr_file_module": null
      },
      {
        "comment_id": "2045216794",
        "repo_full_name": "nodejs/node",
        "pr_number": 54364,
        "pr_file": "lib/internal/code_integrity.js",
        "discussion_id": "2045190884",
        "commented_code": "@@ -0,0 +1,69 @@\n+// Code integrity is a security feature which prevents unsigned\n+// code from executing. More information can be found in the docs\n+// doc/api/code_integrity.md\n+\n+'use strict';\n+\n+const { emitWarning } = require('internal/process/warning');\n+const { isWindows } = require('internal/util');\n+\n+let isCodeIntegrityEnforced;\n+let alreadyQueriedSystemCodeEnforcmentMode = false;\n+\n+// Binding stub for non-Windows platforms\n+let binding = {\n+  isFileTrustedBySystemCodeIntegrityPolicy: () => true,\n+  isInteractiveModeDisabledInternal: () => false,\n+  isSystemEnforcingCodeIntegrity: () => false,\n+};\n+// Load the actual binding if on Windows\n+if (isWindows) {\n+  binding = internalBinding('code_integrity');\n+}\n+\n+const {\n+  isFileTrustedBySystemCodeIntegrityPolicy,\n+  isInteractiveModeDisabledInternal,\n+  isSystemEnforcingCodeIntegrity,\n+} = binding;\n+\n+function isAllowedToExecuteFile(filepath) {\n+  // At the moment code integrity is only implemented on Windows\n+  if (!isWindows) {\n+    return true;\n+  }\n+\n+  if (!alreadyQueriedSystemCodeEnforcmentMode) {\n+    isCodeIntegrityEnforced = isSystemEnforcingCodeIntegrity();\n+\n+    if (isCodeIntegrityEnforced) {\n+      emitWarning(\n+        'Code integrity is being enforced by system policy.' +\n+      '\\nCode integrity is an experimental feature.' +\n+      ' See docs for more info.',\n+        'ExperimentalWarning');\n+    }\n+\n+    alreadyQueriedSystemCodeEnforcmentMode = true;\n+  }\n+\n+  if (!isCodeIntegrityEnforced) {\n+    return true;\n+  }\n+\n+  return isFileTrustedBySystemCodeIntegrityPolicy(filepath);\n+}\n+\n+function isInteractiveModeDisabled() {\n+  if (!isWindows) {\n+    return false;\n+  }\n+  return isInteractiveModeDisabledInternal();",
        "comment_created_at": "2025-04-15T18:22:08+00:00",
        "comment_author": "anonrig",
        "comment_body": "Also, can't this method be cached?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2119441903",
    "pr_number": 58453,
    "pr_file": "lib/internal/streams/end-of-stream.js",
    "created_at": "2025-06-01T18:50:36+00:00",
    "commented_code": "callback.call(stream);\n   };\n \n+  const disposableStack = new DisposableStack();  // eslint-disable-line no-undef\n+\n   const onrequest = () => {\n-    stream.req.on('finish', onfinish);\n+    disposableStack.use(stream.req.addDisposableListener('finish', onfinish));",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2119441903",
        "repo_full_name": "nodejs/node",
        "pr_number": 58453,
        "pr_file": "lib/internal/streams/end-of-stream.js",
        "discussion_id": "2119441903",
        "commented_code": "@@ -177,36 +177,38 @@ function eos(stream, options, callback) {\n     callback.call(stream);\n   };\n \n+  const disposableStack = new DisposableStack();  // eslint-disable-line no-undef\n+\n   const onrequest = () => {\n-    stream.req.on('finish', onfinish);\n+    disposableStack.use(stream.req.addDisposableListener('finish', onfinish));",
        "comment_created_at": "2025-06-01T18:50:36+00:00",
        "comment_author": "benjamingr",
        "comment_body": "This would need a stream benchmark run before landing",
        "pr_file_module": null
      },
      {
        "comment_id": "2119692350",
        "repo_full_name": "nodejs/node",
        "pr_number": 58453,
        "pr_file": "lib/internal/streams/end-of-stream.js",
        "discussion_id": "2119441903",
        "commented_code": "@@ -177,36 +177,38 @@ function eos(stream, options, callback) {\n     callback.call(stream);\n   };\n \n+  const disposableStack = new DisposableStack();  // eslint-disable-line no-undef\n+\n   const onrequest = () => {\n-    stream.req.on('finish', onfinish);\n+    disposableStack.use(stream.req.addDisposableListener('finish', onfinish));",
        "comment_created_at": "2025-06-01T23:05:58+00:00",
        "comment_author": "jasnell",
        "comment_body": "The results are mixed and it's just not clear if the difference is worth being concerned about... some benchmarks are faster, others are slower.\r\n\r\n```\r\nstreams/compose.js n=1000                                                                       ***    -19.41 %       \u00b11.17%  \u00b11.57%  \u00b12.06%\r\nstreams/creation.js kind='duplex' n=50000000                                                    ***      4.39 %       \u00b11.62%  \u00b12.16%  \u00b12.81%\r\nstreams/creation.js kind='readable' n=50000000                                                           2.46 %       \u00b14.12%  \u00b15.48%  \u00b17.14%\r\nstreams/creation.js kind='transform' n=50000000                                                   *      2.21 %       \u00b11.69%  \u00b12.25%  \u00b12.94%\r\nstreams/creation.js kind='writable' n=50000000                                                  ***      6.72 %       \u00b12.15%  \u00b12.85%  \u00b13.71%\r\nstreams/destroy.js kind='duplex' n=1000000                                                              -0.50 %       \u00b13.36%  \u00b14.48%  \u00b15.84%\r\nstreams/destroy.js kind='readable' n=1000000                                                             1.07 %       \u00b12.43%  \u00b13.24%  \u00b14.22%\r\nstreams/destroy.js kind='transform' n=1000000                                                           -0.55 %       \u00b12.33%  \u00b13.10%  \u00b14.03%\r\nstreams/destroy.js kind='writable' n=1000000                                                             0.16 %       \u00b12.75%  \u00b13.66%  \u00b14.77%\r\nstreams/pipe-object-mode.js n=5000000                                                           ***      4.68 %       \u00b12.00%  \u00b12.67%  \u00b13.50%\r\nstreams/pipe.js n=5000000                                                                       ***     10.30 %       \u00b11.19%  \u00b11.59%  \u00b12.07%\r\nstreams/readable-async-iterator.js sync='no' n=100000                                                    1.07 %       \u00b11.92%  \u00b12.55%  \u00b13.32%\r\nstreams/readable-async-iterator.js sync='yes' n=100000                                          ***      8.45 %       \u00b13.80%  \u00b15.06%  \u00b16.59%\r\nstreams/readable-bigread.js n=1000                                                                       0.55 %       \u00b12.27%  \u00b13.02%  \u00b13.94%\r\nstreams/readable-bigunevenread.js n=1000                                                        ***     -2.12 %       \u00b11.13%  \u00b11.52%  \u00b11.99%\r\nstreams/readable-boundaryread.js type='buffer' n=2000                                             *      1.03 %       \u00b10.84%  \u00b11.12%  \u00b11.46%\r\nstreams/readable-boundaryread.js type='string' n=2000                                             *      2.08 %       \u00b11.69%  \u00b12.26%  \u00b12.97%\r\nstreams/readable-from.js type='array' n=10000000                                                ***     -5.20 %       \u00b12.30%  \u00b13.06%  \u00b13.99%\r\nstreams/readable-from.js type='async-generator' n=10000000                                               1.73 %       \u00b12.22%  \u00b12.96%  \u00b13.86%\r\nstreams/readable-from.js type='sync-generator-with-async-values' n=10000000                              1.88 %       \u00b12.05%  \u00b12.73%  \u00b13.56%\r\nstreams/readable-from.js type='sync-generator-with-sync-values' n=10000000                              -1.75 %       \u00b12.41%  \u00b13.24%  \u00b14.28%\r\nstreams/readable-readall.js n=5000                                                               **     -4.53 %       \u00b13.18%  \u00b14.24%  \u00b15.51%\r\nstreams/readable-uint8array.js kind='encoding' n=1000000                                         **      2.40 %       \u00b11.52%  \u00b12.02%  \u00b12.63%\r\nstreams/readable-uint8array.js kind='read' n=1000000                                            ***     -2.98 %       \u00b11.59%  \u00b12.11%  \u00b12.75%\r\nstreams/readable-unevenread.js n=1000                                                             *     -1.81 %       \u00b11.45%  \u00b11.93%  \u00b12.51%\r\nstreams/writable-manywrites.js len=1024 callback='no' writev='no' sync='no' n=100000                     1.10 %       \u00b13.76%  \u00b15.00%  \u00b16.51%\r\nstreams/writable-manywrites.js len=1024 callback='no' writev='no' sync='yes' n=100000           ***     27.55 %       \u00b19.28% \u00b112.36% \u00b116.09%\r\nstreams/writable-manywrites.js len=1024 callback='no' writev='yes' sync='no' n=100000                    2.88 %       \u00b15.18%  \u00b16.90%  \u00b18.98%\r\nstreams/writable-manywrites.js len=1024 callback='no' writev='yes' sync='yes' n=100000            *     11.47 %       \u00b19.08% \u00b112.08% \u00b115.73%\r\nstreams/writable-manywrites.js len=1024 callback='yes' writev='no' sync='no' n=100000                   -1.45 %       \u00b13.28%  \u00b14.36%  \u00b15.68%\r\nstreams/writable-manywrites.js len=1024 callback='yes' writev='no' sync='yes' n=100000          ***     23.32 %       \u00b18.66% \u00b111.53% \u00b115.01%\r\nstreams/writable-manywrites.js len=1024 callback='yes' writev='yes' sync='no' n=100000                   3.83 %       \u00b14.48%  \u00b15.96%  \u00b17.76%\r\nstreams/writable-manywrites.js len=1024 callback='yes' writev='yes' sync='yes' n=100000                  1.32 %       \u00b16.89%  \u00b19.17% \u00b111.94%\r\nstreams/writable-manywrites.js len=32768 callback='no' writev='no' sync='no' n=100000                   -1.30 %       \u00b13.51%  \u00b14.68%  \u00b16.09%\r\nstreams/writable-manywrites.js len=32768 callback='no' writev='no' sync='yes' n=100000          ***     30.32 %      \u00b110.19% \u00b113.57% \u00b117.67%\r\nstreams/writable-manywrites.js len=32768 callback='no' writev='yes' sync='no' n=100000                   0.12 %       \u00b13.88%  \u00b15.17%  \u00b16.73%\r\nstreams/writable-manywrites.js len=32768 callback='no' writev='yes' sync='yes' n=100000          **     13.40 %       \u00b19.34% \u00b112.47% \u00b116.32%\r\nstreams/writable-manywrites.js len=32768 callback='yes' writev='no' sync='no' n=100000                  -1.46 %       \u00b14.38%  \u00b15.83%  \u00b17.61%\r\nstreams/writable-manywrites.js len=32768 callback='yes' writev='no' sync='yes' n=100000         ***     16.67 %       \u00b18.21% \u00b110.94% \u00b114.28%\r\nstreams/writable-manywrites.js len=32768 callback='yes' writev='yes' sync='no' n=100000                  1.19 %       \u00b14.05%  \u00b15.39%  \u00b17.01%\r\nstreams/writable-manywrites.js len=32768 callback='yes' writev='yes' sync='yes' n=100000        ***     21.43 %       \u00b19.84% \u00b113.14% \u00b117.21%\r\nstreams/writable-uint8array.js kind='object-mode' n=50000000                                             0.64 %       \u00b13.66%  \u00b14.87%  \u00b16.34%\r\nstreams/writable-uint8array.js kind='write' n=50000000                                            *      3.85 %       \u00b13.32%  \u00b14.42%  \u00b15.76%\r\nstreams/writable-uint8array.js kind='writev' n=50000000                                           *      3.15 %       \u00b12.99%  \u00b13.98%  \u00b15.18%\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1913526555",
    "pr_number": 56578,
    "pr_file": "lib/internal/buffer.js",
    "created_at": "2025-01-13T17:08:02+00:00",
    "commented_code": "if (byteLength === 3)\n     return readInt24BE(this, offset);\n   if (byteLength === 4)\n-    return this.readInt32BE(offset);\n+    return FunctionPrototypeCall(readInt32BE, this, offset);\n   if (byteLength === 2)\n-    return this.readInt16BE(offset);\n+    return FunctionPrototypeCall(readInt16BE, this, offset);\n   if (byteLength === 1)\n-    return this.readInt8(offset);\n+    return FunctionPrototypeCall(readInt8, this, offset);",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "1913526555",
        "repo_full_name": "nodejs/node",
        "pr_number": 56578,
        "pr_file": "lib/internal/buffer.js",
        "discussion_id": "1913526555",
        "commented_code": "@@ -438,11 +439,11 @@ function readIntBE(offset, byteLength) {\n   if (byteLength === 3)\n     return readInt24BE(this, offset);\n   if (byteLength === 4)\n-    return this.readInt32BE(offset);\n+    return FunctionPrototypeCall(readInt32BE, this, offset);\n   if (byteLength === 2)\n-    return this.readInt16BE(offset);\n+    return FunctionPrototypeCall(readInt16BE, this, offset);\n   if (byteLength === 1)\n-    return this.readInt8(offset);\n+    return FunctionPrototypeCall(readInt8, this, offset);",
        "comment_created_at": "2025-01-13T17:08:02+00:00",
        "comment_author": "addaleax",
        "comment_body": "This is already (correctly imo) marked as needing a benchmark CI run, but just as a heads up, if this does turn out to be an issue, it shouldn't be a big deal to create non-prototype versions of these functions that don't use `this` as the target",
        "pr_file_module": null
      },
      {
        "comment_id": "1913544989",
        "repo_full_name": "nodejs/node",
        "pr_number": 56578,
        "pr_file": "lib/internal/buffer.js",
        "discussion_id": "1913526555",
        "commented_code": "@@ -438,11 +439,11 @@ function readIntBE(offset, byteLength) {\n   if (byteLength === 3)\n     return readInt24BE(this, offset);\n   if (byteLength === 4)\n-    return this.readInt32BE(offset);\n+    return FunctionPrototypeCall(readInt32BE, this, offset);\n   if (byteLength === 2)\n-    return this.readInt16BE(offset);\n+    return FunctionPrototypeCall(readInt16BE, this, offset);\n   if (byteLength === 1)\n-    return this.readInt8(offset);\n+    return FunctionPrototypeCall(readInt8, this, offset);",
        "comment_created_at": "2025-01-13T17:22:29+00:00",
        "comment_author": "nbbeeken",
        "comment_body": "Yea I was thinking of that as an alternative implementation but took the route of least blast radius to start, happy to go through and change them to match the other int parsers that take the argument. (Should we go ahead and do that regardless of the benchmarks?)",
        "pr_file_module": null
      },
      {
        "comment_id": "1914770569",
        "repo_full_name": "nodejs/node",
        "pr_number": 56578,
        "pr_file": "lib/internal/buffer.js",
        "discussion_id": "1913526555",
        "commented_code": "@@ -438,11 +439,11 @@ function readIntBE(offset, byteLength) {\n   if (byteLength === 3)\n     return readInt24BE(this, offset);\n   if (byteLength === 4)\n-    return this.readInt32BE(offset);\n+    return FunctionPrototypeCall(readInt32BE, this, offset);\n   if (byteLength === 2)\n-    return this.readInt16BE(offset);\n+    return FunctionPrototypeCall(readInt16BE, this, offset);\n   if (byteLength === 1)\n-    return this.readInt8(offset);\n+    return FunctionPrototypeCall(readInt8, this, offset);",
        "comment_created_at": "2025-01-14T12:57:32+00:00",
        "comment_author": "addaleax",
        "comment_body": "> Should we go ahead and do that regardless of the benchmarks?\r\n\r\nNo strong preferences from my side, maybe somebody else has one. But for now, I'd say we can fix the failures reported by GHA, then run regular CI + benchmark CI and see what happens",
        "pr_file_module": null
      },
      {
        "comment_id": "1917489828",
        "repo_full_name": "nodejs/node",
        "pr_number": 56578,
        "pr_file": "lib/internal/buffer.js",
        "discussion_id": "1913526555",
        "commented_code": "@@ -438,11 +439,11 @@ function readIntBE(offset, byteLength) {\n   if (byteLength === 3)\n     return readInt24BE(this, offset);\n   if (byteLength === 4)\n-    return this.readInt32BE(offset);\n+    return FunctionPrototypeCall(readInt32BE, this, offset);\n   if (byteLength === 2)\n-    return this.readInt16BE(offset);\n+    return FunctionPrototypeCall(readInt16BE, this, offset);\n   if (byteLength === 1)\n-    return this.readInt8(offset);\n+    return FunctionPrototypeCall(readInt8, this, offset);",
        "comment_created_at": "2025-01-16T00:01:19+00:00",
        "comment_author": "nbbeeken",
        "comment_body": "```\r\nbuffers/buffer-bytelength-string.js n=4000000 repeat=2 encoding='utf8' type='two_bytes'                                                                 **     -1.37 %       \u00b10.99%  \u00b11.32%  \u00b11.71%\r\nbuffers/buffer-bytelength-string.js n=4000000 repeat=256 encoding='base64' type='latin1'                                                                **      2.49 %       \u00b11.83%  \u00b12.45%  \u00b13.24%\r\nbuffers/buffer-creation.js n=600000 len=1024 type='slow-allocUnsafe'                                                                                   ***     -3.01 %       \u00b11.32%  \u00b11.76%  \u00b12.29%\r\nbuffers/buffer-creation.js n=600000 len=4096 type='fast-allocUnsafe'                                                                                   ***     -4.03 %       \u00b12.22%  \u00b12.96%  \u00b13.85%\r\nbuffers/buffer-creation.js n=600000 len=8192 type='fast-allocUnsafe'                                                                                    **     -2.50 %       \u00b11.64%  \u00b12.19%  \u00b12.86%\r\nbuffers/buffer-creation.js n=600000 len=8192 type='slow-allocUnsafe'                                                                                    **     -2.49 %       \u00b11.44%  \u00b11.92%  \u00b12.50%\r\nbuffers/buffer-fill.js n=20000 size=8192 type='fill(\"t\", 0)'                                                                                            **     -4.09 %       \u00b13.06%  \u00b14.09%  \u00b15.37%\r\nbuffers/buffer-from.js n=800000 len=100 source='uint16array'                                                                                           ***     -2.03 %       \u00b10.98%  \u00b11.31%  \u00b11.71%\r\nbuffers/buffer-from.js n=800000 len=2048 source='arraybuffer-middle'                                                                                    **      1.65 %       \u00b11.21%  \u00b11.61%  \u00b12.09%\r\nbuffers/buffer-from.js n=800000 len=2048 source='arraybuffer'                                                                                           **      1.82 %       \u00b11.10%  \u00b11.46%  \u00b11.91%\r\nbuffers/buffer-swap.js n=1000000 len=256 method='swap32' aligned='false'                                                                                **      0.75 %       \u00b10.48%  \u00b10.64%  \u00b10.84%\r\nbuffers/buffer-swap.js n=1000000 len=768 method='swap16' aligned='false'                                                                                **     -1.57 %       \u00b11.08%  \u00b11.45%  \u00b11.90%\r\nbuffers/dataview-set.js n=1000000 type='Uint16BE'                                                                                                      ***    -24.92 %       \u00b11.98%  \u00b12.65%  \u00b13.50%\r\nbuffers/dataview-set.js n=1000000 type='Uint16LE'                                                                                                      ***    -25.11 %       \u00b10.99%  \u00b11.32%  \u00b11.72%\r\n  23.55 false positives, when considering a   5% risk acceptance (*, **, ***),\r\n  4.71 false positives, when considering a   1% risk acceptance (**, ***),\r\n  0.47 false positives, when considering a 0.1% risk acceptance (***)\r\n```\r\n\r\nJust filtered for the two and three star confidence ones and the changes are small, except for oddly the dataview tests, which just happen to be in the buffers folder, not sure how I could've changed that value but maybe this won't reproduce in CI? \ud83e\udd1e\ud83c\udffb ",
        "pr_file_module": null
      },
      {
        "comment_id": "1951263163",
        "repo_full_name": "nodejs/node",
        "pr_number": 56578,
        "pr_file": "lib/internal/buffer.js",
        "discussion_id": "1913526555",
        "commented_code": "@@ -438,11 +439,11 @@ function readIntBE(offset, byteLength) {\n   if (byteLength === 3)\n     return readInt24BE(this, offset);\n   if (byteLength === 4)\n-    return this.readInt32BE(offset);\n+    return FunctionPrototypeCall(readInt32BE, this, offset);\n   if (byteLength === 2)\n-    return this.readInt16BE(offset);\n+    return FunctionPrototypeCall(readInt16BE, this, offset);\n   if (byteLength === 1)\n-    return this.readInt8(offset);\n+    return FunctionPrototypeCall(readInt8, this, offset);",
        "comment_created_at": "2025-02-11T17:15:09+00:00",
        "comment_author": "addaleax",
        "comment_body": "I think the up-to-minus-4% regressions on the others are also a bit concerning though \ud83d\ude15 \r\n\r\nTo me this does feel like an impact we'd want to avoid if we can at all",
        "pr_file_module": null
      },
      {
        "comment_id": "1951341328",
        "repo_full_name": "nodejs/node",
        "pr_number": 56578,
        "pr_file": "lib/internal/buffer.js",
        "discussion_id": "1913526555",
        "commented_code": "@@ -438,11 +439,11 @@ function readIntBE(offset, byteLength) {\n   if (byteLength === 3)\n     return readInt24BE(this, offset);\n   if (byteLength === 4)\n-    return this.readInt32BE(offset);\n+    return FunctionPrototypeCall(readInt32BE, this, offset);\n   if (byteLength === 2)\n-    return this.readInt16BE(offset);\n+    return FunctionPrototypeCall(readInt16BE, this, offset);\n   if (byteLength === 1)\n-    return this.readInt8(offset);\n+    return FunctionPrototypeCall(readInt8, this, offset);",
        "comment_created_at": "2025-02-11T18:06:30+00:00",
        "comment_author": "nbbeeken",
        "comment_body": "SGTM, I'll try switching over to direct invocations and see if we climb back up",
        "pr_file_module": null
      }
    ]
  }
]