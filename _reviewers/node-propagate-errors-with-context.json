[
  {
    "discussion_id": "2162924854",
    "pr_number": 58666,
    "pr_file": "src/node_locks.cc",
    "created_at": "2025-06-24T04:17:12+00:00",
    "commented_code": "+#include \"node_locks.h\"\n+\n+#include \"env-inl.h\"\n+#include \"node_errors.h\"\n+#include \"node_external_reference.h\"\n+#include \"node_internals.h\"\n+#include \"util-inl.h\"\n+#include \"v8.h\"\n+\n+namespace node::worker::locks {\n+\n+using node::errors::TryCatchScope;\n+using v8::Array;\n+using v8::Context;\n+using v8::Exception;\n+using v8::External;\n+using v8::Function;\n+using v8::FunctionCallbackInfo;\n+using v8::HandleScope;\n+using v8::Isolate;\n+using v8::Local;\n+using v8::Object;\n+using v8::ObjectTemplate;\n+using v8::Promise;\n+using v8::String;\n+using v8::Value;\n+\n+static constexpr const char* kSharedMode = \"shared\";\n+static constexpr const char* kExclusiveMode = \"exclusive\";\n+static constexpr const char* kLockStolenError = \"LOCK_STOLEN\";\n+\n+static Local<Object> CreateLockInfoObject(Isolate* isolate,\n+                                          Local<Context> context,\n+                                          const std::u16string& name,\n+                                          Lock::Mode mode,\n+                                          const std::string& client_id);\n+\n+Lock::Lock(Environment* env,\n+           const std::u16string& name,\n+           Mode mode,\n+           const std::string& client_id,\n+           Local<Promise::Resolver> waiting,\n+           Local<Promise::Resolver> released)\n+    : env_(env), name_(name), mode_(mode), client_id_(client_id) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+}\n+\n+LockRequest::LockRequest(Environment* env,\n+                         Local<Promise::Resolver> waiting,\n+                         Local<Promise::Resolver> released,\n+                         Local<Function> callback,\n+                         const std::u16string& name,\n+                         Lock::Mode mode,\n+                         const std::string& client_id,\n+                         bool steal,\n+                         bool if_available)\n+    : env_(env),\n+      name_(name),\n+      mode_(mode),\n+      client_id_(client_id),\n+      steal_(steal),\n+      if_available_(if_available) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+  callback_.Reset(env_->isolate(), callback);\n+}\n+\n+bool LockManager::IsGrantable(const LockRequest* request) const {\n+  // Steal requests bypass all normal granting rules\n+  if (request->steal()) return true;\n+\n+  auto held_locks_iter = held_locks_.find(request->name());\n+  // No existing locks for this resource name\n+  if (held_locks_iter == held_locks_.end()) return true;\n+\n+  // Exclusive requests cannot coexist with any existing locks\n+  if (request->mode() == Lock::Mode::Exclusive) return false;\n+\n+  // For shared requests, check if any existing lock is exclusive\n+  for (const auto& existing_lock : held_locks_iter->second) {\n+    if (existing_lock->mode() == Lock::Mode::Exclusive) return false;\n+  }\n+  // All existing locks are shared, so this shared request can be granted\n+  return true;\n+}\n+\n+// Called when the user callback promise fulfills\n+static void OnLockCallbackFulfilled(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  // Extract the LockHolder from V8 External data\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  // Release the lock and continue processing the queue.\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], false);\n+}\n+\n+// Called when the user callback promise rejects\n+static void OnLockCallbackRejected(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], true);\n+}\n+\n+void LockManager::CleanupStolenLocks(Environment* env) {\n+  std::vector<std::u16string> resources_to_clean;\n+\n+  // Collect resources to clean\n+  {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    for (auto resource_iter = held_locks_.begin();\n+         resource_iter != held_locks_.end();\n+         ++resource_iter) {\n+      auto& resource_locks = resource_iter->second;\n+      bool has_stolen_from_other_env = false;\n+\n+      // Check if this resource has stolen locks from other environments\n+      for (const auto& lock_ptr : resource_locks) {\n+        if (lock_ptr->is_stolen() && lock_ptr->env() != env) {\n+          has_stolen_from_other_env = true;\n+          break;\n+        }\n+      }\n+\n+      if (has_stolen_from_other_env) {\n+        resources_to_clean.push_back(resource_iter->first);\n+      }\n+    }\n+  }\n+\n+  // Clean up resources\n+  for (const auto& resource_name : resources_to_clean) {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    auto resource_iter = held_locks_.find(resource_name);\n+    if (resource_iter != held_locks_.end()) {\n+      auto& resource_locks = resource_iter->second;\n+\n+      // Remove stolen locks from other environments\n+      for (auto lock_iter = resource_locks.begin();\n+           lock_iter != resource_locks.end();) {\n+        if ((*lock_iter)->is_stolen() && (*lock_iter)->env() != env) {\n+          lock_iter = resource_locks.erase(lock_iter);\n+        } else {\n+          ++lock_iter;\n+        }\n+      }\n+\n+      if (resource_locks.empty()) {\n+        held_locks_.erase(resource_iter);\n+      }\n+    }\n+  }\n+}\n+\n+/**\n+ * Web Locks algorithm implementation\n+ * https://w3c.github.io/web-locks/#algorithms\n+ */\n+void LockManager::ProcessQueue(Environment* env) {\n+  Isolate* isolate = env->isolate();\n+  HandleScope handle_scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  // Remove locks that were stolen from this Environment first\n+  CleanupStolenLocks(env);\n+\n+  while (true) {\n+    std::unique_ptr<LockRequest> grantable_request;\n+    std::unique_ptr<LockRequest> if_available_request;\n+    std::unordered_set<Environment*> other_envs_to_wake;\n+\n+    {\n+      std::unordered_map<std::u16string, LockRequest*> first_seen_for_resource;\n+\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      for (auto queue_iter = pending_queue_.begin();\n+           queue_iter != pending_queue_.end();\n+           ++queue_iter) {\n+        LockRequest* request = queue_iter->get();\n+\n+        // Collect unique environments to wake up later\n+        if (request->env() != env) {\n+          other_envs_to_wake.insert(request->env());\n+          continue;\n+        }\n+\n+        // During a single pass, the first time we see a resource name is the\n+        // earliest pending request\n+        auto& first_for_resource = first_seen_for_resource[request->name()];\n+        if (first_for_resource == nullptr) {\n+          first_for_resource = request;  // Mark as first seen for this resource\n+        }\n+\n+        bool has_earlier_request_for_same_resource =\n+            (first_for_resource != request);\n+\n+        if (has_earlier_request_for_same_resource || !IsGrantable(request)) {\n+          if (request->if_available()) {\n+            // ifAvailable request when resource not available: grant with null\n+            if_available_request = std::move(*queue_iter);\n+            pending_queue_.erase(queue_iter);\n+            break;\n+          }\n+          continue;\n+        }\n+\n+        // Found a request that can be granted normally\n+        grantable_request = std::move(*queue_iter);\n+        pending_queue_.erase(queue_iter);\n+        break;\n+      }\n+    }\n+\n+    // Wake each environment only once\n+    for (Environment* target_env : other_envs_to_wake) {\n+      WakeEnvironment(target_env);\n+    }\n+\n+    /**\n+     * ifAvailable:\n+     *  Grant the lock only if it is immediately available;\n+     *  otherwise invoke the callback with null and resolve the promises.\n+     *  Check wrapCallback function in locks.js\n+     */\n+    if (if_available_request) {\n+      Local<Value> null_arg = Null(isolate);\n+      Local<Value> callback_result;\n+      {\n+        TryCatchScope try_catch_scope(env);\n+        if (!if_available_request->callback()\n+                 ->Call(context, Undefined(isolate), 1, &null_arg)\n+                 .ToLocal(&callback_result)) {\n+          if_available_request->waiting_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          if_available_request->released_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          return;\n+        }\n+      }\n+      if_available_request->waiting_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      if_available_request->released_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      return;\n+    }\n+\n+    if (!grantable_request) return;\n+\n+    // Handle steal operations with minimal mutex scope\n+    if (grantable_request->steal()) {\n+      std::unordered_set<Environment*> envs_to_notify;\n+\n+      {\n+        Mutex::ScopedLock scoped_lock(mutex_);\n+        auto held_locks_iter = held_locks_.find(grantable_request->name());\n+        if (held_locks_iter != held_locks_.end()) {\n+          // Mark existing locks as stolen and collect environments to notify\n+          for (auto& existing_lock : held_locks_iter->second) {\n+            existing_lock->mark_stolen();\n+            envs_to_notify.insert(existing_lock->env());\n+\n+            // Immediately reject the stolen lock's released_promise\n+            Local<String> error_string;\n+            if (!String::NewFromUtf8(isolate, kLockStolenError)\n+                     .ToLocal(&error_string)) {\n+              return;\n+            }\n+            Local<Value> error = Exception::Error(error_string);\n+            existing_lock->released_promise()->Reject(context, error).Check();\n+          }\n+\n+          // Remove stolen locks from current environment immediately\n+          for (auto lock_iter = held_locks_iter->second.begin();\n+               lock_iter != held_locks_iter->second.end();) {\n+            if ((*lock_iter)->env() == env) {\n+              lock_iter = held_locks_iter->second.erase(lock_iter);\n+            } else {\n+              ++lock_iter;\n+            }\n+          }\n+\n+          if (held_locks_iter->second.empty()) {\n+            held_locks_.erase(held_locks_iter);\n+          }\n+        }\n+      }\n+\n+      // Wake other environments\n+      for (Environment* target_env : envs_to_notify) {\n+        if (target_env != env) {\n+          WakeEnvironment(target_env);\n+        }\n+      }\n+    }\n+\n+    // Create and store the new granted lock\n+    auto granted_lock =\n+        std::make_shared<Lock>(env,\n+                               grantable_request->name(),\n+                               grantable_request->mode(),\n+                               grantable_request->client_id(),\n+                               grantable_request->waiting_promise(),\n+                               grantable_request->released_promise());\n+    {\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      held_locks_[grantable_request->name()].push_back(granted_lock);\n+    }\n+\n+    // Call user callback\n+    Local<Object> lock_info_obj =\n+        CreateLockInfoObject(isolate,\n+                             context,\n+                             grantable_request->name(),\n+                             grantable_request->mode(),\n+                             grantable_request->client_id());\n+    if (lock_info_obj.IsEmpty()) {\n+      return;\n+    }\n+    Local<Value> callback_arg = lock_info_obj;\n+    Local<Value> callback_result;\n+    {\n+      TryCatchScope try_catch_scope(env);\n+      if (!grantable_request->callback()\n+               ->Call(context, Undefined(isolate), 1, &callback_arg)\n+               .ToLocal(&callback_result)) {\n+        grantable_request->waiting_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        return;\n+      }\n+    }\n+\n+    // Allocate a LockHolder on the heap to safely manage the lock's lifetime\n+    // until the user's callback promise settles.\n+    auto* fulfill_holder = new LockHolder(granted_lock);\n+    auto* reject_holder = new LockHolder(granted_lock);\n+    Local<Function> on_fulfilled_callback;\n+    Local<Function> on_rejected_callback;\n+\n+    if (!Function::New(context,\n+                       OnLockCallbackFulfilled,\n+                       External::New(isolate, fulfill_holder))\n+             .ToLocal(&on_fulfilled_callback) ||\n+        !Function::New(context,\n+                       OnLockCallbackRejected,\n+                       External::New(isolate, reject_holder))\n+             .ToLocal(&on_rejected_callback)) {\n+      delete fulfill_holder;\n+      delete reject_holder;",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2162924854",
        "repo_full_name": "nodejs/node",
        "pr_number": 58666,
        "pr_file": "src/node_locks.cc",
        "discussion_id": "2162924854",
        "commented_code": "@@ -0,0 +1,738 @@\n+#include \"node_locks.h\"\n+\n+#include \"env-inl.h\"\n+#include \"node_errors.h\"\n+#include \"node_external_reference.h\"\n+#include \"node_internals.h\"\n+#include \"util-inl.h\"\n+#include \"v8.h\"\n+\n+namespace node::worker::locks {\n+\n+using node::errors::TryCatchScope;\n+using v8::Array;\n+using v8::Context;\n+using v8::Exception;\n+using v8::External;\n+using v8::Function;\n+using v8::FunctionCallbackInfo;\n+using v8::HandleScope;\n+using v8::Isolate;\n+using v8::Local;\n+using v8::Object;\n+using v8::ObjectTemplate;\n+using v8::Promise;\n+using v8::String;\n+using v8::Value;\n+\n+static constexpr const char* kSharedMode = \"shared\";\n+static constexpr const char* kExclusiveMode = \"exclusive\";\n+static constexpr const char* kLockStolenError = \"LOCK_STOLEN\";\n+\n+static Local<Object> CreateLockInfoObject(Isolate* isolate,\n+                                          Local<Context> context,\n+                                          const std::u16string& name,\n+                                          Lock::Mode mode,\n+                                          const std::string& client_id);\n+\n+Lock::Lock(Environment* env,\n+           const std::u16string& name,\n+           Mode mode,\n+           const std::string& client_id,\n+           Local<Promise::Resolver> waiting,\n+           Local<Promise::Resolver> released)\n+    : env_(env), name_(name), mode_(mode), client_id_(client_id) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+}\n+\n+LockRequest::LockRequest(Environment* env,\n+                         Local<Promise::Resolver> waiting,\n+                         Local<Promise::Resolver> released,\n+                         Local<Function> callback,\n+                         const std::u16string& name,\n+                         Lock::Mode mode,\n+                         const std::string& client_id,\n+                         bool steal,\n+                         bool if_available)\n+    : env_(env),\n+      name_(name),\n+      mode_(mode),\n+      client_id_(client_id),\n+      steal_(steal),\n+      if_available_(if_available) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+  callback_.Reset(env_->isolate(), callback);\n+}\n+\n+bool LockManager::IsGrantable(const LockRequest* request) const {\n+  // Steal requests bypass all normal granting rules\n+  if (request->steal()) return true;\n+\n+  auto held_locks_iter = held_locks_.find(request->name());\n+  // No existing locks for this resource name\n+  if (held_locks_iter == held_locks_.end()) return true;\n+\n+  // Exclusive requests cannot coexist with any existing locks\n+  if (request->mode() == Lock::Mode::Exclusive) return false;\n+\n+  // For shared requests, check if any existing lock is exclusive\n+  for (const auto& existing_lock : held_locks_iter->second) {\n+    if (existing_lock->mode() == Lock::Mode::Exclusive) return false;\n+  }\n+  // All existing locks are shared, so this shared request can be granted\n+  return true;\n+}\n+\n+// Called when the user callback promise fulfills\n+static void OnLockCallbackFulfilled(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  // Extract the LockHolder from V8 External data\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  // Release the lock and continue processing the queue.\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], false);\n+}\n+\n+// Called when the user callback promise rejects\n+static void OnLockCallbackRejected(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], true);\n+}\n+\n+void LockManager::CleanupStolenLocks(Environment* env) {\n+  std::vector<std::u16string> resources_to_clean;\n+\n+  // Collect resources to clean\n+  {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    for (auto resource_iter = held_locks_.begin();\n+         resource_iter != held_locks_.end();\n+         ++resource_iter) {\n+      auto& resource_locks = resource_iter->second;\n+      bool has_stolen_from_other_env = false;\n+\n+      // Check if this resource has stolen locks from other environments\n+      for (const auto& lock_ptr : resource_locks) {\n+        if (lock_ptr->is_stolen() && lock_ptr->env() != env) {\n+          has_stolen_from_other_env = true;\n+          break;\n+        }\n+      }\n+\n+      if (has_stolen_from_other_env) {\n+        resources_to_clean.push_back(resource_iter->first);\n+      }\n+    }\n+  }\n+\n+  // Clean up resources\n+  for (const auto& resource_name : resources_to_clean) {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    auto resource_iter = held_locks_.find(resource_name);\n+    if (resource_iter != held_locks_.end()) {\n+      auto& resource_locks = resource_iter->second;\n+\n+      // Remove stolen locks from other environments\n+      for (auto lock_iter = resource_locks.begin();\n+           lock_iter != resource_locks.end();) {\n+        if ((*lock_iter)->is_stolen() && (*lock_iter)->env() != env) {\n+          lock_iter = resource_locks.erase(lock_iter);\n+        } else {\n+          ++lock_iter;\n+        }\n+      }\n+\n+      if (resource_locks.empty()) {\n+        held_locks_.erase(resource_iter);\n+      }\n+    }\n+  }\n+}\n+\n+/**\n+ * Web Locks algorithm implementation\n+ * https://w3c.github.io/web-locks/#algorithms\n+ */\n+void LockManager::ProcessQueue(Environment* env) {\n+  Isolate* isolate = env->isolate();\n+  HandleScope handle_scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  // Remove locks that were stolen from this Environment first\n+  CleanupStolenLocks(env);\n+\n+  while (true) {\n+    std::unique_ptr<LockRequest> grantable_request;\n+    std::unique_ptr<LockRequest> if_available_request;\n+    std::unordered_set<Environment*> other_envs_to_wake;\n+\n+    {\n+      std::unordered_map<std::u16string, LockRequest*> first_seen_for_resource;\n+\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      for (auto queue_iter = pending_queue_.begin();\n+           queue_iter != pending_queue_.end();\n+           ++queue_iter) {\n+        LockRequest* request = queue_iter->get();\n+\n+        // Collect unique environments to wake up later\n+        if (request->env() != env) {\n+          other_envs_to_wake.insert(request->env());\n+          continue;\n+        }\n+\n+        // During a single pass, the first time we see a resource name is the\n+        // earliest pending request\n+        auto& first_for_resource = first_seen_for_resource[request->name()];\n+        if (first_for_resource == nullptr) {\n+          first_for_resource = request;  // Mark as first seen for this resource\n+        }\n+\n+        bool has_earlier_request_for_same_resource =\n+            (first_for_resource != request);\n+\n+        if (has_earlier_request_for_same_resource || !IsGrantable(request)) {\n+          if (request->if_available()) {\n+            // ifAvailable request when resource not available: grant with null\n+            if_available_request = std::move(*queue_iter);\n+            pending_queue_.erase(queue_iter);\n+            break;\n+          }\n+          continue;\n+        }\n+\n+        // Found a request that can be granted normally\n+        grantable_request = std::move(*queue_iter);\n+        pending_queue_.erase(queue_iter);\n+        break;\n+      }\n+    }\n+\n+    // Wake each environment only once\n+    for (Environment* target_env : other_envs_to_wake) {\n+      WakeEnvironment(target_env);\n+    }\n+\n+    /**\n+     * ifAvailable:\n+     *  Grant the lock only if it is immediately available;\n+     *  otherwise invoke the callback with null and resolve the promises.\n+     *  Check wrapCallback function in locks.js\n+     */\n+    if (if_available_request) {\n+      Local<Value> null_arg = Null(isolate);\n+      Local<Value> callback_result;\n+      {\n+        TryCatchScope try_catch_scope(env);\n+        if (!if_available_request->callback()\n+                 ->Call(context, Undefined(isolate), 1, &null_arg)\n+                 .ToLocal(&callback_result)) {\n+          if_available_request->waiting_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          if_available_request->released_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          return;\n+        }\n+      }\n+      if_available_request->waiting_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      if_available_request->released_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      return;\n+    }\n+\n+    if (!grantable_request) return;\n+\n+    // Handle steal operations with minimal mutex scope\n+    if (grantable_request->steal()) {\n+      std::unordered_set<Environment*> envs_to_notify;\n+\n+      {\n+        Mutex::ScopedLock scoped_lock(mutex_);\n+        auto held_locks_iter = held_locks_.find(grantable_request->name());\n+        if (held_locks_iter != held_locks_.end()) {\n+          // Mark existing locks as stolen and collect environments to notify\n+          for (auto& existing_lock : held_locks_iter->second) {\n+            existing_lock->mark_stolen();\n+            envs_to_notify.insert(existing_lock->env());\n+\n+            // Immediately reject the stolen lock's released_promise\n+            Local<String> error_string;\n+            if (!String::NewFromUtf8(isolate, kLockStolenError)\n+                     .ToLocal(&error_string)) {\n+              return;\n+            }\n+            Local<Value> error = Exception::Error(error_string);\n+            existing_lock->released_promise()->Reject(context, error).Check();\n+          }\n+\n+          // Remove stolen locks from current environment immediately\n+          for (auto lock_iter = held_locks_iter->second.begin();\n+               lock_iter != held_locks_iter->second.end();) {\n+            if ((*lock_iter)->env() == env) {\n+              lock_iter = held_locks_iter->second.erase(lock_iter);\n+            } else {\n+              ++lock_iter;\n+            }\n+          }\n+\n+          if (held_locks_iter->second.empty()) {\n+            held_locks_.erase(held_locks_iter);\n+          }\n+        }\n+      }\n+\n+      // Wake other environments\n+      for (Environment* target_env : envs_to_notify) {\n+        if (target_env != env) {\n+          WakeEnvironment(target_env);\n+        }\n+      }\n+    }\n+\n+    // Create and store the new granted lock\n+    auto granted_lock =\n+        std::make_shared<Lock>(env,\n+                               grantable_request->name(),\n+                               grantable_request->mode(),\n+                               grantable_request->client_id(),\n+                               grantable_request->waiting_promise(),\n+                               grantable_request->released_promise());\n+    {\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      held_locks_[grantable_request->name()].push_back(granted_lock);\n+    }\n+\n+    // Call user callback\n+    Local<Object> lock_info_obj =\n+        CreateLockInfoObject(isolate,\n+                             context,\n+                             grantable_request->name(),\n+                             grantable_request->mode(),\n+                             grantable_request->client_id());\n+    if (lock_info_obj.IsEmpty()) {\n+      return;\n+    }\n+    Local<Value> callback_arg = lock_info_obj;\n+    Local<Value> callback_result;\n+    {\n+      TryCatchScope try_catch_scope(env);\n+      if (!grantable_request->callback()\n+               ->Call(context, Undefined(isolate), 1, &callback_arg)\n+               .ToLocal(&callback_result)) {\n+        grantable_request->waiting_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        return;\n+      }\n+    }\n+\n+    // Allocate a LockHolder on the heap to safely manage the lock's lifetime\n+    // until the user's callback promise settles.\n+    auto* fulfill_holder = new LockHolder(granted_lock);\n+    auto* reject_holder = new LockHolder(granted_lock);\n+    Local<Function> on_fulfilled_callback;\n+    Local<Function> on_rejected_callback;\n+\n+    if (!Function::New(context,\n+                       OnLockCallbackFulfilled,\n+                       External::New(isolate, fulfill_holder))\n+             .ToLocal(&on_fulfilled_callback) ||\n+        !Function::New(context,\n+                       OnLockCallbackRejected,\n+                       External::New(isolate, reject_holder))\n+             .ToLocal(&on_rejected_callback)) {\n+      delete fulfill_holder;\n+      delete reject_holder;",
        "comment_created_at": "2025-06-24T04:17:12+00:00",
        "comment_author": "jasnell",
        "comment_body": "These might need to be handled separately. If the first call succeeds, then the first created function will take ownership over the `fulfill_holder`. If the second call then fails for whatever reason, we are deleting the `fulfill_holder` while it's external is still holding the reference to it that it assumes it owns. It would be best to separate this into two separate calls rather than aggregating them together like this. Create one, create it's external and it's function, then create the second...\r\n\r\nOr, can we at least be certain that we won't end up with a free-after-free type error when deleting these while the External is still holding them?",
        "pr_file_module": null
      },
      {
        "comment_id": "2167766192",
        "repo_full_name": "nodejs/node",
        "pr_number": 58666,
        "pr_file": "src/node_locks.cc",
        "discussion_id": "2162924854",
        "commented_code": "@@ -0,0 +1,738 @@\n+#include \"node_locks.h\"\n+\n+#include \"env-inl.h\"\n+#include \"node_errors.h\"\n+#include \"node_external_reference.h\"\n+#include \"node_internals.h\"\n+#include \"util-inl.h\"\n+#include \"v8.h\"\n+\n+namespace node::worker::locks {\n+\n+using node::errors::TryCatchScope;\n+using v8::Array;\n+using v8::Context;\n+using v8::Exception;\n+using v8::External;\n+using v8::Function;\n+using v8::FunctionCallbackInfo;\n+using v8::HandleScope;\n+using v8::Isolate;\n+using v8::Local;\n+using v8::Object;\n+using v8::ObjectTemplate;\n+using v8::Promise;\n+using v8::String;\n+using v8::Value;\n+\n+static constexpr const char* kSharedMode = \"shared\";\n+static constexpr const char* kExclusiveMode = \"exclusive\";\n+static constexpr const char* kLockStolenError = \"LOCK_STOLEN\";\n+\n+static Local<Object> CreateLockInfoObject(Isolate* isolate,\n+                                          Local<Context> context,\n+                                          const std::u16string& name,\n+                                          Lock::Mode mode,\n+                                          const std::string& client_id);\n+\n+Lock::Lock(Environment* env,\n+           const std::u16string& name,\n+           Mode mode,\n+           const std::string& client_id,\n+           Local<Promise::Resolver> waiting,\n+           Local<Promise::Resolver> released)\n+    : env_(env), name_(name), mode_(mode), client_id_(client_id) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+}\n+\n+LockRequest::LockRequest(Environment* env,\n+                         Local<Promise::Resolver> waiting,\n+                         Local<Promise::Resolver> released,\n+                         Local<Function> callback,\n+                         const std::u16string& name,\n+                         Lock::Mode mode,\n+                         const std::string& client_id,\n+                         bool steal,\n+                         bool if_available)\n+    : env_(env),\n+      name_(name),\n+      mode_(mode),\n+      client_id_(client_id),\n+      steal_(steal),\n+      if_available_(if_available) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+  callback_.Reset(env_->isolate(), callback);\n+}\n+\n+bool LockManager::IsGrantable(const LockRequest* request) const {\n+  // Steal requests bypass all normal granting rules\n+  if (request->steal()) return true;\n+\n+  auto held_locks_iter = held_locks_.find(request->name());\n+  // No existing locks for this resource name\n+  if (held_locks_iter == held_locks_.end()) return true;\n+\n+  // Exclusive requests cannot coexist with any existing locks\n+  if (request->mode() == Lock::Mode::Exclusive) return false;\n+\n+  // For shared requests, check if any existing lock is exclusive\n+  for (const auto& existing_lock : held_locks_iter->second) {\n+    if (existing_lock->mode() == Lock::Mode::Exclusive) return false;\n+  }\n+  // All existing locks are shared, so this shared request can be granted\n+  return true;\n+}\n+\n+// Called when the user callback promise fulfills\n+static void OnLockCallbackFulfilled(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  // Extract the LockHolder from V8 External data\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  // Release the lock and continue processing the queue.\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], false);\n+}\n+\n+// Called when the user callback promise rejects\n+static void OnLockCallbackRejected(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], true);\n+}\n+\n+void LockManager::CleanupStolenLocks(Environment* env) {\n+  std::vector<std::u16string> resources_to_clean;\n+\n+  // Collect resources to clean\n+  {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    for (auto resource_iter = held_locks_.begin();\n+         resource_iter != held_locks_.end();\n+         ++resource_iter) {\n+      auto& resource_locks = resource_iter->second;\n+      bool has_stolen_from_other_env = false;\n+\n+      // Check if this resource has stolen locks from other environments\n+      for (const auto& lock_ptr : resource_locks) {\n+        if (lock_ptr->is_stolen() && lock_ptr->env() != env) {\n+          has_stolen_from_other_env = true;\n+          break;\n+        }\n+      }\n+\n+      if (has_stolen_from_other_env) {\n+        resources_to_clean.push_back(resource_iter->first);\n+      }\n+    }\n+  }\n+\n+  // Clean up resources\n+  for (const auto& resource_name : resources_to_clean) {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    auto resource_iter = held_locks_.find(resource_name);\n+    if (resource_iter != held_locks_.end()) {\n+      auto& resource_locks = resource_iter->second;\n+\n+      // Remove stolen locks from other environments\n+      for (auto lock_iter = resource_locks.begin();\n+           lock_iter != resource_locks.end();) {\n+        if ((*lock_iter)->is_stolen() && (*lock_iter)->env() != env) {\n+          lock_iter = resource_locks.erase(lock_iter);\n+        } else {\n+          ++lock_iter;\n+        }\n+      }\n+\n+      if (resource_locks.empty()) {\n+        held_locks_.erase(resource_iter);\n+      }\n+    }\n+  }\n+}\n+\n+/**\n+ * Web Locks algorithm implementation\n+ * https://w3c.github.io/web-locks/#algorithms\n+ */\n+void LockManager::ProcessQueue(Environment* env) {\n+  Isolate* isolate = env->isolate();\n+  HandleScope handle_scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  // Remove locks that were stolen from this Environment first\n+  CleanupStolenLocks(env);\n+\n+  while (true) {\n+    std::unique_ptr<LockRequest> grantable_request;\n+    std::unique_ptr<LockRequest> if_available_request;\n+    std::unordered_set<Environment*> other_envs_to_wake;\n+\n+    {\n+      std::unordered_map<std::u16string, LockRequest*> first_seen_for_resource;\n+\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      for (auto queue_iter = pending_queue_.begin();\n+           queue_iter != pending_queue_.end();\n+           ++queue_iter) {\n+        LockRequest* request = queue_iter->get();\n+\n+        // Collect unique environments to wake up later\n+        if (request->env() != env) {\n+          other_envs_to_wake.insert(request->env());\n+          continue;\n+        }\n+\n+        // During a single pass, the first time we see a resource name is the\n+        // earliest pending request\n+        auto& first_for_resource = first_seen_for_resource[request->name()];\n+        if (first_for_resource == nullptr) {\n+          first_for_resource = request;  // Mark as first seen for this resource\n+        }\n+\n+        bool has_earlier_request_for_same_resource =\n+            (first_for_resource != request);\n+\n+        if (has_earlier_request_for_same_resource || !IsGrantable(request)) {\n+          if (request->if_available()) {\n+            // ifAvailable request when resource not available: grant with null\n+            if_available_request = std::move(*queue_iter);\n+            pending_queue_.erase(queue_iter);\n+            break;\n+          }\n+          continue;\n+        }\n+\n+        // Found a request that can be granted normally\n+        grantable_request = std::move(*queue_iter);\n+        pending_queue_.erase(queue_iter);\n+        break;\n+      }\n+    }\n+\n+    // Wake each environment only once\n+    for (Environment* target_env : other_envs_to_wake) {\n+      WakeEnvironment(target_env);\n+    }\n+\n+    /**\n+     * ifAvailable:\n+     *  Grant the lock only if it is immediately available;\n+     *  otherwise invoke the callback with null and resolve the promises.\n+     *  Check wrapCallback function in locks.js\n+     */\n+    if (if_available_request) {\n+      Local<Value> null_arg = Null(isolate);\n+      Local<Value> callback_result;\n+      {\n+        TryCatchScope try_catch_scope(env);\n+        if (!if_available_request->callback()\n+                 ->Call(context, Undefined(isolate), 1, &null_arg)\n+                 .ToLocal(&callback_result)) {\n+          if_available_request->waiting_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          if_available_request->released_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          return;\n+        }\n+      }\n+      if_available_request->waiting_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      if_available_request->released_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      return;\n+    }\n+\n+    if (!grantable_request) return;\n+\n+    // Handle steal operations with minimal mutex scope\n+    if (grantable_request->steal()) {\n+      std::unordered_set<Environment*> envs_to_notify;\n+\n+      {\n+        Mutex::ScopedLock scoped_lock(mutex_);\n+        auto held_locks_iter = held_locks_.find(grantable_request->name());\n+        if (held_locks_iter != held_locks_.end()) {\n+          // Mark existing locks as stolen and collect environments to notify\n+          for (auto& existing_lock : held_locks_iter->second) {\n+            existing_lock->mark_stolen();\n+            envs_to_notify.insert(existing_lock->env());\n+\n+            // Immediately reject the stolen lock's released_promise\n+            Local<String> error_string;\n+            if (!String::NewFromUtf8(isolate, kLockStolenError)\n+                     .ToLocal(&error_string)) {\n+              return;\n+            }\n+            Local<Value> error = Exception::Error(error_string);\n+            existing_lock->released_promise()->Reject(context, error).Check();\n+          }\n+\n+          // Remove stolen locks from current environment immediately\n+          for (auto lock_iter = held_locks_iter->second.begin();\n+               lock_iter != held_locks_iter->second.end();) {\n+            if ((*lock_iter)->env() == env) {\n+              lock_iter = held_locks_iter->second.erase(lock_iter);\n+            } else {\n+              ++lock_iter;\n+            }\n+          }\n+\n+          if (held_locks_iter->second.empty()) {\n+            held_locks_.erase(held_locks_iter);\n+          }\n+        }\n+      }\n+\n+      // Wake other environments\n+      for (Environment* target_env : envs_to_notify) {\n+        if (target_env != env) {\n+          WakeEnvironment(target_env);\n+        }\n+      }\n+    }\n+\n+    // Create and store the new granted lock\n+    auto granted_lock =\n+        std::make_shared<Lock>(env,\n+                               grantable_request->name(),\n+                               grantable_request->mode(),\n+                               grantable_request->client_id(),\n+                               grantable_request->waiting_promise(),\n+                               grantable_request->released_promise());\n+    {\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      held_locks_[grantable_request->name()].push_back(granted_lock);\n+    }\n+\n+    // Call user callback\n+    Local<Object> lock_info_obj =\n+        CreateLockInfoObject(isolate,\n+                             context,\n+                             grantable_request->name(),\n+                             grantable_request->mode(),\n+                             grantable_request->client_id());\n+    if (lock_info_obj.IsEmpty()) {\n+      return;\n+    }\n+    Local<Value> callback_arg = lock_info_obj;\n+    Local<Value> callback_result;\n+    {\n+      TryCatchScope try_catch_scope(env);\n+      if (!grantable_request->callback()\n+               ->Call(context, Undefined(isolate), 1, &callback_arg)\n+               .ToLocal(&callback_result)) {\n+        grantable_request->waiting_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        return;\n+      }\n+    }\n+\n+    // Allocate a LockHolder on the heap to safely manage the lock's lifetime\n+    // until the user's callback promise settles.\n+    auto* fulfill_holder = new LockHolder(granted_lock);\n+    auto* reject_holder = new LockHolder(granted_lock);\n+    Local<Function> on_fulfilled_callback;\n+    Local<Function> on_rejected_callback;\n+\n+    if (!Function::New(context,\n+                       OnLockCallbackFulfilled,\n+                       External::New(isolate, fulfill_holder))\n+             .ToLocal(&on_fulfilled_callback) ||\n+        !Function::New(context,\n+                       OnLockCallbackRejected,\n+                       External::New(isolate, reject_holder))\n+             .ToLocal(&on_rejected_callback)) {\n+      delete fulfill_holder;\n+      delete reject_holder;",
        "comment_created_at": "2025-06-25T22:44:08+00:00",
        "comment_author": "IlyasShabi",
        "comment_body": "IIUC we could have an issue if the first `Function::New(`) succeeds but the second fails, since the first External would own `fulfill_holder` but we'd still try to delete it.\r\nI addressed this in my last commit.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2162926925",
    "pr_number": 58666,
    "pr_file": "src/node_locks.cc",
    "created_at": "2025-06-24T04:19:18+00:00",
    "commented_code": "+#include \"node_locks.h\"\n+\n+#include \"env-inl.h\"\n+#include \"node_errors.h\"\n+#include \"node_external_reference.h\"\n+#include \"node_internals.h\"\n+#include \"util-inl.h\"\n+#include \"v8.h\"\n+\n+namespace node::worker::locks {\n+\n+using node::errors::TryCatchScope;\n+using v8::Array;\n+using v8::Context;\n+using v8::Exception;\n+using v8::External;\n+using v8::Function;\n+using v8::FunctionCallbackInfo;\n+using v8::HandleScope;\n+using v8::Isolate;\n+using v8::Local;\n+using v8::Object;\n+using v8::ObjectTemplate;\n+using v8::Promise;\n+using v8::String;\n+using v8::Value;\n+\n+static constexpr const char* kSharedMode = \"shared\";\n+static constexpr const char* kExclusiveMode = \"exclusive\";\n+static constexpr const char* kLockStolenError = \"LOCK_STOLEN\";\n+\n+static Local<Object> CreateLockInfoObject(Isolate* isolate,\n+                                          Local<Context> context,\n+                                          const std::u16string& name,\n+                                          Lock::Mode mode,\n+                                          const std::string& client_id);\n+\n+Lock::Lock(Environment* env,\n+           const std::u16string& name,\n+           Mode mode,\n+           const std::string& client_id,\n+           Local<Promise::Resolver> waiting,\n+           Local<Promise::Resolver> released)\n+    : env_(env), name_(name), mode_(mode), client_id_(client_id) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+}\n+\n+LockRequest::LockRequest(Environment* env,\n+                         Local<Promise::Resolver> waiting,\n+                         Local<Promise::Resolver> released,\n+                         Local<Function> callback,\n+                         const std::u16string& name,\n+                         Lock::Mode mode,\n+                         const std::string& client_id,\n+                         bool steal,\n+                         bool if_available)\n+    : env_(env),\n+      name_(name),\n+      mode_(mode),\n+      client_id_(client_id),\n+      steal_(steal),\n+      if_available_(if_available) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+  callback_.Reset(env_->isolate(), callback);\n+}\n+\n+bool LockManager::IsGrantable(const LockRequest* request) const {\n+  // Steal requests bypass all normal granting rules\n+  if (request->steal()) return true;\n+\n+  auto held_locks_iter = held_locks_.find(request->name());\n+  // No existing locks for this resource name\n+  if (held_locks_iter == held_locks_.end()) return true;\n+\n+  // Exclusive requests cannot coexist with any existing locks\n+  if (request->mode() == Lock::Mode::Exclusive) return false;\n+\n+  // For shared requests, check if any existing lock is exclusive\n+  for (const auto& existing_lock : held_locks_iter->second) {\n+    if (existing_lock->mode() == Lock::Mode::Exclusive) return false;\n+  }\n+  // All existing locks are shared, so this shared request can be granted\n+  return true;\n+}\n+\n+// Called when the user callback promise fulfills\n+static void OnLockCallbackFulfilled(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  // Extract the LockHolder from V8 External data\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  // Release the lock and continue processing the queue.\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], false);\n+}\n+\n+// Called when the user callback promise rejects\n+static void OnLockCallbackRejected(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], true);\n+}\n+\n+void LockManager::CleanupStolenLocks(Environment* env) {\n+  std::vector<std::u16string> resources_to_clean;\n+\n+  // Collect resources to clean\n+  {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    for (auto resource_iter = held_locks_.begin();\n+         resource_iter != held_locks_.end();\n+         ++resource_iter) {\n+      auto& resource_locks = resource_iter->second;\n+      bool has_stolen_from_other_env = false;\n+\n+      // Check if this resource has stolen locks from other environments\n+      for (const auto& lock_ptr : resource_locks) {\n+        if (lock_ptr->is_stolen() && lock_ptr->env() != env) {\n+          has_stolen_from_other_env = true;\n+          break;\n+        }\n+      }\n+\n+      if (has_stolen_from_other_env) {\n+        resources_to_clean.push_back(resource_iter->first);\n+      }\n+    }\n+  }\n+\n+  // Clean up resources\n+  for (const auto& resource_name : resources_to_clean) {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    auto resource_iter = held_locks_.find(resource_name);\n+    if (resource_iter != held_locks_.end()) {\n+      auto& resource_locks = resource_iter->second;\n+\n+      // Remove stolen locks from other environments\n+      for (auto lock_iter = resource_locks.begin();\n+           lock_iter != resource_locks.end();) {\n+        if ((*lock_iter)->is_stolen() && (*lock_iter)->env() != env) {\n+          lock_iter = resource_locks.erase(lock_iter);\n+        } else {\n+          ++lock_iter;\n+        }\n+      }\n+\n+      if (resource_locks.empty()) {\n+        held_locks_.erase(resource_iter);\n+      }\n+    }\n+  }\n+}\n+\n+/**\n+ * Web Locks algorithm implementation\n+ * https://w3c.github.io/web-locks/#algorithms\n+ */\n+void LockManager::ProcessQueue(Environment* env) {\n+  Isolate* isolate = env->isolate();\n+  HandleScope handle_scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  // Remove locks that were stolen from this Environment first\n+  CleanupStolenLocks(env);\n+\n+  while (true) {\n+    std::unique_ptr<LockRequest> grantable_request;\n+    std::unique_ptr<LockRequest> if_available_request;\n+    std::unordered_set<Environment*> other_envs_to_wake;\n+\n+    {\n+      std::unordered_map<std::u16string, LockRequest*> first_seen_for_resource;\n+\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      for (auto queue_iter = pending_queue_.begin();\n+           queue_iter != pending_queue_.end();\n+           ++queue_iter) {\n+        LockRequest* request = queue_iter->get();\n+\n+        // Collect unique environments to wake up later\n+        if (request->env() != env) {\n+          other_envs_to_wake.insert(request->env());\n+          continue;\n+        }\n+\n+        // During a single pass, the first time we see a resource name is the\n+        // earliest pending request\n+        auto& first_for_resource = first_seen_for_resource[request->name()];\n+        if (first_for_resource == nullptr) {\n+          first_for_resource = request;  // Mark as first seen for this resource\n+        }\n+\n+        bool has_earlier_request_for_same_resource =\n+            (first_for_resource != request);\n+\n+        if (has_earlier_request_for_same_resource || !IsGrantable(request)) {\n+          if (request->if_available()) {\n+            // ifAvailable request when resource not available: grant with null\n+            if_available_request = std::move(*queue_iter);\n+            pending_queue_.erase(queue_iter);\n+            break;\n+          }\n+          continue;\n+        }\n+\n+        // Found a request that can be granted normally\n+        grantable_request = std::move(*queue_iter);\n+        pending_queue_.erase(queue_iter);\n+        break;\n+      }\n+    }\n+\n+    // Wake each environment only once\n+    for (Environment* target_env : other_envs_to_wake) {\n+      WakeEnvironment(target_env);\n+    }\n+\n+    /**\n+     * ifAvailable:\n+     *  Grant the lock only if it is immediately available;\n+     *  otherwise invoke the callback with null and resolve the promises.\n+     *  Check wrapCallback function in locks.js\n+     */\n+    if (if_available_request) {\n+      Local<Value> null_arg = Null(isolate);\n+      Local<Value> callback_result;\n+      {\n+        TryCatchScope try_catch_scope(env);\n+        if (!if_available_request->callback()\n+                 ->Call(context, Undefined(isolate), 1, &null_arg)\n+                 .ToLocal(&callback_result)) {\n+          if_available_request->waiting_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          if_available_request->released_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          return;\n+        }\n+      }\n+      if_available_request->waiting_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      if_available_request->released_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      return;\n+    }\n+\n+    if (!grantable_request) return;\n+\n+    // Handle steal operations with minimal mutex scope\n+    if (grantable_request->steal()) {\n+      std::unordered_set<Environment*> envs_to_notify;\n+\n+      {\n+        Mutex::ScopedLock scoped_lock(mutex_);\n+        auto held_locks_iter = held_locks_.find(grantable_request->name());\n+        if (held_locks_iter != held_locks_.end()) {\n+          // Mark existing locks as stolen and collect environments to notify\n+          for (auto& existing_lock : held_locks_iter->second) {\n+            existing_lock->mark_stolen();\n+            envs_to_notify.insert(existing_lock->env());\n+\n+            // Immediately reject the stolen lock's released_promise\n+            Local<String> error_string;\n+            if (!String::NewFromUtf8(isolate, kLockStolenError)\n+                     .ToLocal(&error_string)) {\n+              return;\n+            }\n+            Local<Value> error = Exception::Error(error_string);\n+            existing_lock->released_promise()->Reject(context, error).Check();\n+          }\n+\n+          // Remove stolen locks from current environment immediately\n+          for (auto lock_iter = held_locks_iter->second.begin();\n+               lock_iter != held_locks_iter->second.end();) {\n+            if ((*lock_iter)->env() == env) {\n+              lock_iter = held_locks_iter->second.erase(lock_iter);\n+            } else {\n+              ++lock_iter;\n+            }\n+          }\n+\n+          if (held_locks_iter->second.empty()) {\n+            held_locks_.erase(held_locks_iter);\n+          }\n+        }\n+      }\n+\n+      // Wake other environments\n+      for (Environment* target_env : envs_to_notify) {\n+        if (target_env != env) {\n+          WakeEnvironment(target_env);\n+        }\n+      }\n+    }\n+\n+    // Create and store the new granted lock\n+    auto granted_lock =\n+        std::make_shared<Lock>(env,\n+                               grantable_request->name(),\n+                               grantable_request->mode(),\n+                               grantable_request->client_id(),\n+                               grantable_request->waiting_promise(),\n+                               grantable_request->released_promise());\n+    {\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      held_locks_[grantable_request->name()].push_back(granted_lock);\n+    }\n+\n+    // Call user callback\n+    Local<Object> lock_info_obj =\n+        CreateLockInfoObject(isolate,\n+                             context,\n+                             grantable_request->name(),\n+                             grantable_request->mode(),\n+                             grantable_request->client_id());\n+    if (lock_info_obj.IsEmpty()) {\n+      return;\n+    }\n+    Local<Value> callback_arg = lock_info_obj;\n+    Local<Value> callback_result;\n+    {\n+      TryCatchScope try_catch_scope(env);\n+      if (!grantable_request->callback()\n+               ->Call(context, Undefined(isolate), 1, &callback_arg)\n+               .ToLocal(&callback_result)) {\n+        grantable_request->waiting_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        return;\n+      }\n+    }\n+\n+    // Allocate a LockHolder on the heap to safely manage the lock's lifetime\n+    // until the user's callback promise settles.\n+    auto* fulfill_holder = new LockHolder(granted_lock);\n+    auto* reject_holder = new LockHolder(granted_lock);\n+    Local<Function> on_fulfilled_callback;\n+    Local<Function> on_rejected_callback;\n+\n+    if (!Function::New(context,\n+                       OnLockCallbackFulfilled,\n+                       External::New(isolate, fulfill_holder))\n+             .ToLocal(&on_fulfilled_callback) ||\n+        !Function::New(context,\n+                       OnLockCallbackRejected,\n+                       External::New(isolate, reject_holder))\n+             .ToLocal(&on_rejected_callback)) {\n+      delete fulfill_holder;\n+      delete reject_holder;\n+      return;\n+    }\n+\n+    // Handle promise chain\n+    if (callback_result->IsPromise()) {\n+      Local<Promise> promise = callback_result.As<Promise>();\n+      if (promise->State() == Promise::kRejected) {\n+        Local<Value> rejection_value = promise->Result();\n+        grantable_request->waiting_promise()\n+            ->Reject(context, rejection_value)\n+            .Check();",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2162926925",
        "repo_full_name": "nodejs/node",
        "pr_number": 58666,
        "pr_file": "src/node_locks.cc",
        "discussion_id": "2162926925",
        "commented_code": "@@ -0,0 +1,738 @@\n+#include \"node_locks.h\"\n+\n+#include \"env-inl.h\"\n+#include \"node_errors.h\"\n+#include \"node_external_reference.h\"\n+#include \"node_internals.h\"\n+#include \"util-inl.h\"\n+#include \"v8.h\"\n+\n+namespace node::worker::locks {\n+\n+using node::errors::TryCatchScope;\n+using v8::Array;\n+using v8::Context;\n+using v8::Exception;\n+using v8::External;\n+using v8::Function;\n+using v8::FunctionCallbackInfo;\n+using v8::HandleScope;\n+using v8::Isolate;\n+using v8::Local;\n+using v8::Object;\n+using v8::ObjectTemplate;\n+using v8::Promise;\n+using v8::String;\n+using v8::Value;\n+\n+static constexpr const char* kSharedMode = \"shared\";\n+static constexpr const char* kExclusiveMode = \"exclusive\";\n+static constexpr const char* kLockStolenError = \"LOCK_STOLEN\";\n+\n+static Local<Object> CreateLockInfoObject(Isolate* isolate,\n+                                          Local<Context> context,\n+                                          const std::u16string& name,\n+                                          Lock::Mode mode,\n+                                          const std::string& client_id);\n+\n+Lock::Lock(Environment* env,\n+           const std::u16string& name,\n+           Mode mode,\n+           const std::string& client_id,\n+           Local<Promise::Resolver> waiting,\n+           Local<Promise::Resolver> released)\n+    : env_(env), name_(name), mode_(mode), client_id_(client_id) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+}\n+\n+LockRequest::LockRequest(Environment* env,\n+                         Local<Promise::Resolver> waiting,\n+                         Local<Promise::Resolver> released,\n+                         Local<Function> callback,\n+                         const std::u16string& name,\n+                         Lock::Mode mode,\n+                         const std::string& client_id,\n+                         bool steal,\n+                         bool if_available)\n+    : env_(env),\n+      name_(name),\n+      mode_(mode),\n+      client_id_(client_id),\n+      steal_(steal),\n+      if_available_(if_available) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+  callback_.Reset(env_->isolate(), callback);\n+}\n+\n+bool LockManager::IsGrantable(const LockRequest* request) const {\n+  // Steal requests bypass all normal granting rules\n+  if (request->steal()) return true;\n+\n+  auto held_locks_iter = held_locks_.find(request->name());\n+  // No existing locks for this resource name\n+  if (held_locks_iter == held_locks_.end()) return true;\n+\n+  // Exclusive requests cannot coexist with any existing locks\n+  if (request->mode() == Lock::Mode::Exclusive) return false;\n+\n+  // For shared requests, check if any existing lock is exclusive\n+  for (const auto& existing_lock : held_locks_iter->second) {\n+    if (existing_lock->mode() == Lock::Mode::Exclusive) return false;\n+  }\n+  // All existing locks are shared, so this shared request can be granted\n+  return true;\n+}\n+\n+// Called when the user callback promise fulfills\n+static void OnLockCallbackFulfilled(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  // Extract the LockHolder from V8 External data\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  // Release the lock and continue processing the queue.\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], false);\n+}\n+\n+// Called when the user callback promise rejects\n+static void OnLockCallbackRejected(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], true);\n+}\n+\n+void LockManager::CleanupStolenLocks(Environment* env) {\n+  std::vector<std::u16string> resources_to_clean;\n+\n+  // Collect resources to clean\n+  {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    for (auto resource_iter = held_locks_.begin();\n+         resource_iter != held_locks_.end();\n+         ++resource_iter) {\n+      auto& resource_locks = resource_iter->second;\n+      bool has_stolen_from_other_env = false;\n+\n+      // Check if this resource has stolen locks from other environments\n+      for (const auto& lock_ptr : resource_locks) {\n+        if (lock_ptr->is_stolen() && lock_ptr->env() != env) {\n+          has_stolen_from_other_env = true;\n+          break;\n+        }\n+      }\n+\n+      if (has_stolen_from_other_env) {\n+        resources_to_clean.push_back(resource_iter->first);\n+      }\n+    }\n+  }\n+\n+  // Clean up resources\n+  for (const auto& resource_name : resources_to_clean) {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    auto resource_iter = held_locks_.find(resource_name);\n+    if (resource_iter != held_locks_.end()) {\n+      auto& resource_locks = resource_iter->second;\n+\n+      // Remove stolen locks from other environments\n+      for (auto lock_iter = resource_locks.begin();\n+           lock_iter != resource_locks.end();) {\n+        if ((*lock_iter)->is_stolen() && (*lock_iter)->env() != env) {\n+          lock_iter = resource_locks.erase(lock_iter);\n+        } else {\n+          ++lock_iter;\n+        }\n+      }\n+\n+      if (resource_locks.empty()) {\n+        held_locks_.erase(resource_iter);\n+      }\n+    }\n+  }\n+}\n+\n+/**\n+ * Web Locks algorithm implementation\n+ * https://w3c.github.io/web-locks/#algorithms\n+ */\n+void LockManager::ProcessQueue(Environment* env) {\n+  Isolate* isolate = env->isolate();\n+  HandleScope handle_scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  // Remove locks that were stolen from this Environment first\n+  CleanupStolenLocks(env);\n+\n+  while (true) {\n+    std::unique_ptr<LockRequest> grantable_request;\n+    std::unique_ptr<LockRequest> if_available_request;\n+    std::unordered_set<Environment*> other_envs_to_wake;\n+\n+    {\n+      std::unordered_map<std::u16string, LockRequest*> first_seen_for_resource;\n+\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      for (auto queue_iter = pending_queue_.begin();\n+           queue_iter != pending_queue_.end();\n+           ++queue_iter) {\n+        LockRequest* request = queue_iter->get();\n+\n+        // Collect unique environments to wake up later\n+        if (request->env() != env) {\n+          other_envs_to_wake.insert(request->env());\n+          continue;\n+        }\n+\n+        // During a single pass, the first time we see a resource name is the\n+        // earliest pending request\n+        auto& first_for_resource = first_seen_for_resource[request->name()];\n+        if (first_for_resource == nullptr) {\n+          first_for_resource = request;  // Mark as first seen for this resource\n+        }\n+\n+        bool has_earlier_request_for_same_resource =\n+            (first_for_resource != request);\n+\n+        if (has_earlier_request_for_same_resource || !IsGrantable(request)) {\n+          if (request->if_available()) {\n+            // ifAvailable request when resource not available: grant with null\n+            if_available_request = std::move(*queue_iter);\n+            pending_queue_.erase(queue_iter);\n+            break;\n+          }\n+          continue;\n+        }\n+\n+        // Found a request that can be granted normally\n+        grantable_request = std::move(*queue_iter);\n+        pending_queue_.erase(queue_iter);\n+        break;\n+      }\n+    }\n+\n+    // Wake each environment only once\n+    for (Environment* target_env : other_envs_to_wake) {\n+      WakeEnvironment(target_env);\n+    }\n+\n+    /**\n+     * ifAvailable:\n+     *  Grant the lock only if it is immediately available;\n+     *  otherwise invoke the callback with null and resolve the promises.\n+     *  Check wrapCallback function in locks.js\n+     */\n+    if (if_available_request) {\n+      Local<Value> null_arg = Null(isolate);\n+      Local<Value> callback_result;\n+      {\n+        TryCatchScope try_catch_scope(env);\n+        if (!if_available_request->callback()\n+                 ->Call(context, Undefined(isolate), 1, &null_arg)\n+                 .ToLocal(&callback_result)) {\n+          if_available_request->waiting_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          if_available_request->released_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          return;\n+        }\n+      }\n+      if_available_request->waiting_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      if_available_request->released_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      return;\n+    }\n+\n+    if (!grantable_request) return;\n+\n+    // Handle steal operations with minimal mutex scope\n+    if (grantable_request->steal()) {\n+      std::unordered_set<Environment*> envs_to_notify;\n+\n+      {\n+        Mutex::ScopedLock scoped_lock(mutex_);\n+        auto held_locks_iter = held_locks_.find(grantable_request->name());\n+        if (held_locks_iter != held_locks_.end()) {\n+          // Mark existing locks as stolen and collect environments to notify\n+          for (auto& existing_lock : held_locks_iter->second) {\n+            existing_lock->mark_stolen();\n+            envs_to_notify.insert(existing_lock->env());\n+\n+            // Immediately reject the stolen lock's released_promise\n+            Local<String> error_string;\n+            if (!String::NewFromUtf8(isolate, kLockStolenError)\n+                     .ToLocal(&error_string)) {\n+              return;\n+            }\n+            Local<Value> error = Exception::Error(error_string);\n+            existing_lock->released_promise()->Reject(context, error).Check();\n+          }\n+\n+          // Remove stolen locks from current environment immediately\n+          for (auto lock_iter = held_locks_iter->second.begin();\n+               lock_iter != held_locks_iter->second.end();) {\n+            if ((*lock_iter)->env() == env) {\n+              lock_iter = held_locks_iter->second.erase(lock_iter);\n+            } else {\n+              ++lock_iter;\n+            }\n+          }\n+\n+          if (held_locks_iter->second.empty()) {\n+            held_locks_.erase(held_locks_iter);\n+          }\n+        }\n+      }\n+\n+      // Wake other environments\n+      for (Environment* target_env : envs_to_notify) {\n+        if (target_env != env) {\n+          WakeEnvironment(target_env);\n+        }\n+      }\n+    }\n+\n+    // Create and store the new granted lock\n+    auto granted_lock =\n+        std::make_shared<Lock>(env,\n+                               grantable_request->name(),\n+                               grantable_request->mode(),\n+                               grantable_request->client_id(),\n+                               grantable_request->waiting_promise(),\n+                               grantable_request->released_promise());\n+    {\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      held_locks_[grantable_request->name()].push_back(granted_lock);\n+    }\n+\n+    // Call user callback\n+    Local<Object> lock_info_obj =\n+        CreateLockInfoObject(isolate,\n+                             context,\n+                             grantable_request->name(),\n+                             grantable_request->mode(),\n+                             grantable_request->client_id());\n+    if (lock_info_obj.IsEmpty()) {\n+      return;\n+    }\n+    Local<Value> callback_arg = lock_info_obj;\n+    Local<Value> callback_result;\n+    {\n+      TryCatchScope try_catch_scope(env);\n+      if (!grantable_request->callback()\n+               ->Call(context, Undefined(isolate), 1, &callback_arg)\n+               .ToLocal(&callback_result)) {\n+        grantable_request->waiting_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        return;\n+      }\n+    }\n+\n+    // Allocate a LockHolder on the heap to safely manage the lock's lifetime\n+    // until the user's callback promise settles.\n+    auto* fulfill_holder = new LockHolder(granted_lock);\n+    auto* reject_holder = new LockHolder(granted_lock);\n+    Local<Function> on_fulfilled_callback;\n+    Local<Function> on_rejected_callback;\n+\n+    if (!Function::New(context,\n+                       OnLockCallbackFulfilled,\n+                       External::New(isolate, fulfill_holder))\n+             .ToLocal(&on_fulfilled_callback) ||\n+        !Function::New(context,\n+                       OnLockCallbackRejected,\n+                       External::New(isolate, reject_holder))\n+             .ToLocal(&on_rejected_callback)) {\n+      delete fulfill_holder;\n+      delete reject_holder;\n+      return;\n+    }\n+\n+    // Handle promise chain\n+    if (callback_result->IsPromise()) {\n+      Local<Promise> promise = callback_result.As<Promise>();\n+      if (promise->State() == Promise::kRejected) {\n+        Local<Value> rejection_value = promise->Result();\n+        grantable_request->waiting_promise()\n+            ->Reject(context, rejection_value)\n+            .Check();",
        "comment_created_at": "2025-06-24T04:19:18+00:00",
        "comment_author": "jasnell",
        "comment_body": "Not something to do here, but using `Check()` here has the same issue as using `ToLocalChecked()` in that it will just crash the process rather than propagate the error. This is a common issue throughout the code, however, so not something I would block this PR on. We need to handle these better in general. \r\n\r\nIf you did want to handle this here, then changing these to check if the return value is empty then doing some proper error propagation similar to the way the ToLocal(...) results are handled would be ideal.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2162928041",
    "pr_number": 58666,
    "pr_file": "src/node_locks.cc",
    "created_at": "2025-06-24T04:20:43+00:00",
    "commented_code": "+#include \"node_locks.h\"\n+\n+#include \"env-inl.h\"\n+#include \"node_errors.h\"\n+#include \"node_external_reference.h\"\n+#include \"node_internals.h\"\n+#include \"util-inl.h\"\n+#include \"v8.h\"\n+\n+namespace node::worker::locks {\n+\n+using node::errors::TryCatchScope;\n+using v8::Array;\n+using v8::Context;\n+using v8::Exception;\n+using v8::External;\n+using v8::Function;\n+using v8::FunctionCallbackInfo;\n+using v8::HandleScope;\n+using v8::Isolate;\n+using v8::Local;\n+using v8::Object;\n+using v8::ObjectTemplate;\n+using v8::Promise;\n+using v8::String;\n+using v8::Value;\n+\n+static constexpr const char* kSharedMode = \"shared\";\n+static constexpr const char* kExclusiveMode = \"exclusive\";\n+static constexpr const char* kLockStolenError = \"LOCK_STOLEN\";\n+\n+static Local<Object> CreateLockInfoObject(Isolate* isolate,\n+                                          Local<Context> context,\n+                                          const std::u16string& name,\n+                                          Lock::Mode mode,\n+                                          const std::string& client_id);\n+\n+Lock::Lock(Environment* env,\n+           const std::u16string& name,\n+           Mode mode,\n+           const std::string& client_id,\n+           Local<Promise::Resolver> waiting,\n+           Local<Promise::Resolver> released)\n+    : env_(env), name_(name), mode_(mode), client_id_(client_id) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+}\n+\n+LockRequest::LockRequest(Environment* env,\n+                         Local<Promise::Resolver> waiting,\n+                         Local<Promise::Resolver> released,\n+                         Local<Function> callback,\n+                         const std::u16string& name,\n+                         Lock::Mode mode,\n+                         const std::string& client_id,\n+                         bool steal,\n+                         bool if_available)\n+    : env_(env),\n+      name_(name),\n+      mode_(mode),\n+      client_id_(client_id),\n+      steal_(steal),\n+      if_available_(if_available) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+  callback_.Reset(env_->isolate(), callback);\n+}\n+\n+bool LockManager::IsGrantable(const LockRequest* request) const {\n+  // Steal requests bypass all normal granting rules\n+  if (request->steal()) return true;\n+\n+  auto held_locks_iter = held_locks_.find(request->name());\n+  // No existing locks for this resource name\n+  if (held_locks_iter == held_locks_.end()) return true;\n+\n+  // Exclusive requests cannot coexist with any existing locks\n+  if (request->mode() == Lock::Mode::Exclusive) return false;\n+\n+  // For shared requests, check if any existing lock is exclusive\n+  for (const auto& existing_lock : held_locks_iter->second) {\n+    if (existing_lock->mode() == Lock::Mode::Exclusive) return false;\n+  }\n+  // All existing locks are shared, so this shared request can be granted\n+  return true;\n+}\n+\n+// Called when the user callback promise fulfills\n+static void OnLockCallbackFulfilled(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  // Extract the LockHolder from V8 External data\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  // Release the lock and continue processing the queue.\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], false);\n+}\n+\n+// Called when the user callback promise rejects\n+static void OnLockCallbackRejected(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], true);\n+}\n+\n+void LockManager::CleanupStolenLocks(Environment* env) {\n+  std::vector<std::u16string> resources_to_clean;\n+\n+  // Collect resources to clean\n+  {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    for (auto resource_iter = held_locks_.begin();\n+         resource_iter != held_locks_.end();\n+         ++resource_iter) {\n+      auto& resource_locks = resource_iter->second;\n+      bool has_stolen_from_other_env = false;\n+\n+      // Check if this resource has stolen locks from other environments\n+      for (const auto& lock_ptr : resource_locks) {\n+        if (lock_ptr->is_stolen() && lock_ptr->env() != env) {\n+          has_stolen_from_other_env = true;\n+          break;\n+        }\n+      }\n+\n+      if (has_stolen_from_other_env) {\n+        resources_to_clean.push_back(resource_iter->first);\n+      }\n+    }\n+  }\n+\n+  // Clean up resources\n+  for (const auto& resource_name : resources_to_clean) {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    auto resource_iter = held_locks_.find(resource_name);\n+    if (resource_iter != held_locks_.end()) {\n+      auto& resource_locks = resource_iter->second;\n+\n+      // Remove stolen locks from other environments\n+      for (auto lock_iter = resource_locks.begin();\n+           lock_iter != resource_locks.end();) {\n+        if ((*lock_iter)->is_stolen() && (*lock_iter)->env() != env) {\n+          lock_iter = resource_locks.erase(lock_iter);\n+        } else {\n+          ++lock_iter;\n+        }\n+      }\n+\n+      if (resource_locks.empty()) {\n+        held_locks_.erase(resource_iter);\n+      }\n+    }\n+  }\n+}\n+\n+/**\n+ * Web Locks algorithm implementation\n+ * https://w3c.github.io/web-locks/#algorithms\n+ */\n+void LockManager::ProcessQueue(Environment* env) {\n+  Isolate* isolate = env->isolate();\n+  HandleScope handle_scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  // Remove locks that were stolen from this Environment first\n+  CleanupStolenLocks(env);\n+\n+  while (true) {\n+    std::unique_ptr<LockRequest> grantable_request;\n+    std::unique_ptr<LockRequest> if_available_request;\n+    std::unordered_set<Environment*> other_envs_to_wake;\n+\n+    {\n+      std::unordered_map<std::u16string, LockRequest*> first_seen_for_resource;\n+\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      for (auto queue_iter = pending_queue_.begin();\n+           queue_iter != pending_queue_.end();\n+           ++queue_iter) {\n+        LockRequest* request = queue_iter->get();\n+\n+        // Collect unique environments to wake up later\n+        if (request->env() != env) {\n+          other_envs_to_wake.insert(request->env());\n+          continue;\n+        }\n+\n+        // During a single pass, the first time we see a resource name is the\n+        // earliest pending request\n+        auto& first_for_resource = first_seen_for_resource[request->name()];\n+        if (first_for_resource == nullptr) {\n+          first_for_resource = request;  // Mark as first seen for this resource\n+        }\n+\n+        bool has_earlier_request_for_same_resource =\n+            (first_for_resource != request);\n+\n+        if (has_earlier_request_for_same_resource || !IsGrantable(request)) {\n+          if (request->if_available()) {\n+            // ifAvailable request when resource not available: grant with null\n+            if_available_request = std::move(*queue_iter);\n+            pending_queue_.erase(queue_iter);\n+            break;\n+          }\n+          continue;\n+        }\n+\n+        // Found a request that can be granted normally\n+        grantable_request = std::move(*queue_iter);\n+        pending_queue_.erase(queue_iter);\n+        break;\n+      }\n+    }\n+\n+    // Wake each environment only once\n+    for (Environment* target_env : other_envs_to_wake) {\n+      WakeEnvironment(target_env);\n+    }\n+\n+    /**\n+     * ifAvailable:\n+     *  Grant the lock only if it is immediately available;\n+     *  otherwise invoke the callback with null and resolve the promises.\n+     *  Check wrapCallback function in locks.js\n+     */\n+    if (if_available_request) {\n+      Local<Value> null_arg = Null(isolate);\n+      Local<Value> callback_result;\n+      {\n+        TryCatchScope try_catch_scope(env);\n+        if (!if_available_request->callback()\n+                 ->Call(context, Undefined(isolate), 1, &null_arg)\n+                 .ToLocal(&callback_result)) {\n+          if_available_request->waiting_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          if_available_request->released_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          return;\n+        }\n+      }\n+      if_available_request->waiting_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      if_available_request->released_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      return;\n+    }\n+\n+    if (!grantable_request) return;\n+\n+    // Handle steal operations with minimal mutex scope\n+    if (grantable_request->steal()) {\n+      std::unordered_set<Environment*> envs_to_notify;\n+\n+      {\n+        Mutex::ScopedLock scoped_lock(mutex_);\n+        auto held_locks_iter = held_locks_.find(grantable_request->name());\n+        if (held_locks_iter != held_locks_.end()) {\n+          // Mark existing locks as stolen and collect environments to notify\n+          for (auto& existing_lock : held_locks_iter->second) {\n+            existing_lock->mark_stolen();\n+            envs_to_notify.insert(existing_lock->env());\n+\n+            // Immediately reject the stolen lock's released_promise\n+            Local<String> error_string;\n+            if (!String::NewFromUtf8(isolate, kLockStolenError)\n+                     .ToLocal(&error_string)) {\n+              return;\n+            }\n+            Local<Value> error = Exception::Error(error_string);\n+            existing_lock->released_promise()->Reject(context, error).Check();\n+          }\n+\n+          // Remove stolen locks from current environment immediately\n+          for (auto lock_iter = held_locks_iter->second.begin();\n+               lock_iter != held_locks_iter->second.end();) {\n+            if ((*lock_iter)->env() == env) {\n+              lock_iter = held_locks_iter->second.erase(lock_iter);\n+            } else {\n+              ++lock_iter;\n+            }\n+          }\n+\n+          if (held_locks_iter->second.empty()) {\n+            held_locks_.erase(held_locks_iter);\n+          }\n+        }\n+      }\n+\n+      // Wake other environments\n+      for (Environment* target_env : envs_to_notify) {\n+        if (target_env != env) {\n+          WakeEnvironment(target_env);\n+        }\n+      }\n+    }\n+\n+    // Create and store the new granted lock\n+    auto granted_lock =\n+        std::make_shared<Lock>(env,\n+                               grantable_request->name(),\n+                               grantable_request->mode(),\n+                               grantable_request->client_id(),\n+                               grantable_request->waiting_promise(),\n+                               grantable_request->released_promise());\n+    {\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      held_locks_[grantable_request->name()].push_back(granted_lock);\n+    }\n+\n+    // Call user callback\n+    Local<Object> lock_info_obj =\n+        CreateLockInfoObject(isolate,\n+                             context,\n+                             grantable_request->name(),\n+                             grantable_request->mode(),\n+                             grantable_request->client_id());\n+    if (lock_info_obj.IsEmpty()) {\n+      return;\n+    }\n+    Local<Value> callback_arg = lock_info_obj;\n+    Local<Value> callback_result;\n+    {\n+      TryCatchScope try_catch_scope(env);\n+      if (!grantable_request->callback()\n+               ->Call(context, Undefined(isolate), 1, &callback_arg)\n+               .ToLocal(&callback_result)) {\n+        grantable_request->waiting_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        return;\n+      }\n+    }\n+\n+    // Allocate a LockHolder on the heap to safely manage the lock's lifetime\n+    // until the user's callback promise settles.\n+    auto* fulfill_holder = new LockHolder(granted_lock);\n+    auto* reject_holder = new LockHolder(granted_lock);\n+    Local<Function> on_fulfilled_callback;\n+    Local<Function> on_rejected_callback;\n+\n+    if (!Function::New(context,\n+                       OnLockCallbackFulfilled,\n+                       External::New(isolate, fulfill_holder))\n+             .ToLocal(&on_fulfilled_callback) ||\n+        !Function::New(context,\n+                       OnLockCallbackRejected,\n+                       External::New(isolate, reject_holder))\n+             .ToLocal(&on_rejected_callback)) {\n+      delete fulfill_holder;\n+      delete reject_holder;\n+      return;\n+    }\n+\n+    // Handle promise chain\n+    if (callback_result->IsPromise()) {\n+      Local<Promise> promise = callback_result.As<Promise>();\n+      if (promise->State() == Promise::kRejected) {\n+        Local<Value> rejection_value = promise->Result();\n+        grantable_request->waiting_promise()\n+            ->Reject(context, rejection_value)\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, rejection_value)\n+            .Check();\n+        delete fulfill_holder;\n+        delete reject_holder;\n+        {\n+          Mutex::ScopedLock scoped_lock(mutex_);\n+          ReleaseLock(granted_lock.get());\n+        }\n+        ProcessQueue(env);\n+        return;\n+      } else {\n+        grantable_request->waiting_promise()\n+            ->Resolve(context, callback_result)\n+            .Check();\n+        USE(promise->Then(",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2162928041",
        "repo_full_name": "nodejs/node",
        "pr_number": 58666,
        "pr_file": "src/node_locks.cc",
        "discussion_id": "2162928041",
        "commented_code": "@@ -0,0 +1,738 @@\n+#include \"node_locks.h\"\n+\n+#include \"env-inl.h\"\n+#include \"node_errors.h\"\n+#include \"node_external_reference.h\"\n+#include \"node_internals.h\"\n+#include \"util-inl.h\"\n+#include \"v8.h\"\n+\n+namespace node::worker::locks {\n+\n+using node::errors::TryCatchScope;\n+using v8::Array;\n+using v8::Context;\n+using v8::Exception;\n+using v8::External;\n+using v8::Function;\n+using v8::FunctionCallbackInfo;\n+using v8::HandleScope;\n+using v8::Isolate;\n+using v8::Local;\n+using v8::Object;\n+using v8::ObjectTemplate;\n+using v8::Promise;\n+using v8::String;\n+using v8::Value;\n+\n+static constexpr const char* kSharedMode = \"shared\";\n+static constexpr const char* kExclusiveMode = \"exclusive\";\n+static constexpr const char* kLockStolenError = \"LOCK_STOLEN\";\n+\n+static Local<Object> CreateLockInfoObject(Isolate* isolate,\n+                                          Local<Context> context,\n+                                          const std::u16string& name,\n+                                          Lock::Mode mode,\n+                                          const std::string& client_id);\n+\n+Lock::Lock(Environment* env,\n+           const std::u16string& name,\n+           Mode mode,\n+           const std::string& client_id,\n+           Local<Promise::Resolver> waiting,\n+           Local<Promise::Resolver> released)\n+    : env_(env), name_(name), mode_(mode), client_id_(client_id) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+}\n+\n+LockRequest::LockRequest(Environment* env,\n+                         Local<Promise::Resolver> waiting,\n+                         Local<Promise::Resolver> released,\n+                         Local<Function> callback,\n+                         const std::u16string& name,\n+                         Lock::Mode mode,\n+                         const std::string& client_id,\n+                         bool steal,\n+                         bool if_available)\n+    : env_(env),\n+      name_(name),\n+      mode_(mode),\n+      client_id_(client_id),\n+      steal_(steal),\n+      if_available_(if_available) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+  callback_.Reset(env_->isolate(), callback);\n+}\n+\n+bool LockManager::IsGrantable(const LockRequest* request) const {\n+  // Steal requests bypass all normal granting rules\n+  if (request->steal()) return true;\n+\n+  auto held_locks_iter = held_locks_.find(request->name());\n+  // No existing locks for this resource name\n+  if (held_locks_iter == held_locks_.end()) return true;\n+\n+  // Exclusive requests cannot coexist with any existing locks\n+  if (request->mode() == Lock::Mode::Exclusive) return false;\n+\n+  // For shared requests, check if any existing lock is exclusive\n+  for (const auto& existing_lock : held_locks_iter->second) {\n+    if (existing_lock->mode() == Lock::Mode::Exclusive) return false;\n+  }\n+  // All existing locks are shared, so this shared request can be granted\n+  return true;\n+}\n+\n+// Called when the user callback promise fulfills\n+static void OnLockCallbackFulfilled(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  // Extract the LockHolder from V8 External data\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  // Release the lock and continue processing the queue.\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], false);\n+}\n+\n+// Called when the user callback promise rejects\n+static void OnLockCallbackRejected(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], true);\n+}\n+\n+void LockManager::CleanupStolenLocks(Environment* env) {\n+  std::vector<std::u16string> resources_to_clean;\n+\n+  // Collect resources to clean\n+  {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    for (auto resource_iter = held_locks_.begin();\n+         resource_iter != held_locks_.end();\n+         ++resource_iter) {\n+      auto& resource_locks = resource_iter->second;\n+      bool has_stolen_from_other_env = false;\n+\n+      // Check if this resource has stolen locks from other environments\n+      for (const auto& lock_ptr : resource_locks) {\n+        if (lock_ptr->is_stolen() && lock_ptr->env() != env) {\n+          has_stolen_from_other_env = true;\n+          break;\n+        }\n+      }\n+\n+      if (has_stolen_from_other_env) {\n+        resources_to_clean.push_back(resource_iter->first);\n+      }\n+    }\n+  }\n+\n+  // Clean up resources\n+  for (const auto& resource_name : resources_to_clean) {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    auto resource_iter = held_locks_.find(resource_name);\n+    if (resource_iter != held_locks_.end()) {\n+      auto& resource_locks = resource_iter->second;\n+\n+      // Remove stolen locks from other environments\n+      for (auto lock_iter = resource_locks.begin();\n+           lock_iter != resource_locks.end();) {\n+        if ((*lock_iter)->is_stolen() && (*lock_iter)->env() != env) {\n+          lock_iter = resource_locks.erase(lock_iter);\n+        } else {\n+          ++lock_iter;\n+        }\n+      }\n+\n+      if (resource_locks.empty()) {\n+        held_locks_.erase(resource_iter);\n+      }\n+    }\n+  }\n+}\n+\n+/**\n+ * Web Locks algorithm implementation\n+ * https://w3c.github.io/web-locks/#algorithms\n+ */\n+void LockManager::ProcessQueue(Environment* env) {\n+  Isolate* isolate = env->isolate();\n+  HandleScope handle_scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  // Remove locks that were stolen from this Environment first\n+  CleanupStolenLocks(env);\n+\n+  while (true) {\n+    std::unique_ptr<LockRequest> grantable_request;\n+    std::unique_ptr<LockRequest> if_available_request;\n+    std::unordered_set<Environment*> other_envs_to_wake;\n+\n+    {\n+      std::unordered_map<std::u16string, LockRequest*> first_seen_for_resource;\n+\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      for (auto queue_iter = pending_queue_.begin();\n+           queue_iter != pending_queue_.end();\n+           ++queue_iter) {\n+        LockRequest* request = queue_iter->get();\n+\n+        // Collect unique environments to wake up later\n+        if (request->env() != env) {\n+          other_envs_to_wake.insert(request->env());\n+          continue;\n+        }\n+\n+        // During a single pass, the first time we see a resource name is the\n+        // earliest pending request\n+        auto& first_for_resource = first_seen_for_resource[request->name()];\n+        if (first_for_resource == nullptr) {\n+          first_for_resource = request;  // Mark as first seen for this resource\n+        }\n+\n+        bool has_earlier_request_for_same_resource =\n+            (first_for_resource != request);\n+\n+        if (has_earlier_request_for_same_resource || !IsGrantable(request)) {\n+          if (request->if_available()) {\n+            // ifAvailable request when resource not available: grant with null\n+            if_available_request = std::move(*queue_iter);\n+            pending_queue_.erase(queue_iter);\n+            break;\n+          }\n+          continue;\n+        }\n+\n+        // Found a request that can be granted normally\n+        grantable_request = std::move(*queue_iter);\n+        pending_queue_.erase(queue_iter);\n+        break;\n+      }\n+    }\n+\n+    // Wake each environment only once\n+    for (Environment* target_env : other_envs_to_wake) {\n+      WakeEnvironment(target_env);\n+    }\n+\n+    /**\n+     * ifAvailable:\n+     *  Grant the lock only if it is immediately available;\n+     *  otherwise invoke the callback with null and resolve the promises.\n+     *  Check wrapCallback function in locks.js\n+     */\n+    if (if_available_request) {\n+      Local<Value> null_arg = Null(isolate);\n+      Local<Value> callback_result;\n+      {\n+        TryCatchScope try_catch_scope(env);\n+        if (!if_available_request->callback()\n+                 ->Call(context, Undefined(isolate), 1, &null_arg)\n+                 .ToLocal(&callback_result)) {\n+          if_available_request->waiting_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          if_available_request->released_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          return;\n+        }\n+      }\n+      if_available_request->waiting_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      if_available_request->released_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      return;\n+    }\n+\n+    if (!grantable_request) return;\n+\n+    // Handle steal operations with minimal mutex scope\n+    if (grantable_request->steal()) {\n+      std::unordered_set<Environment*> envs_to_notify;\n+\n+      {\n+        Mutex::ScopedLock scoped_lock(mutex_);\n+        auto held_locks_iter = held_locks_.find(grantable_request->name());\n+        if (held_locks_iter != held_locks_.end()) {\n+          // Mark existing locks as stolen and collect environments to notify\n+          for (auto& existing_lock : held_locks_iter->second) {\n+            existing_lock->mark_stolen();\n+            envs_to_notify.insert(existing_lock->env());\n+\n+            // Immediately reject the stolen lock's released_promise\n+            Local<String> error_string;\n+            if (!String::NewFromUtf8(isolate, kLockStolenError)\n+                     .ToLocal(&error_string)) {\n+              return;\n+            }\n+            Local<Value> error = Exception::Error(error_string);\n+            existing_lock->released_promise()->Reject(context, error).Check();\n+          }\n+\n+          // Remove stolen locks from current environment immediately\n+          for (auto lock_iter = held_locks_iter->second.begin();\n+               lock_iter != held_locks_iter->second.end();) {\n+            if ((*lock_iter)->env() == env) {\n+              lock_iter = held_locks_iter->second.erase(lock_iter);\n+            } else {\n+              ++lock_iter;\n+            }\n+          }\n+\n+          if (held_locks_iter->second.empty()) {\n+            held_locks_.erase(held_locks_iter);\n+          }\n+        }\n+      }\n+\n+      // Wake other environments\n+      for (Environment* target_env : envs_to_notify) {\n+        if (target_env != env) {\n+          WakeEnvironment(target_env);\n+        }\n+      }\n+    }\n+\n+    // Create and store the new granted lock\n+    auto granted_lock =\n+        std::make_shared<Lock>(env,\n+                               grantable_request->name(),\n+                               grantable_request->mode(),\n+                               grantable_request->client_id(),\n+                               grantable_request->waiting_promise(),\n+                               grantable_request->released_promise());\n+    {\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      held_locks_[grantable_request->name()].push_back(granted_lock);\n+    }\n+\n+    // Call user callback\n+    Local<Object> lock_info_obj =\n+        CreateLockInfoObject(isolate,\n+                             context,\n+                             grantable_request->name(),\n+                             grantable_request->mode(),\n+                             grantable_request->client_id());\n+    if (lock_info_obj.IsEmpty()) {\n+      return;\n+    }\n+    Local<Value> callback_arg = lock_info_obj;\n+    Local<Value> callback_result;\n+    {\n+      TryCatchScope try_catch_scope(env);\n+      if (!grantable_request->callback()\n+               ->Call(context, Undefined(isolate), 1, &callback_arg)\n+               .ToLocal(&callback_result)) {\n+        grantable_request->waiting_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        return;\n+      }\n+    }\n+\n+    // Allocate a LockHolder on the heap to safely manage the lock's lifetime\n+    // until the user's callback promise settles.\n+    auto* fulfill_holder = new LockHolder(granted_lock);\n+    auto* reject_holder = new LockHolder(granted_lock);\n+    Local<Function> on_fulfilled_callback;\n+    Local<Function> on_rejected_callback;\n+\n+    if (!Function::New(context,\n+                       OnLockCallbackFulfilled,\n+                       External::New(isolate, fulfill_holder))\n+             .ToLocal(&on_fulfilled_callback) ||\n+        !Function::New(context,\n+                       OnLockCallbackRejected,\n+                       External::New(isolate, reject_holder))\n+             .ToLocal(&on_rejected_callback)) {\n+      delete fulfill_holder;\n+      delete reject_holder;\n+      return;\n+    }\n+\n+    // Handle promise chain\n+    if (callback_result->IsPromise()) {\n+      Local<Promise> promise = callback_result.As<Promise>();\n+      if (promise->State() == Promise::kRejected) {\n+        Local<Value> rejection_value = promise->Result();\n+        grantable_request->waiting_promise()\n+            ->Reject(context, rejection_value)\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, rejection_value)\n+            .Check();\n+        delete fulfill_holder;\n+        delete reject_holder;\n+        {\n+          Mutex::ScopedLock scoped_lock(mutex_);\n+          ReleaseLock(granted_lock.get());\n+        }\n+        ProcessQueue(env);\n+        return;\n+      } else {\n+        grantable_request->waiting_promise()\n+            ->Resolve(context, callback_result)\n+            .Check();\n+        USE(promise->Then(",
        "comment_created_at": "2025-06-24T04:20:43+00:00",
        "comment_author": "jasnell",
        "comment_body": "We should avoid using `USE` for the same error propagation reasons. Calling `Then(...)` can cause a JavaScript error to be scheduled. USE would cause that to be ignored when we ought to propagate it.",
        "pr_file_module": null
      },
      {
        "comment_id": "2167768124",
        "repo_full_name": "nodejs/node",
        "pr_number": 58666,
        "pr_file": "src/node_locks.cc",
        "discussion_id": "2162928041",
        "commented_code": "@@ -0,0 +1,738 @@\n+#include \"node_locks.h\"\n+\n+#include \"env-inl.h\"\n+#include \"node_errors.h\"\n+#include \"node_external_reference.h\"\n+#include \"node_internals.h\"\n+#include \"util-inl.h\"\n+#include \"v8.h\"\n+\n+namespace node::worker::locks {\n+\n+using node::errors::TryCatchScope;\n+using v8::Array;\n+using v8::Context;\n+using v8::Exception;\n+using v8::External;\n+using v8::Function;\n+using v8::FunctionCallbackInfo;\n+using v8::HandleScope;\n+using v8::Isolate;\n+using v8::Local;\n+using v8::Object;\n+using v8::ObjectTemplate;\n+using v8::Promise;\n+using v8::String;\n+using v8::Value;\n+\n+static constexpr const char* kSharedMode = \"shared\";\n+static constexpr const char* kExclusiveMode = \"exclusive\";\n+static constexpr const char* kLockStolenError = \"LOCK_STOLEN\";\n+\n+static Local<Object> CreateLockInfoObject(Isolate* isolate,\n+                                          Local<Context> context,\n+                                          const std::u16string& name,\n+                                          Lock::Mode mode,\n+                                          const std::string& client_id);\n+\n+Lock::Lock(Environment* env,\n+           const std::u16string& name,\n+           Mode mode,\n+           const std::string& client_id,\n+           Local<Promise::Resolver> waiting,\n+           Local<Promise::Resolver> released)\n+    : env_(env), name_(name), mode_(mode), client_id_(client_id) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+}\n+\n+LockRequest::LockRequest(Environment* env,\n+                         Local<Promise::Resolver> waiting,\n+                         Local<Promise::Resolver> released,\n+                         Local<Function> callback,\n+                         const std::u16string& name,\n+                         Lock::Mode mode,\n+                         const std::string& client_id,\n+                         bool steal,\n+                         bool if_available)\n+    : env_(env),\n+      name_(name),\n+      mode_(mode),\n+      client_id_(client_id),\n+      steal_(steal),\n+      if_available_(if_available) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+  callback_.Reset(env_->isolate(), callback);\n+}\n+\n+bool LockManager::IsGrantable(const LockRequest* request) const {\n+  // Steal requests bypass all normal granting rules\n+  if (request->steal()) return true;\n+\n+  auto held_locks_iter = held_locks_.find(request->name());\n+  // No existing locks for this resource name\n+  if (held_locks_iter == held_locks_.end()) return true;\n+\n+  // Exclusive requests cannot coexist with any existing locks\n+  if (request->mode() == Lock::Mode::Exclusive) return false;\n+\n+  // For shared requests, check if any existing lock is exclusive\n+  for (const auto& existing_lock : held_locks_iter->second) {\n+    if (existing_lock->mode() == Lock::Mode::Exclusive) return false;\n+  }\n+  // All existing locks are shared, so this shared request can be granted\n+  return true;\n+}\n+\n+// Called when the user callback promise fulfills\n+static void OnLockCallbackFulfilled(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  // Extract the LockHolder from V8 External data\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  // Release the lock and continue processing the queue.\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], false);\n+}\n+\n+// Called when the user callback promise rejects\n+static void OnLockCallbackRejected(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], true);\n+}\n+\n+void LockManager::CleanupStolenLocks(Environment* env) {\n+  std::vector<std::u16string> resources_to_clean;\n+\n+  // Collect resources to clean\n+  {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    for (auto resource_iter = held_locks_.begin();\n+         resource_iter != held_locks_.end();\n+         ++resource_iter) {\n+      auto& resource_locks = resource_iter->second;\n+      bool has_stolen_from_other_env = false;\n+\n+      // Check if this resource has stolen locks from other environments\n+      for (const auto& lock_ptr : resource_locks) {\n+        if (lock_ptr->is_stolen() && lock_ptr->env() != env) {\n+          has_stolen_from_other_env = true;\n+          break;\n+        }\n+      }\n+\n+      if (has_stolen_from_other_env) {\n+        resources_to_clean.push_back(resource_iter->first);\n+      }\n+    }\n+  }\n+\n+  // Clean up resources\n+  for (const auto& resource_name : resources_to_clean) {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    auto resource_iter = held_locks_.find(resource_name);\n+    if (resource_iter != held_locks_.end()) {\n+      auto& resource_locks = resource_iter->second;\n+\n+      // Remove stolen locks from other environments\n+      for (auto lock_iter = resource_locks.begin();\n+           lock_iter != resource_locks.end();) {\n+        if ((*lock_iter)->is_stolen() && (*lock_iter)->env() != env) {\n+          lock_iter = resource_locks.erase(lock_iter);\n+        } else {\n+          ++lock_iter;\n+        }\n+      }\n+\n+      if (resource_locks.empty()) {\n+        held_locks_.erase(resource_iter);\n+      }\n+    }\n+  }\n+}\n+\n+/**\n+ * Web Locks algorithm implementation\n+ * https://w3c.github.io/web-locks/#algorithms\n+ */\n+void LockManager::ProcessQueue(Environment* env) {\n+  Isolate* isolate = env->isolate();\n+  HandleScope handle_scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  // Remove locks that were stolen from this Environment first\n+  CleanupStolenLocks(env);\n+\n+  while (true) {\n+    std::unique_ptr<LockRequest> grantable_request;\n+    std::unique_ptr<LockRequest> if_available_request;\n+    std::unordered_set<Environment*> other_envs_to_wake;\n+\n+    {\n+      std::unordered_map<std::u16string, LockRequest*> first_seen_for_resource;\n+\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      for (auto queue_iter = pending_queue_.begin();\n+           queue_iter != pending_queue_.end();\n+           ++queue_iter) {\n+        LockRequest* request = queue_iter->get();\n+\n+        // Collect unique environments to wake up later\n+        if (request->env() != env) {\n+          other_envs_to_wake.insert(request->env());\n+          continue;\n+        }\n+\n+        // During a single pass, the first time we see a resource name is the\n+        // earliest pending request\n+        auto& first_for_resource = first_seen_for_resource[request->name()];\n+        if (first_for_resource == nullptr) {\n+          first_for_resource = request;  // Mark as first seen for this resource\n+        }\n+\n+        bool has_earlier_request_for_same_resource =\n+            (first_for_resource != request);\n+\n+        if (has_earlier_request_for_same_resource || !IsGrantable(request)) {\n+          if (request->if_available()) {\n+            // ifAvailable request when resource not available: grant with null\n+            if_available_request = std::move(*queue_iter);\n+            pending_queue_.erase(queue_iter);\n+            break;\n+          }\n+          continue;\n+        }\n+\n+        // Found a request that can be granted normally\n+        grantable_request = std::move(*queue_iter);\n+        pending_queue_.erase(queue_iter);\n+        break;\n+      }\n+    }\n+\n+    // Wake each environment only once\n+    for (Environment* target_env : other_envs_to_wake) {\n+      WakeEnvironment(target_env);\n+    }\n+\n+    /**\n+     * ifAvailable:\n+     *  Grant the lock only if it is immediately available;\n+     *  otherwise invoke the callback with null and resolve the promises.\n+     *  Check wrapCallback function in locks.js\n+     */\n+    if (if_available_request) {\n+      Local<Value> null_arg = Null(isolate);\n+      Local<Value> callback_result;\n+      {\n+        TryCatchScope try_catch_scope(env);\n+        if (!if_available_request->callback()\n+                 ->Call(context, Undefined(isolate), 1, &null_arg)\n+                 .ToLocal(&callback_result)) {\n+          if_available_request->waiting_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          if_available_request->released_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          return;\n+        }\n+      }\n+      if_available_request->waiting_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      if_available_request->released_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      return;\n+    }\n+\n+    if (!grantable_request) return;\n+\n+    // Handle steal operations with minimal mutex scope\n+    if (grantable_request->steal()) {\n+      std::unordered_set<Environment*> envs_to_notify;\n+\n+      {\n+        Mutex::ScopedLock scoped_lock(mutex_);\n+        auto held_locks_iter = held_locks_.find(grantable_request->name());\n+        if (held_locks_iter != held_locks_.end()) {\n+          // Mark existing locks as stolen and collect environments to notify\n+          for (auto& existing_lock : held_locks_iter->second) {\n+            existing_lock->mark_stolen();\n+            envs_to_notify.insert(existing_lock->env());\n+\n+            // Immediately reject the stolen lock's released_promise\n+            Local<String> error_string;\n+            if (!String::NewFromUtf8(isolate, kLockStolenError)\n+                     .ToLocal(&error_string)) {\n+              return;\n+            }\n+            Local<Value> error = Exception::Error(error_string);\n+            existing_lock->released_promise()->Reject(context, error).Check();\n+          }\n+\n+          // Remove stolen locks from current environment immediately\n+          for (auto lock_iter = held_locks_iter->second.begin();\n+               lock_iter != held_locks_iter->second.end();) {\n+            if ((*lock_iter)->env() == env) {\n+              lock_iter = held_locks_iter->second.erase(lock_iter);\n+            } else {\n+              ++lock_iter;\n+            }\n+          }\n+\n+          if (held_locks_iter->second.empty()) {\n+            held_locks_.erase(held_locks_iter);\n+          }\n+        }\n+      }\n+\n+      // Wake other environments\n+      for (Environment* target_env : envs_to_notify) {\n+        if (target_env != env) {\n+          WakeEnvironment(target_env);\n+        }\n+      }\n+    }\n+\n+    // Create and store the new granted lock\n+    auto granted_lock =\n+        std::make_shared<Lock>(env,\n+                               grantable_request->name(),\n+                               grantable_request->mode(),\n+                               grantable_request->client_id(),\n+                               grantable_request->waiting_promise(),\n+                               grantable_request->released_promise());\n+    {\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      held_locks_[grantable_request->name()].push_back(granted_lock);\n+    }\n+\n+    // Call user callback\n+    Local<Object> lock_info_obj =\n+        CreateLockInfoObject(isolate,\n+                             context,\n+                             grantable_request->name(),\n+                             grantable_request->mode(),\n+                             grantable_request->client_id());\n+    if (lock_info_obj.IsEmpty()) {\n+      return;\n+    }\n+    Local<Value> callback_arg = lock_info_obj;\n+    Local<Value> callback_result;\n+    {\n+      TryCatchScope try_catch_scope(env);\n+      if (!grantable_request->callback()\n+               ->Call(context, Undefined(isolate), 1, &callback_arg)\n+               .ToLocal(&callback_result)) {\n+        grantable_request->waiting_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        return;\n+      }\n+    }\n+\n+    // Allocate a LockHolder on the heap to safely manage the lock's lifetime\n+    // until the user's callback promise settles.\n+    auto* fulfill_holder = new LockHolder(granted_lock);\n+    auto* reject_holder = new LockHolder(granted_lock);\n+    Local<Function> on_fulfilled_callback;\n+    Local<Function> on_rejected_callback;\n+\n+    if (!Function::New(context,\n+                       OnLockCallbackFulfilled,\n+                       External::New(isolate, fulfill_holder))\n+             .ToLocal(&on_fulfilled_callback) ||\n+        !Function::New(context,\n+                       OnLockCallbackRejected,\n+                       External::New(isolate, reject_holder))\n+             .ToLocal(&on_rejected_callback)) {\n+      delete fulfill_holder;\n+      delete reject_holder;\n+      return;\n+    }\n+\n+    // Handle promise chain\n+    if (callback_result->IsPromise()) {\n+      Local<Promise> promise = callback_result.As<Promise>();\n+      if (promise->State() == Promise::kRejected) {\n+        Local<Value> rejection_value = promise->Result();\n+        grantable_request->waiting_promise()\n+            ->Reject(context, rejection_value)\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, rejection_value)\n+            .Check();\n+        delete fulfill_holder;\n+        delete reject_holder;\n+        {\n+          Mutex::ScopedLock scoped_lock(mutex_);\n+          ReleaseLock(granted_lock.get());\n+        }\n+        ProcessQueue(env);\n+        return;\n+      } else {\n+        grantable_request->waiting_promise()\n+            ->Resolve(context, callback_result)\n+            .Check();\n+        USE(promise->Then(",
        "comment_created_at": "2025-06-25T22:46:29+00:00",
        "comment_author": "IlyasShabi",
        "comment_body": "Thanks for the explanation, now Im using `USE` only if I don't need the return value and I should continue the cleanup process",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1922735526",
    "pr_number": 55874,
    "pr_file": "src/node_contextify.cc",
    "created_at": "2025-01-20T18:06:19+00:00",
    "commented_code": "Utf8Value message_value(isolate, message);\n   auto message_view = message_value.ToStringView();\n \n+  for (const auto& error_message : throws_only_in_cjs_error_messages) {\n+    if (message_view.find(error_message) != std::string_view::npos &&\n+        error_message.find(\"await is only valid in async functions and \"\n+                           \"the top level bodies of modules\") !=\n+            std::string_view::npos) {\n+      const char* error_text =\n+          \"Top-level await is not supported in CommonJS modules. \"\n+          \"To use top-level await, add \\\"type\\\": \\\"module\\\" to your \"\n+          \"package.json \"\n+          \"or rename the file to use the .mjs extension. Alternatively, wrap \"\n+          \"the await expression in an async function. Module syntax like \"\n+          \"import/export statements requires proper module configuration.\";\n+\n+      isolate->ThrowException(v8::Exception::SyntaxError(",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "1922735526",
        "repo_full_name": "nodejs/node",
        "pr_number": 55874,
        "pr_file": "src/node_contextify.cc",
        "discussion_id": "1922735526",
        "commented_code": "@@ -1816,6 +1816,26 @@ bool ShouldRetryAsESM(Realm* realm,\n   Utf8Value message_value(isolate, message);\n   auto message_view = message_value.ToStringView();\n \n+  for (const auto& error_message : throws_only_in_cjs_error_messages) {\n+    if (message_view.find(error_message) != std::string_view::npos &&\n+        error_message.find(\"await is only valid in async functions and \"\n+                           \"the top level bodies of modules\") !=\n+            std::string_view::npos) {\n+      const char* error_text =\n+          \"Top-level await is not supported in CommonJS modules. \"\n+          \"To use top-level await, add \\\"type\\\": \\\"module\\\" to your \"\n+          \"package.json \"\n+          \"or rename the file to use the .mjs extension. Alternatively, wrap \"\n+          \"the await expression in an async function. Module syntax like \"\n+          \"import/export statements requires proper module configuration.\";\n+\n+      isolate->ThrowException(v8::Exception::SyntaxError(",
        "comment_created_at": "2025-01-20T18:06:19+00:00",
        "comment_author": "joyeecheung",
        "comment_body": "Throwing here would hide the original error, which makes it harder for users to locate e.g. where that top level await is.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2155397591",
    "pr_number": 58758,
    "pr_file": "src/spawn_sync.cc",
    "created_at": "2025-06-18T20:00:36+00:00",
    "commented_code": "void SyncProcessRunner::Spawn(const FunctionCallbackInfo<Value>& args) {\n   Environment* env = Environment::GetCurrent(args);\n+  Local<Context> context = env->context();\n+\n+  std::string resource = \"\";\n+  if (env->permission()->enabled() && args[0]->IsObject()) {\n+    Local<Object> js_options = args[0].As<Object>();\n+    Local<Value> js_file;\n+    if (js_options->Get(context, env->file_string()).ToLocal(&js_file)) {\n+      node::Utf8Value v(env->isolate(), js_file.As<String>());\n+      resource = v.ToString();\n+    }",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2155397591",
        "repo_full_name": "nodejs/node",
        "pr_number": 58758,
        "pr_file": "src/spawn_sync.cc",
        "discussion_id": "2155397591",
        "commented_code": "@@ -378,8 +378,20 @@ void SyncProcessRunner::RegisterExternalReferences(\n \n void SyncProcessRunner::Spawn(const FunctionCallbackInfo<Value>& args) {\n   Environment* env = Environment::GetCurrent(args);\n+  Local<Context> context = env->context();\n+\n+  std::string resource = \"\";\n+  if (env->permission()->enabled() && args[0]->IsObject()) {\n+    Local<Object> js_options = args[0].As<Object>();\n+    Local<Value> js_file;\n+    if (js_options->Get(context, env->file_string()).ToLocal(&js_file)) {\n+      node::Utf8Value v(env->isolate(), js_file.As<String>());\n+      resource = v.ToString();\n+    }",
        "comment_created_at": "2025-06-18T20:00:36+00:00",
        "comment_author": "geeksilva97",
        "comment_body": "```suggestion\r\n    if (!js_options->Get(context, env->file_string()).ToLocal(&js_file)) {\r\n      return;\r\n    }\r\n    \r\n    node::Utf8Value v(env->isolate(), js_file.As<String>());\r\n    resource = v.ToString();\r\n```\r\n\r\nI think if `ToLocal` doesn't work for some reason, an error will be scheduled. Just like in [here](https://github.com/nodejs/node/blob/main/src/process_wrap.cc#L231-L234)",
        "pr_file_module": null
      },
      {
        "comment_id": "2155435062",
        "repo_full_name": "nodejs/node",
        "pr_number": 58758,
        "pr_file": "src/spawn_sync.cc",
        "discussion_id": "2155397591",
        "commented_code": "@@ -378,8 +378,20 @@ void SyncProcessRunner::RegisterExternalReferences(\n \n void SyncProcessRunner::Spawn(const FunctionCallbackInfo<Value>& args) {\n   Environment* env = Environment::GetCurrent(args);\n+  Local<Context> context = env->context();\n+\n+  std::string resource = \"\";\n+  if (env->permission()->enabled() && args[0]->IsObject()) {\n+    Local<Object> js_options = args[0].As<Object>();\n+    Local<Value> js_file;\n+    if (js_options->Get(context, env->file_string()).ToLocal(&js_file)) {\n+      node::Utf8Value v(env->isolate(), js_file.As<String>());\n+      resource = v.ToString();\n+    }",
        "comment_created_at": "2025-06-18T20:25:49+00:00",
        "comment_author": "RafaelGSS",
        "comment_body": "Oh yeah, I think I missed this, thx.",
        "pr_file_module": null
      }
    ]
  }
]