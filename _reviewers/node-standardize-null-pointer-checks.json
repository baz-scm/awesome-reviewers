[
  {
    "discussion_id": "2174607704",
    "pr_number": 58077,
    "pr_file": "src/inspector/network_agent.cc",
    "created_at": "2025-06-30T09:14:15+00:00",
    "commented_code": "// If the request is finished, remove the entry.\n     requests_.erase(in_requestId);\n   }\n-\n   return protocol::DispatchResponse::Success();\n }\n \n+protocol::DispatchResponse NetworkAgent::loadNetworkResource(\n+    const protocol::String& in_url,\n+    std::unique_ptr<protocol::Network::LoadNetworkResourcePageResult>*\n+        out_resource) {\n+  if (!env_->options()->experimental_inspector_network_resource) {\n+    return protocol::DispatchResponse::ServerError(\n+        \"Network resource loading is not enabled. This feature is \"\n+        \"experimental and requires --experimental-inspector-network-resource \"\n+        \"flag to be set.\");\n+  }\n+  std::string data = network_resource_manager_->Get(in_url);",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2174607704",
        "repo_full_name": "nodejs/node",
        "pr_number": 58077,
        "pr_file": "src/inspector/network_agent.cc",
        "discussion_id": "2174607704",
        "commented_code": "@@ -329,10 +341,38 @@ protocol::DispatchResponse NetworkAgent::streamResourceContent(\n     // If the request is finished, remove the entry.\n     requests_.erase(in_requestId);\n   }\n-\n   return protocol::DispatchResponse::Success();\n }\n \n+protocol::DispatchResponse NetworkAgent::loadNetworkResource(\n+    const protocol::String& in_url,\n+    std::unique_ptr<protocol::Network::LoadNetworkResourcePageResult>*\n+        out_resource) {\n+  if (!env_->options()->experimental_inspector_network_resource) {\n+    return protocol::DispatchResponse::ServerError(\n+        \"Network resource loading is not enabled. This feature is \"\n+        \"experimental and requires --experimental-inspector-network-resource \"\n+        \"flag to be set.\");\n+  }\n+  std::string data = network_resource_manager_->Get(in_url);",
        "comment_created_at": "2025-06-30T09:14:15+00:00",
        "comment_author": "legendecas",
        "comment_body": "We should check that `network_resource_manager_` is not null here.\r\n\r\n```suggestion\r\n  CHECK_NOT_NULL(network_resource_manager_);\r\n  std::string data = network_resource_manager_->Get(in_url);\r\n```\r\n\r\nOr, we can do an alternative check and get rid of `env_`:\r\n\r\n```cpp\r\n  if (network_resource_manager_ == nullptr) {\r\n    return protocol::DispatchResponse::ServerError(\r\n        \"Network resource loading is not enabled. This feature is \"\r\n        \"experimental and requires --experimental-inspector-network-resource \"\r\n        \"flag to be set.\");\r\n  }\r\n  std::string data = network_resource_manager_->Get(in_url);\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2175187646",
        "repo_full_name": "nodejs/node",
        "pr_number": 58077,
        "pr_file": "src/inspector/network_agent.cc",
        "discussion_id": "2174607704",
        "commented_code": "@@ -329,10 +341,38 @@ protocol::DispatchResponse NetworkAgent::streamResourceContent(\n     // If the request is finished, remove the entry.\n     requests_.erase(in_requestId);\n   }\n-\n   return protocol::DispatchResponse::Success();\n }\n \n+protocol::DispatchResponse NetworkAgent::loadNetworkResource(\n+    const protocol::String& in_url,\n+    std::unique_ptr<protocol::Network::LoadNetworkResourcePageResult>*\n+        out_resource) {\n+  if (!env_->options()->experimental_inspector_network_resource) {\n+    return protocol::DispatchResponse::ServerError(\n+        \"Network resource loading is not enabled. This feature is \"\n+        \"experimental and requires --experimental-inspector-network-resource \"\n+        \"flag to be set.\");\n+  }\n+  std::string data = network_resource_manager_->Get(in_url);",
        "comment_created_at": "2025-06-30T14:15:51+00:00",
        "comment_author": "islandryu",
        "comment_body": "Applied the suggestion!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2162937281",
    "pr_number": 58666,
    "pr_file": "src/node_locks.cc",
    "created_at": "2025-06-24T04:31:51+00:00",
    "commented_code": "+#include \"node_locks.h\"\n+\n+#include \"env-inl.h\"\n+#include \"node_errors.h\"\n+#include \"node_external_reference.h\"\n+#include \"node_internals.h\"\n+#include \"util-inl.h\"\n+#include \"v8.h\"\n+\n+namespace node::worker::locks {\n+\n+using node::errors::TryCatchScope;\n+using v8::Array;\n+using v8::Context;\n+using v8::Exception;\n+using v8::External;\n+using v8::Function;\n+using v8::FunctionCallbackInfo;\n+using v8::HandleScope;\n+using v8::Isolate;\n+using v8::Local;\n+using v8::Object;\n+using v8::ObjectTemplate;\n+using v8::Promise;\n+using v8::String;\n+using v8::Value;\n+\n+static constexpr const char* kSharedMode = \"shared\";\n+static constexpr const char* kExclusiveMode = \"exclusive\";\n+static constexpr const char* kLockStolenError = \"LOCK_STOLEN\";\n+\n+static Local<Object> CreateLockInfoObject(Isolate* isolate,\n+                                          Local<Context> context,\n+                                          const std::u16string& name,\n+                                          Lock::Mode mode,\n+                                          const std::string& client_id);\n+\n+Lock::Lock(Environment* env,\n+           const std::u16string& name,\n+           Mode mode,\n+           const std::string& client_id,\n+           Local<Promise::Resolver> waiting,\n+           Local<Promise::Resolver> released)\n+    : env_(env), name_(name), mode_(mode), client_id_(client_id) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+}\n+\n+LockRequest::LockRequest(Environment* env,\n+                         Local<Promise::Resolver> waiting,\n+                         Local<Promise::Resolver> released,\n+                         Local<Function> callback,\n+                         const std::u16string& name,\n+                         Lock::Mode mode,\n+                         const std::string& client_id,\n+                         bool steal,\n+                         bool if_available)\n+    : env_(env),\n+      name_(name),\n+      mode_(mode),\n+      client_id_(client_id),\n+      steal_(steal),\n+      if_available_(if_available) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+  callback_.Reset(env_->isolate(), callback);\n+}\n+\n+bool LockManager::IsGrantable(const LockRequest* request) const {\n+  // Steal requests bypass all normal granting rules\n+  if (request->steal()) return true;\n+\n+  auto held_locks_iter = held_locks_.find(request->name());\n+  // No existing locks for this resource name\n+  if (held_locks_iter == held_locks_.end()) return true;\n+\n+  // Exclusive requests cannot coexist with any existing locks\n+  if (request->mode() == Lock::Mode::Exclusive) return false;\n+\n+  // For shared requests, check if any existing lock is exclusive\n+  for (const auto& existing_lock : held_locks_iter->second) {\n+    if (existing_lock->mode() == Lock::Mode::Exclusive) return false;\n+  }\n+  // All existing locks are shared, so this shared request can be granted\n+  return true;\n+}\n+\n+// Called when the user callback promise fulfills\n+static void OnLockCallbackFulfilled(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  // Extract the LockHolder from V8 External data\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  // Release the lock and continue processing the queue.\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], false);\n+}\n+\n+// Called when the user callback promise rejects\n+static void OnLockCallbackRejected(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], true);\n+}\n+\n+void LockManager::CleanupStolenLocks(Environment* env) {\n+  std::vector<std::u16string> resources_to_clean;\n+\n+  // Collect resources to clean\n+  {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    for (auto resource_iter = held_locks_.begin();\n+         resource_iter != held_locks_.end();\n+         ++resource_iter) {\n+      auto& resource_locks = resource_iter->second;\n+      bool has_stolen_from_other_env = false;\n+\n+      // Check if this resource has stolen locks from other environments\n+      for (const auto& lock_ptr : resource_locks) {\n+        if (lock_ptr->is_stolen() && lock_ptr->env() != env) {\n+          has_stolen_from_other_env = true;\n+          break;\n+        }\n+      }\n+\n+      if (has_stolen_from_other_env) {\n+        resources_to_clean.push_back(resource_iter->first);\n+      }\n+    }\n+  }\n+\n+  // Clean up resources\n+  for (const auto& resource_name : resources_to_clean) {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    auto resource_iter = held_locks_.find(resource_name);\n+    if (resource_iter != held_locks_.end()) {\n+      auto& resource_locks = resource_iter->second;\n+\n+      // Remove stolen locks from other environments\n+      for (auto lock_iter = resource_locks.begin();\n+           lock_iter != resource_locks.end();) {\n+        if ((*lock_iter)->is_stolen() && (*lock_iter)->env() != env) {\n+          lock_iter = resource_locks.erase(lock_iter);\n+        } else {\n+          ++lock_iter;\n+        }\n+      }\n+\n+      if (resource_locks.empty()) {\n+        held_locks_.erase(resource_iter);\n+      }\n+    }\n+  }\n+}\n+\n+/**\n+ * Web Locks algorithm implementation\n+ * https://w3c.github.io/web-locks/#algorithms\n+ */\n+void LockManager::ProcessQueue(Environment* env) {\n+  Isolate* isolate = env->isolate();\n+  HandleScope handle_scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  // Remove locks that were stolen from this Environment first\n+  CleanupStolenLocks(env);\n+\n+  while (true) {\n+    std::unique_ptr<LockRequest> grantable_request;\n+    std::unique_ptr<LockRequest> if_available_request;\n+    std::unordered_set<Environment*> other_envs_to_wake;\n+\n+    {\n+      std::unordered_map<std::u16string, LockRequest*> first_seen_for_resource;\n+\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      for (auto queue_iter = pending_queue_.begin();\n+           queue_iter != pending_queue_.end();\n+           ++queue_iter) {\n+        LockRequest* request = queue_iter->get();\n+\n+        // Collect unique environments to wake up later\n+        if (request->env() != env) {\n+          other_envs_to_wake.insert(request->env());\n+          continue;\n+        }\n+\n+        // During a single pass, the first time we see a resource name is the\n+        // earliest pending request\n+        auto& first_for_resource = first_seen_for_resource[request->name()];\n+        if (first_for_resource == nullptr) {\n+          first_for_resource = request;  // Mark as first seen for this resource\n+        }\n+\n+        bool has_earlier_request_for_same_resource =\n+            (first_for_resource != request);\n+\n+        if (has_earlier_request_for_same_resource || !IsGrantable(request)) {\n+          if (request->if_available()) {\n+            // ifAvailable request when resource not available: grant with null\n+            if_available_request = std::move(*queue_iter);\n+            pending_queue_.erase(queue_iter);\n+            break;\n+          }\n+          continue;\n+        }\n+\n+        // Found a request that can be granted normally\n+        grantable_request = std::move(*queue_iter);\n+        pending_queue_.erase(queue_iter);\n+        break;\n+      }\n+    }\n+\n+    // Wake each environment only once\n+    for (Environment* target_env : other_envs_to_wake) {\n+      WakeEnvironment(target_env);\n+    }\n+\n+    /**\n+     * ifAvailable:\n+     *  Grant the lock only if it is immediately available;\n+     *  otherwise invoke the callback with null and resolve the promises.\n+     *  Check wrapCallback function in locks.js\n+     */\n+    if (if_available_request) {\n+      Local<Value> null_arg = Null(isolate);\n+      Local<Value> callback_result;\n+      {\n+        TryCatchScope try_catch_scope(env);\n+        if (!if_available_request->callback()\n+                 ->Call(context, Undefined(isolate), 1, &null_arg)\n+                 .ToLocal(&callback_result)) {\n+          if_available_request->waiting_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          if_available_request->released_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          return;\n+        }\n+      }\n+      if_available_request->waiting_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      if_available_request->released_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      return;\n+    }\n+\n+    if (!grantable_request) return;\n+\n+    // Handle steal operations with minimal mutex scope\n+    if (grantable_request->steal()) {\n+      std::unordered_set<Environment*> envs_to_notify;\n+\n+      {\n+        Mutex::ScopedLock scoped_lock(mutex_);\n+        auto held_locks_iter = held_locks_.find(grantable_request->name());\n+        if (held_locks_iter != held_locks_.end()) {\n+          // Mark existing locks as stolen and collect environments to notify\n+          for (auto& existing_lock : held_locks_iter->second) {\n+            existing_lock->mark_stolen();\n+            envs_to_notify.insert(existing_lock->env());\n+\n+            // Immediately reject the stolen lock's released_promise\n+            Local<String> error_string;\n+            if (!String::NewFromUtf8(isolate, kLockStolenError)\n+                     .ToLocal(&error_string)) {\n+              return;\n+            }\n+            Local<Value> error = Exception::Error(error_string);\n+            existing_lock->released_promise()->Reject(context, error).Check();\n+          }\n+\n+          // Remove stolen locks from current environment immediately\n+          for (auto lock_iter = held_locks_iter->second.begin();\n+               lock_iter != held_locks_iter->second.end();) {\n+            if ((*lock_iter)->env() == env) {\n+              lock_iter = held_locks_iter->second.erase(lock_iter);\n+            } else {\n+              ++lock_iter;\n+            }\n+          }\n+\n+          if (held_locks_iter->second.empty()) {\n+            held_locks_.erase(held_locks_iter);\n+          }\n+        }\n+      }\n+\n+      // Wake other environments\n+      for (Environment* target_env : envs_to_notify) {\n+        if (target_env != env) {\n+          WakeEnvironment(target_env);\n+        }\n+      }\n+    }\n+\n+    // Create and store the new granted lock\n+    auto granted_lock =\n+        std::make_shared<Lock>(env,\n+                               grantable_request->name(),\n+                               grantable_request->mode(),\n+                               grantable_request->client_id(),\n+                               grantable_request->waiting_promise(),\n+                               grantable_request->released_promise());\n+    {\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      held_locks_[grantable_request->name()].push_back(granted_lock);\n+    }\n+\n+    // Call user callback\n+    Local<Object> lock_info_obj =\n+        CreateLockInfoObject(isolate,\n+                             context,\n+                             grantable_request->name(),\n+                             grantable_request->mode(),\n+                             grantable_request->client_id());\n+    if (lock_info_obj.IsEmpty()) {\n+      return;\n+    }\n+    Local<Value> callback_arg = lock_info_obj;\n+    Local<Value> callback_result;\n+    {\n+      TryCatchScope try_catch_scope(env);\n+      if (!grantable_request->callback()\n+               ->Call(context, Undefined(isolate), 1, &callback_arg)\n+               .ToLocal(&callback_result)) {\n+        grantable_request->waiting_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        return;\n+      }\n+    }\n+\n+    // Allocate a LockHolder on the heap to safely manage the lock's lifetime\n+    // until the user's callback promise settles.\n+    auto* fulfill_holder = new LockHolder(granted_lock);\n+    auto* reject_holder = new LockHolder(granted_lock);\n+    Local<Function> on_fulfilled_callback;\n+    Local<Function> on_rejected_callback;\n+\n+    if (!Function::New(context,\n+                       OnLockCallbackFulfilled,\n+                       External::New(isolate, fulfill_holder))\n+             .ToLocal(&on_fulfilled_callback) ||\n+        !Function::New(context,\n+                       OnLockCallbackRejected,\n+                       External::New(isolate, reject_holder))\n+             .ToLocal(&on_rejected_callback)) {\n+      delete fulfill_holder;\n+      delete reject_holder;\n+      return;\n+    }\n+\n+    // Handle promise chain\n+    if (callback_result->IsPromise()) {\n+      Local<Promise> promise = callback_result.As<Promise>();\n+      if (promise->State() == Promise::kRejected) {\n+        Local<Value> rejection_value = promise->Result();\n+        grantable_request->waiting_promise()\n+            ->Reject(context, rejection_value)\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, rejection_value)\n+            .Check();\n+        delete fulfill_holder;\n+        delete reject_holder;\n+        {\n+          Mutex::ScopedLock scoped_lock(mutex_);\n+          ReleaseLock(granted_lock.get());\n+        }\n+        ProcessQueue(env);\n+        return;\n+      } else {\n+        grantable_request->waiting_promise()\n+            ->Resolve(context, callback_result)\n+            .Check();\n+        USE(promise->Then(\n+            context, on_fulfilled_callback, on_rejected_callback));\n+      }\n+    } else {\n+      grantable_request->waiting_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      Local<Value> promise_args[] = {callback_result};\n+      USE(on_fulfilled_callback->Call(\n+          context, Undefined(isolate), 1, promise_args));\n+      delete reject_holder;\n+    }\n+  }\n+}\n+\n+/**\n+ * name        : string   \u2013 resource identifier\n+ * clientId    : string   \u2013 client identifier\n+ * mode        : string   \u2013 lock mode\n+ * steal       : boolean  \u2013 whether to steal existing locks\n+ * ifAvailable : boolean  \u2013 only grant if immediately available\n+ * callback    : Function - JS callback\n+ */\n+void LockManager::Request(const FunctionCallbackInfo<Value>& args) {\n+  Environment* env = Environment::GetCurrent(args);\n+  Isolate* isolate = env->isolate();\n+  HandleScope scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  CHECK_EQ(args.Length(), 6);\n+  CHECK(args[0]->IsString());\n+  CHECK(args[1]->IsString());\n+  CHECK(args[2]->IsString());\n+  CHECK(args[3]->IsBoolean());\n+  CHECK(args[4]->IsBoolean());\n+  CHECK(args[5]->IsFunction());\n+\n+  Local<String> resource_name_str = args[0].As<String>();\n+  TwoByteValue resource_name_utf16(isolate, resource_name_str);\n+  std::u16string resource_name(\n+      reinterpret_cast<const char16_t*>(*resource_name_utf16),\n+      resource_name_utf16.length());\n+  String::Utf8Value client_id_utf8(isolate, args[1]);\n+  std::string client_id(*client_id_utf8);\n+  String::Utf8Value mode_utf8(isolate, args[2]);\n+  std::string mode_str(*mode_utf8);\n+  bool steal = args[3]->BooleanValue(isolate);\n+  bool if_available = args[4]->BooleanValue(isolate);\n+  Local<Function> callback = args[5].As<Function>();\n+\n+  Lock::Mode lock_mode =\n+      mode_str == kSharedMode ? Lock::Mode::Shared : Lock::Mode::Exclusive;\n+\n+  Local<Promise::Resolver> waiting_promise;\n+  if (!Promise::Resolver::New(context).ToLocal(&waiting_promise)) {\n+    return;\n+  }\n+  Local<Promise::Resolver> released_promise;\n+  if (!Promise::Resolver::New(context).ToLocal(&released_promise)) {\n+    return;\n+  }\n+\n+  args.GetReturnValue().Set(released_promise->GetPromise());\n+\n+  LockManager* manager = GetCurrent();\n+  {\n+    Mutex::ScopedLock scoped_lock(manager->mutex_);\n+\n+    // Register cleanup hook for the environment only once\n+    if (manager->registered_envs_.insert(env).second) {\n+      env->AddCleanupHook(LockManager::OnEnvironmentCleanup, env);\n+    }\n+\n+    auto lock_request = std::make_unique<LockRequest>(env,\n+                                                      waiting_promise,\n+                                                      released_promise,\n+                                                      callback,\n+                                                      resource_name,\n+                                                      lock_mode,\n+                                                      client_id,\n+                                                      steal,\n+                                                      if_available);\n+    // Steal requests get priority by going to front of queue\n+    if (steal) {\n+      manager->pending_queue_.emplace_front(std::move(lock_request));\n+    } else {\n+      manager->pending_queue_.push_back(std::move(lock_request));\n+    }\n+  }\n+\n+  manager->ProcessQueue(env);\n+}\n+\n+void LockManager::Query(const FunctionCallbackInfo<Value>& args) {\n+  Environment* env = Environment::GetCurrent(args);\n+  Isolate* isolate = env->isolate();\n+  HandleScope scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  Local<Promise::Resolver> resolver;\n+  if (!Promise::Resolver::New(context).ToLocal(&resolver)) {\n+    return;\n+  }\n+  args.GetReturnValue().Set(resolver->GetPromise());\n+\n+  Local<Object> result = Object::New(isolate);\n+  Local<Array> held_list = Array::New(isolate);\n+  Local<Array> pending_list = Array::New(isolate);\n+  LockManager* manager = GetCurrent();\n+\n+  {\n+    Mutex::ScopedLock scoped_lock(manager->mutex_);\n+\n+    uint32_t index = 0;\n+    for (const auto& resource_entry : manager->held_locks_) {\n+      for (const auto& held_lock : resource_entry.second) {\n+        if (held_lock->env() == env) {\n+          Local<Object> lock_info =\n+              CreateLockInfoObject(isolate,\n+                                   context,\n+                                   held_lock->name(),\n+                                   held_lock->mode(),\n+                                   held_lock->client_id());\n+          if (lock_info.IsEmpty()) {\n+            return;\n+          }\n+          held_list->Set(context, index++, lock_info).Check();\n+        }\n+      }\n+    }\n+\n+    index = 0;\n+    for (const auto& pending_request : manager->pending_queue_) {\n+      if (pending_request->env() == env) {\n+        Local<Object> lock_info =\n+            CreateLockInfoObject(isolate,\n+                                 context,\n+                                 pending_request->name(),\n+                                 pending_request->mode(),\n+                                 pending_request->client_id());\n+        if (lock_info.IsEmpty()) {\n+          return;\n+        }\n+        pending_list->Set(context, index++, lock_info).Check();\n+      }\n+    }\n+  }\n+\n+  result->Set(context, FIXED_ONE_BYTE_STRING(isolate, \"held\"), held_list)\n+      .Check();\n+  result->Set(context, FIXED_ONE_BYTE_STRING(isolate, \"pending\"), pending_list)\n+      .Check();\n+\n+  resolver->Resolve(context, result).Check();\n+}\n+\n+// Runs after the user callback (or its returned promise) settles.\n+void LockManager::ReleaseLockAndProcessQueue(Environment* env,\n+                                             std::shared_ptr<Lock> lock,\n+                                             Local<Value> callback_result,\n+                                             bool was_rejected) {\n+  {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+    ReleaseLock(lock.get());\n+  }\n+\n+  Local<Context> context = env->context();\n+\n+  // For stolen locks, the released_promise was already rejected when marked as\n+  // stolen.\n+  if (!lock->is_stolen()) {\n+    if (was_rejected) {\n+      // The callback promise was rejected, so reject the final promise\n+      lock->released_promise()->Reject(context, callback_result).Check();\n+    } else {\n+      // The callback promise was fulfilled, so resolve the final promise\n+      lock->released_promise()->Resolve(context, callback_result).Check();\n+    }\n+  }\n+\n+  ProcessQueue(env);\n+}\n+\n+// Remove a lock from held_locks_ when it's no longer needed\n+void LockManager::ReleaseLock(Lock* lock) {\n+  const std::u16string& resource_name = lock->name();\n+  auto resource_iter = held_locks_.find(resource_name);\n+  if (resource_iter == held_locks_.end()) return;\n+\n+  auto& resource_locks = resource_iter->second;\n+  for (auto lock_iter = resource_locks.begin();\n+       lock_iter != resource_locks.end();\n+       ++lock_iter) {\n+    if (lock_iter->get() == lock) {\n+      resource_locks.erase(lock_iter);\n+      if (resource_locks.empty()) held_locks_.erase(resource_iter);\n+      break;\n+    }\n+  }\n+}\n+\n+// Wakeup of target Environment's event loop\n+void LockManager::WakeEnvironment(Environment* target_env) {\n+  if (target_env == nullptr || target_env->is_stopping()) return;\n+\n+  target_env->SetImmediateThreadsafe([](Environment* env_to_wake) {\n+    if (env_to_wake != nullptr && !env_to_wake->is_stopping()) {\n+      LockManager::GetCurrent()->ProcessQueue(env_to_wake);\n+    }\n+  });\n+}\n+\n+// Remove all held locks and pending requests that belong to an Environment\n+// that is being destroyed\n+void LockManager::CleanupEnvironment(Environment* env_to_cleanup) {\n+  Mutex::ScopedLock scoped_lock(mutex_);\n+\n+  // Remove every held lock that belongs to this Environment.\n+  for (auto resource_iter = held_locks_.begin();\n+       resource_iter != held_locks_.end();) {\n+    auto& resource_locks = resource_iter->second;\n+    for (auto lock_iter = resource_locks.begin();\n+         lock_iter != resource_locks.end();) {\n+      if ((*lock_iter)->env() == env_to_cleanup) {\n+        lock_iter = resource_locks.erase(lock_iter);\n+      } else {\n+        ++lock_iter;\n+      }\n+    }\n+    if (resource_locks.empty()) {\n+      resource_iter = held_locks_.erase(resource_iter);\n+    } else {\n+      ++resource_iter;\n+    }\n+  }\n+\n+  // Remove every pending request submitted by this Environment.\n+  for (auto request_iter = pending_queue_.begin();\n+       request_iter != pending_queue_.end();) {\n+    if ((*request_iter)->env() == env_to_cleanup) {\n+      request_iter = pending_queue_.erase(request_iter);\n+    } else {\n+      ++request_iter;\n+    }\n+  }\n+\n+  // Finally, remove it from registered_envs_\n+  registered_envs_.erase(env_to_cleanup);\n+}\n+\n+// Cleanup hook wrapper\n+void LockManager::OnEnvironmentCleanup(void* arg) {\n+  Environment* env = static_cast<Environment*>(arg);\n+  LockManager::GetCurrent()->CleanupEnvironment(env);\n+}\n+\n+static Local<Object> CreateLockInfoObject(Isolate* isolate,",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2162937281",
        "repo_full_name": "nodejs/node",
        "pr_number": 58666,
        "pr_file": "src/node_locks.cc",
        "discussion_id": "2162937281",
        "commented_code": "@@ -0,0 +1,738 @@\n+#include \"node_locks.h\"\n+\n+#include \"env-inl.h\"\n+#include \"node_errors.h\"\n+#include \"node_external_reference.h\"\n+#include \"node_internals.h\"\n+#include \"util-inl.h\"\n+#include \"v8.h\"\n+\n+namespace node::worker::locks {\n+\n+using node::errors::TryCatchScope;\n+using v8::Array;\n+using v8::Context;\n+using v8::Exception;\n+using v8::External;\n+using v8::Function;\n+using v8::FunctionCallbackInfo;\n+using v8::HandleScope;\n+using v8::Isolate;\n+using v8::Local;\n+using v8::Object;\n+using v8::ObjectTemplate;\n+using v8::Promise;\n+using v8::String;\n+using v8::Value;\n+\n+static constexpr const char* kSharedMode = \"shared\";\n+static constexpr const char* kExclusiveMode = \"exclusive\";\n+static constexpr const char* kLockStolenError = \"LOCK_STOLEN\";\n+\n+static Local<Object> CreateLockInfoObject(Isolate* isolate,\n+                                          Local<Context> context,\n+                                          const std::u16string& name,\n+                                          Lock::Mode mode,\n+                                          const std::string& client_id);\n+\n+Lock::Lock(Environment* env,\n+           const std::u16string& name,\n+           Mode mode,\n+           const std::string& client_id,\n+           Local<Promise::Resolver> waiting,\n+           Local<Promise::Resolver> released)\n+    : env_(env), name_(name), mode_(mode), client_id_(client_id) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+}\n+\n+LockRequest::LockRequest(Environment* env,\n+                         Local<Promise::Resolver> waiting,\n+                         Local<Promise::Resolver> released,\n+                         Local<Function> callback,\n+                         const std::u16string& name,\n+                         Lock::Mode mode,\n+                         const std::string& client_id,\n+                         bool steal,\n+                         bool if_available)\n+    : env_(env),\n+      name_(name),\n+      mode_(mode),\n+      client_id_(client_id),\n+      steal_(steal),\n+      if_available_(if_available) {\n+  waiting_promise_.Reset(env_->isolate(), waiting);\n+  released_promise_.Reset(env_->isolate(), released);\n+  callback_.Reset(env_->isolate(), callback);\n+}\n+\n+bool LockManager::IsGrantable(const LockRequest* request) const {\n+  // Steal requests bypass all normal granting rules\n+  if (request->steal()) return true;\n+\n+  auto held_locks_iter = held_locks_.find(request->name());\n+  // No existing locks for this resource name\n+  if (held_locks_iter == held_locks_.end()) return true;\n+\n+  // Exclusive requests cannot coexist with any existing locks\n+  if (request->mode() == Lock::Mode::Exclusive) return false;\n+\n+  // For shared requests, check if any existing lock is exclusive\n+  for (const auto& existing_lock : held_locks_iter->second) {\n+    if (existing_lock->mode() == Lock::Mode::Exclusive) return false;\n+  }\n+  // All existing locks are shared, so this shared request can be granted\n+  return true;\n+}\n+\n+// Called when the user callback promise fulfills\n+static void OnLockCallbackFulfilled(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  // Extract the LockHolder from V8 External data\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  // Release the lock and continue processing the queue.\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], false);\n+}\n+\n+// Called when the user callback promise rejects\n+static void OnLockCallbackRejected(\n+    const v8::FunctionCallbackInfo<v8::Value>& info) {\n+  HandleScope handle_scope(info.GetIsolate());\n+  Environment* env = Environment::GetCurrent(info);\n+\n+  auto* lock_holder =\n+      static_cast<LockHolder*>(info.Data().As<External>()->Value());\n+  std::shared_ptr<Lock> lock = lock_holder->lock();\n+  delete lock_holder;\n+\n+  LockManager::GetCurrent()->ReleaseLockAndProcessQueue(\n+      env, lock, info[0], true);\n+}\n+\n+void LockManager::CleanupStolenLocks(Environment* env) {\n+  std::vector<std::u16string> resources_to_clean;\n+\n+  // Collect resources to clean\n+  {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    for (auto resource_iter = held_locks_.begin();\n+         resource_iter != held_locks_.end();\n+         ++resource_iter) {\n+      auto& resource_locks = resource_iter->second;\n+      bool has_stolen_from_other_env = false;\n+\n+      // Check if this resource has stolen locks from other environments\n+      for (const auto& lock_ptr : resource_locks) {\n+        if (lock_ptr->is_stolen() && lock_ptr->env() != env) {\n+          has_stolen_from_other_env = true;\n+          break;\n+        }\n+      }\n+\n+      if (has_stolen_from_other_env) {\n+        resources_to_clean.push_back(resource_iter->first);\n+      }\n+    }\n+  }\n+\n+  // Clean up resources\n+  for (const auto& resource_name : resources_to_clean) {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+\n+    auto resource_iter = held_locks_.find(resource_name);\n+    if (resource_iter != held_locks_.end()) {\n+      auto& resource_locks = resource_iter->second;\n+\n+      // Remove stolen locks from other environments\n+      for (auto lock_iter = resource_locks.begin();\n+           lock_iter != resource_locks.end();) {\n+        if ((*lock_iter)->is_stolen() && (*lock_iter)->env() != env) {\n+          lock_iter = resource_locks.erase(lock_iter);\n+        } else {\n+          ++lock_iter;\n+        }\n+      }\n+\n+      if (resource_locks.empty()) {\n+        held_locks_.erase(resource_iter);\n+      }\n+    }\n+  }\n+}\n+\n+/**\n+ * Web Locks algorithm implementation\n+ * https://w3c.github.io/web-locks/#algorithms\n+ */\n+void LockManager::ProcessQueue(Environment* env) {\n+  Isolate* isolate = env->isolate();\n+  HandleScope handle_scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  // Remove locks that were stolen from this Environment first\n+  CleanupStolenLocks(env);\n+\n+  while (true) {\n+    std::unique_ptr<LockRequest> grantable_request;\n+    std::unique_ptr<LockRequest> if_available_request;\n+    std::unordered_set<Environment*> other_envs_to_wake;\n+\n+    {\n+      std::unordered_map<std::u16string, LockRequest*> first_seen_for_resource;\n+\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      for (auto queue_iter = pending_queue_.begin();\n+           queue_iter != pending_queue_.end();\n+           ++queue_iter) {\n+        LockRequest* request = queue_iter->get();\n+\n+        // Collect unique environments to wake up later\n+        if (request->env() != env) {\n+          other_envs_to_wake.insert(request->env());\n+          continue;\n+        }\n+\n+        // During a single pass, the first time we see a resource name is the\n+        // earliest pending request\n+        auto& first_for_resource = first_seen_for_resource[request->name()];\n+        if (first_for_resource == nullptr) {\n+          first_for_resource = request;  // Mark as first seen for this resource\n+        }\n+\n+        bool has_earlier_request_for_same_resource =\n+            (first_for_resource != request);\n+\n+        if (has_earlier_request_for_same_resource || !IsGrantable(request)) {\n+          if (request->if_available()) {\n+            // ifAvailable request when resource not available: grant with null\n+            if_available_request = std::move(*queue_iter);\n+            pending_queue_.erase(queue_iter);\n+            break;\n+          }\n+          continue;\n+        }\n+\n+        // Found a request that can be granted normally\n+        grantable_request = std::move(*queue_iter);\n+        pending_queue_.erase(queue_iter);\n+        break;\n+      }\n+    }\n+\n+    // Wake each environment only once\n+    for (Environment* target_env : other_envs_to_wake) {\n+      WakeEnvironment(target_env);\n+    }\n+\n+    /**\n+     * ifAvailable:\n+     *  Grant the lock only if it is immediately available;\n+     *  otherwise invoke the callback with null and resolve the promises.\n+     *  Check wrapCallback function in locks.js\n+     */\n+    if (if_available_request) {\n+      Local<Value> null_arg = Null(isolate);\n+      Local<Value> callback_result;\n+      {\n+        TryCatchScope try_catch_scope(env);\n+        if (!if_available_request->callback()\n+                 ->Call(context, Undefined(isolate), 1, &null_arg)\n+                 .ToLocal(&callback_result)) {\n+          if_available_request->waiting_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          if_available_request->released_promise()\n+              ->Reject(context, try_catch_scope.Exception())\n+              .Check();\n+          return;\n+        }\n+      }\n+      if_available_request->waiting_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      if_available_request->released_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      return;\n+    }\n+\n+    if (!grantable_request) return;\n+\n+    // Handle steal operations with minimal mutex scope\n+    if (grantable_request->steal()) {\n+      std::unordered_set<Environment*> envs_to_notify;\n+\n+      {\n+        Mutex::ScopedLock scoped_lock(mutex_);\n+        auto held_locks_iter = held_locks_.find(grantable_request->name());\n+        if (held_locks_iter != held_locks_.end()) {\n+          // Mark existing locks as stolen and collect environments to notify\n+          for (auto& existing_lock : held_locks_iter->second) {\n+            existing_lock->mark_stolen();\n+            envs_to_notify.insert(existing_lock->env());\n+\n+            // Immediately reject the stolen lock's released_promise\n+            Local<String> error_string;\n+            if (!String::NewFromUtf8(isolate, kLockStolenError)\n+                     .ToLocal(&error_string)) {\n+              return;\n+            }\n+            Local<Value> error = Exception::Error(error_string);\n+            existing_lock->released_promise()->Reject(context, error).Check();\n+          }\n+\n+          // Remove stolen locks from current environment immediately\n+          for (auto lock_iter = held_locks_iter->second.begin();\n+               lock_iter != held_locks_iter->second.end();) {\n+            if ((*lock_iter)->env() == env) {\n+              lock_iter = held_locks_iter->second.erase(lock_iter);\n+            } else {\n+              ++lock_iter;\n+            }\n+          }\n+\n+          if (held_locks_iter->second.empty()) {\n+            held_locks_.erase(held_locks_iter);\n+          }\n+        }\n+      }\n+\n+      // Wake other environments\n+      for (Environment* target_env : envs_to_notify) {\n+        if (target_env != env) {\n+          WakeEnvironment(target_env);\n+        }\n+      }\n+    }\n+\n+    // Create and store the new granted lock\n+    auto granted_lock =\n+        std::make_shared<Lock>(env,\n+                               grantable_request->name(),\n+                               grantable_request->mode(),\n+                               grantable_request->client_id(),\n+                               grantable_request->waiting_promise(),\n+                               grantable_request->released_promise());\n+    {\n+      Mutex::ScopedLock scoped_lock(mutex_);\n+      held_locks_[grantable_request->name()].push_back(granted_lock);\n+    }\n+\n+    // Call user callback\n+    Local<Object> lock_info_obj =\n+        CreateLockInfoObject(isolate,\n+                             context,\n+                             grantable_request->name(),\n+                             grantable_request->mode(),\n+                             grantable_request->client_id());\n+    if (lock_info_obj.IsEmpty()) {\n+      return;\n+    }\n+    Local<Value> callback_arg = lock_info_obj;\n+    Local<Value> callback_result;\n+    {\n+      TryCatchScope try_catch_scope(env);\n+      if (!grantable_request->callback()\n+               ->Call(context, Undefined(isolate), 1, &callback_arg)\n+               .ToLocal(&callback_result)) {\n+        grantable_request->waiting_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, try_catch_scope.Exception())\n+            .Check();\n+        return;\n+      }\n+    }\n+\n+    // Allocate a LockHolder on the heap to safely manage the lock's lifetime\n+    // until the user's callback promise settles.\n+    auto* fulfill_holder = new LockHolder(granted_lock);\n+    auto* reject_holder = new LockHolder(granted_lock);\n+    Local<Function> on_fulfilled_callback;\n+    Local<Function> on_rejected_callback;\n+\n+    if (!Function::New(context,\n+                       OnLockCallbackFulfilled,\n+                       External::New(isolate, fulfill_holder))\n+             .ToLocal(&on_fulfilled_callback) ||\n+        !Function::New(context,\n+                       OnLockCallbackRejected,\n+                       External::New(isolate, reject_holder))\n+             .ToLocal(&on_rejected_callback)) {\n+      delete fulfill_holder;\n+      delete reject_holder;\n+      return;\n+    }\n+\n+    // Handle promise chain\n+    if (callback_result->IsPromise()) {\n+      Local<Promise> promise = callback_result.As<Promise>();\n+      if (promise->State() == Promise::kRejected) {\n+        Local<Value> rejection_value = promise->Result();\n+        grantable_request->waiting_promise()\n+            ->Reject(context, rejection_value)\n+            .Check();\n+        grantable_request->released_promise()\n+            ->Reject(context, rejection_value)\n+            .Check();\n+        delete fulfill_holder;\n+        delete reject_holder;\n+        {\n+          Mutex::ScopedLock scoped_lock(mutex_);\n+          ReleaseLock(granted_lock.get());\n+        }\n+        ProcessQueue(env);\n+        return;\n+      } else {\n+        grantable_request->waiting_promise()\n+            ->Resolve(context, callback_result)\n+            .Check();\n+        USE(promise->Then(\n+            context, on_fulfilled_callback, on_rejected_callback));\n+      }\n+    } else {\n+      grantable_request->waiting_promise()\n+          ->Resolve(context, callback_result)\n+          .Check();\n+      Local<Value> promise_args[] = {callback_result};\n+      USE(on_fulfilled_callback->Call(\n+          context, Undefined(isolate), 1, promise_args));\n+      delete reject_holder;\n+    }\n+  }\n+}\n+\n+/**\n+ * name        : string   \u2013 resource identifier\n+ * clientId    : string   \u2013 client identifier\n+ * mode        : string   \u2013 lock mode\n+ * steal       : boolean  \u2013 whether to steal existing locks\n+ * ifAvailable : boolean  \u2013 only grant if immediately available\n+ * callback    : Function - JS callback\n+ */\n+void LockManager::Request(const FunctionCallbackInfo<Value>& args) {\n+  Environment* env = Environment::GetCurrent(args);\n+  Isolate* isolate = env->isolate();\n+  HandleScope scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  CHECK_EQ(args.Length(), 6);\n+  CHECK(args[0]->IsString());\n+  CHECK(args[1]->IsString());\n+  CHECK(args[2]->IsString());\n+  CHECK(args[3]->IsBoolean());\n+  CHECK(args[4]->IsBoolean());\n+  CHECK(args[5]->IsFunction());\n+\n+  Local<String> resource_name_str = args[0].As<String>();\n+  TwoByteValue resource_name_utf16(isolate, resource_name_str);\n+  std::u16string resource_name(\n+      reinterpret_cast<const char16_t*>(*resource_name_utf16),\n+      resource_name_utf16.length());\n+  String::Utf8Value client_id_utf8(isolate, args[1]);\n+  std::string client_id(*client_id_utf8);\n+  String::Utf8Value mode_utf8(isolate, args[2]);\n+  std::string mode_str(*mode_utf8);\n+  bool steal = args[3]->BooleanValue(isolate);\n+  bool if_available = args[4]->BooleanValue(isolate);\n+  Local<Function> callback = args[5].As<Function>();\n+\n+  Lock::Mode lock_mode =\n+      mode_str == kSharedMode ? Lock::Mode::Shared : Lock::Mode::Exclusive;\n+\n+  Local<Promise::Resolver> waiting_promise;\n+  if (!Promise::Resolver::New(context).ToLocal(&waiting_promise)) {\n+    return;\n+  }\n+  Local<Promise::Resolver> released_promise;\n+  if (!Promise::Resolver::New(context).ToLocal(&released_promise)) {\n+    return;\n+  }\n+\n+  args.GetReturnValue().Set(released_promise->GetPromise());\n+\n+  LockManager* manager = GetCurrent();\n+  {\n+    Mutex::ScopedLock scoped_lock(manager->mutex_);\n+\n+    // Register cleanup hook for the environment only once\n+    if (manager->registered_envs_.insert(env).second) {\n+      env->AddCleanupHook(LockManager::OnEnvironmentCleanup, env);\n+    }\n+\n+    auto lock_request = std::make_unique<LockRequest>(env,\n+                                                      waiting_promise,\n+                                                      released_promise,\n+                                                      callback,\n+                                                      resource_name,\n+                                                      lock_mode,\n+                                                      client_id,\n+                                                      steal,\n+                                                      if_available);\n+    // Steal requests get priority by going to front of queue\n+    if (steal) {\n+      manager->pending_queue_.emplace_front(std::move(lock_request));\n+    } else {\n+      manager->pending_queue_.push_back(std::move(lock_request));\n+    }\n+  }\n+\n+  manager->ProcessQueue(env);\n+}\n+\n+void LockManager::Query(const FunctionCallbackInfo<Value>& args) {\n+  Environment* env = Environment::GetCurrent(args);\n+  Isolate* isolate = env->isolate();\n+  HandleScope scope(isolate);\n+  Local<Context> context = env->context();\n+\n+  Local<Promise::Resolver> resolver;\n+  if (!Promise::Resolver::New(context).ToLocal(&resolver)) {\n+    return;\n+  }\n+  args.GetReturnValue().Set(resolver->GetPromise());\n+\n+  Local<Object> result = Object::New(isolate);\n+  Local<Array> held_list = Array::New(isolate);\n+  Local<Array> pending_list = Array::New(isolate);\n+  LockManager* manager = GetCurrent();\n+\n+  {\n+    Mutex::ScopedLock scoped_lock(manager->mutex_);\n+\n+    uint32_t index = 0;\n+    for (const auto& resource_entry : manager->held_locks_) {\n+      for (const auto& held_lock : resource_entry.second) {\n+        if (held_lock->env() == env) {\n+          Local<Object> lock_info =\n+              CreateLockInfoObject(isolate,\n+                                   context,\n+                                   held_lock->name(),\n+                                   held_lock->mode(),\n+                                   held_lock->client_id());\n+          if (lock_info.IsEmpty()) {\n+            return;\n+          }\n+          held_list->Set(context, index++, lock_info).Check();\n+        }\n+      }\n+    }\n+\n+    index = 0;\n+    for (const auto& pending_request : manager->pending_queue_) {\n+      if (pending_request->env() == env) {\n+        Local<Object> lock_info =\n+            CreateLockInfoObject(isolate,\n+                                 context,\n+                                 pending_request->name(),\n+                                 pending_request->mode(),\n+                                 pending_request->client_id());\n+        if (lock_info.IsEmpty()) {\n+          return;\n+        }\n+        pending_list->Set(context, index++, lock_info).Check();\n+      }\n+    }\n+  }\n+\n+  result->Set(context, FIXED_ONE_BYTE_STRING(isolate, \"held\"), held_list)\n+      .Check();\n+  result->Set(context, FIXED_ONE_BYTE_STRING(isolate, \"pending\"), pending_list)\n+      .Check();\n+\n+  resolver->Resolve(context, result).Check();\n+}\n+\n+// Runs after the user callback (or its returned promise) settles.\n+void LockManager::ReleaseLockAndProcessQueue(Environment* env,\n+                                             std::shared_ptr<Lock> lock,\n+                                             Local<Value> callback_result,\n+                                             bool was_rejected) {\n+  {\n+    Mutex::ScopedLock scoped_lock(mutex_);\n+    ReleaseLock(lock.get());\n+  }\n+\n+  Local<Context> context = env->context();\n+\n+  // For stolen locks, the released_promise was already rejected when marked as\n+  // stolen.\n+  if (!lock->is_stolen()) {\n+    if (was_rejected) {\n+      // The callback promise was rejected, so reject the final promise\n+      lock->released_promise()->Reject(context, callback_result).Check();\n+    } else {\n+      // The callback promise was fulfilled, so resolve the final promise\n+      lock->released_promise()->Resolve(context, callback_result).Check();\n+    }\n+  }\n+\n+  ProcessQueue(env);\n+}\n+\n+// Remove a lock from held_locks_ when it's no longer needed\n+void LockManager::ReleaseLock(Lock* lock) {\n+  const std::u16string& resource_name = lock->name();\n+  auto resource_iter = held_locks_.find(resource_name);\n+  if (resource_iter == held_locks_.end()) return;\n+\n+  auto& resource_locks = resource_iter->second;\n+  for (auto lock_iter = resource_locks.begin();\n+       lock_iter != resource_locks.end();\n+       ++lock_iter) {\n+    if (lock_iter->get() == lock) {\n+      resource_locks.erase(lock_iter);\n+      if (resource_locks.empty()) held_locks_.erase(resource_iter);\n+      break;\n+    }\n+  }\n+}\n+\n+// Wakeup of target Environment's event loop\n+void LockManager::WakeEnvironment(Environment* target_env) {\n+  if (target_env == nullptr || target_env->is_stopping()) return;\n+\n+  target_env->SetImmediateThreadsafe([](Environment* env_to_wake) {\n+    if (env_to_wake != nullptr && !env_to_wake->is_stopping()) {\n+      LockManager::GetCurrent()->ProcessQueue(env_to_wake);\n+    }\n+  });\n+}\n+\n+// Remove all held locks and pending requests that belong to an Environment\n+// that is being destroyed\n+void LockManager::CleanupEnvironment(Environment* env_to_cleanup) {\n+  Mutex::ScopedLock scoped_lock(mutex_);\n+\n+  // Remove every held lock that belongs to this Environment.\n+  for (auto resource_iter = held_locks_.begin();\n+       resource_iter != held_locks_.end();) {\n+    auto& resource_locks = resource_iter->second;\n+    for (auto lock_iter = resource_locks.begin();\n+         lock_iter != resource_locks.end();) {\n+      if ((*lock_iter)->env() == env_to_cleanup) {\n+        lock_iter = resource_locks.erase(lock_iter);\n+      } else {\n+        ++lock_iter;\n+      }\n+    }\n+    if (resource_locks.empty()) {\n+      resource_iter = held_locks_.erase(resource_iter);\n+    } else {\n+      ++resource_iter;\n+    }\n+  }\n+\n+  // Remove every pending request submitted by this Environment.\n+  for (auto request_iter = pending_queue_.begin();\n+       request_iter != pending_queue_.end();) {\n+    if ((*request_iter)->env() == env_to_cleanup) {\n+      request_iter = pending_queue_.erase(request_iter);\n+    } else {\n+      ++request_iter;\n+    }\n+  }\n+\n+  // Finally, remove it from registered_envs_\n+  registered_envs_.erase(env_to_cleanup);\n+}\n+\n+// Cleanup hook wrapper\n+void LockManager::OnEnvironmentCleanup(void* arg) {\n+  Environment* env = static_cast<Environment*>(arg);\n+  LockManager::GetCurrent()->CleanupEnvironment(env);\n+}\n+\n+static Local<Object> CreateLockInfoObject(Isolate* isolate,",
        "comment_created_at": "2025-06-24T04:31:51+00:00",
        "comment_author": "jasnell",
        "comment_body": "Consider having this return a `MaybeLocal<Object>` to better facilitate error propagation",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2045197814",
    "pr_number": 54364,
    "pr_file": "src/node_code_integrity.cc",
    "created_at": "2025-04-15T18:09:31+00:00",
    "commented_code": "+#include \"node_code_integrity.h\"\n+#include \"env-inl.h\"\n+#include \"node.h\"\n+#include \"node_external_reference.h\"\n+#include \"v8.h\"\n+\n+namespace node {\n+\n+using v8::Boolean;\n+using v8::Context;\n+using v8::FunctionCallbackInfo;\n+using v8::Local;\n+using v8::Object;\n+using v8::Value;\n+\n+namespace per_process {\n+bool isWldpInitialized = false;\n+pfnWldpCanExecuteFile WldpCanExecuteFile;\n+pfnWldpGetApplicationSettingBoolean WldpGetApplicationSettingBoolean;\n+pfnWldpQuerySecurityPolicy WldpQuerySecurityPolicy;\n+}  // namespace per_process\n+\n+namespace code_integrity {\n+\n+static PCWSTR NODEJS = L\"Node.js\";\n+static PCWSTR ENFORCE_CODE_INTEGRITY_SETTING_NAME = L\"EnforceCodeIntegrity\";\n+static PCWSTR DISABLE_INTERPRETIVE_MODE_SETTING_NAME =\n+    L\"DisableInteractiveMode\";\n+\n+void InitWldp(Environment* env) {\n+  if (per_process::isWldpInitialized) {\n+    return;\n+  }\n+\n+  HMODULE wldp_module =\n+      LoadLibraryExA(\"wldp.dll\", nullptr, LOAD_LIBRARY_SEARCH_SYSTEM32);\n+\n+  if (wldp_module == nullptr) {\n+    return env->ThrowError(\"Unable to load wldp.dll\");\n+  }\n+\n+  per_process::WldpCanExecuteFile =\n+      (pfnWldpCanExecuteFile)GetProcAddress(wldp_module, \"WldpCanExecuteFile\");\n+\n+  per_process::WldpGetApplicationSettingBoolean =\n+      (pfnWldpGetApplicationSettingBoolean)GetProcAddress(\n+          wldp_module, \"WldpGetApplicationSettingBoolean\");\n+\n+  per_process::WldpQuerySecurityPolicy =\n+      (pfnWldpQuerySecurityPolicy)GetProcAddress(wldp_module,\n+                                                 \"WldpQuerySecurityPolicy\");\n+\n+  per_process::isWldpInitialized = true;\n+}\n+\n+static void IsFileTrustedBySystemCodeIntegrityPolicy(\n+    const FunctionCallbackInfo<Value>& args) {\n+  CHECK_EQ(args.Length(), 1);\n+  CHECK(args[0]->IsString());\n+\n+  Environment* env = Environment::GetCurrent(args);\n+  if (!per_process::isWldpInitialized) {\n+    InitWldp(env);\n+  }\n+\n+  BufferValue path(env->isolate(), args[0]);\n+  if (*path == nullptr) {\n+    return env->ThrowError(\"path cannot be empty\");\n+  }",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2045197814",
        "repo_full_name": "nodejs/node",
        "pr_number": 54364,
        "pr_file": "src/node_code_integrity.cc",
        "discussion_id": "2045197814",
        "commented_code": "@@ -0,0 +1,237 @@\n+#include \"node_code_integrity.h\"\n+#include \"env-inl.h\"\n+#include \"node.h\"\n+#include \"node_external_reference.h\"\n+#include \"v8.h\"\n+\n+namespace node {\n+\n+using v8::Boolean;\n+using v8::Context;\n+using v8::FunctionCallbackInfo;\n+using v8::Local;\n+using v8::Object;\n+using v8::Value;\n+\n+namespace per_process {\n+bool isWldpInitialized = false;\n+pfnWldpCanExecuteFile WldpCanExecuteFile;\n+pfnWldpGetApplicationSettingBoolean WldpGetApplicationSettingBoolean;\n+pfnWldpQuerySecurityPolicy WldpQuerySecurityPolicy;\n+}  // namespace per_process\n+\n+namespace code_integrity {\n+\n+static PCWSTR NODEJS = L\"Node.js\";\n+static PCWSTR ENFORCE_CODE_INTEGRITY_SETTING_NAME = L\"EnforceCodeIntegrity\";\n+static PCWSTR DISABLE_INTERPRETIVE_MODE_SETTING_NAME =\n+    L\"DisableInteractiveMode\";\n+\n+void InitWldp(Environment* env) {\n+  if (per_process::isWldpInitialized) {\n+    return;\n+  }\n+\n+  HMODULE wldp_module =\n+      LoadLibraryExA(\"wldp.dll\", nullptr, LOAD_LIBRARY_SEARCH_SYSTEM32);\n+\n+  if (wldp_module == nullptr) {\n+    return env->ThrowError(\"Unable to load wldp.dll\");\n+  }\n+\n+  per_process::WldpCanExecuteFile =\n+      (pfnWldpCanExecuteFile)GetProcAddress(wldp_module, \"WldpCanExecuteFile\");\n+\n+  per_process::WldpGetApplicationSettingBoolean =\n+      (pfnWldpGetApplicationSettingBoolean)GetProcAddress(\n+          wldp_module, \"WldpGetApplicationSettingBoolean\");\n+\n+  per_process::WldpQuerySecurityPolicy =\n+      (pfnWldpQuerySecurityPolicy)GetProcAddress(wldp_module,\n+                                                 \"WldpQuerySecurityPolicy\");\n+\n+  per_process::isWldpInitialized = true;\n+}\n+\n+static void IsFileTrustedBySystemCodeIntegrityPolicy(\n+    const FunctionCallbackInfo<Value>& args) {\n+  CHECK_EQ(args.Length(), 1);\n+  CHECK(args[0]->IsString());\n+\n+  Environment* env = Environment::GetCurrent(args);\n+  if (!per_process::isWldpInitialized) {\n+    InitWldp(env);\n+  }\n+\n+  BufferValue path(env->isolate(), args[0]);\n+  if (*path == nullptr) {\n+    return env->ThrowError(\"path cannot be empty\");\n+  }",
        "comment_created_at": "2025-04-15T18:09:31+00:00",
        "comment_author": "anonrig",
        "comment_body": "We mostly call CHECK_NOT_NULL macro for this particular case.\r\n\r\n```suggestion\r\n  CHECK_NOT_NULL(path);\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2067118625",
    "pr_number": 58058,
    "pr_file": "src/node_buffer.cc",
    "created_at": "2025-04-29T18:29:45+00:00",
    "commented_code": "args.GetReturnValue().Set(args[0]);\n }\n \n+bool FastIsUtf8(v8::Local<v8::Value>, Local<Value> buffer) {\n+  TRACK_V8_FAST_API_CALL(\"buffer.isUtf8\");\n+  CHECK(buffer->IsTypedArray());\n+  auto buffer_ = buffer.As<v8::TypedArray>()->Buffer();\n+  auto buffer_data = buffer_->Data();\n+  return simdutf::validate_utf8(reinterpret_cast<const char*>(buffer_data),\n+                                buffer_->ByteLength());",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2067118625",
        "repo_full_name": "nodejs/node",
        "pr_number": 58058,
        "pr_file": "src/node_buffer.cc",
        "discussion_id": "2067118625",
        "commented_code": "@@ -1175,6 +1175,28 @@ void Swap64(const FunctionCallbackInfo<Value>& args) {\n   args.GetReturnValue().Set(args[0]);\n }\n \n+bool FastIsUtf8(v8::Local<v8::Value>, Local<Value> buffer) {\n+  TRACK_V8_FAST_API_CALL(\"buffer.isUtf8\");\n+  CHECK(buffer->IsTypedArray());\n+  auto buffer_ = buffer.As<v8::TypedArray>()->Buffer();\n+  auto buffer_data = buffer_->Data();\n+  return simdutf::validate_utf8(reinterpret_cast<const char*>(buffer_data),\n+                                buffer_->ByteLength());",
        "comment_created_at": "2025-04-29T18:29:45+00:00",
        "comment_author": "Renegade334",
        "comment_body": "This doesn't account for any offset on the backing ArrayBuffer. `ArrayBufferViewContents` is probably needed here.",
        "pr_file_module": null
      },
      {
        "comment_id": "2067842052",
        "repo_full_name": "nodejs/node",
        "pr_number": 58058,
        "pr_file": "src/node_buffer.cc",
        "discussion_id": "2067118625",
        "commented_code": "@@ -1175,6 +1175,28 @@ void Swap64(const FunctionCallbackInfo<Value>& args) {\n   args.GetReturnValue().Set(args[0]);\n }\n \n+bool FastIsUtf8(v8::Local<v8::Value>, Local<Value> buffer) {\n+  TRACK_V8_FAST_API_CALL(\"buffer.isUtf8\");\n+  CHECK(buffer->IsTypedArray());\n+  auto buffer_ = buffer.As<v8::TypedArray>()->Buffer();\n+  auto buffer_data = buffer_->Data();\n+  return simdutf::validate_utf8(reinterpret_cast<const char*>(buffer_data),\n+                                buffer_->ByteLength());",
        "comment_created_at": "2025-04-30T04:40:41+00:00",
        "comment_author": "Renegade334",
        "comment_body": "Come to think of it, the new CFunction signature will allow V8 to chuck any validated argument down the fast path, which includes ArrayBuffers and SharedArrayBuffers.\r\n\r\nFor example, after optimisation, `Buffer.isUtf8(new ArrayBuffer())` currently aborts:\r\n```\r\n  #  .../out/Release/node[782125]: bool node::Buffer::{anonymous}::FastIsUtf8(v8::Local<v8::Value>, v8::Local<v8::Value>) at ../src/node_buffer.cc:1180\r\n  #  Assertion failed: buffer->IsTypedArray()\r\n```\r\n\r\n`ArrayBufferViewContents` would handle all of these cases.",
        "pr_file_module": null
      },
      {
        "comment_id": "2072424102",
        "repo_full_name": "nodejs/node",
        "pr_number": 58058,
        "pr_file": "src/node_buffer.cc",
        "discussion_id": "2067118625",
        "commented_code": "@@ -1175,6 +1175,28 @@ void Swap64(const FunctionCallbackInfo<Value>& args) {\n   args.GetReturnValue().Set(args[0]);\n }\n \n+bool FastIsUtf8(v8::Local<v8::Value>, Local<Value> buffer) {\n+  TRACK_V8_FAST_API_CALL(\"buffer.isUtf8\");\n+  CHECK(buffer->IsTypedArray());\n+  auto buffer_ = buffer.As<v8::TypedArray>()->Buffer();\n+  auto buffer_data = buffer_->Data();\n+  return simdutf::validate_utf8(reinterpret_cast<const char*>(buffer_data),\n+                                buffer_->ByteLength());",
        "comment_created_at": "2025-05-03T16:24:48+00:00",
        "comment_author": "anonrig",
        "comment_body": "Agreed. Updated the pull-request.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2155403042",
    "pr_number": 58758,
    "pr_file": "src/spawn_sync.cc",
    "created_at": "2025-06-18T20:04:09+00:00",
    "commented_code": "void SyncProcessRunner::Spawn(const FunctionCallbackInfo<Value>& args) {\n   Environment* env = Environment::GetCurrent(args);\n+  Local<Context> context = env->context();\n+\n+  std::string resource = \"\";\n+  if (env->permission()->enabled() && args[0]->IsObject()) {\n+    Local<Object> js_options = args[0].As<Object>();\n+    Local<Value> js_file;\n+    if (js_options->Get(context, env->file_string()).ToLocal(&js_file)) {\n+      node::Utf8Value v(env->isolate(), js_file.As<String>());",
    "repo_full_name": "nodejs/node",
    "discussion_comments": [
      {
        "comment_id": "2155403042",
        "repo_full_name": "nodejs/node",
        "pr_number": 58758,
        "pr_file": "src/spawn_sync.cc",
        "discussion_id": "2155403042",
        "commented_code": "@@ -378,8 +378,20 @@ void SyncProcessRunner::RegisterExternalReferences(\n \n void SyncProcessRunner::Spawn(const FunctionCallbackInfo<Value>& args) {\n   Environment* env = Environment::GetCurrent(args);\n+  Local<Context> context = env->context();\n+\n+  std::string resource = \"\";\n+  if (env->permission()->enabled() && args[0]->IsObject()) {\n+    Local<Object> js_options = args[0].As<Object>();\n+    Local<Value> js_file;\n+    if (js_options->Get(context, env->file_string()).ToLocal(&js_file)) {\n+      node::Utf8Value v(env->isolate(), js_file.As<String>());",
        "comment_created_at": "2025-06-18T20:04:09+00:00",
        "comment_author": "geeksilva97",
        "comment_body": "Should we check if `js_file` is a String before calling `js_file.As<String>()`?",
        "pr_file_module": null
      },
      {
        "comment_id": "2155435412",
        "repo_full_name": "nodejs/node",
        "pr_number": 58758,
        "pr_file": "src/spawn_sync.cc",
        "discussion_id": "2155403042",
        "commented_code": "@@ -378,8 +378,20 @@ void SyncProcessRunner::RegisterExternalReferences(\n \n void SyncProcessRunner::Spawn(const FunctionCallbackInfo<Value>& args) {\n   Environment* env = Environment::GetCurrent(args);\n+  Local<Context> context = env->context();\n+\n+  std::string resource = \"\";\n+  if (env->permission()->enabled() && args[0]->IsObject()) {\n+    Local<Object> js_options = args[0].As<Object>();\n+    Local<Value> js_file;\n+    if (js_options->Get(context, env->file_string()).ToLocal(&js_file)) {\n+      node::Utf8Value v(env->isolate(), js_file.As<String>());",
        "comment_created_at": "2025-06-18T20:26:04+00:00",
        "comment_author": "RafaelGSS",
        "comment_body": "Yup, will do that",
        "pr_file_module": null
      }
    ]
  }
]