[
  {
    "discussion_id": "2085560005",
    "pr_number": 10385,
    "pr_file": "ml/backend.go",
    "created_at": "2025-05-12T21:33:26+00:00",
    "commented_code": "Layer(int) Context\n }\n \n+// RopeOpts contains optional parameters for RoPE function\n+type RopeOpts struct {",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "2085560005",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10385,
        "pr_file": "ml/backend.go",
        "discussion_id": "2085560005",
        "commented_code": "@@ -119,6 +119,25 @@ type Context interface {\n \tLayer(int) Context\n }\n \n+// RopeOpts contains optional parameters for RoPE function\n+type RopeOpts struct {",
        "comment_created_at": "2025-05-12T21:33:26+00:00",
        "comment_author": "mxyng",
        "comment_body": "I'd prefer no abbreviations here\r\n```suggestion\r\ntype RopeOptions struct {\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2124632162",
    "pr_number": 10174,
    "pr_file": "server/routes.go",
    "created_at": "2025-06-03T18:34:57+00:00",
    "commented_code": "continue\n \t\t\t}\n \t\t}\n-\n+\t\tcap, err := GetModel(n.String())\n+\t\tif err != nil {\n+\t\t\tslog.Warn(\"bad model details\", \"name\", n, \"error\", err)\n+\t\t\tcontinue\n+\t\t}",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "2124632162",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10174,
        "pr_file": "server/routes.go",
        "discussion_id": "2124632162",
        "commented_code": "@@ -921,14 +921,19 @@ func (s *Server) ListHandler(c *gin.Context) {\n \t\t\t\tcontinue\n \t\t\t}\n \t\t}\n-\n+\t\tcap, err := GetModel(n.String())\n+\t\tif err != nil {\n+\t\t\tslog.Warn(\"bad model details\", \"name\", n, \"error\", err)\n+\t\t\tcontinue\n+\t\t}",
        "comment_created_at": "2025-06-03T18:34:57+00:00",
        "comment_author": "BruceMacD",
        "comment_body": "```suggestion\r\n\t\tmodel, err := GetModel(n.String())\r\n\t\tif err != nil {\r\n\t\t\tslog.Warn(\"bad model details\", \"name\", n, \"error\", err)\r\n\t\t\tcontinue\r\n\t\t}\r\n```\r\n\r\nThe variable name should reference the actual type here",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2109712605",
    "pr_number": 10584,
    "pr_file": "server/thinking.go",
    "created_at": "2025-05-27T16:59:02+00:00",
    "commented_code": "+package server\n+\n+import (\n+\t\"strings\"\n+\t\"text/template\"\n+\t\"text/template/parse\"\n+\t\"unicode\"\n+)\n+\n+type thinkingParseState int",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "2109712605",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10584,
        "pr_file": "server/thinking.go",
        "discussion_id": "2109712605",
        "commented_code": "@@ -0,0 +1,300 @@\n+package server\n+\n+import (\n+\t\"strings\"\n+\t\"text/template\"\n+\t\"text/template/parse\"\n+\t\"unicode\"\n+)\n+\n+type thinkingParseState int",
        "comment_created_at": "2025-05-27T16:59:02+00:00",
        "comment_author": "ParthSareen",
        "comment_body": "nit: Can just do `thinkingState` to minimize verbosity",
        "pr_file_module": null
      },
      {
        "comment_id": "2109847551",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10584,
        "pr_file": "server/thinking.go",
        "discussion_id": "2109712605",
        "commented_code": "@@ -0,0 +1,300 @@\n+package server\n+\n+import (\n+\t\"strings\"\n+\t\"text/template\"\n+\t\"text/template/parse\"\n+\t\"unicode\"\n+)\n+\n+type thinkingParseState int",
        "comment_created_at": "2025-05-27T18:10:54+00:00",
        "comment_author": "drifkin",
        "comment_body": "ooh yes, much nicer, esp because all the individual states are simplified as well and those names are strewn all over this come. Updating",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2083631193",
    "pr_number": 10415,
    "pr_file": "server/tools.go",
    "created_at": "2025-05-11T21:59:14+00:00",
    "commented_code": "+package server\n+\n+import (\n+\t\"bytes\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"strings\"\n+\tgotmpl \"text/template\"\n+\n+\tjsonv2 \"github.com/go-json-experiment/json\"\n+\tjsontext \"github.com/go-json-experiment/json/jsontext\"\n+\n+\t\"github.com/ollama/ollama/api\"\n+)\n+\n+type State int\n+\n+// TODO: potentially coalesce states\n+const (\n+\tSendTokens State = iota\n+\tGreedyToolWithPrefix\n+\tGreedyToolNoPrefix\n+\tForceTools\n+\tToolSuffix\n+\tContainsPrefix\n+\tPartialPrefix\n+\tNotPartialPrefix\n+\tDone\n+)\n+\n+type ExternalState int\n+\n+const (\n+\tToolCallFound ExternalState = iota\n+\tToolCallSendPartial\n+\tToolCallAccumulate\n+\tToolCallSendTokens\n+)\n+\n+func (s ExternalState) String() string {\n+\tswitch s {\n+\tcase ToolCallFound:\n+\t\treturn \"ToolCallFound\"\n+\tcase ToolCallSendPartial:\n+\t\treturn \"ToolCallSendPartial\"\n+\tcase ToolCallAccumulate:\n+\t\treturn \"ToolCallAccumulate\"\n+\tcase ToolCallSendTokens:\n+\t\treturn \"ToolCallSendTokens\"\n+\tdefault:\n+\t\treturn fmt.Sprintf(\"Unknown ExternalState (%d)\", s)\n+\t}\n+}\n+\n+func (s State) String() string {\n+\tswitch s {\n+\tcase SendTokens:\n+\t\treturn \"SendTokens\"\n+\tcase GreedyToolWithPrefix:\n+\t\treturn \"GreedyToolWithPrefix\"\n+\tcase GreedyToolNoPrefix:\n+\t\treturn \"GreedyToolNoPrefix\"\n+\tcase ForceTools:\n+\t\treturn \"ForceTools\"\n+\tcase ToolSuffix:\n+\t\treturn \"ToolSuffix\"\n+\tcase PartialPrefix:\n+\t\treturn \"PossiblePrefix\"\n+\tcase Done:\n+\t\treturn \"Done\"\n+\tcase ContainsPrefix:\n+\t\treturn \"PartialPrefix\"\n+\tdefault:\n+\t\treturn fmt.Sprintf(\"Unknown State (%d)\", s)\n+\t}\n+}\n+\n+// TODO: simplify if possible\n+type ToolParser struct {\n+\ttmpl        *gotmpl.Template\n+\tstate       State\n+\tsb          *strings.Builder\n+\ttoolPrefix  string\n+\ttoolIndex   int\n+\tParserState ExternalState\n+\tDone        bool\n+}\n+\n+// ? move to a separate file\n+// parseJSONToolCalls attempts to parse a JSON string into a slice of ToolCalls.\n+// Returns parsed tool calls, a boolean indicating if the JSON is incomplete, and a boolean indicating if the tool calls were found\n+func (p *ToolParser) parseJSONToolCalls(s string) ([]api.ToolCall, bool, bool) {\n+\tfmt.Printf(\"attempting to parse JSON tool calls: input=%s\n\", s)\n+\n+\tvar b bytes.Buffer\n+\tif err := p.tmpl.Execute(&b, map[string][]api.ToolCall{\n+\t\t\"ToolCalls\": {\n+\t\t\t{\n+\t\t\t\tFunction: api.ToolCallFunction{\n+\t\t\t\t\tName: \"@@name@@\",\n+\t\t\t\t\tArguments: api.ToolCallFunctionArguments{\n+\t\t\t\t\t\t\"@@argument@@\": 1,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t}); err != nil {\n+\t\tfmt.Printf(\"failed to execute template: error=%v\n\", err)\n+\t\treturn nil, false, false\n+\t}\n+\n+\t// this can be either a map or an array\n+\tvar temp any\n+\terr := jsonv2.Unmarshal(b.Bytes(), &temp)\n+\tif err != nil {\n+\t\tfmt.Printf(\"failed to unmarshal template: error=%v\n\", err)\n+\t\treturn nil, false, false\n+\t}\n+\n+\tvar collect func(any) []map[string]any\n+\tcollect = func(obj any) (all []map[string]any) {\n+\t\tswitch o := obj.(type) {\n+\t\tcase map[string]any:\n+\t\t\tall = append(all, o)\n+\t\t\tfor _, v := range o {\n+\t\t\t\tall = append(all, collect(v)...)\n+\t\t\t}\n+\t\tcase []any:\n+\t\t\tfor _, v := range o {\n+\t\t\t\tall = append(all, collect(v)...)\n+\t\t\t}\n+\t\tdefault:\n+\t\t\t// TODO: err or fallback\n+\t\t\tfmt.Printf(\"collect encountered unknown type: type=%T\n\", obj)\n+\t\t\treturn nil\n+\t\t}\n+\n+\t\treturn all\n+\t}\n+\n+\tvar templateObjects []map[string]any\n+\tswitch t := temp.(type) {\n+\tcase map[string]any:\n+\t\ttemplateObjects = []map[string]any{t}\n+\tcase []map[string]any:\n+\t\ttemplateObjects = t\n+\t// ! fallback?\n+\tcase []any:\n+\t\ttemplateObjects = collect(t)\n+\t}\n+\tif len(templateObjects) == 0 {\n+\t\tfmt.Println(\"no template objects found\")\n+\t\treturn nil, false, false\n+\t}\n+\n+\t// find the keys that correspond to the name and arguments fields\n+\tvar name, arguments string\n+\tfor k, v := range templateObjects[0] {\n+\t\tswitch v.(type) {\n+\t\tcase string:\n+\t\t\tname = k\n+\t\t\tfmt.Printf(\"found name field: key=%s\n\", k)\n+\t\tcase map[string]any:\n+\t\t\targuments = k\n+\t\t\tfmt.Printf(\"found arguments field: key=%s\n\", k)\n+\t\t}\n+\t}\n+\n+\tif name == \"\" || arguments == \"\" {\n+\t\tfmt.Printf(\"missing required fields: name_found=%v arguments_found=%v\n\", name != \"\", arguments != \"\")\n+\t\treturn nil, false, false\n+\t}\n+\n+\t// TODO: there is probably some underlying repeat work here to avoid\n+\t// This incrementally decodes the JSON string and returns the first parsedobject\n+\tdec := jsontext.NewDecoder(strings.NewReader(s))\n+\tif got, err := dec.ReadValue(); err == nil {\n+\t\ts = got.String()\n+\t\tfmt.Printf(\"decoded JSON value: value=%s\n\", s)\n+\t}\n+\n+\tvar responseObjects any\n+\terr = jsonv2.Unmarshal([]byte(s), &responseObjects)\n+\tif err != nil {\n+\t\tif errors.Is(err, io.ErrUnexpectedEOF) || err.Error() == \"unexpected end of JSON input\" {\n+\t\t\tfmt.Println(\"incomplete JSON detected\")\n+\t\t\treturn nil, true, false\n+\t\t} else {\n+\t\t\tfmt.Printf(\"failed to unmarshal response: error=%v\n\", err)\n+\t\t\treturn nil, false, false\n+\t\t}\n+\t}\n+\n+\tvar objs []map[string]any\n+\tobjs = append(objs, collect(responseObjects)...)\n+\tif len(objs) == 0 {\n+\t\treturn nil, false, false\n+\t}\n+\n+\tfmt.Printf(\"collected objects: count=%d\n\", len(objs))\n+\n+\tvar toolCalls []api.ToolCall\n+\tfor _, kv := range objs {\n+\t\tn, nok := kv[name].(string)\n+\t\ta, aok := kv[arguments].(map[string]any)\n+\t\tif nok && aok {\n+\t\t\tfmt.Printf(\"found valid tool call: name=%s\n\", n)\n+\t\t\ttoolCalls = append(toolCalls, api.ToolCall{\n+\t\t\t\tFunction: api.ToolCallFunction{\n+\t\t\t\t\tName:      n,\n+\t\t\t\t\tArguments: a,\n+\t\t\t\t},\n+\t\t\t})\n+\t\t}\n+\t}\n+\n+\tfmt.Printf(\"parsed tool calls: count=%d\n\", len(toolCalls))\n+\treturn toolCalls, false, true\n+}\n+\n+// TODO: clean up the boundary of internal and external state transitions\n+func (p *ToolParser) updateStateAfterJSONParse(ok bool, partial bool, tcs []api.ToolCall) {\n+\tfmt.Printf(\"updating output state: ok=%v partial=%v tool_calls=%d current_state=%s\n\", ok, partial, len(tcs), p.state)\n+\n+\t// state transition logic\n+\tswitch {\n+\tcase !ok && !partial && p.state == ForceTools:\n+\t\t// force partial tool if we have a prefix\n+\t\t// no op and stay in force tools\n+\t\tp.sb.Reset()\n+\tcase !ok && !partial:\n+\t\tif p.state == GreedyToolNoPrefix {\n+\t\t\tp.state = Done\n+\t\t\t// ? the output parser state is the same even though internal can we not leak the external state?\n+\t\t\tp.Done = true\n+\t\t}\n+\t\tif p.state == GreedyToolWithPrefix {\n+\t\t\tp.state = SendTokens\n+\t\t}\n+\t\tif p.state == PartialPrefix {\n+\t\t\tp.state = NotPartialPrefix\n+\t\t}\n+\tcase !ok && partial:\n+\t\t// acucumulate\n+\n+\tcase len(tcs) > 0:\n+\t\t// do not parse again in the greedy JSON case as soon as we have a tool call\n+\t\tp.sb.Reset()\n+\t}\n+\tp.updateExternalState(tcs)\n+\tfmt.Printf(\"state updated: new_state=%s parser_state=%s\n\", p.state, p.ParserState)\n+}\n+\n+func (p *ToolParser) updateExternalState(tcs []api.ToolCall) {\n+\tfmt.Printf(\"updating external state: current_state=%s tool_calls=%d\n\", p.state, len(tcs))\n+\n+\tswitch {\n+\tcase len(tcs) > 0:\n+\t\t// do not parse again in the greedy JSON case as soon as we have a tool call\n+\t\tif p.state == GreedyToolWithPrefix {\n+\t\t\tp.state = SendTokens\n+\t\t} else if p.state == GreedyToolNoPrefix {\n+\t\t\tp.state = Done\n+\t\t\tp.Done = true\n+\t\t}\n+\t\tp.ParserState = ToolCallFound\n+\tcase p.state == GreedyToolWithPrefix || p.state == GreedyToolNoPrefix ||\n+\t\tp.state == ToolSuffix || p.state == PartialPrefix ||\n+\t\t(p.state == ForceTools && len(tcs) == 0):\n+\t\tp.ParserState = ToolCallAccumulate\n+\tcase p.state == ContainsPrefix:\n+\t\tp.ParserState = ToolCallSendPartial\n+\tcase p.state == SendTokens || p.state == Done:\n+\t\tp.ParserState = ToolCallSendTokens\n+\tcase p.state == NotPartialPrefix:\n+\t\tp.ParserState = ToolCallSendPartial\n+\tdefault:\n+\t\tp.ParserState = ToolCallSendTokens\n+\t\tp.sb.Reset()\n+\t\tp.state = SendTokens\n+\t}\n+}\n+\n+// string, and if it has a prefix\n+func (p *ToolParser) checkPrefix(s string) (string, bool) {\n+\tfmt.Printf(\"checking prefix: input=%s prefix=%s\n\", s, p.toolPrefix)\n+\n+\tif p.toolPrefix == \"\" {\n+\t\treturn s, true\n+\t}\n+\toriginal := s\n+\ts, hasPrefix := strings.CutPrefix(s, p.toolPrefix)\n+\tif hasPrefix {\n+\t\tp.state = ForceTools\n+\t\tfmt.Printf(\"found exact prefix match: remaining=%s\n\", s)\n+\t\t// partial tool possibly - accumulate\n+\t} else if suffixOverlap(s, p.toolPrefix) > 0 {\n+\t\tp.state = PartialPrefix\n+\t\tfmt.Printf(\"found partial prefix: remaining=%s\n\", s)\n+\t\treturn \"\", false\n+\t\t// the case where \"token<tool_call>\" - send \"token\" back\n+\t\t// accounts for spaces in prefix or suffix to avoid breaking cache\n+\t} else if strings.Contains(original, p.toolPrefix) {\n+\t\tidx := strings.Index(original, p.toolPrefix)\n+\t\tif idx != -1 {\n+\t\t\t// still keeps the prefix\n+\t\t\tp.state = ContainsPrefix\n+\t\t\tp.sb.Reset()\n+\t\t\t// todo: see if there is a simpler way for this\n+\t\t\tidx2 := strings.Index(s, p.toolPrefix)\n+\t\t\t// buffer now only has the prefix\n+\t\t\tp.sb.WriteString(s[idx2:])\n+\t\t\tfmt.Printf(\"found prefix in middle: prefix_start=%d content_before=%s\n\", idx, original[:idx])\n+\t\t\treturn original[:idx], false\n+\t\t}\n+\t}\n+\n+\treturn s, true\n+}\n+\n+// TODO: simplify the flow of this function\n+// ParseToolCalls extracts tool calls from a string using a tool token prefix or direct JSON parsing.\n+// Returns tool calls, whether parsing is incomplete, and any errors.\n+func (p *ToolParser) ParseToolCalls(s string) ([]api.ToolCall, string) {\n+\tfmt.Printf(\"parsing tool calls: input=%s current_state=%s\n\", s, p.state)\n+\n+\tp.sb.WriteString(s)\n+\ts = p.sb.String()\n+\n+\ts = strings.TrimSpace(s)\n+\n+\tif len(s) == 0 {\n+\t\tp.updateExternalState(nil)\n+\t\treturn nil, \"\"\n+\t}\n+\n+\ts, cont := p.checkPrefix(s)\n+\tif !cont {\n+\t\tp.updateExternalState(nil)\n+\t\tif p.state == ContainsPrefix {\n+\t\t\tfmt.Printf(\"returning partial prefix: remaining=%s\n\", s)\n+\t\t\treturn nil, s\n+\t\t}\n+\t\t// * we'd be returning here for just accumulating with possible prefix\n+\t\t// * ext state is accumulation\n+\t\treturn nil, \"\"\n+\t}\n+\t// * lets say the check fails here and now we're still in external state accumulation here\n+\n+\t// stay in SendTokens unless we have a prefix\n+\tif p.state == SendTokens {\n+\t\tp.updateExternalState(nil)\n+\t\tp.sb.Reset()\n+\t\tfmt.Printf(\"returning send tokens: remaining=%s\n\", s)\n+\t\treturn nil, s\n+\t}\n+\n+\t// * we'd parse here as json to see if it's a tool call\n+\ttcs, partial, ok := p.parseJSONToolCalls(s)\n+\t// * it would not be a tool call here\n+\tp.updateStateAfterJSONParse(ok, partial, tcs)\n+\tif !ok {\n+\t\t// * and so we should send the data here\n+\t\t// * we also need to move out of that internal state after sending the tokens\n+\t\tif p.state == NotPartialPrefix {\n+\t\t\tp.state = SendTokens\n+\t\t\t// the string would have acc until here\n+\t\t\treturn nil, p.sb.String()\n+\t\t}\n+\t\treturn nil, \"\"\n+\t}\n+\tfor _, tc := range tcs {\n+\t\ttc.Function.Index = p.toolIndex\n+\t\tp.toolIndex++\n+\t}\n+\tfmt.Printf(\"finished parsing tool calls: tool_calls_found=%d\n\", len(tcs))\n+\treturn tcs, \"\"\n+}\n+\n+func suffixOverlap(s, delim string) int {\n+\tmax := min(len(delim), len(s))\n+\tfor i := max; i > 0; i-- {\n+\t\tif strings.HasSuffix(s, delim[:i]) {\n+\t\t\treturn i\n+\t\t}\n+\t}\n+\treturn 0\n+}\n+\n+func NewToolParser(model *Model) *ToolParser {\n+\t// TODO: use new template parsing to get all tokens for the prefix\n+\ttemplateToolPrefix, _ := ToolPrefix(model.Template.Template)",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "2083631193",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10415,
        "pr_file": "server/tools.go",
        "discussion_id": "2083631193",
        "commented_code": "@@ -0,0 +1,414 @@\n+package server\n+\n+import (\n+\t\"bytes\"\n+\t\"errors\"\n+\t\"fmt\"\n+\t\"io\"\n+\t\"strings\"\n+\tgotmpl \"text/template\"\n+\n+\tjsonv2 \"github.com/go-json-experiment/json\"\n+\tjsontext \"github.com/go-json-experiment/json/jsontext\"\n+\n+\t\"github.com/ollama/ollama/api\"\n+)\n+\n+type State int\n+\n+// TODO: potentially coalesce states\n+const (\n+\tSendTokens State = iota\n+\tGreedyToolWithPrefix\n+\tGreedyToolNoPrefix\n+\tForceTools\n+\tToolSuffix\n+\tContainsPrefix\n+\tPartialPrefix\n+\tNotPartialPrefix\n+\tDone\n+)\n+\n+type ExternalState int\n+\n+const (\n+\tToolCallFound ExternalState = iota\n+\tToolCallSendPartial\n+\tToolCallAccumulate\n+\tToolCallSendTokens\n+)\n+\n+func (s ExternalState) String() string {\n+\tswitch s {\n+\tcase ToolCallFound:\n+\t\treturn \"ToolCallFound\"\n+\tcase ToolCallSendPartial:\n+\t\treturn \"ToolCallSendPartial\"\n+\tcase ToolCallAccumulate:\n+\t\treturn \"ToolCallAccumulate\"\n+\tcase ToolCallSendTokens:\n+\t\treturn \"ToolCallSendTokens\"\n+\tdefault:\n+\t\treturn fmt.Sprintf(\"Unknown ExternalState (%d)\", s)\n+\t}\n+}\n+\n+func (s State) String() string {\n+\tswitch s {\n+\tcase SendTokens:\n+\t\treturn \"SendTokens\"\n+\tcase GreedyToolWithPrefix:\n+\t\treturn \"GreedyToolWithPrefix\"\n+\tcase GreedyToolNoPrefix:\n+\t\treturn \"GreedyToolNoPrefix\"\n+\tcase ForceTools:\n+\t\treturn \"ForceTools\"\n+\tcase ToolSuffix:\n+\t\treturn \"ToolSuffix\"\n+\tcase PartialPrefix:\n+\t\treturn \"PossiblePrefix\"\n+\tcase Done:\n+\t\treturn \"Done\"\n+\tcase ContainsPrefix:\n+\t\treturn \"PartialPrefix\"\n+\tdefault:\n+\t\treturn fmt.Sprintf(\"Unknown State (%d)\", s)\n+\t}\n+}\n+\n+// TODO: simplify if possible\n+type ToolParser struct {\n+\ttmpl        *gotmpl.Template\n+\tstate       State\n+\tsb          *strings.Builder\n+\ttoolPrefix  string\n+\ttoolIndex   int\n+\tParserState ExternalState\n+\tDone        bool\n+}\n+\n+// ? move to a separate file\n+// parseJSONToolCalls attempts to parse a JSON string into a slice of ToolCalls.\n+// Returns parsed tool calls, a boolean indicating if the JSON is incomplete, and a boolean indicating if the tool calls were found\n+func (p *ToolParser) parseJSONToolCalls(s string) ([]api.ToolCall, bool, bool) {\n+\tfmt.Printf(\"attempting to parse JSON tool calls: input=%s\\n\", s)\n+\n+\tvar b bytes.Buffer\n+\tif err := p.tmpl.Execute(&b, map[string][]api.ToolCall{\n+\t\t\"ToolCalls\": {\n+\t\t\t{\n+\t\t\t\tFunction: api.ToolCallFunction{\n+\t\t\t\t\tName: \"@@name@@\",\n+\t\t\t\t\tArguments: api.ToolCallFunctionArguments{\n+\t\t\t\t\t\t\"@@argument@@\": 1,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t}); err != nil {\n+\t\tfmt.Printf(\"failed to execute template: error=%v\\n\", err)\n+\t\treturn nil, false, false\n+\t}\n+\n+\t// this can be either a map or an array\n+\tvar temp any\n+\terr := jsonv2.Unmarshal(b.Bytes(), &temp)\n+\tif err != nil {\n+\t\tfmt.Printf(\"failed to unmarshal template: error=%v\\n\", err)\n+\t\treturn nil, false, false\n+\t}\n+\n+\tvar collect func(any) []map[string]any\n+\tcollect = func(obj any) (all []map[string]any) {\n+\t\tswitch o := obj.(type) {\n+\t\tcase map[string]any:\n+\t\t\tall = append(all, o)\n+\t\t\tfor _, v := range o {\n+\t\t\t\tall = append(all, collect(v)...)\n+\t\t\t}\n+\t\tcase []any:\n+\t\t\tfor _, v := range o {\n+\t\t\t\tall = append(all, collect(v)...)\n+\t\t\t}\n+\t\tdefault:\n+\t\t\t// TODO: err or fallback\n+\t\t\tfmt.Printf(\"collect encountered unknown type: type=%T\\n\", obj)\n+\t\t\treturn nil\n+\t\t}\n+\n+\t\treturn all\n+\t}\n+\n+\tvar templateObjects []map[string]any\n+\tswitch t := temp.(type) {\n+\tcase map[string]any:\n+\t\ttemplateObjects = []map[string]any{t}\n+\tcase []map[string]any:\n+\t\ttemplateObjects = t\n+\t// ! fallback?\n+\tcase []any:\n+\t\ttemplateObjects = collect(t)\n+\t}\n+\tif len(templateObjects) == 0 {\n+\t\tfmt.Println(\"no template objects found\")\n+\t\treturn nil, false, false\n+\t}\n+\n+\t// find the keys that correspond to the name and arguments fields\n+\tvar name, arguments string\n+\tfor k, v := range templateObjects[0] {\n+\t\tswitch v.(type) {\n+\t\tcase string:\n+\t\t\tname = k\n+\t\t\tfmt.Printf(\"found name field: key=%s\\n\", k)\n+\t\tcase map[string]any:\n+\t\t\targuments = k\n+\t\t\tfmt.Printf(\"found arguments field: key=%s\\n\", k)\n+\t\t}\n+\t}\n+\n+\tif name == \"\" || arguments == \"\" {\n+\t\tfmt.Printf(\"missing required fields: name_found=%v arguments_found=%v\\n\", name != \"\", arguments != \"\")\n+\t\treturn nil, false, false\n+\t}\n+\n+\t// TODO: there is probably some underlying repeat work here to avoid\n+\t// This incrementally decodes the JSON string and returns the first parsedobject\n+\tdec := jsontext.NewDecoder(strings.NewReader(s))\n+\tif got, err := dec.ReadValue(); err == nil {\n+\t\ts = got.String()\n+\t\tfmt.Printf(\"decoded JSON value: value=%s\\n\", s)\n+\t}\n+\n+\tvar responseObjects any\n+\terr = jsonv2.Unmarshal([]byte(s), &responseObjects)\n+\tif err != nil {\n+\t\tif errors.Is(err, io.ErrUnexpectedEOF) || err.Error() == \"unexpected end of JSON input\" {\n+\t\t\tfmt.Println(\"incomplete JSON detected\")\n+\t\t\treturn nil, true, false\n+\t\t} else {\n+\t\t\tfmt.Printf(\"failed to unmarshal response: error=%v\\n\", err)\n+\t\t\treturn nil, false, false\n+\t\t}\n+\t}\n+\n+\tvar objs []map[string]any\n+\tobjs = append(objs, collect(responseObjects)...)\n+\tif len(objs) == 0 {\n+\t\treturn nil, false, false\n+\t}\n+\n+\tfmt.Printf(\"collected objects: count=%d\\n\", len(objs))\n+\n+\tvar toolCalls []api.ToolCall\n+\tfor _, kv := range objs {\n+\t\tn, nok := kv[name].(string)\n+\t\ta, aok := kv[arguments].(map[string]any)\n+\t\tif nok && aok {\n+\t\t\tfmt.Printf(\"found valid tool call: name=%s\\n\", n)\n+\t\t\ttoolCalls = append(toolCalls, api.ToolCall{\n+\t\t\t\tFunction: api.ToolCallFunction{\n+\t\t\t\t\tName:      n,\n+\t\t\t\t\tArguments: a,\n+\t\t\t\t},\n+\t\t\t})\n+\t\t}\n+\t}\n+\n+\tfmt.Printf(\"parsed tool calls: count=%d\\n\", len(toolCalls))\n+\treturn toolCalls, false, true\n+}\n+\n+// TODO: clean up the boundary of internal and external state transitions\n+func (p *ToolParser) updateStateAfterJSONParse(ok bool, partial bool, tcs []api.ToolCall) {\n+\tfmt.Printf(\"updating output state: ok=%v partial=%v tool_calls=%d current_state=%s\\n\", ok, partial, len(tcs), p.state)\n+\n+\t// state transition logic\n+\tswitch {\n+\tcase !ok && !partial && p.state == ForceTools:\n+\t\t// force partial tool if we have a prefix\n+\t\t// no op and stay in force tools\n+\t\tp.sb.Reset()\n+\tcase !ok && !partial:\n+\t\tif p.state == GreedyToolNoPrefix {\n+\t\t\tp.state = Done\n+\t\t\t// ? the output parser state is the same even though internal can we not leak the external state?\n+\t\t\tp.Done = true\n+\t\t}\n+\t\tif p.state == GreedyToolWithPrefix {\n+\t\t\tp.state = SendTokens\n+\t\t}\n+\t\tif p.state == PartialPrefix {\n+\t\t\tp.state = NotPartialPrefix\n+\t\t}\n+\tcase !ok && partial:\n+\t\t// acucumulate\n+\n+\tcase len(tcs) > 0:\n+\t\t// do not parse again in the greedy JSON case as soon as we have a tool call\n+\t\tp.sb.Reset()\n+\t}\n+\tp.updateExternalState(tcs)\n+\tfmt.Printf(\"state updated: new_state=%s parser_state=%s\\n\", p.state, p.ParserState)\n+}\n+\n+func (p *ToolParser) updateExternalState(tcs []api.ToolCall) {\n+\tfmt.Printf(\"updating external state: current_state=%s tool_calls=%d\\n\", p.state, len(tcs))\n+\n+\tswitch {\n+\tcase len(tcs) > 0:\n+\t\t// do not parse again in the greedy JSON case as soon as we have a tool call\n+\t\tif p.state == GreedyToolWithPrefix {\n+\t\t\tp.state = SendTokens\n+\t\t} else if p.state == GreedyToolNoPrefix {\n+\t\t\tp.state = Done\n+\t\t\tp.Done = true\n+\t\t}\n+\t\tp.ParserState = ToolCallFound\n+\tcase p.state == GreedyToolWithPrefix || p.state == GreedyToolNoPrefix ||\n+\t\tp.state == ToolSuffix || p.state == PartialPrefix ||\n+\t\t(p.state == ForceTools && len(tcs) == 0):\n+\t\tp.ParserState = ToolCallAccumulate\n+\tcase p.state == ContainsPrefix:\n+\t\tp.ParserState = ToolCallSendPartial\n+\tcase p.state == SendTokens || p.state == Done:\n+\t\tp.ParserState = ToolCallSendTokens\n+\tcase p.state == NotPartialPrefix:\n+\t\tp.ParserState = ToolCallSendPartial\n+\tdefault:\n+\t\tp.ParserState = ToolCallSendTokens\n+\t\tp.sb.Reset()\n+\t\tp.state = SendTokens\n+\t}\n+}\n+\n+// string, and if it has a prefix\n+func (p *ToolParser) checkPrefix(s string) (string, bool) {\n+\tfmt.Printf(\"checking prefix: input=%s prefix=%s\\n\", s, p.toolPrefix)\n+\n+\tif p.toolPrefix == \"\" {\n+\t\treturn s, true\n+\t}\n+\toriginal := s\n+\ts, hasPrefix := strings.CutPrefix(s, p.toolPrefix)\n+\tif hasPrefix {\n+\t\tp.state = ForceTools\n+\t\tfmt.Printf(\"found exact prefix match: remaining=%s\\n\", s)\n+\t\t// partial tool possibly - accumulate\n+\t} else if suffixOverlap(s, p.toolPrefix) > 0 {\n+\t\tp.state = PartialPrefix\n+\t\tfmt.Printf(\"found partial prefix: remaining=%s\\n\", s)\n+\t\treturn \"\", false\n+\t\t// the case where \"token<tool_call>\" - send \"token\" back\n+\t\t// accounts for spaces in prefix or suffix to avoid breaking cache\n+\t} else if strings.Contains(original, p.toolPrefix) {\n+\t\tidx := strings.Index(original, p.toolPrefix)\n+\t\tif idx != -1 {\n+\t\t\t// still keeps the prefix\n+\t\t\tp.state = ContainsPrefix\n+\t\t\tp.sb.Reset()\n+\t\t\t// todo: see if there is a simpler way for this\n+\t\t\tidx2 := strings.Index(s, p.toolPrefix)\n+\t\t\t// buffer now only has the prefix\n+\t\t\tp.sb.WriteString(s[idx2:])\n+\t\t\tfmt.Printf(\"found prefix in middle: prefix_start=%d content_before=%s\\n\", idx, original[:idx])\n+\t\t\treturn original[:idx], false\n+\t\t}\n+\t}\n+\n+\treturn s, true\n+}\n+\n+// TODO: simplify the flow of this function\n+// ParseToolCalls extracts tool calls from a string using a tool token prefix or direct JSON parsing.\n+// Returns tool calls, whether parsing is incomplete, and any errors.\n+func (p *ToolParser) ParseToolCalls(s string) ([]api.ToolCall, string) {\n+\tfmt.Printf(\"parsing tool calls: input=%s current_state=%s\\n\", s, p.state)\n+\n+\tp.sb.WriteString(s)\n+\ts = p.sb.String()\n+\n+\ts = strings.TrimSpace(s)\n+\n+\tif len(s) == 0 {\n+\t\tp.updateExternalState(nil)\n+\t\treturn nil, \"\"\n+\t}\n+\n+\ts, cont := p.checkPrefix(s)\n+\tif !cont {\n+\t\tp.updateExternalState(nil)\n+\t\tif p.state == ContainsPrefix {\n+\t\t\tfmt.Printf(\"returning partial prefix: remaining=%s\\n\", s)\n+\t\t\treturn nil, s\n+\t\t}\n+\t\t// * we'd be returning here for just accumulating with possible prefix\n+\t\t// * ext state is accumulation\n+\t\treturn nil, \"\"\n+\t}\n+\t// * lets say the check fails here and now we're still in external state accumulation here\n+\n+\t// stay in SendTokens unless we have a prefix\n+\tif p.state == SendTokens {\n+\t\tp.updateExternalState(nil)\n+\t\tp.sb.Reset()\n+\t\tfmt.Printf(\"returning send tokens: remaining=%s\\n\", s)\n+\t\treturn nil, s\n+\t}\n+\n+\t// * we'd parse here as json to see if it's a tool call\n+\ttcs, partial, ok := p.parseJSONToolCalls(s)\n+\t// * it would not be a tool call here\n+\tp.updateStateAfterJSONParse(ok, partial, tcs)\n+\tif !ok {\n+\t\t// * and so we should send the data here\n+\t\t// * we also need to move out of that internal state after sending the tokens\n+\t\tif p.state == NotPartialPrefix {\n+\t\t\tp.state = SendTokens\n+\t\t\t// the string would have acc until here\n+\t\t\treturn nil, p.sb.String()\n+\t\t}\n+\t\treturn nil, \"\"\n+\t}\n+\tfor _, tc := range tcs {\n+\t\ttc.Function.Index = p.toolIndex\n+\t\tp.toolIndex++\n+\t}\n+\tfmt.Printf(\"finished parsing tool calls: tool_calls_found=%d\\n\", len(tcs))\n+\treturn tcs, \"\"\n+}\n+\n+func suffixOverlap(s, delim string) int {\n+\tmax := min(len(delim), len(s))\n+\tfor i := max; i > 0; i-- {\n+\t\tif strings.HasSuffix(s, delim[:i]) {\n+\t\t\treturn i\n+\t\t}\n+\t}\n+\treturn 0\n+}\n+\n+func NewToolParser(model *Model) *ToolParser {\n+\t// TODO: use new template parsing to get all tokens for the prefix\n+\ttemplateToolPrefix, _ := ToolPrefix(model.Template.Template)",
        "comment_created_at": "2025-05-11T21:59:14+00:00",
        "comment_author": "jmorganca",
        "comment_body": "Some of the variable and function names here are very long. Ideally 1 nameComponent, 2 if needed for clarity, but 3 is often a sign that better naming or structure can be used.\r\n\r\n```\r\nprefix, ok := toolPrefix(model.Template.Template)\r\nif !ok {\r\n  return nil\r\n}\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2110406749",
    "pr_number": 10881,
    "pr_file": "envconfig/config.go",
    "created_at": "2025-05-27T22:30:23+00:00",
    "commented_code": "NewEngine = Bool(\"OLLAMA_NEW_ENGINE\")\n \t// ContextLength sets the default context length\n \tContextLength = Uint(\"OLLAMA_CONTEXT_LENGTH\", 4096)\n+\t// UseAuth enables authentication between the Ollama client and server\n+\tUseAuth = Bool(\"OLLAMA_USE_AUTH\")",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "2110406749",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10881,
        "pr_file": "envconfig/config.go",
        "discussion_id": "2110406749",
        "commented_code": "@@ -183,6 +183,8 @@ var (\n \tNewEngine = Bool(\"OLLAMA_NEW_ENGINE\")\n \t// ContextLength sets the default context length\n \tContextLength = Uint(\"OLLAMA_CONTEXT_LENGTH\", 4096)\n+\t// UseAuth enables authentication between the Ollama client and server\n+\tUseAuth = Bool(\"OLLAMA_USE_AUTH\")",
        "comment_created_at": "2025-05-27T22:30:23+00:00",
        "comment_author": "jmorganca",
        "comment_body": "```suggestion\r\n\tUseAuth = Bool(\"OLLAMA_AUTH\")\r\n```\r\n\r\nnit on potentially a more consistent name since we don't have `_USE_` anywhere else",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1864070746",
    "pr_number": 7884,
    "pr_file": "server/routes.go",
    "created_at": "2024-11-30T03:55:26+00:00",
    "commented_code": "streamResponse(c, ch)\n }\n \n+func (s *Server) version(w http.ResponseWriter, r *http.Request) {",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1864070746",
        "repo_full_name": "ollama/ollama",
        "pr_number": 7884,
        "pr_file": "server/routes.go",
        "discussion_id": "1864070746",
        "commented_code": "@@ -1566,6 +1567,24 @@ func (s *Server) ChatHandler(c *gin.Context) {\n \tstreamResponse(c, ch)\n }\n \n+func (s *Server) version(w http.ResponseWriter, r *http.Request) {",
        "comment_created_at": "2024-11-30T03:55:26+00:00",
        "comment_author": "ParthSareen",
        "comment_body": "should this be VersionHandler to stay consistent with the other handlers?",
        "pr_file_module": null
      },
      {
        "comment_id": "1914305870",
        "repo_full_name": "ollama/ollama",
        "pr_number": 7884,
        "pr_file": "server/routes.go",
        "discussion_id": "1864070746",
        "commented_code": "@@ -1566,6 +1567,24 @@ func (s *Server) ChatHandler(c *gin.Context) {\n \tstreamResponse(c, ch)\n }\n \n+func (s *Server) version(w http.ResponseWriter, r *http.Request) {",
        "comment_created_at": "2025-01-14T06:24:37+00:00",
        "comment_author": "bmizerany",
        "comment_body": " handleVersion",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1893160052",
    "pr_number": 8134,
    "pr_file": "cmd/cmd.go",
    "created_at": "2024-12-19T21:18:35+00:00",
    "commented_code": "envVars[\"OLLAMA_LLM_LIBRARY\"],\n \t\t\t\tenvVars[\"OLLAMA_GPU_OVERHEAD\"],\n \t\t\t\tenvVars[\"OLLAMA_LOAD_TIMEOUT\"],\n+\t\t\t\tenvVars[\"OLLAMA_DRAFT_GPU_DEVS\"],",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1893160052",
        "repo_full_name": "ollama/ollama",
        "pr_number": 8134,
        "pr_file": "cmd/cmd.go",
        "discussion_id": "1893160052",
        "commented_code": "@@ -1473,6 +1473,8 @@ func NewCLI() *cobra.Command {\n \t\t\t\tenvVars[\"OLLAMA_LLM_LIBRARY\"],\n \t\t\t\tenvVars[\"OLLAMA_GPU_OVERHEAD\"],\n \t\t\t\tenvVars[\"OLLAMA_LOAD_TIMEOUT\"],\n+\t\t\t\tenvVars[\"OLLAMA_DRAFT_GPU_DEVS\"],",
        "comment_created_at": "2024-12-19T21:18:35+00:00",
        "comment_author": "oxfighterjet",
        "comment_body": "This is entirely a personal opinion, but would it perhaps be more uniform to spell out DEVICES rather than using DEVS? The word DEVICES does not seem to be shorthanded to DEVS in the ollama repo, and I find the extra few characters helpful in making it explicit that this is about devices rather than development or something else.\r\nMy suggestion would apply to every use of the shorthand \"devs\" even in your variable names.\r\n\r\nOf course, this is only a suggestion.",
        "pr_file_module": null
      },
      {
        "comment_id": "1894614381",
        "repo_full_name": "ollama/ollama",
        "pr_number": 8134,
        "pr_file": "cmd/cmd.go",
        "discussion_id": "1893160052",
        "commented_code": "@@ -1473,6 +1473,8 @@ func NewCLI() *cobra.Command {\n \t\t\t\tenvVars[\"OLLAMA_LLM_LIBRARY\"],\n \t\t\t\tenvVars[\"OLLAMA_GPU_OVERHEAD\"],\n \t\t\t\tenvVars[\"OLLAMA_LOAD_TIMEOUT\"],\n+\t\t\t\tenvVars[\"OLLAMA_DRAFT_GPU_DEVS\"],",
        "comment_created_at": "2024-12-21T12:17:43+00:00",
        "comment_author": "bfroemel",
        "comment_body": "I agree - DEVICES is the better name! However, in an attempt to fix https://github.com/ollama/ollama/pull/8134#discussion_r1890840858 I have remove these new `OLLAMA_DRAFT_*` environment variables again (which also resolves the naming issue). FIX: https://github.com/ollama/ollama/pull/8134/commits/59e036b6b0e3b2674c27c7d57aae0f7d529c0f31 https://github.com/ollama/ollama/pull/8134/commits/b0087f990d742a0f02a47a68886ef1a8a233edd1",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1960690548",
    "pr_number": 9198,
    "pr_file": "model/models/gemma2/model.go",
    "created_at": "2025-02-18T22:38:56+00:00",
    "commented_code": "+package gemma2\n+\n+import (\n+\t\"math\"\n+\n+\t\"github.com/ollama/ollama/kvcache\"\n+\t\"github.com/ollama/ollama/ml\"\n+\t\"github.com/ollama/ollama/ml/nn\"\n+\t\"github.com/ollama/ollama/model\"\n+)\n+\n+type Options struct {\n+\thiddenSize, numHeads, numKVHeads int\n+\tattnKeyLen, attnValLen           int\n+\teps, ropeBase, ropeScale         float32\n+\tattnLogitSoftcap                 float32\n+\tfinalLogitSoftcap                float32\n+}\n+\n+type Model struct {\n+\tmodel.Base\n+\tmodel.SentencePieceModel\n+\n+\tTokenEmbedding *nn.Embedding `gguf:\"token_embd\"`\n+\tLayers         []Layer       `gguf:\"blk\"`\n+\tOutputNorm     *nn.RMSNorm   `gguf:\"output_norm\"`           // is this supposed to be root means square?\n+\tOutput         *nn.Linear    `gguf:\"output,alt:token_embd\"` // just set to token_embd?\n+\n+\t*Options\n+}\n+\n+func New(c ml.Config) (model.Model, error) {\n+\tm := Model{\n+\t\tSentencePieceModel: model.NewSentencePieceModel(\n+\t\t\tc.String(\"tokenizer.ggml.pretokenizer\", `(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\n]*|\\s*[\\r\n]+|\\s+(?!\\S)|\\s+`),\n+\t\t\t&model.Vocabulary{\n+\t\t\t\tValues: c.Strings(\"tokenizer.ggml.tokens\"),\n+\t\t\t\tScores: c.Floats(\"tokenizer.ggml.scores\"),\n+\t\t\t\tTypes:  c.Uints(\"tokenizer.ggml.token_type\"),\n+\t\t\t\tBOS:    int32(c.Uint(\"tokenizer.ggml.bos_token_id\")),\n+\t\t\t\tEOS:    int32(c.Uint(\"tokenizer.ggml.eos_token_id\")),\n+\t\t\t},\n+\t\t),\n+\t\tLayers: make([]Layer, c.Uint(\"block_count\")),\n+\t\tOptions: &Options{\n+\t\t\thiddenSize:        int(c.Uint(\"embedding_length\")),\n+\t\t\tnumHeads:          int(c.Uint(\"attention.head_count\")),\n+\t\t\tnumKVHeads:        int(c.Uint(\"attention.head_count_kv\")),\n+\t\t\tattnKeyLen:        int(c.Uint(\"attention.key_length\")),\n+\t\t\tattnValLen:        int(c.Uint(\"attention.value_length\")),\n+\t\t\teps:               c.Float(\"attention.layer_norm_rms_epsilon\"),\n+\t\t\tropeBase:          c.Float(\"rope.freq_base\", 10000.0),\n+\t\t\tropeScale:         c.Float(\"rope.freq_scale\", 1.0),\n+\t\t\tattnLogitSoftcap:  c.Float(\"attn_logit_softcapping\"),\n+\t\t\tfinalLogitSoftcap: c.Float(\"final_logit_softcapping\"),\n+\t\t},\n+\t}\n+\n+\tslidingWindowLen := int32(c.Uint(\"attention.sliding_window\"))\n+\tm.Cache = kvcache.NewWrapperCache(kvcache.NewSWACache(slidingWindowLen, m.Shift), kvcache.NewCausalCache(m.Shift))\n+\n+\treturn &m, nil\n+}\n+\n+type SelfAttention struct {\n+\tQuery  *nn.Linear `gguf:\"attn_q\"`\n+\tKey    *nn.Linear `gguf:\"attn_k\"`\n+\tValue  *nn.Linear `gguf:\"attn_v\"`\n+\tOutput *nn.Linear `gguf:\"attn_output\"`\n+}\n+\n+func (sa *SelfAttention) Forward(ctx ml.Context, hiddenState, positionIDs ml.Tensor, cache kvcache.Cache, opts *Options) ml.Tensor {\n+\tbatchSize := hiddenState.Dim(1)",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1960690548",
        "repo_full_name": "ollama/ollama",
        "pr_number": 9198,
        "pr_file": "model/models/gemma2/model.go",
        "discussion_id": "1960690548",
        "commented_code": "@@ -0,0 +1,193 @@\n+package gemma2\n+\n+import (\n+\t\"math\"\n+\n+\t\"github.com/ollama/ollama/kvcache\"\n+\t\"github.com/ollama/ollama/ml\"\n+\t\"github.com/ollama/ollama/ml/nn\"\n+\t\"github.com/ollama/ollama/model\"\n+)\n+\n+type Options struct {\n+\thiddenSize, numHeads, numKVHeads int\n+\tattnKeyLen, attnValLen           int\n+\teps, ropeBase, ropeScale         float32\n+\tattnLogitSoftcap                 float32\n+\tfinalLogitSoftcap                float32\n+}\n+\n+type Model struct {\n+\tmodel.Base\n+\tmodel.SentencePieceModel\n+\n+\tTokenEmbedding *nn.Embedding `gguf:\"token_embd\"`\n+\tLayers         []Layer       `gguf:\"blk\"`\n+\tOutputNorm     *nn.RMSNorm   `gguf:\"output_norm\"`           // is this supposed to be root means square?\n+\tOutput         *nn.Linear    `gguf:\"output,alt:token_embd\"` // just set to token_embd?\n+\n+\t*Options\n+}\n+\n+func New(c ml.Config) (model.Model, error) {\n+\tm := Model{\n+\t\tSentencePieceModel: model.NewSentencePieceModel(\n+\t\t\tc.String(\"tokenizer.ggml.pretokenizer\", `(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+`),\n+\t\t\t&model.Vocabulary{\n+\t\t\t\tValues: c.Strings(\"tokenizer.ggml.tokens\"),\n+\t\t\t\tScores: c.Floats(\"tokenizer.ggml.scores\"),\n+\t\t\t\tTypes:  c.Uints(\"tokenizer.ggml.token_type\"),\n+\t\t\t\tBOS:    int32(c.Uint(\"tokenizer.ggml.bos_token_id\")),\n+\t\t\t\tEOS:    int32(c.Uint(\"tokenizer.ggml.eos_token_id\")),\n+\t\t\t},\n+\t\t),\n+\t\tLayers: make([]Layer, c.Uint(\"block_count\")),\n+\t\tOptions: &Options{\n+\t\t\thiddenSize:        int(c.Uint(\"embedding_length\")),\n+\t\t\tnumHeads:          int(c.Uint(\"attention.head_count\")),\n+\t\t\tnumKVHeads:        int(c.Uint(\"attention.head_count_kv\")),\n+\t\t\tattnKeyLen:        int(c.Uint(\"attention.key_length\")),\n+\t\t\tattnValLen:        int(c.Uint(\"attention.value_length\")),\n+\t\t\teps:               c.Float(\"attention.layer_norm_rms_epsilon\"),\n+\t\t\tropeBase:          c.Float(\"rope.freq_base\", 10000.0),\n+\t\t\tropeScale:         c.Float(\"rope.freq_scale\", 1.0),\n+\t\t\tattnLogitSoftcap:  c.Float(\"attn_logit_softcapping\"),\n+\t\t\tfinalLogitSoftcap: c.Float(\"final_logit_softcapping\"),\n+\t\t},\n+\t}\n+\n+\tslidingWindowLen := int32(c.Uint(\"attention.sliding_window\"))\n+\tm.Cache = kvcache.NewWrapperCache(kvcache.NewSWACache(slidingWindowLen, m.Shift), kvcache.NewCausalCache(m.Shift))\n+\n+\treturn &m, nil\n+}\n+\n+type SelfAttention struct {\n+\tQuery  *nn.Linear `gguf:\"attn_q\"`\n+\tKey    *nn.Linear `gguf:\"attn_k\"`\n+\tValue  *nn.Linear `gguf:\"attn_v\"`\n+\tOutput *nn.Linear `gguf:\"attn_output\"`\n+}\n+\n+func (sa *SelfAttention) Forward(ctx ml.Context, hiddenState, positionIDs ml.Tensor, cache kvcache.Cache, opts *Options) ml.Tensor {\n+\tbatchSize := hiddenState.Dim(1)",
        "comment_created_at": "2025-02-18T22:38:56+00:00",
        "comment_author": "BruceMacD",
        "comment_body": "I'd like to avoid single letter variables, this is so hard to read. Let me know what you think of how I've done Qwen2:\r\nhttps://github.com/ollama/ollama/pull/9200",
        "pr_file_module": null
      }
    ]
  }
]