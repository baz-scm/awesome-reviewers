[
  {
    "discussion_id": "2109722140",
    "pr_number": 10584,
    "pr_file": "server/thinking.go",
    "created_at": "2025-05-27T17:01:23+00:00",
    "commented_code": "+package server\n+\n+import (\n+\t\"strings\"\n+\t\"text/template\"\n+\t\"text/template/parse\"\n+\t\"unicode\"\n+)\n+\n+type thinkingParseState int\n+\n+const (\n+\t// We're looking for the opening tag, but we haven't seen any non-whitespace\n+\t// characters yet\n+\tthinkingParseState_LookingForOpening thinkingParseState = iota\n+\t// We've seen the opening tag, but we haven't seen any non-whitespace\n+\t// characters yet (we want to eat any whitespace between the opening tag and\n+\t// the thinking content)\n+\tthinkingParseState_ThinkingStartedEatingWhitespace\n+\t// We've seen non-whitespace characters after the opening tag, but we haven't\n+\t// seen the closing tag yet\n+\tthinkingParseState_Thinking\n+\t// We've seen the closing tag, but we haven't seen any non-whitespace\n+\t// characters after the closing tag yet (we want to eat any whitespace between\n+\t// the closing tag and the content)\n+\tthinkingParseState_ThinkingDoneEatingWhitespace\n+\t// We've seen the closing tag and seen at least one non-whitespace character\n+\t// after it\n+\tthinkingParseState_ThinkingDone\n+)\n+\n+func (s thinkingParseState) String() string {\n+\tswitch s {\n+\tcase thinkingParseState_LookingForOpening:\n+\t\treturn \"LookingForOpening\"\n+\tcase thinkingParseState_ThinkingStartedEatingWhitespace:\n+\t\treturn \"ThinkingStartedEatingWhitespace\"\n+\tcase thinkingParseState_Thinking:\n+\t\treturn \"Thinking\"\n+\tcase thinkingParseState_ThinkingDoneEatingWhitespace:\n+\t\treturn \"ThinkingDoneEatingWhitespace\"\n+\tcase thinkingParseState_ThinkingDone:\n+\t\treturn \"ThinkingDone\"\n+\tdefault:\n+\t\treturn \"Unknown\"\n+\t}\n+}\n+\n+type thinkingParser struct {\n+\tstate      thinkingParseState\n+\topeningTag string\n+\tclosingTag string\n+\tacc        strings.Builder\n+}\n+\n+// returns the thinking content and the normal content that should be\n+// immediately sent to the user. It will internally buffer if it needs to see\n+// more content to disambiguate\n+func (s *thinkingParser) addContent(content string) (string, string) {",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "2109722140",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10584,
        "pr_file": "server/thinking.go",
        "discussion_id": "2109722140",
        "commented_code": "@@ -0,0 +1,300 @@\n+package server\n+\n+import (\n+\t\"strings\"\n+\t\"text/template\"\n+\t\"text/template/parse\"\n+\t\"unicode\"\n+)\n+\n+type thinkingParseState int\n+\n+const (\n+\t// We're looking for the opening tag, but we haven't seen any non-whitespace\n+\t// characters yet\n+\tthinkingParseState_LookingForOpening thinkingParseState = iota\n+\t// We've seen the opening tag, but we haven't seen any non-whitespace\n+\t// characters yet (we want to eat any whitespace between the opening tag and\n+\t// the thinking content)\n+\tthinkingParseState_ThinkingStartedEatingWhitespace\n+\t// We've seen non-whitespace characters after the opening tag, but we haven't\n+\t// seen the closing tag yet\n+\tthinkingParseState_Thinking\n+\t// We've seen the closing tag, but we haven't seen any non-whitespace\n+\t// characters after the closing tag yet (we want to eat any whitespace between\n+\t// the closing tag and the content)\n+\tthinkingParseState_ThinkingDoneEatingWhitespace\n+\t// We've seen the closing tag and seen at least one non-whitespace character\n+\t// after it\n+\tthinkingParseState_ThinkingDone\n+)\n+\n+func (s thinkingParseState) String() string {\n+\tswitch s {\n+\tcase thinkingParseState_LookingForOpening:\n+\t\treturn \"LookingForOpening\"\n+\tcase thinkingParseState_ThinkingStartedEatingWhitespace:\n+\t\treturn \"ThinkingStartedEatingWhitespace\"\n+\tcase thinkingParseState_Thinking:\n+\t\treturn \"Thinking\"\n+\tcase thinkingParseState_ThinkingDoneEatingWhitespace:\n+\t\treturn \"ThinkingDoneEatingWhitespace\"\n+\tcase thinkingParseState_ThinkingDone:\n+\t\treturn \"ThinkingDone\"\n+\tdefault:\n+\t\treturn \"Unknown\"\n+\t}\n+}\n+\n+type thinkingParser struct {\n+\tstate      thinkingParseState\n+\topeningTag string\n+\tclosingTag string\n+\tacc        strings.Builder\n+}\n+\n+// returns the thinking content and the normal content that should be\n+// immediately sent to the user. It will internally buffer if it needs to see\n+// more content to disambiguate\n+func (s *thinkingParser) addContent(content string) (string, string) {",
        "comment_created_at": "2025-05-27T17:01:23+00:00",
        "comment_author": "ParthSareen",
        "comment_body": "we use `godoc` style formatting: https://tip.golang.org/doc/comment\r\nso it would be something like \r\n```\r\naddContent returns the ...\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2109819076",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10584,
        "pr_file": "server/thinking.go",
        "discussion_id": "2109722140",
        "commented_code": "@@ -0,0 +1,300 @@\n+package server\n+\n+import (\n+\t\"strings\"\n+\t\"text/template\"\n+\t\"text/template/parse\"\n+\t\"unicode\"\n+)\n+\n+type thinkingParseState int\n+\n+const (\n+\t// We're looking for the opening tag, but we haven't seen any non-whitespace\n+\t// characters yet\n+\tthinkingParseState_LookingForOpening thinkingParseState = iota\n+\t// We've seen the opening tag, but we haven't seen any non-whitespace\n+\t// characters yet (we want to eat any whitespace between the opening tag and\n+\t// the thinking content)\n+\tthinkingParseState_ThinkingStartedEatingWhitespace\n+\t// We've seen non-whitespace characters after the opening tag, but we haven't\n+\t// seen the closing tag yet\n+\tthinkingParseState_Thinking\n+\t// We've seen the closing tag, but we haven't seen any non-whitespace\n+\t// characters after the closing tag yet (we want to eat any whitespace between\n+\t// the closing tag and the content)\n+\tthinkingParseState_ThinkingDoneEatingWhitespace\n+\t// We've seen the closing tag and seen at least one non-whitespace character\n+\t// after it\n+\tthinkingParseState_ThinkingDone\n+)\n+\n+func (s thinkingParseState) String() string {\n+\tswitch s {\n+\tcase thinkingParseState_LookingForOpening:\n+\t\treturn \"LookingForOpening\"\n+\tcase thinkingParseState_ThinkingStartedEatingWhitespace:\n+\t\treturn \"ThinkingStartedEatingWhitespace\"\n+\tcase thinkingParseState_Thinking:\n+\t\treturn \"Thinking\"\n+\tcase thinkingParseState_ThinkingDoneEatingWhitespace:\n+\t\treturn \"ThinkingDoneEatingWhitespace\"\n+\tcase thinkingParseState_ThinkingDone:\n+\t\treturn \"ThinkingDone\"\n+\tdefault:\n+\t\treturn \"Unknown\"\n+\t}\n+}\n+\n+type thinkingParser struct {\n+\tstate      thinkingParseState\n+\topeningTag string\n+\tclosingTag string\n+\tacc        strings.Builder\n+}\n+\n+// returns the thinking content and the normal content that should be\n+// immediately sent to the user. It will internally buffer if it needs to see\n+// more content to disambiguate\n+func (s *thinkingParser) addContent(content string) (string, string) {",
        "comment_created_at": "2025-05-27T17:53:10+00:00",
        "comment_author": "ParthSareen",
        "comment_body": "would be good to just take a pass wherever there are comments on funcs - plus IDE will render nicer :)",
        "pr_file_module": null
      },
      {
        "comment_id": "2109851052",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10584,
        "pr_file": "server/thinking.go",
        "discussion_id": "2109722140",
        "commented_code": "@@ -0,0 +1,300 @@\n+package server\n+\n+import (\n+\t\"strings\"\n+\t\"text/template\"\n+\t\"text/template/parse\"\n+\t\"unicode\"\n+)\n+\n+type thinkingParseState int\n+\n+const (\n+\t// We're looking for the opening tag, but we haven't seen any non-whitespace\n+\t// characters yet\n+\tthinkingParseState_LookingForOpening thinkingParseState = iota\n+\t// We've seen the opening tag, but we haven't seen any non-whitespace\n+\t// characters yet (we want to eat any whitespace between the opening tag and\n+\t// the thinking content)\n+\tthinkingParseState_ThinkingStartedEatingWhitespace\n+\t// We've seen non-whitespace characters after the opening tag, but we haven't\n+\t// seen the closing tag yet\n+\tthinkingParseState_Thinking\n+\t// We've seen the closing tag, but we haven't seen any non-whitespace\n+\t// characters after the closing tag yet (we want to eat any whitespace between\n+\t// the closing tag and the content)\n+\tthinkingParseState_ThinkingDoneEatingWhitespace\n+\t// We've seen the closing tag and seen at least one non-whitespace character\n+\t// after it\n+\tthinkingParseState_ThinkingDone\n+)\n+\n+func (s thinkingParseState) String() string {\n+\tswitch s {\n+\tcase thinkingParseState_LookingForOpening:\n+\t\treturn \"LookingForOpening\"\n+\tcase thinkingParseState_ThinkingStartedEatingWhitespace:\n+\t\treturn \"ThinkingStartedEatingWhitespace\"\n+\tcase thinkingParseState_Thinking:\n+\t\treturn \"Thinking\"\n+\tcase thinkingParseState_ThinkingDoneEatingWhitespace:\n+\t\treturn \"ThinkingDoneEatingWhitespace\"\n+\tcase thinkingParseState_ThinkingDone:\n+\t\treturn \"ThinkingDone\"\n+\tdefault:\n+\t\treturn \"Unknown\"\n+\t}\n+}\n+\n+type thinkingParser struct {\n+\tstate      thinkingParseState\n+\topeningTag string\n+\tclosingTag string\n+\tacc        strings.Builder\n+}\n+\n+// returns the thinking content and the normal content that should be\n+// immediately sent to the user. It will internally buffer if it needs to see\n+// more content to disambiguate\n+func (s *thinkingParser) addContent(content string) (string, string) {",
        "comment_created_at": "2025-05-27T18:13:05+00:00",
        "comment_author": "drifkin",
        "comment_body": "thanks! will take a pass",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1964017219",
    "pr_number": 9022,
    "pr_file": "api/types.go",
    "created_at": "2025-02-20T17:00:40+00:00",
    "commented_code": "return nil\n }\n \n+// ErrorResponse implements a structured error interface that is returned from the Ollama server\n+type ErrorResponse struct {\n+\tErr  string `json:\"error,omitempty\"` // The annotated error from the server, helps with debugging the code-path\n+\tHint string `json:\"hint,omitempty\"`  // A user-friendly message about what went wrong, with suggested troubleshooting",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1964017219",
        "repo_full_name": "ollama/ollama",
        "pr_number": 9022,
        "pr_file": "api/types.go",
        "discussion_id": "1964017219",
        "commented_code": "@@ -661,6 +640,19 @@ func (d *Duration) UnmarshalJSON(b []byte) (err error) {\n \treturn nil\n }\n \n+// ErrorResponse implements a structured error interface that is returned from the Ollama server\n+type ErrorResponse struct {\n+\tErr  string `json:\"error,omitempty\"` // The annotated error from the server, helps with debugging the code-path\n+\tHint string `json:\"hint,omitempty\"`  // A user-friendly message about what went wrong, with suggested troubleshooting",
        "comment_created_at": "2025-02-20T17:00:40+00:00",
        "comment_author": "mxyng",
        "comment_body": "Comments should be in the line above\r\n\r\n```suggestion\r\n\t// Err is the error from the server. It helps with debugging the code-path\r\n\tErr  string `json:\"error\"`\r\n\r\n\t// Hint is a user-friendly message about what went wrong, with suggested troubleshooting\r\n\tHint string `json:\"hint\"`\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1962259955",
    "pr_number": 9204,
    "pr_file": "ml/backend.go",
    "created_at": "2025-02-19T19:32:40+00:00",
    "commented_code": "Copy(ctx Context, t2 Tensor) Tensor\n }\n \n+type ScaledDotProductAttention interface {",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1962259955",
        "repo_full_name": "ollama/ollama",
        "pr_number": 9204,
        "pr_file": "ml/backend.go",
        "discussion_id": "1962259955",
        "commented_code": "@@ -96,6 +96,10 @@ type Tensor interface {\n \tCopy(ctx Context, t2 Tensor) Tensor\n }\n \n+type ScaledDotProductAttention interface {",
        "comment_created_at": "2025-02-19T19:32:40+00:00",
        "comment_author": "BruceMacD",
        "comment_body": "I know that comments aren't in other places here, but we should be documenting these interfaces and functions with comments where this serves as an implementation guide for different back-ends, and a reference for model implementers. ",
        "pr_file_module": null
      },
      {
        "comment_id": "1962572696",
        "repo_full_name": "ollama/ollama",
        "pr_number": 9204,
        "pr_file": "ml/backend.go",
        "discussion_id": "1962259955",
        "commented_code": "@@ -96,6 +96,10 @@ type Tensor interface {\n \tCopy(ctx Context, t2 Tensor) Tensor\n }\n \n+type ScaledDotProductAttention interface {",
        "comment_created_at": "2025-02-20T00:26:40+00:00",
        "comment_author": "jessegross",
        "comment_body": "I agree, it's good to start documenting these interfaces. Same for the one below.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1955351023",
    "pr_number": 8301,
    "pr_file": "kvcache/cache.go",
    "created_at": "2025-02-13T23:33:53+00:00",
    "commented_code": "+package kvcache\n+\n+import (\n+\t\"errors\"\n+\n+\t\"github.com/ollama/ollama/ml\"\n+)\n+\n+var (\n+\tErrKvCacheFull  = errors.New(\"could not find a kv cache slot\")\n+\tErrNotSupported = errors.New(\"model does not support operation\")\n+)\n+\n+type Cache interface {\n+\t// ** used by model implementations **\n+\n+\t// Sets the active layer of the cache",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1955351023",
        "repo_full_name": "ollama/ollama",
        "pr_number": 8301,
        "pr_file": "kvcache/cache.go",
        "discussion_id": "1955351023",
        "commented_code": "@@ -0,0 +1,54 @@\n+package kvcache\n+\n+import (\n+\t\"errors\"\n+\n+\t\"github.com/ollama/ollama/ml\"\n+)\n+\n+var (\n+\tErrKvCacheFull  = errors.New(\"could not find a kv cache slot\")\n+\tErrNotSupported = errors.New(\"model does not support operation\")\n+)\n+\n+type Cache interface {\n+\t// ** used by model implementations **\n+\n+\t// Sets the active layer of the cache",
        "comment_created_at": "2025-02-13T23:33:53+00:00",
        "comment_author": "jmorganca",
        "comment_body": "I _think_ generally the doc for functions should start with the function name, e.g.\r\n\r\n```suggestion\r\n\t// SetLayer sets the active layer of the cache\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1955351312",
        "repo_full_name": "ollama/ollama",
        "pr_number": 8301,
        "pr_file": "kvcache/cache.go",
        "discussion_id": "1955351023",
        "commented_code": "@@ -0,0 +1,54 @@\n+package kvcache\n+\n+import (\n+\t\"errors\"\n+\n+\t\"github.com/ollama/ollama/ml\"\n+)\n+\n+var (\n+\tErrKvCacheFull  = errors.New(\"could not find a kv cache slot\")\n+\tErrNotSupported = errors.New(\"model does not support operation\")\n+)\n+\n+type Cache interface {\n+\t// ** used by model implementations **\n+\n+\t// Sets the active layer of the cache",
        "comment_created_at": "2025-02-13T23:34:19+00:00",
        "comment_author": "jmorganca",
        "comment_body": "More: https://go.dev/doc/comment",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2032187600",
    "pr_number": 10171,
    "pr_file": "ml/backend/ggml/ggml.go",
    "created_at": "2025-04-08T00:29:51+00:00",
    "commented_code": "}\n }\n \n+func (c Context) Reserve() error {",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "2032187600",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10171,
        "pr_file": "ml/backend/ggml/ggml.go",
        "discussion_id": "2032187600",
        "commented_code": "@@ -530,6 +539,24 @@ func (c Context) Compute(tensors ...ml.Tensor) {\n \t}\n }\n \n+func (c Context) Reserve() error {",
        "comment_created_at": "2025-04-08T00:29:51+00:00",
        "comment_author": "jmorganca",
        "comment_body": "A GoDoc comment here would be great! Since there are some preconditions to running this.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2096324196",
    "pr_number": 10415,
    "pr_file": "tools/utils.go",
    "created_at": "2025-05-19T19:02:33+00:00",
    "commented_code": "+package tools\n+\n+import (\n+\t\"bytes\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"log/slog\"\n+\t\"slices\"\n+\t\"strings\"\n+\tgotmpl \"text/template\"\n+\t\"text/template/parse\"\n+\n+\t\"github.com/ollama/ollama/api\"\n+\t\"github.com/ollama/ollama/template\"\n+)\n+\n+// extractToolCallsFormat traverses a template AST to find text that follows a \".ToolCalls\" condition.\n+// It walks the template nodes looking for if-statements containing \".ToolCalls\" and extracts any\n+// immediate text nodes that follow. This is used to identify tool call prefixes and formatting.\n+//\n+// Returns:\n+//   - string: The extracted text following the first \".ToolCalls\" condition found\n+//   - bool: Whether a \".ToolCalls\" condition was found in the template\n+func extractToolCallsFormat(tmpl *gotmpl.Template) (string, bool) {\n+\tif tmpl == nil || tmpl.Tree == nil {\n+\t\tslog.Debug(\"TextAfterToolCalls: template or tree is nil\")\n+\t\treturn \"\", false\n+\t}\n+\n+\tvar result string\n+\tvar found bool\n+\n+\tvar walk func(nodes []parse.Node)\n+\twalk = func(nodes []parse.Node) {\n+\t\tfor _, node := range nodes {\n+\t\t\tif found {\n+\t\t\t\treturn\n+\t\t\t}\n+\n+\t\t\tswitch n := node.(type) {\n+\t\t\tcase *parse.IfNode:\n+\t\t\t\tif isToolCallsNode(n) {\n+\t\t\t\t\t// Collect immediate TextNode(s) at start of IfNode's list\n+\t\t\t\t\tvar sb strings.Builder\n+\t\t\t\t\tfor _, innerNode := range n.List.Nodes {\n+\t\t\t\t\t\tif tn, ok := innerNode.(*parse.TextNode); ok {\n+\t\t\t\t\t\t\tsb.Write(tn.Text)\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t// Stop at first non-text node\n+\t\t\t\t\t\t\tbreak\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\tresult = sb.String()\n+\t\t\t\t\tfound = true\n+\t\t\t\t\treturn\n+\t\t\t\t}\n+\t\t\t\t// Recurse into child nodes\n+\t\t\t\twalk(n.List.Nodes)\n+\t\t\t\tif n.ElseList != nil {\n+\t\t\t\t\twalk(n.ElseList.Nodes)\n+\t\t\t\t}\n+\t\t\tcase *parse.ListNode:\n+\t\t\t\twalk(n.Nodes)\n+\t\t\tcase *parse.RangeNode:\n+\t\t\t\twalk(n.List.Nodes)\n+\t\t\t\tif n.ElseList != nil {\n+\t\t\t\t\twalk(n.ElseList.Nodes)\n+\t\t\t\t}\n+\t\t\tcase *parse.WithNode:\n+\t\t\t\twalk(n.List.Nodes)\n+\t\t\t\tif n.ElseList != nil {\n+\t\t\t\t\twalk(n.ElseList.Nodes)\n+\t\t\t\t}\n+\t\t\tdefault:\n+\t\t\t\t// Continue to next node\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\tif found {\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\twalk(tmpl.Tree.Root.Nodes)\n+\treturn result, found\n+}\n+\n+// isToolCallsNode detects if a node's condition includes \".ToolCalls\"\n+func isToolCallsNode(n *parse.IfNode) bool {\n+\tfor _, cmd := range n.Pipe.Cmds {\n+\t\tfor _, arg := range cmd.Args {\n+\t\t\tif field, ok := arg.(*parse.FieldNode); ok {\n+\t\t\t\tif slices.Contains(field.Ident, \"ToolCalls\") {\n+\t\t\t\t\treturn true\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+// TODO(parthsareen): get full prefix from the template instead of just the first token\n+\n+// toolPrefix returns the prefix for the tool call if it exists from a template\n+func toolPrefix(tmpl *gotmpl.Template) string {\n+\ttokenText, ok := extractToolCallsFormat(tmpl)\n+\tif !ok {\n+\t\treturn \"\"\n+\t}\n+\ttokenText = strings.TrimSpace(tokenText)\n+\tif tokenText == \"\" {\n+\t\treturn \"\"\n+\t}\n+\tfirst := strings.Fields(tokenText)[0]\n+\n+\tstart := -1\n+\tend := -1\n+\tfor i, r := range tokenText {\n+\t\tif r == '<' || r == '[' {\n+\t\t\tstart = i\n+\t\t}\n+\t\tif (r == '>' || r == ']') && start != -1 {\n+\t\t\tend = i\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\tif start != -1 && end != -1 {\n+\t\t// return the token including the [ or < and the ] or >\n+\t\treturn tokenText[start : end+1]\n+\t} else if start != -1 {\n+\t\t// get until the [ or < - in the case tag was not closed\n+\t\treturn tokenText[:start]\n+\t} else if end != -1 {\n+\t\t// get after the ] or > - in the case tag was not opened\n+\t\treturn tokenText[end+1:]\n+\t}\n+\treturn first\n+}\n+\n+// toolTemplate creates a subtree from the node that ranges over .ToolCalls\n+//\n+// Returns:\n+//   - *gotmpl.Template: The subtree containing the .ToolCalls range\n+//   - error: Error if parsing failed\n+func toolTemplate(t *template.Template) (*gotmpl.Template, error) {\n+\ttmpl := t.Subtree(func(n parse.Node) bool {\n+\t\tif t, ok := n.(*parse.RangeNode); ok {\n+\t\t\treturn slices.Contains(template.Identifiers(t.Pipe), \"ToolCalls\")\n+\t\t}\n+\n+\t\treturn false\n+\t})\n+\n+\tif tmpl == nil {\n+\t\treturn nil, errors.New(\"failed to find tool template\")\n+\t}\n+\n+\treturn tmpl, nil\n+}\n+\n+// suffixOverlap returns the length of the longest suffix overlap between two strings\n+//\n+// Returns:\n+//   - int: The length of the longest suffix overlap\n+func suffixOverlap(s, prefix string) int {\n+\tmax := min(len(prefix), len(s))\n+\tfor i := max; i > 0; i-- {\n+\t\tif strings.HasSuffix(s, prefix[:i]) {\n+\t\t\treturn i\n+\t\t}\n+\t}\n+\treturn 0\n+}\n+\n+// extractToolArgs executes a template with a known tool call format to extract the name and arguments\n+//\n+// Returns:\n+//   - string: The name of the tool call\n+//   - string: The arguments of the tool call\n+//   - error: Error if parsing failed\n+func extractToolArgs(tmpl *gotmpl.Template) (name, arguments string, err error) {\n+\tvar b bytes.Buffer\n+\tif err := tmpl.Execute(&b, map[string][]api.ToolCall{\n+\t\t\"ToolCalls\": {\n+\t\t\t{\n+\t\t\t\tFunction: api.ToolCallFunction{\n+\t\t\t\t\tName: \"@@name@@\",\n+\t\t\t\t\tArguments: api.ToolCallFunctionArguments{\n+\t\t\t\t\t\t\"@@argument@@\": 1,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t}); err != nil {\n+\t\treturn \"\", \"\", err\n+\t}\n+\n+\tvar obj any\n+\terr = json.Unmarshal(b.Bytes(), &obj)\n+\tif err != nil {\n+\t\treturn \"\", \"\", err\n+\t}\n+\n+\tvar objs []map[string]any\n+\tswitch v := obj.(type) {\n+\tcase map[string]any:\n+\t\tobjs = []map[string]any{v}\n+\tcase []map[string]any:\n+\t\tobjs = v\n+\tcase []any:\n+\t\tobjs = collect(v)\n+\t}\n+\tif len(objs) == 0 {\n+\t\treturn \"\", \"\", errors.New(\"no template objects found\")\n+\t}\n+\n+\t// find the keys that correspond to the name and arguments fields\n+\tfor k, v := range objs[0] {\n+\t\tswitch v.(type) {\n+\t\tcase string:\n+\t\t\tname = k\n+\t\tcase map[string]any:\n+\t\t\targuments = k\n+\t\t}\n+\t}\n+\n+\tif name == \"\" || arguments == \"\" {\n+\t\tslog.Debug(\"missing required fields in tool call template\", \"name\", name, \"arguments\", arguments)\n+\t\treturn \"\", \"\", errors.New(\"missing required fields in tool call template\")\n+\t}\n+\n+\treturn name, arguments, nil\n+}\n+\n+// collect recursively traverses an object to collect all nested maps\n+//\n+// Returns:\n+//   - []map[string]any: A slice of all nested maps found in the object\n+func collect(obj any) []map[string]any {\n+\tvar all []map[string]any\n+\tswitch o := obj.(type) {\n+\tcase map[string]any:\n+\t\tall = append(all, o)\n+\t\tfor _, v := range o {\n+\t\t\tall = append(all, collect(v)...)\n+\t\t}\n+\tcase []any:\n+\t\tfor _, v := range o {\n+\t\t\tall = append(all, collect(v)...)\n+\t\t}\n+\tdefault:\n+\t\treturn nil\n+\t}\n+\n+\treturn all\n+}\n+\n+// parseJSONToolCalls attempts to parse a JSON string into a slice ToolCalls.\n+// It first checks for balanced braces before attempting to parse.\n+// Returns:\n+//   - []api.ToolCall: The parsed tool calls if successful\n+//   - error: ErrAccumulateMore if braces unbalanced, ErrInvalidToolCall if invalid, or nil if successful\n+func parseJSONToolCalls(s string, name, arguments string) ([]api.ToolCall, error) {",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "2096324196",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10415,
        "pr_file": "tools/utils.go",
        "discussion_id": "2096324196",
        "commented_code": "@@ -0,0 +1,329 @@\n+package tools\n+\n+import (\n+\t\"bytes\"\n+\t\"encoding/json\"\n+\t\"errors\"\n+\t\"log/slog\"\n+\t\"slices\"\n+\t\"strings\"\n+\tgotmpl \"text/template\"\n+\t\"text/template/parse\"\n+\n+\t\"github.com/ollama/ollama/api\"\n+\t\"github.com/ollama/ollama/template\"\n+)\n+\n+// extractToolCallsFormat traverses a template AST to find text that follows a \".ToolCalls\" condition.\n+// It walks the template nodes looking for if-statements containing \".ToolCalls\" and extracts any\n+// immediate text nodes that follow. This is used to identify tool call prefixes and formatting.\n+//\n+// Returns:\n+//   - string: The extracted text following the first \".ToolCalls\" condition found\n+//   - bool: Whether a \".ToolCalls\" condition was found in the template\n+func extractToolCallsFormat(tmpl *gotmpl.Template) (string, bool) {\n+\tif tmpl == nil || tmpl.Tree == nil {\n+\t\tslog.Debug(\"TextAfterToolCalls: template or tree is nil\")\n+\t\treturn \"\", false\n+\t}\n+\n+\tvar result string\n+\tvar found bool\n+\n+\tvar walk func(nodes []parse.Node)\n+\twalk = func(nodes []parse.Node) {\n+\t\tfor _, node := range nodes {\n+\t\t\tif found {\n+\t\t\t\treturn\n+\t\t\t}\n+\n+\t\t\tswitch n := node.(type) {\n+\t\t\tcase *parse.IfNode:\n+\t\t\t\tif isToolCallsNode(n) {\n+\t\t\t\t\t// Collect immediate TextNode(s) at start of IfNode's list\n+\t\t\t\t\tvar sb strings.Builder\n+\t\t\t\t\tfor _, innerNode := range n.List.Nodes {\n+\t\t\t\t\t\tif tn, ok := innerNode.(*parse.TextNode); ok {\n+\t\t\t\t\t\t\tsb.Write(tn.Text)\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t// Stop at first non-text node\n+\t\t\t\t\t\t\tbreak\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\tresult = sb.String()\n+\t\t\t\t\tfound = true\n+\t\t\t\t\treturn\n+\t\t\t\t}\n+\t\t\t\t// Recurse into child nodes\n+\t\t\t\twalk(n.List.Nodes)\n+\t\t\t\tif n.ElseList != nil {\n+\t\t\t\t\twalk(n.ElseList.Nodes)\n+\t\t\t\t}\n+\t\t\tcase *parse.ListNode:\n+\t\t\t\twalk(n.Nodes)\n+\t\t\tcase *parse.RangeNode:\n+\t\t\t\twalk(n.List.Nodes)\n+\t\t\t\tif n.ElseList != nil {\n+\t\t\t\t\twalk(n.ElseList.Nodes)\n+\t\t\t\t}\n+\t\t\tcase *parse.WithNode:\n+\t\t\t\twalk(n.List.Nodes)\n+\t\t\t\tif n.ElseList != nil {\n+\t\t\t\t\twalk(n.ElseList.Nodes)\n+\t\t\t\t}\n+\t\t\tdefault:\n+\t\t\t\t// Continue to next node\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\tif found {\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\twalk(tmpl.Tree.Root.Nodes)\n+\treturn result, found\n+}\n+\n+// isToolCallsNode detects if a node's condition includes \".ToolCalls\"\n+func isToolCallsNode(n *parse.IfNode) bool {\n+\tfor _, cmd := range n.Pipe.Cmds {\n+\t\tfor _, arg := range cmd.Args {\n+\t\t\tif field, ok := arg.(*parse.FieldNode); ok {\n+\t\t\t\tif slices.Contains(field.Ident, \"ToolCalls\") {\n+\t\t\t\t\treturn true\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+// TODO(parthsareen): get full prefix from the template instead of just the first token\n+\n+// toolPrefix returns the prefix for the tool call if it exists from a template\n+func toolPrefix(tmpl *gotmpl.Template) string {\n+\ttokenText, ok := extractToolCallsFormat(tmpl)\n+\tif !ok {\n+\t\treturn \"\"\n+\t}\n+\ttokenText = strings.TrimSpace(tokenText)\n+\tif tokenText == \"\" {\n+\t\treturn \"\"\n+\t}\n+\tfirst := strings.Fields(tokenText)[0]\n+\n+\tstart := -1\n+\tend := -1\n+\tfor i, r := range tokenText {\n+\t\tif r == '<' || r == '[' {\n+\t\t\tstart = i\n+\t\t}\n+\t\tif (r == '>' || r == ']') && start != -1 {\n+\t\t\tend = i\n+\t\t\tbreak\n+\t\t}\n+\t}\n+\tif start != -1 && end != -1 {\n+\t\t// return the token including the [ or < and the ] or >\n+\t\treturn tokenText[start : end+1]\n+\t} else if start != -1 {\n+\t\t// get until the [ or < - in the case tag was not closed\n+\t\treturn tokenText[:start]\n+\t} else if end != -1 {\n+\t\t// get after the ] or > - in the case tag was not opened\n+\t\treturn tokenText[end+1:]\n+\t}\n+\treturn first\n+}\n+\n+// toolTemplate creates a subtree from the node that ranges over .ToolCalls\n+//\n+// Returns:\n+//   - *gotmpl.Template: The subtree containing the .ToolCalls range\n+//   - error: Error if parsing failed\n+func toolTemplate(t *template.Template) (*gotmpl.Template, error) {\n+\ttmpl := t.Subtree(func(n parse.Node) bool {\n+\t\tif t, ok := n.(*parse.RangeNode); ok {\n+\t\t\treturn slices.Contains(template.Identifiers(t.Pipe), \"ToolCalls\")\n+\t\t}\n+\n+\t\treturn false\n+\t})\n+\n+\tif tmpl == nil {\n+\t\treturn nil, errors.New(\"failed to find tool template\")\n+\t}\n+\n+\treturn tmpl, nil\n+}\n+\n+// suffixOverlap returns the length of the longest suffix overlap between two strings\n+//\n+// Returns:\n+//   - int: The length of the longest suffix overlap\n+func suffixOverlap(s, prefix string) int {\n+\tmax := min(len(prefix), len(s))\n+\tfor i := max; i > 0; i-- {\n+\t\tif strings.HasSuffix(s, prefix[:i]) {\n+\t\t\treturn i\n+\t\t}\n+\t}\n+\treturn 0\n+}\n+\n+// extractToolArgs executes a template with a known tool call format to extract the name and arguments\n+//\n+// Returns:\n+//   - string: The name of the tool call\n+//   - string: The arguments of the tool call\n+//   - error: Error if parsing failed\n+func extractToolArgs(tmpl *gotmpl.Template) (name, arguments string, err error) {\n+\tvar b bytes.Buffer\n+\tif err := tmpl.Execute(&b, map[string][]api.ToolCall{\n+\t\t\"ToolCalls\": {\n+\t\t\t{\n+\t\t\t\tFunction: api.ToolCallFunction{\n+\t\t\t\t\tName: \"@@name@@\",\n+\t\t\t\t\tArguments: api.ToolCallFunctionArguments{\n+\t\t\t\t\t\t\"@@argument@@\": 1,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t},\n+\t\t},\n+\t}); err != nil {\n+\t\treturn \"\", \"\", err\n+\t}\n+\n+\tvar obj any\n+\terr = json.Unmarshal(b.Bytes(), &obj)\n+\tif err != nil {\n+\t\treturn \"\", \"\", err\n+\t}\n+\n+\tvar objs []map[string]any\n+\tswitch v := obj.(type) {\n+\tcase map[string]any:\n+\t\tobjs = []map[string]any{v}\n+\tcase []map[string]any:\n+\t\tobjs = v\n+\tcase []any:\n+\t\tobjs = collect(v)\n+\t}\n+\tif len(objs) == 0 {\n+\t\treturn \"\", \"\", errors.New(\"no template objects found\")\n+\t}\n+\n+\t// find the keys that correspond to the name and arguments fields\n+\tfor k, v := range objs[0] {\n+\t\tswitch v.(type) {\n+\t\tcase string:\n+\t\t\tname = k\n+\t\tcase map[string]any:\n+\t\t\targuments = k\n+\t\t}\n+\t}\n+\n+\tif name == \"\" || arguments == \"\" {\n+\t\tslog.Debug(\"missing required fields in tool call template\", \"name\", name, \"arguments\", arguments)\n+\t\treturn \"\", \"\", errors.New(\"missing required fields in tool call template\")\n+\t}\n+\n+\treturn name, arguments, nil\n+}\n+\n+// collect recursively traverses an object to collect all nested maps\n+//\n+// Returns:\n+//   - []map[string]any: A slice of all nested maps found in the object\n+func collect(obj any) []map[string]any {\n+\tvar all []map[string]any\n+\tswitch o := obj.(type) {\n+\tcase map[string]any:\n+\t\tall = append(all, o)\n+\t\tfor _, v := range o {\n+\t\t\tall = append(all, collect(v)...)\n+\t\t}\n+\tcase []any:\n+\t\tfor _, v := range o {\n+\t\t\tall = append(all, collect(v)...)\n+\t\t}\n+\tdefault:\n+\t\treturn nil\n+\t}\n+\n+\treturn all\n+}\n+\n+// parseJSONToolCalls attempts to parse a JSON string into a slice ToolCalls.\n+// It first checks for balanced braces before attempting to parse.\n+// Returns:\n+//   - []api.ToolCall: The parsed tool calls if successful\n+//   - error: ErrAccumulateMore if braces unbalanced, ErrInvalidToolCall if invalid, or nil if successful\n+func parseJSONToolCalls(s string, name, arguments string) ([]api.ToolCall, error) {",
        "comment_created_at": "2025-05-19T19:02:33+00:00",
        "comment_author": "jmorganca",
        "comment_body": "What is `name` and `arguments` here? Are those the formats? I would add them to the GoDoc for this function. I'm not sure what their purposes is from reading the comment.\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1994353470",
    "pr_number": 9743,
    "pr_file": "sample/transforms.go",
    "created_at": "2025-03-13T21:56:07+00:00",
    "commented_code": "}\n \n // temperature applies scaling to the logits\n-func temperature(ts []token, temp float32) []token {\n+func temperature(ts *[]token, temp float32) {\n+\tif ts == nil {\n+\t\treturn\n+\t}\n+\n \t// Ensure temperature clipping near 0 to avoid numerical instability\n \ttemp = max(temp, 1e-7)\n-\tfor i := range ts {\n-\t\tts[i].value = ts[i].value / temp\n+\tfor i := range *ts {\n+\t\t(*ts)[i].value = (*ts)[i].value / temp\n \t}\n-\treturn ts\n }\n \n // softmax applies normalization to the logits\n-func softmax(ts []token) []token {\n+func softmax(ts *[]token) {\n+\tif ts == nil {\n+\t\treturn\n+\t}\n+\n \t// Find max logit for numerical stability\n \tmaxLogit := float32(math.Inf(-1))\n-\tfor _, t := range ts {\n+\tfor _, t := range *ts {\n \t\tif t.value > maxLogit {\n \t\t\tmaxLogit = t.value\n \t\t}\n \t}\n \n \t// Compute exp(x - max)\n \tvar sum float32\n-\tfor i, v := range ts {\n-\t\tts[i].value = float32(math.Exp(float64(v.value - maxLogit)))\n-\t\tsum += ts[i].value\n+\tfor i, v := range *ts {\n+\t\t(*ts)[i].value = float32(math.Exp(float64(v.value - maxLogit)))\n+\t\tsum += (*ts)[i].value\n \t}\n \n \t// exp(x - max) / sum(exp(x - max))\n-\tfor i := range ts {\n-\t\tts[i].value /= sum\n+\tfor i := range *ts {\n+\t\t(*ts)[i].value /= sum\n \t}\n-\n-\treturn ts\n }\n \n // topK limits the number of tokens considered to the k highest logits\n-func topK(ts []token, k int) []token {\n-\tif k >= len(ts) || k <= 0 {\n-\t\tslices.SortFunc(ts, func(a, b token) int {\n+func topK(ts *[]token, k int) {",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1994353470",
        "repo_full_name": "ollama/ollama",
        "pr_number": 9743,
        "pr_file": "sample/transforms.go",
        "discussion_id": "1994353470",
        "commented_code": "@@ -26,44 +26,53 @@ func (h *tokenHeap) Pop() any {\n }\n \n // temperature applies scaling to the logits\n-func temperature(ts []token, temp float32) []token {\n+func temperature(ts *[]token, temp float32) {\n+\tif ts == nil {\n+\t\treturn\n+\t}\n+\n \t// Ensure temperature clipping near 0 to avoid numerical instability\n \ttemp = max(temp, 1e-7)\n-\tfor i := range ts {\n-\t\tts[i].value = ts[i].value / temp\n+\tfor i := range *ts {\n+\t\t(*ts)[i].value = (*ts)[i].value / temp\n \t}\n-\treturn ts\n }\n \n // softmax applies normalization to the logits\n-func softmax(ts []token) []token {\n+func softmax(ts *[]token) {\n+\tif ts == nil {\n+\t\treturn\n+\t}\n+\n \t// Find max logit for numerical stability\n \tmaxLogit := float32(math.Inf(-1))\n-\tfor _, t := range ts {\n+\tfor _, t := range *ts {\n \t\tif t.value > maxLogit {\n \t\t\tmaxLogit = t.value\n \t\t}\n \t}\n \n \t// Compute exp(x - max)\n \tvar sum float32\n-\tfor i, v := range ts {\n-\t\tts[i].value = float32(math.Exp(float64(v.value - maxLogit)))\n-\t\tsum += ts[i].value\n+\tfor i, v := range *ts {\n+\t\t(*ts)[i].value = float32(math.Exp(float64(v.value - maxLogit)))\n+\t\tsum += (*ts)[i].value\n \t}\n \n \t// exp(x - max) / sum(exp(x - max))\n-\tfor i := range ts {\n-\t\tts[i].value /= sum\n+\tfor i := range *ts {\n+\t\t(*ts)[i].value /= sum\n \t}\n-\n-\treturn ts\n }\n \n // topK limits the number of tokens considered to the k highest logits\n-func topK(ts []token, k int) []token {\n-\tif k >= len(ts) || k <= 0 {\n-\t\tslices.SortFunc(ts, func(a, b token) int {\n+func topK(ts *[]token, k int) {",
        "comment_created_at": "2025-03-13T21:56:07+00:00",
        "comment_author": "jmorganca",
        "comment_body": "Add comment as to why it's passed in by pointer here. Something like the length of the slice is modified to k",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1964268337",
    "pr_number": 9256,
    "pr_file": "ml/backend.go",
    "created_at": "2025-02-20T20:08:37+00:00",
    "commented_code": "SystemInfo() string\n }\n \n-var backends = make(map[string]func(*os.File) (Backend, error))\n+// BackendParams controls how the backend loads and executes models\n+type BackendParams struct {\n+\tNumThreads int // Number of threads to use if running on the CPU\n \n-func RegisterBackend(name string, f func(*os.File) (Backend, error)) {\n+\tMainGPU      int       // Main GPU\n+\tNumGPULayers int       // Number of layers to offload to GPU\n+\tTensorSplit  []float32 // Fraction of the model to offload to each GPU",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1964268337",
        "repo_full_name": "ollama/ollama",
        "pr_number": 9256,
        "pr_file": "ml/backend.go",
        "discussion_id": "1964268337",
        "commented_code": "@@ -26,19 +26,28 @@ type Backend interface {\n \tSystemInfo() string\n }\n \n-var backends = make(map[string]func(*os.File) (Backend, error))\n+// BackendParams controls how the backend loads and executes models\n+type BackendParams struct {\n+\tNumThreads int // Number of threads to use if running on the CPU\n \n-func RegisterBackend(name string, f func(*os.File) (Backend, error)) {\n+\tMainGPU      int       // Main GPU\n+\tNumGPULayers int       // Number of layers to offload to GPU\n+\tTensorSplit  []float32 // Fraction of the model to offload to each GPU",
        "comment_created_at": "2025-02-20T20:08:37+00:00",
        "comment_author": "jmorganca",
        "comment_body": "pedantic but should we make these GoDoc comments above the fields?\r\n\r\n```\r\n//MainGPU is the gpu where xyz...\r\nMainGPU int\r\n```\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "1964357944",
        "repo_full_name": "ollama/ollama",
        "pr_number": 9256,
        "pr_file": "ml/backend.go",
        "discussion_id": "1964268337",
        "commented_code": "@@ -26,19 +26,28 @@ type Backend interface {\n \tSystemInfo() string\n }\n \n-var backends = make(map[string]func(*os.File) (Backend, error))\n+// BackendParams controls how the backend loads and executes models\n+type BackendParams struct {\n+\tNumThreads int // Number of threads to use if running on the CPU\n \n-func RegisterBackend(name string, f func(*os.File) (Backend, error)) {\n+\tMainGPU      int       // Main GPU\n+\tNumGPULayers int       // Number of layers to offload to GPU\n+\tTensorSplit  []float32 // Fraction of the model to offload to each GPU",
        "comment_created_at": "2025-02-20T21:23:21+00:00",
        "comment_author": "jessegross",
        "comment_body": "Sure",
        "pr_file_module": null
      }
    ]
  }
]