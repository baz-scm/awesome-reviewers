[
  {
    "discussion_id": "1983913312",
    "pr_number": 9374,
    "pr_file": "sample/samplers.go",
    "created_at": "2025-03-06T19:07:51+00:00",
    "commented_code": "import (\n \t\"errors\"\n-\t\"math\"\n-\n-\t\"golang.org/x/exp/rand\"\n-\t\"gonum.org/v1/gonum/stat/sampleuv\"\n+\t\"math/rand/v2\"\n )\n \n+// Sampler is not thread-safe. Each goroutine should have its own instance.\n type Sampler interface {\n \tSample([]float32) (int32, error)\n }\n \n+type tokenInfo struct {\n+\tid    int32\n+\tlogit float32\n+\tprob  float32\n+}\n+\n+type tokenSliceInfo struct {\n+\ttokens []tokenInfo\n+\tsorted bool\n+\tsum    float32\n+}\n+\n type weighted struct {\n-\tsrc        rand.Source\n-\ttransforms []Transform\n+\trng        *rand.Rand\n+\ttransforms []transform\n }\n \n-// TODO(parthsareen): remove uv sample dependency https://github.com/ollama/ollama/issues/9279\n-func Weighted(seed *uint64, transforms ...Transform) Sampler {\n-\tvar src rand.Source\n-\tif seed != nil {\n-\t\tsrc = rand.NewSource(*seed)\n+func Weighted(rng *rand.Rand, transforms ...transform) Sampler {\n+\treturn &weighted{\n+\t\trng:        rng,\n+\t\ttransforms: transforms,\n \t}\n-\treturn weighted{src: src, transforms: transforms}\n }\n \n-func (s weighted) Sample(logits []float32) (int32, error) {\n-\tlogits64 := make([]float64, len(logits))\n+func (s *weighted) Sample(logits []float32) (int32, error) {\n+\ttokens := make([]tokenInfo, len(logits))",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1983913312",
        "repo_full_name": "ollama/ollama",
        "pr_number": 9374,
        "pr_file": "sample/samplers.go",
        "discussion_id": "1983913312",
        "commented_code": "@@ -2,59 +2,75 @@ package sample\n \n import (\n \t\"errors\"\n-\t\"math\"\n-\n-\t\"golang.org/x/exp/rand\"\n-\t\"gonum.org/v1/gonum/stat/sampleuv\"\n+\t\"math/rand/v2\"\n )\n \n+// Sampler is not thread-safe. Each goroutine should have its own instance.\n type Sampler interface {\n \tSample([]float32) (int32, error)\n }\n \n+type tokenInfo struct {\n+\tid    int32\n+\tlogit float32\n+\tprob  float32\n+}\n+\n+type tokenSliceInfo struct {\n+\ttokens []tokenInfo\n+\tsorted bool\n+\tsum    float32\n+}\n+\n type weighted struct {\n-\tsrc        rand.Source\n-\ttransforms []Transform\n+\trng        *rand.Rand\n+\ttransforms []transform\n }\n \n-// TODO(parthsareen): remove uv sample dependency https://github.com/ollama/ollama/issues/9279\n-func Weighted(seed *uint64, transforms ...Transform) Sampler {\n-\tvar src rand.Source\n-\tif seed != nil {\n-\t\tsrc = rand.NewSource(*seed)\n+func Weighted(rng *rand.Rand, transforms ...transform) Sampler {\n+\treturn &weighted{\n+\t\trng:        rng,\n+\t\ttransforms: transforms,\n \t}\n-\treturn weighted{src: src, transforms: transforms}\n }\n \n-func (s weighted) Sample(logits []float32) (int32, error) {\n-\tlogits64 := make([]float64, len(logits))\n+func (s *weighted) Sample(logits []float32) (int32, error) {\n+\ttokens := make([]tokenInfo, len(logits))",
        "comment_created_at": "2025-03-06T19:07:51+00:00",
        "comment_author": "jmorganca",
        "comment_body": "this allocation can be one time?\r\n\r\n```\r\ntype weighted struct {\r\n\trng        *rand.Rand\r\n\ttransforms []transform\r\n\tbuf        []tokenInfo // reuse buffer\r\n}\r\n\r\nfunc (s *weighted) Sample(logits []float32) (int32, error) {\r\n\tif cap(s.buf) < len(logits) {\r\n\t\ts.buf = make([]tokenInfo, len(logits))\r\n\t}\r\n\ttokens := s.buf[:len(logits)]\r\n\t// rest of your logic\r\n}\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1983964187",
        "repo_full_name": "ollama/ollama",
        "pr_number": 9374,
        "pr_file": "sample/samplers.go",
        "discussion_id": "1983913312",
        "commented_code": "@@ -2,59 +2,75 @@ package sample\n \n import (\n \t\"errors\"\n-\t\"math\"\n-\n-\t\"golang.org/x/exp/rand\"\n-\t\"gonum.org/v1/gonum/stat/sampleuv\"\n+\t\"math/rand/v2\"\n )\n \n+// Sampler is not thread-safe. Each goroutine should have its own instance.\n type Sampler interface {\n \tSample([]float32) (int32, error)\n }\n \n+type tokenInfo struct {\n+\tid    int32\n+\tlogit float32\n+\tprob  float32\n+}\n+\n+type tokenSliceInfo struct {\n+\ttokens []tokenInfo\n+\tsorted bool\n+\tsum    float32\n+}\n+\n type weighted struct {\n-\tsrc        rand.Source\n-\ttransforms []Transform\n+\trng        *rand.Rand\n+\ttransforms []transform\n }\n \n-// TODO(parthsareen): remove uv sample dependency https://github.com/ollama/ollama/issues/9279\n-func Weighted(seed *uint64, transforms ...Transform) Sampler {\n-\tvar src rand.Source\n-\tif seed != nil {\n-\t\tsrc = rand.NewSource(*seed)\n+func Weighted(rng *rand.Rand, transforms ...transform) Sampler {\n+\treturn &weighted{\n+\t\trng:        rng,\n+\t\ttransforms: transforms,\n \t}\n-\treturn weighted{src: src, transforms: transforms}\n }\n \n-func (s weighted) Sample(logits []float32) (int32, error) {\n-\tlogits64 := make([]float64, len(logits))\n+func (s *weighted) Sample(logits []float32) (int32, error) {\n+\ttokens := make([]tokenInfo, len(logits))",
        "comment_created_at": "2025-03-06T19:50:09+00:00",
        "comment_author": "ParthSareen",
        "comment_body": "Good call!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2075992214",
    "pr_number": 10363,
    "pr_file": "server/quantization.go",
    "created_at": "2025-05-06T17:56:38+00:00",
    "commented_code": "+package server\n+\n+import (\n+\t\"fmt\"\n+\t\"io\"\n+\t\"log/slog\"\n+\t\"maps\"\n+\t\"os\"\n+\t\"strings\"\n+\t\"unsafe\"\n+\n+\tfsggml \"github.com/ollama/ollama/fs/ggml\"\n+\t\"github.com/ollama/ollama/ml/backend/ggml\"\n+)\n+\n+type quantizer struct {\n+\t*os.File\n+\toffset     uint64\n+\tfrom, to   *fsggml.Tensor\n+\tprogressFn func(n uint64)\n+}\n+\n+func (q quantizer) WriteTo(w io.Writer) (int64, error) {\n+\tquantize := q.from.Kind != q.to.Kind\n+\tsr := io.NewSectionReader(q, int64(q.offset), int64(q.from.Size()))\n+\tdata := make([]byte, q.from.Size())\n+\t_, err := io.ReadFull(sr, data)\n+\tif err != nil {\n+\t\tslog.Warn(\"file read error\", \"tensor\", q.from.Name, \"file\", q.Name(), \"error\", err)\n+\t\treturn 0, fmt.Errorf(\"unable to read tensor %s from %s: %s\", q.from.Name, q.Name(), err)\n+\t}\n+\tif quantize {\n+\t\tvar f32s []float32\n+\t\tnewType := fsggml.TensorType(q.to.Kind)\n+\t\tif fsggml.TensorType(q.from.Kind) == fsggml.TensorTypeF32 {\n+\t\t\tf32s = unsafe.Slice((*float32)(unsafe.Pointer(&data[0])), q.from.Elements())\n+\t\t} else {\n+\t\t\tf32s = ggml.ConvertToF32(data, q.from.Kind, q.from.Elements())\n+\t\t}\n+\t\tdata = ggml.Quantize(newType, f32s, q.from.Shape)\n+\t}\n+\n+\tn, err := w.Write(data)\n+\tq.progressFn(q.from.Size())\n+\treturn int64(n), err",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "2075992214",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10363,
        "pr_file": "server/quantization.go",
        "discussion_id": "2075992214",
        "commented_code": "@@ -0,0 +1,273 @@\n+package server\n+\n+import (\n+\t\"fmt\"\n+\t\"io\"\n+\t\"log/slog\"\n+\t\"maps\"\n+\t\"os\"\n+\t\"strings\"\n+\t\"unsafe\"\n+\n+\tfsggml \"github.com/ollama/ollama/fs/ggml\"\n+\t\"github.com/ollama/ollama/ml/backend/ggml\"\n+)\n+\n+type quantizer struct {\n+\t*os.File\n+\toffset     uint64\n+\tfrom, to   *fsggml.Tensor\n+\tprogressFn func(n uint64)\n+}\n+\n+func (q quantizer) WriteTo(w io.Writer) (int64, error) {\n+\tquantize := q.from.Kind != q.to.Kind\n+\tsr := io.NewSectionReader(q, int64(q.offset), int64(q.from.Size()))\n+\tdata := make([]byte, q.from.Size())\n+\t_, err := io.ReadFull(sr, data)\n+\tif err != nil {\n+\t\tslog.Warn(\"file read error\", \"tensor\", q.from.Name, \"file\", q.Name(), \"error\", err)\n+\t\treturn 0, fmt.Errorf(\"unable to read tensor %s from %s: %s\", q.from.Name, q.Name(), err)\n+\t}\n+\tif quantize {\n+\t\tvar f32s []float32\n+\t\tnewType := fsggml.TensorType(q.to.Kind)\n+\t\tif fsggml.TensorType(q.from.Kind) == fsggml.TensorTypeF32 {\n+\t\t\tf32s = unsafe.Slice((*float32)(unsafe.Pointer(&data[0])), q.from.Elements())\n+\t\t} else {\n+\t\t\tf32s = ggml.ConvertToF32(data, q.from.Kind, q.from.Elements())\n+\t\t}\n+\t\tdata = ggml.Quantize(newType, f32s, q.from.Shape)\n+\t}\n+\n+\tn, err := w.Write(data)\n+\tq.progressFn(q.from.Size())\n+\treturn int64(n), err",
        "comment_created_at": "2025-05-06T17:56:38+00:00",
        "comment_author": "mxyng",
        "comment_body": "Shouldn't buffer the data if `!quantize`\r\n\r\n```suggestion\r\n\tif !quantize {\r\n\t\tn, err := io.Copy(w, sr)\r\n\t\tq.progressFn(q.from.Size())\r\n\t\treturn int64(n), err\r\n\t}\r\n\r\n\tdata := make([]byte, q.from.Size())\r\n\t_, err := io.ReadFull(sr, data)\r\n\tif err != nil {\r\n\t\tslog.Warn(\"file read error\", \"tensor\", q.from.Name, \"file\", q.Name(), \"error\", err)\r\n\t\treturn 0, fmt.Errorf(\"unable to read tensor %s from %s: %s\", q.from.Name, q.Name(), err)\r\n\t}\r\n\r\n\tvar f32s []float32\r\n\tnewType := fsggml.TensorType(q.to.Kind)\r\n\tif fsggml.TensorType(q.from.Kind) == fsggml.TensorTypeF32 {\r\n\t\tf32s = unsafe.Slice((*float32)(unsafe.Pointer(&data[0])), q.from.Elements())\r\n\t} else {\r\n\t\tf32s = ggml.ConvertToF32(data, q.from.Kind, q.from.Elements())\r\n\t}\r\n\tdata = ggml.Quantize(newType, f32s, q.from.Shape)\r\n\r\n\tn, err := w.Write(data)\r\n\tq.progressFn(n)\r\n\treturn int64(n), err\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2006563010",
    "pr_number": 9897,
    "pr_file": "ml/backend/ggml/ggml.go",
    "created_at": "2025-03-20T22:41:04+00:00",
    "commented_code": "return fmt.Errorf(\"unassigned tensor: %s\", t.Name)\n \t\t\t\t}\n \n-\t\t\t\tbts := C.malloc(C.size_t(t.Size()))\n-\t\t\t\tif bts == nil {\n-\t\t\t\t\treturn errors.New(\"failed to allocate tensor buffer\")\n+\t\t\t\ttts[i] = tt\n+\t\t\t}\n+\n+\t\t\tbsr := bufio.NewReader(io.NewSectionReader(sr, int64(t.Offset), int64(t.Size())))",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "2006563010",
        "repo_full_name": "ollama/ollama",
        "pr_number": 9897,
        "pr_file": "ml/backend/ggml/ggml.go",
        "discussion_id": "2006563010",
        "commented_code": "@@ -312,24 +320,53 @@ func New(r *os.File, params ml.BackendParams) (ml.Backend, error) {\n \t\t\t\t\treturn fmt.Errorf(\"unassigned tensor: %s\", t.Name)\n \t\t\t\t}\n \n-\t\t\t\tbts := C.malloc(C.size_t(t.Size()))\n-\t\t\t\tif bts == nil {\n-\t\t\t\t\treturn errors.New(\"failed to allocate tensor buffer\")\n+\t\t\t\ttts[i] = tt\n+\t\t\t}\n+\n+\t\t\tbsr := bufio.NewReader(io.NewSectionReader(sr, int64(t.Offset), int64(t.Size())))",
        "comment_created_at": "2025-03-20T22:41:04+00:00",
        "comment_author": "jessegross",
        "comment_body": "The default size for a buffered I/O reader is 4k. Since we are reading in 32k chunks, is buffered I/O actually providing any value or is it just adding an extra copy?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1960652112",
    "pr_number": 9079,
    "pr_file": "progress/progress.go",
    "created_at": "2025-02-18T21:59:18+00:00",
    "commented_code": "}\n \n type Progress struct {\n-\tmu sync.Mutex\n-\tw  io.Writer\n+\tmu  sync.Mutex\n+\tw   io.Writer\n+\tbuf bytes.Buffer",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1960652112",
        "repo_full_name": "ollama/ollama",
        "pr_number": 9079,
        "pr_file": "progress/progress.go",
        "discussion_id": "1960652112",
        "commented_code": "@@ -12,8 +13,9 @@ type State interface {\n }\n \n type Progress struct {\n-\tmu sync.Mutex\n-\tw  io.Writer\n+\tmu  sync.Mutex\n+\tw   io.Writer\n+\tbuf bytes.Buffer",
        "comment_created_at": "2025-02-18T21:59:18+00:00",
        "comment_author": "mxyng",
        "comment_body": "This can be simplified by using a bufio.Writer instead\r\n\r\n```suggestion\r\n\tw   *bufio.Writer\r\n```",
        "pr_file_module": null
      }
    ]
  }
]