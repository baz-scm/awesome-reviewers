[
  {
    "discussion_id": "1706265368",
    "pr_number": 5872,
    "pr_file": "gpu/ascend_linux.go",
    "created_at": "2024-08-07T01:17:48+00:00",
    "commented_code": "+//go:build linux\n+\n+package gpu\n+\n+/*\n+#cgo linux LDFLAGS: -lrt -lpthread -ldl -lstdc++ -lm\n+#cgo windows LDFLAGS: -lpthread\n+\n+#include \"gpu_info_ascend.h\"\n+\n+*/\n+import \"C\"\n+import (\n+\t\"fmt\"\n+\t\"log/slog\"\n+\t\"unsafe\"\n+)\n+\n+var AscendLinuxGlobs = []string{\n+\t\"/usr/local/Ascend/latest/aarch64-linux/lib64/libascendcl.so*\",",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1706265368",
        "repo_full_name": "ollama/ollama",
        "pr_number": 5872,
        "pr_file": "gpu/ascend_linux.go",
        "discussion_id": "1706265368",
        "commented_code": "@@ -0,0 +1,80 @@\n+//go:build linux\n+\n+package gpu\n+\n+/*\n+#cgo linux LDFLAGS: -lrt -lpthread -ldl -lstdc++ -lm\n+#cgo windows LDFLAGS: -lpthread\n+\n+#include \"gpu_info_ascend.h\"\n+\n+*/\n+import \"C\"\n+import (\n+\t\"fmt\"\n+\t\"log/slog\"\n+\t\"unsafe\"\n+)\n+\n+var AscendLinuxGlobs = []string{\n+\t\"/usr/local/Ascend/latest/aarch64-linux/lib64/libascendcl.so*\",",
        "comment_created_at": "2024-08-07T01:17:48+00:00",
        "comment_author": "hipudding",
        "comment_body": "If user install asccend-toolkit with non-root user. The lib path is in their home dir. Please use ENV instead.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1733785997",
    "pr_number": 5872,
    "pr_file": "gpu/ascend_linux.go",
    "created_at": "2024-08-28T02:23:31+00:00",
    "commented_code": "+//go:build linux\n+\n+package gpu\n+\n+/*\n+#cgo linux LDFLAGS: -lrt -lpthread -ldl -lstdc++ -lm\n+#cgo windows LDFLAGS: -lpthread\n+\n+#include \"gpu_info_ascend.h\"\n+\n+*/\n+import \"C\"\n+import (\n+\t\"fmt\"\n+\t\"log/slog\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+\t\"unsafe\"\n+)\n+\n+var AscendLinuxGlobs = []string{\n+\t\"/usr/local/Ascend/latest/aarch64-linux/lib64/libascendcl.so*\",",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1733785997",
        "repo_full_name": "ollama/ollama",
        "pr_number": 5872,
        "pr_file": "gpu/ascend_linux.go",
        "discussion_id": "1733785997",
        "commented_code": "@@ -0,0 +1,101 @@\n+//go:build linux\n+\n+package gpu\n+\n+/*\n+#cgo linux LDFLAGS: -lrt -lpthread -ldl -lstdc++ -lm\n+#cgo windows LDFLAGS: -lpthread\n+\n+#include \"gpu_info_ascend.h\"\n+\n+*/\n+import \"C\"\n+import (\n+\t\"fmt\"\n+\t\"log/slog\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"strings\"\n+\t\"unsafe\"\n+)\n+\n+var AscendLinuxGlobs = []string{\n+\t\"/usr/local/Ascend/latest/aarch64-linux/lib64/libascendcl.so*\",",
        "comment_created_at": "2024-08-28T02:23:31+00:00",
        "comment_author": "hipudding",
        "comment_body": "Still can't find libascendcl.so in this path.\r\n\r\nit's better to use: $ASCEND_TOOLKIT_HOME/lib64",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2047331915",
    "pr_number": 10285,
    "pr_file": "server/zeroconf.go",
    "created_at": "2025-04-16T16:41:08+00:00",
    "commented_code": "+package server\n+\n+import (\n+\t\"log\"\n+\n+\t\"github.com/grandcat/zeroconf\"\n+)\n+\n+var server *zeroconf.Server\n+\n+// RegisterService registers the service with Zeroconf\n+func RegisterService() {\n+\tvar err error\n+\tserver, err = zeroconf.Register(\n+\t\t\"OllamaInstance\",    // Service Name\n+\t\t\"_ollama._tcp\",      // Service Type\n+\t\t\"local.\",            // Domain\n+\t\t11434,               // Port",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "2047331915",
        "repo_full_name": "ollama/ollama",
        "pr_number": 10285,
        "pr_file": "server/zeroconf.go",
        "discussion_id": "2047331915",
        "commented_code": "@@ -0,0 +1,35 @@\n+package server\n+\n+import (\n+\t\"log\"\n+\n+\t\"github.com/grandcat/zeroconf\"\n+)\n+\n+var server *zeroconf.Server\n+\n+// RegisterService registers the service with Zeroconf\n+func RegisterService() {\n+\tvar err error\n+\tserver, err = zeroconf.Register(\n+\t\t\"OllamaInstance\",    // Service Name\n+\t\t\"_ollama._tcp\",      // Service Type\n+\t\t\"local.\",            // Domain\n+\t\t11434,               // Port",
        "comment_created_at": "2025-04-16T16:41:08+00:00",
        "comment_author": "cwthomas-llu",
        "comment_body": "You shouldn't hardcode the port as the default port can be changed through the env variable `OLLAMA_HOST`.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1851037921",
    "pr_number": 5059,
    "pr_file": "gpu/gpu_linux.go",
    "created_at": "2024-11-20T22:02:03+00:00",
    "commented_code": "NvcudaMgmtName = \"libcuda.so*\"\n \tNvmlMgmtName   = \"\" // not currently wired on linux\n \tOneapiMgmtName = \"libze_intel_gpu.so*\"\n+\tVulkanMgmtName = \"libvulkan.so*\"\n+\tlibcapMgmtName = \"libcap.so*\"\n )\n \n+var VulkanGlobs = []string{\n+\t\"/usr/lib/x86_64-linux-gnu/libvulkan.so*\",",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1851037921",
        "repo_full_name": "ollama/ollama",
        "pr_number": 5059,
        "pr_file": "gpu/gpu_linux.go",
        "discussion_id": "1851037921",
        "commented_code": "@@ -48,8 +48,24 @@ var (\n \tNvcudaMgmtName = \"libcuda.so*\"\n \tNvmlMgmtName   = \"\" // not currently wired on linux\n \tOneapiMgmtName = \"libze_intel_gpu.so*\"\n+\tVulkanMgmtName = \"libvulkan.so*\"\n+\tlibcapMgmtName = \"libcap.so*\"\n )\n \n+var VulkanGlobs = []string{\n+\t\"/usr/lib/x86_64-linux-gnu/libvulkan.so*\",",
        "comment_created_at": "2024-11-20T22:02:03+00:00",
        "comment_author": "geerlingguy",
        "comment_body": "This doesn't account for other arch's like aarch64. On my Raspberry Pi (see https://github.com/geerlingguy/ollama-benchmark/issues/1#issuecomment-2489622573), I get the error:\r\n\r\n```\r\n+ cp '/usr/lib//libvulkan.so*' ../build/linux/arm64/vulkan/bin/\r\ncp: cannot stat '/usr/lib//libvulkan.so*': No such file or directory\r\nllm/generate/generate_linux.go:3: running \"bash\": exit status 1\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1865742356",
        "repo_full_name": "ollama/ollama",
        "pr_number": 5059,
        "pr_file": "gpu/gpu_linux.go",
        "discussion_id": "1851037921",
        "commented_code": "@@ -48,8 +48,24 @@ var (\n \tNvcudaMgmtName = \"libcuda.so*\"\n \tNvmlMgmtName   = \"\" // not currently wired on linux\n \tOneapiMgmtName = \"libze_intel_gpu.so*\"\n+\tVulkanMgmtName = \"libvulkan.so*\"\n+\tlibcapMgmtName = \"libcap.so*\"\n )\n \n+var VulkanGlobs = []string{\n+\t\"/usr/lib/x86_64-linux-gnu/libvulkan.so*\",",
        "comment_created_at": "2024-12-02T12:11:24+00:00",
        "comment_author": "TheArcaneBrony",
        "comment_body": "Also unlikely to work on NixOS for example, as /usr/lib doesn't exist there (could use an environment variable?)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1504770055",
    "pr_number": 2770,
    "pr_file": "server/modelpath.go",
    "created_at": "2024-02-27T18:47:47+00:00",
    "commented_code": "// modelsDir returns the value of the OLLAMA_MODELS environment variable or the user's home directory if OLLAMA_MODELS is not set.\n // The models directory is where Ollama stores its model files and manifests.\n func modelsDir() (string, error) {\n-\tif models, exists := os.LookupEnv(\"OLLAMA_MODELS\"); exists {\n-\t\treturn models, nil\n-\t}\n \thome, err := os.UserHomeDir()\n \tif err != nil {\n \t\treturn \"\", err\n \t}\n+\tif models, exists := os.LookupEnv(\"OLLAMA_MODELS\"); exists {\n+\t\tif strings.HasPrefix(models, \"~/\") {",
    "repo_full_name": "ollama/ollama",
    "discussion_comments": [
      {
        "comment_id": "1504770055",
        "repo_full_name": "ollama/ollama",
        "pr_number": 2770,
        "pr_file": "server/modelpath.go",
        "discussion_id": "1504770055",
        "commented_code": "@@ -103,13 +103,16 @@ func (mp ModelPath) GetShortTagname() string {\n // modelsDir returns the value of the OLLAMA_MODELS environment variable or the user's home directory if OLLAMA_MODELS is not set.\n // The models directory is where Ollama stores its model files and manifests.\n func modelsDir() (string, error) {\n-\tif models, exists := os.LookupEnv(\"OLLAMA_MODELS\"); exists {\n-\t\treturn models, nil\n-\t}\n \thome, err := os.UserHomeDir()\n \tif err != nil {\n \t\treturn \"\", err\n \t}\n+\tif models, exists := os.LookupEnv(\"OLLAMA_MODELS\"); exists {\n+\t\tif strings.HasPrefix(models, \"~/\") {",
        "comment_created_at": "2024-02-27T18:47:47+00:00",
        "comment_author": "dhiltgen",
        "comment_body": "Should we allow windows paths here too?\r\n```\r\n$env:OLLAMA_MODELS=\"~\\ollama-dir\"\r\nollama.exe serve\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1506133931",
        "repo_full_name": "ollama/ollama",
        "pr_number": 2770,
        "pr_file": "server/modelpath.go",
        "discussion_id": "1504770055",
        "commented_code": "@@ -103,13 +103,16 @@ func (mp ModelPath) GetShortTagname() string {\n // modelsDir returns the value of the OLLAMA_MODELS environment variable or the user's home directory if OLLAMA_MODELS is not set.\n // The models directory is where Ollama stores its model files and manifests.\n func modelsDir() (string, error) {\n-\tif models, exists := os.LookupEnv(\"OLLAMA_MODELS\"); exists {\n-\t\treturn models, nil\n-\t}\n \thome, err := os.UserHomeDir()\n \tif err != nil {\n \t\treturn \"\", err\n \t}\n+\tif models, exists := os.LookupEnv(\"OLLAMA_MODELS\"); exists {\n+\t\tif strings.HasPrefix(models, \"~/\") {",
        "comment_created_at": "2024-02-28T15:18:13+00:00",
        "comment_author": "BruceMacD",
        "comment_body": "As far as I know Windows uses `%USERPROFILE%` rather than `~`, but good call, generally better to use os.PathSeparator ",
        "pr_file_module": null
      },
      {
        "comment_id": "1506348083",
        "repo_full_name": "ollama/ollama",
        "pr_number": 2770,
        "pr_file": "server/modelpath.go",
        "discussion_id": "1504770055",
        "commented_code": "@@ -103,13 +103,16 @@ func (mp ModelPath) GetShortTagname() string {\n // modelsDir returns the value of the OLLAMA_MODELS environment variable or the user's home directory if OLLAMA_MODELS is not set.\n // The models directory is where Ollama stores its model files and manifests.\n func modelsDir() (string, error) {\n-\tif models, exists := os.LookupEnv(\"OLLAMA_MODELS\"); exists {\n-\t\treturn models, nil\n-\t}\n \thome, err := os.UserHomeDir()\n \tif err != nil {\n \t\treturn \"\", err\n \t}\n+\tif models, exists := os.LookupEnv(\"OLLAMA_MODELS\"); exists {\n+\t\tif strings.HasPrefix(models, \"~/\") {",
        "comment_created_at": "2024-02-28T17:44:01+00:00",
        "comment_author": "dhiltgen",
        "comment_body": "In powershell \"~\" does work.",
        "pr_file_module": null
      }
    ]
  }
]