[
  {
    "discussion_id": "2077968531",
    "pr_number": 2705,
    "pr_file": "internal/lang/marks/diag.go",
    "created_at": "2025-05-07T15:49:40+00:00",
    "commented_code": "+// Copyright (c) The OpenTofu Authors\n+// SPDX-License-Identifier: MPL-2.0\n+// Copyright (c) 2023 HashiCorp, Inc.\n+// SPDX-License-Identifier: MPL-2.0\n+\n+package marks\n+\n+import \"github.com/opentofu/opentofu/internal/tfdiags\"\n+\n+// DiagnosticOutputDeprecationCause checks whether the given diagnostic is\n+// a deprecation warning, and if so returns the deprecation cause and\n+// true. If not, returns the zero value of DeprecationCause and false.\n+func DiagnosticOutputDeprecationCause(diag tfdiags.Diagnostic) (DeprecationCause, bool) {\n+\tmaybe := tfdiags.ExtraInfo[diagnosticExtraDeprecationCause](diag)\n+\tif maybe == nil {\n+\t\treturn DeprecationCause{}, false\n+\t}\n+\treturn maybe.diagnosticDeprecationCause(), true\n+}\n+\n+type diagnosticExtraDeprecationCause interface {\n+\tdiagnosticDeprecationCause() DeprecationCause\n+}\n+\n+// diagnosticDeprecationCause implements diagnosticExtraDeprecationCause\n+func (c DeprecationCause) diagnosticDeprecationCause() DeprecationCause {\n+\treturn c\n+}\n+\n+// DeprecatedOutputDiagnosticExtra is a container for the DeprecationCause used to decide later if the diagnostic\n+// needs to be shown or not\n+type DeprecatedOutputDiagnosticExtra struct {\n+\tCause DeprecationCause\n+\n+\twrapped interface{}\n+}",
    "repo_full_name": "opentofu/opentofu",
    "discussion_comments": [
      {
        "comment_id": "2077968531",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2705,
        "pr_file": "internal/lang/marks/diag.go",
        "discussion_id": "2077968531",
        "commented_code": "@@ -0,0 +1,53 @@\n+// Copyright (c) The OpenTofu Authors\n+// SPDX-License-Identifier: MPL-2.0\n+// Copyright (c) 2023 HashiCorp, Inc.\n+// SPDX-License-Identifier: MPL-2.0\n+\n+package marks\n+\n+import \"github.com/opentofu/opentofu/internal/tfdiags\"\n+\n+// DiagnosticOutputDeprecationCause checks whether the given diagnostic is\n+// a deprecation warning, and if so returns the deprecation cause and\n+// true. If not, returns the zero value of DeprecationCause and false.\n+func DiagnosticOutputDeprecationCause(diag tfdiags.Diagnostic) (DeprecationCause, bool) {\n+\tmaybe := tfdiags.ExtraInfo[diagnosticExtraDeprecationCause](diag)\n+\tif maybe == nil {\n+\t\treturn DeprecationCause{}, false\n+\t}\n+\treturn maybe.diagnosticDeprecationCause(), true\n+}\n+\n+type diagnosticExtraDeprecationCause interface {\n+\tdiagnosticDeprecationCause() DeprecationCause\n+}\n+\n+// diagnosticDeprecationCause implements diagnosticExtraDeprecationCause\n+func (c DeprecationCause) diagnosticDeprecationCause() DeprecationCause {\n+\treturn c\n+}\n+\n+// DeprecatedOutputDiagnosticExtra is a container for the DeprecationCause used to decide later if the diagnostic\n+// needs to be shown or not\n+type DeprecatedOutputDiagnosticExtra struct {\n+\tCause DeprecationCause\n+\n+\twrapped interface{}\n+}",
        "comment_created_at": "2025-05-07T15:49:40+00:00",
        "comment_author": "apparentlymart",
        "comment_body": "Does this type need to be exported?\r\n\r\nI see that it's used in some of the tests in `package tofu` but I wonder if we could encapsulate this a little better so that only `package marks` needs to know how this works internally. For example, we could export from _this_ package a function that produces a function that matches the signature used by the last argument of `tfdiags.Override`, and then use that function directly as the argument:\r\n\r\n```go\r\nfunc DeprecatedOutputDiagnosticOverride(cause DeprecationCause) func() tfdiags.DiagnosticExtraWrapper {\r\n    return func () tfdiags.DiagnosticExtraWrapper {\r\n        return &DeprecatedOutputDiagnosticExtra{\r\n            Cause: cause,\r\n         }\r\n    }\r\n}\r\n```\r\n\r\nHonestly the design of `tfdiags.Override` is kinda complicated and maybe one day we can find a way to simplify it a little so this extra function isn't needed, but hopefully something like the above could at least keep most of the details encapsulated in `package marks`?\r\n\r\n(This is not super important, so if this is particularly hard to do then I'm okay with not bothering. Just trying to think about ways to minimize how much exported API surface we have in each package.)\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2079131191",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2705,
        "pr_file": "internal/lang/marks/diag.go",
        "discussion_id": "2077968531",
        "commented_code": "@@ -0,0 +1,53 @@\n+// Copyright (c) The OpenTofu Authors\n+// SPDX-License-Identifier: MPL-2.0\n+// Copyright (c) 2023 HashiCorp, Inc.\n+// SPDX-License-Identifier: MPL-2.0\n+\n+package marks\n+\n+import \"github.com/opentofu/opentofu/internal/tfdiags\"\n+\n+// DiagnosticOutputDeprecationCause checks whether the given diagnostic is\n+// a deprecation warning, and if so returns the deprecation cause and\n+// true. If not, returns the zero value of DeprecationCause and false.\n+func DiagnosticOutputDeprecationCause(diag tfdiags.Diagnostic) (DeprecationCause, bool) {\n+\tmaybe := tfdiags.ExtraInfo[diagnosticExtraDeprecationCause](diag)\n+\tif maybe == nil {\n+\t\treturn DeprecationCause{}, false\n+\t}\n+\treturn maybe.diagnosticDeprecationCause(), true\n+}\n+\n+type diagnosticExtraDeprecationCause interface {\n+\tdiagnosticDeprecationCause() DeprecationCause\n+}\n+\n+// diagnosticDeprecationCause implements diagnosticExtraDeprecationCause\n+func (c DeprecationCause) diagnosticDeprecationCause() DeprecationCause {\n+\treturn c\n+}\n+\n+// DeprecatedOutputDiagnosticExtra is a container for the DeprecationCause used to decide later if the diagnostic\n+// needs to be shown or not\n+type DeprecatedOutputDiagnosticExtra struct {\n+\tCause DeprecationCause\n+\n+\twrapped interface{}\n+}",
        "comment_created_at": "2025-05-08T08:03:06+00:00",
        "comment_author": "yottta",
        "comment_body": "Thanks! Really good point! Really kind of you to provide some code that actually worked flawlessly.\r\nSo applied in 538dec6f1ad081f9b78bcbb614cf595869b21a6f.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1957927990",
    "pr_number": 2521,
    "pr_file": "internal/states/statemgr/locker.go",
    "created_at": "2025-02-17T09:49:32+00:00",
    "commented_code": "// Unique ID for the lock. NewLockInfo provides a random ID, but this may\n \t// be overridden by the lock implementation. The final value of ID will be\n \t// returned by the call to Lock.\n-\tID string\n+\tID string `json:\"ID,omitempty\"`",
    "repo_full_name": "opentofu/opentofu",
    "discussion_comments": [
      {
        "comment_id": "1957927990",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2521,
        "pr_file": "internal/states/statemgr/locker.go",
        "discussion_id": "1957927990",
        "commented_code": "@@ -134,25 +134,25 @@ type LockInfo struct {\n \t// Unique ID for the lock. NewLockInfo provides a random ID, but this may\n \t// be overridden by the lock implementation. The final value of ID will be\n \t// returned by the call to Lock.\n-\tID string\n+\tID string `json:\"ID,omitempty\"`",
        "comment_created_at": "2025-02-17T09:49:32+00:00",
        "comment_author": "yottta",
        "comment_body": "`question`\r\nThis was a linting error and I totally agree with it, to have the json fields explicitly named.\r\nWas there a reason till now not to have this with json tags?",
        "pr_file_module": null
      },
      {
        "comment_id": "1961370868",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2521,
        "pr_file": "internal/states/statemgr/locker.go",
        "discussion_id": "1957927990",
        "commented_code": "@@ -134,25 +134,25 @@ type LockInfo struct {\n \t// Unique ID for the lock. NewLockInfo provides a random ID, but this may\n \t// be overridden by the lock implementation. The final value of ID will be\n \t// returned by the call to Lock.\n-\tID string\n+\tID string `json:\"ID,omitempty\"`",
        "comment_created_at": "2025-02-19T10:14:12+00:00",
        "comment_author": "diofeher",
        "comment_body": "Not related to your change but: \r\n\r\n1 - Were we receiving these lint errors only as warning? \r\n2 - Were we not receiving these lint problems on the pipeline?",
        "pr_file_module": null
      },
      {
        "comment_id": "1961403484",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2521,
        "pr_file": "internal/states/statemgr/locker.go",
        "discussion_id": "1957927990",
        "commented_code": "@@ -134,25 +134,25 @@ type LockInfo struct {\n \t// Unique ID for the lock. NewLockInfo provides a random ID, but this may\n \t// be overridden by the lock implementation. The final value of ID will be\n \t// returned by the call to Lock.\n-\tID string\n+\tID string `json:\"ID,omitempty\"`",
        "comment_created_at": "2025-02-19T10:34:41+00:00",
        "comment_author": "yottta",
        "comment_body": "You identified that correctly in [one of your comments](https://github.com/opentofu/opentofu/pull/2521#discussion_r1961379081), it was excluded before.\r\nAnd now, since I am using that struct again in my new changes, I encountered the same issue. I could have used the nolint directive as well, but I would prefer to have the actual issue fixed.\r\nLet's see what others are saying.",
        "pr_file_module": null
      },
      {
        "comment_id": "1961597882",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2521,
        "pr_file": "internal/states/statemgr/locker.go",
        "discussion_id": "1957927990",
        "commented_code": "@@ -134,25 +134,25 @@ type LockInfo struct {\n \t// Unique ID for the lock. NewLockInfo provides a random ID, but this may\n \t// be overridden by the lock implementation. The final value of ID will be\n \t// returned by the call to Lock.\n-\tID string\n+\tID string `json:\"ID,omitempty\"`",
        "comment_created_at": "2025-02-19T12:32:51+00:00",
        "comment_author": "cam72cam",
        "comment_body": "This appears to be nearly identical to the previous functionality (without the tag) as public properties are already encoded in the json package.\r\n\r\nI see two potential differences:\r\n1. The casing of the names is different and should be identical to the field name as before.\r\n2. The omitempty might generate payloads that are different that what was generated previously.\r\n\r\n1 could cause some serious breakage with previous locks (assuming that we json encoded it in previous releases)\r\n\r\n2 is probably not an issue as tools should not be directly manipulating this data outside of tofu.\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "1961600217",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2521,
        "pr_file": "internal/states/statemgr/locker.go",
        "discussion_id": "1957927990",
        "commented_code": "@@ -134,25 +134,25 @@ type LockInfo struct {\n \t// Unique ID for the lock. NewLockInfo provides a random ID, but this may\n \t// be overridden by the lock implementation. The final value of ID will be\n \t// returned by the call to Lock.\n-\tID string\n+\tID string `json:\"ID,omitempty\"`",
        "comment_created_at": "2025-02-19T12:34:33+00:00",
        "comment_author": "cam72cam",
        "comment_body": "`grep \"json.Marshal\" internal/backend/ -r` shows that backends already depend on the current field names, which means they should be preserved\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "1961633330",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2521,
        "pr_file": "internal/states/statemgr/locker.go",
        "discussion_id": "1957927990",
        "commented_code": "@@ -134,25 +134,25 @@ type LockInfo struct {\n \t// Unique ID for the lock. NewLockInfo provides a random ID, but this may\n \t// be overridden by the lock implementation. The final value of ID will be\n \t// returned by the call to Lock.\n-\tID string\n+\tID string `json:\"ID,omitempty\"`",
        "comment_created_at": "2025-02-19T12:56:20+00:00",
        "comment_author": "yottta",
        "comment_body": "Thanks for the ideas and the exchange. Fixed both points in 26f76c25053af5028e5ffba68ca5d5e64a2d38bc in order to match the default behavior.",
        "pr_file_module": null
      },
      {
        "comment_id": "1964316377",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2521,
        "pr_file": "internal/states/statemgr/locker.go",
        "discussion_id": "1957927990",
        "commented_code": "@@ -134,25 +134,25 @@ type LockInfo struct {\n \t// Unique ID for the lock. NewLockInfo provides a random ID, but this may\n \t// be overridden by the lock implementation. The final value of ID will be\n \t// returned by the call to Lock.\n-\tID string\n+\tID string `json:\"ID,omitempty\"`",
        "comment_created_at": "2025-02-20T20:48:16+00:00",
        "comment_author": "cam72cam",
        "comment_body": "Marking as resolved :+1: ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2031481648",
    "pr_number": 2620,
    "pr_file": "internal/command/arguments/extended.go",
    "created_at": "2025-04-07T15:18:43+00:00",
    "commented_code": "return targetables, diags\n }\n \n-func parseRawTargetsAndExcludes(targets []string, excludes []string) ([]addrs.Targetable, []addrs.Targetable, tfdiags.Diagnostics) {\n-\tvar parsedTargets []addrs.Targetable\n-\tvar parsedExcludes []addrs.Targetable\n+// parseFile gets a filePath and reads the file, which contains a list of targets\n+// with each line in the file representating a targeted object, and returns\n+// a list of addrs.Targetable. This is used for parsing the input of -target-file\n+// and -exclude-file flags\n+func parseFileTargetables(filePath, flag string) ([]addrs.Targetable, tfdiags.Diagnostics) {\n+\n+\t// If no file passed, no targets\n+\tif filePath == \"\" {\n+\t\treturn nil, nil\n+\t}\n+\tvar targetables []addrs.Targetable\n \tvar diags tfdiags.Diagnostics\n \n-\tif len(targets) > 0 && len(excludes) > 0 {\n+\tb, err := os.ReadFile(filePath)\n+\tdiags = diags.Append(err)\n+\n+\tsc := hcl.NewRangeScanner(b, filePath, bufio.ScanLines)\n+\tfor sc.Scan() {\n+\t\tlineBytes := sc.Bytes()\n+\t\tlineRange := sc.Range()\n+\t\tif isComment(lineBytes) {\n+\t\t\tcontinue\n+\t\t}\n+\t\ttraversal, syntaxDiags := hclsyntax.ParseTraversalAbs(lineBytes, lineRange.Filename, lineRange.Start)\n+\t\tif syntaxDiags.HasErrors() {\n+\t\t\tdiags = diags.Append(nil).Append(\n+\t\t\t\t&hcl.Diagnostic{\n+\t\t\t\t\tSeverity: tfdiags.Error.ToHCL(),\n+\t\t\t\t\tSummary:  \"Invalid syntax\",\n+\t\t\t\t\tDetail:   fmt.Sprintf(\"For %s %q: %v\", flag, lineBytes, syntaxDiags[0].Detail),\n+\t\t\t\t\tSubject: &hcl.Range{\n+\t\t\t\t\t\tFilename: lineRange.Filename,\n+\t\t\t\t\t\tStart:    lineRange.Start,\n+\t\t\t\t\t\tEnd:      lineRange.End,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\ttarget, targetDiags := addrs.ParseTarget(traversal)\n+\t\tif targetDiags.HasErrors() {\n+\t\t\tdiags = diags.Append(tfdiags.Sourceless(\n+\t\t\t\ttfdiags.Error,\n+\t\t\t\tfmt.Sprintf(\"Invalid %s address\", flag),\n+\t\t\t\tfmt.Sprintf(\"my detail: %v %s %q\", targetDiags[0].Description().Detail, flag, lineBytes),\n+\t\t\t))\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\ttargetables = append(targetables, target.Subject)\n+\t}\n+\treturn targetables, diags\n+}\n+\n+func isComment(b []byte) bool {\n+\tif strings.HasPrefix(string(b), \"#\") {\n+\t\treturn true\n+\t}\n+\treturn false\n+}\n+\n+func parseRawTargetsAndExcludes(targetsDirect, excludesDirect []string, targetFile, excludeFile string) ([]addrs.Targetable, []addrs.Targetable, tfdiags.Diagnostics) {",
    "repo_full_name": "opentofu/opentofu",
    "discussion_comments": [
      {
        "comment_id": "2031481648",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2620,
        "pr_file": "internal/command/arguments/extended.go",
        "discussion_id": "2031481648",
        "commented_code": "@@ -128,28 +133,97 @@ func parseTargetables(rawTargetables []string, flag string) ([]addrs.Targetable,\n \treturn targetables, diags\n }\n \n-func parseRawTargetsAndExcludes(targets []string, excludes []string) ([]addrs.Targetable, []addrs.Targetable, tfdiags.Diagnostics) {\n-\tvar parsedTargets []addrs.Targetable\n-\tvar parsedExcludes []addrs.Targetable\n+// parseFile gets a filePath and reads the file, which contains a list of targets\n+// with each line in the file representating a targeted object, and returns\n+// a list of addrs.Targetable. This is used for parsing the input of -target-file\n+// and -exclude-file flags\n+func parseFileTargetables(filePath, flag string) ([]addrs.Targetable, tfdiags.Diagnostics) {\n+\n+\t// If no file passed, no targets\n+\tif filePath == \"\" {\n+\t\treturn nil, nil\n+\t}\n+\tvar targetables []addrs.Targetable\n \tvar diags tfdiags.Diagnostics\n \n-\tif len(targets) > 0 && len(excludes) > 0 {\n+\tb, err := os.ReadFile(filePath)\n+\tdiags = diags.Append(err)\n+\n+\tsc := hcl.NewRangeScanner(b, filePath, bufio.ScanLines)\n+\tfor sc.Scan() {\n+\t\tlineBytes := sc.Bytes()\n+\t\tlineRange := sc.Range()\n+\t\tif isComment(lineBytes) {\n+\t\t\tcontinue\n+\t\t}\n+\t\ttraversal, syntaxDiags := hclsyntax.ParseTraversalAbs(lineBytes, lineRange.Filename, lineRange.Start)\n+\t\tif syntaxDiags.HasErrors() {\n+\t\t\tdiags = diags.Append(nil).Append(\n+\t\t\t\t&hcl.Diagnostic{\n+\t\t\t\t\tSeverity: tfdiags.Error.ToHCL(),\n+\t\t\t\t\tSummary:  \"Invalid syntax\",\n+\t\t\t\t\tDetail:   fmt.Sprintf(\"For %s %q: %v\", flag, lineBytes, syntaxDiags[0].Detail),\n+\t\t\t\t\tSubject: &hcl.Range{\n+\t\t\t\t\t\tFilename: lineRange.Filename,\n+\t\t\t\t\t\tStart:    lineRange.Start,\n+\t\t\t\t\t\tEnd:      lineRange.End,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\ttarget, targetDiags := addrs.ParseTarget(traversal)\n+\t\tif targetDiags.HasErrors() {\n+\t\t\tdiags = diags.Append(tfdiags.Sourceless(\n+\t\t\t\ttfdiags.Error,\n+\t\t\t\tfmt.Sprintf(\"Invalid %s address\", flag),\n+\t\t\t\tfmt.Sprintf(\"my detail: %v %s %q\", targetDiags[0].Description().Detail, flag, lineBytes),\n+\t\t\t))\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\ttargetables = append(targetables, target.Subject)\n+\t}\n+\treturn targetables, diags\n+}\n+\n+func isComment(b []byte) bool {\n+\tif strings.HasPrefix(string(b), \"#\") {\n+\t\treturn true\n+\t}\n+\treturn false\n+}\n+\n+func parseRawTargetsAndExcludes(targetsDirect, excludesDirect []string, targetFile, excludeFile string) ([]addrs.Targetable, []addrs.Targetable, tfdiags.Diagnostics) {",
        "comment_created_at": "2025-04-07T15:18:43+00:00",
        "comment_author": "apparentlymart",
        "comment_body": "One thing I noticed looking at this signature is that it only accepts a single file in each case. I suppose this is okay, but it's a little inconsistent with `-var-file` where we allow any mix of any number of `-var` and `-var-file` options on the command line.\r\n\r\nI expect we could extend this to support multiple `-target-file` or `-exclude-file` options later without any backward-compatibility problems and so starting with the simpler case is probably fine... but I figured I'd raise it now in case you think that the more flexible design is straightforward enough to implement immediately.\r\n\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2031492028",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2620,
        "pr_file": "internal/command/arguments/extended.go",
        "discussion_id": "2031481648",
        "commented_code": "@@ -128,28 +133,97 @@ func parseTargetables(rawTargetables []string, flag string) ([]addrs.Targetable,\n \treturn targetables, diags\n }\n \n-func parseRawTargetsAndExcludes(targets []string, excludes []string) ([]addrs.Targetable, []addrs.Targetable, tfdiags.Diagnostics) {\n-\tvar parsedTargets []addrs.Targetable\n-\tvar parsedExcludes []addrs.Targetable\n+// parseFile gets a filePath and reads the file, which contains a list of targets\n+// with each line in the file representating a targeted object, and returns\n+// a list of addrs.Targetable. This is used for parsing the input of -target-file\n+// and -exclude-file flags\n+func parseFileTargetables(filePath, flag string) ([]addrs.Targetable, tfdiags.Diagnostics) {\n+\n+\t// If no file passed, no targets\n+\tif filePath == \"\" {\n+\t\treturn nil, nil\n+\t}\n+\tvar targetables []addrs.Targetable\n \tvar diags tfdiags.Diagnostics\n \n-\tif len(targets) > 0 && len(excludes) > 0 {\n+\tb, err := os.ReadFile(filePath)\n+\tdiags = diags.Append(err)\n+\n+\tsc := hcl.NewRangeScanner(b, filePath, bufio.ScanLines)\n+\tfor sc.Scan() {\n+\t\tlineBytes := sc.Bytes()\n+\t\tlineRange := sc.Range()\n+\t\tif isComment(lineBytes) {\n+\t\t\tcontinue\n+\t\t}\n+\t\ttraversal, syntaxDiags := hclsyntax.ParseTraversalAbs(lineBytes, lineRange.Filename, lineRange.Start)\n+\t\tif syntaxDiags.HasErrors() {\n+\t\t\tdiags = diags.Append(nil).Append(\n+\t\t\t\t&hcl.Diagnostic{\n+\t\t\t\t\tSeverity: tfdiags.Error.ToHCL(),\n+\t\t\t\t\tSummary:  \"Invalid syntax\",\n+\t\t\t\t\tDetail:   fmt.Sprintf(\"For %s %q: %v\", flag, lineBytes, syntaxDiags[0].Detail),\n+\t\t\t\t\tSubject: &hcl.Range{\n+\t\t\t\t\t\tFilename: lineRange.Filename,\n+\t\t\t\t\t\tStart:    lineRange.Start,\n+\t\t\t\t\t\tEnd:      lineRange.End,\n+\t\t\t\t\t},\n+\t\t\t\t},\n+\t\t\t)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\ttarget, targetDiags := addrs.ParseTarget(traversal)\n+\t\tif targetDiags.HasErrors() {\n+\t\t\tdiags = diags.Append(tfdiags.Sourceless(\n+\t\t\t\ttfdiags.Error,\n+\t\t\t\tfmt.Sprintf(\"Invalid %s address\", flag),\n+\t\t\t\tfmt.Sprintf(\"my detail: %v %s %q\", targetDiags[0].Description().Detail, flag, lineBytes),\n+\t\t\t))\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\ttargetables = append(targetables, target.Subject)\n+\t}\n+\treturn targetables, diags\n+}\n+\n+func isComment(b []byte) bool {\n+\tif strings.HasPrefix(string(b), \"#\") {\n+\t\treturn true\n+\t}\n+\treturn false\n+}\n+\n+func parseRawTargetsAndExcludes(targetsDirect, excludesDirect []string, targetFile, excludeFile string) ([]addrs.Targetable, []addrs.Targetable, tfdiags.Diagnostics) {",
        "comment_created_at": "2025-04-07T15:24:20+00:00",
        "comment_author": "bittelc",
        "comment_body": "This is an awesome comment. I can most definitely work on this and incorporate multiple files into the feature. Thank you for the prelim review. If you see more things, please comment away when you have time, and I\u2019ll just keep slugging away until you and the rest of the team are happy with the code.\r\nBeing my first PR to the codebase, I want to make sure I respect the quality of the codebase.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2063605337",
    "pr_number": 2720,
    "pr_file": "internal/backend/remote-state/azure/backend_state.go",
    "created_at": "2025-04-28T12:59:32+00:00",
    "commented_code": ")\n \n func (b *Backend) Workspaces() ([]string, error) {\n-\tprefix := b.keyName + keyEnvPrefix\n-\tparams := containers.ListBlobsInput{\n-\t\tPrefix: &prefix,\n-\t}\n-\n \tctx := context.TODO()\n \tclient, err := b.armClient.getContainersClient(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\tresp, err := client.ListBlobs(ctx, b.armClient.storageAccountName, b.containerName, params)\n-\tif err != nil {\n-\t\treturn nil, err\n+\n+\tcount := 1\n+\tprefix := b.keyName + keyEnvPrefix\n+\tparams := containers.ListBlobsInput{\n+\t\tPrefix: &prefix,\n \t}\n+\tresult := []string{backend.DefaultStateName}\n+\n+\tfor {\n+\t\tlog.Printf(\"[TRACE] Getting page %d of blob results\", count)\n+\t\tresp, err := client.ListBlobs(ctx, b.armClient.storageAccountName, b.containerName, params)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\n+\t\t// Used to paginate blobs, saving the NextMarker result from ListBlobs\n+\t\tparams.Marker = resp.NextMarker\n+\t\tfor _, obj := range resp.Blobs.Blobs {\n+\t\t\tkey := obj.Name\n+\t\t\tif !strings.HasPrefix(key, prefix) {\n+\t\t\t\tcontinue\n+\t\t\t}\n \n-\tenvs := map[string]struct{}{}\n-\tfor _, obj := range resp.Blobs.Blobs {\n-\t\tkey := obj.Name\n-\t\tif strings.HasPrefix(key, prefix) {\n \t\t\tname := strings.TrimPrefix(key, prefix)\n \t\t\t// we store the state in a key, not a directory\n \t\t\tif strings.Contains(name, \"/\") {\n \t\t\t\tcontinue\n \t\t\t}\n+\t\t\tresult = append(result, name)\n+\t\t}\n \n-\t\t\tenvs[name] = struct{}{}\n+\t\tcount++\n+\t\tif *params.Marker == \"\" {",
    "repo_full_name": "opentofu/opentofu",
    "discussion_comments": [
      {
        "comment_id": "2063605337",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2720,
        "pr_file": "internal/backend/remote-state/azure/backend_state.go",
        "discussion_id": "2063605337",
        "commented_code": "@@ -26,39 +27,48 @@ const (\n )\n \n func (b *Backend) Workspaces() ([]string, error) {\n-\tprefix := b.keyName + keyEnvPrefix\n-\tparams := containers.ListBlobsInput{\n-\t\tPrefix: &prefix,\n-\t}\n-\n \tctx := context.TODO()\n \tclient, err := b.armClient.getContainersClient(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\tresp, err := client.ListBlobs(ctx, b.armClient.storageAccountName, b.containerName, params)\n-\tif err != nil {\n-\t\treturn nil, err\n+\n+\tcount := 1\n+\tprefix := b.keyName + keyEnvPrefix\n+\tparams := containers.ListBlobsInput{\n+\t\tPrefix: &prefix,\n \t}\n+\tresult := []string{backend.DefaultStateName}\n+\n+\tfor {\n+\t\tlog.Printf(\"[TRACE] Getting page %d of blob results\", count)\n+\t\tresp, err := client.ListBlobs(ctx, b.armClient.storageAccountName, b.containerName, params)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\n+\t\t// Used to paginate blobs, saving the NextMarker result from ListBlobs\n+\t\tparams.Marker = resp.NextMarker\n+\t\tfor _, obj := range resp.Blobs.Blobs {\n+\t\t\tkey := obj.Name\n+\t\t\tif !strings.HasPrefix(key, prefix) {\n+\t\t\t\tcontinue\n+\t\t\t}\n \n-\tenvs := map[string]struct{}{}\n-\tfor _, obj := range resp.Blobs.Blobs {\n-\t\tkey := obj.Name\n-\t\tif strings.HasPrefix(key, prefix) {\n \t\t\tname := strings.TrimPrefix(key, prefix)\n \t\t\t// we store the state in a key, not a directory\n \t\t\tif strings.Contains(name, \"/\") {\n \t\t\t\tcontinue\n \t\t\t}\n+\t\t\tresult = append(result, name)\n+\t\t}\n \n-\t\t\tenvs[name] = struct{}{}\n+\t\tcount++\n+\t\tif *params.Marker == \"\" {",
        "comment_created_at": "2025-04-28T12:59:32+00:00",
        "comment_author": "Yantrio",
        "comment_body": "what if the API returned a nil marker back (not an empty string?)",
        "pr_file_module": null
      },
      {
        "comment_id": "2063789847",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2720,
        "pr_file": "internal/backend/remote-state/azure/backend_state.go",
        "discussion_id": "2063605337",
        "commented_code": "@@ -26,39 +27,48 @@ const (\n )\n \n func (b *Backend) Workspaces() ([]string, error) {\n-\tprefix := b.keyName + keyEnvPrefix\n-\tparams := containers.ListBlobsInput{\n-\t\tPrefix: &prefix,\n-\t}\n-\n \tctx := context.TODO()\n \tclient, err := b.armClient.getContainersClient(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\tresp, err := client.ListBlobs(ctx, b.armClient.storageAccountName, b.containerName, params)\n-\tif err != nil {\n-\t\treturn nil, err\n+\n+\tcount := 1\n+\tprefix := b.keyName + keyEnvPrefix\n+\tparams := containers.ListBlobsInput{\n+\t\tPrefix: &prefix,\n \t}\n+\tresult := []string{backend.DefaultStateName}\n+\n+\tfor {\n+\t\tlog.Printf(\"[TRACE] Getting page %d of blob results\", count)\n+\t\tresp, err := client.ListBlobs(ctx, b.armClient.storageAccountName, b.containerName, params)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\n+\t\t// Used to paginate blobs, saving the NextMarker result from ListBlobs\n+\t\tparams.Marker = resp.NextMarker\n+\t\tfor _, obj := range resp.Blobs.Blobs {\n+\t\t\tkey := obj.Name\n+\t\t\tif !strings.HasPrefix(key, prefix) {\n+\t\t\t\tcontinue\n+\t\t\t}\n \n-\tenvs := map[string]struct{}{}\n-\tfor _, obj := range resp.Blobs.Blobs {\n-\t\tkey := obj.Name\n-\t\tif strings.HasPrefix(key, prefix) {\n \t\t\tname := strings.TrimPrefix(key, prefix)\n \t\t\t// we store the state in a key, not a directory\n \t\t\tif strings.Contains(name, \"/\") {\n \t\t\t\tcontinue\n \t\t\t}\n+\t\t\tresult = append(result, name)\n+\t\t}\n \n-\t\t\tenvs[name] = struct{}{}\n+\t\tcount++\n+\t\tif *params.Marker == \"\" {",
        "comment_created_at": "2025-04-28T14:30:33+00:00",
        "comment_author": "diofeher",
        "comment_body": "That's a good point! When I was implementing, I went to this approach by checking if NextMarker was nil, but it wasn't working properly because it was serializing on an empty string, even if the parameter was not present. What's strange is that NextMarker is defined as:\r\n\r\n```\r\ntype ListBlobsResult struct {\r\n\tautorest.Response\r\n....\r\n        NextMarker *string `xml:\"NextMarker,omitempty\"`\r\n```\r\n\r\nso I was expecting to be nil if no NextMarker was there. But it seems there's a pointer even if NextMarker is not present:\r\n\r\nOutput of:\r\nfmt.Printf(\"%T %v: %T %v\\n\\n\", resp.NextMarker, resp.NextMarker, *resp.NextMarker, *resp.NextMarker)\r\n\r\n```\r\n*string 0x14000b144f0: string 2!104!MDAwMDMyIXByb2QudGVycmFmb3JtLnRmc3RhdGVlbnY6ZW52MTgzITAwMDAyOCE5OTk5LTEyLTMxVDIzOjU5OjU5Ljk5OTk5OTlaIQ--\r\n\r\n*string 0x14000502ec0: string 2!104!MDAwMDMyIXByb2QudGVycmFmb3JtLnRmc3RhdGVlbnY6ZW52MjczITAwMDAyOCE5OTk5LTEyLTMxVDIzOjU5OjU5Ljk5OTk5OTlaIQ--\r\n\r\n*string 0x14000804690: string 2!100!MDAwMDMxIXByb2QudGVycmFmb3JtLnRmc3RhdGVlbnY6ZW52OTMhMDAwMDI4ITk5OTktMTItMzFUMjM6NTk6NTkuOTk5OTk5OVoh\r\n\r\n*string 0x14000805000: string\r\n```\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2063793261",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2720,
        "pr_file": "internal/backend/remote-state/azure/backend_state.go",
        "discussion_id": "2063605337",
        "commented_code": "@@ -26,39 +27,48 @@ const (\n )\n \n func (b *Backend) Workspaces() ([]string, error) {\n-\tprefix := b.keyName + keyEnvPrefix\n-\tparams := containers.ListBlobsInput{\n-\t\tPrefix: &prefix,\n-\t}\n-\n \tctx := context.TODO()\n \tclient, err := b.armClient.getContainersClient(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\tresp, err := client.ListBlobs(ctx, b.armClient.storageAccountName, b.containerName, params)\n-\tif err != nil {\n-\t\treturn nil, err\n+\n+\tcount := 1\n+\tprefix := b.keyName + keyEnvPrefix\n+\tparams := containers.ListBlobsInput{\n+\t\tPrefix: &prefix,\n \t}\n+\tresult := []string{backend.DefaultStateName}\n+\n+\tfor {\n+\t\tlog.Printf(\"[TRACE] Getting page %d of blob results\", count)\n+\t\tresp, err := client.ListBlobs(ctx, b.armClient.storageAccountName, b.containerName, params)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\n+\t\t// Used to paginate blobs, saving the NextMarker result from ListBlobs\n+\t\tparams.Marker = resp.NextMarker\n+\t\tfor _, obj := range resp.Blobs.Blobs {\n+\t\t\tkey := obj.Name\n+\t\t\tif !strings.HasPrefix(key, prefix) {\n+\t\t\t\tcontinue\n+\t\t\t}\n \n-\tenvs := map[string]struct{}{}\n-\tfor _, obj := range resp.Blobs.Blobs {\n-\t\tkey := obj.Name\n-\t\tif strings.HasPrefix(key, prefix) {\n \t\t\tname := strings.TrimPrefix(key, prefix)\n \t\t\t// we store the state in a key, not a directory\n \t\t\tif strings.Contains(name, \"/\") {\n \t\t\t\tcontinue\n \t\t\t}\n+\t\t\tresult = append(result, name)\n+\t\t}\n \n-\t\t\tenvs[name] = struct{}{}\n+\t\tcount++\n+\t\tif *params.Marker == \"\" {",
        "comment_created_at": "2025-04-28T14:32:26+00:00",
        "comment_author": "diofeher",
        "comment_body": "What I can do is to create an extra check, but I wasn't able to hit it in my tests:\r\n\r\n```\r\nif params.Marker == nil || *params.Marker == \"\" {\r\n\t\t\tbreak\r\n\t\t}\r\n```\r\n\r\nWDYT?",
        "pr_file_module": null
      },
      {
        "comment_id": "2063895354",
        "repo_full_name": "opentofu/opentofu",
        "pr_number": 2720,
        "pr_file": "internal/backend/remote-state/azure/backend_state.go",
        "discussion_id": "2063605337",
        "commented_code": "@@ -26,39 +27,48 @@ const (\n )\n \n func (b *Backend) Workspaces() ([]string, error) {\n-\tprefix := b.keyName + keyEnvPrefix\n-\tparams := containers.ListBlobsInput{\n-\t\tPrefix: &prefix,\n-\t}\n-\n \tctx := context.TODO()\n \tclient, err := b.armClient.getContainersClient(ctx)\n \tif err != nil {\n \t\treturn nil, err\n \t}\n-\tresp, err := client.ListBlobs(ctx, b.armClient.storageAccountName, b.containerName, params)\n-\tif err != nil {\n-\t\treturn nil, err\n+\n+\tcount := 1\n+\tprefix := b.keyName + keyEnvPrefix\n+\tparams := containers.ListBlobsInput{\n+\t\tPrefix: &prefix,\n \t}\n+\tresult := []string{backend.DefaultStateName}\n+\n+\tfor {\n+\t\tlog.Printf(\"[TRACE] Getting page %d of blob results\", count)\n+\t\tresp, err := client.ListBlobs(ctx, b.armClient.storageAccountName, b.containerName, params)\n+\t\tif err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\n+\t\t// Used to paginate blobs, saving the NextMarker result from ListBlobs\n+\t\tparams.Marker = resp.NextMarker\n+\t\tfor _, obj := range resp.Blobs.Blobs {\n+\t\t\tkey := obj.Name\n+\t\t\tif !strings.HasPrefix(key, prefix) {\n+\t\t\t\tcontinue\n+\t\t\t}\n \n-\tenvs := map[string]struct{}{}\n-\tfor _, obj := range resp.Blobs.Blobs {\n-\t\tkey := obj.Name\n-\t\tif strings.HasPrefix(key, prefix) {\n \t\t\tname := strings.TrimPrefix(key, prefix)\n \t\t\t// we store the state in a key, not a directory\n \t\t\tif strings.Contains(name, \"/\") {\n \t\t\t\tcontinue\n \t\t\t}\n+\t\t\tresult = append(result, name)\n+\t\t}\n \n-\t\t\tenvs[name] = struct{}{}\n+\t\tcount++\n+\t\tif *params.Marker == \"\" {",
        "comment_created_at": "2025-04-28T15:15:43+00:00",
        "comment_author": "diofeher",
        "comment_body": "Fixed on https://github.com/opentofu/opentofu/pull/2720/commits/38b7e344ecd18da49fbae526e3b3f37aa03c4b65",
        "pr_file_module": null
      }
    ]
  }
]