[
  {
    "discussion_id": "2309249688",
    "pr_number": 523,
    "pr_file": "src/parlant/adapters/nlp/ollama_service.py",
    "created_at": "2025-08-29T06:11:50+00:00",
    "commented_code": "def __init__(\n         self,\n-        logger: Logger,\n-        base_url: str = \"http://localhost:11434\",\n-        model_name: str = \"nomic-embed-text\",\n+        logger: Logger\n     ):\n-        self.model_name = model_name\n-        self.base_url = base_url.rstrip(\"/\")\n+        self.model_name = os.environ.get(\"OLLAMA_EMBEDDING_MODEL\", \"nomic-embed-text\")",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "2309249688",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 523,
        "pr_file": "src/parlant/adapters/nlp/ollama_service.py",
        "discussion_id": "2309249688",
        "commented_code": "@@ -418,15 +418,13 @@ class OllamaEmbedder(Embedder):\n \n     def __init__(\n         self,\n-        logger: Logger,\n-        base_url: str = \"http://localhost:11434\",\n-        model_name: str = \"nomic-embed-text\",\n+        logger: Logger\n     ):\n-        self.model_name = model_name\n-        self.base_url = base_url.rstrip(\"/\")\n+        self.model_name = os.environ.get(\"OLLAMA_EMBEDDING_MODEL\", \"nomic-embed-text\")",
        "comment_created_at": "2025-08-29T06:11:50+00:00",
        "comment_author": "mc-dorzo",
        "comment_body": "This breaks consistency. In CustomOllamaSchematicGenerator, you get the model name and base URL (based on the environment variables, but the embedder does not. I think what was before was fine.\r\nAlso, please ensure you have the Ruff extension installed and run mypy before. I see that there are a few mypy errors in the file currently.",
        "pr_file_module": null
      },
      {
        "comment_id": "2309255831",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 523,
        "pr_file": "src/parlant/adapters/nlp/ollama_service.py",
        "discussion_id": "2309249688",
        "commented_code": "@@ -418,15 +418,13 @@ class OllamaEmbedder(Embedder):\n \n     def __init__(\n         self,\n-        logger: Logger,\n-        base_url: str = \"http://localhost:11434\",\n-        model_name: str = \"nomic-embed-text\",\n+        logger: Logger\n     ):\n-        self.model_name = model_name\n-        self.base_url = base_url.rstrip(\"/\")\n+        self.model_name = os.environ.get(\"OLLAMA_EMBEDDING_MODEL\", \"nomic-embed-text\")",
        "comment_created_at": "2025-08-29T06:15:44+00:00",
        "comment_author": "Agam1997",
        "comment_body": "Will take a look.\r\n\r\nI have ruff and mypy, the linter however always gives me an error:\r\n\r\n[44] stderr:\r\nmypy: \"parlant/src/parlant/core/engines/types.py\" shadows library module \"types\"\r\nnote: A user-defined top-level module with name \"types\" is not supported\r\n\r\n[44] Error running mypy in /Users/agamdubey/open-source: mypy failed with error: \"mypy: \"parlant/src/parlant/core/engines/types.py\" shadows library module \"types\"\". See Output panel for details.",
        "pr_file_module": null
      },
      {
        "comment_id": "2309578313",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 523,
        "pr_file": "src/parlant/adapters/nlp/ollama_service.py",
        "discussion_id": "2309249688",
        "commented_code": "@@ -418,15 +418,13 @@ class OllamaEmbedder(Embedder):\n \n     def __init__(\n         self,\n-        logger: Logger,\n-        base_url: str = \"http://localhost:11434\",\n-        model_name: str = \"nomic-embed-text\",\n+        logger: Logger\n     ):\n-        self.model_name = model_name\n-        self.base_url = base_url.rstrip(\"/\")\n+        self.model_name = os.environ.get(\"OLLAMA_EMBEDDING_MODEL\", \"nomic-embed-text\")",
        "comment_created_at": "2025-08-29T08:49:07+00:00",
        "comment_author": "Agam1997",
        "comment_body": "@mc-dorzo pushed a fix as we discussed ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2072582796",
    "pr_number": 357,
    "pr_file": "src/parlant/core/engines/alpha/tool_calling/single_tool_batch.py",
    "created_at": "2025-05-04T10:46:33+00:00",
    "commented_code": "\"argument_evaluations\": [\n                 {\n                     \"parameter_name\": \"<PARAMETER NAME>\",\n-                    \"acceptable_source_for_this_argument_according_to_its_tool_definition\": \"<REAPET THE ACCEPTABLE SOURCE FOR THE ARGUMENT FROM TOOL DEFINITION>\",\n+                    \"acceptable_source_for_this_argument_according_to_its_tool_definition\": \"<REPEAT THE ACCEPTABLE SOURCE FOR THE ARGUMENT FROM TOOL DEFINITION>\",\n                     \"evaluate_is_it_provided_by_an_acceptable_source\": \"<BRIEFLY EVALUATE IF THE SOURCE FOR THE VALUE MATCHES THE ACCEPTABLE SOURCE>\",\n-                    \"evaluate_was_it_already_provided_and_should_it_be_provided_again\": \"<BRIEFLY EVALUATE IF THE PARAMERWE VALUE WAS PROVIDED AND SHOULD BE PROVIDED AGAIN>\",\n+                    \"evaluate_was_it_already_provided_and_should_it_be_provided_again\": \"<BRIEFLY EVALUATE IF THE PARAMETER VALUE WAS PROVIDED AND SHOULD BE PROVIDED AGAIN>\",\n                     \"evaluate_is_it_potentially_problematic_to_guess_what_the_value_is_if_it_isnt_provided\": \"<BRIEFLY EVALUATE IF IT'S A PROBLEM TO GUESS THE VALUE>\",\"\"\"\n         if optional_arguments:\n             result += \"\"\"\n                     \"is_optional\": <BOOL>,\"\"\"\n \n         result += \"\"\"\n-                    \"is_missing\": <BOOL>,\n-                    \"value_as_string\": \"<PARAMETER VALUE>\"\n+                    \"valid_invalid_or_missing\": <STR: EITHER 'missing', 'invalid' OR 'valid' DEPENDING IF THE VALUE IS MISSING, PROVIDED BUT NOT FOUND IN ENUM LIST, OR PROVIDED AND FOUND IN ENUM LIST (OR DOESN'T HAVE ENUM LIST)>\",",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "2072582796",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 357,
        "pr_file": "src/parlant/core/engines/alpha/tool_calling/single_tool_batch.py",
        "discussion_id": "2072582796",
        "commented_code": "@@ -468,17 +509,17 @@ def _format_tool_calls_for_candidate_tool_json_description(\n             \"argument_evaluations\": [\n                 {\n                     \"parameter_name\": \"<PARAMETER NAME>\",\n-                    \"acceptable_source_for_this_argument_according_to_its_tool_definition\": \"<REAPET THE ACCEPTABLE SOURCE FOR THE ARGUMENT FROM TOOL DEFINITION>\",\n+                    \"acceptable_source_for_this_argument_according_to_its_tool_definition\": \"<REPEAT THE ACCEPTABLE SOURCE FOR THE ARGUMENT FROM TOOL DEFINITION>\",\n                     \"evaluate_is_it_provided_by_an_acceptable_source\": \"<BRIEFLY EVALUATE IF THE SOURCE FOR THE VALUE MATCHES THE ACCEPTABLE SOURCE>\",\n-                    \"evaluate_was_it_already_provided_and_should_it_be_provided_again\": \"<BRIEFLY EVALUATE IF THE PARAMERWE VALUE WAS PROVIDED AND SHOULD BE PROVIDED AGAIN>\",\n+                    \"evaluate_was_it_already_provided_and_should_it_be_provided_again\": \"<BRIEFLY EVALUATE IF THE PARAMETER VALUE WAS PROVIDED AND SHOULD BE PROVIDED AGAIN>\",\n                     \"evaluate_is_it_potentially_problematic_to_guess_what_the_value_is_if_it_isnt_provided\": \"<BRIEFLY EVALUATE IF IT'S A PROBLEM TO GUESS THE VALUE>\",\"\"\"\n         if optional_arguments:\n             result += \"\"\"\n                     \"is_optional\": <BOOL>,\"\"\"\n \n         result += \"\"\"\n-                    \"is_missing\": <BOOL>,\n-                    \"value_as_string\": \"<PARAMETER VALUE>\"\n+                    \"valid_invalid_or_missing\": <STR: EITHER 'missing', 'invalid' OR 'valid' DEPENDING IF THE VALUE IS MISSING, PROVIDED BUT NOT FOUND IN ENUM LIST, OR PROVIDED AND FOUND IN ENUM LIST (OR DOESN'T HAVE ENUM LIST)>\",",
        "comment_created_at": "2025-05-04T10:46:33+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "I know this sounds weird but I've encountered inconsistencies with LLM outputs when *we* weren't consistent with putting value descriptions in quotes. Therefore, please add quote around the `<....>` content to avoid such edge cases.  Also note that it seems like you have that last quote but the initial one is missing.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1913829717",
    "pr_number": 226,
    "pr_file": "src/parlant/core/engines/alpha/message_event_generator.py",
    "created_at": "2025-01-13T21:29:47+00:00",
    "commented_code": "shots=await self.shots(),\n             )\n \n-            self._logger.debug(f\"Message production prompt:\n{prompt}\")\n+            self._logger.debug(f\"[MessageEventGenerator][Prompt]:\n{prompt}\")",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "1913829717",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 226,
        "pr_file": "src/parlant/core/engines/alpha/message_event_generator.py",
        "discussion_id": "1913829717",
        "commented_code": "@@ -142,7 +142,7 @@ async def generate_events(\n                 shots=await self.shots(),\n             )\n \n-            self._logger.debug(f\"Message production prompt:\\n{prompt}\")\n+            self._logger.debug(f\"[MessageEventGenerator][Prompt]:\\n{prompt}\")",
        "comment_created_at": "2025-01-13T21:29:47+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "I see you sometimes have a colon (:) after the `[..]` part and sometimes don't.\r\nLet's be consistent: go over all instances and let's go with **no colon**. Just a space after the last bracket (in this case a newline is fine instead of the space since it's a multiline prompt)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1895856546",
    "pr_number": 200,
    "pr_file": "tests/api/test_services.py",
    "created_at": "2024-12-23T15:13:56+00:00",
    "commented_code": "from parlant.core.services.tools.plugins import tool\n from parlant.core.tools import ToolResult, ToolContext\n from parlant.core.services.tools.service_registry import ServiceRegistry\n-\n-from tests.core.services.tools.test_openapi import (\n-    OPENAPI_SERVER_URL,\n-    rng_app,\n-    run_openapi_server,\n-)\n-\n-\n-from tests.core.services.tools.test_plugin_client import run_service_server\n+from tests.test_utilities import OPENAPI_SERVER_URL, rng_app, run_openapi_server, run_service_server",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "1895856546",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 200,
        "pr_file": "tests/api/test_services.py",
        "discussion_id": "1895856546",
        "commented_code": "@@ -22,15 +22,7 @@\n from parlant.core.services.tools.plugins import tool\n from parlant.core.tools import ToolResult, ToolContext\n from parlant.core.services.tools.service_registry import ServiceRegistry\n-\n-from tests.core.services.tools.test_openapi import (\n-    OPENAPI_SERVER_URL,\n-    rng_app,\n-    run_openapi_server,\n-)\n-\n-\n-from tests.core.services.tools.test_plugin_client import run_service_server\n+from tests.test_utilities import OPENAPI_SERVER_URL, rng_app, run_openapi_server, run_service_server",
        "comment_created_at": "2024-12-23T15:13:56+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "Let's have a blank line separating parlant lib imports from test imports",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1816148982",
    "pr_number": 116,
    "pr_file": "sdk/src/emcie/sdk/bin/emcie.py",
    "created_at": "2024-10-25T07:33:09+00:00",
    "commented_code": "return cast(SessionDTO, response.json()[\"session\"])\n \n+    @staticmethod\n+    def list_sessions(\n+        ctx: click.Context, agent_id: Optional[str], end_user_id: Optional[str]",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "1816148982",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 116,
        "pr_file": "sdk/src/emcie/sdk/bin/emcie.py",
        "discussion_id": "1816148982",
        "commented_code": "@@ -240,6 +240,20 @@ def create_session(\n \n         return cast(SessionDTO, response.json()[\"session\"])\n \n+    @staticmethod\n+    def list_sessions(\n+        ctx: click.Context, agent_id: Optional[str], end_user_id: Optional[str]",
        "comment_created_at": "2024-10-25T07:33:09+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "Stoppp forgetting the trailing comma in the param list!!! :)",
        "pr_file_module": null
      },
      {
        "comment_id": "1816368036",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 116,
        "pr_file": "sdk/src/emcie/sdk/bin/emcie.py",
        "discussion_id": "1816148982",
        "commented_code": "@@ -240,6 +240,20 @@ def create_session(\n \n         return cast(SessionDTO, response.json()[\"session\"])\n \n+    @staticmethod\n+    def list_sessions(\n+        ctx: click.Context, agent_id: Optional[str], end_user_id: Optional[str]",
        "comment_created_at": "2024-10-25T09:41:21+00:00",
        "comment_author": "mc-dorzo",
        "comment_body": "I was starting to comment here that actually I did it consciously and explaining why but then realize it will sound like excuses. any way, fixed along multiple other functions in the file.\r\nMy rule regarding this is that tailing comma need to come in all cases except __init__ function (which can be viewed in one line), and functions with one parameter. is this fine?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1816149694",
    "pr_number": 116,
    "pr_file": "sdk/src/emcie/sdk/bin/emcie.py",
    "created_at": "2024-10-25T07:33:47+00:00",
    "commented_code": "return cast(SessionDTO, response.json()[\"session\"])\n \n+    @staticmethod\n+    def list_sessions(\n+        ctx: click.Context, agent_id: Optional[str], end_user_id: Optional[str]\n+    ) -> list[SessionDTO]:\n+        response = requests.get(\n+            urljoin(ctx.obj.server_address, \"/sessions\"),\n+            params={\n+                \"agent_id\": agent_id,\n+                \"end_user_id\": end_user_id,\n+            },\n+        )\n+        response.raise_for_status()",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "1816149694",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 116,
        "pr_file": "sdk/src/emcie/sdk/bin/emcie.py",
        "discussion_id": "1816149694",
        "commented_code": "@@ -240,6 +240,20 @@ def create_session(\n \n         return cast(SessionDTO, response.json()[\"session\"])\n \n+    @staticmethod\n+    def list_sessions(\n+        ctx: click.Context, agent_id: Optional[str], end_user_id: Optional[str]\n+    ) -> list[SessionDTO]:\n+        response = requests.get(\n+            urljoin(ctx.obj.server_address, \"/sessions\"),\n+            params={\n+                \"agent_id\": agent_id,\n+                \"end_user_id\": end_user_id,\n+            },\n+        )\n+        response.raise_for_status()",
        "comment_created_at": "2024-10-25T07:33:47+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "Please mind the consistency of the pattern\u2014in other cases here we have an empty line before and after raise_for_status",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1842424164",
    "pr_number": 137,
    "pr_file": "tests/core/services/indexing/test_coherence.py",
    "created_at": "2024-11-14T15:28:52+00:00",
    "commented_code": "-from datetime import datetime, timezone\n from dataclasses import dataclass\n-from lagom import Container\n-from pytest import fixture, mark\n+from datetime import datetime, timezone\n \n+from lagom import Container\n from parlant.core.agents import Agent, AgentId, AgentStore\n-\n-from parlant.core.guidelines import GuidelineContent\n from parlant.core.glossary import GlossaryStore\n-\n+from parlant.core.guidelines import GuidelineContent\n from parlant.core.services.indexing.coherence_checker import (\n     CoherenceChecker,\n     IncoherenceKind,\n     IncoherenceTest,\n )\n+from pytest import fixture",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "1842424164",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 137,
        "pr_file": "tests/core/services/indexing/test_coherence.py",
        "discussion_id": "1842424164",
        "commented_code": "@@ -1,18 +1,16 @@\n-from datetime import datetime, timezone\n from dataclasses import dataclass\n-from lagom import Container\n-from pytest import fixture, mark\n+from datetime import datetime, timezone\n \n+from lagom import Container\n from parlant.core.agents import Agent, AgentId, AgentStore\n-\n-from parlant.core.guidelines import GuidelineContent\n from parlant.core.glossary import GlossaryStore\n-\n+from parlant.core.guidelines import GuidelineContent\n from parlant.core.services.indexing.coherence_checker import (\n     CoherenceChecker,\n     IncoherenceKind,\n     IncoherenceTest,\n )\n+from pytest import fixture",
        "comment_created_at": "2024-11-14T15:28:52+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "In this and the other file, order of imports should be not be semantic (e.g. \"these are the pure-test related imports\u2014since the lines are fuzzier this way) but rather this, which is always enforceable:\r\n\r\n1. stdlib / 3rd party imports (though if you wish, feel free to separate these two out\u2014not necessary)\r\n2. parlant imports (not from .tests -- i.e. not dev-only imports, but only core-app imports)\r\n3. parlant.tests imports",
        "pr_file_module": null
      },
      {
        "comment_id": "1842492691",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 137,
        "pr_file": "tests/core/services/indexing/test_coherence.py",
        "discussion_id": "1842424164",
        "commented_code": "@@ -1,18 +1,16 @@\n-from datetime import datetime, timezone\n from dataclasses import dataclass\n-from lagom import Container\n-from pytest import fixture, mark\n+from datetime import datetime, timezone\n \n+from lagom import Container\n from parlant.core.agents import Agent, AgentId, AgentStore\n-\n-from parlant.core.guidelines import GuidelineContent\n from parlant.core.glossary import GlossaryStore\n-\n+from parlant.core.guidelines import GuidelineContent\n from parlant.core.services.indexing.coherence_checker import (\n     CoherenceChecker,\n     IncoherenceKind,\n     IncoherenceTest,\n )\n+from pytest import fixture",
        "comment_created_at": "2024-11-14T16:06:28+00:00",
        "comment_author": "MCNatsu",
        "comment_body": "Acknowledged, thanks",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1835426998",
    "pr_number": 134,
    "pr_file": "src/parlant/adapters/nlp/google.py",
    "created_at": "2024-11-09T15:06:00+00:00",
    "commented_code": "import os\n+import time\n import google.generativeai as genai  # type: ignore\n from typing import Any, Mapping\n import jsonfinder  # type: ignore\n from pydantic import ValidationError\n+from parlant.core.nlp.tokenization import EstimatingTokenizer",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "1835426998",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 134,
        "pr_file": "src/parlant/adapters/nlp/google.py",
        "discussion_id": "1835426998",
        "commented_code": "@@ -1,17 +1,38 @@\n import os\n+import time\n import google.generativeai as genai  # type: ignore\n from typing import Any, Mapping\n import jsonfinder  # type: ignore\n from pydantic import ValidationError\n+from parlant.core.nlp.tokenization import EstimatingTokenizer",
        "comment_created_at": "2024-11-09T15:06:00+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "parlant imports should be in one contiguous block, after 3rd party imports",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1721705254",
    "pr_number": 53,
    "pr_file": "server/src/emcie/server/core/context_variables.py",
    "created_at": "2024-08-19T12:23:08+00:00",
    "commented_code": "variable_set: str,\n         id: ContextVariableId,\n     ) -> None:\n-        await self._variable_collection.delete_one(\n-            {\n-                \"id\": {\"$eq\": id},\n-                \"variable_set\": {\"$eq\": variable_set},\n-            }\n-        )\n-        await self._value_collection.delete_one(\n-            {\n-                \"variable_id\": {\"$eq\": id},\n-                \"variable_set\": {\"$eq\": variable_set},\n-            }\n-        )\n+        try:\n+            await self._variable_collection.delete_one(\n+                {\n+                    \"id\": {\"$eq\": id},\n+                    \"variable_set\": {\"$eq\": variable_set},\n+                }\n+            )\n+        except NoMatchingDocumentsError:\n+            raise common.ItemNotFoundError(",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "1721705254",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 53,
        "pr_file": "server/src/emcie/server/core/context_variables.py",
        "discussion_id": "1721705254",
        "commented_code": "@@ -196,18 +197,29 @@ async def delete_variable(\n         variable_set: str,\n         id: ContextVariableId,\n     ) -> None:\n-        await self._variable_collection.delete_one(\n-            {\n-                \"id\": {\"$eq\": id},\n-                \"variable_set\": {\"$eq\": variable_set},\n-            }\n-        )\n-        await self._value_collection.delete_one(\n-            {\n-                \"variable_id\": {\"$eq\": id},\n-                \"variable_set\": {\"$eq\": variable_set},\n-            }\n-        )\n+        try:\n+            await self._variable_collection.delete_one(\n+                {\n+                    \"id\": {\"$eq\": id},\n+                    \"variable_set\": {\"$eq\": variable_set},\n+                }\n+            )\n+        except NoMatchingDocumentsError:\n+            raise common.ItemNotFoundError(",
        "comment_created_at": "2024-08-19T12:23:08+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "You're using multiple things from `common`, so why not just import them directly? (Consistently with what we're doing everywhere else in this file\u2014and our codebase in general)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1721709361",
    "pr_number": 53,
    "pr_file": "server/src/emcie/server/core/sessions.py",
    "created_at": "2024-08-19T12:26:17+00:00",
    "commented_code": "from __future__ import annotations\n from abc import ABC, abstractmethod\n+import asyncio\n from dataclasses import dataclass\n from datetime import datetime, timezone\n from typing import Any, Literal, Mapping, NewType, Optional, Sequence, TypedDict\n \n from emcie.server.async_utils import Timeout\n from emcie.server.core import common\n-from emcie.server.core.common import JSONSerializable\n+from emcie.server.core.common import ItemNotFoundError, JSONSerializable, UniqueId",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "1721709361",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 53,
        "pr_file": "server/src/emcie/server/core/sessions.py",
        "discussion_id": "1721709361",
        "commented_code": "@@ -1,15 +1,17 @@\n from __future__ import annotations\n from abc import ABC, abstractmethod\n+import asyncio\n from dataclasses import dataclass\n from datetime import datetime, timezone\n from typing import Any, Literal, Mapping, NewType, Optional, Sequence, TypedDict\n \n from emcie.server.async_utils import Timeout\n from emcie.server.core import common\n-from emcie.server.core.common import JSONSerializable\n+from emcie.server.core.common import ItemNotFoundError, JSONSerializable, UniqueId",
        "comment_created_at": "2024-08-19T12:26:17+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "Note that we're importing `emcie.server.core.common` in two different ways. Let's remove the named module import and stick with importing all of the symbols we need directly.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1720706563",
    "pr_number": 46,
    "pr_file": "server/tests/test_guideline_connection_proposer.py",
    "created_at": "2024-08-17T07:28:39+00:00",
    "commented_code": "+from dataclasses import dataclass\n+from lagom import Container\n+from pytest import fixture, mark\n+\n+from emcie.server.core.agents import AgentId, AgentStore\n+from emcie.server.core.guidelines import Guideline, GuidelineStore\n+\n+from emcie.server.guideline_connection_proposer import GuidelineConnectionProposer\n+from emcie.server.logger import Logger\n+from tests.test_utilities import SyncAwaiter\n+\n+\n+@fixture\n+def agent_id(\n+    container: Container,\n+    sync_await: SyncAwaiter,\n+) -> AgentId:\n+    store = container[AgentStore]\n+    agent = sync_await(store.create_agent(name=\"test-agent\"))\n+    return agent.id\n+\n+\n+@dataclass\n+class _TestContext:\n+    sync_await: SyncAwaiter\n+    container: Container\n+    agent_id: AgentId\n+\n+\n+@fixture\n+def context(\n+    sync_await: SyncAwaiter,\n+    container: Container,\n+    agent_id: AgentId,\n+) -> _TestContext:\n+    return _TestContext(sync_await, container, agent_id)\n+\n+\n+@mark.parametrize(\n+    (\n+        \"source_guideline_definition\",\n+        \"target_guideline_definition\",\n+    ),\n+    [\n+        (\n+            {\n+                \"predicate\": \"The user asks about the weather\",",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "1720706563",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 46,
        "pr_file": "server/tests/test_guideline_connection_proposer.py",
        "discussion_id": "1720706563",
        "commented_code": "@@ -0,0 +1,304 @@\n+from dataclasses import dataclass\n+from lagom import Container\n+from pytest import fixture, mark\n+\n+from emcie.server.core.agents import AgentId, AgentStore\n+from emcie.server.core.guidelines import Guideline, GuidelineStore\n+\n+from emcie.server.guideline_connection_proposer import GuidelineConnectionProposer\n+from emcie.server.logger import Logger\n+from tests.test_utilities import SyncAwaiter\n+\n+\n+@fixture\n+def agent_id(\n+    container: Container,\n+    sync_await: SyncAwaiter,\n+) -> AgentId:\n+    store = container[AgentStore]\n+    agent = sync_await(store.create_agent(name=\"test-agent\"))\n+    return agent.id\n+\n+\n+@dataclass\n+class _TestContext:\n+    sync_await: SyncAwaiter\n+    container: Container\n+    agent_id: AgentId\n+\n+\n+@fixture\n+def context(\n+    sync_await: SyncAwaiter,\n+    container: Container,\n+    agent_id: AgentId,\n+) -> _TestContext:\n+    return _TestContext(sync_await, container, agent_id)\n+\n+\n+@mark.parametrize(\n+    (\n+        \"source_guideline_definition\",\n+        \"target_guideline_definition\",\n+    ),\n+    [\n+        (\n+            {\n+                \"predicate\": \"The user asks about the weather\",",
        "comment_created_at": "2024-08-17T07:28:39+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "Inconsistent capitalization of predicates.\n1. \"The user...\"\n2. \"providing the...\"\n\nPlease choose one capitalization scheme and stick to it in all of them",
        "pr_file_module": null
      }
    ]
  }
]