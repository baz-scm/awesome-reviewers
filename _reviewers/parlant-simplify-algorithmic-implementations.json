[
  {
    "discussion_id": "2016485222",
    "pr_number": 327,
    "pr_file": "src/parlant/core/engines/alpha/engine.py",
    "created_at": "2025-03-27T12:37:08+00:00",
    "commented_code": "key=key,\n         )\n \n+    async def _filter_missing_tool_parameters(\n+        self, missing_parameters: Sequence[MissingToolData]\n+    ) -> Sequence[MissingToolData]:\n+        # Precedence 0 is the default, so minimal precedence values start from 1\n+        positive_precedence = [\n+            m.precedence\n+            for m in missing_parameters\n+            if m.precedence is not None and m.precedence > 0\n+        ]\n+        if positive_precedence is None:\n+            return missing_parameters\n+\n+        return [m for m in missing_parameters if m.precedence == min(positive_precedence)]",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "2016485222",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 327,
        "pr_file": "src/parlant/core/engines/alpha/engine.py",
        "discussion_id": "2016485222",
        "commented_code": "@@ -957,6 +964,20 @@ async def _load_context_variable_value(\n             key=key,\n         )\n \n+    async def _filter_missing_tool_parameters(\n+        self, missing_parameters: Sequence[MissingToolData]\n+    ) -> Sequence[MissingToolData]:\n+        # Precedence 0 is the default, so minimal precedence values start from 1\n+        positive_precedence = [\n+            m.precedence\n+            for m in missing_parameters\n+            if m.precedence is not None and m.precedence > 0\n+        ]\n+        if positive_precedence is None:\n+            return missing_parameters\n+\n+        return [m for m in missing_parameters if m.precedence == min(positive_precedence)]",
        "comment_created_at": "2025-03-27T12:37:08+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "Wouldn't this make precedence==1 come before precedence==0?\r\n\r\nWhat would be the issue with this impl?\r\n\r\n```python\r\nfirst_precedence = min(m.precedence for m in missing_parameters)\r\nreturn [m for m in missing_parameters if m.precedence == first_precedence]\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1842427597",
    "pr_number": 146,
    "pr_file": "tests/e2e/test_utilities.py",
    "created_at": "2024-11-14T15:30:56+00:00",
    "commented_code": "home_dir: Path\n \n \n+def is_server_running(port: int) -> bool:\n+    process = subprocess.Popen(\n+        args=[\"lsof\", f\"-i:{port}\"],\n+        stdout=asyncio.subprocess.PIPE,\n+        stderr=asyncio.subprocess.PIPE,\n+    )\n+    process.wait()\n+\n+    stdout_view, stderr_view = process.communicate()",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "1842427597",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 146,
        "pr_file": "tests/e2e/test_utilities.py",
        "discussion_id": "1842427597",
        "commented_code": "@@ -96,11 +97,31 @@ class ContextOfTest:\n     home_dir: Path\n \n \n+def is_server_running(port: int) -> bool:\n+    process = subprocess.Popen(\n+        args=[\"lsof\", f\"-i:{port}\"],\n+        stdout=asyncio.subprocess.PIPE,\n+        stderr=asyncio.subprocess.PIPE,\n+    )\n+    process.wait()\n+\n+    stdout_view, stderr_view = process.communicate()",
        "comment_created_at": "2024-11-14T15:30:56+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "I think you can replace the impl here with `subprocess.getstatusoutput()` or even `subprocess.getoutput()`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1835408633",
    "pr_number": 134,
    "pr_file": "src/parlant/adapters/db/chroma/glossary.py",
    "created_at": "2024-11-09T14:25:10+00:00",
    "commented_code": "return TermId(term_document[\"id\"])\n \n+    async def _query_chunks(self, query: str) -> list[str]:\n+        max_length = self._embedder.max_tokens // 5\n+        tokenizer = self._embedder.get_tokenizer()\n+\n+        total_token_count = await tokenizer.estimate_token_count(query)\n+\n+        words = query.split()\n+        total_word_count = len(words)\n+\n+        tokens_per_word = total_token_count / total_word_count\n+\n+        words_per_chunk = max(int(max_length / tokens_per_word), 1)\n+\n+        chunks = []\n+        for i in range(0, total_word_count, words_per_chunk):\n+            chunk_words = words[i : i + words_per_chunk]\n+            chunk = \" \".join(chunk_words)\n+            chunks.append(chunk)\n+\n+        return [text if await tokenizer.estimate_token_count(text) else \"\" for text in chunks]\n+\n     async def find_relevant_terms(\n         self,\n         term_set: str,\n         query: str,\n     ) -> Sequence[Term]:\n-        return [\n-            self._deserialize(d)\n-            for d in await self._collection.find_similar_documents(\n+        queries = await self._query_chunks(query)\n+\n+        tasks = [\n+            self._collection.find_similar_documents(\n                 filters={\"term_set\": {\"$eq\": term_set}},\n-                query=query,\n+                query=q,\n                 k=self._n_results,\n             )\n+            for q in queries\n         ]\n \n+        all_results = sorted(",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "1835408633",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 134,
        "pr_file": "src/parlant/adapters/db/chroma/glossary.py",
        "discussion_id": "1835408633",
        "commented_code": "@@ -165,20 +173,50 @@ async def delete_term(\n \n         return TermId(term_document[\"id\"])\n \n+    async def _query_chunks(self, query: str) -> list[str]:\n+        max_length = self._embedder.max_tokens // 5\n+        tokenizer = self._embedder.get_tokenizer()\n+\n+        total_token_count = await tokenizer.estimate_token_count(query)\n+\n+        words = query.split()\n+        total_word_count = len(words)\n+\n+        tokens_per_word = total_token_count / total_word_count\n+\n+        words_per_chunk = max(int(max_length / tokens_per_word), 1)\n+\n+        chunks = []\n+        for i in range(0, total_word_count, words_per_chunk):\n+            chunk_words = words[i : i + words_per_chunk]\n+            chunk = \" \".join(chunk_words)\n+            chunks.append(chunk)\n+\n+        return [text if await tokenizer.estimate_token_count(text) else \"\" for text in chunks]\n+\n     async def find_relevant_terms(\n         self,\n         term_set: str,\n         query: str,\n     ) -> Sequence[Term]:\n-        return [\n-            self._deserialize(d)\n-            for d in await self._collection.find_similar_documents(\n+        queries = await self._query_chunks(query)\n+\n+        tasks = [\n+            self._collection.find_similar_documents(\n                 filters={\"term_set\": {\"$eq\": term_set}},\n-                query=query,\n+                query=q,\n                 k=self._n_results,\n             )\n+            for q in queries\n         ]\n \n+        all_results = sorted(",
        "comment_created_at": "2024-11-09T14:25:10+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "I'd separate this action here into multiple stages. Mainly because \"all_results\" is not literally \"all the results\" you are fetching here, but only the top N ones, and sorted as well.\n\nStage 1:\n`all_results = chain.from_iterable(await asyncio.gather(*tasks))`\nStage 2:\n`unique_results = list(set(all_results))`\nStage 3:\n`top_results = sorted(unique_results, key=lambda r: r.distance)[:max_terms]`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1662409894",
    "pr_number": 10,
    "pr_file": "server/src/emcie/server/core/persistence.py",
    "created_at": "2024-07-02T12:15:32+00:00",
    "commented_code": "+from abc import ABC, abstractmethod\n+import asyncio\n+from collections import defaultdict\n+from datetime import datetime\n+import json\n+from pathlib import Path\n+import re\n+from typing import Any, Iterable, TypedDict\n+import aiofiles\n+\n+from emcie.server.core import common\n+\n+\n+class FieldFilter(TypedDict, total=False):\n+    equal_to: Any\n+    not_equal_to: Any\n+    greater_than: Any\n+    less_than: Any\n+    regex: str\n+\n+\n+class DocumentDatabase(ABC):\n+    @staticmethod\n+    def _matches_filters(\n+        filters: dict[str, FieldFilter],\n+        candidate: dict[str, Any],\n+    ) -> bool:\n+        for field, conditions in filters.items():\n+            value = candidate.get(field)",
    "repo_full_name": "emcie-co/parlant",
    "discussion_comments": [
      {
        "comment_id": "1662409894",
        "repo_full_name": "emcie-co/parlant",
        "pr_number": 10,
        "pr_file": "server/src/emcie/server/core/persistence.py",
        "discussion_id": "1662409894",
        "commented_code": "@@ -0,0 +1,282 @@\n+from abc import ABC, abstractmethod\n+import asyncio\n+from collections import defaultdict\n+from datetime import datetime\n+import json\n+from pathlib import Path\n+import re\n+from typing import Any, Iterable, TypedDict\n+import aiofiles\n+\n+from emcie.server.core import common\n+\n+\n+class FieldFilter(TypedDict, total=False):\n+    equal_to: Any\n+    not_equal_to: Any\n+    greater_than: Any\n+    less_than: Any\n+    regex: str\n+\n+\n+class DocumentDatabase(ABC):\n+    @staticmethod\n+    def _matches_filters(\n+        filters: dict[str, FieldFilter],\n+        candidate: dict[str, Any],\n+    ) -> bool:\n+        for field, conditions in filters.items():\n+            value = candidate.get(field)",
        "comment_created_at": "2024-07-02T12:15:32+00:00",
        "comment_author": "kichanyurd",
        "comment_body": "Something like this perhaps would be cleaner?\r\n\r\n```python\r\ntests = {\r\n  \"equal_to\": lambda a, b: a == b,\r\n  \"not_equal_to\": lambda a, b: a == b,\r\n...\r\n  \"regex\": lambda a, b: re.match(str(a), str(b)),\r\n}\r\n\r\nfor test, value in conditions.items():\r\n  if not tests[test](value, candidate.get(field)):\r\n    return False\r\n```",
        "pr_file_module": null
      }
    ]
  }
]