[
  {
    "discussion_id": "1852233987",
    "pr_number": 19894,
    "pr_file": "crates/polars-ops/src/series/ops/index_of.rs",
    "created_at": "2024-11-21T14:25:16+00:00",
    "commented_code": "+use arrow::array::PrimitiveArray;\n+use polars_core::downcast_as_macro_arg_physical;\n+use polars_core::prelude::*;\n+use polars_utils::float::IsFloat;\n+\n+/// Search for an item, typically in a ChunkedArray.\n+trait ChunkSearch<'a, T> {\n+    /// Return the index of the given value within self, or `None` if not found.\n+    fn index_of(&'a self, value: Option<T>) -> Option<usize>;\n+}\n+\n+/// Find index where predicate is true.\n+fn index_of_predicate<P, T>(ca: &ChunkedArray<T>, predicate: P) -> Option<usize>\n+where\n+    T: PolarsNumericType,\n+    P: Fn(&T::Native) -> bool,\n+{\n+    let mut index = 0;\n+    for chunk in ca.chunks() {\n+        let chunk = chunk\n+            .as_any()\n+            .downcast_ref::<PrimitiveArray<T::Native>>()\n+            .unwrap();\n+        if chunk.validity().is_some() {\n+            for maybe_value in chunk.iter() {\n+                if maybe_value.map(&predicate) == Some(true) {\n+                    return Some(index);\n+                } else {\n+                    index += 1;\n+                }\n+            }\n+        } else {\n+            // No nulls, so we can simplify:\n+            for value in chunk.values_iter() {\n+                if predicate(value) {\n+                    return Some(index);\n+                } else {\n+                    index += 1;\n+                }\n+            }\n+        }\n+    }\n+    None\n+}\n+\n+impl<'a, T> ChunkSearch<'a, T::Native> for ChunkedArray<T>\n+where\n+    T: PolarsNumericType,\n+{\n+    fn index_of(&'a self, value: Option<T::Native>) -> Option<usize> {\n+        // A NaN is never equal to anything, including itself. But we still want\n+        // to be able to search for NaNs, so we handle them specially.\n+        if value.map(|v| v.is_nan()) == Some(true) {\n+            return index_of_predicate(self, |v| v.is_nan());\n+        }\n+\n+        // Searching for an actual value:\n+        if let Some(value) = value {\n+            return index_of_predicate(self, |v| *v == value);",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1852233987",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 19894,
        "pr_file": "crates/polars-ops/src/series/ops/index_of.rs",
        "discussion_id": "1852233987",
        "commented_code": "@@ -0,0 +1,137 @@\n+use arrow::array::PrimitiveArray;\n+use polars_core::downcast_as_macro_arg_physical;\n+use polars_core::prelude::*;\n+use polars_utils::float::IsFloat;\n+\n+/// Search for an item, typically in a ChunkedArray.\n+trait ChunkSearch<'a, T> {\n+    /// Return the index of the given value within self, or `None` if not found.\n+    fn index_of(&'a self, value: Option<T>) -> Option<usize>;\n+}\n+\n+/// Find index where predicate is true.\n+fn index_of_predicate<P, T>(ca: &ChunkedArray<T>, predicate: P) -> Option<usize>\n+where\n+    T: PolarsNumericType,\n+    P: Fn(&T::Native) -> bool,\n+{\n+    let mut index = 0;\n+    for chunk in ca.chunks() {\n+        let chunk = chunk\n+            .as_any()\n+            .downcast_ref::<PrimitiveArray<T::Native>>()\n+            .unwrap();\n+        if chunk.validity().is_some() {\n+            for maybe_value in chunk.iter() {\n+                if maybe_value.map(&predicate) == Some(true) {\n+                    return Some(index);\n+                } else {\n+                    index += 1;\n+                }\n+            }\n+        } else {\n+            // No nulls, so we can simplify:\n+            for value in chunk.values_iter() {\n+                if predicate(value) {\n+                    return Some(index);\n+                } else {\n+                    index += 1;\n+                }\n+            }\n+        }\n+    }\n+    None\n+}\n+\n+impl<'a, T> ChunkSearch<'a, T::Native> for ChunkedArray<T>\n+where\n+    T: PolarsNumericType,\n+{\n+    fn index_of(&'a self, value: Option<T::Native>) -> Option<usize> {\n+        // A NaN is never equal to anything, including itself. But we still want\n+        // to be able to search for NaNs, so we handle them specially.\n+        if value.map(|v| v.is_nan()) == Some(true) {\n+            return index_of_predicate(self, |v| v.is_nan());\n+        }\n+\n+        // Searching for an actual value:\n+        if let Some(value) = value {\n+            return index_of_predicate(self, |v| *v == value);",
        "comment_created_at": "2024-11-21T14:25:16+00:00",
        "comment_author": "nameexhaustion",
        "comment_body": "We should use `tot_eq` from the `TotalEq` trait for comparisons - then we won't need the extra branch above for NaNs as well.\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "1854623190",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 19894,
        "pr_file": "crates/polars-ops/src/series/ops/index_of.rs",
        "discussion_id": "1852233987",
        "commented_code": "@@ -0,0 +1,137 @@\n+use arrow::array::PrimitiveArray;\n+use polars_core::downcast_as_macro_arg_physical;\n+use polars_core::prelude::*;\n+use polars_utils::float::IsFloat;\n+\n+/// Search for an item, typically in a ChunkedArray.\n+trait ChunkSearch<'a, T> {\n+    /// Return the index of the given value within self, or `None` if not found.\n+    fn index_of(&'a self, value: Option<T>) -> Option<usize>;\n+}\n+\n+/// Find index where predicate is true.\n+fn index_of_predicate<P, T>(ca: &ChunkedArray<T>, predicate: P) -> Option<usize>\n+where\n+    T: PolarsNumericType,\n+    P: Fn(&T::Native) -> bool,\n+{\n+    let mut index = 0;\n+    for chunk in ca.chunks() {\n+        let chunk = chunk\n+            .as_any()\n+            .downcast_ref::<PrimitiveArray<T::Native>>()\n+            .unwrap();\n+        if chunk.validity().is_some() {\n+            for maybe_value in chunk.iter() {\n+                if maybe_value.map(&predicate) == Some(true) {\n+                    return Some(index);\n+                } else {\n+                    index += 1;\n+                }\n+            }\n+        } else {\n+            // No nulls, so we can simplify:\n+            for value in chunk.values_iter() {\n+                if predicate(value) {\n+                    return Some(index);\n+                } else {\n+                    index += 1;\n+                }\n+            }\n+        }\n+    }\n+    None\n+}\n+\n+impl<'a, T> ChunkSearch<'a, T::Native> for ChunkedArray<T>\n+where\n+    T: PolarsNumericType,\n+{\n+    fn index_of(&'a self, value: Option<T::Native>) -> Option<usize> {\n+        // A NaN is never equal to anything, including itself. But we still want\n+        // to be able to search for NaNs, so we handle them specially.\n+        if value.map(|v| v.is_nan()) == Some(true) {\n+            return index_of_predicate(self, |v| v.is_nan());\n+        }\n+\n+        // Searching for an actual value:\n+        if let Some(value) = value {\n+            return index_of_predicate(self, |v| *v == value);",
        "comment_created_at": "2024-11-22T20:35:41+00:00",
        "comment_author": "itamarst",
        "comment_body": "Thanks for the pointer, I didn't know that existed. However, I disagree with the suggestion.\r\n\r\n* The current implementation has a constant overhead: it does the check _once_, when the operation is being set up.\r\n* `tot_eq` for float64 or float32 would turn this into an `O(N)` overhead, since it would have to do `is_nan()` for every single value in the Series. https://godbolt.org/z/Wdnoa3ahn suggests the compiler will not be able to optimize this away.\r\n\r\nSo I would suggest keeping things as is.",
        "pr_file_module": null
      },
      {
        "comment_id": "1855204273",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 19894,
        "pr_file": "crates/polars-ops/src/series/ops/index_of.rs",
        "discussion_id": "1852233987",
        "commented_code": "@@ -0,0 +1,137 @@\n+use arrow::array::PrimitiveArray;\n+use polars_core::downcast_as_macro_arg_physical;\n+use polars_core::prelude::*;\n+use polars_utils::float::IsFloat;\n+\n+/// Search for an item, typically in a ChunkedArray.\n+trait ChunkSearch<'a, T> {\n+    /// Return the index of the given value within self, or `None` if not found.\n+    fn index_of(&'a self, value: Option<T>) -> Option<usize>;\n+}\n+\n+/// Find index where predicate is true.\n+fn index_of_predicate<P, T>(ca: &ChunkedArray<T>, predicate: P) -> Option<usize>\n+where\n+    T: PolarsNumericType,\n+    P: Fn(&T::Native) -> bool,\n+{\n+    let mut index = 0;\n+    for chunk in ca.chunks() {\n+        let chunk = chunk\n+            .as_any()\n+            .downcast_ref::<PrimitiveArray<T::Native>>()\n+            .unwrap();\n+        if chunk.validity().is_some() {\n+            for maybe_value in chunk.iter() {\n+                if maybe_value.map(&predicate) == Some(true) {\n+                    return Some(index);\n+                } else {\n+                    index += 1;\n+                }\n+            }\n+        } else {\n+            // No nulls, so we can simplify:\n+            for value in chunk.values_iter() {\n+                if predicate(value) {\n+                    return Some(index);\n+                } else {\n+                    index += 1;\n+                }\n+            }\n+        }\n+    }\n+    None\n+}\n+\n+impl<'a, T> ChunkSearch<'a, T::Native> for ChunkedArray<T>\n+where\n+    T: PolarsNumericType,\n+{\n+    fn index_of(&'a self, value: Option<T::Native>) -> Option<usize> {\n+        // A NaN is never equal to anything, including itself. But we still want\n+        // to be able to search for NaNs, so we handle them specially.\n+        if value.map(|v| v.is_nan()) == Some(true) {\n+            return index_of_predicate(self, |v| v.is_nan());\n+        }\n+\n+        // Searching for an actual value:\n+        if let Some(value) = value {\n+            return index_of_predicate(self, |v| *v == value);",
        "comment_created_at": "2024-11-23T14:33:20+00:00",
        "comment_author": "ritchie46",
        "comment_body": "I do wonder though if it is worth the extra binary bloat. The `is_nan` will be correctly predicted on every non-nan, until we hit it. On that mis prediction we are done, so I think it doesn't really matter and we can save a monomorphized function.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1493302205",
    "pr_number": 14558,
    "pr_file": "crates/polars-ops/src/chunked_array/list/sets.rs",
    "created_at": "2024-02-17T10:44:15+00:00",
    "commented_code": "set.extend(a);\n             out.extend_buf(set.symmetric_difference(set2).copied())\n         },\n+        SetOperation::IsDisjoint => {\n+            // If broadcast `set2` should already be filled.\n+            if !broadcast_rhs {\n+                set2.clear();\n+                set2.extend(b);",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1493302205",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 14558,
        "pr_file": "crates/polars-ops/src/chunked_array/list/sets.rs",
        "discussion_id": "1493302205",
        "commented_code": "@@ -99,6 +101,15 @@ where\n             set.extend(a);\n             out.extend_buf(set.symmetric_difference(set2).copied())\n         },\n+        SetOperation::IsDisjoint => {\n+            // If broadcast `set2` should already be filled.\n+            if !broadcast_rhs {\n+                set2.clear();\n+                set2.extend(b);",
        "comment_created_at": "2024-02-17T10:44:15+00:00",
        "comment_author": "Object905",
        "comment_body": "Possible optimization - if len of a and b is known here, then could extend set with smaller one and compare with bigger",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1935298285",
    "pr_number": 20960,
    "pr_file": "crates/polars-stream/src/nodes/merge_sorted.rs",
    "created_at": "2025-01-30T09:39:32+00:00",
    "commented_code": "+use std::collections::VecDeque;\n use std::sync::Arc;\n \n+use polars_core::prelude::ChunkCompareIneq;\n use polars_core::schema::Schema;\n use polars_ops::frame::_merge_sorted_dfs;\n use polars_utils::pl_str::PlSmallStr;\n \n+use crate::async_primitives::connector::Receiver;\n+use crate::async_primitives::distributor_channel::distributor_channel;\n+use crate::morsel::{get_ideal_morsel_size, SourceToken};\n use crate::nodes::compute_node_prelude::*;\n-use crate::nodes::in_memory_sink::InMemorySinkNode;\n-use crate::nodes::in_memory_source::InMemorySourceNode;\n-\n-enum MergeSortedState {\n-    Sink {\n-        left: InMemorySinkNode,\n-        right: InMemorySinkNode,\n-    },\n-    Source(InMemorySourceNode),\n-    Done,\n+use crate::DEFAULT_DISTRIBUTOR_BUFFER_SIZE;\n+\n+#[derive(Debug)]\n+enum State {\n+    /// Merging values from buffered or ports.\n+    Merging,\n+    /// Flushing buffer values.\n+    Flushing,\n+    /// Passing values along from one of the ports.\n+    Piping,\n }\n \n pub struct MergeSortedNode {\n-    state: MergeSortedState,\n     num_pipelines: usize,\n-    key: PlSmallStr,\n+    key_column_idx: usize,\n+    state: State,\n+\n+    seq: MorselSeq,\n+\n+    starting_nulls: bool,\n+\n+    // Not yet merged buffers.\n+    left_unmerged: VecDeque<DataFrame>,\n+    right_unmerged: VecDeque<DataFrame>,\n }\n \n impl MergeSortedNode {\n     pub fn new(schema: Arc<Schema>, key: PlSmallStr) -> Self {\n         assert!(schema.contains(key.as_str()));\n+        let key_column_idx = schema.index_of(key.as_str()).unwrap();\n+\n         Self {\n-            state: MergeSortedState::Sink {\n-                left: InMemorySinkNode::new(schema.clone()),\n-                right: InMemorySinkNode::new(schema),\n-            },\n-            num_pipelines: 0,\n-            key,\n+            num_pipelines: 1,\n+            key_column_idx,\n+            state: State::Merging,\n+\n+            seq: MorselSeq::default(),\n+\n+            starting_nulls: false,\n+\n+            left_unmerged: VecDeque::new(),\n+            right_unmerged: VecDeque::new(),\n         }\n     }\n }\n \n impl ComputeNode for MergeSortedNode {\n     fn name(&self) -> &str {\n-        \"in_memory_merge_sorted\"\n+        \"merge_sorted\"\n     }\n \n     fn initialize(&mut self, num_pipelines: usize) {\n         self.num_pipelines = num_pipelines;\n     }\n \n     fn update_state(&mut self, recv: &mut [PortState], send: &mut [PortState]) -> PolarsResult<()> {\n-        assert!(recv.len() == 2 && send.len() == 1);\n+        assert_eq!(send.len(), 1);\n+        assert_eq!(recv.len(), 2);\n \n         // If the output doesn't want any more data, transition to being done.\n-        if send[0] == PortState::Done && !matches!(self.state, MergeSortedState::Done) {\n-            self.state = MergeSortedState::Done;\n+        if send[0] == PortState::Done {\n+            recv[0] = PortState::Done;\n+            recv[1] = PortState::Done;\n+\n+            self.left_unmerged.clear();\n+            self.right_unmerged.clear();\n+            self.state = State::Piping;\n+\n+            return Ok(());\n         }\n \n-        // If the input is done, transition to being a source.\n-        if let MergeSortedState::Sink { left, right } = &mut self.state {\n-            if recv[0] == PortState::Done && recv[1] == PortState::Done {\n-                let left_df = left.get_output()?.unwrap();\n-                let right_df = right.get_output()?.unwrap();\n-                let left_s = left_df.column(self.key.as_str()).unwrap();\n-                let right_s = right_df.column(self.key.as_str()).unwrap();\n-                let df = _merge_sorted_dfs(\n-                    &left_df,\n-                    &right_df,\n-                    left_s.as_materialized_series(),\n-                    right_s.as_materialized_series(),\n-                    true,\n-                )?;\n-                let mut source_node = InMemorySourceNode::new(Arc::new(df), MorselSeq::default());\n-                source_node.initialize(self.num_pipelines);\n-                self.state = MergeSortedState::Source(source_node);\n+        if recv[0] == PortState::Done || recv[1] == PortState::Done {\n+            if !self.left_unmerged.is_empty() || !self.right_unmerged.is_empty() {\n+                self.state = State::Flushing;\n+            } else {\n+                self.state = State::Piping;\n             }\n+        } else {\n+            self.state = State::Merging;\n         }\n \n-        match &mut self.state {\n-            MergeSortedState::Sink { left, right, .. } => {\n-                left.update_state(&mut recv[0..1], &mut [])?;\n-                right.update_state(&mut recv[1..2], &mut [])?;\n+        match self.state {\n+            State::Merging if send[0] == PortState::Blocked => {\n+                recv[0] = PortState::Blocked;\n+                recv[1] = PortState::Blocked;\n+            },\n+\n+            // If one input side is blocked and we haven't buffered anything for that side, we\n+            // block the other ports as well.\n+            State::Merging if recv[0] == PortState::Blocked && self.left_unmerged.is_empty() => {\n                 send[0] = PortState::Blocked;\n+                recv[1] = PortState::Blocked;\n+            },\n+            State::Merging if recv[1] == PortState::Blocked && self.right_unmerged.is_empty() => {\n+                send[0] = PortState::Blocked;\n+                recv[0] = PortState::Blocked;\n+            },\n+\n+            State::Merging => {\n+                if recv[0] != PortState::Blocked {\n+                    recv[0] = PortState::Ready;\n+                }\n+                if recv[1] != PortState::Blocked {\n+                    recv[1] = PortState::Ready;\n+                }\n+                send[0] = PortState::Ready;\n             },\n-            MergeSortedState::Source(source_node) => {\n-                recv[0] = PortState::Done;\n-                recv[1] = PortState::Done;\n-                source_node.update_state(&mut [], send)?;\n+\n+            State::Flushing => {\n+                if recv[0] != PortState::Done {\n+                    recv[0] = PortState::Blocked;\n+                }\n+                if recv[1] != PortState::Done {\n+                    recv[1] = PortState::Blocked;\n+                }\n             },\n-            MergeSortedState::Done => {\n-                recv[0] = PortState::Done;\n-                recv[1] = PortState::Done;\n+\n+            State::Piping if recv[0] == PortState::Done && recv[1] == PortState::Done => {\n                 send[0] = PortState::Done;\n             },\n+            State::Piping if recv[0] == PortState::Blocked || recv[1] == PortState::Blocked => {\n+                send[0] = PortState::Blocked;\n+            },\n+            State::Piping if send[0] == PortState::Blocked => {\n+                if recv[0] != PortState::Done {\n+                    recv[0] = PortState::Blocked;\n+                }\n+                if recv[1] != PortState::Done {\n+                    recv[1] = PortState::Blocked;\n+                }\n+            },\n+            State::Piping => {\n+                if recv[0] != PortState::Done {\n+                    recv[0] = PortState::Ready;\n+                }\n+                if recv[1] != PortState::Done {\n+                    recv[1] = PortState::Ready;\n+                }\n+                send[0] = PortState::Ready;\n+            },\n         }\n-        Ok(())\n-    }\n \n-    fn is_memory_intensive_pipeline_blocker(&self) -> bool {\n-        matches!(self.state, MergeSortedState::Sink { .. })\n+        Ok(())\n     }\n \n     fn spawn<'env, 's>(\n         &'env mut self,\n         scope: &'s TaskScope<'s, 'env>,\n         recv_ports: &mut [Option<RecvPort<'_>>],\n         send_ports: &mut [Option<SendPort<'_>>],\n-        state: &'s ExecutionState,\n+        _state: &'s ExecutionState,\n         join_handles: &mut Vec<JoinHandle<PolarsResult<()>>>,\n     ) {\n-        assert!(recv_ports.len() == 2);\n-        assert!(send_ports.len() == 1);\n-        match &mut self.state {\n-            MergeSortedState::Sink { left, right, .. } => {\n-                if recv_ports[0].is_some() {\n-                    left.spawn(scope, &mut recv_ports[0..1], &mut [], state, join_handles);\n-                }\n-                if recv_ports[1].is_some() {\n-                    right.spawn(scope, &mut recv_ports[1..2], &mut [], state, join_handles);\n+        assert_eq!(recv_ports.len(), 2);\n+        assert_eq!(send_ports.len(), 1);\n+\n+        let seq = &mut self.seq;\n+        let starting_nulls = &mut self.starting_nulls;\n+        let key_column_idx = self.key_column_idx;\n+        let left_unmerged = &mut self.left_unmerged;\n+        let right_unmerged = &mut self.right_unmerged;\n+\n+        let source_token = SourceToken::new();\n+\n+        match self.state {\n+            State::Merging => {\n+                /// Request that a port stops producing [`Morsel`]s and buffer all the remaining\n+                /// [`Morsel`]s.\n+                async fn buffer_port(\n+                    port: &mut Receiver<Morsel>,\n+                    buffer: &mut VecDeque<DataFrame>,\n+                ) {\n+                    // If a stop was requested, we need to buffer the remaining\n+                    // morsels and trigger a phase transition.\n+                    let Ok(morsel) = port.recv().await else {\n+                        return;\n+                    };\n+\n+                    // Request the port stop producing morsels.\n+                    morsel.source_token().stop();\n+\n+                    // Buffer all the morsels that were already produced.\n+                    buffer.push_back(morsel.into_df());\n+                    while let Ok(morsel) = port.recv().await {\n+                        buffer.push_back(morsel.into_df());\n+                    }\n                 }\n+\n+                let send = send_ports[0].take().unwrap().parallel();\n+\n+                let (mut distributor, dist_recv) =\n+                    distributor_channel(self.num_pipelines, DEFAULT_DISTRIBUTOR_BUFFER_SIZE);\n+\n+                let mut left = recv_ports[0].take().unwrap().serial();\n+                let mut right = recv_ports[1].take().unwrap().serial();\n+\n+                let _source_token = source_token.clone();\n+                join_handles.push(scope.spawn_task(TaskPriority::Low, async move {\n+                    let mut trigger_phase_transition = false;\n+                    let source_token = _source_token;\n+\n+                    loop {\n+                        if source_token.stop_requested() {\n+                            trigger_phase_transition = true;\n+                        }\n+\n+                        // If we have morsels from both input ports, find until where we can merge\n+                        // them and send that on to be merged.\n+                        while !left_unmerged.is_empty() && !right_unmerged.is_empty() {\n+                            let mut left = left_unmerged.pop_front().unwrap();\n+                            let mut right = right_unmerged.pop_front().unwrap();\n+\n+                            // Ensure that we have some data to merge.\n+                            if left.is_empty() || right.is_empty() {\n+                                if !left.is_empty() {\n+                                    left_unmerged.push_front(left);\n+                                }\n+                                if !right.is_empty() {\n+                                    right_unmerged.push_front(right);\n+                                }\n+                                continue;\n+                            }\n+\n+                            let left_key = &left[key_column_idx];\n+                            let right_key = &right[key_column_idx];\n+\n+                            let left_null_count = left_key.null_count();\n+                            let right_null_count = right_key.null_count();\n+\n+                            let has_nulls = left_null_count > 0 || right_null_count > 0;\n+\n+                            // If we are on the first morsel we need to decide whether we have\n+                            // nulls first or not.\n+                            if seq.to_u64() == 0\n+                                && has_nulls\n+                                && (left_key.head(Some(1)).has_nulls()\n+                                    || right_key.head(Some(1)).has_nulls())\n+                            {\n+                                *starting_nulls = true;\n+                            }\n+\n+                            // For both left and right, find row index of the minimum of the maxima\n+                            // of the left and right key columns. We can safely merge until this\n+                            // point.\n+                            let mut left_cutoff = left.height();\n+                            let mut right_cutoff = right.height();\n+\n+                            let left_key_last = left_key.tail(Some(1));\n+                            let right_key_last = right_key.tail(Some(1));\n+\n+                            // We already made sure we had data to work with.\n+                            assert!(!left_key_last.is_empty());\n+                            assert!(!right_key_last.is_empty());\n+\n+                            if has_nulls {\n+                                if *starting_nulls {\n+                                    // If there are starting nulls do those first, then repeat\n+                                    // without the nulls.\n+                                    left_cutoff = left_null_count;\n+                                    right_cutoff = right_null_count;\n+                                } else {\n+                                    // If there are ending nulls then first do things without the\n+                                    // nulls and then repeat with only the nulls the nulls.\n+                                    let left_is_all_nulls = left_null_count == left.height();\n+                                    let right_is_all_nulls = right_null_count == right.height();\n+\n+                                    match (left_is_all_nulls, right_is_all_nulls) {\n+                                        (false, false) => {\n+                                            let left_nulls;\n+                                            let right_nulls;\n+                                            (left, left_nulls) = left\n+                                                .split_at((left.height() - left_null_count) as i64);\n+                                            (right, right_nulls) = right.split_at(\n+                                                (right.height() - right_null_count) as i64,\n+                                            );\n+\n+                                            left_unmerged.push_front(left_nulls);\n+                                            left_unmerged.push_front(left);\n+                                            right_unmerged.push_front(right_nulls);\n+                                            right_unmerged.push_front(right);\n+                                            continue;\n+                                        },\n+                                        (true, false) => left_cutoff = 0,\n+                                        (false, true) => right_cutoff = 0,\n+                                        (true, true) => {},\n+                                    }\n+                                }\n+                            } else if left_key_last.lt(&right_key_last)?.all() {\n+                                // @TODO: This is essentially search sorted, but that does not\n+                                // support categoricals at moment.\n+                                let gt_mask = right_key.gt(&left_key_last)?.downcast_into_array();\n+                                right_cutoff = gt_mask.values().leading_zeros();\n+                            } else if left_key_last.gt(&right_key_last)?.all() {\n+                                // @TODO: This is essentially search sorted, but that does not\n+                                // support categoricals at moment.\n+                                let gt_mask = left_key.gt(&right_key_last)?.downcast_into_array();\n+                                left_cutoff = gt_mask.values().leading_zeros();\n+                            }\n+\n+                            let left_mergeable: DataFrame;\n+                            let right_mergeable: DataFrame;\n+                            (left_mergeable, left) = left.split_at(left_cutoff as i64);\n+                            (right_mergeable, right) = right.split_at(right_cutoff as i64);\n+\n+                            if distributor\n+                                .send((*seq, left_mergeable, right_mergeable))\n+                                .await\n+                                .is_err()\n+                            {\n+                                return Ok(());\n+                            };\n+                            // The merging task might split the merged dataframe in two.\n+                            *seq = seq.successor().successor();\n+\n+                            if !left.is_empty() {\n+                                left_unmerged.push_front(left);\n+                            }\n+                            if !right.is_empty() {\n+                                right_unmerged.push_front(right);\n+                            }\n+                        }\n+\n+                        if trigger_phase_transition {\n+                            buffer_port(&mut left, left_unmerged).await;\n+                            buffer_port(&mut right, right_unmerged).await;\n+                            return Ok(());\n+                        }\n+\n+                        let (empty_port, empty_unmerged) = if left_unmerged.is_empty() {\n+                            (&mut left, &mut *left_unmerged)\n+                        } else {\n+                            (&mut right, &mut *right_unmerged)\n+                        };\n+\n+                        // Try to get a new morsel from the empty side.\n+                        let Ok(received_unmerged) = empty_port.recv().await else {\n+                            trigger_phase_transition = true;\n+                            continue;\n+                        };\n+                        empty_unmerged.push_back(received_unmerged.into_df());\n+                    }\n+                }));\n+\n+                // Task that actually merges the two dataframes. Since this merge might be very\n+                // expensive, this is split over several tasks.\n+                join_handles.extend(dist_recv.into_iter().zip(send).map(|(mut recv, mut send)| {\n+                    let source_token = source_token.clone();\n+                    let ideal_morsel_size = get_ideal_morsel_size();\n+                    scope.spawn_task(TaskPriority::High, async move {\n+                        while let Ok((seq, left, right)) = recv.recv().await {\n+                            let left_s = left[key_column_idx].as_materialized_series();\n+                            let right_s = right[key_column_idx].as_materialized_series();\n+\n+                            let merged = _merge_sorted_dfs(&left, &right, left_s, right_s, false)?;\n+\n+                            if ideal_morsel_size > 1 && merged.height() > ideal_morsel_size {\n+                                // The merged dataframe will have at most doubled in size from the\n+                                // input so we can divide by half.\n+                                let (m1, m2) = merged.split_at((merged.height() / 2) as i64);\n+\n+                                let morsel = Morsel::new(m1, seq, source_token.clone());\n+                                if send.send(morsel).await.is_err() {\n+                                    break;\n+                                }\n+                                let morsel = Morsel::new(m2, seq.successor(), source_token.clone());",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1935298285",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 20960,
        "pr_file": "crates/polars-stream/src/nodes/merge_sorted.rs",
        "discussion_id": "1935298285",
        "commented_code": "@@ -1,126 +1,477 @@\n+use std::collections::VecDeque;\n use std::sync::Arc;\n \n+use polars_core::prelude::ChunkCompareIneq;\n use polars_core::schema::Schema;\n use polars_ops::frame::_merge_sorted_dfs;\n use polars_utils::pl_str::PlSmallStr;\n \n+use crate::async_primitives::connector::Receiver;\n+use crate::async_primitives::distributor_channel::distributor_channel;\n+use crate::morsel::{get_ideal_morsel_size, SourceToken};\n use crate::nodes::compute_node_prelude::*;\n-use crate::nodes::in_memory_sink::InMemorySinkNode;\n-use crate::nodes::in_memory_source::InMemorySourceNode;\n-\n-enum MergeSortedState {\n-    Sink {\n-        left: InMemorySinkNode,\n-        right: InMemorySinkNode,\n-    },\n-    Source(InMemorySourceNode),\n-    Done,\n+use crate::DEFAULT_DISTRIBUTOR_BUFFER_SIZE;\n+\n+#[derive(Debug)]\n+enum State {\n+    /// Merging values from buffered or ports.\n+    Merging,\n+    /// Flushing buffer values.\n+    Flushing,\n+    /// Passing values along from one of the ports.\n+    Piping,\n }\n \n pub struct MergeSortedNode {\n-    state: MergeSortedState,\n     num_pipelines: usize,\n-    key: PlSmallStr,\n+    key_column_idx: usize,\n+    state: State,\n+\n+    seq: MorselSeq,\n+\n+    starting_nulls: bool,\n+\n+    // Not yet merged buffers.\n+    left_unmerged: VecDeque<DataFrame>,\n+    right_unmerged: VecDeque<DataFrame>,\n }\n \n impl MergeSortedNode {\n     pub fn new(schema: Arc<Schema>, key: PlSmallStr) -> Self {\n         assert!(schema.contains(key.as_str()));\n+        let key_column_idx = schema.index_of(key.as_str()).unwrap();\n+\n         Self {\n-            state: MergeSortedState::Sink {\n-                left: InMemorySinkNode::new(schema.clone()),\n-                right: InMemorySinkNode::new(schema),\n-            },\n-            num_pipelines: 0,\n-            key,\n+            num_pipelines: 1,\n+            key_column_idx,\n+            state: State::Merging,\n+\n+            seq: MorselSeq::default(),\n+\n+            starting_nulls: false,\n+\n+            left_unmerged: VecDeque::new(),\n+            right_unmerged: VecDeque::new(),\n         }\n     }\n }\n \n impl ComputeNode for MergeSortedNode {\n     fn name(&self) -> &str {\n-        \"in_memory_merge_sorted\"\n+        \"merge_sorted\"\n     }\n \n     fn initialize(&mut self, num_pipelines: usize) {\n         self.num_pipelines = num_pipelines;\n     }\n \n     fn update_state(&mut self, recv: &mut [PortState], send: &mut [PortState]) -> PolarsResult<()> {\n-        assert!(recv.len() == 2 && send.len() == 1);\n+        assert_eq!(send.len(), 1);\n+        assert_eq!(recv.len(), 2);\n \n         // If the output doesn't want any more data, transition to being done.\n-        if send[0] == PortState::Done && !matches!(self.state, MergeSortedState::Done) {\n-            self.state = MergeSortedState::Done;\n+        if send[0] == PortState::Done {\n+            recv[0] = PortState::Done;\n+            recv[1] = PortState::Done;\n+\n+            self.left_unmerged.clear();\n+            self.right_unmerged.clear();\n+            self.state = State::Piping;\n+\n+            return Ok(());\n         }\n \n-        // If the input is done, transition to being a source.\n-        if let MergeSortedState::Sink { left, right } = &mut self.state {\n-            if recv[0] == PortState::Done && recv[1] == PortState::Done {\n-                let left_df = left.get_output()?.unwrap();\n-                let right_df = right.get_output()?.unwrap();\n-                let left_s = left_df.column(self.key.as_str()).unwrap();\n-                let right_s = right_df.column(self.key.as_str()).unwrap();\n-                let df = _merge_sorted_dfs(\n-                    &left_df,\n-                    &right_df,\n-                    left_s.as_materialized_series(),\n-                    right_s.as_materialized_series(),\n-                    true,\n-                )?;\n-                let mut source_node = InMemorySourceNode::new(Arc::new(df), MorselSeq::default());\n-                source_node.initialize(self.num_pipelines);\n-                self.state = MergeSortedState::Source(source_node);\n+        if recv[0] == PortState::Done || recv[1] == PortState::Done {\n+            if !self.left_unmerged.is_empty() || !self.right_unmerged.is_empty() {\n+                self.state = State::Flushing;\n+            } else {\n+                self.state = State::Piping;\n             }\n+        } else {\n+            self.state = State::Merging;\n         }\n \n-        match &mut self.state {\n-            MergeSortedState::Sink { left, right, .. } => {\n-                left.update_state(&mut recv[0..1], &mut [])?;\n-                right.update_state(&mut recv[1..2], &mut [])?;\n+        match self.state {\n+            State::Merging if send[0] == PortState::Blocked => {\n+                recv[0] = PortState::Blocked;\n+                recv[1] = PortState::Blocked;\n+            },\n+\n+            // If one input side is blocked and we haven't buffered anything for that side, we\n+            // block the other ports as well.\n+            State::Merging if recv[0] == PortState::Blocked && self.left_unmerged.is_empty() => {\n                 send[0] = PortState::Blocked;\n+                recv[1] = PortState::Blocked;\n+            },\n+            State::Merging if recv[1] == PortState::Blocked && self.right_unmerged.is_empty() => {\n+                send[0] = PortState::Blocked;\n+                recv[0] = PortState::Blocked;\n+            },\n+\n+            State::Merging => {\n+                if recv[0] != PortState::Blocked {\n+                    recv[0] = PortState::Ready;\n+                }\n+                if recv[1] != PortState::Blocked {\n+                    recv[1] = PortState::Ready;\n+                }\n+                send[0] = PortState::Ready;\n             },\n-            MergeSortedState::Source(source_node) => {\n-                recv[0] = PortState::Done;\n-                recv[1] = PortState::Done;\n-                source_node.update_state(&mut [], send)?;\n+\n+            State::Flushing => {\n+                if recv[0] != PortState::Done {\n+                    recv[0] = PortState::Blocked;\n+                }\n+                if recv[1] != PortState::Done {\n+                    recv[1] = PortState::Blocked;\n+                }\n             },\n-            MergeSortedState::Done => {\n-                recv[0] = PortState::Done;\n-                recv[1] = PortState::Done;\n+\n+            State::Piping if recv[0] == PortState::Done && recv[1] == PortState::Done => {\n                 send[0] = PortState::Done;\n             },\n+            State::Piping if recv[0] == PortState::Blocked || recv[1] == PortState::Blocked => {\n+                send[0] = PortState::Blocked;\n+            },\n+            State::Piping if send[0] == PortState::Blocked => {\n+                if recv[0] != PortState::Done {\n+                    recv[0] = PortState::Blocked;\n+                }\n+                if recv[1] != PortState::Done {\n+                    recv[1] = PortState::Blocked;\n+                }\n+            },\n+            State::Piping => {\n+                if recv[0] != PortState::Done {\n+                    recv[0] = PortState::Ready;\n+                }\n+                if recv[1] != PortState::Done {\n+                    recv[1] = PortState::Ready;\n+                }\n+                send[0] = PortState::Ready;\n+            },\n         }\n-        Ok(())\n-    }\n \n-    fn is_memory_intensive_pipeline_blocker(&self) -> bool {\n-        matches!(self.state, MergeSortedState::Sink { .. })\n+        Ok(())\n     }\n \n     fn spawn<'env, 's>(\n         &'env mut self,\n         scope: &'s TaskScope<'s, 'env>,\n         recv_ports: &mut [Option<RecvPort<'_>>],\n         send_ports: &mut [Option<SendPort<'_>>],\n-        state: &'s ExecutionState,\n+        _state: &'s ExecutionState,\n         join_handles: &mut Vec<JoinHandle<PolarsResult<()>>>,\n     ) {\n-        assert!(recv_ports.len() == 2);\n-        assert!(send_ports.len() == 1);\n-        match &mut self.state {\n-            MergeSortedState::Sink { left, right, .. } => {\n-                if recv_ports[0].is_some() {\n-                    left.spawn(scope, &mut recv_ports[0..1], &mut [], state, join_handles);\n-                }\n-                if recv_ports[1].is_some() {\n-                    right.spawn(scope, &mut recv_ports[1..2], &mut [], state, join_handles);\n+        assert_eq!(recv_ports.len(), 2);\n+        assert_eq!(send_ports.len(), 1);\n+\n+        let seq = &mut self.seq;\n+        let starting_nulls = &mut self.starting_nulls;\n+        let key_column_idx = self.key_column_idx;\n+        let left_unmerged = &mut self.left_unmerged;\n+        let right_unmerged = &mut self.right_unmerged;\n+\n+        let source_token = SourceToken::new();\n+\n+        match self.state {\n+            State::Merging => {\n+                /// Request that a port stops producing [`Morsel`]s and buffer all the remaining\n+                /// [`Morsel`]s.\n+                async fn buffer_port(\n+                    port: &mut Receiver<Morsel>,\n+                    buffer: &mut VecDeque<DataFrame>,\n+                ) {\n+                    // If a stop was requested, we need to buffer the remaining\n+                    // morsels and trigger a phase transition.\n+                    let Ok(morsel) = port.recv().await else {\n+                        return;\n+                    };\n+\n+                    // Request the port stop producing morsels.\n+                    morsel.source_token().stop();\n+\n+                    // Buffer all the morsels that were already produced.\n+                    buffer.push_back(morsel.into_df());\n+                    while let Ok(morsel) = port.recv().await {\n+                        buffer.push_back(morsel.into_df());\n+                    }\n                 }\n+\n+                let send = send_ports[0].take().unwrap().parallel();\n+\n+                let (mut distributor, dist_recv) =\n+                    distributor_channel(self.num_pipelines, DEFAULT_DISTRIBUTOR_BUFFER_SIZE);\n+\n+                let mut left = recv_ports[0].take().unwrap().serial();\n+                let mut right = recv_ports[1].take().unwrap().serial();\n+\n+                let _source_token = source_token.clone();\n+                join_handles.push(scope.spawn_task(TaskPriority::Low, async move {\n+                    let mut trigger_phase_transition = false;\n+                    let source_token = _source_token;\n+\n+                    loop {\n+                        if source_token.stop_requested() {\n+                            trigger_phase_transition = true;\n+                        }\n+\n+                        // If we have morsels from both input ports, find until where we can merge\n+                        // them and send that on to be merged.\n+                        while !left_unmerged.is_empty() && !right_unmerged.is_empty() {\n+                            let mut left = left_unmerged.pop_front().unwrap();\n+                            let mut right = right_unmerged.pop_front().unwrap();\n+\n+                            // Ensure that we have some data to merge.\n+                            if left.is_empty() || right.is_empty() {\n+                                if !left.is_empty() {\n+                                    left_unmerged.push_front(left);\n+                                }\n+                                if !right.is_empty() {\n+                                    right_unmerged.push_front(right);\n+                                }\n+                                continue;\n+                            }\n+\n+                            let left_key = &left[key_column_idx];\n+                            let right_key = &right[key_column_idx];\n+\n+                            let left_null_count = left_key.null_count();\n+                            let right_null_count = right_key.null_count();\n+\n+                            let has_nulls = left_null_count > 0 || right_null_count > 0;\n+\n+                            // If we are on the first morsel we need to decide whether we have\n+                            // nulls first or not.\n+                            if seq.to_u64() == 0\n+                                && has_nulls\n+                                && (left_key.head(Some(1)).has_nulls()\n+                                    || right_key.head(Some(1)).has_nulls())\n+                            {\n+                                *starting_nulls = true;\n+                            }\n+\n+                            // For both left and right, find row index of the minimum of the maxima\n+                            // of the left and right key columns. We can safely merge until this\n+                            // point.\n+                            let mut left_cutoff = left.height();\n+                            let mut right_cutoff = right.height();\n+\n+                            let left_key_last = left_key.tail(Some(1));\n+                            let right_key_last = right_key.tail(Some(1));\n+\n+                            // We already made sure we had data to work with.\n+                            assert!(!left_key_last.is_empty());\n+                            assert!(!right_key_last.is_empty());\n+\n+                            if has_nulls {\n+                                if *starting_nulls {\n+                                    // If there are starting nulls do those first, then repeat\n+                                    // without the nulls.\n+                                    left_cutoff = left_null_count;\n+                                    right_cutoff = right_null_count;\n+                                } else {\n+                                    // If there are ending nulls then first do things without the\n+                                    // nulls and then repeat with only the nulls the nulls.\n+                                    let left_is_all_nulls = left_null_count == left.height();\n+                                    let right_is_all_nulls = right_null_count == right.height();\n+\n+                                    match (left_is_all_nulls, right_is_all_nulls) {\n+                                        (false, false) => {\n+                                            let left_nulls;\n+                                            let right_nulls;\n+                                            (left, left_nulls) = left\n+                                                .split_at((left.height() - left_null_count) as i64);\n+                                            (right, right_nulls) = right.split_at(\n+                                                (right.height() - right_null_count) as i64,\n+                                            );\n+\n+                                            left_unmerged.push_front(left_nulls);\n+                                            left_unmerged.push_front(left);\n+                                            right_unmerged.push_front(right_nulls);\n+                                            right_unmerged.push_front(right);\n+                                            continue;\n+                                        },\n+                                        (true, false) => left_cutoff = 0,\n+                                        (false, true) => right_cutoff = 0,\n+                                        (true, true) => {},\n+                                    }\n+                                }\n+                            } else if left_key_last.lt(&right_key_last)?.all() {\n+                                // @TODO: This is essentially search sorted, but that does not\n+                                // support categoricals at moment.\n+                                let gt_mask = right_key.gt(&left_key_last)?.downcast_into_array();\n+                                right_cutoff = gt_mask.values().leading_zeros();\n+                            } else if left_key_last.gt(&right_key_last)?.all() {\n+                                // @TODO: This is essentially search sorted, but that does not\n+                                // support categoricals at moment.\n+                                let gt_mask = left_key.gt(&right_key_last)?.downcast_into_array();\n+                                left_cutoff = gt_mask.values().leading_zeros();\n+                            }\n+\n+                            let left_mergeable: DataFrame;\n+                            let right_mergeable: DataFrame;\n+                            (left_mergeable, left) = left.split_at(left_cutoff as i64);\n+                            (right_mergeable, right) = right.split_at(right_cutoff as i64);\n+\n+                            if distributor\n+                                .send((*seq, left_mergeable, right_mergeable))\n+                                .await\n+                                .is_err()\n+                            {\n+                                return Ok(());\n+                            };\n+                            // The merging task might split the merged dataframe in two.\n+                            *seq = seq.successor().successor();\n+\n+                            if !left.is_empty() {\n+                                left_unmerged.push_front(left);\n+                            }\n+                            if !right.is_empty() {\n+                                right_unmerged.push_front(right);\n+                            }\n+                        }\n+\n+                        if trigger_phase_transition {\n+                            buffer_port(&mut left, left_unmerged).await;\n+                            buffer_port(&mut right, right_unmerged).await;\n+                            return Ok(());\n+                        }\n+\n+                        let (empty_port, empty_unmerged) = if left_unmerged.is_empty() {\n+                            (&mut left, &mut *left_unmerged)\n+                        } else {\n+                            (&mut right, &mut *right_unmerged)\n+                        };\n+\n+                        // Try to get a new morsel from the empty side.\n+                        let Ok(received_unmerged) = empty_port.recv().await else {\n+                            trigger_phase_transition = true;\n+                            continue;\n+                        };\n+                        empty_unmerged.push_back(received_unmerged.into_df());\n+                    }\n+                }));\n+\n+                // Task that actually merges the two dataframes. Since this merge might be very\n+                // expensive, this is split over several tasks.\n+                join_handles.extend(dist_recv.into_iter().zip(send).map(|(mut recv, mut send)| {\n+                    let source_token = source_token.clone();\n+                    let ideal_morsel_size = get_ideal_morsel_size();\n+                    scope.spawn_task(TaskPriority::High, async move {\n+                        while let Ok((seq, left, right)) = recv.recv().await {\n+                            let left_s = left[key_column_idx].as_materialized_series();\n+                            let right_s = right[key_column_idx].as_materialized_series();\n+\n+                            let merged = _merge_sorted_dfs(&left, &right, left_s, right_s, false)?;\n+\n+                            if ideal_morsel_size > 1 && merged.height() > ideal_morsel_size {\n+                                // The merged dataframe will have at most doubled in size from the\n+                                // input so we can divide by half.\n+                                let (m1, m2) = merged.split_at((merged.height() / 2) as i64);\n+\n+                                let morsel = Morsel::new(m1, seq, source_token.clone());\n+                                if send.send(morsel).await.is_err() {\n+                                    break;\n+                                }\n+                                let morsel = Morsel::new(m2, seq.successor(), source_token.clone());",
        "comment_created_at": "2025-01-30T09:39:32+00:00",
        "comment_author": "orlp",
        "comment_body": "You can just send two morsels with the same sequence ID.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1867154779",
    "pr_number": 20026,
    "pr_file": "crates/polars-ops/src/frame/join/dispatch_left_right.rs",
    "created_at": "2024-12-03T07:04:58+00:00",
    "commented_code": "s_right = s_right.rechunk();\n     }\n \n-    let ids = sort_or_hash_left(&s_left, &s_right, verbose, args.validation, args.join_nulls)?;\n+    let mut ids = sort_or_hash_left(&s_left, &s_right, verbose, args.validation, args.join_nulls)?;\n     let right = if let Some(drop_names) = drop_names {\n         right.drop_many(drop_names)\n     } else {\n         right.drop(s_right.name()).unwrap()\n     };\n+\n+    // The current sort_or_hash_left implementation preserves the Left DataFrame order so skip left for now.\n+    if args.maintain_order == MaintainOrder::Right\n+        || args.maintain_order == MaintainOrder::RightLeft\n+    {\n+        let (ref left_idx, ref right_idx) = ids;\n+        #[cfg(feature = \"chunked_ids\")]\n+        match (left_idx, right_idx) {\n+            (ChunkJoinIds::Left(left_idx), ChunkJoinOptIds::Left(right_idx)) => {\n+                ids = maintain_order_idx(left_idx.as_slice(), right_idx.as_slice(), args);\n+            },\n+            (ChunkJoinIds::Right(left_idx), ChunkJoinOptIds::Right(right_idx)) => {\n+                ids = maintain_order_chunkid(left_idx.as_slice(), right_idx.as_slice(), args);\n+            },\n+            (_, _) => unreachable!(),\n+        }\n+\n+        #[cfg(not(feature = \"chunked_ids\"))]\n+        {\n+            ids = maintain_order_idx(left_idx, right_idx, args);\n+        }\n+    }\n+\n     Ok(materialize_left_join(&left, &right, ids, args))\n }\n \n+fn maintain_order_idx(\n+    left_idx: &[IdxSize],\n+    right_idx: &[NullableIdxSize],\n+    args: &JoinArgs,\n+) -> LeftJoinIds {\n+    let left = unsafe { IdxCa::mmap_slice(\"a\".into(), left_idx) };\n+    let reference: &[IdxSize] = unsafe { std::mem::transmute(right_idx) };\n+    let right = unsafe { IdxCa::mmap_slice(\"b\".into(), reference) };\n+    let mut df =\n+        DataFrame::new(vec![left.into_series().into(), right.into_series().into()]).unwrap();\n+\n+    let options = SortMultipleOptions::new()\n+        .with_order_descending(false)\n+        .with_maintain_order(true);\n+\n+    let columns = match args.maintain_order {\n+        // If the left order is preserved then there are no unsorted right rows\n+        // So Left and LeftRight are equal\n+        MaintainOrder::Left | MaintainOrder::LeftRight => vec![\"a\"],\n+        MaintainOrder::Right => vec![\"b\"],\n+        MaintainOrder::RightLeft => vec![\"b\", \"a\"],\n+        _ => unreachable!(),\n+    };\n+\n+    df.sort_in_place(columns, options).unwrap();\n+\n+    let join_tuples_left = df\n+        .column(\"a\")\n+        .unwrap()\n+        .as_series()\n+        .unwrap()\n+        .idx()\n+        .unwrap()\n+        .cont_slice()\n+        .unwrap();\n+    let join_tuples_right = df\n+        .column(\"b\")\n+        .unwrap()\n+        .as_series()\n+        .unwrap()\n+        .idx()\n+        .unwrap()\n+        .cont_slice()\n+        .unwrap();\n+\n+    let join_tuples_right: &[NullableIdxSize] = unsafe { std::mem::transmute(join_tuples_right) };\n+\n+    to_left_join_ids(join_tuples_left.to_vec(), join_tuples_right.to_vec())",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1867154779",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 20026,
        "pr_file": "crates/polars-ops/src/frame/join/dispatch_left_right.rs",
        "discussion_id": "1867154779",
        "commented_code": "@@ -67,15 +67,100 @@ pub fn materialize_left_join_from_series(\n         s_right = s_right.rechunk();\n     }\n \n-    let ids = sort_or_hash_left(&s_left, &s_right, verbose, args.validation, args.join_nulls)?;\n+    let mut ids = sort_or_hash_left(&s_left, &s_right, verbose, args.validation, args.join_nulls)?;\n     let right = if let Some(drop_names) = drop_names {\n         right.drop_many(drop_names)\n     } else {\n         right.drop(s_right.name()).unwrap()\n     };\n+\n+    // The current sort_or_hash_left implementation preserves the Left DataFrame order so skip left for now.\n+    if args.maintain_order == MaintainOrder::Right\n+        || args.maintain_order == MaintainOrder::RightLeft\n+    {\n+        let (ref left_idx, ref right_idx) = ids;\n+        #[cfg(feature = \"chunked_ids\")]\n+        match (left_idx, right_idx) {\n+            (ChunkJoinIds::Left(left_idx), ChunkJoinOptIds::Left(right_idx)) => {\n+                ids = maintain_order_idx(left_idx.as_slice(), right_idx.as_slice(), args);\n+            },\n+            (ChunkJoinIds::Right(left_idx), ChunkJoinOptIds::Right(right_idx)) => {\n+                ids = maintain_order_chunkid(left_idx.as_slice(), right_idx.as_slice(), args);\n+            },\n+            (_, _) => unreachable!(),\n+        }\n+\n+        #[cfg(not(feature = \"chunked_ids\"))]\n+        {\n+            ids = maintain_order_idx(left_idx, right_idx, args);\n+        }\n+    }\n+\n     Ok(materialize_left_join(&left, &right, ids, args))\n }\n \n+fn maintain_order_idx(\n+    left_idx: &[IdxSize],\n+    right_idx: &[NullableIdxSize],\n+    args: &JoinArgs,\n+) -> LeftJoinIds {\n+    let left = unsafe { IdxCa::mmap_slice(\"a\".into(), left_idx) };\n+    let reference: &[IdxSize] = unsafe { std::mem::transmute(right_idx) };\n+    let right = unsafe { IdxCa::mmap_slice(\"b\".into(), reference) };\n+    let mut df =\n+        DataFrame::new(vec![left.into_series().into(), right.into_series().into()]).unwrap();\n+\n+    let options = SortMultipleOptions::new()\n+        .with_order_descending(false)\n+        .with_maintain_order(true);\n+\n+    let columns = match args.maintain_order {\n+        // If the left order is preserved then there are no unsorted right rows\n+        // So Left and LeftRight are equal\n+        MaintainOrder::Left | MaintainOrder::LeftRight => vec![\"a\"],\n+        MaintainOrder::Right => vec![\"b\"],\n+        MaintainOrder::RightLeft => vec![\"b\", \"a\"],\n+        _ => unreachable!(),\n+    };\n+\n+    df.sort_in_place(columns, options).unwrap();\n+\n+    let join_tuples_left = df\n+        .column(\"a\")\n+        .unwrap()\n+        .as_series()\n+        .unwrap()\n+        .idx()\n+        .unwrap()\n+        .cont_slice()\n+        .unwrap();\n+    let join_tuples_right = df\n+        .column(\"b\")\n+        .unwrap()\n+        .as_series()\n+        .unwrap()\n+        .idx()\n+        .unwrap()\n+        .cont_slice()\n+        .unwrap();\n+\n+    let join_tuples_right: &[NullableIdxSize] = unsafe { std::mem::transmute(join_tuples_right) };\n+\n+    to_left_join_ids(join_tuples_left.to_vec(), join_tuples_right.to_vec())",
        "comment_created_at": "2024-12-03T07:04:58+00:00",
        "comment_author": "ritchie46",
        "comment_body": "This allocates a new vec. We should be able to gather without reallocing.",
        "pr_file_module": null
      },
      {
        "comment_id": "1867465468",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 20026,
        "pr_file": "crates/polars-ops/src/frame/join/dispatch_left_right.rs",
        "discussion_id": "1867154779",
        "commented_code": "@@ -67,15 +67,100 @@ pub fn materialize_left_join_from_series(\n         s_right = s_right.rechunk();\n     }\n \n-    let ids = sort_or_hash_left(&s_left, &s_right, verbose, args.validation, args.join_nulls)?;\n+    let mut ids = sort_or_hash_left(&s_left, &s_right, verbose, args.validation, args.join_nulls)?;\n     let right = if let Some(drop_names) = drop_names {\n         right.drop_many(drop_names)\n     } else {\n         right.drop(s_right.name()).unwrap()\n     };\n+\n+    // The current sort_or_hash_left implementation preserves the Left DataFrame order so skip left for now.\n+    if args.maintain_order == MaintainOrder::Right\n+        || args.maintain_order == MaintainOrder::RightLeft\n+    {\n+        let (ref left_idx, ref right_idx) = ids;\n+        #[cfg(feature = \"chunked_ids\")]\n+        match (left_idx, right_idx) {\n+            (ChunkJoinIds::Left(left_idx), ChunkJoinOptIds::Left(right_idx)) => {\n+                ids = maintain_order_idx(left_idx.as_slice(), right_idx.as_slice(), args);\n+            },\n+            (ChunkJoinIds::Right(left_idx), ChunkJoinOptIds::Right(right_idx)) => {\n+                ids = maintain_order_chunkid(left_idx.as_slice(), right_idx.as_slice(), args);\n+            },\n+            (_, _) => unreachable!(),\n+        }\n+\n+        #[cfg(not(feature = \"chunked_ids\"))]\n+        {\n+            ids = maintain_order_idx(left_idx, right_idx, args);\n+        }\n+    }\n+\n     Ok(materialize_left_join(&left, &right, ids, args))\n }\n \n+fn maintain_order_idx(\n+    left_idx: &[IdxSize],\n+    right_idx: &[NullableIdxSize],\n+    args: &JoinArgs,\n+) -> LeftJoinIds {\n+    let left = unsafe { IdxCa::mmap_slice(\"a\".into(), left_idx) };\n+    let reference: &[IdxSize] = unsafe { std::mem::transmute(right_idx) };\n+    let right = unsafe { IdxCa::mmap_slice(\"b\".into(), reference) };\n+    let mut df =\n+        DataFrame::new(vec![left.into_series().into(), right.into_series().into()]).unwrap();\n+\n+    let options = SortMultipleOptions::new()\n+        .with_order_descending(false)\n+        .with_maintain_order(true);\n+\n+    let columns = match args.maintain_order {\n+        // If the left order is preserved then there are no unsorted right rows\n+        // So Left and LeftRight are equal\n+        MaintainOrder::Left | MaintainOrder::LeftRight => vec![\"a\"],\n+        MaintainOrder::Right => vec![\"b\"],\n+        MaintainOrder::RightLeft => vec![\"b\", \"a\"],\n+        _ => unreachable!(),\n+    };\n+\n+    df.sort_in_place(columns, options).unwrap();\n+\n+    let join_tuples_left = df\n+        .column(\"a\")\n+        .unwrap()\n+        .as_series()\n+        .unwrap()\n+        .idx()\n+        .unwrap()\n+        .cont_slice()\n+        .unwrap();\n+    let join_tuples_right = df\n+        .column(\"b\")\n+        .unwrap()\n+        .as_series()\n+        .unwrap()\n+        .idx()\n+        .unwrap()\n+        .cont_slice()\n+        .unwrap();\n+\n+    let join_tuples_right: &[NullableIdxSize] = unsafe { std::mem::transmute(join_tuples_right) };\n+\n+    to_left_join_ids(join_tuples_left.to_vec(), join_tuples_right.to_vec())",
        "comment_created_at": "2024-12-03T10:34:22+00:00",
        "comment_author": "stijnherfst",
        "comment_body": "I was able to remove the copy by restructuring everything. I did notice there is a case (`test_chunked_gather_phys_repr_17446`) where the left IDs are [IdxSize] and the right IDs [ChunkId]. Is arbitrary mixing of ChunkIDs and non ChunkIDs normal and does it need to be supported or is this a bug/undesiredness?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1957068369",
    "pr_number": 21266,
    "pr_file": "crates/polars-plan/src/dsl/function_expr/index_of.rs",
    "created_at": "2025-02-15T08:29:51+00:00",
    "commented_code": "// If the Series is sorted, we can use an optimized binary search to\n         // find the value.\n         IsSorted::Ascending | IsSorted::Descending\n-            if !needle.is_null() &&\n-            // search_sorted() doesn't support decimals at the moment.\n-            !series.dtype().is_decimal() =>\n+            if !(needle.is_null()\n+                 // search_sorted() doesn't support these types at the moment:",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1957068369",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 21266,
        "pr_file": "crates/polars-plan/src/dsl/function_expr/index_of.rs",
        "discussion_id": "1957068369",
        "commented_code": "@@ -28,9 +28,11 @@ pub(super) fn index_of(s: &mut [Column]) -> PolarsResult<Column> {\n         // If the Series is sorted, we can use an optimized binary search to\n         // find the value.\n         IsSorted::Ascending | IsSorted::Descending\n-            if !needle.is_null() &&\n-            // search_sorted() doesn't support decimals at the moment.\n-            !series.dtype().is_decimal() =>\n+            if !(needle.is_null()\n+                 // search_sorted() doesn't support these types at the moment:",
        "comment_created_at": "2025-02-15T08:29:51+00:00",
        "comment_author": "ritchie46",
        "comment_body": "I think this should be supported. For decimals we should extract the `Int128` in both the haystack and the needle. \r\n\r\nAnd for the nested types we should convert both to the row-encoding.",
        "pr_file_module": null
      },
      {
        "comment_id": "1959760821",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 21266,
        "pr_file": "crates/polars-plan/src/dsl/function_expr/index_of.rs",
        "discussion_id": "1957068369",
        "commented_code": "@@ -28,9 +28,11 @@ pub(super) fn index_of(s: &mut [Column]) -> PolarsResult<Column> {\n         // If the Series is sorted, we can use an optimized binary search to\n         // find the value.\n         IsSorted::Ascending | IsSorted::Descending\n-            if !needle.is_null() &&\n-            // search_sorted() doesn't support decimals at the moment.\n-            !series.dtype().is_decimal() =>\n+            if !(needle.is_null()\n+                 // search_sorted() doesn't support these types at the moment:",
        "comment_created_at": "2025-02-18T13:35:13+00:00",
        "comment_author": "itamarst",
        "comment_body": "I can get that to that in a couple of weeks, hopefully. Could still merge this issue as a short-term workaround for `index_of()`, or just close it.",
        "pr_file_module": null
      },
      {
        "comment_id": "1977765206",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 21266,
        "pr_file": "crates/polars-plan/src/dsl/function_expr/index_of.rs",
        "discussion_id": "1957068369",
        "commented_code": "@@ -28,9 +28,11 @@ pub(super) fn index_of(s: &mut [Column]) -> PolarsResult<Column> {\n         // If the Series is sorted, we can use an optimized binary search to\n         // find the value.\n         IsSorted::Ascending | IsSorted::Descending\n-            if !needle.is_null() &&\n-            // search_sorted() doesn't support decimals at the moment.\n-            !series.dtype().is_decimal() =>\n+            if !(needle.is_null()\n+                 // search_sorted() doesn't support these types at the moment:",
        "comment_created_at": "2025-03-03T15:56:31+00:00",
        "comment_author": "itamarst",
        "comment_body": "I have added list and array support to `search_sorted`, to the extent possible. Decimals apparently work? So not search why that was disabled in `index_of`.",
        "pr_file_module": null
      }
    ]
  }
]