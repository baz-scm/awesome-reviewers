[
  {
    "discussion_id": "2098048792",
    "pr_number": 22840,
    "pr_file": "py-polars/tests/unit/operations/namespaces/test_binary.py",
    "created_at": "2025-05-20T13:58:19+00:00",
    "commented_code": "assert_frame_equal(result, expected_df)\n \n \n+@pytest.mark.parametrize(\n+    (\"dtype\", \"inner_type_size\", \"struct_type\"),\n+    [\n+        (pl.Array(pl.Int8, 3), 1, \"b\"),\n+        (pl.Array(pl.UInt8, 3), 1, \"B\"),\n+        (pl.Array(pl.UInt8, (3, 4, 5)), 1, \"B\"),\n+        (pl.Array(pl.Int16, 3), 2, \"h\"),\n+        (pl.Array(pl.UInt16, 3), 2, \"H\"),\n+        (pl.Array(pl.Int32, 3), 4, \"i\"),\n+        (pl.Array(pl.UInt32, 3), 4, \"I\"),\n+        (pl.Array(pl.Int64, 3), 8, \"q\"),\n+        (pl.Array(pl.UInt64, 3), 8, \"Q\"),\n+        (pl.Array(pl.Float32, 3), 4, \"f\"),\n+        (pl.Array(pl.Float64, 3), 8, \"d\"),\n+    ],\n+)\n+def test_reinterpret_list(\n+    dtype: pl.Array,\n+    inner_type_size: int,\n+    struct_type: str,\n+) -> None:\n+    # Make test reproducible\n+    random.seed(42)\n+\n+    type_size = inner_type_size\n+    shape = dtype.shape\n+    if isinstance(shape, int):\n+        shape = (shape,)\n+    for dim_size in dtype.shape:\n+        type_size *= dim_size\n+\n+    byte_arr = [random.randbytes(type_size) for _ in range(3)]",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "2098048792",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 22840,
        "pr_file": "py-polars/tests/unit/operations/namespaces/test_binary.py",
        "discussion_id": "2098048792",
        "commented_code": "@@ -210,6 +211,64 @@ def test_reinterpret(\n         assert_frame_equal(result, expected_df)\n \n \n+@pytest.mark.parametrize(\n+    (\"dtype\", \"inner_type_size\", \"struct_type\"),\n+    [\n+        (pl.Array(pl.Int8, 3), 1, \"b\"),\n+        (pl.Array(pl.UInt8, 3), 1, \"B\"),\n+        (pl.Array(pl.UInt8, (3, 4, 5)), 1, \"B\"),\n+        (pl.Array(pl.Int16, 3), 2, \"h\"),\n+        (pl.Array(pl.UInt16, 3), 2, \"H\"),\n+        (pl.Array(pl.Int32, 3), 4, \"i\"),\n+        (pl.Array(pl.UInt32, 3), 4, \"I\"),\n+        (pl.Array(pl.Int64, 3), 8, \"q\"),\n+        (pl.Array(pl.UInt64, 3), 8, \"Q\"),\n+        (pl.Array(pl.Float32, 3), 4, \"f\"),\n+        (pl.Array(pl.Float64, 3), 8, \"d\"),\n+    ],\n+)\n+def test_reinterpret_list(\n+    dtype: pl.Array,\n+    inner_type_size: int,\n+    struct_type: str,\n+) -> None:\n+    # Make test reproducible\n+    random.seed(42)\n+\n+    type_size = inner_type_size\n+    shape = dtype.shape\n+    if isinstance(shape, int):\n+        shape = (shape,)\n+    for dim_size in dtype.shape:\n+        type_size *= dim_size\n+\n+    byte_arr = [random.randbytes(type_size) for _ in range(3)]",
        "comment_created_at": "2025-05-20T13:58:19+00:00",
        "comment_author": "itamarst",
        "comment_body": "What happens if byte strings are different lengths?",
        "pr_file_module": null
      },
      {
        "comment_id": "2098055613",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 22840,
        "pr_file": "py-polars/tests/unit/operations/namespaces/test_binary.py",
        "discussion_id": "2098048792",
        "commented_code": "@@ -210,6 +211,64 @@ def test_reinterpret(\n         assert_frame_equal(result, expected_df)\n \n \n+@pytest.mark.parametrize(\n+    (\"dtype\", \"inner_type_size\", \"struct_type\"),\n+    [\n+        (pl.Array(pl.Int8, 3), 1, \"b\"),\n+        (pl.Array(pl.UInt8, 3), 1, \"B\"),\n+        (pl.Array(pl.UInt8, (3, 4, 5)), 1, \"B\"),\n+        (pl.Array(pl.Int16, 3), 2, \"h\"),\n+        (pl.Array(pl.UInt16, 3), 2, \"H\"),\n+        (pl.Array(pl.Int32, 3), 4, \"i\"),\n+        (pl.Array(pl.UInt32, 3), 4, \"I\"),\n+        (pl.Array(pl.Int64, 3), 8, \"q\"),\n+        (pl.Array(pl.UInt64, 3), 8, \"Q\"),\n+        (pl.Array(pl.Float32, 3), 4, \"f\"),\n+        (pl.Array(pl.Float64, 3), 8, \"d\"),\n+    ],\n+)\n+def test_reinterpret_list(\n+    dtype: pl.Array,\n+    inner_type_size: int,\n+    struct_type: str,\n+) -> None:\n+    # Make test reproducible\n+    random.seed(42)\n+\n+    type_size = inner_type_size\n+    shape = dtype.shape\n+    if isinstance(shape, int):\n+        shape = (shape,)\n+    for dim_size in dtype.shape:\n+        type_size *= dim_size\n+\n+    byte_arr = [random.randbytes(type_size) for _ in range(3)]",
        "comment_created_at": "2025-05-20T14:00:12+00:00",
        "comment_author": "itamarst",
        "comment_body": "As far as _desirable_ behavior:\r\n\r\n1. Pad with nulls (only applicable to too-short).\r\n2. Replace with null.\r\n3. Error out completely.\r\n\r\nOne imagines it might be desirable to have different behavior for too-short and too-long.",
        "pr_file_module": null
      },
      {
        "comment_id": "2098272776",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 22840,
        "pr_file": "py-polars/tests/unit/operations/namespaces/test_binary.py",
        "discussion_id": "2098048792",
        "commented_code": "@@ -210,6 +211,64 @@ def test_reinterpret(\n         assert_frame_equal(result, expected_df)\n \n \n+@pytest.mark.parametrize(\n+    (\"dtype\", \"inner_type_size\", \"struct_type\"),\n+    [\n+        (pl.Array(pl.Int8, 3), 1, \"b\"),\n+        (pl.Array(pl.UInt8, 3), 1, \"B\"),\n+        (pl.Array(pl.UInt8, (3, 4, 5)), 1, \"B\"),\n+        (pl.Array(pl.Int16, 3), 2, \"h\"),\n+        (pl.Array(pl.UInt16, 3), 2, \"H\"),\n+        (pl.Array(pl.Int32, 3), 4, \"i\"),\n+        (pl.Array(pl.UInt32, 3), 4, \"I\"),\n+        (pl.Array(pl.Int64, 3), 8, \"q\"),\n+        (pl.Array(pl.UInt64, 3), 8, \"Q\"),\n+        (pl.Array(pl.Float32, 3), 4, \"f\"),\n+        (pl.Array(pl.Float64, 3), 8, \"d\"),\n+    ],\n+)\n+def test_reinterpret_list(\n+    dtype: pl.Array,\n+    inner_type_size: int,\n+    struct_type: str,\n+) -> None:\n+    # Make test reproducible\n+    random.seed(42)\n+\n+    type_size = inner_type_size\n+    shape = dtype.shape\n+    if isinstance(shape, int):\n+        shape = (shape,)\n+    for dim_size in dtype.shape:\n+        type_size *= dim_size\n+\n+    byte_arr = [random.randbytes(type_size) for _ in range(3)]",
        "comment_created_at": "2025-05-20T15:26:37+00:00",
        "comment_author": "itamarst",
        "comment_body": "Looks like behavior for primitive dtypes is null if too short, and null if too long.\r\n\r\n1. Docstring for `Series` `reinterpret` is wrong, it says extra data will be ignored but actually you get `null`. I think actual behavior of `null` makes more sense, something is _wrong_ you shouldn't silently hide it. Which means I should update the docstring too.\r\n2. Will probably emulate that for Array: if insufficient data for array of correct length, or too much!, replace with `null` instead of `Array`.\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2098482397",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 22840,
        "pr_file": "py-polars/tests/unit/operations/namespaces/test_binary.py",
        "discussion_id": "2098048792",
        "commented_code": "@@ -210,6 +211,64 @@ def test_reinterpret(\n         assert_frame_equal(result, expected_df)\n \n \n+@pytest.mark.parametrize(\n+    (\"dtype\", \"inner_type_size\", \"struct_type\"),\n+    [\n+        (pl.Array(pl.Int8, 3), 1, \"b\"),\n+        (pl.Array(pl.UInt8, 3), 1, \"B\"),\n+        (pl.Array(pl.UInt8, (3, 4, 5)), 1, \"B\"),\n+        (pl.Array(pl.Int16, 3), 2, \"h\"),\n+        (pl.Array(pl.UInt16, 3), 2, \"H\"),\n+        (pl.Array(pl.Int32, 3), 4, \"i\"),\n+        (pl.Array(pl.UInt32, 3), 4, \"I\"),\n+        (pl.Array(pl.Int64, 3), 8, \"q\"),\n+        (pl.Array(pl.UInt64, 3), 8, \"Q\"),\n+        (pl.Array(pl.Float32, 3), 4, \"f\"),\n+        (pl.Array(pl.Float64, 3), 8, \"d\"),\n+    ],\n+)\n+def test_reinterpret_list(\n+    dtype: pl.Array,\n+    inner_type_size: int,\n+    struct_type: str,\n+) -> None:\n+    # Make test reproducible\n+    random.seed(42)\n+\n+    type_size = inner_type_size\n+    shape = dtype.shape\n+    if isinstance(shape, int):\n+        shape = (shape,)\n+    for dim_size in dtype.shape:\n+        type_size *= dim_size\n+\n+    byte_arr = [random.randbytes(type_size) for _ in range(3)]",
        "comment_created_at": "2025-05-20T17:10:03+00:00",
        "comment_author": "itamarst",
        "comment_body": "This is blocked by the reshaping logic, which doesn't do what we want with nulls.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2125832883",
    "pr_number": 22840,
    "pr_file": "py-polars/polars/series/binary.py",
    "created_at": "2025-06-04T07:02:04+00:00",
    "commented_code": "-------\n         Series\n             Series of data type `dtype`.\n-            Note that if binary array is too short value will be null.\n-            If binary array is too long, remainder will be ignored.\n+            Note that if the binary array is too short or too long, the resulting",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "2125832883",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 22840,
        "pr_file": "py-polars/polars/series/binary.py",
        "discussion_id": "2125832883",
        "commented_code": "@@ -233,8 +233,8 @@ def reinterpret(\n         -------\n         Series\n             Series of data type `dtype`.\n-            Note that if binary array is too short value will be null.\n-            If binary array is too long, remainder will be ignored.\n+            Note that if the binary array is too short or too long, the resulting",
        "comment_created_at": "2025-06-04T07:02:04+00:00",
        "comment_author": "nameexhaustion",
        "comment_body": "```suggestion\r\n            Note that rows of the binary array where the length does not match the width of the output array will become NULL.\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2126311454",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 22840,
        "pr_file": "py-polars/polars/series/binary.py",
        "discussion_id": "2125832883",
        "commented_code": "@@ -233,8 +233,8 @@ def reinterpret(\n         -------\n         Series\n             Series of data type `dtype`.\n-            Note that if binary array is too short value will be null.\n-            If binary array is too long, remainder will be ignored.\n+            Note that if the binary array is too short or too long, the resulting",
        "comment_created_at": "2025-06-04T10:57:12+00:00",
        "comment_author": "nameexhaustion",
        "comment_body": "Please also document that when reinterpreting to `Array`s, it is not allowed to reinterpret to more than 1 nesting level and recommend to instead `reshape()` separately afterwards.\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1646325022",
    "pr_number": 17003,
    "pr_file": "py-polars/polars/expr/expr.py",
    "created_at": "2024-06-19T14:39:42+00:00",
    "commented_code": "def eq_missing(self, other: Any) -> Self:\n         \"\"\"\n-        Method equivalent of equality operator `expr == other` where `None == None`.\n+        Equality operator where `None` is treated as a distinct value.",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1646325022",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 17003,
        "pr_file": "py-polars/polars/expr/expr.py",
        "discussion_id": "1646325022",
        "commented_code": "@@ -5005,9 +5005,11 @@ def eq(self, other: Any) -> Self:\n \n     def eq_missing(self, other: Any) -> Self:\n         \"\"\"\n-        Method equivalent of equality operator `expr == other` where `None == None`.\n+        Equality operator where `None` is treated as a distinct value.",
        "comment_created_at": "2024-06-19T14:39:42+00:00",
        "comment_author": "stinodego",
        "comment_body": "We should be talking about nulls instead of `None` in this context.\r\n\r\n```suggestion\r\n        Equality operator where null is treated as a distinct value.\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1646397463",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 17003,
        "pr_file": "py-polars/polars/expr/expr.py",
        "discussion_id": "1646325022",
        "commented_code": "@@ -5005,9 +5005,11 @@ def eq(self, other: Any) -> Self:\n \n     def eq_missing(self, other: Any) -> Self:\n         \"\"\"\n-        Method equivalent of equality operator `expr == other` where `None == None`.\n+        Equality operator where `None` is treated as a distinct value.",
        "comment_created_at": "2024-06-19T15:29:38+00:00",
        "comment_author": "bertiewooster",
        "comment_body": "Fair point. I searched the docs and they largely follow the convention of using \"null\" when discussing values in the dataframe. Probably `None` was used initially because that's how you assign a value of null from Python, so I can imagine Python users who read pages needing some thought to realize how null arises.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1646327563",
    "pr_number": 17003,
    "pr_file": "py-polars/polars/expr/expr.py",
    "created_at": "2024-06-19T14:40:57+00:00",
    "commented_code": "def eq_missing(self, other: Any) -> Self:\n         \"\"\"\n-        Method equivalent of equality operator `expr == other` where `None == None`.\n+        Equality operator where `None` is treated as a distinct value.\n \n         This differs from default `eq` where null values are propagated.\n+        With this method, `None == None` returns `True` instead of `None`,\n+        and `x == None` returns `False` instead of `None` where `x` is not `None`.",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1646327563",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 17003,
        "pr_file": "py-polars/polars/expr/expr.py",
        "discussion_id": "1646327563",
        "commented_code": "@@ -5005,9 +5005,11 @@ def eq(self, other: Any) -> Self:\n \n     def eq_missing(self, other: Any) -> Self:\n         \"\"\"\n-        Method equivalent of equality operator `expr == other` where `None == None`.\n+        Equality operator where `None` is treated as a distinct value.\n \n         This differs from default `eq` where null values are propagated.\n+        With this method, `None == None` returns `True` instead of `None`,\n+        and `x == None` returns `False` instead of `None` where `x` is not `None`.",
        "comment_created_at": "2024-06-19T14:40:57+00:00",
        "comment_author": "stinodego",
        "comment_body": "This is honestly not really clear for me.",
        "pr_file_module": null
      },
      {
        "comment_id": "1646334300",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 17003,
        "pr_file": "py-polars/polars/expr/expr.py",
        "discussion_id": "1646327563",
        "commented_code": "@@ -5005,9 +5005,11 @@ def eq(self, other: Any) -> Self:\n \n     def eq_missing(self, other: Any) -> Self:\n         \"\"\"\n-        Method equivalent of equality operator `expr == other` where `None == None`.\n+        Equality operator where `None` is treated as a distinct value.\n \n         This differs from default `eq` where null values are propagated.\n+        With this method, `None == None` returns `True` instead of `None`,\n+        and `x == None` returns `False` instead of `None` where `x` is not `None`.",
        "comment_created_at": "2024-06-19T14:46:00+00:00",
        "comment_author": "mcrumiller",
        "comment_body": "I also don't think the example should be using the `==` sign since that is an explicit operator for the `eq` method. How about:\r\n\r\n> Equality operator where null is treated as a distinct value.\r\n>\r\n> With this method, null is equal to null and is not equal to any other value.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2139915509",
    "pr_number": 23143,
    "pr_file": "py-polars/polars/expr/expr.py",
    "created_at": "2025-06-11T11:38:10+00:00",
    "commented_code": "Parameters\n         ----------\n         ignore_nulls\n-            Ignore null values (default).\n \n-            If set to `False`, `Kleene logic`_ is used to deal with nulls:\n-            if the column contains any null values and no `True` values,\n-            the output is null.\n+            * If set to `True` (default), null values are ignored. If there\n+              are no non-null values, the output is `False`.",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "2139915509",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 23143,
        "pr_file": "py-polars/polars/expr/expr.py",
        "discussion_id": "2139915509",
        "commented_code": "@@ -475,11 +475,12 @@ def any(self, *, ignore_nulls: bool = True) -> Expr:\n         Parameters\n         ----------\n         ignore_nulls\n-            Ignore null values (default).\n \n-            If set to `False`, `Kleene logic`_ is used to deal with nulls:\n-            if the column contains any null values and no `True` values,\n-            the output is null.\n+            * If set to `True` (default), null values are ignored. If there\n+              are no non-null values, the output is `False`.",
        "comment_created_at": "2025-06-11T11:38:10+00:00",
        "comment_author": "gdementen",
        "comment_body": "I would personally find that sentence slightly easier to understand without the double negation, even if that means a longer sentence. For example:\r\n\r\n> If there are only null values or no values at all, the output is `False`.\r\n\r\nThe same comment applies to most of the other changes in this commit.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1898321439",
    "pr_number": 20469,
    "pr_file": "py-polars/tests/unit/operations/aggregation/test_horizontal.py",
    "created_at": "2024-12-27T07:23:05+00:00",
    "commented_code": ")\n \n     assert_frame_equal(out.collect(), expected_df)\n+\n+\n+@pytest.mark.parametrize(\"ignore_nulls\", [True, False])\n+@pytest.mark.parametrize(\n+    (\"dtype_in\", \"dtype_out\"),\n+    [\n+        (pl.Null, pl.Null),\n+        (pl.Boolean, pl.UInt32),\n+        (pl.UInt8, pl.UInt8),\n+        (pl.Float32, pl.Float32),\n+        (pl.Float64, pl.Float64),\n+        (pl.Decimal(None, 5), pl.Decimal(None, 5)),\n+    ],\n+)\n+def test_horizontal_sum_with_null_col_ignore_strategy(\n+    dtype_in: PolarsDataType,\n+    dtype_out: PolarsDataType,\n+    ignore_nulls: bool,\n+) -> None:\n+    lf = pl.LazyFrame(\n+        {\n+            \"null\": [None, None, None],\n+            \"s\": pl.Series([1, 0, 1], dtype=dtype_in, strict=False),\n+            \"s2\": pl.Series([1, 0, None], dtype=dtype_in, strict=False),\n+        }\n+    )\n+    result = lf.select(pl.sum_horizontal(\"null\", \"s\", \"s2\", ignore_nulls=ignore_nulls))\n+    if ignore_nulls and dtype_in != pl.Null:\n+        values = [2, 0, 1]\n+    else:\n+        values = [None, None, None]  # type: ignore[list-item]",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1898321439",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 20469,
        "pr_file": "py-polars/tests/unit/operations/aggregation/test_horizontal.py",
        "discussion_id": "1898321439",
        "commented_code": "@@ -556,3 +556,68 @@ def test_horizontal_sum_boolean_with_null() -> None:\n     )\n \n     assert_frame_equal(out.collect(), expected_df)\n+\n+\n+@pytest.mark.parametrize(\"ignore_nulls\", [True, False])\n+@pytest.mark.parametrize(\n+    (\"dtype_in\", \"dtype_out\"),\n+    [\n+        (pl.Null, pl.Null),\n+        (pl.Boolean, pl.UInt32),\n+        (pl.UInt8, pl.UInt8),\n+        (pl.Float32, pl.Float32),\n+        (pl.Float64, pl.Float64),\n+        (pl.Decimal(None, 5), pl.Decimal(None, 5)),\n+    ],\n+)\n+def test_horizontal_sum_with_null_col_ignore_strategy(\n+    dtype_in: PolarsDataType,\n+    dtype_out: PolarsDataType,\n+    ignore_nulls: bool,\n+) -> None:\n+    lf = pl.LazyFrame(\n+        {\n+            \"null\": [None, None, None],\n+            \"s\": pl.Series([1, 0, 1], dtype=dtype_in, strict=False),\n+            \"s2\": pl.Series([1, 0, None], dtype=dtype_in, strict=False),\n+        }\n+    )\n+    result = lf.select(pl.sum_horizontal(\"null\", \"s\", \"s2\", ignore_nulls=ignore_nulls))\n+    if ignore_nulls and dtype_in != pl.Null:\n+        values = [2, 0, 1]\n+    else:\n+        values = [None, None, None]  # type: ignore[list-item]",
        "comment_created_at": "2024-12-27T07:23:05+00:00",
        "comment_author": "ritchie46",
        "comment_body": "This is wrong. If our sum doesn't ignore nulls, it doesn't propagate them, but replaces them with the identity: 0.\r\n\r\nThe horizontal semantics should be the same as the vertical semantics.",
        "pr_file_module": null
      },
      {
        "comment_id": "1898462538",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 20469,
        "pr_file": "py-polars/tests/unit/operations/aggregation/test_horizontal.py",
        "discussion_id": "1898321439",
        "commented_code": "@@ -556,3 +556,68 @@ def test_horizontal_sum_boolean_with_null() -> None:\n     )\n \n     assert_frame_equal(out.collect(), expected_df)\n+\n+\n+@pytest.mark.parametrize(\"ignore_nulls\", [True, False])\n+@pytest.mark.parametrize(\n+    (\"dtype_in\", \"dtype_out\"),\n+    [\n+        (pl.Null, pl.Null),\n+        (pl.Boolean, pl.UInt32),\n+        (pl.UInt8, pl.UInt8),\n+        (pl.Float32, pl.Float32),\n+        (pl.Float64, pl.Float64),\n+        (pl.Decimal(None, 5), pl.Decimal(None, 5)),\n+    ],\n+)\n+def test_horizontal_sum_with_null_col_ignore_strategy(\n+    dtype_in: PolarsDataType,\n+    dtype_out: PolarsDataType,\n+    ignore_nulls: bool,\n+) -> None:\n+    lf = pl.LazyFrame(\n+        {\n+            \"null\": [None, None, None],\n+            \"s\": pl.Series([1, 0, 1], dtype=dtype_in, strict=False),\n+            \"s2\": pl.Series([1, 0, None], dtype=dtype_in, strict=False),\n+        }\n+    )\n+    result = lf.select(pl.sum_horizontal(\"null\", \"s\", \"s2\", ignore_nulls=ignore_nulls))\n+    if ignore_nulls and dtype_in != pl.Null:\n+        values = [2, 0, 1]\n+    else:\n+        values = [None, None, None]  # type: ignore[list-item]",
        "comment_created_at": "2024-12-27T11:39:30+00:00",
        "comment_author": "mcrumiller",
        "comment_body": "I think you have it reversed.\n\n* Ignore nulls: 1 + 2 + null = 3 (nulls replaced by 0)\n* Don't ignore nulls: 1 + 2 + null = null (nulls are propagated)",
        "pr_file_module": null
      },
      {
        "comment_id": "1898483157",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 20469,
        "pr_file": "py-polars/tests/unit/operations/aggregation/test_horizontal.py",
        "discussion_id": "1898321439",
        "commented_code": "@@ -556,3 +556,68 @@ def test_horizontal_sum_boolean_with_null() -> None:\n     )\n \n     assert_frame_equal(out.collect(), expected_df)\n+\n+\n+@pytest.mark.parametrize(\"ignore_nulls\", [True, False])\n+@pytest.mark.parametrize(\n+    (\"dtype_in\", \"dtype_out\"),\n+    [\n+        (pl.Null, pl.Null),\n+        (pl.Boolean, pl.UInt32),\n+        (pl.UInt8, pl.UInt8),\n+        (pl.Float32, pl.Float32),\n+        (pl.Float64, pl.Float64),\n+        (pl.Decimal(None, 5), pl.Decimal(None, 5)),\n+    ],\n+)\n+def test_horizontal_sum_with_null_col_ignore_strategy(\n+    dtype_in: PolarsDataType,\n+    dtype_out: PolarsDataType,\n+    ignore_nulls: bool,\n+) -> None:\n+    lf = pl.LazyFrame(\n+        {\n+            \"null\": [None, None, None],\n+            \"s\": pl.Series([1, 0, 1], dtype=dtype_in, strict=False),\n+            \"s2\": pl.Series([1, 0, None], dtype=dtype_in, strict=False),\n+        }\n+    )\n+    result = lf.select(pl.sum_horizontal(\"null\", \"s\", \"s2\", ignore_nulls=ignore_nulls))\n+    if ignore_nulls and dtype_in != pl.Null:\n+        values = [2, 0, 1]\n+    else:\n+        values = [None, None, None]  # type: ignore[list-item]",
        "comment_created_at": "2024-12-27T12:25:36+00:00",
        "comment_author": "ritchie46",
        "comment_body": "I mean that our `sum` is agnostic to nulls. I think we made a mistake exposing this to `sum_horizontal` as our vertical sum is agnostic to nulls.",
        "pr_file_module": null
      },
      {
        "comment_id": "1898497422",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 20469,
        "pr_file": "py-polars/tests/unit/operations/aggregation/test_horizontal.py",
        "discussion_id": "1898321439",
        "commented_code": "@@ -556,3 +556,68 @@ def test_horizontal_sum_boolean_with_null() -> None:\n     )\n \n     assert_frame_equal(out.collect(), expected_df)\n+\n+\n+@pytest.mark.parametrize(\"ignore_nulls\", [True, False])\n+@pytest.mark.parametrize(\n+    (\"dtype_in\", \"dtype_out\"),\n+    [\n+        (pl.Null, pl.Null),\n+        (pl.Boolean, pl.UInt32),\n+        (pl.UInt8, pl.UInt8),\n+        (pl.Float32, pl.Float32),\n+        (pl.Float64, pl.Float64),\n+        (pl.Decimal(None, 5), pl.Decimal(None, 5)),\n+    ],\n+)\n+def test_horizontal_sum_with_null_col_ignore_strategy(\n+    dtype_in: PolarsDataType,\n+    dtype_out: PolarsDataType,\n+    ignore_nulls: bool,\n+) -> None:\n+    lf = pl.LazyFrame(\n+        {\n+            \"null\": [None, None, None],\n+            \"s\": pl.Series([1, 0, 1], dtype=dtype_in, strict=False),\n+            \"s2\": pl.Series([1, 0, None], dtype=dtype_in, strict=False),\n+        }\n+    )\n+    result = lf.select(pl.sum_horizontal(\"null\", \"s\", \"s2\", ignore_nulls=ignore_nulls))\n+    if ignore_nulls and dtype_in != pl.Null:\n+        values = [2, 0, 1]\n+    else:\n+        values = [None, None, None]  # type: ignore[list-item]",
        "comment_created_at": "2024-12-27T12:56:52+00:00",
        "comment_author": "mcrumiller",
        "comment_body": "I think what you're saying is that the `ignore_nulls` parameter should be removed entirely, and the `ignore_nulls=True` behavior should simply be the default. Is that correct? If so, that sounds like a breaking change.\r\n\r\nGiven that the current implementation has the parameter, and that there is an issue with it (`pl.Null` columns are not subject to the parameter, but nulls in other columns are), is the path forward to accept this PR (if I didn't mess anything up! which I don't think I did), and 2) remove the parameter in a follow-up PR to be merged in 1.19.0?\r\n\r\nThis PR contains a small fix for the float32 case where `mean_horizontal` returns f64 for f32 columns. I could make that a separate PR as well if you don't want to accept this one.",
        "pr_file_module": null
      },
      {
        "comment_id": "1898586065",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 20469,
        "pr_file": "py-polars/tests/unit/operations/aggregation/test_horizontal.py",
        "discussion_id": "1898321439",
        "commented_code": "@@ -556,3 +556,68 @@ def test_horizontal_sum_boolean_with_null() -> None:\n     )\n \n     assert_frame_equal(out.collect(), expected_df)\n+\n+\n+@pytest.mark.parametrize(\"ignore_nulls\", [True, False])\n+@pytest.mark.parametrize(\n+    (\"dtype_in\", \"dtype_out\"),\n+    [\n+        (pl.Null, pl.Null),\n+        (pl.Boolean, pl.UInt32),\n+        (pl.UInt8, pl.UInt8),\n+        (pl.Float32, pl.Float32),\n+        (pl.Float64, pl.Float64),\n+        (pl.Decimal(None, 5), pl.Decimal(None, 5)),\n+    ],\n+)\n+def test_horizontal_sum_with_null_col_ignore_strategy(\n+    dtype_in: PolarsDataType,\n+    dtype_out: PolarsDataType,\n+    ignore_nulls: bool,\n+) -> None:\n+    lf = pl.LazyFrame(\n+        {\n+            \"null\": [None, None, None],\n+            \"s\": pl.Series([1, 0, 1], dtype=dtype_in, strict=False),\n+            \"s2\": pl.Series([1, 0, None], dtype=dtype_in, strict=False),\n+        }\n+    )\n+    result = lf.select(pl.sum_horizontal(\"null\", \"s\", \"s2\", ignore_nulls=ignore_nulls))\n+    if ignore_nulls and dtype_in != pl.Null:\n+        values = [2, 0, 1]\n+    else:\n+        values = [None, None, None]  # type: ignore[list-item]",
        "comment_created_at": "2024-12-27T15:38:03+00:00",
        "comment_author": "ritchie46",
        "comment_body": "Yeah, I think you're right. Consider it an observation. ;) Will take a look a bit later. ",
        "pr_file_module": null
      },
      {
        "comment_id": "1899150185",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 20469,
        "pr_file": "py-polars/tests/unit/operations/aggregation/test_horizontal.py",
        "discussion_id": "1898321439",
        "commented_code": "@@ -556,3 +556,68 @@ def test_horizontal_sum_boolean_with_null() -> None:\n     )\n \n     assert_frame_equal(out.collect(), expected_df)\n+\n+\n+@pytest.mark.parametrize(\"ignore_nulls\", [True, False])\n+@pytest.mark.parametrize(\n+    (\"dtype_in\", \"dtype_out\"),\n+    [\n+        (pl.Null, pl.Null),\n+        (pl.Boolean, pl.UInt32),\n+        (pl.UInt8, pl.UInt8),\n+        (pl.Float32, pl.Float32),\n+        (pl.Float64, pl.Float64),\n+        (pl.Decimal(None, 5), pl.Decimal(None, 5)),\n+    ],\n+)\n+def test_horizontal_sum_with_null_col_ignore_strategy(\n+    dtype_in: PolarsDataType,\n+    dtype_out: PolarsDataType,\n+    ignore_nulls: bool,\n+) -> None:\n+    lf = pl.LazyFrame(\n+        {\n+            \"null\": [None, None, None],\n+            \"s\": pl.Series([1, 0, 1], dtype=dtype_in, strict=False),\n+            \"s2\": pl.Series([1, 0, None], dtype=dtype_in, strict=False),\n+        }\n+    )\n+    result = lf.select(pl.sum_horizontal(\"null\", \"s\", \"s2\", ignore_nulls=ignore_nulls))\n+    if ignore_nulls and dtype_in != pl.Null:\n+        values = [2, 0, 1]\n+    else:\n+        values = [None, None, None]  # type: ignore[list-item]",
        "comment_created_at": "2024-12-29T15:23:18+00:00",
        "comment_author": "mcrumiller",
        "comment_body": "Thanks Ritchie. I have a follow-up to this adding temporals for mean horizontal but I'll wait for this one first.",
        "pr_file_module": null
      }
    ]
  }
]