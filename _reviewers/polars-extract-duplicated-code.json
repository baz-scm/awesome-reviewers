[
  {
    "discussion_id": "2166647632",
    "pr_number": 23131,
    "pr_file": "crates/polars-stream/src/nodes/shift.rs",
    "created_at": "2025-06-25T12:53:56+00:00",
    "commented_code": "+use std::collections::VecDeque;\n+use std::sync::Arc;\n+\n+use polars_core::schema::Schema;\n+use polars_core::utils::Container;\n+use polars_error::polars_ensure;\n+\n+use super::compute_node_prelude::*;\n+use crate::async_primitives::connector::{Receiver, Sender};\n+use crate::morsel::SourceToken;\n+\n+pub struct ShiftNode {\n+    state: State,\n+    output_schema: Arc<Schema>,\n+}\n+\n+#[derive(Default)]\n+enum State {",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "2166647632",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 23131,
        "pr_file": "crates/polars-stream/src/nodes/shift.rs",
        "discussion_id": "2166647632",
        "commented_code": "@@ -0,0 +1,474 @@\n+use std::collections::VecDeque;\n+use std::sync::Arc;\n+\n+use polars_core::schema::Schema;\n+use polars_core::utils::Container;\n+use polars_error::polars_ensure;\n+\n+use super::compute_node_prelude::*;\n+use crate::async_primitives::connector::{Receiver, Sender};\n+use crate::morsel::SourceToken;\n+\n+pub struct ShiftNode {\n+    state: State,\n+    output_schema: Arc<Schema>,\n+}\n+\n+#[derive(Default)]\n+enum State {",
        "comment_created_at": "2025-06-25T12:53:56+00:00",
        "comment_author": "orlp",
        "comment_body": "I think it's probably simpler to have the `buffer` and `seq` as part of the `ShiftNode` rather than for (almost) each state.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1855199851",
    "pr_number": 19932,
    "pr_file": "crates/polars-time/src/group_by/dynamic.rs",
    "created_at": "2024-11-23T14:03:22+00:00",
    "commented_code": "let groups = if by.is_empty() {\n             let vals = dt.downcast_iter().next().unwrap();\n             let ts = vals.values().as_slice();\n-            let (groups, lower, upper) = group_by_windows(\n-                w,\n-                ts,\n-                options.closed_window,\n-                tu,\n-                tz,\n-                include_lower_bound,\n-                include_upper_bound,\n-                options.start_by,\n-            );\n+\n+            let vanilla_start_step = (ts[0] == 0) && (ts[1] - ts[0] == 1);",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1855199851",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 19932,
        "pr_file": "crates/polars-time/src/group_by/dynamic.rs",
        "discussion_id": "1855199851",
        "commented_code": "@@ -311,16 +313,109 @@ impl Wrap<&DataFrame> {\n         let groups = if by.is_empty() {\n             let vals = dt.downcast_iter().next().unwrap();\n             let ts = vals.values().as_slice();\n-            let (groups, lower, upper) = group_by_windows(\n-                w,\n-                ts,\n-                options.closed_window,\n-                tu,\n-                tz,\n-                include_lower_bound,\n-                include_upper_bound,\n-                options.start_by,\n-            );\n+\n+            let vanilla_start_step = (ts[0] == 0) && (ts[1] - ts[0] == 1);",
        "comment_created_at": "2024-11-23T14:03:22+00:00",
        "comment_author": "ritchie46",
        "comment_body": "Can we move this to a separate function so that implementation is separate from dispatch?",
        "pr_file_module": null
      },
      {
        "comment_id": "1862004791",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 19932,
        "pr_file": "crates/polars-time/src/group_by/dynamic.rs",
        "discussion_id": "1855199851",
        "commented_code": "@@ -311,16 +313,109 @@ impl Wrap<&DataFrame> {\n         let groups = if by.is_empty() {\n             let vals = dt.downcast_iter().next().unwrap();\n             let ts = vals.values().as_slice();\n-            let (groups, lower, upper) = group_by_windows(\n-                w,\n-                ts,\n-                options.closed_window,\n-                tu,\n-                tz,\n-                include_lower_bound,\n-                include_upper_bound,\n-                options.start_by,\n-            );\n+\n+            let vanilla_start_step = (ts[0] == 0) && (ts[1] - ts[0] == 1);",
        "comment_created_at": "2024-11-28T11:21:41+00:00",
        "comment_author": "jvdd",
        "comment_body": "Moved the logic to a separate function in the group_by.rs file",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2107318804",
    "pr_number": 22888,
    "pr_file": "crates/polars-core/src/chunked_array/logical/datetime.rs",
    "created_at": "2025-05-26T13:03:48+00:00",
    "commented_code": "},\n             #[cfg(feature = \"dtype-date\")]\n             Date => {\n+                let has_timezone = self.time_zone().is_some();\n+                let timestamp_to_datetime = match self.time_unit() {\n+                    TimeUnit::Milliseconds => timestamp_ms_to_datetime,\n+                    TimeUnit::Microseconds => timestamp_us_to_datetime,\n+                    TimeUnit::Nanoseconds => timestamp_ns_to_datetime,\n+                };\n+                let datetime_to_timestamp = match self.time_unit() {\n+                    TimeUnit::Milliseconds => datetime_to_timestamp_ms,\n+                    TimeUnit::Microseconds => datetime_to_timestamp_us,\n+                    TimeUnit::Nanoseconds => datetime_to_timestamp_ns,\n+                };\n                 let cast_to_date = |tu_in_day: i64| {\n-                    let mut dt = self\n-                        .phys\n-                        .apply_values(|v| v.div_euclid(tu_in_day))\n+                    let values = {\n+                        #[cfg(feature = \"timezones\")]\n+                        {\n+                            if has_timezone {",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "2107318804",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 22888,
        "pr_file": "crates/polars-core/src/chunked_array/logical/datetime.rs",
        "discussion_id": "2107318804",
        "commented_code": "@@ -70,14 +80,58 @@ impl LogicalType for DatetimeChunked {\n             },\n             #[cfg(feature = \"dtype-date\")]\n             Date => {\n+                let has_timezone = self.time_zone().is_some();\n+                let timestamp_to_datetime = match self.time_unit() {\n+                    TimeUnit::Milliseconds => timestamp_ms_to_datetime,\n+                    TimeUnit::Microseconds => timestamp_us_to_datetime,\n+                    TimeUnit::Nanoseconds => timestamp_ns_to_datetime,\n+                };\n+                let datetime_to_timestamp = match self.time_unit() {\n+                    TimeUnit::Milliseconds => datetime_to_timestamp_ms,\n+                    TimeUnit::Microseconds => datetime_to_timestamp_us,\n+                    TimeUnit::Nanoseconds => datetime_to_timestamp_ns,\n+                };\n                 let cast_to_date = |tu_in_day: i64| {\n-                    let mut dt = self\n-                        .phys\n-                        .apply_values(|v| v.div_euclid(tu_in_day))\n+                    let values = {\n+                        #[cfg(feature = \"timezones\")]\n+                        {\n+                            if has_timezone {",
        "comment_created_at": "2025-05-26T13:03:48+00:00",
        "comment_author": "MarcoGorelli",
        "comment_body": "a pattern that's used elsewhere is something like\r\n```\r\nmatch self.dtype() {\r\n    #[cfg(feature = \"timezones\")]\r\n    Datetime(_, Some(tz)) => ...\r\n    _ => ...\r\n```\r\ndoes something like that work here, to avoid duplicating `self.phys.apply_values(|v| v.div_euclid(tu_in_day))`?",
        "pr_file_module": null
      },
      {
        "comment_id": "2108614683",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 22888,
        "pr_file": "crates/polars-core/src/chunked_array/logical/datetime.rs",
        "discussion_id": "2107318804",
        "commented_code": "@@ -70,14 +80,58 @@ impl LogicalType for DatetimeChunked {\n             },\n             #[cfg(feature = \"dtype-date\")]\n             Date => {\n+                let has_timezone = self.time_zone().is_some();\n+                let timestamp_to_datetime = match self.time_unit() {\n+                    TimeUnit::Milliseconds => timestamp_ms_to_datetime,\n+                    TimeUnit::Microseconds => timestamp_us_to_datetime,\n+                    TimeUnit::Nanoseconds => timestamp_ns_to_datetime,\n+                };\n+                let datetime_to_timestamp = match self.time_unit() {\n+                    TimeUnit::Milliseconds => datetime_to_timestamp_ms,\n+                    TimeUnit::Microseconds => datetime_to_timestamp_us,\n+                    TimeUnit::Nanoseconds => datetime_to_timestamp_ns,\n+                };\n                 let cast_to_date = |tu_in_day: i64| {\n-                    let mut dt = self\n-                        .phys\n-                        .apply_values(|v| v.div_euclid(tu_in_day))\n+                    let values = {\n+                        #[cfg(feature = \"timezones\")]\n+                        {\n+                            if has_timezone {",
        "comment_created_at": "2025-05-27T08:48:17+00:00",
        "comment_author": "florian-klein",
        "comment_body": "Ah, now I see what you meant! That's a really good idea - I'll rewrite it. Thanks!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2126059501",
    "pr_number": 22718,
    "pr_file": "crates/polars-lazy/src/physical_plan/exotic.rs",
    "created_at": "2025-06-04T08:51:45+00:00",
    "commented_code": "&mut ExpressionConversionState::new(true),\n     )\n }\n+\n+pub(crate) fn prepare_expression_for_context_with_schema(",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "2126059501",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 22718,
        "pr_file": "crates/polars-lazy/src/physical_plan/exotic.rs",
        "discussion_id": "2126059501",
        "commented_code": "@@ -46,3 +47,36 @@ pub(crate) fn prepare_expression_for_context(\n         &mut ExpressionConversionState::new(true),\n     )\n }\n+\n+pub(crate) fn prepare_expression_for_context_with_schema(",
        "comment_created_at": "2025-06-04T08:51:45+00:00",
        "comment_author": "ritchie46",
        "comment_body": "Can we add a `schema: Option<Schema>` argument to `prepare_expression_for_context` to reduce duplication.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2035558058",
    "pr_number": 22195,
    "pr_file": "crates/polars-python/src/lazyframe/visitor/nodes.rs",
    "created_at": "2025-04-09T14:54:27+00:00",
    "commented_code": "offset,\n                 } => (\"row_index\", name.to_string(), offset.unwrap_or(0)).into_py_any(py)?,\n                 FunctionIR::FastCount {\n-                    sources: _,\n-                    scan_type: _,\n-                    alias: _,\n-                } => return Err(PyNotImplementedError::new_err(\"function count\")),\n+                    sources,\n+                    scan_type,\n+                    alias,\n+                } => {\n+                    let sources = sources\n+                        .into_paths()\n+                        .ok_or_else(|| {\n+                            PyNotImplementedError::new_err(\"FastCount with BytesIO sources\")\n+                        })?\n+                        .into_py_any(py)?;\n+\n+                    let scan_type = match &**scan_type {",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "2035558058",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 22195,
        "pr_file": "crates/polars-python/src/lazyframe/visitor/nodes.rs",
        "discussion_id": "2035558058",
        "commented_code": "@@ -610,10 +610,65 @@ pub(crate) fn into_py(py: Python<'_>, plan: &IR) -> PyResult<PyObject> {\n                     offset,\n                 } => (\"row_index\", name.to_string(), offset.unwrap_or(0)).into_py_any(py)?,\n                 FunctionIR::FastCount {\n-                    sources: _,\n-                    scan_type: _,\n-                    alias: _,\n-                } => return Err(PyNotImplementedError::new_err(\"function count\")),\n+                    sources,\n+                    scan_type,\n+                    alias,\n+                } => {\n+                    let sources = sources\n+                        .into_paths()\n+                        .ok_or_else(|| {\n+                            PyNotImplementedError::new_err(\"FastCount with BytesIO sources\")\n+                        })?\n+                        .into_py_any(py)?;\n+\n+                    let scan_type = match &**scan_type {",
        "comment_created_at": "2025-04-09T14:54:27+00:00",
        "comment_author": "ritchie46",
        "comment_body": "This is also converted in `IR::Scan` can we factor this out into a function?",
        "pr_file_module": null
      },
      {
        "comment_id": "2036260241",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 22195,
        "pr_file": "crates/polars-python/src/lazyframe/visitor/nodes.rs",
        "discussion_id": "2035558058",
        "commented_code": "@@ -610,10 +610,65 @@ pub(crate) fn into_py(py: Python<'_>, plan: &IR) -> PyResult<PyObject> {\n                     offset,\n                 } => (\"row_index\", name.to_string(), offset.unwrap_or(0)).into_py_any(py)?,\n                 FunctionIR::FastCount {\n-                    sources: _,\n-                    scan_type: _,\n-                    alias: _,\n-                } => return Err(PyNotImplementedError::new_err(\"function count\")),\n+                    sources,\n+                    scan_type,\n+                    alias,\n+                } => {\n+                    let sources = sources\n+                        .into_paths()\n+                        .ok_or_else(|| {\n+                            PyNotImplementedError::new_err(\"FastCount with BytesIO sources\")\n+                        })?\n+                        .into_py_any(py)?;\n+\n+                    let scan_type = match &**scan_type {",
        "comment_created_at": "2025-04-09T23:18:10+00:00",
        "comment_author": "Matt711",
        "comment_body": "Yup added in https://github.com/pola-rs/polars/pull/22195/commits/e76b5e61acc4bdc199eb51a99a65075dc0f6cb74",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2022335504",
    "pr_number": 22014,
    "pr_file": "crates/polars-plan/src/plans/builder_ir.rs",
    "created_at": "2025-04-01T07:50:03+00:00",
    "commented_code": "};\n         self.add_alp(lp)\n     }\n+\n+    pub fn sink(self, payload: SinkType) -> PolarsResult<Self> {\n+        // This is duplicated from `dsl_to_ir::to_alp_impl`, would be good to refactor this and deduplicate.",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "2022335504",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 22014,
        "pr_file": "crates/polars-plan/src/plans/builder_ir.rs",
        "discussion_id": "2022335504",
        "commented_code": "@@ -302,4 +302,65 @@ impl<'a> IRBuilder<'a> {\n         };\n         self.add_alp(lp)\n     }\n+\n+    pub fn sink(self, payload: SinkType) -> PolarsResult<Self> {\n+        // This is duplicated from `dsl_to_ir::to_alp_impl`, would be good to refactor this and deduplicate.",
        "comment_created_at": "2025-04-01T07:50:03+00:00",
        "comment_author": "ritchie46",
        "comment_body": "Can we do that in this PR? \r\n\r\nMake a function and factor out the shared arguments?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1975657448",
    "pr_number": 21534,
    "pr_file": "crates/polars-python/src/lazyframe/general.rs",
    "created_at": "2025-02-28T16:04:39+00:00",
    "commented_code": "ldf.cache().into()\n     }\n \n-    fn profile(&self, py: Python) -> PyResult<(PyDataFrame, PyDataFrame)> {\n-        let (df, time_df) = py.enter_polars(|| self.ldf.clone().profile())?;\n+    #[pyo3(signature = (lambda_post_opt=None))]\n+    fn profile(\n+        &self,\n+        py: Python,\n+        lambda_post_opt: Option<PyObject>,\n+    ) -> PyResult<(PyDataFrame, PyDataFrame)> {\n+        let (df, time_df) = py.enter_polars(|| {\n+            let ldf = self.ldf.clone();\n+            if let Some(lambda) = lambda_post_opt {\n+                ldf._profile_post_opt(|root, lp_arena, expr_arena, duration_since_start| {\n+                    Python::with_gil(|py| {\n+                        let nt = NodeTraverser::new(\n+                            root,\n+                            std::mem::take(lp_arena),\n+                            std::mem::take(expr_arena),\n+                        );\n+\n+                        // Get a copy of the arena's.\n+                        let arenas = nt.get_arenas();\n+\n+                        // Pass the node visitor which allows the python callback to replace parts of the query plan.\n+                        // Remove \"cuda\" or specify better once we have multiple post-opt callbacks.\n+                        lambda\n+                            .call1(py, (nt, duration_since_start.map(|t| t.as_nanos() as u64)))\n+                            .map_err(\n+                                |e| polars_err!(ComputeError: \"'cuda' conversion failed: {}\", e),\n+                            )?;\n+\n+                        // Unpack the arena's.\n+                        // At this point the `nt` is useless.\n+\n+                        std::mem::swap(lp_arena, &mut *arenas.0.lock().unwrap());\n+                        std::mem::swap(expr_arena, &mut *arenas.1.lock().unwrap());\n+\n+                        Ok(())",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1975657448",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 21534,
        "pr_file": "crates/polars-python/src/lazyframe/general.rs",
        "discussion_id": "1975657448",
        "commented_code": "@@ -613,8 +613,47 @@ impl PyLazyFrame {\n         ldf.cache().into()\n     }\n \n-    fn profile(&self, py: Python) -> PyResult<(PyDataFrame, PyDataFrame)> {\n-        let (df, time_df) = py.enter_polars(|| self.ldf.clone().profile())?;\n+    #[pyo3(signature = (lambda_post_opt=None))]\n+    fn profile(\n+        &self,\n+        py: Python,\n+        lambda_post_opt: Option<PyObject>,\n+    ) -> PyResult<(PyDataFrame, PyDataFrame)> {\n+        let (df, time_df) = py.enter_polars(|| {\n+            let ldf = self.ldf.clone();\n+            if let Some(lambda) = lambda_post_opt {\n+                ldf._profile_post_opt(|root, lp_arena, expr_arena, duration_since_start| {\n+                    Python::with_gil(|py| {\n+                        let nt = NodeTraverser::new(\n+                            root,\n+                            std::mem::take(lp_arena),\n+                            std::mem::take(expr_arena),\n+                        );\n+\n+                        // Get a copy of the arena's.\n+                        let arenas = nt.get_arenas();\n+\n+                        // Pass the node visitor which allows the python callback to replace parts of the query plan.\n+                        // Remove \"cuda\" or specify better once we have multiple post-opt callbacks.\n+                        lambda\n+                            .call1(py, (nt, duration_since_start.map(|t| t.as_nanos() as u64)))\n+                            .map_err(\n+                                |e| polars_err!(ComputeError: \"'cuda' conversion failed: {}\", e),\n+                            )?;\n+\n+                        // Unpack the arena's.\n+                        // At this point the `nt` is useless.\n+\n+                        std::mem::swap(lp_arena, &mut *arenas.0.lock().unwrap());\n+                        std::mem::swap(expr_arena, &mut *arenas.1.lock().unwrap());\n+\n+                        Ok(())",
        "comment_created_at": "2025-02-28T16:04:39+00:00",
        "comment_author": "wence-",
        "comment_body": "Not really happy with this code duplication `collect` does the same other than calling `_collect_post_opt` rather than `_profile_post_opt`.",
        "pr_file_module": null
      },
      {
        "comment_id": "1975761759",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 21534,
        "pr_file": "crates/polars-python/src/lazyframe/general.rs",
        "discussion_id": "1975657448",
        "commented_code": "@@ -613,8 +613,47 @@ impl PyLazyFrame {\n         ldf.cache().into()\n     }\n \n-    fn profile(&self, py: Python) -> PyResult<(PyDataFrame, PyDataFrame)> {\n-        let (df, time_df) = py.enter_polars(|| self.ldf.clone().profile())?;\n+    #[pyo3(signature = (lambda_post_opt=None))]\n+    fn profile(\n+        &self,\n+        py: Python,\n+        lambda_post_opt: Option<PyObject>,\n+    ) -> PyResult<(PyDataFrame, PyDataFrame)> {\n+        let (df, time_df) = py.enter_polars(|| {\n+            let ldf = self.ldf.clone();\n+            if let Some(lambda) = lambda_post_opt {\n+                ldf._profile_post_opt(|root, lp_arena, expr_arena, duration_since_start| {\n+                    Python::with_gil(|py| {\n+                        let nt = NodeTraverser::new(\n+                            root,\n+                            std::mem::take(lp_arena),\n+                            std::mem::take(expr_arena),\n+                        );\n+\n+                        // Get a copy of the arena's.\n+                        let arenas = nt.get_arenas();\n+\n+                        // Pass the node visitor which allows the python callback to replace parts of the query plan.\n+                        // Remove \"cuda\" or specify better once we have multiple post-opt callbacks.\n+                        lambda\n+                            .call1(py, (nt, duration_since_start.map(|t| t.as_nanos() as u64)))\n+                            .map_err(\n+                                |e| polars_err!(ComputeError: \"'cuda' conversion failed: {}\", e),\n+                            )?;\n+\n+                        // Unpack the arena's.\n+                        // At this point the `nt` is useless.\n+\n+                        std::mem::swap(lp_arena, &mut *arenas.0.lock().unwrap());\n+                        std::mem::swap(expr_arena, &mut *arenas.1.lock().unwrap());\n+\n+                        Ok(())",
        "comment_created_at": "2025-02-28T17:19:23+00:00",
        "comment_author": "wence-",
        "comment_body": "Moved into reusable function.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1966703807",
    "pr_number": 20693,
    "pr_file": "crates/polars-python/src/lazyframe/general.rs",
    "created_at": "2025-02-23T08:11:24+00:00",
    "commented_code": "ldf.cache().into()\n     }\n \n-    fn profile(&self, py: Python) -> PyResult<(PyDataFrame, PyDataFrame)> {\n-        let (df, time_df) = py.enter_polars(|| self.ldf.clone().profile())?;\n+    #[pyo3(signature = (lambda_post_opt=None))]\n+    fn profile(\n+        &self,\n+        py: Python,\n+        lambda_post_opt: Option<PyObject>,\n+    ) -> PyResult<(PyDataFrame, PyDataFrame)> {\n+        // if we don't allow threads and we have udfs trying to acquire the gil from different\n+        // threads we deadlock.\n+        let (df, time_df) = py.allow_threads(|| {\n+            let ldf = self.ldf.clone();\n+            if let Some(lambda) = lambda_post_opt {\n+                ldf._profile_post_opt(|root, lp_arena, expr_arena| {\n+                    Python::with_gil(|py| {",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1966703807",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 20693,
        "pr_file": "crates/polars-python/src/lazyframe/general.rs",
        "discussion_id": "1966703807",
        "commented_code": "@@ -613,8 +613,47 @@ impl PyLazyFrame {\n         ldf.cache().into()\n     }\n \n-    fn profile(&self, py: Python) -> PyResult<(PyDataFrame, PyDataFrame)> {\n-        let (df, time_df) = py.enter_polars(|| self.ldf.clone().profile())?;\n+    #[pyo3(signature = (lambda_post_opt=None))]\n+    fn profile(\n+        &self,\n+        py: Python,\n+        lambda_post_opt: Option<PyObject>,\n+    ) -> PyResult<(PyDataFrame, PyDataFrame)> {\n+        // if we don't allow threads and we have udfs trying to acquire the gil from different\n+        // threads we deadlock.\n+        let (df, time_df) = py.allow_threads(|| {\n+            let ldf = self.ldf.clone();\n+            if let Some(lambda) = lambda_post_opt {\n+                ldf._profile_post_opt(|root, lp_arena, expr_arena| {\n+                    Python::with_gil(|py| {",
        "comment_created_at": "2025-02-23T08:11:24+00:00",
        "comment_author": "ritchie46",
        "comment_body": "I believe this code is exactly the same as in collect. Can we put it in a function?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1935322298",
    "pr_number": 20960,
    "pr_file": "crates/polars-stream/src/nodes/merge_sorted.rs",
    "created_at": "2025-01-30T09:55:35+00:00",
    "commented_code": "+use std::collections::VecDeque;\n use std::sync::Arc;\n \n+use polars_core::prelude::ChunkCompareIneq;\n use polars_core::schema::Schema;\n use polars_ops::frame::_merge_sorted_dfs;\n use polars_utils::pl_str::PlSmallStr;\n \n+use crate::async_primitives::connector::Receiver;\n+use crate::async_primitives::distributor_channel::distributor_channel;\n+use crate::morsel::{get_ideal_morsel_size, SourceToken};\n use crate::nodes::compute_node_prelude::*;\n-use crate::nodes::in_memory_sink::InMemorySinkNode;\n-use crate::nodes::in_memory_source::InMemorySourceNode;\n-\n-enum MergeSortedState {\n-    Sink {\n-        left: InMemorySinkNode,\n-        right: InMemorySinkNode,\n-    },\n-    Source(InMemorySourceNode),\n-    Done,\n+use crate::DEFAULT_DISTRIBUTOR_BUFFER_SIZE;\n+\n+#[derive(Debug)]\n+enum State {\n+    /// Merging values from buffered or ports.\n+    Merging,\n+    /// Flushing buffer values.\n+    Flushing,\n+    /// Passing values along from one of the ports.\n+    Piping,\n }\n \n pub struct MergeSortedNode {\n-    state: MergeSortedState,\n     num_pipelines: usize,\n-    key: PlSmallStr,\n+    key_column_idx: usize,\n+    state: State,\n+\n+    seq: MorselSeq,\n+\n+    starting_nulls: bool,\n+\n+    // Not yet merged buffers.\n+    left_unmerged: VecDeque<DataFrame>,\n+    right_unmerged: VecDeque<DataFrame>,\n }\n \n impl MergeSortedNode {\n     pub fn new(schema: Arc<Schema>, key: PlSmallStr) -> Self {\n         assert!(schema.contains(key.as_str()));\n+        let key_column_idx = schema.index_of(key.as_str()).unwrap();\n+\n         Self {\n-            state: MergeSortedState::Sink {\n-                left: InMemorySinkNode::new(schema.clone()),\n-                right: InMemorySinkNode::new(schema),\n-            },\n-            num_pipelines: 0,\n-            key,\n+            num_pipelines: 1,\n+            key_column_idx,\n+            state: State::Merging,\n+\n+            seq: MorselSeq::default(),\n+\n+            starting_nulls: false,\n+\n+            left_unmerged: VecDeque::new(),\n+            right_unmerged: VecDeque::new(),\n         }\n     }\n }\n \n impl ComputeNode for MergeSortedNode {\n     fn name(&self) -> &str {\n-        \"in_memory_merge_sorted\"\n+        \"merge_sorted\"\n     }\n \n     fn initialize(&mut self, num_pipelines: usize) {\n         self.num_pipelines = num_pipelines;\n     }\n \n     fn update_state(&mut self, recv: &mut [PortState], send: &mut [PortState]) -> PolarsResult<()> {\n-        assert!(recv.len() == 2 && send.len() == 1);\n+        assert_eq!(send.len(), 1);\n+        assert_eq!(recv.len(), 2);\n \n         // If the output doesn't want any more data, transition to being done.\n-        if send[0] == PortState::Done && !matches!(self.state, MergeSortedState::Done) {\n-            self.state = MergeSortedState::Done;\n+        if send[0] == PortState::Done {\n+            recv[0] = PortState::Done;\n+            recv[1] = PortState::Done;\n+\n+            self.left_unmerged.clear();\n+            self.right_unmerged.clear();\n+            self.state = State::Piping;\n+\n+            return Ok(());\n         }\n \n-        // If the input is done, transition to being a source.\n-        if let MergeSortedState::Sink { left, right } = &mut self.state {\n-            if recv[0] == PortState::Done && recv[1] == PortState::Done {\n-                let left_df = left.get_output()?.unwrap();\n-                let right_df = right.get_output()?.unwrap();\n-                let left_s = left_df.column(self.key.as_str()).unwrap();\n-                let right_s = right_df.column(self.key.as_str()).unwrap();\n-                let df = _merge_sorted_dfs(\n-                    &left_df,\n-                    &right_df,\n-                    left_s.as_materialized_series(),\n-                    right_s.as_materialized_series(),\n-                    true,\n-                )?;\n-                let mut source_node = InMemorySourceNode::new(Arc::new(df), MorselSeq::default());\n-                source_node.initialize(self.num_pipelines);\n-                self.state = MergeSortedState::Source(source_node);\n+        if recv[0] == PortState::Done || recv[1] == PortState::Done {\n+            if !self.left_unmerged.is_empty() || !self.right_unmerged.is_empty() {\n+                self.state = State::Flushing;\n+            } else {\n+                self.state = State::Piping;\n             }\n+        } else {\n+            self.state = State::Merging;\n         }\n \n-        match &mut self.state {\n-            MergeSortedState::Sink { left, right, .. } => {\n-                left.update_state(&mut recv[0..1], &mut [])?;\n-                right.update_state(&mut recv[1..2], &mut [])?;\n+        match self.state {\n+            State::Merging if send[0] == PortState::Blocked => {\n+                recv[0] = PortState::Blocked;\n+                recv[1] = PortState::Blocked;\n+            },\n+\n+            // If one input side is blocked and we haven't buffered anything for that side, we",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1935322298",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 20960,
        "pr_file": "crates/polars-stream/src/nodes/merge_sorted.rs",
        "discussion_id": "1935322298",
        "commented_code": "@@ -1,126 +1,477 @@\n+use std::collections::VecDeque;\n use std::sync::Arc;\n \n+use polars_core::prelude::ChunkCompareIneq;\n use polars_core::schema::Schema;\n use polars_ops::frame::_merge_sorted_dfs;\n use polars_utils::pl_str::PlSmallStr;\n \n+use crate::async_primitives::connector::Receiver;\n+use crate::async_primitives::distributor_channel::distributor_channel;\n+use crate::morsel::{get_ideal_morsel_size, SourceToken};\n use crate::nodes::compute_node_prelude::*;\n-use crate::nodes::in_memory_sink::InMemorySinkNode;\n-use crate::nodes::in_memory_source::InMemorySourceNode;\n-\n-enum MergeSortedState {\n-    Sink {\n-        left: InMemorySinkNode,\n-        right: InMemorySinkNode,\n-    },\n-    Source(InMemorySourceNode),\n-    Done,\n+use crate::DEFAULT_DISTRIBUTOR_BUFFER_SIZE;\n+\n+#[derive(Debug)]\n+enum State {\n+    /// Merging values from buffered or ports.\n+    Merging,\n+    /// Flushing buffer values.\n+    Flushing,\n+    /// Passing values along from one of the ports.\n+    Piping,\n }\n \n pub struct MergeSortedNode {\n-    state: MergeSortedState,\n     num_pipelines: usize,\n-    key: PlSmallStr,\n+    key_column_idx: usize,\n+    state: State,\n+\n+    seq: MorselSeq,\n+\n+    starting_nulls: bool,\n+\n+    // Not yet merged buffers.\n+    left_unmerged: VecDeque<DataFrame>,\n+    right_unmerged: VecDeque<DataFrame>,\n }\n \n impl MergeSortedNode {\n     pub fn new(schema: Arc<Schema>, key: PlSmallStr) -> Self {\n         assert!(schema.contains(key.as_str()));\n+        let key_column_idx = schema.index_of(key.as_str()).unwrap();\n+\n         Self {\n-            state: MergeSortedState::Sink {\n-                left: InMemorySinkNode::new(schema.clone()),\n-                right: InMemorySinkNode::new(schema),\n-            },\n-            num_pipelines: 0,\n-            key,\n+            num_pipelines: 1,\n+            key_column_idx,\n+            state: State::Merging,\n+\n+            seq: MorselSeq::default(),\n+\n+            starting_nulls: false,\n+\n+            left_unmerged: VecDeque::new(),\n+            right_unmerged: VecDeque::new(),\n         }\n     }\n }\n \n impl ComputeNode for MergeSortedNode {\n     fn name(&self) -> &str {\n-        \"in_memory_merge_sorted\"\n+        \"merge_sorted\"\n     }\n \n     fn initialize(&mut self, num_pipelines: usize) {\n         self.num_pipelines = num_pipelines;\n     }\n \n     fn update_state(&mut self, recv: &mut [PortState], send: &mut [PortState]) -> PolarsResult<()> {\n-        assert!(recv.len() == 2 && send.len() == 1);\n+        assert_eq!(send.len(), 1);\n+        assert_eq!(recv.len(), 2);\n \n         // If the output doesn't want any more data, transition to being done.\n-        if send[0] == PortState::Done && !matches!(self.state, MergeSortedState::Done) {\n-            self.state = MergeSortedState::Done;\n+        if send[0] == PortState::Done {\n+            recv[0] = PortState::Done;\n+            recv[1] = PortState::Done;\n+\n+            self.left_unmerged.clear();\n+            self.right_unmerged.clear();\n+            self.state = State::Piping;\n+\n+            return Ok(());\n         }\n \n-        // If the input is done, transition to being a source.\n-        if let MergeSortedState::Sink { left, right } = &mut self.state {\n-            if recv[0] == PortState::Done && recv[1] == PortState::Done {\n-                let left_df = left.get_output()?.unwrap();\n-                let right_df = right.get_output()?.unwrap();\n-                let left_s = left_df.column(self.key.as_str()).unwrap();\n-                let right_s = right_df.column(self.key.as_str()).unwrap();\n-                let df = _merge_sorted_dfs(\n-                    &left_df,\n-                    &right_df,\n-                    left_s.as_materialized_series(),\n-                    right_s.as_materialized_series(),\n-                    true,\n-                )?;\n-                let mut source_node = InMemorySourceNode::new(Arc::new(df), MorselSeq::default());\n-                source_node.initialize(self.num_pipelines);\n-                self.state = MergeSortedState::Source(source_node);\n+        if recv[0] == PortState::Done || recv[1] == PortState::Done {\n+            if !self.left_unmerged.is_empty() || !self.right_unmerged.is_empty() {\n+                self.state = State::Flushing;\n+            } else {\n+                self.state = State::Piping;\n             }\n+        } else {\n+            self.state = State::Merging;\n         }\n \n-        match &mut self.state {\n-            MergeSortedState::Sink { left, right, .. } => {\n-                left.update_state(&mut recv[0..1], &mut [])?;\n-                right.update_state(&mut recv[1..2], &mut [])?;\n+        match self.state {\n+            State::Merging if send[0] == PortState::Blocked => {\n+                recv[0] = PortState::Blocked;\n+                recv[1] = PortState::Blocked;\n+            },\n+\n+            // If one input side is blocked and we haven't buffered anything for that side, we",
        "comment_created_at": "2025-01-30T09:55:35+00:00",
        "comment_author": "orlp",
        "comment_body": "I don't think this needs to be its own case, or needs to check `*_unmerged.is_empty()`, I think we can merge this into the above case:\r\n```rust\r\nlet blocked = send[0] == PortState::Blocked || recv.iter().any(|p| p == PortState::Blocked);\r\nif blocked {\r\n    recv[0] = PortState::Blocked;\r\n    recv[1] = PortState::Blocked;\r\n    send[0] = PortState::Blocked;\r\n    return;\r\n}\r\n```\r\nAnd you can apply this logic regardless of the state you are in, simplifying the rest of the logic not having to deal with blocking.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1845564796",
    "pr_number": 19815,
    "pr_file": "crates/polars-core/src/datatypes/dtype.rs",
    "created_at": "2024-11-17T19:12:52+00:00",
    "commented_code": "UInt64 => Scalar::from(u64::MAX),\n             Float32 => Scalar::from(f32::INFINITY),\n             Float64 => Scalar::from(f64::INFINITY),\n+            #[cfg(feature = \"dtype-time\")]\n+            Time => Scalar::new(Time, AnyValue::Time(86_399_999_999_999)),",
    "repo_full_name": "pola-rs/polars",
    "discussion_comments": [
      {
        "comment_id": "1845564796",
        "repo_full_name": "pola-rs/polars",
        "pr_number": 19815,
        "pr_file": "crates/polars-core/src/datatypes/dtype.rs",
        "discussion_id": "1845564796",
        "commented_code": "@@ -590,6 +590,8 @@ impl DataType {\n             UInt64 => Scalar::from(u64::MAX),\n             Float32 => Scalar::from(f32::INFINITY),\n             Float64 => Scalar::from(f64::INFINITY),\n+            #[cfg(feature = \"dtype-time\")]\n+            Time => Scalar::new(Time, AnyValue::Time(86_399_999_999_999)),",
        "comment_created_at": "2024-11-17T19:12:52+00:00",
        "comment_author": "mcrumiller",
        "comment_body": "I think it might be clearer to use `NS_IN_DAY - 1` here instead of the literal value.",
        "pr_file_module": null
      }
    ]
  }
]