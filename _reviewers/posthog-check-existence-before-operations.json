[
  {
    "discussion_id": "2272705859",
    "pr_number": 36480,
    "pr_file": "posthog/hogql/database/join_functions.py",
    "created_at": "2025-08-13T09:30:42+00:00",
    "commented_code": "+from collections.abc import Callable\n+from typing import Any, Literal, Optional, TypeVar, overload, cast\n+from pydantic import BaseModel\n+\n+\n+class LazyJoinFunctionSerialConfig(BaseModel):\n+    type: Literal[\"join_function\"] = \"join_function\"\n+    name: str\n+\n+\n+class LazyJoinClosureSerialConfig(BaseModel):\n+    type: Literal[\"closure\"] = \"closure\"\n+    name: str\n+    args: tuple[Any, ...]\n+\n+\n+REGISTERED_JOIN_FUNCTIONS: dict[str, Callable] = {}\n+\n+\n+REGISTERED_JOIN_CLOSURES: dict[str, Callable] = {}\n+\n+_F = TypeVar(\"_F\", bound=Callable)\n+\n+\n+@overload\n+def register_join_function(_func: _F) -> _F: ...\n+\n+\n+@overload\n+def register_join_function(*, name: Optional[str] = ..., closure: bool = ...) -> Callable[[_F], _F]: ...\n+\n+\n+def register_join_function(_func: Optional[_F] = None, *, name: Optional[str] = None, closure: bool = False):\n+    \"\"\"\n+    Decorator to register a join function in the allowlist.\n+\n+    Usage:\n+    - @register_join_function\n+    - @register_join_function()\n+    - @register_join_function(name=\"custom_name\")\n+    - @register_join_function(closure=True)  # for factory functions returning a join callable\n+    \"\"\"\n+\n+    def _decorator(func: _F) -> _F:\n+        key = name or cast(str, getattr(func, \"__name__\", \"\"))\n+        if closure:\n+            REGISTERED_JOIN_CLOSURES[key] = func\n+        else:\n+            REGISTERED_JOIN_FUNCTIONS[key] = func",
    "repo_full_name": "PostHog/posthog",
    "discussion_comments": [
      {
        "comment_id": "2272705859",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 36480,
        "pr_file": "posthog/hogql/database/join_functions.py",
        "discussion_id": "2272705859",
        "commented_code": "@@ -0,0 +1,63 @@\n+from collections.abc import Callable\n+from typing import Any, Literal, Optional, TypeVar, overload, cast\n+from pydantic import BaseModel\n+\n+\n+class LazyJoinFunctionSerialConfig(BaseModel):\n+    type: Literal[\"join_function\"] = \"join_function\"\n+    name: str\n+\n+\n+class LazyJoinClosureSerialConfig(BaseModel):\n+    type: Literal[\"closure\"] = \"closure\"\n+    name: str\n+    args: tuple[Any, ...]\n+\n+\n+REGISTERED_JOIN_FUNCTIONS: dict[str, Callable] = {}\n+\n+\n+REGISTERED_JOIN_CLOSURES: dict[str, Callable] = {}\n+\n+_F = TypeVar(\"_F\", bound=Callable)\n+\n+\n+@overload\n+def register_join_function(_func: _F) -> _F: ...\n+\n+\n+@overload\n+def register_join_function(*, name: Optional[str] = ..., closure: bool = ...) -> Callable[[_F], _F]: ...\n+\n+\n+def register_join_function(_func: Optional[_F] = None, *, name: Optional[str] = None, closure: bool = False):\n+    \"\"\"\n+    Decorator to register a join function in the allowlist.\n+\n+    Usage:\n+    - @register_join_function\n+    - @register_join_function()\n+    - @register_join_function(name=\"custom_name\")\n+    - @register_join_function(closure=True)  # for factory functions returning a join callable\n+    \"\"\"\n+\n+    def _decorator(func: _F) -> _F:\n+        key = name or cast(str, getattr(func, \"__name__\", \"\"))\n+        if closure:\n+            REGISTERED_JOIN_CLOSURES[key] = func\n+        else:\n+            REGISTERED_JOIN_FUNCTIONS[key] = func",
        "comment_created_at": "2025-08-13T09:30:42+00:00",
        "comment_author": "Gilbert09",
        "comment_body": "Can we also check if the `key` already exists, if so, raise an error - we should never have overlapping keys here",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2275844503",
    "pr_number": 36562,
    "pr_file": "ee/hogai/eval/schema.py",
    "created_at": "2025-08-14T08:17:34+00:00",
    "commented_code": "+import json\n+from abc import ABC, abstractmethod\n+from collections.abc import Generator, Sequence\n+from typing import Generic, Self, TypeVar\n+\n+from django.db.models import Model\n+from pydantic import BaseModel\n+from pydantic_avro import AvroBase\n+\n+from posthog.models import (\n+    DataWarehouseTable,\n+    GroupTypeMapping,\n+    PropertyDefinition,\n+    Team,\n+)\n+\n+T = TypeVar(\"T\", bound=Model)\n+\n+\n+class BaseSnapshot(AvroBase, ABC, Generic[T]):\n+    @classmethod\n+    @abstractmethod\n+    def serialize_for_project(cls, project_id: int) -> Generator[Self, None, None]:\n+        raise NotImplementedError\n+\n+    @classmethod\n+    @abstractmethod\n+    def deserialize_for_project(\n+        cls, project_id: int, models: Sequence[Self], *, team_id: int\n+    ) -> Generator[T, None, None]:\n+        raise NotImplementedError\n+\n+\n+# posthog/models/team.py\n+class TeamSnapshot(BaseSnapshot[Team]):\n+    name: str\n+    test_account_filters: str\n+\n+    @classmethod\n+    def serialize_for_project(cls, project_id: int):\n+        team = Team.objects.get(pk=project_id)",
    "repo_full_name": "PostHog/posthog",
    "discussion_comments": [
      {
        "comment_id": "2275844503",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 36562,
        "pr_file": "ee/hogai/eval/schema.py",
        "discussion_id": "2275844503",
        "commented_code": "@@ -0,0 +1,143 @@\n+import json\n+from abc import ABC, abstractmethod\n+from collections.abc import Generator, Sequence\n+from typing import Generic, Self, TypeVar\n+\n+from django.db.models import Model\n+from pydantic import BaseModel\n+from pydantic_avro import AvroBase\n+\n+from posthog.models import (\n+    DataWarehouseTable,\n+    GroupTypeMapping,\n+    PropertyDefinition,\n+    Team,\n+)\n+\n+T = TypeVar(\"T\", bound=Model)\n+\n+\n+class BaseSnapshot(AvroBase, ABC, Generic[T]):\n+    @classmethod\n+    @abstractmethod\n+    def serialize_for_project(cls, project_id: int) -> Generator[Self, None, None]:\n+        raise NotImplementedError\n+\n+    @classmethod\n+    @abstractmethod\n+    def deserialize_for_project(\n+        cls, project_id: int, models: Sequence[Self], *, team_id: int\n+    ) -> Generator[T, None, None]:\n+        raise NotImplementedError\n+\n+\n+# posthog/models/team.py\n+class TeamSnapshot(BaseSnapshot[Team]):\n+    name: str\n+    test_account_filters: str\n+\n+    @classmethod\n+    def serialize_for_project(cls, project_id: int):\n+        team = Team.objects.get(pk=project_id)",
        "comment_created_at": "2025-08-14T08:17:34+00:00",
        "comment_author": "sortafreel",
        "comment_body": "Same-ish question here - can we always guarantee that project_id exists? I assume the serialization happens right away, so there's not enough time for anything to happen in between.\r\n\r\nHowever, from my understanding, they are refreshed twice monthly, so the question stands :)",
        "pr_file_module": null
      },
      {
        "comment_id": "2275899976",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 36562,
        "pr_file": "ee/hogai/eval/schema.py",
        "discussion_id": "2275844503",
        "commented_code": "@@ -0,0 +1,143 @@\n+import json\n+from abc import ABC, abstractmethod\n+from collections.abc import Generator, Sequence\n+from typing import Generic, Self, TypeVar\n+\n+from django.db.models import Model\n+from pydantic import BaseModel\n+from pydantic_avro import AvroBase\n+\n+from posthog.models import (\n+    DataWarehouseTable,\n+    GroupTypeMapping,\n+    PropertyDefinition,\n+    Team,\n+)\n+\n+T = TypeVar(\"T\", bound=Model)\n+\n+\n+class BaseSnapshot(AvroBase, ABC, Generic[T]):\n+    @classmethod\n+    @abstractmethod\n+    def serialize_for_project(cls, project_id: int) -> Generator[Self, None, None]:\n+        raise NotImplementedError\n+\n+    @classmethod\n+    @abstractmethod\n+    def deserialize_for_project(\n+        cls, project_id: int, models: Sequence[Self], *, team_id: int\n+    ) -> Generator[T, None, None]:\n+        raise NotImplementedError\n+\n+\n+# posthog/models/team.py\n+class TeamSnapshot(BaseSnapshot[Team]):\n+    name: str\n+    test_account_filters: str\n+\n+    @classmethod\n+    def serialize_for_project(cls, project_id: int):\n+        team = Team.objects.get(pk=project_id)",
        "comment_created_at": "2025-08-14T08:31:52+00:00",
        "comment_author": "skoob13",
        "comment_body": "Since the input is going to be a dataset, we don't want to continue an evaluation run if the dataset contains incorrect data. The idea here is to run for every record or fail altogether.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2257685078",
    "pr_number": 36258,
    "pr_file": "posthog/tasks/email.py",
    "created_at": "2025-08-06T16:18:04+00:00",
    "commented_code": "# Build the dictionaries from the optimized result set\n     for activity in latest_activities:\n-        if activity.user:\n-            last_editors[activity.item_id] = activity.user.email\n-            last_edit_dates[activity.item_id] = activity.created_at.strftime(\"%Y-%m-%d\")\n-        else:\n-            last_editors[activity.item_id] = None\n-            last_edit_dates[activity.item_id] = None\n+        if activity.item_id is not None:  # Ensure item_id is not None before using as dict key",
    "repo_full_name": "PostHog/posthog",
    "discussion_comments": [
      {
        "comment_id": "2257685078",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 36258,
        "pr_file": "posthog/tasks/email.py",
        "discussion_id": "2257685078",
        "commented_code": "@@ -728,12 +729,13 @@ def send_team_hog_functions_digest(team_id: int, hog_function_ids: list[str] | N\n \n     # Build the dictionaries from the optimized result set\n     for activity in latest_activities:\n-        if activity.user:\n-            last_editors[activity.item_id] = activity.user.email\n-            last_edit_dates[activity.item_id] = activity.created_at.strftime(\"%Y-%m-%d\")\n-        else:\n-            last_editors[activity.item_id] = None\n-            last_edit_dates[activity.item_id] = None\n+        if activity.item_id is not None:  # Ensure item_id is not None before using as dict key",
        "comment_created_at": "2025-08-06T16:18:04+00:00",
        "comment_author": "Twixes",
        "comment_body": "Nit: Typically clearer to do the less-nested `if activity.item_id is None: continue` in cases like this ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2251121522",
    "pr_number": 36089,
    "pr_file": "ee/hogai/assistant.py",
    "created_at": "2025-08-04T10:50:48+00:00",
    "commented_code": "def _chunk_reasoning_headline(self, reasoning: dict[str, Any]) -> Optional[str]:\n         \"\"\"Process a chunk of OpenAI `reasoning`, and if a new headline was just finalized, return it.\"\"\"\n         try:\n-            summary_text_chunk = reasoning[\"summary\"][0][\"text\"]\n-        except (KeyError, IndexError) as e:\n-            capture_exception(e)\n-            self._reasoning_headline_chunk = None  # not expected, so let's just reset\n+            if summary := reasoning.get(\"summary\"):\n+                summary_text_chunk = summary[0][\"text\"]",
    "repo_full_name": "PostHog/posthog",
    "discussion_comments": [
      {
        "comment_id": "2251121522",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 36089,
        "pr_file": "ee/hogai/assistant.py",
        "discussion_id": "2251121522",
        "commented_code": "@@ -546,10 +546,15 @@ def _process_memory_initializer_chunk(self, langchain_message: AIMessageChunk) -\n     def _chunk_reasoning_headline(self, reasoning: dict[str, Any]) -> Optional[str]:\n         \"\"\"Process a chunk of OpenAI `reasoning`, and if a new headline was just finalized, return it.\"\"\"\n         try:\n-            summary_text_chunk = reasoning[\"summary\"][0][\"text\"]\n-        except (KeyError, IndexError) as e:\n-            capture_exception(e)\n-            self._reasoning_headline_chunk = None  # not expected, so let's just reset\n+            if summary := reasoning.get(\"summary\"):\n+                summary_text_chunk = summary[0][\"text\"]",
        "comment_created_at": "2025-08-04T10:50:48+00:00",
        "comment_author": "sortafreel",
        "comment_body": "`IndexError` seems possible still, as you access `summary[0]`?",
        "pr_file_module": null
      },
      {
        "comment_id": "2251594412",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 36089,
        "pr_file": "ee/hogai/assistant.py",
        "discussion_id": "2251121522",
        "commented_code": "@@ -546,10 +546,15 @@ def _process_memory_initializer_chunk(self, langchain_message: AIMessageChunk) -\n     def _chunk_reasoning_headline(self, reasoning: dict[str, Any]) -> Optional[str]:\n         \"\"\"Process a chunk of OpenAI `reasoning`, and if a new headline was just finalized, return it.\"\"\"\n         try:\n-            summary_text_chunk = reasoning[\"summary\"][0][\"text\"]\n-        except (KeyError, IndexError) as e:\n-            capture_exception(e)\n-            self._reasoning_headline_chunk = None  # not expected, so let's just reset\n+            if summary := reasoning.get(\"summary\"):\n+                summary_text_chunk = summary[0][\"text\"]",
        "comment_created_at": "2025-08-04T14:00:50+00:00",
        "comment_author": "Twixes",
        "comment_body": "Actually not, because the walrus operator checks for _truthiness_, not non-null",
        "pr_file_module": null
      }
    ]
  }
]