[
  {
    "discussion_id": "2276284218",
    "pr_number": 36586,
    "pr_file": "posthog/warehouse/api/external_data_source.py",
    "created_at": "2025-08-14T10:53:42+00:00",
    "commented_code": "status=status.HTTP_200_OK,\n             data={str(key): value.model_dump() for key, value in configs.items()},\n         )\n+\n+    @action(methods=[\"GET\"], detail=False)\n+    def dwh_scene_stats(self, request: Request, *arg: Any, **kwargs: Any):",
    "repo_full_name": "PostHog/posthog",
    "discussion_comments": [
      {
        "comment_id": "2276284218",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 36586,
        "pr_file": "posthog/warehouse/api/external_data_source.py",
        "discussion_id": "2276284218",
        "commented_code": "@@ -610,3 +613,63 @@ def wizard(self, request: Request, *arg: Any, **kwargs: Any):\n             status=status.HTTP_200_OK,\n             data={str(key): value.model_dump() for key, value in configs.items()},\n         )\n+\n+    @action(methods=[\"GET\"], detail=False)\n+    def dwh_scene_stats(self, request: Request, *arg: Any, **kwargs: Any):",
        "comment_created_at": "2025-08-14T10:53:42+00:00",
        "comment_author": "Gilbert09",
        "comment_body": "Nit: can we not include this in the `external_data_source` API viewset, please? Ideally, our viewsets should be RESTful in the sense that they relate to \"objects\" - we're trying to fudge this aggregation endpoint in a place that doesn't make much sense. I'd opt for a new api endpoint like`/api/data_warehouse`",
        "pr_file_module": null
      },
      {
        "comment_id": "2276746510",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 36586,
        "pr_file": "posthog/warehouse/api/external_data_source.py",
        "discussion_id": "2276284218",
        "commented_code": "@@ -610,3 +613,63 @@ def wizard(self, request: Request, *arg: Any, **kwargs: Any):\n             status=status.HTTP_200_OK,\n             data={str(key): value.model_dump() for key, value in configs.items()},\n         )\n+\n+    @action(methods=[\"GET\"], detail=False)\n+    def dwh_scene_stats(self, request: Request, *arg: Any, **kwargs: Any):",
        "comment_created_at": "2025-08-14T14:07:49+00:00",
        "comment_author": "naumaanh",
        "comment_body": "yes! i can move this into a new file. that makes more sense as most likely multiple other endpoints will need to be registered as well!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2276290936",
    "pr_number": 36586,
    "pr_file": "posthog/warehouse/api/external_data_source.py",
    "created_at": "2025-08-14T10:56:50+00:00",
    "commented_code": "status=status.HTTP_200_OK,\n             data={str(key): value.model_dump() for key, value in configs.items()},\n         )\n+\n+    @action(methods=[\"GET\"], detail=False)\n+    def dwh_scene_stats(self, request: Request, *arg: Any, **kwargs: Any):\n+        \"\"\"\n+        Returns aggregated statistics for the data warehouse scene including total rows processed.\n+        Used by the frontend data warehouse scene to display usage information.\n+        \"\"\"\n+        billing_interval = \"\"\n+        rows_synced = 0\n+        data_modeling_rows = 0\n+\n+        try:\n+            billing_manager = BillingManager(get_cached_instance_license())\n+            org_billing = billing_manager.get_billing(organization=self.team.organization)\n+\n+            if org_billing and org_billing.get(\"billing_period\"):\n+                billing_period = org_billing[\"billing_period\"]\n+                billing_period_start = parser.parse(billing_period[\"current_period_start\"])\n+                billing_period_end = parser.parse(billing_period[\"current_period_end\"])\n+                billing_interval = billing_period.get(\"interval\", \"month\")\n+\n+                usage_summary = org_billing.get(\"usage_summary\", {})\n+                billing_tracked_rows = usage_summary.get(\"rows_synced\", {}).get(\"usage\", 0)\n+\n+                all_external_jobs = ExternalDataJob.objects.filter(\n+                    team_id=self.team_id,\n+                    created_at__gte=billing_period_start,\n+                    created_at__lt=billing_period_end,\n+                    billable=True,\n+                )\n+                total_db_rows = all_external_jobs.aggregate(total=Sum(\"rows_synced\"))[\"total\"] or 0\n+\n+                pending_billing_rows = max(0, total_db_rows - billing_tracked_rows)\n+\n+                rows_synced = billing_tracked_rows + pending_billing_rows\n+\n+                data_modeling_jobs = DataModelingJob.objects.filter(\n+                    team_id=self.team_id,\n+                    created_at__gte=billing_period_start,\n+                    created_at__lt=billing_period_end,\n+                )\n+                data_modeling_rows = data_modeling_jobs.aggregate(total=Sum(\"rows_materialized\"))[\"total\"] or 0\n+\n+        except Exception as e:\n+            logger.exception(\"Could not retrieve billing information\", exc_info=e)\n+\n+        return Response(\n+            status=status.HTTP_200_OK,\n+            data={\n+                \"billingInterval\": billing_interval,\n+                \"externalData\": {\n+                    \"billingPeriodEnd\": billing_period_end,\n+                    \"billingPeriodStart\": billing_period_start,\n+                    \"dataModelingRows\": data_modeling_rows,\n+                    \"trackedBillingRows\": billing_tracked_rows,\n+                    \"pendingBillingRows\": pending_billing_rows,\n+                    \"totalRows\": rows_synced,\n+                },\n+            },",
    "repo_full_name": "PostHog/posthog",
    "discussion_comments": [
      {
        "comment_id": "2276290936",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 36586,
        "pr_file": "posthog/warehouse/api/external_data_source.py",
        "discussion_id": "2276290936",
        "commented_code": "@@ -610,3 +613,63 @@ def wizard(self, request: Request, *arg: Any, **kwargs: Any):\n             status=status.HTTP_200_OK,\n             data={str(key): value.model_dump() for key, value in configs.items()},\n         )\n+\n+    @action(methods=[\"GET\"], detail=False)\n+    def dwh_scene_stats(self, request: Request, *arg: Any, **kwargs: Any):\n+        \"\"\"\n+        Returns aggregated statistics for the data warehouse scene including total rows processed.\n+        Used by the frontend data warehouse scene to display usage information.\n+        \"\"\"\n+        billing_interval = \"\"\n+        rows_synced = 0\n+        data_modeling_rows = 0\n+\n+        try:\n+            billing_manager = BillingManager(get_cached_instance_license())\n+            org_billing = billing_manager.get_billing(organization=self.team.organization)\n+\n+            if org_billing and org_billing.get(\"billing_period\"):\n+                billing_period = org_billing[\"billing_period\"]\n+                billing_period_start = parser.parse(billing_period[\"current_period_start\"])\n+                billing_period_end = parser.parse(billing_period[\"current_period_end\"])\n+                billing_interval = billing_period.get(\"interval\", \"month\")\n+\n+                usage_summary = org_billing.get(\"usage_summary\", {})\n+                billing_tracked_rows = usage_summary.get(\"rows_synced\", {}).get(\"usage\", 0)\n+\n+                all_external_jobs = ExternalDataJob.objects.filter(\n+                    team_id=self.team_id,\n+                    created_at__gte=billing_period_start,\n+                    created_at__lt=billing_period_end,\n+                    billable=True,\n+                )\n+                total_db_rows = all_external_jobs.aggregate(total=Sum(\"rows_synced\"))[\"total\"] or 0\n+\n+                pending_billing_rows = max(0, total_db_rows - billing_tracked_rows)\n+\n+                rows_synced = billing_tracked_rows + pending_billing_rows\n+\n+                data_modeling_jobs = DataModelingJob.objects.filter(\n+                    team_id=self.team_id,\n+                    created_at__gte=billing_period_start,\n+                    created_at__lt=billing_period_end,\n+                )\n+                data_modeling_rows = data_modeling_jobs.aggregate(total=Sum(\"rows_materialized\"))[\"total\"] or 0\n+\n+        except Exception as e:\n+            logger.exception(\"Could not retrieve billing information\", exc_info=e)\n+\n+        return Response(\n+            status=status.HTTP_200_OK,\n+            data={\n+                \"billingInterval\": billing_interval,\n+                \"externalData\": {\n+                    \"billingPeriodEnd\": billing_period_end,\n+                    \"billingPeriodStart\": billing_period_start,\n+                    \"dataModelingRows\": data_modeling_rows,\n+                    \"trackedBillingRows\": billing_tracked_rows,\n+                    \"pendingBillingRows\": pending_billing_rows,\n+                    \"totalRows\": rows_synced,\n+                },\n+            },",
        "comment_created_at": "2025-08-14T10:56:50+00:00",
        "comment_author": "Gilbert09",
        "comment_body": "This response doesn't conform to what you're expecting in the frontend:\r\n```typescipt\r\nPromise<{\r\n    billingInterval: string\r\n    billingPeriodEnd: string\r\n    billingPeriodStart: string\r\n    dataModelingRows: number\r\n    externalData: {\r\n        billingTrackedRows: number\r\n        pendingBillingRows: number\r\n        totalRows: number\r\n    }\r\n}>\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2191021252",
    "pr_number": 34580,
    "pr_file": "posthog/session_recordings/session_recording_api.py",
    "created_at": "2025-07-07T21:13:51+00:00",
    "commented_code": "recording.deleted = True\n         recording.save()\n \n+        # Also need to remove from playlist items if it's in one\n+        SessionRecordingPlaylistItem.objects.filter(playlist__team=self.team, recording=recording).update(deleted=True)\n+\n         return Response({\"success\": True}, status=204)\n \n+    @extend_schema(exclude=True)\n+    def delete(self, request: request.Request, *args: Any, **kwargs: Any) -> Response:\n+        \"\"\"\n+        Bulk soft delete all recordings matching the provided filters.\n+        Always run asynchronously via Celery.\n+        \"\"\"\n+        user_distinct_id = cast(User, request.user).distinct_id\n+\n+        try:\n+            query = filter_from_params_to_query(request.GET.dict())",
    "repo_full_name": "PostHog/posthog",
    "discussion_comments": [
      {
        "comment_id": "2191021252",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 34580,
        "pr_file": "posthog/session_recordings/session_recording_api.py",
        "discussion_id": "2191021252",
        "commented_code": "@@ -652,8 +656,98 @@ def destroy(self, request: request.Request, *args: Any, **kwargs: Any) -> Respon\n         recording.deleted = True\n         recording.save()\n \n+        # Also need to remove from playlist items if it's in one\n+        SessionRecordingPlaylistItem.objects.filter(playlist__team=self.team, recording=recording).update(deleted=True)\n+\n         return Response({\"success\": True}, status=204)\n \n+    @extend_schema(exclude=True)\n+    def delete(self, request: request.Request, *args: Any, **kwargs: Any) -> Response:\n+        \"\"\"\n+        Bulk soft delete all recordings matching the provided filters.\n+        Always run asynchronously via Celery.\n+        \"\"\"\n+        user_distinct_id = cast(User, request.user).distinct_id\n+\n+        try:\n+            query = filter_from_params_to_query(request.GET.dict())",
        "comment_created_at": "2025-07-07T21:13:51+00:00",
        "comment_author": "pauldambra",
        "comment_body": "the query results could change between us displaying them in the browser and the async task running\r\n\r\nis that what people would want?\r\n\r\nshould we be sending a set of session ids?\r\nthere's a maximum size to a payload so that gives us an upper limit on how many can be requested for delete in one go.\r\n\r\nit makes me wonder if there's a real need for this UI / query step here - once we add it we have to support it and it's one more feature in the UI that is there for a very, very small proportion of vists\r\n\r\nif we only had a bulk delete API and folk could script against it, what would change here?\r\n\r\ni can't think of a time when that wouldn't have solved the support case... we can even have an example script that we can share with people to show what it would look like\r\n\r\ndeleting many recordings after all should be an exception\r\n\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2204239516",
    "pr_number": 33948,
    "pr_file": "posthog/api/survey.py",
    "created_at": "2025-07-14T08:43:03+00:00",
    "commented_code": "),\n         )\n \n+    # If survey_id is provided, return individual survey\n+    if survey_id:\n+        try:\n+            survey = Survey.objects.select_related(\"linked_flag\", \"targeting_flag\", \"internal_targeting_flag\").get(\n+                id=survey_id, team=team\n+            )\n+        except Survey.DoesNotExist:\n+            return cors_response(\n+                request,\n+                generate_exception_response(\n+                    \"surveys\",\n+                    \"Survey not found.\",\n+                    type=\"not_found\",\n+                    code=\"survey_not_found\",\n+                    status_code=status.HTTP_404_NOT_FOUND,\n+                ),\n+            )\n+\n+        # Check if survey is archived\n+        if survey.archived:\n+            return cors_response(\n+                request,\n+                generate_exception_response(\n+                    \"surveys\",\n+                    \"This survey is no longer available.\",\n+                    type=\"not_found\",\n+                    code=\"survey_archived\",\n+                    status_code=status.HTTP_404_NOT_FOUND,\n+                ),\n+            )\n+\n+        # Return individual survey response\n+        serialized_survey = SurveyAPISerializer(survey).data\n+        response_data = {\n+            \"survey\": serialized_survey,\n+            \"project_config\": {\n+                \"api_host\": request.build_absolute_uri(\"/\").rstrip(\"/\"),\n+                \"token\": team.api_token,\n+            },\n+        }\n+        return cors_response(request, JsonResponse(response_data))\n+\n+    # Return all surveys (existing behavior)\n     return cors_response(request, JsonResponse(get_surveys_response(team)))\n \n \n+# Constants for better maintainability\n+logger = structlog.get_logger(__name__)\n+SURVEY_ID_MAX_LENGTH = 50\n+CACHE_TIMEOUT_SECONDS = 300\n+\n+\n+def is_valid_uuid(uuid_string: str) -> bool:\n+    \"\"\"Validate if a string is a valid UUID format.\"\"\"\n+    try:\n+        uuid.UUID(uuid_string)\n+        return True\n+    except (ValueError, TypeError):\n+        return False\n+\n+\n+@csrf_exempt\n+@axes_dispatch\n+def public_survey_page(request, survey_id: str):",
    "repo_full_name": "PostHog/posthog",
    "discussion_comments": [
      {
        "comment_id": "2204239516",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 33948,
        "pr_file": "posthog/api/survey.py",
        "discussion_id": "2204239516",
        "commented_code": "@@ -1386,9 +1394,178 @@ def surveys(request: Request):\n             ),\n         )\n \n+    # If survey_id is provided, return individual survey\n+    if survey_id:\n+        try:\n+            survey = Survey.objects.select_related(\"linked_flag\", \"targeting_flag\", \"internal_targeting_flag\").get(\n+                id=survey_id, team=team\n+            )\n+        except Survey.DoesNotExist:\n+            return cors_response(\n+                request,\n+                generate_exception_response(\n+                    \"surveys\",\n+                    \"Survey not found.\",\n+                    type=\"not_found\",\n+                    code=\"survey_not_found\",\n+                    status_code=status.HTTP_404_NOT_FOUND,\n+                ),\n+            )\n+\n+        # Check if survey is archived\n+        if survey.archived:\n+            return cors_response(\n+                request,\n+                generate_exception_response(\n+                    \"surveys\",\n+                    \"This survey is no longer available.\",\n+                    type=\"not_found\",\n+                    code=\"survey_archived\",\n+                    status_code=status.HTTP_404_NOT_FOUND,\n+                ),\n+            )\n+\n+        # Return individual survey response\n+        serialized_survey = SurveyAPISerializer(survey).data\n+        response_data = {\n+            \"survey\": serialized_survey,\n+            \"project_config\": {\n+                \"api_host\": request.build_absolute_uri(\"/\").rstrip(\"/\"),\n+                \"token\": team.api_token,\n+            },\n+        }\n+        return cors_response(request, JsonResponse(response_data))\n+\n+    # Return all surveys (existing behavior)\n     return cors_response(request, JsonResponse(get_surveys_response(team)))\n \n \n+# Constants for better maintainability\n+logger = structlog.get_logger(__name__)\n+SURVEY_ID_MAX_LENGTH = 50\n+CACHE_TIMEOUT_SECONDS = 300\n+\n+\n+def is_valid_uuid(uuid_string: str) -> bool:\n+    \"\"\"Validate if a string is a valid UUID format.\"\"\"\n+    try:\n+        uuid.UUID(uuid_string)\n+        return True\n+    except (ValueError, TypeError):\n+        return False\n+\n+\n+@csrf_exempt\n+@axes_dispatch\n+def public_survey_page(request, survey_id: str):",
        "comment_created_at": "2025-07-14T08:43:03+00:00",
        "comment_author": "marandaneto",
        "comment_body": "how will we know who's answering the survey? is the link only for anonymous users?",
        "pr_file_module": null
      },
      {
        "comment_id": "2206145507",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 33948,
        "pr_file": "posthog/api/survey.py",
        "discussion_id": "2204239516",
        "commented_code": "@@ -1386,9 +1394,178 @@ def surveys(request: Request):\n             ),\n         )\n \n+    # If survey_id is provided, return individual survey\n+    if survey_id:\n+        try:\n+            survey = Survey.objects.select_related(\"linked_flag\", \"targeting_flag\", \"internal_targeting_flag\").get(\n+                id=survey_id, team=team\n+            )\n+        except Survey.DoesNotExist:\n+            return cors_response(\n+                request,\n+                generate_exception_response(\n+                    \"surveys\",\n+                    \"Survey not found.\",\n+                    type=\"not_found\",\n+                    code=\"survey_not_found\",\n+                    status_code=status.HTTP_404_NOT_FOUND,\n+                ),\n+            )\n+\n+        # Check if survey is archived\n+        if survey.archived:\n+            return cors_response(\n+                request,\n+                generate_exception_response(\n+                    \"surveys\",\n+                    \"This survey is no longer available.\",\n+                    type=\"not_found\",\n+                    code=\"survey_archived\",\n+                    status_code=status.HTTP_404_NOT_FOUND,\n+                ),\n+            )\n+\n+        # Return individual survey response\n+        serialized_survey = SurveyAPISerializer(survey).data\n+        response_data = {\n+            \"survey\": serialized_survey,\n+            \"project_config\": {\n+                \"api_host\": request.build_absolute_uri(\"/\").rstrip(\"/\"),\n+                \"token\": team.api_token,\n+            },\n+        }\n+        return cors_response(request, JsonResponse(response_data))\n+\n+    # Return all surveys (existing behavior)\n     return cors_response(request, JsonResponse(get_surveys_response(team)))\n \n \n+# Constants for better maintainability\n+logger = structlog.get_logger(__name__)\n+SURVEY_ID_MAX_LENGTH = 50\n+CACHE_TIMEOUT_SECONDS = 300\n+\n+\n+def is_valid_uuid(uuid_string: str) -> bool:\n+    \"\"\"Validate if a string is a valid UUID format.\"\"\"\n+    try:\n+        uuid.UUID(uuid_string)\n+        return True\n+    except (ValueError, TypeError):\n+        return False\n+\n+\n+@csrf_exempt\n+@axes_dispatch\n+def public_survey_page(request, survey_id: str):",
        "comment_created_at": "2025-07-15T02:25:02+00:00",
        "comment_author": "lucasheriques",
        "comment_body": "for now we don't have a way to identifying users. I think we should merge this code as is, at least regarding identification, and I'll work on it as a fast follow regardless",
        "pr_file_module": null
      },
      {
        "comment_id": "2207419458",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 33948,
        "pr_file": "posthog/api/survey.py",
        "discussion_id": "2204239516",
        "commented_code": "@@ -1386,9 +1394,178 @@ def surveys(request: Request):\n             ),\n         )\n \n+    # If survey_id is provided, return individual survey\n+    if survey_id:\n+        try:\n+            survey = Survey.objects.select_related(\"linked_flag\", \"targeting_flag\", \"internal_targeting_flag\").get(\n+                id=survey_id, team=team\n+            )\n+        except Survey.DoesNotExist:\n+            return cors_response(\n+                request,\n+                generate_exception_response(\n+                    \"surveys\",\n+                    \"Survey not found.\",\n+                    type=\"not_found\",\n+                    code=\"survey_not_found\",\n+                    status_code=status.HTTP_404_NOT_FOUND,\n+                ),\n+            )\n+\n+        # Check if survey is archived\n+        if survey.archived:\n+            return cors_response(\n+                request,\n+                generate_exception_response(\n+                    \"surveys\",\n+                    \"This survey is no longer available.\",\n+                    type=\"not_found\",\n+                    code=\"survey_archived\",\n+                    status_code=status.HTTP_404_NOT_FOUND,\n+                ),\n+            )\n+\n+        # Return individual survey response\n+        serialized_survey = SurveyAPISerializer(survey).data\n+        response_data = {\n+            \"survey\": serialized_survey,\n+            \"project_config\": {\n+                \"api_host\": request.build_absolute_uri(\"/\").rstrip(\"/\"),\n+                \"token\": team.api_token,\n+            },\n+        }\n+        return cors_response(request, JsonResponse(response_data))\n+\n+    # Return all surveys (existing behavior)\n     return cors_response(request, JsonResponse(get_surveys_response(team)))\n \n \n+# Constants for better maintainability\n+logger = structlog.get_logger(__name__)\n+SURVEY_ID_MAX_LENGTH = 50\n+CACHE_TIMEOUT_SECONDS = 300\n+\n+\n+def is_valid_uuid(uuid_string: str) -> bool:\n+    \"\"\"Validate if a string is a valid UUID format.\"\"\"\n+    try:\n+        uuid.UUID(uuid_string)\n+        return True\n+    except (ValueError, TypeError):\n+        return False\n+\n+\n+@csrf_exempt\n+@axes_dispatch\n+def public_survey_page(request, survey_id: str):",
        "comment_created_at": "2025-07-15T13:02:40+00:00",
        "comment_author": "marandaneto",
        "comment_body": "is the current API and approach extendable for identified users in the near feature? or will we need to break links?",
        "pr_file_module": null
      },
      {
        "comment_id": "2208621256",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 33948,
        "pr_file": "posthog/api/survey.py",
        "discussion_id": "2204239516",
        "commented_code": "@@ -1386,9 +1394,178 @@ def surveys(request: Request):\n             ),\n         )\n \n+    # If survey_id is provided, return individual survey\n+    if survey_id:\n+        try:\n+            survey = Survey.objects.select_related(\"linked_flag\", \"targeting_flag\", \"internal_targeting_flag\").get(\n+                id=survey_id, team=team\n+            )\n+        except Survey.DoesNotExist:\n+            return cors_response(\n+                request,\n+                generate_exception_response(\n+                    \"surveys\",\n+                    \"Survey not found.\",\n+                    type=\"not_found\",\n+                    code=\"survey_not_found\",\n+                    status_code=status.HTTP_404_NOT_FOUND,\n+                ),\n+            )\n+\n+        # Check if survey is archived\n+        if survey.archived:\n+            return cors_response(\n+                request,\n+                generate_exception_response(\n+                    \"surveys\",\n+                    \"This survey is no longer available.\",\n+                    type=\"not_found\",\n+                    code=\"survey_archived\",\n+                    status_code=status.HTTP_404_NOT_FOUND,\n+                ),\n+            )\n+\n+        # Return individual survey response\n+        serialized_survey = SurveyAPISerializer(survey).data\n+        response_data = {\n+            \"survey\": serialized_survey,\n+            \"project_config\": {\n+                \"api_host\": request.build_absolute_uri(\"/\").rstrip(\"/\"),\n+                \"token\": team.api_token,\n+            },\n+        }\n+        return cors_response(request, JsonResponse(response_data))\n+\n+    # Return all surveys (existing behavior)\n     return cors_response(request, JsonResponse(get_surveys_response(team)))\n \n \n+# Constants for better maintainability\n+logger = structlog.get_logger(__name__)\n+SURVEY_ID_MAX_LENGTH = 50\n+CACHE_TIMEOUT_SECONDS = 300\n+\n+\n+def is_valid_uuid(uuid_string: str) -> bool:\n+    \"\"\"Validate if a string is a valid UUID format.\"\"\"\n+    try:\n+        uuid.UUID(uuid_string)\n+        return True\n+    except (ValueError, TypeError):\n+        return False\n+\n+\n+@csrf_exempt\n+@axes_dispatch\n+def public_survey_page(request, survey_id: str):",
        "comment_created_at": "2025-07-15T20:38:31+00:00",
        "comment_author": "lucasheriques",
        "comment_body": "i just tested it, for now it's a very simple thing: just add a query parameter, `distinct_id`, [and use that for identifying users](https://github.com/PostHog/posthog/pull/33948/files#diff-fdea57bef4ea1f195c8313118abe5b886b35d55386ec5d1d57abee11d1c9a5a2R903-R906). just tested and it worked fine \ud83d\ude4f \r\n\r\nthough in the future we might extend this by instead asking the user to provide something like their email directly.\r\n\r\nNo need for breaking links, as url will forever be `external_surveys`",
        "pr_file_module": null
      }
    ]
  }
]