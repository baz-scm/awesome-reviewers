[
  {
    "discussion_id": "2027343712",
    "pr_number": 30764,
    "pr_file": "posthog/settings/session_replay.py",
    "created_at": "2025-04-03T16:13:54+00:00",
    "commented_code": "# intended to allow testing of new releases of rrweb or our lazy loaded recording script\n SESSION_REPLAY_RRWEB_SCRIPT = get_from_env(\"SESSION_REPLAY_RRWEB_SCRIPT\", None, optional=True)\n \n-# a list of teams that are allowed to use the SESSION_REPLAY_RRWEB_SCRIPT\n-# can be a comma separated list of team ids or '*' to allow all teams\n-SESSION_REPLAY_RRWEB_SCRIPT_ALLOWED_TEAMS = get_list(get_from_env(\"SESSION_REPLAY_RRWEB_SCRIPT_ALLOWED_TEAMS\", \"\"))\n+# can be * for all teams or a number to limit to any team with an id less than the number\n+SESSION_REPLAY_RRWEB_SCRIPT_MAX_ALLOWED_TEAMS = get_from_env(\"SESSION_REPLAY_RRWEB_SCRIPT_MAX_ALLOWED_TEAMS\", \"-1\")",
    "repo_full_name": "PostHog/posthog",
    "discussion_comments": [
      {
        "comment_id": "2027343712",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 30764,
        "pr_file": "posthog/settings/session_replay.py",
        "discussion_id": "2027343712",
        "commented_code": "@@ -37,9 +37,8 @@\n # intended to allow testing of new releases of rrweb or our lazy loaded recording script\n SESSION_REPLAY_RRWEB_SCRIPT = get_from_env(\"SESSION_REPLAY_RRWEB_SCRIPT\", None, optional=True)\n \n-# a list of teams that are allowed to use the SESSION_REPLAY_RRWEB_SCRIPT\n-# can be a comma separated list of team ids or '*' to allow all teams\n-SESSION_REPLAY_RRWEB_SCRIPT_ALLOWED_TEAMS = get_list(get_from_env(\"SESSION_REPLAY_RRWEB_SCRIPT_ALLOWED_TEAMS\", \"\"))\n+# can be * for all teams or a number to limit to any team with an id less than the number\n+SESSION_REPLAY_RRWEB_SCRIPT_MAX_ALLOWED_TEAMS = get_from_env(\"SESSION_REPLAY_RRWEB_SCRIPT_MAX_ALLOWED_TEAMS\", \"-1\")",
        "comment_created_at": "2025-04-03T16:13:54+00:00",
        "comment_author": "pauldambra",
        "comment_body": "i went for above and below a fixed team number\r\nwe could do something like the session id hashing in posthog-js for a repeatable above or below a sample rate but this felt simpler",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2273215707",
    "pr_number": 36283,
    "pr_file": "posthog/models/cohort/util.py",
    "created_at": "2025-08-13T12:08:09+00:00",
    "commented_code": "dfs(cohort_id, seen, sorted_cohort_ids)\n \n     return sorted_cohort_ids\n+\n+\n+def get_dependent_cohorts_reverse(\n+    cohort: Cohort,\n+    using_database: str = \"default\",\n+) -> list[Cohort]:\n+    \"\"\"\n+    Get cohorts that depend on the given cohort (reverse dependencies).\n+    This is the opposite of get_dependent_cohorts - it finds cohorts that reference this one.\n+    \"\"\"\n+    from posthog.models.cohort.cohort import Cohort\n+    from django.db.models import Q\n+\n+    # Use database-level JSON query to filter cohorts that reference this one\n+    # This is much more efficient than loading all cohorts and checking in Python\n+    cohort_id_str = str(cohort.id)\n+\n+    # Build a query that checks if the filters JSON contains references to our cohort\n+    # We check both the new filters format and legacy groups format\n+    filter_conditions = Q()\n+\n+    # Check for cohort references in filters.properties structure\n+    filter_conditions |= Q(filters__icontains=f'\"value\": {cohort.id}')\n+    filter_conditions |= Q(filters__icontains=f'\"value\": \"{cohort_id_str}\"')\n+\n+    # Also check legacy groups format for backward compatibility\n+    filter_conditions |= Q(groups__icontains=f'\"value\": {cohort.id}')\n+    filter_conditions |= Q(groups__icontains=f'\"value\": \"{cohort_id_str}\"')\n+\n+    # Get potentially dependent cohorts using database filtering\n+    candidate_cohorts = (\n+        Cohort.objects.db_manager(using_database)\n+        .filter(filter_conditions, team=cohort.team, deleted=False)\n+        .exclude(id=cohort.id)\n+    )\n+\n+    dependent_cohorts = []\n+\n+    # Now verify the matches (since JSON icontains can have false positives)\n+    for candidate_cohort in candidate_cohorts:\n+        # Check if this cohort actually references our target cohort\n+        for prop in candidate_cohort.properties.flat:\n+            if prop.type == \"cohort\" and not isinstance(prop.value, list):\n+                try:\n+                    referenced_cohort_id = int(prop.value)\n+                    if referenced_cohort_id == cohort.id:\n+                        dependent_cohorts.append(candidate_cohort)\n+                        break  # Found dependency, no need to check more properties\n+                except (ValueError, TypeError):\n+                    continue\n+\n+    return dependent_cohorts\n+\n+\n+def get_minimum_required_type_for_dependency(dependency_type: str, current_type: str) -> str:\n+    \"\"\"\n+    Determine the minimum required cohort type when a dependency changes type.\n+\n+    Args:\n+        dependency_type: The new type of the dependency\n+        current_type: The current type of the dependent cohort\n+\n+    Returns:\n+        The minimum required type for the dependent cohort\n+    \"\"\"\n+    type_hierarchy = {\n+        \"static\": 0,\n+        \"person_property\": 1,\n+        \"behavioral\": 2,\n+        \"analytical\": 3,\n+    }\n+\n+    dependency_level = type_hierarchy.get(dependency_type, 3)\n+    current_level = type_hierarchy.get(current_type, 0)\n+\n+    # The dependent cohort must be at least as complex as its dependencies\n+    required_level = max(dependency_level, current_level)\n+\n+    # Convert back to type string\n+    level_to_type = {v: k for k, v in type_hierarchy.items()}\n+    return level_to_type.get(required_level, \"analytical\")",
    "repo_full_name": "PostHog/posthog",
    "discussion_comments": [
      {
        "comment_id": "2273215707",
        "repo_full_name": "PostHog/posthog",
        "pr_number": 36283,
        "pr_file": "posthog/models/cohort/util.py",
        "discussion_id": "2273215707",
        "commented_code": "@@ -586,3 +586,140 @@ def dfs(node, seen, sorted_arr):\n             dfs(cohort_id, seen, sorted_cohort_ids)\n \n     return sorted_cohort_ids\n+\n+\n+def get_dependent_cohorts_reverse(\n+    cohort: Cohort,\n+    using_database: str = \"default\",\n+) -> list[Cohort]:\n+    \"\"\"\n+    Get cohorts that depend on the given cohort (reverse dependencies).\n+    This is the opposite of get_dependent_cohorts - it finds cohorts that reference this one.\n+    \"\"\"\n+    from posthog.models.cohort.cohort import Cohort\n+    from django.db.models import Q\n+\n+    # Use database-level JSON query to filter cohorts that reference this one\n+    # This is much more efficient than loading all cohorts and checking in Python\n+    cohort_id_str = str(cohort.id)\n+\n+    # Build a query that checks if the filters JSON contains references to our cohort\n+    # We check both the new filters format and legacy groups format\n+    filter_conditions = Q()\n+\n+    # Check for cohort references in filters.properties structure\n+    filter_conditions |= Q(filters__icontains=f'\"value\": {cohort.id}')\n+    filter_conditions |= Q(filters__icontains=f'\"value\": \"{cohort_id_str}\"')\n+\n+    # Also check legacy groups format for backward compatibility\n+    filter_conditions |= Q(groups__icontains=f'\"value\": {cohort.id}')\n+    filter_conditions |= Q(groups__icontains=f'\"value\": \"{cohort_id_str}\"')\n+\n+    # Get potentially dependent cohorts using database filtering\n+    candidate_cohorts = (\n+        Cohort.objects.db_manager(using_database)\n+        .filter(filter_conditions, team=cohort.team, deleted=False)\n+        .exclude(id=cohort.id)\n+    )\n+\n+    dependent_cohorts = []\n+\n+    # Now verify the matches (since JSON icontains can have false positives)\n+    for candidate_cohort in candidate_cohorts:\n+        # Check if this cohort actually references our target cohort\n+        for prop in candidate_cohort.properties.flat:\n+            if prop.type == \"cohort\" and not isinstance(prop.value, list):\n+                try:\n+                    referenced_cohort_id = int(prop.value)\n+                    if referenced_cohort_id == cohort.id:\n+                        dependent_cohorts.append(candidate_cohort)\n+                        break  # Found dependency, no need to check more properties\n+                except (ValueError, TypeError):\n+                    continue\n+\n+    return dependent_cohorts\n+\n+\n+def get_minimum_required_type_for_dependency(dependency_type: str, current_type: str) -> str:\n+    \"\"\"\n+    Determine the minimum required cohort type when a dependency changes type.\n+\n+    Args:\n+        dependency_type: The new type of the dependency\n+        current_type: The current type of the dependent cohort\n+\n+    Returns:\n+        The minimum required type for the dependent cohort\n+    \"\"\"\n+    type_hierarchy = {\n+        \"static\": 0,\n+        \"person_property\": 1,\n+        \"behavioral\": 2,\n+        \"analytical\": 3,\n+    }\n+\n+    dependency_level = type_hierarchy.get(dependency_type, 3)\n+    current_level = type_hierarchy.get(current_type, 0)\n+\n+    # The dependent cohort must be at least as complex as its dependencies\n+    required_level = max(dependency_level, current_level)\n+\n+    # Convert back to type string\n+    level_to_type = {v: k for k, v in type_hierarchy.items()}\n+    return level_to_type.get(required_level, \"analytical\")",
        "comment_created_at": "2025-08-13T12:08:09+00:00",
        "comment_author": "meikelmosby",
        "comment_body": "this is pretty hard to parse.. can we type it and also maybe structure it a bit neater like\n\n```\n// possibly a type already exists somewhere .. \nCohortType = Literal[\"static\", \"person_property\", \"behavioral\", \"analytical\"]\n\ndef get_minimum_required_type_for_dependency(\n    dependency_type: CohortType,\n    current_type: CohortType\n) -> CohortType:\n    \"\"\"\n    Determine the minimum required cohort type when a dependency changes type.\n\n    Ensures the dependent cohort is at least as complex as the dependency.\n\n    Args:\n        dependency_type: The new type of the dependency\n        current_type: The current type of the dependent cohort\n\n    Returns:\n        The minimum required type for the dependent cohort\n    \"\"\"\n    type_hierarchy: Dict[CohortType, int] = {\n        \"static\": 0,\n        \"person_property\": 1,\n        \"behavioral\": 2,\n        \"analytical\": 3,\n    }\n\n    level_to_type: Dict[int, CohortType] = {level: type_name for type_name, level in type_hierarchy.items()}\n\n    dependency_level: int = type_hierarchy[dependency_type]\n    current_level: int = type_hierarchy[current_type]\n\n    required_level: int = max(dependency_level, current_level)\n\n    return level_to_type[required_level]\n```\n\nthat way we also dont need the fallbacks or so bc we should only be able to pass in known types, no?",
        "pr_file_module": null
      }
    ]
  }
]