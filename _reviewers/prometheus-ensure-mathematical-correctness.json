[
  {
    "discussion_id": "2157225305",
    "pr_number": 16330,
    "pr_file": "promql/promqltest/testdata/native_histograms.test",
    "created_at": "2025-06-19T14:55:58+00:00",
    "commented_code": "{} {{schema:0 count:-30 sum:-1111.1 z_bucket:-2 z_bucket_w:0.001 buckets:[-1 0 -1 -2 -1 -1 -1] n_buckets:[0 2 -2 -2 -7 0 0 0 0 -5 -5 -2]}}\n \n clear\n+\n+# Test native histogram with trim operators (\"</\": TRIM_UPPER, \">/\": TRIM_LOWER)\n+load 1m\n+  h_test {{schema:0 count:34 z_bucket:1 z_bucket_w:0.001 buckets:[2 4 8 16] n_buckets:[1 2]}} \n+  h_test_2 {{schema:2 count:27 z_bucket:1 z_bucket_w:0.001 buckets:[1 2 4 7 3] n_buckets:[1 5 3 1]}}\n+  cbh {{schema:-53 sum:5 count:15 custom_values:[5 10 15 20] buckets:[1 6 4 3 1]}}\n+  zero_bucket {{schema:0 z_bucket:5 z_bucket_w:0.01 buckets:[2 3] n_buckets:[1 2 3]}}",
    "repo_full_name": "prometheus/prometheus",
    "discussion_comments": [
      {
        "comment_id": "2157225305",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 16330,
        "pr_file": "promql/promqltest/testdata/native_histograms.test",
        "discussion_id": "2157225305",
        "commented_code": "@@ -1319,3 +1319,60 @@ eval instant at 10m histogram_sub_3{idx=\"0\"} - ignoring(idx) histogram_sub_3{idx\n     {} {{schema:0 count:-30 sum:-1111.1 z_bucket:-2 z_bucket_w:0.001 buckets:[-1 0 -1 -2 -1 -1 -1] n_buckets:[0 2 -2 -2 -7 0 0 0 0 -5 -5 -2]}}\n \n clear\n+\n+# Test native histogram with trim operators (\"</\": TRIM_UPPER, \">/\": TRIM_LOWER)\n+load 1m\n+  h_test {{schema:0 count:34 z_bucket:1 z_bucket_w:0.001 buckets:[2 4 8 16] n_buckets:[1 2]}} \n+  h_test_2 {{schema:2 count:27 z_bucket:1 z_bucket_w:0.001 buckets:[1 2 4 7 3] n_buckets:[1 5 3 1]}}\n+  cbh {{schema:-53 sum:5 count:15 custom_values:[5 10 15 20] buckets:[1 6 4 3 1]}}\n+  zero_bucket {{schema:0 z_bucket:5 z_bucket_w:0.01 buckets:[2 3] n_buckets:[1 2 3]}}",
        "comment_created_at": "2025-06-19T14:55:58+00:00",
        "comment_author": "beorn7",
        "comment_body": "To elaborate on my comment:\r\n\r\nThese should all have `sum:...` fields with plausible values.\r\n\r\n`cbd` already has a `sum:...` field, but its value is not plausible. If we assume that the observations are more or less in the middle of each bucket (and around 2.5 for the first bucket and not much above 20 for the +Inf bucket), the sum should be around 170.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2180608241",
    "pr_number": 16791,
    "pr_file": "promql/promqltest/testdata/native_histograms.test",
    "created_at": "2025-07-02T17:28:43+00:00",
    "commented_code": "expect info msg: PromQL info: input to histogram_fraction has NaN observations, which are excluded from all fractions for metric name \"histogram_nan\"\n     {case=\"100% NaNs\"} 0.0\n     {case=\"20% NaNs\"} 0.8\n+\n+clear\n+\n+# Carefully chosen interval and range so that the zero point of the count is inside the\n+# interpolation period.\n+load 1m\n+  metric {{schema:0 count:15.0 sum:25.0 buckets:[5 10]}} {{schema:0 count:2490.0 sum:75.0 buckets:[15 2475]}}x55\n+\n+eval instant at 55m increase(metric[90m])",
    "repo_full_name": "prometheus/prometheus",
    "discussion_comments": [
      {
        "comment_id": "2180608241",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 16791,
        "pr_file": "promql/promqltest/testdata/native_histograms.test",
        "discussion_id": "2180608241",
        "commented_code": "@@ -1373,3 +1373,14 @@ eval instant at 1m histogram_fraction(-Inf, +Inf, histogram_nan)\n     expect info msg: PromQL info: input to histogram_fraction has NaN observations, which are excluded from all fractions for metric name \"histogram_nan\"\n     {case=\"100% NaNs\"} 0.0\n     {case=\"20% NaNs\"} 0.8\n+\n+clear\n+\n+# Carefully chosen interval and range so that the zero point of the count is inside the\n+# interpolation period.\n+load 1m\n+  metric {{schema:0 count:15.0 sum:25.0 buckets:[5 10]}} {{schema:0 count:2490.0 sum:75.0 buckets:[15 2475]}}x55\n+\n+eval instant at 55m increase(metric[90m])",
        "comment_created_at": "2025-07-02T17:28:43+00:00",
        "comment_author": "beorn7",
        "comment_body": "Here the last sample in the range coincides with the boundary of the range. Let's change this to have something in between, e.g.\r\n```suggestion\r\neval instant at 54m30s increase(metric[90m])\r\n```\r\n\r\n(Spoiler: The values below change, but somehow the buckets still sum up to the count.)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2182649804",
    "pr_number": 16791,
    "pr_file": "promql/promqltest/testdata/native_histograms.test",
    "created_at": "2025-07-03T12:22:54+00:00",
    "commented_code": "expect info msg: PromQL info: input to histogram_fraction has NaN observations, which are excluded from all fractions for metric name \"histogram_nan\"\n     {case=\"100% NaNs\"} 0.0\n     {case=\"20% NaNs\"} 0.8\n+\n+clear\n+\n+# Carefully chosen interval and range so that the zero point of the count is inside the\n+# interpolation period.\n+load 1m\n+  metric {{schema:0 count:15.0 sum:25.0 buckets:[5 10]}} {{schema:0 count:2490.0 sum:75.0 buckets:[15 2475]}}x55\n+\n+eval instant at 55m increase(metric[90m])\n+  {} {{count:2490 sum:50.303030303030305 counter_reset_hint:gauge buckets:[15 2475]}}\n+# old result:    {} {{count:2497.5 sum:50.45454545454545 counter_reset_hint:gauge buckets:[10.09090909090909 2487.409090909091]}}",
    "repo_full_name": "prometheus/prometheus",
    "discussion_comments": [
      {
        "comment_id": "2182649804",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 16791,
        "pr_file": "promql/promqltest/testdata/native_histograms.test",
        "discussion_id": "2182649804",
        "commented_code": "@@ -1373,3 +1373,14 @@ eval instant at 1m histogram_fraction(-Inf, +Inf, histogram_nan)\n     expect info msg: PromQL info: input to histogram_fraction has NaN observations, which are excluded from all fractions for metric name \"histogram_nan\"\n     {case=\"100% NaNs\"} 0.0\n     {case=\"20% NaNs\"} 0.8\n+\n+clear\n+\n+# Carefully chosen interval and range so that the zero point of the count is inside the\n+# interpolation period.\n+load 1m\n+  metric {{schema:0 count:15.0 sum:25.0 buckets:[5 10]}} {{schema:0 count:2490.0 sum:75.0 buckets:[15 2475]}}x55\n+\n+eval instant at 55m increase(metric[90m])\n+  {} {{count:2490 sum:50.303030303030305 counter_reset_hint:gauge buckets:[15 2475]}}\n+# old result:    {} {{count:2497.5 sum:50.45454545454545 counter_reset_hint:gauge buckets:[10.09090909090909 2487.409090909091]}}",
        "comment_created_at": "2025-07-03T12:22:54+00:00",
        "comment_author": "beorn7",
        "comment_body": "For the record, here I have replaced the tests with the one from #16825, including enlightening comments. I think this demonstrates the benefits and problems of this POC quite well.\r\n\r\n```suggestion\r\n# Tests to demonstrate how an extrapolation below zero is prevented for both float counters and native histograms.\r\n# (The float counter result and the resulting count of the histogram is the same.)\r\n\r\nload 1m\r\n  metric{type=\"histogram\"} {{schema:0 count:15 sum:25 buckets:[5 10]}} {{schema:0 count:2490 sum:75 buckets:[15 2475]}}x55\r\n  metric{type=\"counter\"} 15 2490x55\r\n\r\n# End of range coincides with sample. Zero point of count is reached within the range.\r\neval instant at 55m increase(metric[90m])\r\n    {type=\"histogram\"} {{count:2490 sum:50.303030303030305 counter_reset_hint:gauge buckets:[15 2475]}}\r\n    {type=\"counter\"} 2490\r\n\r\n# End of range does not coincide with sample. Zero point of count is reached within the range.\r\neval instant at 54m30s increase(metric[90m])\r\n    {type=\"histogram\"} {{count:2512.9166666666665 sum:50.76599326599326 counter_reset_hint:gauge buckets:[15.092592592592593 2497.8240740740744]}}\r\n    {type=\"counter\"} 2512.9166666666665\r\n    \r\n# End of range coincides with sample. Zero point of count is reached outside of (i.e. before) the range.\r\n# This means no change of extrapolation is required for the histogram count (and neither for the float counter),\r\n# however, the 2nd bucket's extrapolation will reach zero within the range. This is corrected here, but at the\r\n# price of an inconsistent histogram (the sum of the buckets is 2488.75 and not 2486.25).\r\neval instant at 55m increase(metric[55m15s])\r\n    {type=\"histogram\"} {{count:2486.25 sum:50.227272727272734 counter_reset_hint:gauge buckets:[13.75 2475]}}\r\n    {type=\"counter\"} 2486.25\r\n\r\n# End of range does not coincide with sample. Zero point of count is reached outside of (i.e. before) the range.\r\n# This means no change of extrapolation is required for the histogram count (and neither for the float counter),\r\n# however, the 2nd bucket's extrapolation will reach zero within the range. This is corrected here, but at the\r\n# price of an inconsistent histogram (the sum of the buckets is 2511.7361111111113 and not 2509.375).\r\neval instant at 54m30s increase(metric[54m45s])\r\n    {type=\"histogram\"} {{count:2509.375 sum:50.69444444444444 counter_reset_hint:gauge buckets:[13.912037037037038 2497.8240740740744]}}\r\n    {type=\"counter\"} 2509.375\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2167883819",
    "pr_number": 16773,
    "pr_file": "promql/promqltest/testdata/aggregators.test",
    "created_at": "2025-06-26T01:00:08+00:00",
    "commented_code": "clear\n \n+# Demonstrate robustness of direct mean calculation vs. incremental mean calculation.\n+# The tests below are prone to small inaccuracies with incremental mean calculation.\n+# The exact number of aggregated values that trigger an inaccuracy depends on the\n+# hardware.\n+# See also discussion in https://github.com/prometheus/prometheus/issues/16714\n+load 5m\n+  foo{idx=\"0\"} 52\n+  foo{idx=\"1\"} 52\n+  foo{idx=\"2\"} 52\n+  foo{idx=\"3\"} 52\n+  foo{idx=\"4\"} 52\n+  foo{idx=\"5\"} 52\n+  foo{idx=\"6\"} 52\n+  foo{idx=\"7\"} 52\n+  foo{idx=\"8\"} 52\n+  foo{idx=\"9\"} 52\n+  foo{idx=\"10\"} 52\n+  foo{idx=\"11\"} 52\n+\n+eval instant at 0 avg(foo) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(11, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(10, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(9, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(8, foo)) - 52\n+  {} 0",
    "repo_full_name": "prometheus/prometheus",
    "discussion_comments": [
      {
        "comment_id": "2167883819",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 16773,
        "pr_file": "promql/promqltest/testdata/aggregators.test",
        "discussion_id": "2167883819",
        "commented_code": "@@ -663,6 +661,42 @@ eval instant at 1m avg by (group) (data{test=\"nan\"})\n \n clear\n \n+# Demonstrate robustness of direct mean calculation vs. incremental mean calculation.\n+# The tests below are prone to small inaccuracies with incremental mean calculation.\n+# The exact number of aggregated values that trigger an inaccuracy depends on the\n+# hardware.\n+# See also discussion in https://github.com/prometheus/prometheus/issues/16714\n+load 5m\n+  foo{idx=\"0\"} 52\n+  foo{idx=\"1\"} 52\n+  foo{idx=\"2\"} 52\n+  foo{idx=\"3\"} 52\n+  foo{idx=\"4\"} 52\n+  foo{idx=\"5\"} 52\n+  foo{idx=\"6\"} 52\n+  foo{idx=\"7\"} 52\n+  foo{idx=\"8\"} 52\n+  foo{idx=\"9\"} 52\n+  foo{idx=\"10\"} 52\n+  foo{idx=\"11\"} 52\n+\n+eval instant at 0 avg(foo) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(11, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(10, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(9, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(8, foo)) - 52\n+  {} 0",
        "comment_created_at": "2025-06-26T01:00:08+00:00",
        "comment_author": "charleskorn",
        "comment_body": "Given that `promqltest` allows a small epsilon here when checking results, what about adding a test case like `avg(foo) - 52 == 0` or `avg(foo) == 52`? (We had some alert rules that use `avg` with conditions like that, which led to https://github.com/prometheus/prometheus/issues/16714#issuecomment-2998876794.)",
        "pr_file_module": null
      },
      {
        "comment_id": "2168662644",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 16773,
        "pr_file": "promql/promqltest/testdata/aggregators.test",
        "discussion_id": "2167883819",
        "commented_code": "@@ -663,6 +661,42 @@ eval instant at 1m avg by (group) (data{test=\"nan\"})\n \n clear\n \n+# Demonstrate robustness of direct mean calculation vs. incremental mean calculation.\n+# The tests below are prone to small inaccuracies with incremental mean calculation.\n+# The exact number of aggregated values that trigger an inaccuracy depends on the\n+# hardware.\n+# See also discussion in https://github.com/prometheus/prometheus/issues/16714\n+load 5m\n+  foo{idx=\"0\"} 52\n+  foo{idx=\"1\"} 52\n+  foo{idx=\"2\"} 52\n+  foo{idx=\"3\"} 52\n+  foo{idx=\"4\"} 52\n+  foo{idx=\"5\"} 52\n+  foo{idx=\"6\"} 52\n+  foo{idx=\"7\"} 52\n+  foo{idx=\"8\"} 52\n+  foo{idx=\"9\"} 52\n+  foo{idx=\"10\"} 52\n+  foo{idx=\"11\"} 52\n+\n+eval instant at 0 avg(foo) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(11, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(10, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(9, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(8, foo)) - 52\n+  {} 0",
        "comment_created_at": "2025-06-26T09:45:56+00:00",
        "comment_author": "bboreham",
        "comment_body": "Are you suggesting to check floating point values for exact equality without epsilon?",
        "pr_file_module": null
      },
      {
        "comment_id": "2169093701",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 16773,
        "pr_file": "promql/promqltest/testdata/aggregators.test",
        "discussion_id": "2167883819",
        "commented_code": "@@ -663,6 +661,42 @@ eval instant at 1m avg by (group) (data{test=\"nan\"})\n \n clear\n \n+# Demonstrate robustness of direct mean calculation vs. incremental mean calculation.\n+# The tests below are prone to small inaccuracies with incremental mean calculation.\n+# The exact number of aggregated values that trigger an inaccuracy depends on the\n+# hardware.\n+# See also discussion in https://github.com/prometheus/prometheus/issues/16714\n+load 5m\n+  foo{idx=\"0\"} 52\n+  foo{idx=\"1\"} 52\n+  foo{idx=\"2\"} 52\n+  foo{idx=\"3\"} 52\n+  foo{idx=\"4\"} 52\n+  foo{idx=\"5\"} 52\n+  foo{idx=\"6\"} 52\n+  foo{idx=\"7\"} 52\n+  foo{idx=\"8\"} 52\n+  foo{idx=\"9\"} 52\n+  foo{idx=\"10\"} 52\n+  foo{idx=\"11\"} 52\n+\n+eval instant at 0 avg(foo) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(11, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(10, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(9, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(8, foo)) - 52\n+  {} 0",
        "comment_created_at": "2025-06-26T13:35:19+00:00",
        "comment_author": "beorn7",
        "comment_body": "I think he is.\r\n\r\nAnd it even works because the direct mean calculation yields precise results in these cases. I have added those tests, with a comment that they have no tolerance. Should they trip at some point on some hardware, we know that they might not be tolerant enough.",
        "pr_file_module": null
      },
      {
        "comment_id": "2170342839",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 16773,
        "pr_file": "promql/promqltest/testdata/aggregators.test",
        "discussion_id": "2167883819",
        "commented_code": "@@ -663,6 +661,42 @@ eval instant at 1m avg by (group) (data{test=\"nan\"})\n \n clear\n \n+# Demonstrate robustness of direct mean calculation vs. incremental mean calculation.\n+# The tests below are prone to small inaccuracies with incremental mean calculation.\n+# The exact number of aggregated values that trigger an inaccuracy depends on the\n+# hardware.\n+# See also discussion in https://github.com/prometheus/prometheus/issues/16714\n+load 5m\n+  foo{idx=\"0\"} 52\n+  foo{idx=\"1\"} 52\n+  foo{idx=\"2\"} 52\n+  foo{idx=\"3\"} 52\n+  foo{idx=\"4\"} 52\n+  foo{idx=\"5\"} 52\n+  foo{idx=\"6\"} 52\n+  foo{idx=\"7\"} 52\n+  foo{idx=\"8\"} 52\n+  foo{idx=\"9\"} 52\n+  foo{idx=\"10\"} 52\n+  foo{idx=\"11\"} 52\n+\n+eval instant at 0 avg(foo) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(11, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(10, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(9, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(8, foo)) - 52\n+  {} 0",
        "comment_created_at": "2025-06-27T00:19:01+00:00",
        "comment_author": "charleskorn",
        "comment_body": ">Are you suggesting to check floating point values for exact equality without epsilon?\r\n\r\nYes, exactly. My rationale is that this is what happens when using `avg` with a comparison operator in alerting rules, so we should do the same in tests as well to match the experience users get.\r\n\r\n---\r\n\r\nI notice you've added these tests for `avg_over_time` @beorn7, did you mean to add some for `avg` as well?",
        "pr_file_module": null
      },
      {
        "comment_id": "2171661322",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 16773,
        "pr_file": "promql/promqltest/testdata/aggregators.test",
        "discussion_id": "2167883819",
        "commented_code": "@@ -663,6 +661,42 @@ eval instant at 1m avg by (group) (data{test=\"nan\"})\n \n clear\n \n+# Demonstrate robustness of direct mean calculation vs. incremental mean calculation.\n+# The tests below are prone to small inaccuracies with incremental mean calculation.\n+# The exact number of aggregated values that trigger an inaccuracy depends on the\n+# hardware.\n+# See also discussion in https://github.com/prometheus/prometheus/issues/16714\n+load 5m\n+  foo{idx=\"0\"} 52\n+  foo{idx=\"1\"} 52\n+  foo{idx=\"2\"} 52\n+  foo{idx=\"3\"} 52\n+  foo{idx=\"4\"} 52\n+  foo{idx=\"5\"} 52\n+  foo{idx=\"6\"} 52\n+  foo{idx=\"7\"} 52\n+  foo{idx=\"8\"} 52\n+  foo{idx=\"9\"} 52\n+  foo{idx=\"10\"} 52\n+  foo{idx=\"11\"} 52\n+\n+eval instant at 0 avg(foo) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(11, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(10, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(9, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(8, foo)) - 52\n+  {} 0",
        "comment_created_at": "2025-06-27T11:13:22+00:00",
        "comment_author": "bboreham",
        "comment_body": "In my book it's easier to remember the rule \"never compare floats for exact equality\".",
        "pr_file_module": null
      },
      {
        "comment_id": "2171935506",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 16773,
        "pr_file": "promql/promqltest/testdata/aggregators.test",
        "discussion_id": "2167883819",
        "commented_code": "@@ -663,6 +661,42 @@ eval instant at 1m avg by (group) (data{test=\"nan\"})\n \n clear\n \n+# Demonstrate robustness of direct mean calculation vs. incremental mean calculation.\n+# The tests below are prone to small inaccuracies with incremental mean calculation.\n+# The exact number of aggregated values that trigger an inaccuracy depends on the\n+# hardware.\n+# See also discussion in https://github.com/prometheus/prometheus/issues/16714\n+load 5m\n+  foo{idx=\"0\"} 52\n+  foo{idx=\"1\"} 52\n+  foo{idx=\"2\"} 52\n+  foo{idx=\"3\"} 52\n+  foo{idx=\"4\"} 52\n+  foo{idx=\"5\"} 52\n+  foo{idx=\"6\"} 52\n+  foo{idx=\"7\"} 52\n+  foo{idx=\"8\"} 52\n+  foo{idx=\"9\"} 52\n+  foo{idx=\"10\"} 52\n+  foo{idx=\"11\"} 52\n+\n+eval instant at 0 avg(foo) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(11, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(10, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(9, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(8, foo)) - 52\n+  {} 0",
        "comment_created_at": "2025-06-27T12:30:16+00:00",
        "comment_author": "beorn7",
        "comment_body": "I'll add avg tests, too.",
        "pr_file_module": null
      },
      {
        "comment_id": "2171946593",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 16773,
        "pr_file": "promql/promqltest/testdata/aggregators.test",
        "discussion_id": "2167883819",
        "commented_code": "@@ -663,6 +661,42 @@ eval instant at 1m avg by (group) (data{test=\"nan\"})\n \n clear\n \n+# Demonstrate robustness of direct mean calculation vs. incremental mean calculation.\n+# The tests below are prone to small inaccuracies with incremental mean calculation.\n+# The exact number of aggregated values that trigger an inaccuracy depends on the\n+# hardware.\n+# See also discussion in https://github.com/prometheus/prometheus/issues/16714\n+load 5m\n+  foo{idx=\"0\"} 52\n+  foo{idx=\"1\"} 52\n+  foo{idx=\"2\"} 52\n+  foo{idx=\"3\"} 52\n+  foo{idx=\"4\"} 52\n+  foo{idx=\"5\"} 52\n+  foo{idx=\"6\"} 52\n+  foo{idx=\"7\"} 52\n+  foo{idx=\"8\"} 52\n+  foo{idx=\"9\"} 52\n+  foo{idx=\"10\"} 52\n+  foo{idx=\"11\"} 52\n+\n+eval instant at 0 avg(foo) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(11, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(10, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(9, foo)) - 52\n+  {} 0\n+\n+eval instant at 0 avg(topk(8, foo)) - 52\n+  {} 0",
        "comment_created_at": "2025-06-27T12:32:46+00:00",
        "comment_author": "beorn7",
        "comment_body": "And I'll add @bboreham's \"never compare floats for exact equality\" rule to the comment.",
        "pr_file_module": null
      }
    ]
  }
]