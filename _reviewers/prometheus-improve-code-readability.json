[
  {
    "discussion_id": "1981813717",
    "pr_number": 15809,
    "pr_file": "util/treecache/treecache.go",
    "created_at": "2025-03-05T16:56:21+00:00",
    "commented_code": "}\n \n // NewZookeeperTreeCache creates a new ZookeeperTreeCache for a given path.\n-func NewZookeeperTreeCache(conn *zk.Conn, path string, events chan ZookeeperTreeCacheEvent, logger *slog.Logger) *ZookeeperTreeCache {\n+func NewZookeeperTreeCache(conn *zk.Conn, path string, events chan ZookeeperTreeCacheEvent, logger *slog.Logger, failureCounter prometheus.Counter, numWatchers prometheus.Gauge) *ZookeeperTreeCache {",
    "repo_full_name": "prometheus/prometheus",
    "discussion_comments": [
      {
        "comment_id": "1981813717",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 15809,
        "pr_file": "util/treecache/treecache.go",
        "discussion_id": "1981813717",
        "commented_code": "@@ -89,21 +72,22 @@ type zookeeperTreeCacheNode struct {\n }\n \n // NewZookeeperTreeCache creates a new ZookeeperTreeCache for a given path.\n-func NewZookeeperTreeCache(conn *zk.Conn, path string, events chan ZookeeperTreeCacheEvent, logger *slog.Logger) *ZookeeperTreeCache {\n+func NewZookeeperTreeCache(conn *zk.Conn, path string, events chan ZookeeperTreeCacheEvent, logger *slog.Logger, failureCounter prometheus.Counter, numWatchers prometheus.Gauge) *ZookeeperTreeCache {",
        "comment_created_at": "2025-03-05T16:56:21+00:00",
        "comment_author": "beorn7",
        "comment_body": "Let's break the overly long line, maybe like this:\r\n\r\n```suggestion\r\nfunc NewZookeeperTreeCache(\r\n\tconn *zk.Conn, path string, \r\n\tevents chan ZookeeperTreeCacheEvent, \r\n\tlogger *slog.Logger, \r\n\tfailureCounter prometheus.Counter, numWatchers prometheus.Gauge,\r\n) *ZookeeperTreeCache {\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1517978309",
    "pr_number": 9589,
    "pr_file": "scrape/manager.go",
    "created_at": "2024-03-08T16:47:13+00:00",
    "commented_code": "}\n \tm.mtxScrape.Unlock()\n \twg.Wait()\n+\n+\tm.warnIfTargetsRelabelledToSameLabels()\n+}\n+\n+func (m *Manager) warnIfTargetsRelabelledToSameLabels() {\n+\tactiveTargets := make(map[uint64]*Target)\n+\tfor _, scrapePool := range m.scrapePools {\n+\t\tfor _, target := range scrapePool.activeTargets {\n+\t\t\tif t, ok := activeTargets[target.labels.Hash()]; ok {",
    "repo_full_name": "prometheus/prometheus",
    "discussion_comments": [
      {
        "comment_id": "1517978309",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 9589,
        "pr_file": "scrape/manager.go",
        "discussion_id": "1517978309",
        "commented_code": "@@ -184,6 +185,25 @@ func (m *Manager) reload() {\n \t}\n \tm.mtxScrape.Unlock()\n \twg.Wait()\n+\n+\tm.warnIfTargetsRelabelledToSameLabels()\n+}\n+\n+func (m *Manager) warnIfTargetsRelabelledToSameLabels() {\n+\tactiveTargets := make(map[uint64]*Target)\n+\tfor _, scrapePool := range m.scrapePools {\n+\t\tfor _, target := range scrapePool.activeTargets {\n+\t\t\tif t, ok := activeTargets[target.labels.Hash()]; ok {",
        "comment_created_at": "2024-03-08T16:47:13+00:00",
        "comment_author": "GiedriusS",
        "comment_body": "Nit: I think we should return early.\r\n```\r\nt, ok := activeTargets[target.labels.Hash()]\r\nif !ok {\r\n  continue\r\n}\r\n\r\n... log here ...\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1518546597",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 9589,
        "pr_file": "scrape/manager.go",
        "discussion_id": "1517978309",
        "commented_code": "@@ -184,6 +185,25 @@ func (m *Manager) reload() {\n \t}\n \tm.mtxScrape.Unlock()\n \twg.Wait()\n+\n+\tm.warnIfTargetsRelabelledToSameLabels()\n+}\n+\n+func (m *Manager) warnIfTargetsRelabelledToSameLabels() {\n+\tactiveTargets := make(map[uint64]*Target)\n+\tfor _, scrapePool := range m.scrapePools {\n+\t\tfor _, target := range scrapePool.activeTargets {\n+\t\t\tif t, ok := activeTargets[target.labels.Hash()]; ok {",
        "comment_created_at": "2024-03-09T09:53:01+00:00",
        "comment_author": "darshanime",
        "comment_body": "updated, TFR!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1553202062",
    "pr_number": 13506,
    "pr_file": "model/textparse/openmetricsparse.go",
    "created_at": "2024-04-05T08:47:17+00:00",
    "commented_code": "return true\n }\n \n-// CreatedTimestamp returns nil as it's not implemented yet.\n-// TODO(bwplotka): https://github.com/prometheus/prometheus/issues/12980\n+// For OpenMetrics text, the created timestamp is exposed as it was an extra metric.\n+// The difference between an usual metric and the created timestamp is that for\n+// the created timestamp, the metric name ends with \"_created\".\n+//\n+// Created timestamps are always exposed right after the metric they are\n+// associated with. The parser cannot be used for such verification, so it is expected\n+// that the caller knows the order of the metrics and calls this function accordingly.\n func (p *OpenMetricsParser) CreatedTimestamp() *int64 {\n+\tif p.mtype == model.MetricTypeCounter ||",
    "repo_full_name": "prometheus/prometheus",
    "discussion_comments": [
      {
        "comment_id": "1553202062",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 13506,
        "pr_file": "model/textparse/openmetricsparse.go",
        "discussion_id": "1553202062",
        "commented_code": "@@ -219,9 +219,26 @@ func (p *OpenMetricsParser) Exemplar(e *exemplar.Exemplar) bool {\n \treturn true\n }\n \n-// CreatedTimestamp returns nil as it's not implemented yet.\n-// TODO(bwplotka): https://github.com/prometheus/prometheus/issues/12980\n+// For OpenMetrics text, the created timestamp is exposed as it was an extra metric.\n+// The difference between an usual metric and the created timestamp is that for\n+// the created timestamp, the metric name ends with \"_created\".\n+//\n+// Created timestamps are always exposed right after the metric they are\n+// associated with. The parser cannot be used for such verification, so it is expected\n+// that the caller knows the order of the metrics and calls this function accordingly.\n func (p *OpenMetricsParser) CreatedTimestamp() *int64 {\n+\tif p.mtype == model.MetricTypeCounter ||",
        "comment_created_at": "2024-04-05T08:47:17+00:00",
        "comment_author": "bwplotka",
        "comment_body": "Prefer less indent, in this case filtering out: https://thanos.io/tip/contributing/coding-style-guide.md/#control-structure-prefer-early-returns-and-avoid-else",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1925655610",
    "pr_number": 15687,
    "pr_file": "model/histogram/float_histogram.go",
    "created_at": "2025-01-22T16:51:47+00:00",
    "commented_code": "return spansA, bucketsA\n }\n \n+// kahanAddBuckets works like addBuckets but it is used in FloatHistogram's KahanAdd/KahanSub methods\n+// and takes an additional argument, bucketsC, representing buckets of the compensation histogram.\n+// It returns the resulting spans/buckets and compensation buckets.\n+func kahanAddBuckets(\n+\tschema int32, threshold float64, negative bool,\n+\tspansA []Span, bucketsA []float64,\n+\tspansB []Span, bucketsB []float64,\n+\tbucketsC []float64,\n+) ([]Span, []float64, []float64) {",
    "repo_full_name": "prometheus/prometheus",
    "discussion_comments": [
      {
        "comment_id": "1925655610",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 15687,
        "pr_file": "model/histogram/float_histogram.go",
        "discussion_id": "1925655610",
        "commented_code": "@@ -1325,6 +1535,138 @@ func addBuckets(\n \treturn spansA, bucketsA\n }\n \n+// kahanAddBuckets works like addBuckets but it is used in FloatHistogram's KahanAdd/KahanSub methods\n+// and takes an additional argument, bucketsC, representing buckets of the compensation histogram.\n+// It returns the resulting spans/buckets and compensation buckets.\n+func kahanAddBuckets(\n+\tschema int32, threshold float64, negative bool,\n+\tspansA []Span, bucketsA []float64,\n+\tspansB []Span, bucketsB []float64,\n+\tbucketsC []float64,\n+) ([]Span, []float64, []float64) {",
        "comment_created_at": "2025-01-22T16:51:47+00:00",
        "comment_author": "beorn7",
        "comment_body": "Again, named returns might be helpful.",
        "pr_file_module": null
      },
      {
        "comment_id": "1951341138",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 15687,
        "pr_file": "model/histogram/float_histogram.go",
        "discussion_id": "1925655610",
        "commented_code": "@@ -1325,6 +1535,138 @@ func addBuckets(\n \treturn spansA, bucketsA\n }\n \n+// kahanAddBuckets works like addBuckets but it is used in FloatHistogram's KahanAdd/KahanSub methods\n+// and takes an additional argument, bucketsC, representing buckets of the compensation histogram.\n+// It returns the resulting spans/buckets and compensation buckets.\n+func kahanAddBuckets(\n+\tschema int32, threshold float64, negative bool,\n+\tspansA []Span, bucketsA []float64,\n+\tspansB []Span, bucketsB []float64,\n+\tbucketsC []float64,\n+) ([]Span, []float64, []float64) {",
        "comment_created_at": "2025-02-11T18:06:19+00:00",
        "comment_author": "crush-on-anechka",
        "comment_body": "done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2193122326",
    "pr_number": 15833,
    "pr_file": "promql/parser/printer.go",
    "created_at": "2025-07-08T17:54:55+00:00",
    "commented_code": "func (node *BinaryExpr) getMatchingStr() string {\n \tmatching := \"\"\n \tvm := node.VectorMatching\n-\tif vm != nil && (len(vm.MatchingLabels) > 0 || vm.On) {\n-\t\tvmTag := \"ignoring\"\n-\t\tif vm.On {\n-\t\t\tvmTag = \"on\"\n-\t\t}\n-\t\tmatching = fmt.Sprintf(\" %s (%s)\", vmTag, strings.Join(vm.MatchingLabels, \", \"))\n-\n-\t\tif vm.Card == CardManyToOne || vm.Card == CardOneToMany {\n-\t\t\tvmCard := \"right\"\n-\t\t\tif vm.Card == CardManyToOne {\n-\t\t\t\tvmCard = \"left\"\n+\tif vm != nil {\n+\t\tif len(vm.MatchingLabels) > 0 || vm.On {",
    "repo_full_name": "prometheus/prometheus",
    "discussion_comments": [
      {
        "comment_id": "2193122326",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 15833,
        "pr_file": "promql/parser/printer.go",
        "discussion_id": "2193122326",
        "commented_code": "@@ -128,19 +128,24 @@ func (node *BinaryExpr) ShortString() string {\n func (node *BinaryExpr) getMatchingStr() string {\n \tmatching := \"\"\n \tvm := node.VectorMatching\n-\tif vm != nil && (len(vm.MatchingLabels) > 0 || vm.On) {\n-\t\tvmTag := \"ignoring\"\n-\t\tif vm.On {\n-\t\t\tvmTag = \"on\"\n-\t\t}\n-\t\tmatching = fmt.Sprintf(\" %s (%s)\", vmTag, strings.Join(vm.MatchingLabels, \", \"))\n-\n-\t\tif vm.Card == CardManyToOne || vm.Card == CardOneToMany {\n-\t\t\tvmCard := \"right\"\n-\t\t\tif vm.Card == CardManyToOne {\n-\t\t\t\tvmCard = \"left\"\n+\tif vm != nil {\n+\t\tif len(vm.MatchingLabels) > 0 || vm.On {",
        "comment_created_at": "2025-07-08T17:54:55+00:00",
        "comment_author": "ywwg",
        "comment_body": "was there a reason for removing the &&? The code seems equivalent and the new form implies that there might be an `else` below, though there is not.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2172206201",
    "pr_number": 16780,
    "pr_file": "tsdb/wlog/checkpoint.go",
    "created_at": "2025-06-27T14:45:53+00:00",
    "commented_code": "return filepath.Join(dir, checkpoint.name), checkpoint.index, nil\n }\n \n-// DeleteCheckpoints deletes all checkpoints in a directory below a given index.\n+// CheckpointPrefix is the prefix used for checkpoint files.\n+const CheckpointPrefix = \"checkpoint.\"\n+\n+// CheckpointTempFileSuffix is the suffix used when creating temporary checkpoint files.\n+const CheckpointTempFileSuffix = \".tmp\"\n+\n+// DeleteCheckpoints deletes all checkpoints in a directory below a given index and any temporary checkpoints that might have\n+// failed to be created.\n func DeleteCheckpoints(dir string, maxIndex int) error {\n-\tcheckpoints, err := listCheckpoints(dir)\n+\tcheckpoints, err := listCheckpoints(dir, true)\n \tif err != nil {\n \t\treturn err\n \t}\n \n+\tif len(checkpoints) == 0 {\n+\t\treturn nil\n+\t}\n+\n+\t// We can't guarantee that Checkpoint() will not be called at the same time as DeleteCheckpoints() so we only delete\n+\t// temporary checkpoints that are older than the most recent successful checkpoint.\n+\tvar lastSuccessfulCheckpointIndex int\n+\tfor lastSuccessfulCheckpointIndex = len(checkpoints) - 1; lastSuccessfulCheckpointIndex >= 0; lastSuccessfulCheckpointIndex-- {\n+\t\tif !strings.HasSuffix(checkpoints[lastSuccessfulCheckpointIndex].name, CheckpointTempFileSuffix) {",
    "repo_full_name": "prometheus/prometheus",
    "discussion_comments": [
      {
        "comment_id": "2172206201",
        "repo_full_name": "prometheus/prometheus",
        "pr_number": 16780,
        "pr_file": "tsdb/wlog/checkpoint.go",
        "discussion_id": "2172206201",
        "commented_code": "@@ -64,26 +64,50 @@ func LastCheckpoint(dir string) (string, int, error) {\n \treturn filepath.Join(dir, checkpoint.name), checkpoint.index, nil\n }\n \n-// DeleteCheckpoints deletes all checkpoints in a directory below a given index.\n+// CheckpointPrefix is the prefix used for checkpoint files.\n+const CheckpointPrefix = \"checkpoint.\"\n+\n+// CheckpointTempFileSuffix is the suffix used when creating temporary checkpoint files.\n+const CheckpointTempFileSuffix = \".tmp\"\n+\n+// DeleteCheckpoints deletes all checkpoints in a directory below a given index and any temporary checkpoints that might have\n+// failed to be created.\n func DeleteCheckpoints(dir string, maxIndex int) error {\n-\tcheckpoints, err := listCheckpoints(dir)\n+\tcheckpoints, err := listCheckpoints(dir, true)\n \tif err != nil {\n \t\treturn err\n \t}\n \n+\tif len(checkpoints) == 0 {\n+\t\treturn nil\n+\t}\n+\n+\t// We can't guarantee that Checkpoint() will not be called at the same time as DeleteCheckpoints() so we only delete\n+\t// temporary checkpoints that are older than the most recent successful checkpoint.\n+\tvar lastSuccessfulCheckpointIndex int\n+\tfor lastSuccessfulCheckpointIndex = len(checkpoints) - 1; lastSuccessfulCheckpointIndex >= 0; lastSuccessfulCheckpointIndex-- {\n+\t\tif !strings.HasSuffix(checkpoints[lastSuccessfulCheckpointIndex].name, CheckpointTempFileSuffix) {",
        "comment_created_at": "2025-06-27T14:45:53+00:00",
        "comment_author": "bboreham",
        "comment_body": "I think the code might be a little easier to read if this was extracted to a function `IsTempCheckpoint`.",
        "pr_file_module": null
      }
    ]
  }
]