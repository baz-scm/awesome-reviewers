[
  {
    "discussion_id": "1750220950",
    "pr_number": 4892,
    "pr_file": "prowler/lib/persistence/sqlite.py",
    "created_at": "2024-09-09T13:03:06+00:00",
    "commented_code": "+import os\n+import sqlite3\n+import tempfile\n+\n+import dill\n+\n+DEFAULT_CACHE_SIZE = int(os.environ.get('PROWLER_CACHE_SIZE', 2000))\n+\n+\n+class SQLiteDict:\n+\n+    def __init__(self, cache_size=2000):\n+        self._tmp_path = tempfile.NamedTemporaryFile(prefix='prowler-dict-')\n+        self.db_name = self._tmp_path.name\n+        self.conn = sqlite3.connect(self.db_name)\n+        self.cache_size = cache_size or DEFAULT_CACHE_SIZE\n+        self._configure_cache()\n+        self._create_table()\n+\n+    def _configure_cache(self):\n+        with self.conn:\n+            self.conn.execute(f'PRAGMA cache_size = {-self.cache_size}')",
    "repo_full_name": "prowler-cloud/prowler",
    "discussion_comments": [
      {
        "comment_id": "1750220950",
        "repo_full_name": "prowler-cloud/prowler",
        "pr_number": 4892,
        "pr_file": "prowler/lib/persistence/sqlite.py",
        "discussion_id": "1750220950",
        "commented_code": "@@ -0,0 +1,267 @@\n+import os\n+import sqlite3\n+import tempfile\n+\n+import dill\n+\n+DEFAULT_CACHE_SIZE = int(os.environ.get('PROWLER_CACHE_SIZE', 2000))\n+\n+\n+class SQLiteDict:\n+\n+    def __init__(self, cache_size=2000):\n+        self._tmp_path = tempfile.NamedTemporaryFile(prefix='prowler-dict-')\n+        self.db_name = self._tmp_path.name\n+        self.conn = sqlite3.connect(self.db_name)\n+        self.cache_size = cache_size or DEFAULT_CACHE_SIZE\n+        self._configure_cache()\n+        self._create_table()\n+\n+    def _configure_cache(self):\n+        with self.conn:\n+            self.conn.execute(f'PRAGMA cache_size = {-self.cache_size}')",
        "comment_created_at": "2024-09-09T13:03:06+00:00",
        "comment_author": "jfagoagas",
        "comment_body": "Why not to add a parameter to this query?",
        "pr_file_module": null
      },
      {
        "comment_id": "1751925501",
        "repo_full_name": "prowler-cloud/prowler",
        "pr_number": 4892,
        "pr_file": "prowler/lib/persistence/sqlite.py",
        "discussion_id": "1750220950",
        "commented_code": "@@ -0,0 +1,267 @@\n+import os\n+import sqlite3\n+import tempfile\n+\n+import dill\n+\n+DEFAULT_CACHE_SIZE = int(os.environ.get('PROWLER_CACHE_SIZE', 2000))\n+\n+\n+class SQLiteDict:\n+\n+    def __init__(self, cache_size=2000):\n+        self._tmp_path = tempfile.NamedTemporaryFile(prefix='prowler-dict-')\n+        self.db_name = self._tmp_path.name\n+        self.conn = sqlite3.connect(self.db_name)\n+        self.cache_size = cache_size or DEFAULT_CACHE_SIZE\n+        self._configure_cache()\n+        self._create_table()\n+\n+    def _configure_cache(self):\n+        with self.conn:\n+            self.conn.execute(f'PRAGMA cache_size = {-self.cache_size}')",
        "comment_created_at": "2024-09-10T13:13:18+00:00",
        "comment_author": "cr0hn",
        "comment_body": "This query fixes the maximum memory cache used by SQLite. The idea is to limit it",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1751745341",
    "pr_number": 4892,
    "pr_file": "prowler/lib/utils/gc.py",
    "created_at": "2024-09-10T11:07:12+00:00",
    "commented_code": "+import gc\n+\n+from contextlib import contextmanager\n+\n+\n+@contextmanager\n+def force_gc(disable_gc=False):",
    "repo_full_name": "prowler-cloud/prowler",
    "discussion_comments": [
      {
        "comment_id": "1751745341",
        "repo_full_name": "prowler-cloud/prowler",
        "pr_number": 4892,
        "pr_file": "prowler/lib/utils/gc.py",
        "discussion_id": "1751745341",
        "commented_code": "@@ -0,0 +1,35 @@\n+import gc\n+\n+from contextlib import contextmanager\n+\n+\n+@contextmanager\n+def force_gc(disable_gc=False):",
        "comment_created_at": "2024-09-10T11:07:12+00:00",
        "comment_author": "jfagoagas",
        "comment_body": "What is the point of this context manager? Is it intended for testing and benchmarking?",
        "pr_file_module": null
      },
      {
        "comment_id": "1751913957",
        "repo_full_name": "prowler-cloud/prowler",
        "pr_number": 4892,
        "pr_file": "prowler/lib/utils/gc.py",
        "discussion_id": "1751745341",
        "commented_code": "@@ -0,0 +1,35 @@\n+import gc\n+\n+from contextlib import contextmanager\n+\n+\n+@contextmanager\n+def force_gc(disable_gc=False):",
        "comment_created_at": "2024-09-10T13:06:56+00:00",
        "comment_author": "cr0hn",
        "comment_body": "This context manager is used for the Python Garbage collector to run instead of waiting for the next planner run",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1751746008",
    "pr_number": 4892,
    "pr_file": "prowler/lib/utils/gc.py",
    "created_at": "2024-09-10T11:07:42+00:00",
    "commented_code": "+import gc\n+\n+from contextlib import contextmanager\n+\n+\n+@contextmanager\n+def force_gc(disable_gc=False):\n+    \"\"\"\n+    Context manager that temporarily disables garbage collection if `disable_gc` argument is True.\n+\n+    Args:\n+        disable_gc (bool): If True, garbage collection will be disabled temporarily.\n+\n+    Yields:\n+        None\n+\n+    Notes:\n+        - If `disable_gc` is True, garbage collection will be disabled before entering the block.\n+        - The block of code should be indented after the `yield` statement.\n+        - Garbage collection will be invoked with `gc.collect()` before exiting the block, regardless of the value of `disable_gc`.\n+        - If `disable_gc` is True, garbage collection will be enabled after exiting the block.\n+    \"\"\"\n+    if disable_gc:\n+        gc.disable()\n+\n+    try:\n+        yield\n+    finally:\n+        gc.collect()\n+\n+    if disable_gc:\n+        gc.enable()",
    "repo_full_name": "prowler-cloud/prowler",
    "discussion_comments": [
      {
        "comment_id": "1751746008",
        "repo_full_name": "prowler-cloud/prowler",
        "pr_number": 4892,
        "pr_file": "prowler/lib/utils/gc.py",
        "discussion_id": "1751746008",
        "commented_code": "@@ -0,0 +1,35 @@\n+import gc\n+\n+from contextlib import contextmanager\n+\n+\n+@contextmanager\n+def force_gc(disable_gc=False):\n+    \"\"\"\n+    Context manager that temporarily disables garbage collection if `disable_gc` argument is True.\n+\n+    Args:\n+        disable_gc (bool): If True, garbage collection will be disabled temporarily.\n+\n+    Yields:\n+        None\n+\n+    Notes:\n+        - If `disable_gc` is True, garbage collection will be disabled before entering the block.\n+        - The block of code should be indented after the `yield` statement.\n+        - Garbage collection will be invoked with `gc.collect()` before exiting the block, regardless of the value of `disable_gc`.\n+        - If `disable_gc` is True, garbage collection will be enabled after exiting the block.\n+    \"\"\"\n+    if disable_gc:\n+        gc.disable()\n+\n+    try:\n+        yield\n+    finally:\n+        gc.collect()\n+\n+    if disable_gc:\n+        gc.enable()",
        "comment_created_at": "2024-09-10T11:07:42+00:00",
        "comment_author": "jfagoagas",
        "comment_body": "Would not be easier to just call explicitly the GC from `main`?",
        "pr_file_module": null
      },
      {
        "comment_id": "1751918282",
        "repo_full_name": "prowler-cloud/prowler",
        "pr_number": 4892,
        "pr_file": "prowler/lib/utils/gc.py",
        "discussion_id": "1751746008",
        "commented_code": "@@ -0,0 +1,35 @@\n+import gc\n+\n+from contextlib import contextmanager\n+\n+\n+@contextmanager\n+def force_gc(disable_gc=False):\n+    \"\"\"\n+    Context manager that temporarily disables garbage collection if `disable_gc` argument is True.\n+\n+    Args:\n+        disable_gc (bool): If True, garbage collection will be disabled temporarily.\n+\n+    Yields:\n+        None\n+\n+    Notes:\n+        - If `disable_gc` is True, garbage collection will be disabled before entering the block.\n+        - The block of code should be indented after the `yield` statement.\n+        - Garbage collection will be invoked with `gc.collect()` before exiting the block, regardless of the value of `disable_gc`.\n+        - If `disable_gc` is True, garbage collection will be enabled after exiting the block.\n+    \"\"\"\n+    if disable_gc:\n+        gc.disable()\n+\n+    try:\n+        yield\n+    finally:\n+        gc.collect()\n+\n+    if disable_gc:\n+        gc.enable()",
        "comment_created_at": "2024-09-10T13:09:31+00:00",
        "comment_author": "cr0hn",
        "comment_body": "You could do it, but I don't recommend it. \r\n\r\nIMO, a CM improves the readability and allows a future new feature implementation, like, temporal disabling the GC (with a high memory data load, for example)",
        "pr_file_module": null
      },
      {
        "comment_id": "1753996144",
        "repo_full_name": "prowler-cloud/prowler",
        "pr_number": 4892,
        "pr_file": "prowler/lib/utils/gc.py",
        "discussion_id": "1751746008",
        "commented_code": "@@ -0,0 +1,35 @@\n+import gc\n+\n+from contextlib import contextmanager\n+\n+\n+@contextmanager\n+def force_gc(disable_gc=False):\n+    \"\"\"\n+    Context manager that temporarily disables garbage collection if `disable_gc` argument is True.\n+\n+    Args:\n+        disable_gc (bool): If True, garbage collection will be disabled temporarily.\n+\n+    Yields:\n+        None\n+\n+    Notes:\n+        - If `disable_gc` is True, garbage collection will be disabled before entering the block.\n+        - The block of code should be indented after the `yield` statement.\n+        - Garbage collection will be invoked with `gc.collect()` before exiting the block, regardless of the value of `disable_gc`.\n+        - If `disable_gc` is True, garbage collection will be enabled after exiting the block.\n+    \"\"\"\n+    if disable_gc:\n+        gc.disable()\n+\n+    try:\n+        yield\n+    finally:\n+        gc.collect()\n+\n+    if disable_gc:\n+        gc.enable()",
        "comment_created_at": "2024-09-11T10:37:05+00:00",
        "comment_author": "jfagoagas",
        "comment_body": "We are not sure about this, but we will review that later on.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1940969560",
    "pr_number": 6746,
    "pr_file": "api/src/backend/tasks/jobs/scan.py",
    "created_at": "2025-02-04T11:09:44+00:00",
    "commented_code": "raw_result=finding.raw,\n                         check_id=finding.check_id,\n                         scan=scan_instance,\n-                        first_seen_at=last_first_seen_at,\n+                        first_seen_at=first_seen,\n                     )\n                     finding_instance.add_resources([resource_instance])\n \n-                # Update compliance data if applicable\n-                if finding.status.value == \"MUTED\":\n-                    continue\n-\n-                region_dict = check_status_by_region.setdefault(finding.region, {})\n-                current_status = region_dict.get(finding.check_id)\n-                if current_status == \"FAIL\":\n-                    continue\n-                region_dict[finding.check_id] = finding.status.value\n+                # Update compliance status\n+                if finding.status.value != \"MUTED\":\n+                    region_data = check_status_by_region.setdefault(finding.region, {})\n+                    if region_data.get(finding.check_id) != \"FAIL\":\n+                        region_data[finding.check_id] = finding.status.value\n \n-            # Update scan progress\n+            # Progress updates and output generation\n             with rls_transaction(tenant_id):\n                 scan_instance.progress = progress\n                 scan_instance.save()\n \n+            all_findings.extend(findings)\n+\n+        # Generate output files\n+        for mode, config in OUTPUT_FORMATS_MAPPING.items():\n+            kwargs = dict(config[\"kwargs\"])\n+            if mode == \"html\":\n+                kwargs[\"provider\"] = prowler_provider\n+                kwargs[\"stats\"] = stats\n+            config[\"class\"](\n+                findings=all_findings,\n+                create_file_descriptor=True,\n+                file_path=output_directory,\n+                file_extension=config[\"suffix\"],\n+            ).batch_write_data_to_file(**kwargs)",
    "repo_full_name": "prowler-cloud/prowler",
    "discussion_comments": [
      {
        "comment_id": "1940969560",
        "repo_full_name": "prowler-cloud/prowler",
        "pr_number": 6746,
        "pr_file": "api/src/backend/tasks/jobs/scan.py",
        "discussion_id": "1940969560",
        "commented_code": "@@ -266,92 +382,96 @@ def perform_prowler_scan(\n                         raw_result=finding.raw,\n                         check_id=finding.check_id,\n                         scan=scan_instance,\n-                        first_seen_at=last_first_seen_at,\n+                        first_seen_at=first_seen,\n                     )\n                     finding_instance.add_resources([resource_instance])\n \n-                # Update compliance data if applicable\n-                if finding.status.value == \"MUTED\":\n-                    continue\n-\n-                region_dict = check_status_by_region.setdefault(finding.region, {})\n-                current_status = region_dict.get(finding.check_id)\n-                if current_status == \"FAIL\":\n-                    continue\n-                region_dict[finding.check_id] = finding.status.value\n+                # Update compliance status\n+                if finding.status.value != \"MUTED\":\n+                    region_data = check_status_by_region.setdefault(finding.region, {})\n+                    if region_data.get(finding.check_id) != \"FAIL\":\n+                        region_data[finding.check_id] = finding.status.value\n \n-            # Update scan progress\n+            # Progress updates and output generation\n             with rls_transaction(tenant_id):\n                 scan_instance.progress = progress\n                 scan_instance.save()\n \n+            all_findings.extend(findings)\n+\n+        # Generate output files\n+        for mode, config in OUTPUT_FORMATS_MAPPING.items():\n+            kwargs = dict(config[\"kwargs\"])\n+            if mode == \"html\":\n+                kwargs[\"provider\"] = prowler_provider\n+                kwargs[\"stats\"] = stats\n+            config[\"class\"](\n+                findings=all_findings,\n+                create_file_descriptor=True,\n+                file_path=output_directory,\n+                file_extension=config[\"suffix\"],\n+            ).batch_write_data_to_file(**kwargs)",
        "comment_created_at": "2025-02-04T11:09:44+00:00",
        "comment_author": "jfagoagas",
        "comment_body": "I thought we talked about writing findings to file in _streaming_ instead of all at once to reduce memory overhead.",
        "pr_file_module": null
      }
    ]
  }
]