[
  {
    "discussion_id": "1969774768",
    "pr_number": 11468,
    "pr_file": "pydantic/config.py",
    "created_at": "2025-02-25T13:22:06+00:00",
    "commented_code": "as the performance difference is minimal if repeated strings are rare.\n     \"\"\"\n \n+    validate_by_alias: bool\n+    \"\"\"\n+    Whether an aliased field may be populated by its alias. Defaults to `True`.\n+\n+    !!! note\n+        In v2.11, `validate_by_alias` was introduced in conjunction with [`validate_by_name`][pydantic.ConfigDict.validate_by_name]\n+        to empower users with more fine grained validation control. In <v2.11, disabling validation by alias was not possible.\n+\n+    !!! tip\n+        If you set `validate_by_alias` to `False`, you should set `validate_by_name` to `True` to ensure that the field can still be populated.",
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "1969774768",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11468,
        "pr_file": "pydantic/config.py",
        "discussion_id": "1969774768",
        "commented_code": "@@ -1025,6 +1033,123 @@ class Model(BaseModel):\n         as the performance difference is minimal if repeated strings are rare.\n     \"\"\"\n \n+    validate_by_alias: bool\n+    \"\"\"\n+    Whether an aliased field may be populated by its alias. Defaults to `True`.\n+\n+    !!! note\n+        In v2.11, `validate_by_alias` was introduced in conjunction with [`validate_by_name`][pydantic.ConfigDict.validate_by_name]\n+        to empower users with more fine grained validation control. In <v2.11, disabling validation by alias was not possible.\n+\n+    !!! tip\n+        If you set `validate_by_alias` to `False`, you should set `validate_by_name` to `True` to ensure that the field can still be populated.",
        "comment_created_at": "2025-02-25T13:22:06+00:00",
        "comment_author": "Viicos",
        "comment_body": "This makes me think the literal pattern would really fit better here.. If having this boolean pattern on two configuration values only introduced the inconsistency when setting both `validate_by_alias=False, validate_by_name=False`, it would be fine (I don't see why users would do so), but I won't be surprised if many users find it counter-intuitive that you also need to set `validate_by_name=True` here.\r\n\r\nI think it's worth reconsidering, cc @samuelcolvin ",
        "pr_file_module": null
      },
      {
        "comment_id": "1969787804",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11468,
        "pr_file": "pydantic/config.py",
        "discussion_id": "1969774768",
        "commented_code": "@@ -1025,6 +1033,123 @@ class Model(BaseModel):\n         as the performance difference is minimal if repeated strings are rare.\n     \"\"\"\n \n+    validate_by_alias: bool\n+    \"\"\"\n+    Whether an aliased field may be populated by its alias. Defaults to `True`.\n+\n+    !!! note\n+        In v2.11, `validate_by_alias` was introduced in conjunction with [`validate_by_name`][pydantic.ConfigDict.validate_by_name]\n+        to empower users with more fine grained validation control. In <v2.11, disabling validation by alias was not possible.\n+\n+    !!! tip\n+        If you set `validate_by_alias` to `False`, you should set `validate_by_name` to `True` to ensure that the field can still be populated.",
        "comment_created_at": "2025-02-25T13:29:45+00:00",
        "comment_author": "Viicos",
        "comment_body": "Also, what should happen if you set `validate_by_alias=False`, but explicitly set `by_alias=True` or `by_name=True` during validation?",
        "pr_file_module": null
      },
      {
        "comment_id": "1970135718",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11468,
        "pr_file": "pydantic/config.py",
        "discussion_id": "1969774768",
        "commented_code": "@@ -1025,6 +1033,123 @@ class Model(BaseModel):\n         as the performance difference is minimal if repeated strings are rare.\n     \"\"\"\n \n+    validate_by_alias: bool\n+    \"\"\"\n+    Whether an aliased field may be populated by its alias. Defaults to `True`.\n+\n+    !!! note\n+        In v2.11, `validate_by_alias` was introduced in conjunction with [`validate_by_name`][pydantic.ConfigDict.validate_by_name]\n+        to empower users with more fine grained validation control. In <v2.11, disabling validation by alias was not possible.\n+\n+    !!! tip\n+        If you set `validate_by_alias` to `False`, you should set `validate_by_name` to `True` to ensure that the field can still be populated.",
        "comment_created_at": "2025-02-25T16:30:19+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "> Also, what should happen if you set validate_by_alias=False, but explicitly set by_alias=True or by_name=True during validation?\r\n\r\nValidation time settings always take priority, when set. This is the same with `strict`.",
        "pr_file_module": null
      },
      {
        "comment_id": "1970151411",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11468,
        "pr_file": "pydantic/config.py",
        "discussion_id": "1969774768",
        "commented_code": "@@ -1025,6 +1033,123 @@ class Model(BaseModel):\n         as the performance difference is minimal if repeated strings are rare.\n     \"\"\"\n \n+    validate_by_alias: bool\n+    \"\"\"\n+    Whether an aliased field may be populated by its alias. Defaults to `True`.\n+\n+    !!! note\n+        In v2.11, `validate_by_alias` was introduced in conjunction with [`validate_by_name`][pydantic.ConfigDict.validate_by_name]\n+        to empower users with more fine grained validation control. In <v2.11, disabling validation by alias was not possible.\n+\n+    !!! tip\n+        If you set `validate_by_alias` to `False`, you should set `validate_by_name` to `True` to ensure that the field can still be populated.",
        "comment_created_at": "2025-02-25T16:37:52+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "I'm sympathetic to the literal pattern argument. If we were starting fully from scratch, I think it might make more sense. Specifically, the boolean traps can be a bit confusing. In particular, the fact that you have to set `validate_by_name=True` if `validate_by_alias=False` explicitly is a bit confusing, especially for new users.\r\n\r\nOne thing we could do to mitigate this challenge is automatically set `validate_by_name=True` if a user sets `validate_By_alias=False`.\r\n\r\nMy thoughts re why we should stick with the 2 boolean flags:\r\n\r\n* It represents less change to this setting compared to a switch to literals - there's already a lot of change going on here, and I'm hesitant to introduce a setting `type` change as well.\r\n* 2 boolean flags provide greater configurability for interaction between config and runtime settings, as you can override one behavior and not the other. It's also helpful to have unset markers for each thing. For example:\r\n\r\n```\r\nM1: validate_by_alias = True, validate_by_name = False\r\nM2: validate_by_alias = False, validate_by_name = True\r\n\r\nruntime setting: by_name = True\r\n\r\n==>\r\n\r\nM1: alias and name validation\r\nM2: name only validation\r\n```\r\n\r\nThis can't be achieved with the literal approach. Either you'd use:\r\n* `validate_by='name'`, and M1 would lose alias validation\r\n* `validate_by='name and alias'` and M2 would no longer avoid validating with alias\r\n\r\n* Autocomplete is easier with boolean flags, and the behavior is relatively intuitive\r\n\r\nAliases are one of the most common (if not the most commonly used) field tool, so I do think this decision is quite important. I also understand that if we go with bools here, we're stuck with that until at least V4. ",
        "pr_file_module": null
      },
      {
        "comment_id": "1971318650",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11468,
        "pr_file": "pydantic/config.py",
        "discussion_id": "1969774768",
        "commented_code": "@@ -1025,6 +1033,123 @@ class Model(BaseModel):\n         as the performance difference is minimal if repeated strings are rare.\n     \"\"\"\n \n+    validate_by_alias: bool\n+    \"\"\"\n+    Whether an aliased field may be populated by its alias. Defaults to `True`.\n+\n+    !!! note\n+        In v2.11, `validate_by_alias` was introduced in conjunction with [`validate_by_name`][pydantic.ConfigDict.validate_by_name]\n+        to empower users with more fine grained validation control. In <v2.11, disabling validation by alias was not possible.\n+\n+    !!! tip\n+        If you set `validate_by_alias` to `False`, you should set `validate_by_name` to `True` to ensure that the field can still be populated.",
        "comment_created_at": "2025-02-26T10:16:28+00:00",
        "comment_author": "Viicos",
        "comment_body": "Yes, as discussed on Slack, thanks for summing things up here, this might be useful as a reference in case we get questions about the current API.\r\n\r\nAs we discussed as well, defaulting `validate_by_name` to `True` if `validate_by_alias` is set to `False` is postponed after this PR, and should be tackled either before 2.11 or after. Leaving this conversation unresolved so that it's easier to find it later.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1971496958",
    "pr_number": 11468,
    "pr_file": "pydantic/mypy.py",
    "created_at": "2025-02-26T12:26:01+00:00",
    "commented_code": null,
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "1971496958",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11468,
        "pr_file": "pydantic/mypy.py",
        "discussion_id": "1971496958",
        "commented_code": null,
        "comment_created_at": "2025-02-26T12:26:01+00:00",
        "comment_author": "Viicos",
        "comment_body": "I think you'll have to update the `collect_config()` logic to handle both `validate_by_name` and `populate_by_name`. Mypy does static analysis so it can't be aware of the added logic in `ConfigWrapper.core_config()`.\r\n\r\nAlso, I'm not sure if the plugin already handled this, but previously if `populate_by_name` was set, the following calls were allowed:\r\n\r\n```python\r\nclass Model(BaseModel):\r\n    field: int = Field(alias='alias')\r\n\r\n    model_config = {'populate_by_name': True}\r\n\r\nModel(field=1)  # OK\r\nModel(alias=1)  # OK\r\n```\r\n\r\nIf the plugin accepted both these calls, it will probably need to be updated to disallow the following:\r\n\r\n```python\r\nclass Model(BaseModel):\r\n    field: int = Field(alias='alias')\r\n\r\n    model_config = {'validate_by_alias': True, 'validate_by_name': False}\r\n\r\nModel(field=1)  # Type checker error\r\nModel(alias=1)  # OK\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1971708310",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11468,
        "pr_file": "pydantic/mypy.py",
        "discussion_id": "1971496958",
        "commented_code": null,
        "comment_created_at": "2025-02-26T14:37:19+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "Agreed, definitely important. I've pushed a [commit](https://github.com/pydantic/pydantic/pull/11468/commits/2341a58997683df514a7dcd27a615a5d05678f55) to make this backwards compatible.\r\n\r\nThe new behavior:\r\n\r\n```py\r\nfrom pydantic import BaseModel, ConfigDict, Field\r\n\r\nclass Model1(BaseModel):\r\n    model_config = ConfigDict(validate_by_alias=False, validate_by_name=True)\r\n\r\n    my_field: str = Field(alias='my_alias')\r\n\r\nm1 = Model1(my_field='foo')\r\n\r\nclass Model2(BaseModel):\r\n    model_config = ConfigDict(validate_by_alias=True, validate_by_name=False)\r\n\r\n    my_field: str = Field(alias='my_alias')\r\n\r\nm2 = Model2(my_alias='foo')\r\n\r\nclass Model3(BaseModel):\r\n    model_config = ConfigDict(validate_by_alias=True, validate_by_name=True)\r\n\r\n    my_field: str = Field(alias='my_alias')\r\n\r\n# for this case, we prefer the field name over the alias, as we did in the past\r\n# if populate_by_name was True\r\nm31 = Model3(my_field='foo')\r\nm32 = Model3(my_alias='foo')\r\n#> test.py:23: error: Missing named argument \"my_field\" for \"Model3\"  [call-arg]\r\n\r\nclass Model4(BaseModel):\r\n    my_field: str = Field(alias='my_alias')\r\n\r\nm4 = Model4(my_alias='foo')\r\n\r\nclass Model5(BaseModel):\r\n    model_config = ConfigDict(populate_by_name=True)\r\n\r\n    my_field: str = Field(alias='my_alias')\r\n\r\n# for this case, we prefer the field name over the alias\r\nm51 = Model5(my_field='foo')\r\nm52 = Model5(my_alias='foo')\r\n#> test.py:39: error: Missing named argument \"my_field\" for \"Model5\"  [call-arg]\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1975250068",
    "pr_number": 11504,
    "pr_file": "pydantic/config.py",
    "created_at": "2025-02-28T11:22:47+00:00",
    "commented_code": "The format of JSON serialized timedeltas. Accepts the string values of `'iso8601'` and\n     `'float'`. Defaults to `'iso8601'`.\n \n-    - `'iso8601'` will serialize timedeltas to ISO 8601 durations.\n+    !!! warning\n+        In v2.11+ it is recommended to use the [`ser_json_datetime`][pydantic.config.ConfigDict.ser_json_datetime]\n+        setting instead of `ser_json_timedelta`. This setting will be deprecated in v3.\n+\n+    - `'iso8601'` will serialize timedeltas to [ISO 8601 durations](https://en.wikipedia.org/wiki/ISO_8601#Durations).\n     - `'float'` will serialize timedeltas to the total number of seconds.\n     \"\"\"\n \n+    val_datetime_unit: Literal['seconds', 'milliseconds', 'infer']\n+    \"\"\"\n+    The unit to assume for validating numeric input for datetime-like types. This includes:\n+\n+    - [`datetime.datetime`][]\n+    - [`datetime.date`][]\n+    - [`datetime.time`][]\n+    - [`datetime.timedelta`][]\n+\n+    Defaults to `'infer'`.\n+    The \"epoch\" reference below refers to the Unix epoch, which is 1970-01-01 00:00:00 UTC.\n+\n+    - `'seconds'` will validate date or time numeric inputs as seconds since the epoch.\n+    - `'milliseconds'` will validate date or time numeric inputs as milliseconds since the epoch.\n+    - `'infer'` will infer the unit from the string numeric input on unix time:\n+        i.e. seconds (if >= -2e10 and <= 2e10) or milliseconds (if < -2e10or > 2e10) since the epoch.\n+    \"\"\"\n+\n+    ser_datetime_unit: Literal['seconds', 'milliseconds', 'infer']\n+    \"\"\"\n+    The unit to use for serializing datetime-like types. This includes:\n+\n+    - [`datetime.datetime`][]\n+    - [`datetime.date`][]\n+    - [`datetime.time`][]\n+    - [`datetime.timedelta`][]\n+\n+    This only applies when serializing to `'float'`. ISO8601 durations use a predefined format.\n+    Defaults to `'infer'`.\n+    The \"epoch\" reference below refers to the Unix epoch, which is 1970-01-01 00:00:00 UTC.\n+\n+    - `'seconds'` will validate date or time numeric inputs as seconds since the epoch.\n+    - `'milliseconds'` will validate date or time numeric inputs as milliseconds since the epoch.\n+    - `'infer'` will infer the unit from the string numeric input on unix time:\n+        i.e. seconds (if >= -2e10 and <= 2e10) or milliseconds (if < -2e10or > 2e10) since the epoch.\n+    \"\"\"\n+\n+    val_json_datetime: tuple[Literal['iso8601', 'float', 'int'], ...]\n+    \"\"\"\n+    The formats to accept when validating datetime-like types from JSON. This includes:\n+\n+    - [`datetime.datetime`][]\n+    - [`datetime.date`][]\n+    - [`datetime.time`][]\n+    - [`datetime.timedelta`][]\n+\n+    Defaults to ('iso8601', 'float', 'int').\n+    If `'float'` or `'int'` is included, `val_datetime_unit` can be used to specify the unit (s vs ms) of the float.",
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "1975250068",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11504,
        "pr_file": "pydantic/config.py",
        "discussion_id": "1975250068",
        "commented_code": "@@ -592,10 +592,90 @@ class Transaction(BaseModel):\n     The format of JSON serialized timedeltas. Accepts the string values of `'iso8601'` and\n     `'float'`. Defaults to `'iso8601'`.\n \n-    - `'iso8601'` will serialize timedeltas to ISO 8601 durations.\n+    !!! warning\n+        In v2.11+ it is recommended to use the [`ser_json_datetime`][pydantic.config.ConfigDict.ser_json_datetime]\n+        setting instead of `ser_json_timedelta`. This setting will be deprecated in v3.\n+\n+    - `'iso8601'` will serialize timedeltas to [ISO 8601 durations](https://en.wikipedia.org/wiki/ISO_8601#Durations).\n     - `'float'` will serialize timedeltas to the total number of seconds.\n     \"\"\"\n \n+    val_datetime_unit: Literal['seconds', 'milliseconds', 'infer']\n+    \"\"\"\n+    The unit to assume for validating numeric input for datetime-like types. This includes:\n+\n+    - [`datetime.datetime`][]\n+    - [`datetime.date`][]\n+    - [`datetime.time`][]\n+    - [`datetime.timedelta`][]\n+\n+    Defaults to `'infer'`.\n+    The \"epoch\" reference below refers to the Unix epoch, which is 1970-01-01 00:00:00 UTC.\n+\n+    - `'seconds'` will validate date or time numeric inputs as seconds since the epoch.\n+    - `'milliseconds'` will validate date or time numeric inputs as milliseconds since the epoch.\n+    - `'infer'` will infer the unit from the string numeric input on unix time:\n+        i.e. seconds (if >= -2e10 and <= 2e10) or milliseconds (if < -2e10or > 2e10) since the epoch.\n+    \"\"\"\n+\n+    ser_datetime_unit: Literal['seconds', 'milliseconds', 'infer']\n+    \"\"\"\n+    The unit to use for serializing datetime-like types. This includes:\n+\n+    - [`datetime.datetime`][]\n+    - [`datetime.date`][]\n+    - [`datetime.time`][]\n+    - [`datetime.timedelta`][]\n+\n+    This only applies when serializing to `'float'`. ISO8601 durations use a predefined format.\n+    Defaults to `'infer'`.\n+    The \"epoch\" reference below refers to the Unix epoch, which is 1970-01-01 00:00:00 UTC.\n+\n+    - `'seconds'` will validate date or time numeric inputs as seconds since the epoch.\n+    - `'milliseconds'` will validate date or time numeric inputs as milliseconds since the epoch.\n+    - `'infer'` will infer the unit from the string numeric input on unix time:\n+        i.e. seconds (if >= -2e10 and <= 2e10) or milliseconds (if < -2e10or > 2e10) since the epoch.\n+    \"\"\"\n+\n+    val_json_datetime: tuple[Literal['iso8601', 'float', 'int'], ...]\n+    \"\"\"\n+    The formats to accept when validating datetime-like types from JSON. This includes:\n+\n+    - [`datetime.datetime`][]\n+    - [`datetime.date`][]\n+    - [`datetime.time`][]\n+    - [`datetime.timedelta`][]\n+\n+    Defaults to ('iso8601', 'float', 'int').\n+    If `'float'` or `'int'` is included, `val_datetime_unit` can be used to specify the unit (s vs ms) of the float.",
        "comment_created_at": "2025-02-28T11:22:47+00:00",
        "comment_author": "ollz272",
        "comment_body": "Just a thought, is it worth adding a warning/error if the unit is set when `val_json_datetime/ser_json_datetime` is specifically `iso8601`?",
        "pr_file_module": null
      },
      {
        "comment_id": "1977783594",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11504,
        "pr_file": "pydantic/config.py",
        "discussion_id": "1975250068",
        "commented_code": "@@ -592,10 +592,90 @@ class Transaction(BaseModel):\n     The format of JSON serialized timedeltas. Accepts the string values of `'iso8601'` and\n     `'float'`. Defaults to `'iso8601'`.\n \n-    - `'iso8601'` will serialize timedeltas to ISO 8601 durations.\n+    !!! warning\n+        In v2.11+ it is recommended to use the [`ser_json_datetime`][pydantic.config.ConfigDict.ser_json_datetime]\n+        setting instead of `ser_json_timedelta`. This setting will be deprecated in v3.\n+\n+    - `'iso8601'` will serialize timedeltas to [ISO 8601 durations](https://en.wikipedia.org/wiki/ISO_8601#Durations).\n     - `'float'` will serialize timedeltas to the total number of seconds.\n     \"\"\"\n \n+    val_datetime_unit: Literal['seconds', 'milliseconds', 'infer']\n+    \"\"\"\n+    The unit to assume for validating numeric input for datetime-like types. This includes:\n+\n+    - [`datetime.datetime`][]\n+    - [`datetime.date`][]\n+    - [`datetime.time`][]\n+    - [`datetime.timedelta`][]\n+\n+    Defaults to `'infer'`.\n+    The \"epoch\" reference below refers to the Unix epoch, which is 1970-01-01 00:00:00 UTC.\n+\n+    - `'seconds'` will validate date or time numeric inputs as seconds since the epoch.\n+    - `'milliseconds'` will validate date or time numeric inputs as milliseconds since the epoch.\n+    - `'infer'` will infer the unit from the string numeric input on unix time:\n+        i.e. seconds (if >= -2e10 and <= 2e10) or milliseconds (if < -2e10or > 2e10) since the epoch.\n+    \"\"\"\n+\n+    ser_datetime_unit: Literal['seconds', 'milliseconds', 'infer']\n+    \"\"\"\n+    The unit to use for serializing datetime-like types. This includes:\n+\n+    - [`datetime.datetime`][]\n+    - [`datetime.date`][]\n+    - [`datetime.time`][]\n+    - [`datetime.timedelta`][]\n+\n+    This only applies when serializing to `'float'`. ISO8601 durations use a predefined format.\n+    Defaults to `'infer'`.\n+    The \"epoch\" reference below refers to the Unix epoch, which is 1970-01-01 00:00:00 UTC.\n+\n+    - `'seconds'` will validate date or time numeric inputs as seconds since the epoch.\n+    - `'milliseconds'` will validate date or time numeric inputs as milliseconds since the epoch.\n+    - `'infer'` will infer the unit from the string numeric input on unix time:\n+        i.e. seconds (if >= -2e10 and <= 2e10) or milliseconds (if < -2e10or > 2e10) since the epoch.\n+    \"\"\"\n+\n+    val_json_datetime: tuple[Literal['iso8601', 'float', 'int'], ...]\n+    \"\"\"\n+    The formats to accept when validating datetime-like types from JSON. This includes:\n+\n+    - [`datetime.datetime`][]\n+    - [`datetime.date`][]\n+    - [`datetime.time`][]\n+    - [`datetime.timedelta`][]\n+\n+    Defaults to ('iso8601', 'float', 'int').\n+    If `'float'` or `'int'` is included, `val_datetime_unit` can be used to specify the unit (s vs ms) of the float.",
        "comment_created_at": "2025-03-03T16:08:01+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "Fixed this problem by consolidating the settings as you had previously :)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1856826739",
    "pr_number": 10949,
    "pr_file": "pydantic/config.py",
    "created_at": "2024-11-25T15:33:44+00:00",
    "commented_code": "3. Using `'never'` we would have gotten `user=SubUser(hobbies=['scuba diving'], sins=['lying'])`.\n     \"\"\"\n \n+    val_date_or_time_unit: Literal['seconds', 'milliseconds', 'infer']\n+    \"\"\"The unit to assume for validating date or time strings. Defaults to `'infer'`.\n+    Only applies when the date / time like input is an int / float.\n+\n+    The \"epoch\" reference below refers to the Unix epoch, which is 1970-01-01 00:00:00 UTC.\n+\n+    - `'seconds'` will validate date or time strings as seconds since the epoch.\n+    - `'milliseconds'` will validate date or time strings as milliseconds since the epoch.\n+    - `'infer'` will infer the unit from the string based on unix time:\n+        i.e. seconds (if >= -2e10 and <= 2e10) or milliseconds (if < -2e10or > 2e10) since the epoch.\n+    \"\"\"\n+\n+    # TODO: does infer even make sense here? I guess in the context of float?",
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "1856826739",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10949,
        "pr_file": "pydantic/config.py",
        "discussion_id": "1856826739",
        "commented_code": "@@ -555,15 +555,49 @@ class Transaction(BaseModel):\n     3. Using `'never'` we would have gotten `user=SubUser(hobbies=['scuba diving'], sins=['lying'])`.\n     \"\"\"\n \n+    val_date_or_time_unit: Literal['seconds', 'milliseconds', 'infer']\n+    \"\"\"The unit to assume for validating date or time strings. Defaults to `'infer'`.\n+    Only applies when the date / time like input is an int / float.\n+\n+    The \"epoch\" reference below refers to the Unix epoch, which is 1970-01-01 00:00:00 UTC.\n+\n+    - `'seconds'` will validate date or time strings as seconds since the epoch.\n+    - `'milliseconds'` will validate date or time strings as milliseconds since the epoch.\n+    - `'infer'` will infer the unit from the string based on unix time:\n+        i.e. seconds (if >= -2e10 and <= 2e10) or milliseconds (if < -2e10or > 2e10) since the epoch.\n+    \"\"\"\n+\n+    # TODO: does infer even make sense here? I guess in the context of float?",
        "comment_created_at": "2024-11-25T15:33:44+00:00",
        "comment_author": "davidhewitt",
        "comment_body": "Yes I think we want it for symmetry, if the default is `infer` then things round-trip properly. Otherwise we end up changing the scale for users when they validate then dump.",
        "pr_file_module": null
      }
    ]
  }
]