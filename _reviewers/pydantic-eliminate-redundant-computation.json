[
  {
    "discussion_id": "1972625739",
    "pr_number": 11479,
    "pr_file": "pydantic/_internal/_core_utils.py",
    "created_at": "2025-02-27T00:33:51+00:00",
    "commented_code": "from pydantic_core import CoreSchema, core_schema\n from pydantic_core import validate_core_schema as _validate_core_schema\n from typing_extensions import TypeGuard, get_args, get_origin\n+from typing_inspection import typing_objects\n \n from . import _repr\n-from ._typing_extra import is_generic_alias, is_type_alias_type\n+from ._typing_extra import is_generic_alias",
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "1972625739",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11479,
        "pr_file": "pydantic/_internal/_core_utils.py",
        "discussion_id": "1972625739",
        "commented_code": "@@ -8,9 +8,10 @@\n from pydantic_core import CoreSchema, core_schema\n from pydantic_core import validate_core_schema as _validate_core_schema\n from typing_extensions import TypeGuard, get_args, get_origin\n+from typing_inspection import typing_objects\n \n from . import _repr\n-from ._typing_extra import is_generic_alias, is_type_alias_type\n+from ._typing_extra import is_generic_alias",
        "comment_created_at": "2025-02-27T00:33:51+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "Why is `is_generic_alias` not included in `typing_inspection`?",
        "pr_file_module": null
      },
      {
        "comment_id": "1973268698",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11479,
        "pr_file": "pydantic/_internal/_core_utils.py",
        "discussion_id": "1972625739",
        "commented_code": "@@ -8,9 +8,10 @@\n from pydantic_core import CoreSchema, core_schema\n from pydantic_core import validate_core_schema as _validate_core_schema\n from typing_extensions import TypeGuard, get_args, get_origin\n+from typing_inspection import typing_objects\n \n from . import _repr\n-from ._typing_extra import is_generic_alias, is_type_alias_type\n+from ._typing_extra import is_generic_alias",
        "comment_created_at": "2025-02-27T10:06:14+00:00",
        "comment_author": "Viicos",
        "comment_body": "`is_generic_alias` does an `isinstance()` check against `typing._GenericAlias` (e.g. `List[int]` is an instance of such a class), which isn't documented and technically private (although I don't think it will change). So it's best to avoid relying on it.\r\n\r\nIt is also a footgun as while `is_generic_alias()` works for all parameterized typing objects, it doesn't check for new unions (`is_generic_alias(int | str) == False`, but `is_generic_alias(Union[int, str]) == True`). For instance, I'm not sure we expected new unions to be skipped here:\r\n\r\nhttps://github.com/pydantic/pydantic/blob/acb0f10fda1c78441e052c57b4288bc91431f852/pydantic/_internal/_core_utils.py#L66-L74\r\n\r\nSimilarly, I've used this function here as a way to check for `type[list[int]]` forms (here `type_param` is `list[int]`):\r\n\r\nhttps://github.com/pydantic/pydantic/blob/acb0f10fda1c78441e052c57b4288bc91431f852/pydantic/_internal/_generate_schema.py#L1711-L1715\r\n\r\nThis would also match `type[Union[int, str]]`, which we actually want to support! Thankfully there's a specific check for unions just before, but this could easily be missed.\r\n\r\n---\r\n\r\nI think there are still valid use cases where you want to check if something is a generic alias (and by that I don't mean `isinstance(obj, (types.GenericAlias, typing._GenericAlias)`, but if the `obj` is a parameterized generic class -- excluding unions, typing special forms like `Literal`, `Annotated`, etc), but it's probably best to rely on `get_origin()` and the `typing_objects` check functions.\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1838568611",
    "pr_number": 10537,
    "pr_file": "pydantic/type_adapter.py",
    "created_at": "2024-11-12T18:17:48+00:00",
    "commented_code": "self._type = type\n         self._config = config\n         self._parent_depth = _parent_depth\n-        if module is None:\n-            f = sys._getframe(1)\n-            self._module_name = cast(str, f.f_globals.get('__name__', ''))\n-        else:\n-            self._module_name = module\n-\n-        self._core_schema: CoreSchema | None = None\n-        self._validator: SchemaValidator | PluggableSchemaValidator | None = None\n-        self._serializer: SchemaSerializer | None = None\n-\n-        if not self._defer_build():\n-            # Immediately initialize the core schema, validator and serializer\n-            with self._with_frame_depth(1):  # +1 frame depth for this __init__\n-                # Model itself may be using deferred building. For backward compatibility we don't rebuild model mocks\n-                # here as part of __init__ even though TypeAdapter itself is not using deferred building.\n-                self._init_core_attrs(rebuild_mocks=False)\n-\n-    @contextmanager\n-    def _with_frame_depth(self, depth: int) -> Iterator[None]:\n-        self._parent_depth += depth\n-        try:\n-            yield\n-        finally:\n-            self._parent_depth -= depth\n \n-    @_frame_depth(1)\n-    def _init_core_attrs(self, rebuild_mocks: bool) -> None:\n+        self.core_schema: CoreSchema\n+        self.validator: SchemaValidator | PluggableSchemaValidator\n+        self.serializer: SchemaSerializer\n+\n+        localns: _namespace_utils.MappingNamespace = (\n+            _typing_extra.parent_frame_namespace(parent_depth=self._parent_depth) or {}\n+        )\n+        globalns: _namespace_utils.MappingNamespace = sys._getframe(max(self._parent_depth - 1, 1)).f_globals\n+        self._module_name = module or cast(str, globalns.get('__name__', ''))\n+        self._init_core_attrs(\n+            ns_resolver=_namespace_utils.NsResolver(\n+                namespaces_tuple=_namespace_utils.NamespacesTuple(locals=localns, globals=globalns),\n+                parent_namespace=localns,\n+            ),\n+            force=False,\n+        )\n+\n+    def _init_core_attrs(self, ns_resolver: _namespace_utils.NsResolver, force: bool) -> bool:\n+        \"\"\"Initialize the core schema, validator, and serializer for the type.\n+\n+        If `force` is set to `False` and `_defer_build` is `True`, the core schema, validator, and serializer will be set to mocks.\n+\n+        Args:\n+            ns_resolver: The namespace resolver to use when building the core schema for the adapted type.\n+            force: Whether to force the initialization of the core schema, validator, and serializer.\n+\n+        Returns:\n+            `True` if the core schema, validator, and serializer were successfully initialized, otherwise `False`.\n+        \"\"\"\n+        if not force and self._defer_build:\n+            _mock_val_ser.set_type_adapter_mocks(self, str(self._type))\n+            self._pydantic_complete = False\n+            return False\n+\n         try:\n-            self._core_schema = _getattr_no_parents(self._type, '__pydantic_core_schema__')\n-            self._validator = _getattr_no_parents(self._type, '__pydantic_validator__')\n-            self._serializer = _getattr_no_parents(self._type, '__pydantic_serializer__')\n+            self.core_schema = _getattr_no_parents(self._type, '__pydantic_core_schema__')\n+            self.validator = _getattr_no_parents(self._type, '__pydantic_validator__')\n+            self.serializer = _getattr_no_parents(self._type, '__pydantic_serializer__')\n         except AttributeError:\n             config_wrapper = _config.ConfigWrapper(self._config)\n             core_config = config_wrapper.core_config(None)\n \n-            self._core_schema = _get_schema(self._type, config_wrapper, parent_depth=self._parent_depth)\n-            self._validator = create_schema_validator(\n-                schema=self._core_schema,\n+            self.core_schema = _get_schema(self._type, config_wrapper, ns_resolver=ns_resolver)\n+            self.validator = create_schema_validator(\n+                schema=self.core_schema,\n                 schema_type=self._type,\n                 schema_type_module=self._module_name,\n                 schema_type_name=str(self._type),\n                 schema_kind='TypeAdapter',\n                 config=core_config,\n                 plugin_settings=config_wrapper.plugin_settings,\n             )\n-            self._serializer = SchemaSerializer(self._core_schema, core_config)\n-\n-        if rebuild_mocks and isinstance(self._core_schema, _mock_val_ser.MockCoreSchema):\n-            self._core_schema.rebuild()\n-            self._init_core_attrs(rebuild_mocks=False)\n-            assert not isinstance(self._core_schema, _mock_val_ser.MockCoreSchema)\n-            assert not isinstance(self._validator, _mock_val_ser.MockValSer)\n-            assert not isinstance(self._serializer, _mock_val_ser.MockValSer)\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property and core_schema(self)\n-    def core_schema(self) -> CoreSchema:\n-        \"\"\"The pydantic-core schema used to build the SchemaValidator and SchemaSerializer.\"\"\"\n-        if self._core_schema is None or isinstance(self._core_schema, _mock_val_ser.MockCoreSchema):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockCoreSchema from public function\n-        assert self._core_schema is not None and not isinstance(self._core_schema, _mock_val_ser.MockCoreSchema)\n-        return self._core_schema\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property + validator(self)\n-    def validator(self) -> SchemaValidator | PluggableSchemaValidator:\n-        \"\"\"The pydantic-core SchemaValidator used to validate instances of the model.\"\"\"\n-        if not isinstance(self._validator, (SchemaValidator, PluggableSchemaValidator)):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockValSer from public function\n-        assert isinstance(self._validator, (SchemaValidator, PluggableSchemaValidator))\n-        return self._validator\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property + serializer(self)\n-    def serializer(self) -> SchemaSerializer:\n-        \"\"\"The pydantic-core SchemaSerializer used to dump instances of the model.\"\"\"\n-        if not isinstance(self._serializer, SchemaSerializer):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockValSer from public function\n-        assert isinstance(self._serializer, SchemaSerializer)\n-        return self._serializer\n+            self.serializer = SchemaSerializer(self.core_schema, core_config)\n+\n+        # TODO: I think we should move this to the rebuild pattern?\n+        if isinstance(self.core_schema, _mock_val_ser.MockCoreSchema):\n+            self.core_schema = self.core_schema.rebuild()  # type: ignore[assignment]\n+            self._init_core_attrs(ns_resolver=ns_resolver, force=True)",
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "1838568611",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10537,
        "pr_file": "pydantic/type_adapter.py",
        "discussion_id": "1838568611",
        "commented_code": "@@ -233,100 +208,122 @@ def __init__(\n         self._type = type\n         self._config = config\n         self._parent_depth = _parent_depth\n-        if module is None:\n-            f = sys._getframe(1)\n-            self._module_name = cast(str, f.f_globals.get('__name__', ''))\n-        else:\n-            self._module_name = module\n-\n-        self._core_schema: CoreSchema | None = None\n-        self._validator: SchemaValidator | PluggableSchemaValidator | None = None\n-        self._serializer: SchemaSerializer | None = None\n-\n-        if not self._defer_build():\n-            # Immediately initialize the core schema, validator and serializer\n-            with self._with_frame_depth(1):  # +1 frame depth for this __init__\n-                # Model itself may be using deferred building. For backward compatibility we don't rebuild model mocks\n-                # here as part of __init__ even though TypeAdapter itself is not using deferred building.\n-                self._init_core_attrs(rebuild_mocks=False)\n-\n-    @contextmanager\n-    def _with_frame_depth(self, depth: int) -> Iterator[None]:\n-        self._parent_depth += depth\n-        try:\n-            yield\n-        finally:\n-            self._parent_depth -= depth\n \n-    @_frame_depth(1)\n-    def _init_core_attrs(self, rebuild_mocks: bool) -> None:\n+        self.core_schema: CoreSchema\n+        self.validator: SchemaValidator | PluggableSchemaValidator\n+        self.serializer: SchemaSerializer\n+\n+        localns: _namespace_utils.MappingNamespace = (\n+            _typing_extra.parent_frame_namespace(parent_depth=self._parent_depth) or {}\n+        )\n+        globalns: _namespace_utils.MappingNamespace = sys._getframe(max(self._parent_depth - 1, 1)).f_globals\n+        self._module_name = module or cast(str, globalns.get('__name__', ''))\n+        self._init_core_attrs(\n+            ns_resolver=_namespace_utils.NsResolver(\n+                namespaces_tuple=_namespace_utils.NamespacesTuple(locals=localns, globals=globalns),\n+                parent_namespace=localns,\n+            ),\n+            force=False,\n+        )\n+\n+    def _init_core_attrs(self, ns_resolver: _namespace_utils.NsResolver, force: bool) -> bool:\n+        \"\"\"Initialize the core schema, validator, and serializer for the type.\n+\n+        If `force` is set to `False` and `_defer_build` is `True`, the core schema, validator, and serializer will be set to mocks.\n+\n+        Args:\n+            ns_resolver: The namespace resolver to use when building the core schema for the adapted type.\n+            force: Whether to force the initialization of the core schema, validator, and serializer.\n+\n+        Returns:\n+            `True` if the core schema, validator, and serializer were successfully initialized, otherwise `False`.\n+        \"\"\"\n+        if not force and self._defer_build:\n+            _mock_val_ser.set_type_adapter_mocks(self, str(self._type))\n+            self._pydantic_complete = False\n+            return False\n+\n         try:\n-            self._core_schema = _getattr_no_parents(self._type, '__pydantic_core_schema__')\n-            self._validator = _getattr_no_parents(self._type, '__pydantic_validator__')\n-            self._serializer = _getattr_no_parents(self._type, '__pydantic_serializer__')\n+            self.core_schema = _getattr_no_parents(self._type, '__pydantic_core_schema__')\n+            self.validator = _getattr_no_parents(self._type, '__pydantic_validator__')\n+            self.serializer = _getattr_no_parents(self._type, '__pydantic_serializer__')\n         except AttributeError:\n             config_wrapper = _config.ConfigWrapper(self._config)\n             core_config = config_wrapper.core_config(None)\n \n-            self._core_schema = _get_schema(self._type, config_wrapper, parent_depth=self._parent_depth)\n-            self._validator = create_schema_validator(\n-                schema=self._core_schema,\n+            self.core_schema = _get_schema(self._type, config_wrapper, ns_resolver=ns_resolver)\n+            self.validator = create_schema_validator(\n+                schema=self.core_schema,\n                 schema_type=self._type,\n                 schema_type_module=self._module_name,\n                 schema_type_name=str(self._type),\n                 schema_kind='TypeAdapter',\n                 config=core_config,\n                 plugin_settings=config_wrapper.plugin_settings,\n             )\n-            self._serializer = SchemaSerializer(self._core_schema, core_config)\n-\n-        if rebuild_mocks and isinstance(self._core_schema, _mock_val_ser.MockCoreSchema):\n-            self._core_schema.rebuild()\n-            self._init_core_attrs(rebuild_mocks=False)\n-            assert not isinstance(self._core_schema, _mock_val_ser.MockCoreSchema)\n-            assert not isinstance(self._validator, _mock_val_ser.MockValSer)\n-            assert not isinstance(self._serializer, _mock_val_ser.MockValSer)\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property and core_schema(self)\n-    def core_schema(self) -> CoreSchema:\n-        \"\"\"The pydantic-core schema used to build the SchemaValidator and SchemaSerializer.\"\"\"\n-        if self._core_schema is None or isinstance(self._core_schema, _mock_val_ser.MockCoreSchema):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockCoreSchema from public function\n-        assert self._core_schema is not None and not isinstance(self._core_schema, _mock_val_ser.MockCoreSchema)\n-        return self._core_schema\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property + validator(self)\n-    def validator(self) -> SchemaValidator | PluggableSchemaValidator:\n-        \"\"\"The pydantic-core SchemaValidator used to validate instances of the model.\"\"\"\n-        if not isinstance(self._validator, (SchemaValidator, PluggableSchemaValidator)):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockValSer from public function\n-        assert isinstance(self._validator, (SchemaValidator, PluggableSchemaValidator))\n-        return self._validator\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property + serializer(self)\n-    def serializer(self) -> SchemaSerializer:\n-        \"\"\"The pydantic-core SchemaSerializer used to dump instances of the model.\"\"\"\n-        if not isinstance(self._serializer, SchemaSerializer):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockValSer from public function\n-        assert isinstance(self._serializer, SchemaSerializer)\n-        return self._serializer\n+            self.serializer = SchemaSerializer(self.core_schema, core_config)\n+\n+        # TODO: I think we should move this to the rebuild pattern?\n+        if isinstance(self.core_schema, _mock_val_ser.MockCoreSchema):\n+            self.core_schema = self.core_schema.rebuild()  # type: ignore[assignment]\n+            self._init_core_attrs(ns_resolver=ns_resolver, force=True)",
        "comment_created_at": "2024-11-12T18:17:48+00:00",
        "comment_author": "MarkusSintonen",
        "comment_body": "Hmm does this do double building, it first calls `self.core_schema.rebuild()` and then in `_init_core_attrs` it again does `_get_schema` which builds also?",
        "pr_file_module": null
      },
      {
        "comment_id": "1840270434",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10537,
        "pr_file": "pydantic/type_adapter.py",
        "discussion_id": "1838568611",
        "commented_code": "@@ -233,100 +208,122 @@ def __init__(\n         self._type = type\n         self._config = config\n         self._parent_depth = _parent_depth\n-        if module is None:\n-            f = sys._getframe(1)\n-            self._module_name = cast(str, f.f_globals.get('__name__', ''))\n-        else:\n-            self._module_name = module\n-\n-        self._core_schema: CoreSchema | None = None\n-        self._validator: SchemaValidator | PluggableSchemaValidator | None = None\n-        self._serializer: SchemaSerializer | None = None\n-\n-        if not self._defer_build():\n-            # Immediately initialize the core schema, validator and serializer\n-            with self._with_frame_depth(1):  # +1 frame depth for this __init__\n-                # Model itself may be using deferred building. For backward compatibility we don't rebuild model mocks\n-                # here as part of __init__ even though TypeAdapter itself is not using deferred building.\n-                self._init_core_attrs(rebuild_mocks=False)\n-\n-    @contextmanager\n-    def _with_frame_depth(self, depth: int) -> Iterator[None]:\n-        self._parent_depth += depth\n-        try:\n-            yield\n-        finally:\n-            self._parent_depth -= depth\n \n-    @_frame_depth(1)\n-    def _init_core_attrs(self, rebuild_mocks: bool) -> None:\n+        self.core_schema: CoreSchema\n+        self.validator: SchemaValidator | PluggableSchemaValidator\n+        self.serializer: SchemaSerializer\n+\n+        localns: _namespace_utils.MappingNamespace = (\n+            _typing_extra.parent_frame_namespace(parent_depth=self._parent_depth) or {}\n+        )\n+        globalns: _namespace_utils.MappingNamespace = sys._getframe(max(self._parent_depth - 1, 1)).f_globals\n+        self._module_name = module or cast(str, globalns.get('__name__', ''))\n+        self._init_core_attrs(\n+            ns_resolver=_namespace_utils.NsResolver(\n+                namespaces_tuple=_namespace_utils.NamespacesTuple(locals=localns, globals=globalns),\n+                parent_namespace=localns,\n+            ),\n+            force=False,\n+        )\n+\n+    def _init_core_attrs(self, ns_resolver: _namespace_utils.NsResolver, force: bool) -> bool:\n+        \"\"\"Initialize the core schema, validator, and serializer for the type.\n+\n+        If `force` is set to `False` and `_defer_build` is `True`, the core schema, validator, and serializer will be set to mocks.\n+\n+        Args:\n+            ns_resolver: The namespace resolver to use when building the core schema for the adapted type.\n+            force: Whether to force the initialization of the core schema, validator, and serializer.\n+\n+        Returns:\n+            `True` if the core schema, validator, and serializer were successfully initialized, otherwise `False`.\n+        \"\"\"\n+        if not force and self._defer_build:\n+            _mock_val_ser.set_type_adapter_mocks(self, str(self._type))\n+            self._pydantic_complete = False\n+            return False\n+\n         try:\n-            self._core_schema = _getattr_no_parents(self._type, '__pydantic_core_schema__')\n-            self._validator = _getattr_no_parents(self._type, '__pydantic_validator__')\n-            self._serializer = _getattr_no_parents(self._type, '__pydantic_serializer__')\n+            self.core_schema = _getattr_no_parents(self._type, '__pydantic_core_schema__')\n+            self.validator = _getattr_no_parents(self._type, '__pydantic_validator__')\n+            self.serializer = _getattr_no_parents(self._type, '__pydantic_serializer__')\n         except AttributeError:\n             config_wrapper = _config.ConfigWrapper(self._config)\n             core_config = config_wrapper.core_config(None)\n \n-            self._core_schema = _get_schema(self._type, config_wrapper, parent_depth=self._parent_depth)\n-            self._validator = create_schema_validator(\n-                schema=self._core_schema,\n+            self.core_schema = _get_schema(self._type, config_wrapper, ns_resolver=ns_resolver)\n+            self.validator = create_schema_validator(\n+                schema=self.core_schema,\n                 schema_type=self._type,\n                 schema_type_module=self._module_name,\n                 schema_type_name=str(self._type),\n                 schema_kind='TypeAdapter',\n                 config=core_config,\n                 plugin_settings=config_wrapper.plugin_settings,\n             )\n-            self._serializer = SchemaSerializer(self._core_schema, core_config)\n-\n-        if rebuild_mocks and isinstance(self._core_schema, _mock_val_ser.MockCoreSchema):\n-            self._core_schema.rebuild()\n-            self._init_core_attrs(rebuild_mocks=False)\n-            assert not isinstance(self._core_schema, _mock_val_ser.MockCoreSchema)\n-            assert not isinstance(self._validator, _mock_val_ser.MockValSer)\n-            assert not isinstance(self._serializer, _mock_val_ser.MockValSer)\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property and core_schema(self)\n-    def core_schema(self) -> CoreSchema:\n-        \"\"\"The pydantic-core schema used to build the SchemaValidator and SchemaSerializer.\"\"\"\n-        if self._core_schema is None or isinstance(self._core_schema, _mock_val_ser.MockCoreSchema):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockCoreSchema from public function\n-        assert self._core_schema is not None and not isinstance(self._core_schema, _mock_val_ser.MockCoreSchema)\n-        return self._core_schema\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property + validator(self)\n-    def validator(self) -> SchemaValidator | PluggableSchemaValidator:\n-        \"\"\"The pydantic-core SchemaValidator used to validate instances of the model.\"\"\"\n-        if not isinstance(self._validator, (SchemaValidator, PluggableSchemaValidator)):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockValSer from public function\n-        assert isinstance(self._validator, (SchemaValidator, PluggableSchemaValidator))\n-        return self._validator\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property + serializer(self)\n-    def serializer(self) -> SchemaSerializer:\n-        \"\"\"The pydantic-core SchemaSerializer used to dump instances of the model.\"\"\"\n-        if not isinstance(self._serializer, SchemaSerializer):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockValSer from public function\n-        assert isinstance(self._serializer, SchemaSerializer)\n-        return self._serializer\n+            self.serializer = SchemaSerializer(self.core_schema, core_config)\n+\n+        # TODO: I think we should move this to the rebuild pattern?\n+        if isinstance(self.core_schema, _mock_val_ser.MockCoreSchema):\n+            self.core_schema = self.core_schema.rebuild()  # type: ignore[assignment]\n+            self._init_core_attrs(ns_resolver=ns_resolver, force=True)",
        "comment_created_at": "2024-11-13T13:24:43+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "Good question, looking into this.",
        "pr_file_module": null
      },
      {
        "comment_id": "1840292465",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10537,
        "pr_file": "pydantic/type_adapter.py",
        "discussion_id": "1838568611",
        "commented_code": "@@ -233,100 +208,122 @@ def __init__(\n         self._type = type\n         self._config = config\n         self._parent_depth = _parent_depth\n-        if module is None:\n-            f = sys._getframe(1)\n-            self._module_name = cast(str, f.f_globals.get('__name__', ''))\n-        else:\n-            self._module_name = module\n-\n-        self._core_schema: CoreSchema | None = None\n-        self._validator: SchemaValidator | PluggableSchemaValidator | None = None\n-        self._serializer: SchemaSerializer | None = None\n-\n-        if not self._defer_build():\n-            # Immediately initialize the core schema, validator and serializer\n-            with self._with_frame_depth(1):  # +1 frame depth for this __init__\n-                # Model itself may be using deferred building. For backward compatibility we don't rebuild model mocks\n-                # here as part of __init__ even though TypeAdapter itself is not using deferred building.\n-                self._init_core_attrs(rebuild_mocks=False)\n-\n-    @contextmanager\n-    def _with_frame_depth(self, depth: int) -> Iterator[None]:\n-        self._parent_depth += depth\n-        try:\n-            yield\n-        finally:\n-            self._parent_depth -= depth\n \n-    @_frame_depth(1)\n-    def _init_core_attrs(self, rebuild_mocks: bool) -> None:\n+        self.core_schema: CoreSchema\n+        self.validator: SchemaValidator | PluggableSchemaValidator\n+        self.serializer: SchemaSerializer\n+\n+        localns: _namespace_utils.MappingNamespace = (\n+            _typing_extra.parent_frame_namespace(parent_depth=self._parent_depth) or {}\n+        )\n+        globalns: _namespace_utils.MappingNamespace = sys._getframe(max(self._parent_depth - 1, 1)).f_globals\n+        self._module_name = module or cast(str, globalns.get('__name__', ''))\n+        self._init_core_attrs(\n+            ns_resolver=_namespace_utils.NsResolver(\n+                namespaces_tuple=_namespace_utils.NamespacesTuple(locals=localns, globals=globalns),\n+                parent_namespace=localns,\n+            ),\n+            force=False,\n+        )\n+\n+    def _init_core_attrs(self, ns_resolver: _namespace_utils.NsResolver, force: bool) -> bool:\n+        \"\"\"Initialize the core schema, validator, and serializer for the type.\n+\n+        If `force` is set to `False` and `_defer_build` is `True`, the core schema, validator, and serializer will be set to mocks.\n+\n+        Args:\n+            ns_resolver: The namespace resolver to use when building the core schema for the adapted type.\n+            force: Whether to force the initialization of the core schema, validator, and serializer.\n+\n+        Returns:\n+            `True` if the core schema, validator, and serializer were successfully initialized, otherwise `False`.\n+        \"\"\"\n+        if not force and self._defer_build:\n+            _mock_val_ser.set_type_adapter_mocks(self, str(self._type))\n+            self._pydantic_complete = False\n+            return False\n+\n         try:\n-            self._core_schema = _getattr_no_parents(self._type, '__pydantic_core_schema__')\n-            self._validator = _getattr_no_parents(self._type, '__pydantic_validator__')\n-            self._serializer = _getattr_no_parents(self._type, '__pydantic_serializer__')\n+            self.core_schema = _getattr_no_parents(self._type, '__pydantic_core_schema__')\n+            self.validator = _getattr_no_parents(self._type, '__pydantic_validator__')\n+            self.serializer = _getattr_no_parents(self._type, '__pydantic_serializer__')\n         except AttributeError:\n             config_wrapper = _config.ConfigWrapper(self._config)\n             core_config = config_wrapper.core_config(None)\n \n-            self._core_schema = _get_schema(self._type, config_wrapper, parent_depth=self._parent_depth)\n-            self._validator = create_schema_validator(\n-                schema=self._core_schema,\n+            self.core_schema = _get_schema(self._type, config_wrapper, ns_resolver=ns_resolver)\n+            self.validator = create_schema_validator(\n+                schema=self.core_schema,\n                 schema_type=self._type,\n                 schema_type_module=self._module_name,\n                 schema_type_name=str(self._type),\n                 schema_kind='TypeAdapter',\n                 config=core_config,\n                 plugin_settings=config_wrapper.plugin_settings,\n             )\n-            self._serializer = SchemaSerializer(self._core_schema, core_config)\n-\n-        if rebuild_mocks and isinstance(self._core_schema, _mock_val_ser.MockCoreSchema):\n-            self._core_schema.rebuild()\n-            self._init_core_attrs(rebuild_mocks=False)\n-            assert not isinstance(self._core_schema, _mock_val_ser.MockCoreSchema)\n-            assert not isinstance(self._validator, _mock_val_ser.MockValSer)\n-            assert not isinstance(self._serializer, _mock_val_ser.MockValSer)\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property and core_schema(self)\n-    def core_schema(self) -> CoreSchema:\n-        \"\"\"The pydantic-core schema used to build the SchemaValidator and SchemaSerializer.\"\"\"\n-        if self._core_schema is None or isinstance(self._core_schema, _mock_val_ser.MockCoreSchema):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockCoreSchema from public function\n-        assert self._core_schema is not None and not isinstance(self._core_schema, _mock_val_ser.MockCoreSchema)\n-        return self._core_schema\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property + validator(self)\n-    def validator(self) -> SchemaValidator | PluggableSchemaValidator:\n-        \"\"\"The pydantic-core SchemaValidator used to validate instances of the model.\"\"\"\n-        if not isinstance(self._validator, (SchemaValidator, PluggableSchemaValidator)):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockValSer from public function\n-        assert isinstance(self._validator, (SchemaValidator, PluggableSchemaValidator))\n-        return self._validator\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property + serializer(self)\n-    def serializer(self) -> SchemaSerializer:\n-        \"\"\"The pydantic-core SchemaSerializer used to dump instances of the model.\"\"\"\n-        if not isinstance(self._serializer, SchemaSerializer):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockValSer from public function\n-        assert isinstance(self._serializer, SchemaSerializer)\n-        return self._serializer\n+            self.serializer = SchemaSerializer(self.core_schema, core_config)\n+\n+        # TODO: I think we should move this to the rebuild pattern?\n+        if isinstance(self.core_schema, _mock_val_ser.MockCoreSchema):\n+            self.core_schema = self.core_schema.rebuild()  # type: ignore[assignment]\n+            self._init_core_attrs(ns_resolver=ns_resolver, force=True)",
        "comment_created_at": "2024-11-13T13:35:34+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "So, this happens when we have a model that deferred (or failed) schema building.\r\n\r\nI think this logic needs to be more complex - should we reassign `__pydantic_core_schema__`? What about `__pydantic_validator__` and `__pydantic_serializer__`?",
        "pr_file_module": null
      },
      {
        "comment_id": "1840357329",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10537,
        "pr_file": "pydantic/type_adapter.py",
        "discussion_id": "1838568611",
        "commented_code": "@@ -233,100 +208,122 @@ def __init__(\n         self._type = type\n         self._config = config\n         self._parent_depth = _parent_depth\n-        if module is None:\n-            f = sys._getframe(1)\n-            self._module_name = cast(str, f.f_globals.get('__name__', ''))\n-        else:\n-            self._module_name = module\n-\n-        self._core_schema: CoreSchema | None = None\n-        self._validator: SchemaValidator | PluggableSchemaValidator | None = None\n-        self._serializer: SchemaSerializer | None = None\n-\n-        if not self._defer_build():\n-            # Immediately initialize the core schema, validator and serializer\n-            with self._with_frame_depth(1):  # +1 frame depth for this __init__\n-                # Model itself may be using deferred building. For backward compatibility we don't rebuild model mocks\n-                # here as part of __init__ even though TypeAdapter itself is not using deferred building.\n-                self._init_core_attrs(rebuild_mocks=False)\n-\n-    @contextmanager\n-    def _with_frame_depth(self, depth: int) -> Iterator[None]:\n-        self._parent_depth += depth\n-        try:\n-            yield\n-        finally:\n-            self._parent_depth -= depth\n \n-    @_frame_depth(1)\n-    def _init_core_attrs(self, rebuild_mocks: bool) -> None:\n+        self.core_schema: CoreSchema\n+        self.validator: SchemaValidator | PluggableSchemaValidator\n+        self.serializer: SchemaSerializer\n+\n+        localns: _namespace_utils.MappingNamespace = (\n+            _typing_extra.parent_frame_namespace(parent_depth=self._parent_depth) or {}\n+        )\n+        globalns: _namespace_utils.MappingNamespace = sys._getframe(max(self._parent_depth - 1, 1)).f_globals\n+        self._module_name = module or cast(str, globalns.get('__name__', ''))\n+        self._init_core_attrs(\n+            ns_resolver=_namespace_utils.NsResolver(\n+                namespaces_tuple=_namespace_utils.NamespacesTuple(locals=localns, globals=globalns),\n+                parent_namespace=localns,\n+            ),\n+            force=False,\n+        )\n+\n+    def _init_core_attrs(self, ns_resolver: _namespace_utils.NsResolver, force: bool) -> bool:\n+        \"\"\"Initialize the core schema, validator, and serializer for the type.\n+\n+        If `force` is set to `False` and `_defer_build` is `True`, the core schema, validator, and serializer will be set to mocks.\n+\n+        Args:\n+            ns_resolver: The namespace resolver to use when building the core schema for the adapted type.\n+            force: Whether to force the initialization of the core schema, validator, and serializer.\n+\n+        Returns:\n+            `True` if the core schema, validator, and serializer were successfully initialized, otherwise `False`.\n+        \"\"\"\n+        if not force and self._defer_build:\n+            _mock_val_ser.set_type_adapter_mocks(self, str(self._type))\n+            self._pydantic_complete = False\n+            return False\n+\n         try:\n-            self._core_schema = _getattr_no_parents(self._type, '__pydantic_core_schema__')\n-            self._validator = _getattr_no_parents(self._type, '__pydantic_validator__')\n-            self._serializer = _getattr_no_parents(self._type, '__pydantic_serializer__')\n+            self.core_schema = _getattr_no_parents(self._type, '__pydantic_core_schema__')\n+            self.validator = _getattr_no_parents(self._type, '__pydantic_validator__')\n+            self.serializer = _getattr_no_parents(self._type, '__pydantic_serializer__')\n         except AttributeError:\n             config_wrapper = _config.ConfigWrapper(self._config)\n             core_config = config_wrapper.core_config(None)\n \n-            self._core_schema = _get_schema(self._type, config_wrapper, parent_depth=self._parent_depth)\n-            self._validator = create_schema_validator(\n-                schema=self._core_schema,\n+            self.core_schema = _get_schema(self._type, config_wrapper, ns_resolver=ns_resolver)\n+            self.validator = create_schema_validator(\n+                schema=self.core_schema,\n                 schema_type=self._type,\n                 schema_type_module=self._module_name,\n                 schema_type_name=str(self._type),\n                 schema_kind='TypeAdapter',\n                 config=core_config,\n                 plugin_settings=config_wrapper.plugin_settings,\n             )\n-            self._serializer = SchemaSerializer(self._core_schema, core_config)\n-\n-        if rebuild_mocks and isinstance(self._core_schema, _mock_val_ser.MockCoreSchema):\n-            self._core_schema.rebuild()\n-            self._init_core_attrs(rebuild_mocks=False)\n-            assert not isinstance(self._core_schema, _mock_val_ser.MockCoreSchema)\n-            assert not isinstance(self._validator, _mock_val_ser.MockValSer)\n-            assert not isinstance(self._serializer, _mock_val_ser.MockValSer)\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property and core_schema(self)\n-    def core_schema(self) -> CoreSchema:\n-        \"\"\"The pydantic-core schema used to build the SchemaValidator and SchemaSerializer.\"\"\"\n-        if self._core_schema is None or isinstance(self._core_schema, _mock_val_ser.MockCoreSchema):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockCoreSchema from public function\n-        assert self._core_schema is not None and not isinstance(self._core_schema, _mock_val_ser.MockCoreSchema)\n-        return self._core_schema\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property + validator(self)\n-    def validator(self) -> SchemaValidator | PluggableSchemaValidator:\n-        \"\"\"The pydantic-core SchemaValidator used to validate instances of the model.\"\"\"\n-        if not isinstance(self._validator, (SchemaValidator, PluggableSchemaValidator)):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockValSer from public function\n-        assert isinstance(self._validator, (SchemaValidator, PluggableSchemaValidator))\n-        return self._validator\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property + serializer(self)\n-    def serializer(self) -> SchemaSerializer:\n-        \"\"\"The pydantic-core SchemaSerializer used to dump instances of the model.\"\"\"\n-        if not isinstance(self._serializer, SchemaSerializer):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockValSer from public function\n-        assert isinstance(self._serializer, SchemaSerializer)\n-        return self._serializer\n+            self.serializer = SchemaSerializer(self.core_schema, core_config)\n+\n+        # TODO: I think we should move this to the rebuild pattern?\n+        if isinstance(self.core_schema, _mock_val_ser.MockCoreSchema):\n+            self.core_schema = self.core_schema.rebuild()  # type: ignore[assignment]\n+            self._init_core_attrs(ns_resolver=ns_resolver, force=True)",
        "comment_created_at": "2024-11-13T14:09:40+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "I've updated this - we no longer do the recursive call :).",
        "pr_file_module": null
      },
      {
        "comment_id": "1840597883",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10537,
        "pr_file": "pydantic/type_adapter.py",
        "discussion_id": "1838568611",
        "commented_code": "@@ -233,100 +208,122 @@ def __init__(\n         self._type = type\n         self._config = config\n         self._parent_depth = _parent_depth\n-        if module is None:\n-            f = sys._getframe(1)\n-            self._module_name = cast(str, f.f_globals.get('__name__', ''))\n-        else:\n-            self._module_name = module\n-\n-        self._core_schema: CoreSchema | None = None\n-        self._validator: SchemaValidator | PluggableSchemaValidator | None = None\n-        self._serializer: SchemaSerializer | None = None\n-\n-        if not self._defer_build():\n-            # Immediately initialize the core schema, validator and serializer\n-            with self._with_frame_depth(1):  # +1 frame depth for this __init__\n-                # Model itself may be using deferred building. For backward compatibility we don't rebuild model mocks\n-                # here as part of __init__ even though TypeAdapter itself is not using deferred building.\n-                self._init_core_attrs(rebuild_mocks=False)\n-\n-    @contextmanager\n-    def _with_frame_depth(self, depth: int) -> Iterator[None]:\n-        self._parent_depth += depth\n-        try:\n-            yield\n-        finally:\n-            self._parent_depth -= depth\n \n-    @_frame_depth(1)\n-    def _init_core_attrs(self, rebuild_mocks: bool) -> None:\n+        self.core_schema: CoreSchema\n+        self.validator: SchemaValidator | PluggableSchemaValidator\n+        self.serializer: SchemaSerializer\n+\n+        localns: _namespace_utils.MappingNamespace = (\n+            _typing_extra.parent_frame_namespace(parent_depth=self._parent_depth) or {}\n+        )\n+        globalns: _namespace_utils.MappingNamespace = sys._getframe(max(self._parent_depth - 1, 1)).f_globals\n+        self._module_name = module or cast(str, globalns.get('__name__', ''))\n+        self._init_core_attrs(\n+            ns_resolver=_namespace_utils.NsResolver(\n+                namespaces_tuple=_namespace_utils.NamespacesTuple(locals=localns, globals=globalns),\n+                parent_namespace=localns,\n+            ),\n+            force=False,\n+        )\n+\n+    def _init_core_attrs(self, ns_resolver: _namespace_utils.NsResolver, force: bool) -> bool:\n+        \"\"\"Initialize the core schema, validator, and serializer for the type.\n+\n+        If `force` is set to `False` and `_defer_build` is `True`, the core schema, validator, and serializer will be set to mocks.\n+\n+        Args:\n+            ns_resolver: The namespace resolver to use when building the core schema for the adapted type.\n+            force: Whether to force the initialization of the core schema, validator, and serializer.\n+\n+        Returns:\n+            `True` if the core schema, validator, and serializer were successfully initialized, otherwise `False`.\n+        \"\"\"\n+        if not force and self._defer_build:\n+            _mock_val_ser.set_type_adapter_mocks(self, str(self._type))\n+            self._pydantic_complete = False\n+            return False\n+\n         try:\n-            self._core_schema = _getattr_no_parents(self._type, '__pydantic_core_schema__')\n-            self._validator = _getattr_no_parents(self._type, '__pydantic_validator__')\n-            self._serializer = _getattr_no_parents(self._type, '__pydantic_serializer__')\n+            self.core_schema = _getattr_no_parents(self._type, '__pydantic_core_schema__')\n+            self.validator = _getattr_no_parents(self._type, '__pydantic_validator__')\n+            self.serializer = _getattr_no_parents(self._type, '__pydantic_serializer__')\n         except AttributeError:\n             config_wrapper = _config.ConfigWrapper(self._config)\n             core_config = config_wrapper.core_config(None)\n \n-            self._core_schema = _get_schema(self._type, config_wrapper, parent_depth=self._parent_depth)\n-            self._validator = create_schema_validator(\n-                schema=self._core_schema,\n+            self.core_schema = _get_schema(self._type, config_wrapper, ns_resolver=ns_resolver)\n+            self.validator = create_schema_validator(\n+                schema=self.core_schema,\n                 schema_type=self._type,\n                 schema_type_module=self._module_name,\n                 schema_type_name=str(self._type),\n                 schema_kind='TypeAdapter',\n                 config=core_config,\n                 plugin_settings=config_wrapper.plugin_settings,\n             )\n-            self._serializer = SchemaSerializer(self._core_schema, core_config)\n-\n-        if rebuild_mocks and isinstance(self._core_schema, _mock_val_ser.MockCoreSchema):\n-            self._core_schema.rebuild()\n-            self._init_core_attrs(rebuild_mocks=False)\n-            assert not isinstance(self._core_schema, _mock_val_ser.MockCoreSchema)\n-            assert not isinstance(self._validator, _mock_val_ser.MockValSer)\n-            assert not isinstance(self._serializer, _mock_val_ser.MockValSer)\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property and core_schema(self)\n-    def core_schema(self) -> CoreSchema:\n-        \"\"\"The pydantic-core schema used to build the SchemaValidator and SchemaSerializer.\"\"\"\n-        if self._core_schema is None or isinstance(self._core_schema, _mock_val_ser.MockCoreSchema):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockCoreSchema from public function\n-        assert self._core_schema is not None and not isinstance(self._core_schema, _mock_val_ser.MockCoreSchema)\n-        return self._core_schema\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property + validator(self)\n-    def validator(self) -> SchemaValidator | PluggableSchemaValidator:\n-        \"\"\"The pydantic-core SchemaValidator used to validate instances of the model.\"\"\"\n-        if not isinstance(self._validator, (SchemaValidator, PluggableSchemaValidator)):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockValSer from public function\n-        assert isinstance(self._validator, (SchemaValidator, PluggableSchemaValidator))\n-        return self._validator\n-\n-    @cached_property\n-    @_frame_depth(2)  # +2 for @cached_property + serializer(self)\n-    def serializer(self) -> SchemaSerializer:\n-        \"\"\"The pydantic-core SchemaSerializer used to dump instances of the model.\"\"\"\n-        if not isinstance(self._serializer, SchemaSerializer):\n-            self._init_core_attrs(rebuild_mocks=True)  # Do not expose MockValSer from public function\n-        assert isinstance(self._serializer, SchemaSerializer)\n-        return self._serializer\n+            self.serializer = SchemaSerializer(self.core_schema, core_config)\n+\n+        # TODO: I think we should move this to the rebuild pattern?\n+        if isinstance(self.core_schema, _mock_val_ser.MockCoreSchema):\n+            self.core_schema = self.core_schema.rebuild()  # type: ignore[assignment]\n+            self._init_core_attrs(ns_resolver=ns_resolver, force=True)",
        "comment_created_at": "2024-11-13T15:29:12+00:00",
        "comment_author": "MarkusSintonen",
        "comment_body": "@sydney-runkle was there some test against the duplicated schema building issue? To test the the GenerateSchema is called only ones in this scenario, in case there was a bug here?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1838647449",
    "pr_number": 10537,
    "pr_file": "pydantic/type_adapter.py",
    "created_at": "2024-11-12T19:25:14+00:00",
    "commented_code": "self._type = type\n         self._config = config\n         self._parent_depth = _parent_depth\n-        if module is None:\n-            f = sys._getframe(1)\n-            self._module_name = cast(str, f.f_globals.get('__name__', ''))\n-        else:\n-            self._module_name = module\n-\n-        self._core_schema: CoreSchema | None = None\n-        self._validator: SchemaValidator | PluggableSchemaValidator | None = None\n-        self._serializer: SchemaSerializer | None = None\n-\n-        if not self._defer_build():\n-            # Immediately initialize the core schema, validator and serializer\n-            with self._with_frame_depth(1):  # +1 frame depth for this __init__\n-                # Model itself may be using deferred building. For backward compatibility we don't rebuild model mocks\n-                # here as part of __init__ even though TypeAdapter itself is not using deferred building.\n-                self._init_core_attrs(rebuild_mocks=False)\n-\n-    @contextmanager\n-    def _with_frame_depth(self, depth: int) -> Iterator[None]:\n-        self._parent_depth += depth\n-        try:\n-            yield\n-        finally:\n-            self._parent_depth -= depth\n \n-    @_frame_depth(1)\n-    def _init_core_attrs(self, rebuild_mocks: bool) -> None:\n+        self.core_schema: CoreSchema\n+        self.validator: SchemaValidator | PluggableSchemaValidator\n+        self.serializer: SchemaSerializer\n+\n+        localns: _namespace_utils.MappingNamespace = (\n+            _typing_extra.parent_frame_namespace(parent_depth=self._parent_depth) or {}\n+        )\n+        globalns: _namespace_utils.MappingNamespace = sys._getframe(max(self._parent_depth - 1, 1)).f_globals\n+        self._module_name = module or cast(str, globalns.get('__name__', ''))\n+        self._init_core_attrs(\n+            ns_resolver=_namespace_utils.NsResolver(\n+                namespaces_tuple=_namespace_utils.NamespacesTuple(locals=localns, globals=globalns),\n+                parent_namespace=localns,\n+            ),\n+            force=False,\n+        )\n+\n+    def _init_core_attrs(self, ns_resolver: _namespace_utils.NsResolver, force: bool) -> bool:\n+        \"\"\"Initialize the core schema, validator, and serializer for the type.\n+\n+        If `force` is set to `False` and `_defer_build` is `True`, the core schema, validator, and serializer will be set to mocks.\n+\n+        Args:\n+            ns_resolver: The namespace resolver to use when building the core schema for the adapted type.\n+            force: Whether to force the initialization of the core schema, validator, and serializer.\n+\n+        Returns:\n+            `True` if the core schema, validator, and serializer were successfully initialized, otherwise `False`.\n+\n+        Notes on namespace management, and subtle differences from `BaseModel`:\n+\n+            `BaseModel` uses its own `__module__` to find out where it was defined\n+            and then looks for symbols to resolve forward references in those globals.\n+            On the other hand, `TypeAdapter` can be initialized with arbitrary objects,\n+            including type aliases, where `__module__` (always `typing.py`) is not useful.",
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "1838647449",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10537,
        "pr_file": "pydantic/type_adapter.py",
        "discussion_id": "1838647449",
        "commented_code": "@@ -233,100 +156,174 @@ def __init__(\n         self._type = type\n         self._config = config\n         self._parent_depth = _parent_depth\n-        if module is None:\n-            f = sys._getframe(1)\n-            self._module_name = cast(str, f.f_globals.get('__name__', ''))\n-        else:\n-            self._module_name = module\n-\n-        self._core_schema: CoreSchema | None = None\n-        self._validator: SchemaValidator | PluggableSchemaValidator | None = None\n-        self._serializer: SchemaSerializer | None = None\n-\n-        if not self._defer_build():\n-            # Immediately initialize the core schema, validator and serializer\n-            with self._with_frame_depth(1):  # +1 frame depth for this __init__\n-                # Model itself may be using deferred building. For backward compatibility we don't rebuild model mocks\n-                # here as part of __init__ even though TypeAdapter itself is not using deferred building.\n-                self._init_core_attrs(rebuild_mocks=False)\n-\n-    @contextmanager\n-    def _with_frame_depth(self, depth: int) -> Iterator[None]:\n-        self._parent_depth += depth\n-        try:\n-            yield\n-        finally:\n-            self._parent_depth -= depth\n \n-    @_frame_depth(1)\n-    def _init_core_attrs(self, rebuild_mocks: bool) -> None:\n+        self.core_schema: CoreSchema\n+        self.validator: SchemaValidator | PluggableSchemaValidator\n+        self.serializer: SchemaSerializer\n+\n+        localns: _namespace_utils.MappingNamespace = (\n+            _typing_extra.parent_frame_namespace(parent_depth=self._parent_depth) or {}\n+        )\n+        globalns: _namespace_utils.MappingNamespace = sys._getframe(max(self._parent_depth - 1, 1)).f_globals\n+        self._module_name = module or cast(str, globalns.get('__name__', ''))\n+        self._init_core_attrs(\n+            ns_resolver=_namespace_utils.NsResolver(\n+                namespaces_tuple=_namespace_utils.NamespacesTuple(locals=localns, globals=globalns),\n+                parent_namespace=localns,\n+            ),\n+            force=False,\n+        )\n+\n+    def _init_core_attrs(self, ns_resolver: _namespace_utils.NsResolver, force: bool) -> bool:\n+        \"\"\"Initialize the core schema, validator, and serializer for the type.\n+\n+        If `force` is set to `False` and `_defer_build` is `True`, the core schema, validator, and serializer will be set to mocks.\n+\n+        Args:\n+            ns_resolver: The namespace resolver to use when building the core schema for the adapted type.\n+            force: Whether to force the initialization of the core schema, validator, and serializer.\n+\n+        Returns:\n+            `True` if the core schema, validator, and serializer were successfully initialized, otherwise `False`.\n+\n+        Notes on namespace management, and subtle differences from `BaseModel`:\n+\n+            `BaseModel` uses its own `__module__` to find out where it was defined\n+            and then looks for symbols to resolve forward references in those globals.\n+            On the other hand, `TypeAdapter` can be initialized with arbitrary objects,\n+            including type aliases, where `__module__` (always `typing.py`) is not useful.",
        "comment_created_at": "2024-11-12T19:25:14+00:00",
        "comment_author": "Viicos",
        "comment_body": "```suggestion\r\n            which may not be types and thus do not have a `__module__` available\r\n```\r\n\r\nmaybe? I think the most common example is `SomeType = list[...]`, and is more common that PEP 695 type aliases. I think it's best to emphasize on the fact that most objects passed to type adapters are _instances_ (e.g. `type A = int`, `A` is instance of a `TypeAliasType`).",
        "pr_file_module": null
      },
      {
        "comment_id": "1838654703",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10537,
        "pr_file": "pydantic/type_adapter.py",
        "discussion_id": "1838647449",
        "commented_code": "@@ -233,100 +156,174 @@ def __init__(\n         self._type = type\n         self._config = config\n         self._parent_depth = _parent_depth\n-        if module is None:\n-            f = sys._getframe(1)\n-            self._module_name = cast(str, f.f_globals.get('__name__', ''))\n-        else:\n-            self._module_name = module\n-\n-        self._core_schema: CoreSchema | None = None\n-        self._validator: SchemaValidator | PluggableSchemaValidator | None = None\n-        self._serializer: SchemaSerializer | None = None\n-\n-        if not self._defer_build():\n-            # Immediately initialize the core schema, validator and serializer\n-            with self._with_frame_depth(1):  # +1 frame depth for this __init__\n-                # Model itself may be using deferred building. For backward compatibility we don't rebuild model mocks\n-                # here as part of __init__ even though TypeAdapter itself is not using deferred building.\n-                self._init_core_attrs(rebuild_mocks=False)\n-\n-    @contextmanager\n-    def _with_frame_depth(self, depth: int) -> Iterator[None]:\n-        self._parent_depth += depth\n-        try:\n-            yield\n-        finally:\n-            self._parent_depth -= depth\n \n-    @_frame_depth(1)\n-    def _init_core_attrs(self, rebuild_mocks: bool) -> None:\n+        self.core_schema: CoreSchema\n+        self.validator: SchemaValidator | PluggableSchemaValidator\n+        self.serializer: SchemaSerializer\n+\n+        localns: _namespace_utils.MappingNamespace = (\n+            _typing_extra.parent_frame_namespace(parent_depth=self._parent_depth) or {}\n+        )\n+        globalns: _namespace_utils.MappingNamespace = sys._getframe(max(self._parent_depth - 1, 1)).f_globals\n+        self._module_name = module or cast(str, globalns.get('__name__', ''))\n+        self._init_core_attrs(\n+            ns_resolver=_namespace_utils.NsResolver(\n+                namespaces_tuple=_namespace_utils.NamespacesTuple(locals=localns, globals=globalns),\n+                parent_namespace=localns,\n+            ),\n+            force=False,\n+        )\n+\n+    def _init_core_attrs(self, ns_resolver: _namespace_utils.NsResolver, force: bool) -> bool:\n+        \"\"\"Initialize the core schema, validator, and serializer for the type.\n+\n+        If `force` is set to `False` and `_defer_build` is `True`, the core schema, validator, and serializer will be set to mocks.\n+\n+        Args:\n+            ns_resolver: The namespace resolver to use when building the core schema for the adapted type.\n+            force: Whether to force the initialization of the core schema, validator, and serializer.\n+\n+        Returns:\n+            `True` if the core schema, validator, and serializer were successfully initialized, otherwise `False`.\n+\n+        Notes on namespace management, and subtle differences from `BaseModel`:\n+\n+            `BaseModel` uses its own `__module__` to find out where it was defined\n+            and then looks for symbols to resolve forward references in those globals.\n+            On the other hand, `TypeAdapter` can be initialized with arbitrary objects,\n+            including type aliases, where `__module__` (always `typing.py`) is not useful.",
        "comment_created_at": "2024-11-12T19:31:52+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "Good call, done.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1822139922",
    "pr_number": 10725,
    "pr_file": "pydantic/_internal/_repr.py",
    "created_at": "2024-10-30T08:48:00+00:00",
    "commented_code": null,
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "1822139922",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10725,
        "pr_file": "pydantic/_internal/_repr.py",
        "discussion_id": "1822139922",
        "commented_code": null,
        "comment_created_at": "2024-10-30T08:48:00+00:00",
        "comment_author": "Viicos",
        "comment_body": "This `display_as_type` function needs to be refactored, as it is relatively expensive to recursively check for `get_origin`, `get_args`, etc. It is currently used:\r\n- In `FieldInfo.__repr_args__`, to make a string representation of the `annotation` attribute. This can be kept.\r\n- In `get_type_ref`, called for each arg of a parametrized type. We should find a simpler way to generate a core schema reference.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1829698083",
    "pr_number": 10766,
    "pr_file": "pydantic/networks.py",
    "created_at": "2024-11-05T16:53:51+00:00",
    "commented_code": "return schema\n \n \n-class _BaseMultiHostUrl(MultiHostUrl):\n+class _BaseMultiHostUrl:\n     _constraints: ClassVar[UrlConstraints] = UrlConstraints()\n+    _url: _CoreMultiHostUrl\n+\n+    @cached_property\n+    def _validator(self) -> TypeAdapter:\n+        return TypeAdapter(self.__class__)",
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "1829698083",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10766,
        "pr_file": "pydantic/networks.py",
        "discussion_id": "1829698083",
        "commented_code": "@@ -118,13 +287,160 @@ def __get_pydantic_core_schema__(cls, source: type[Any], handler: GetCoreSchemaH\n             return schema\n \n \n-class _BaseMultiHostUrl(MultiHostUrl):\n+class _BaseMultiHostUrl:\n     _constraints: ClassVar[UrlConstraints] = UrlConstraints()\n+    _url: _CoreMultiHostUrl\n+\n+    @cached_property\n+    def _validator(self) -> TypeAdapter:\n+        return TypeAdapter(self.__class__)",
        "comment_created_at": "2024-11-05T16:53:51+00:00",
        "comment_author": "davidhewitt",
        "comment_body": "It feels like it could be both simpler and more efficient if here this `TypeAdapter` just built the underlying rust `Url`, with appropriate constraints? Is there a reason why that might be problematic for subclasses? \ud83e\udd14 ",
        "pr_file_module": null
      },
      {
        "comment_id": "1829716312",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10766,
        "pr_file": "pydantic/networks.py",
        "discussion_id": "1829698083",
        "commented_code": "@@ -118,13 +287,160 @@ def __get_pydantic_core_schema__(cls, source: type[Any], handler: GetCoreSchemaH\n             return schema\n \n \n-class _BaseMultiHostUrl(MultiHostUrl):\n+class _BaseMultiHostUrl:\n     _constraints: ClassVar[UrlConstraints] = UrlConstraints()\n+    _url: _CoreMultiHostUrl\n+\n+    @cached_property\n+    def _validator(self) -> TypeAdapter:\n+        return TypeAdapter(self.__class__)",
        "comment_created_at": "2024-11-05T17:04:26+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "Hmm, I don't think there's an easy way to do this - you can't easily create a `TypeAdapter` with just a core schema. Even if we could hack that together, should we?",
        "pr_file_module": null
      },
      {
        "comment_id": "1829720770",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10766,
        "pr_file": "pydantic/networks.py",
        "discussion_id": "1829698083",
        "commented_code": "@@ -118,13 +287,160 @@ def __get_pydantic_core_schema__(cls, source: type[Any], handler: GetCoreSchemaH\n             return schema\n \n \n-class _BaseMultiHostUrl(MultiHostUrl):\n+class _BaseMultiHostUrl:\n     _constraints: ClassVar[UrlConstraints] = UrlConstraints()\n+    _url: _CoreMultiHostUrl\n+\n+    @cached_property\n+    def _validator(self) -> TypeAdapter:\n+        return TypeAdapter(self.__class__)",
        "comment_created_at": "2024-11-05T17:07:33+00:00",
        "comment_author": "samuelcolvin",
        "comment_body": "well we could use a `SchemaValidator` instead of a `TypeAdapter`?",
        "pr_file_module": null
      },
      {
        "comment_id": "1829737406",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10766,
        "pr_file": "pydantic/networks.py",
        "discussion_id": "1829698083",
        "commented_code": "@@ -118,13 +287,160 @@ def __get_pydantic_core_schema__(cls, source: type[Any], handler: GetCoreSchemaH\n             return schema\n \n \n-class _BaseMultiHostUrl(MultiHostUrl):\n+class _BaseMultiHostUrl:\n     _constraints: ClassVar[UrlConstraints] = UrlConstraints()\n+    _url: _CoreMultiHostUrl\n+\n+    @cached_property\n+    def _validator(self) -> TypeAdapter:\n+        return TypeAdapter(self.__class__)",
        "comment_created_at": "2024-11-05T17:18:03+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "Found a relatively simple way with `TypeAdapter`. That's easiest for now, as we already have the `isinstance` conditional in the wrap validator in the custom core schema.\r\n\r\nDown the line, maybe it does make sense to just use `SchemaValidator` inside these types to perform internal validation. I'm going to write up an issue with next steps based on the feedback here, and I'll include this \ud83d\udc4d ",
        "pr_file_module": null
      }
    ]
  }
]