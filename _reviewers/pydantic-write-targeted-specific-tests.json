[
  {
    "discussion_id": "2063706095",
    "pr_number": 11803,
    "pr_file": "tests/test_private_attributes.py",
    "created_at": "2025-04-28T13:51:06+00:00",
    "commented_code": "# Checks below are just to ensure that everything is the same as in `test_private_attr_set_name`\n     # The main check is that model class definition above doesn't crash\n     assert Model()._private_attr == 2\n+\n+\n+def test_models_contain_consistent_private_attributes_type(create_module):",
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "2063706095",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11803,
        "pr_file": "tests/test_private_attributes.py",
        "discussion_id": "2063706095",
        "commented_code": "@@ -577,3 +577,24 @@ class Model(BaseModel):\n     # Checks below are just to ensure that everything is the same as in `test_private_attr_set_name`\n     # The main check is that model class definition above doesn't crash\n     assert Model()._private_attr == 2\n+\n+\n+def test_models_contain_consistent_private_attributes_type(create_module):",
        "comment_created_at": "2025-04-28T13:51:06+00:00",
        "comment_author": "karta9821",
        "comment_body": "The test written in this way did not work:\r\n```python\r\ndef test_models_contain_consistent_private_attributes_type(create_module):\r\n    @create_module\r\n    def module():\r\n        import enum\r\n\r\n        from pydantic import BaseModel\r\n\r\n        class Table(enum.Enum):\r\n            TABLE_1 = enum.auto()\r\n\r\n        class FirstModel(BaseModel):\r\n            _table: enum.Enum = Table\r\n\r\n        class SecondModel(BaseModel):\r\n            _table: enum.Enum = Table\r\n\r\n    assert module.FirstModel._table == module.SecondModel._table\r\n```\r\nIn other words, the error could not be reproduced.",
        "pr_file_module": null
      },
      {
        "comment_id": "2063956365",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11803,
        "pr_file": "tests/test_private_attributes.py",
        "discussion_id": "2063706095",
        "commented_code": "@@ -577,3 +577,24 @@ class Model(BaseModel):\n     # Checks below are just to ensure that everything is the same as in `test_private_attr_set_name`\n     # The main check is that model class definition above doesn't crash\n     assert Model()._private_attr == 2\n+\n+\n+def test_models_contain_consistent_private_attributes_type(create_module):",
        "comment_created_at": "2025-04-28T15:40:25+00:00",
        "comment_author": "Viicos",
        "comment_body": "The test you added is unrelated to your change, which makes me believe your contribution is AI generated. If so, please state it explicitly in the PR description.\r\n\r\nYou can replace by the following test:\r\n\r\n```python\r\ndef test_private_attribute_not_skipped_during_ns_inspection() -> None:\r\n    # It is important for the enum name to start with the class name\r\n    # (it previously caused issues as we were comparing qualnames without\r\n    # taking this into account):\r\n    class Fullname(str, Enum):\r\n        pass\r\n\r\n    class Full(BaseModel):\r\n        _priv: object = Fullname\r\n\r\n    assert isinstance(Full._priv, ModelPrivateAttr)\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2063999031",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11803,
        "pr_file": "tests/test_private_attributes.py",
        "discussion_id": "2063706095",
        "commented_code": "@@ -577,3 +577,24 @@ class Model(BaseModel):\n     # Checks below are just to ensure that everything is the same as in `test_private_attr_set_name`\n     # The main check is that model class definition above doesn't crash\n     assert Model()._private_attr == 2\n+\n+\n+def test_models_contain_consistent_private_attributes_type(create_module):",
        "comment_created_at": "2025-04-28T16:01:21+00:00",
        "comment_author": "karta9821",
        "comment_body": "It wasnâ€™t generated by AI â€” I just didnâ€™t really know how to approach writing this test. I wanted to create a case as close as possible to the one in the issues. ğŸ¥² \r\n\r\nThanks for the example of how to write this test differently.\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2064009190",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 11803,
        "pr_file": "tests/test_private_attributes.py",
        "discussion_id": "2063706095",
        "commented_code": "@@ -577,3 +577,24 @@ class Model(BaseModel):\n     # Checks below are just to ensure that everything is the same as in `test_private_attr_set_name`\n     # The main check is that model class definition above doesn't crash\n     assert Model()._private_attr == 2\n+\n+\n+def test_models_contain_consistent_private_attributes_type(create_module):",
        "comment_created_at": "2025-04-28T16:07:27+00:00",
        "comment_author": "karta9821",
        "comment_body": "Now I finally understand where the problem in this test lies.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1723491589",
    "pr_number": 10182,
    "pr_file": "tests/conftest.py",
    "created_at": "2024-08-20T15:10:49+00:00",
    "commented_code": "monkeypatch.setattr(GenerateSchema, 'generate_schema', generate_schema_call_counter)\n     return counter\n+\n+\n+@pytest.fixture(scope='function', autouse=True)\n+def validate_json_schemas(monkeypatch: pytest.MonkeyPatch, request: pytest.FixtureRequest) -> None:\n+    orig_generate = GenerateJsonSchema.generate\n+\n+    def generate(*args: Any, **kwargs: Any) -> Any:\n+        json_schema = orig_generate(*args, **kwargs)\n+        if not request.node.get_closest_marker('skip_json_schema_validation'):\n+            try:\n+                Draft202012Validator.check_schema(json_schema)\n+            except SchemaError:\n+                pytest.fail('Failed to validate the JSON Schema against the Draft 2020-12 spec')",
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "1723491589",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10182,
        "pr_file": "tests/conftest.py",
        "discussion_id": "1723491589",
        "commented_code": "@@ -143,3 +153,20 @@ def generate_schema_call_counter(*args: Any, **kwargs: Any) -> Any:\n \n     monkeypatch.setattr(GenerateSchema, 'generate_schema', generate_schema_call_counter)\n     return counter\n+\n+\n+@pytest.fixture(scope='function', autouse=True)\n+def validate_json_schemas(monkeypatch: pytest.MonkeyPatch, request: pytest.FixtureRequest) -> None:\n+    orig_generate = GenerateJsonSchema.generate\n+\n+    def generate(*args: Any, **kwargs: Any) -> Any:\n+        json_schema = orig_generate(*args, **kwargs)\n+        if not request.node.get_closest_marker('skip_json_schema_validation'):\n+            try:\n+                Draft202012Validator.check_schema(json_schema)\n+            except SchemaError:\n+                pytest.fail('Failed to validate the JSON Schema against the Draft 2020-12 spec')",
        "comment_created_at": "2024-08-20T15:10:49+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "Perhaps this could be a bit more verbose:\r\n\r\n1. Can we include the `SchemaError` information in this result?\r\n2. Could we add a note about the fact that this is purely a testing feature, not a runtime `pydantic` check (at this point)?\r\n\r\nPerhaps this is a bit excessive, but can we test this test? As in, run a test within a test, and check that this is raised for invalid schema? If not, no worries, but could you document an example of a failing test on this PR just to have as a reference for the blame later?",
        "pr_file_module": null
      },
      {
        "comment_id": "1723798117",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10182,
        "pr_file": "tests/conftest.py",
        "discussion_id": "1723491589",
        "commented_code": "@@ -143,3 +153,20 @@ def generate_schema_call_counter(*args: Any, **kwargs: Any) -> Any:\n \n     monkeypatch.setattr(GenerateSchema, 'generate_schema', generate_schema_call_counter)\n     return counter\n+\n+\n+@pytest.fixture(scope='function', autouse=True)\n+def validate_json_schemas(monkeypatch: pytest.MonkeyPatch, request: pytest.FixtureRequest) -> None:\n+    orig_generate = GenerateJsonSchema.generate\n+\n+    def generate(*args: Any, **kwargs: Any) -> Any:\n+        json_schema = orig_generate(*args, **kwargs)\n+        if not request.node.get_closest_marker('skip_json_schema_validation'):\n+            try:\n+                Draft202012Validator.check_schema(json_schema)\n+            except SchemaError:\n+                pytest.fail('Failed to validate the JSON Schema against the Draft 2020-12 spec')",
        "comment_created_at": "2024-08-20T18:46:29+00:00",
        "comment_author": "Viicos",
        "comment_body": "> 1. Can we include the `SchemaError` information in this result?\r\n\r\nPytest will display the exception by default. This is the output you would get for a failing test:\r\n\r\n<details>\r\n\r\n```\r\ntests/test_json_schema.py F                                                                                                                       [100%]\r\ntests/test_json_schema.py:6476 test_fails - Failed: Failed to validate the JSON Schema against the Draft 2020-12 specâ€¦                            [100%]\r\n======================================================================= FAILURES ========================================================================\r\n______________________________________________________________________ test_fails _______________________________________________________________________\r\n\r\nargs = (<pydantic.json_schema.GenerateJsonSchema object at 0x7b80723f5820>, {'metadata': {'pydantic_js_annotation_functions':...onSchema.__get_pydantic_json_schema__ of WithJsonSchema(json_schema={'type': 'invalid'}, mode=None)>]}, 'type': 'int'})\r\nkwargs = {'mode': 'validation'}, json_schema = {'type': 'invalid'}\r\n\r\n    def generate(*args: Any, **kwargs: Any) -> Any:\r\n        json_schema = orig_generate(*args, **kwargs)\r\n        if not request.node.get_closest_marker('skip_json_schema_validation'):\r\n            try:\r\n>               Draft202012Validator.check_schema(json_schema)\r\n\r\ntests/conftest.py:166: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\ncls = <class 'jsonschema.validators.Draft202012Validator'>, schema = {'type': 'invalid'}\r\nformat_checker = <FormatChecker checkers=['date', 'email', 'idn-email', 'idn-hostname', 'ipv4', 'ipv6', 'regex', 'uuid']>\r\n\r\n    @classmethod\r\n    def check_schema(cls, schema, format_checker=_UNSET):\r\n        Validator = validator_for(cls.META_SCHEMA, default=cls)\r\n        if format_checker is _UNSET:\r\n            format_checker = Validator.FORMAT_CHECKER\r\n        validator = Validator(\r\n            schema=cls.META_SCHEMA,\r\n            format_checker=format_checker,\r\n        )\r\n        for error in validator.iter_errors(schema):\r\n>           raise exceptions.SchemaError.create_from(error)\r\nE           jsonschema.exceptions.SchemaError: 'invalid' is not valid under any of the given schemas\r\nE           \r\nE           Failed validating 'anyOf' in metaschema['allOf'][3]['properties']['type']:\r\nE               {'anyOf': [{'$ref': '#/$defs/simpleTypes'},\r\nE                          {'type': 'array',\r\nE                           'items': {'$ref': '#/$defs/simpleTypes'},\r\nE                           'minItems': 1,\r\nE                           'uniqueItems': True}]}\r\nE           \r\nE           On schema['type']:\r\nE               'invalid'\r\n\r\n../../.pyenv/versions/3.12.4/envs/pydanticdev/lib/python3.12/site-packages/jsonschema/validators.py:317: SchemaError\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n    def test_fails():\r\n>       TypeAdapter(Annotated[int, WithJsonSchema({'type': 'invalid'})]).json_schema()\r\n\r\ntests/test_json_schema.py:6478: \r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\npydantic/type_adapter.py:142: in wrapped\r\n    return func(self, *args, **kwargs)\r\npydantic/type_adapter.py:549: in json_schema\r\n    return schema_generator_instance.generate(self.core_schema, mode=mode)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\r\n\r\nargs = (<pydantic.json_schema.GenerateJsonSchema object at 0x7b80723f5820>, {'metadata': {'pydantic_js_annotation_functions':...onSchema.__get_pydantic_json_schema__ of WithJsonSchema(json_schema={'type': 'invalid'}, mode=None)>]}, 'type': 'int'})\r\nkwargs = {'mode': 'validation'}, json_schema = {'type': 'invalid'}\r\n\r\n    def generate(*args: Any, **kwargs: Any) -> Any:\r\n        json_schema = orig_generate(*args, **kwargs)\r\n        if not request.node.get_closest_marker('skip_json_schema_validation'):\r\n            try:\r\n                Draft202012Validator.check_schema(json_schema)\r\n            except SchemaError:\r\n>               pytest.fail('Failed to validate the JSON Schema against the Draft 2020-12 spec')\r\nE               Failed: Failed to validate the JSON Schema against the Draft 2020-12 spec\r\n\r\ntests/conftest.py:168: Failed\r\n                                   Summary of Failures                                    \r\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”“\r\nâ”ƒ  File                       â”ƒ  Function    â”ƒ  Function Line  â”ƒ  Error Line  â”ƒ  Error   â”ƒ\r\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”©\r\nâ”‚  tests/test_json_schema.py  â”‚  test_fails  â”‚  6477           â”‚  6478        â”‚  Failed  â”‚\r\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\r\nResults (1.65s):\r\n         1 failed\r\n      5846 deselected\r\n\r\n```\r\n\r\n</details>\r\n\r\n> 2\\. Could we add a note about the fact that this is purely a testing feature, not a runtime `pydantic` check (at this point)?\r\n\r\nAdded.\r\n\r\n> Perhaps this is a bit excessive, but can we test this test?\r\n\r\nSeems like there are [ways to do so](https://stackoverflow.com/a/56635224), but they are pretty involved. I added a test with an expected failure.\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1755214920",
    "pr_number": 10293,
    "pr_file": "tests/test_json_schema.py",
    "created_at": "2024-09-11T17:30:15+00:00",
    "commented_code": "'ser_json_timedelta,properties',\n     [\n         ('float', {'duration': {'default': 300.0, 'title': 'Duration', 'type': 'number'}}),\n+        ('seconds_float', {'duration': {'default': 300.0, 'title': 'Duration', 'type': 'number'}}),\n+        ('milliseconds_float', {'duration': {'default': 300000.0, 'title': 'Duration', 'type': 'number'}}),\n         ('iso8601', {'duration': {'default': 'PT5M', 'format': 'duration', 'title': 'Duration', 'type': 'string'}}),\n     ],\n )\n-def test_model_default_timedelta(ser_json_timedelta: Literal['float', 'iso8601'], properties: typing.Dict[str, Any]):\n-    class Model(BaseModel):\n-        model_config = ConfigDict(ser_json_timedelta=ser_json_timedelta)\n+def test_model_default_timedelta(",
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "1755214920",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10293,
        "pr_file": "tests/test_json_schema.py",
        "discussion_id": "1755214920",
        "commented_code": "@@ -1778,21 +1779,42 @@ class Outer(BaseModel):\n     'ser_json_timedelta,properties',\n     [\n         ('float', {'duration': {'default': 300.0, 'title': 'Duration', 'type': 'number'}}),\n+        ('seconds_float', {'duration': {'default': 300.0, 'title': 'Duration', 'type': 'number'}}),\n+        ('milliseconds_float', {'duration': {'default': 300000.0, 'title': 'Duration', 'type': 'number'}}),\n         ('iso8601', {'duration': {'default': 'PT5M', 'format': 'duration', 'title': 'Duration', 'type': 'string'}}),\n     ],\n )\n-def test_model_default_timedelta(ser_json_timedelta: Literal['float', 'iso8601'], properties: typing.Dict[str, Any]):\n-    class Model(BaseModel):\n-        model_config = ConfigDict(ser_json_timedelta=ser_json_timedelta)\n+def test_model_default_timedelta(",
        "comment_created_at": "2024-09-11T17:30:15+00:00",
        "comment_author": "ollz272",
        "comment_body": "After submitting this im pretty sure the float options should have their own tests, but i'll let you guys decide on this ğŸ‘ğŸ» ",
        "pr_file_module": null
      },
      {
        "comment_id": "1765154229",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10293,
        "pr_file": "tests/test_json_schema.py",
        "discussion_id": "1755214920",
        "commented_code": "@@ -1778,21 +1779,42 @@ class Outer(BaseModel):\n     'ser_json_timedelta,properties',\n     [\n         ('float', {'duration': {'default': 300.0, 'title': 'Duration', 'type': 'number'}}),\n+        ('seconds_float', {'duration': {'default': 300.0, 'title': 'Duration', 'type': 'number'}}),\n+        ('milliseconds_float', {'duration': {'default': 300000.0, 'title': 'Duration', 'type': 'number'}}),\n         ('iso8601', {'duration': {'default': 'PT5M', 'format': 'duration', 'title': 'Duration', 'type': 'string'}}),\n     ],\n )\n-def test_model_default_timedelta(ser_json_timedelta: Literal['float', 'iso8601'], properties: typing.Dict[str, Any]):\n-    class Model(BaseModel):\n-        model_config = ConfigDict(ser_json_timedelta=ser_json_timedelta)\n+def test_model_default_timedelta(",
        "comment_created_at": "2024-09-18T14:20:33+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "Yeah, I think having their own tests would be good so that we can avoid the conditional warning checks.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1798364441",
    "pr_number": 10484,
    "pr_file": "tests/test_validate_call.py",
    "created_at": "2024-10-13T14:14:19+00:00",
    "commented_code": "]\n \n \n-def test_v_args():\n-    @validate_call\n-    def foo1(v__args: int):\n-        return v__args\n-\n-    assert foo1(123) == 123\n-\n-    @validate_call\n-    def foo2(v__kwargs: int):\n-        return v__kwargs\n-\n-    assert foo2(123) == 123\n-\n-    @validate_call\n-    def foo3(v__positional_only: int):\n-        return v__positional_only\n-\n-    assert foo3(123) == 123\n-\n-    @validate_call\n-    def foo4(v__duplicate_kwargs: int):\n-        return v__duplicate_kwargs\n-\n-    assert foo4(123) == 123\n-\n-",
    "repo_full_name": "pydantic/pydantic",
    "discussion_comments": [
      {
        "comment_id": "1798364441",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10484,
        "pr_file": "tests/test_validate_call.py",
        "discussion_id": "1798364441",
        "commented_code": "@@ -347,32 +462,6 @@ def foo(args: int, kwargs: int):\n     ]\n \n \n-def test_v_args():\n-    @validate_call\n-    def foo1(v__args: int):\n-        return v__args\n-\n-    assert foo1(123) == 123\n-\n-    @validate_call\n-    def foo2(v__kwargs: int):\n-        return v__kwargs\n-\n-    assert foo2(123) == 123\n-\n-    @validate_call\n-    def foo3(v__positional_only: int):\n-        return v__positional_only\n-\n-    assert foo3(123) == 123\n-\n-    @validate_call\n-    def foo4(v__duplicate_kwargs: int):\n-        return v__duplicate_kwargs\n-\n-    assert foo4(123) == 123\n-\n-",
        "comment_created_at": "2024-10-13T14:14:19+00:00",
        "comment_author": "sydney-runkle",
        "comment_body": "Why remove this?",
        "pr_file_module": null
      },
      {
        "comment_id": "1798426957",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10484,
        "pr_file": "tests/test_validate_call.py",
        "discussion_id": "1798364441",
        "commented_code": "@@ -347,32 +462,6 @@ def foo(args: int, kwargs: int):\n     ]\n \n \n-def test_v_args():\n-    @validate_call\n-    def foo1(v__args: int):\n-        return v__args\n-\n-    assert foo1(123) == 123\n-\n-    @validate_call\n-    def foo2(v__kwargs: int):\n-        return v__kwargs\n-\n-    assert foo2(123) == 123\n-\n-    @validate_call\n-    def foo3(v__positional_only: int):\n-        return v__positional_only\n-\n-    assert foo3(123) == 123\n-\n-    @validate_call\n-    def foo4(v__duplicate_kwargs: int):\n-        return v__duplicate_kwargs\n-\n-    assert foo4(123) == 123\n-\n-",
        "comment_created_at": "2024-10-13T15:59:17+00:00",
        "comment_author": "kc0506",
        "comment_body": "This looks like an incomplete/unnecessary test to me â€” the functions are nothing special and basially the same as simply\r\n```py\r\n@validate_call\r\ndef foo(x: int):\r\n    return x\r\n```\r\nwhich obviously have been covered in other tests.",
        "pr_file_module": null
      },
      {
        "comment_id": "1798433711",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10484,
        "pr_file": "tests/test_validate_call.py",
        "discussion_id": "1798364441",
        "commented_code": "@@ -347,32 +462,6 @@ def foo(args: int, kwargs: int):\n     ]\n \n \n-def test_v_args():\n-    @validate_call\n-    def foo1(v__args: int):\n-        return v__args\n-\n-    assert foo1(123) == 123\n-\n-    @validate_call\n-    def foo2(v__kwargs: int):\n-        return v__kwargs\n-\n-    assert foo2(123) == 123\n-\n-    @validate_call\n-    def foo3(v__positional_only: int):\n-        return v__positional_only\n-\n-    assert foo3(123) == 123\n-\n-    @validate_call\n-    def foo4(v__duplicate_kwargs: int):\n-        return v__duplicate_kwargs\n-\n-    assert foo4(123) == 123\n-\n-",
        "comment_created_at": "2024-10-13T16:11:03+00:00",
        "comment_author": "kc0506",
        "comment_body": "It seems these are from `test_deprecated_validate_arguments.py`, and the argument names are invalid in the previous version. But for the new `validate_call` they are just normal names.",
        "pr_file_module": null
      },
      {
        "comment_id": "1799990581",
        "repo_full_name": "pydantic/pydantic",
        "pr_number": 10484,
        "pr_file": "tests/test_validate_call.py",
        "discussion_id": "1798364441",
        "commented_code": "@@ -347,32 +462,6 @@ def foo(args: int, kwargs: int):\n     ]\n \n \n-def test_v_args():\n-    @validate_call\n-    def foo1(v__args: int):\n-        return v__args\n-\n-    assert foo1(123) == 123\n-\n-    @validate_call\n-    def foo2(v__kwargs: int):\n-        return v__kwargs\n-\n-    assert foo2(123) == 123\n-\n-    @validate_call\n-    def foo3(v__positional_only: int):\n-        return v__positional_only\n-\n-    assert foo3(123) == 123\n-\n-    @validate_call\n-    def foo4(v__duplicate_kwargs: int):\n-        return v__duplicate_kwargs\n-\n-    assert foo4(123) == 123\n-\n-",
        "comment_created_at": "2024-10-14T19:38:02+00:00",
        "comment_author": "Viicos",
        "comment_body": "Yes can be removed after looking at the git blame.",
        "pr_file_module": null
      }
    ]
  }
]