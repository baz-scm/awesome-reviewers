[
  {
    "discussion_id": "2180603267",
    "pr_number": 157453,
    "pr_file": ".ci/docker/common/install_cuda.sh",
    "created_at": "2025-07-02T17:25:41+00:00",
    "commented_code": "rm -rf tmp_cudnn\n }\n \n+function install_nvshmem {\n+  cuda_major_version=$1      # e.g. \"12\"\n+  nvshmem_version=$2         # e.g. \"3.3.9\"\n+\n+  case \"${arch_path}\" in\n+    sbsa)\n+      dl_arch=\"aarch64\"\n+      ;;\n+    x86_64)\n+      dl_arch=\"x64\"\n+      ;;\n+    *)\n+      dl_arch=\"${arch}\"\n+      ;;\n+  esac\n+\n+  tmpdir=\"tmp_nvshmem\"\n+  mkdir -p \"${tmpdir}\" && cd \"${tmpdir}\"\n+\n+  # nvSHMEM license: https://docs.nvidia.com/nvshmem/api/sla.html\n+  filename=\"libnvshmem_cuda${cuda_major_version}-linux-${arch_path}-${nvshmem_version}\"\n+  url=\"https://developer.download.nvidia.com/compute/redist/nvshmem/${nvshmem_version}/builds/cuda${cuda_major_version}/txz/agnostic/${dl_arch}/${filename}.tar.gz\"\n+\n+  # download, unpack, install\n+  wget -q \"${url}\"\n+  tar xf \"${filename}.tar.gz\"\n+  cp -a \"libnvshmem/include/\"* /usr/local/include/\n+  cp -a \"libnvshmem/lib/\"*     /usr/local/lib/",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2180603267",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157453,
        "pr_file": ".ci/docker/common/install_cuda.sh",
        "discussion_id": "2180603267",
        "commented_code": "@@ -40,13 +42,52 @@ function install_cudnn {\n   rm -rf tmp_cudnn\n }\n \n+function install_nvshmem {\n+  cuda_major_version=$1      # e.g. \"12\"\n+  nvshmem_version=$2         # e.g. \"3.3.9\"\n+\n+  case \"${arch_path}\" in\n+    sbsa)\n+      dl_arch=\"aarch64\"\n+      ;;\n+    x86_64)\n+      dl_arch=\"x64\"\n+      ;;\n+    *)\n+      dl_arch=\"${arch}\"\n+      ;;\n+  esac\n+\n+  tmpdir=\"tmp_nvshmem\"\n+  mkdir -p \"${tmpdir}\" && cd \"${tmpdir}\"\n+\n+  # nvSHMEM license: https://docs.nvidia.com/nvshmem/api/sla.html\n+  filename=\"libnvshmem_cuda${cuda_major_version}-linux-${arch_path}-${nvshmem_version}\"\n+  url=\"https://developer.download.nvidia.com/compute/redist/nvshmem/${nvshmem_version}/builds/cuda${cuda_major_version}/txz/agnostic/${dl_arch}/${filename}.tar.gz\"\n+\n+  # download, unpack, install\n+  wget -q \"${url}\"\n+  tar xf \"${filename}.tar.gz\"\n+  cp -a \"libnvshmem/include/\"* /usr/local/include/\n+  cp -a \"libnvshmem/lib/\"*     /usr/local/lib/",
        "comment_created_at": "2025-07-02T17:25:41+00:00",
        "comment_author": "kwen2501",
        "comment_body": "Oh I was previously detecting NVSHMEM lib from `python/site-packages/nvidia`.\r\nMaybe I would need to change how we set `NVSHMEM_HOME` based on this change?",
        "pr_file_module": null
      },
      {
        "comment_id": "2180618592",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157453,
        "pr_file": ".ci/docker/common/install_cuda.sh",
        "discussion_id": "2180603267",
        "commented_code": "@@ -40,13 +42,52 @@ function install_cudnn {\n   rm -rf tmp_cudnn\n }\n \n+function install_nvshmem {\n+  cuda_major_version=$1      # e.g. \"12\"\n+  nvshmem_version=$2         # e.g. \"3.3.9\"\n+\n+  case \"${arch_path}\" in\n+    sbsa)\n+      dl_arch=\"aarch64\"\n+      ;;\n+    x86_64)\n+      dl_arch=\"x64\"\n+      ;;\n+    *)\n+      dl_arch=\"${arch}\"\n+      ;;\n+  esac\n+\n+  tmpdir=\"tmp_nvshmem\"\n+  mkdir -p \"${tmpdir}\" && cd \"${tmpdir}\"\n+\n+  # nvSHMEM license: https://docs.nvidia.com/nvshmem/api/sla.html\n+  filename=\"libnvshmem_cuda${cuda_major_version}-linux-${arch_path}-${nvshmem_version}\"\n+  url=\"https://developer.download.nvidia.com/compute/redist/nvshmem/${nvshmem_version}/builds/cuda${cuda_major_version}/txz/agnostic/${dl_arch}/${filename}.tar.gz\"\n+\n+  # download, unpack, install\n+  wget -q \"${url}\"\n+  tar xf \"${filename}.tar.gz\"\n+  cp -a \"libnvshmem/include/\"* /usr/local/include/\n+  cp -a \"libnvshmem/lib/\"*     /usr/local/lib/",
        "comment_created_at": "2025-07-02T17:33:38+00:00",
        "comment_author": "Skylion007",
        "comment_body": "It should be detected either way here? We do use NVSHMEM from the python package anyway at the end for non-static builds.",
        "pr_file_module": null
      },
      {
        "comment_id": "2180692788",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157453,
        "pr_file": ".ci/docker/common/install_cuda.sh",
        "discussion_id": "2180603267",
        "commented_code": "@@ -40,13 +42,52 @@ function install_cudnn {\n   rm -rf tmp_cudnn\n }\n \n+function install_nvshmem {\n+  cuda_major_version=$1      # e.g. \"12\"\n+  nvshmem_version=$2         # e.g. \"3.3.9\"\n+\n+  case \"${arch_path}\" in\n+    sbsa)\n+      dl_arch=\"aarch64\"\n+      ;;\n+    x86_64)\n+      dl_arch=\"x64\"\n+      ;;\n+    *)\n+      dl_arch=\"${arch}\"\n+      ;;\n+  esac\n+\n+  tmpdir=\"tmp_nvshmem\"\n+  mkdir -p \"${tmpdir}\" && cd \"${tmpdir}\"\n+\n+  # nvSHMEM license: https://docs.nvidia.com/nvshmem/api/sla.html\n+  filename=\"libnvshmem_cuda${cuda_major_version}-linux-${arch_path}-${nvshmem_version}\"\n+  url=\"https://developer.download.nvidia.com/compute/redist/nvshmem/${nvshmem_version}/builds/cuda${cuda_major_version}/txz/agnostic/${dl_arch}/${filename}.tar.gz\"\n+\n+  # download, unpack, install\n+  wget -q \"${url}\"\n+  tar xf \"${filename}.tar.gz\"\n+  cp -a \"libnvshmem/include/\"* /usr/local/include/\n+  cp -a \"libnvshmem/lib/\"*     /usr/local/lib/",
        "comment_created_at": "2025-07-02T18:15:45+00:00",
        "comment_author": "kwen2501",
        "comment_body": "This is how we currently detect it for building:\r\nhttps://github.com/pytorch/pytorch/blob/d5d14ee823e70224a154884a5c2912643d648094/tools/setup_helpers/cmake.py#L316-L320\r\n\r\nAnd there is a gate here that stops building torch with NVSHMEM if `NVSHMEM_HOME` is not set:\r\nhttps://github.com/pytorch/pytorch/blob/0105cd89ab508ec56126c1de85c8f5b5acc446b5/caffe2/CMakeLists.txt#L998-L1002\r\n\r\nI see two solutions:\r\n(1) We add `export NVSHMEM_HOME=/usr/local` here, but it looks a bit weird;\r\n(2) We add a `findNVSHMEM.cmake` as a single place to detect the library and set `NVSHMEM_HOME` there.\r\n\r\nWhat do you think?",
        "pr_file_module": null
      },
      {
        "comment_id": "2180700543",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157453,
        "pr_file": ".ci/docker/common/install_cuda.sh",
        "discussion_id": "2180603267",
        "commented_code": "@@ -40,13 +42,52 @@ function install_cudnn {\n   rm -rf tmp_cudnn\n }\n \n+function install_nvshmem {\n+  cuda_major_version=$1      # e.g. \"12\"\n+  nvshmem_version=$2         # e.g. \"3.3.9\"\n+\n+  case \"${arch_path}\" in\n+    sbsa)\n+      dl_arch=\"aarch64\"\n+      ;;\n+    x86_64)\n+      dl_arch=\"x64\"\n+      ;;\n+    *)\n+      dl_arch=\"${arch}\"\n+      ;;\n+  esac\n+\n+  tmpdir=\"tmp_nvshmem\"\n+  mkdir -p \"${tmpdir}\" && cd \"${tmpdir}\"\n+\n+  # nvSHMEM license: https://docs.nvidia.com/nvshmem/api/sla.html\n+  filename=\"libnvshmem_cuda${cuda_major_version}-linux-${arch_path}-${nvshmem_version}\"\n+  url=\"https://developer.download.nvidia.com/compute/redist/nvshmem/${nvshmem_version}/builds/cuda${cuda_major_version}/txz/agnostic/${dl_arch}/${filename}.tar.gz\"\n+\n+  # download, unpack, install\n+  wget -q \"${url}\"\n+  tar xf \"${filename}.tar.gz\"\n+  cp -a \"libnvshmem/include/\"* /usr/local/include/\n+  cp -a \"libnvshmem/lib/\"*     /usr/local/lib/",
        "comment_created_at": "2025-07-02T18:19:00+00:00",
        "comment_author": "Skylion007",
        "comment_body": "I'd say a findNVSHMEM.cmake",
        "pr_file_module": null
      },
      {
        "comment_id": "2180701834",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157453,
        "pr_file": ".ci/docker/common/install_cuda.sh",
        "discussion_id": "2180603267",
        "commented_code": "@@ -40,13 +42,52 @@ function install_cudnn {\n   rm -rf tmp_cudnn\n }\n \n+function install_nvshmem {\n+  cuda_major_version=$1      # e.g. \"12\"\n+  nvshmem_version=$2         # e.g. \"3.3.9\"\n+\n+  case \"${arch_path}\" in\n+    sbsa)\n+      dl_arch=\"aarch64\"\n+      ;;\n+    x86_64)\n+      dl_arch=\"x64\"\n+      ;;\n+    *)\n+      dl_arch=\"${arch}\"\n+      ;;\n+  esac\n+\n+  tmpdir=\"tmp_nvshmem\"\n+  mkdir -p \"${tmpdir}\" && cd \"${tmpdir}\"\n+\n+  # nvSHMEM license: https://docs.nvidia.com/nvshmem/api/sla.html\n+  filename=\"libnvshmem_cuda${cuda_major_version}-linux-${arch_path}-${nvshmem_version}\"\n+  url=\"https://developer.download.nvidia.com/compute/redist/nvshmem/${nvshmem_version}/builds/cuda${cuda_major_version}/txz/agnostic/${dl_arch}/${filename}.tar.gz\"\n+\n+  # download, unpack, install\n+  wget -q \"${url}\"\n+  tar xf \"${filename}.tar.gz\"\n+  cp -a \"libnvshmem/include/\"* /usr/local/include/\n+  cp -a \"libnvshmem/lib/\"*     /usr/local/lib/",
        "comment_created_at": "2025-07-02T18:19:42+00:00",
        "comment_author": "Skylion007",
        "comment_body": "The pip version is fine too obviously, but it didn't seem to work for you other build?",
        "pr_file_module": null
      },
      {
        "comment_id": "2180713400",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157453,
        "pr_file": ".ci/docker/common/install_cuda.sh",
        "discussion_id": "2180603267",
        "commented_code": "@@ -40,13 +42,52 @@ function install_cudnn {\n   rm -rf tmp_cudnn\n }\n \n+function install_nvshmem {\n+  cuda_major_version=$1      # e.g. \"12\"\n+  nvshmem_version=$2         # e.g. \"3.3.9\"\n+\n+  case \"${arch_path}\" in\n+    sbsa)\n+      dl_arch=\"aarch64\"\n+      ;;\n+    x86_64)\n+      dl_arch=\"x64\"\n+      ;;\n+    *)\n+      dl_arch=\"${arch}\"\n+      ;;\n+  esac\n+\n+  tmpdir=\"tmp_nvshmem\"\n+  mkdir -p \"${tmpdir}\" && cd \"${tmpdir}\"\n+\n+  # nvSHMEM license: https://docs.nvidia.com/nvshmem/api/sla.html\n+  filename=\"libnvshmem_cuda${cuda_major_version}-linux-${arch_path}-${nvshmem_version}\"\n+  url=\"https://developer.download.nvidia.com/compute/redist/nvshmem/${nvshmem_version}/builds/cuda${cuda_major_version}/txz/agnostic/${dl_arch}/${filename}.tar.gz\"\n+\n+  # download, unpack, install\n+  wget -q \"${url}\"\n+  tar xf \"${filename}.tar.gz\"\n+  cp -a \"libnvshmem/include/\"* /usr/local/include/\n+  cp -a \"libnvshmem/lib/\"*     /usr/local/lib/",
        "comment_created_at": "2025-07-02T18:23:44+00:00",
        "comment_author": "Skylion007",
        "comment_body": "@kwen2501 Also libtorch will be missing it now, right?",
        "pr_file_module": null
      },
      {
        "comment_id": "2180720505",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157453,
        "pr_file": ".ci/docker/common/install_cuda.sh",
        "discussion_id": "2180603267",
        "commented_code": "@@ -40,13 +42,52 @@ function install_cudnn {\n   rm -rf tmp_cudnn\n }\n \n+function install_nvshmem {\n+  cuda_major_version=$1      # e.g. \"12\"\n+  nvshmem_version=$2         # e.g. \"3.3.9\"\n+\n+  case \"${arch_path}\" in\n+    sbsa)\n+      dl_arch=\"aarch64\"\n+      ;;\n+    x86_64)\n+      dl_arch=\"x64\"\n+      ;;\n+    *)\n+      dl_arch=\"${arch}\"\n+      ;;\n+  esac\n+\n+  tmpdir=\"tmp_nvshmem\"\n+  mkdir -p \"${tmpdir}\" && cd \"${tmpdir}\"\n+\n+  # nvSHMEM license: https://docs.nvidia.com/nvshmem/api/sla.html\n+  filename=\"libnvshmem_cuda${cuda_major_version}-linux-${arch_path}-${nvshmem_version}\"\n+  url=\"https://developer.download.nvidia.com/compute/redist/nvshmem/${nvshmem_version}/builds/cuda${cuda_major_version}/txz/agnostic/${dl_arch}/${filename}.tar.gz\"\n+\n+  # download, unpack, install\n+  wget -q \"${url}\"\n+  tar xf \"${filename}.tar.gz\"\n+  cp -a \"libnvshmem/include/\"* /usr/local/include/\n+  cp -a \"libnvshmem/lib/\"*     /usr/local/lib/",
        "comment_created_at": "2025-07-02T18:26:19+00:00",
        "comment_author": "Skylion007",
        "comment_body": "So libnvshmem comes with `libnvshmem/lib/cmake/nvshmem/NVSHMEMConfig.cmake`, but it doesn't set the NVSHMEM home.",
        "pr_file_module": null
      },
      {
        "comment_id": "2180731276",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157453,
        "pr_file": ".ci/docker/common/install_cuda.sh",
        "discussion_id": "2180603267",
        "commented_code": "@@ -40,13 +42,52 @@ function install_cudnn {\n   rm -rf tmp_cudnn\n }\n \n+function install_nvshmem {\n+  cuda_major_version=$1      # e.g. \"12\"\n+  nvshmem_version=$2         # e.g. \"3.3.9\"\n+\n+  case \"${arch_path}\" in\n+    sbsa)\n+      dl_arch=\"aarch64\"\n+      ;;\n+    x86_64)\n+      dl_arch=\"x64\"\n+      ;;\n+    *)\n+      dl_arch=\"${arch}\"\n+      ;;\n+  esac\n+\n+  tmpdir=\"tmp_nvshmem\"\n+  mkdir -p \"${tmpdir}\" && cd \"${tmpdir}\"\n+\n+  # nvSHMEM license: https://docs.nvidia.com/nvshmem/api/sla.html\n+  filename=\"libnvshmem_cuda${cuda_major_version}-linux-${arch_path}-${nvshmem_version}\"\n+  url=\"https://developer.download.nvidia.com/compute/redist/nvshmem/${nvshmem_version}/builds/cuda${cuda_major_version}/txz/agnostic/${dl_arch}/${filename}.tar.gz\"\n+\n+  # download, unpack, install\n+  wget -q \"${url}\"\n+  tar xf \"${filename}.tar.gz\"\n+  cp -a \"libnvshmem/include/\"* /usr/local/include/\n+  cp -a \"libnvshmem/lib/\"*     /usr/local/lib/",
        "comment_created_at": "2025-07-02T18:30:22+00:00",
        "comment_author": "Skylion007",
        "comment_body": "@kwen2501 This more complicated as our current CMake is broken when we build with NVSHMEM because it tries to build for unsupported architectures.",
        "pr_file_module": null
      },
      {
        "comment_id": "2180818125",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157453,
        "pr_file": ".ci/docker/common/install_cuda.sh",
        "discussion_id": "2180603267",
        "commented_code": "@@ -40,13 +42,52 @@ function install_cudnn {\n   rm -rf tmp_cudnn\n }\n \n+function install_nvshmem {\n+  cuda_major_version=$1      # e.g. \"12\"\n+  nvshmem_version=$2         # e.g. \"3.3.9\"\n+\n+  case \"${arch_path}\" in\n+    sbsa)\n+      dl_arch=\"aarch64\"\n+      ;;\n+    x86_64)\n+      dl_arch=\"x64\"\n+      ;;\n+    *)\n+      dl_arch=\"${arch}\"\n+      ;;\n+  esac\n+\n+  tmpdir=\"tmp_nvshmem\"\n+  mkdir -p \"${tmpdir}\" && cd \"${tmpdir}\"\n+\n+  # nvSHMEM license: https://docs.nvidia.com/nvshmem/api/sla.html\n+  filename=\"libnvshmem_cuda${cuda_major_version}-linux-${arch_path}-${nvshmem_version}\"\n+  url=\"https://developer.download.nvidia.com/compute/redist/nvshmem/${nvshmem_version}/builds/cuda${cuda_major_version}/txz/agnostic/${dl_arch}/${filename}.tar.gz\"\n+\n+  # download, unpack, install\n+  wget -q \"${url}\"\n+  tar xf \"${filename}.tar.gz\"\n+  cp -a \"libnvshmem/include/\"* /usr/local/include/\n+  cp -a \"libnvshmem/lib/\"*     /usr/local/lib/",
        "comment_created_at": "2025-07-02T19:24:25+00:00",
        "comment_author": "kwen2501",
        "comment_body": "> @kwen2501 Also libtorch will be missing it now, right?\r\n\r\nCorrect. So we'd need to find a way to work for both. (pip install or system install)",
        "pr_file_module": null
      },
      {
        "comment_id": "2180864310",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157453,
        "pr_file": ".ci/docker/common/install_cuda.sh",
        "discussion_id": "2180603267",
        "commented_code": "@@ -40,13 +42,52 @@ function install_cudnn {\n   rm -rf tmp_cudnn\n }\n \n+function install_nvshmem {\n+  cuda_major_version=$1      # e.g. \"12\"\n+  nvshmem_version=$2         # e.g. \"3.3.9\"\n+\n+  case \"${arch_path}\" in\n+    sbsa)\n+      dl_arch=\"aarch64\"\n+      ;;\n+    x86_64)\n+      dl_arch=\"x64\"\n+      ;;\n+    *)\n+      dl_arch=\"${arch}\"\n+      ;;\n+  esac\n+\n+  tmpdir=\"tmp_nvshmem\"\n+  mkdir -p \"${tmpdir}\" && cd \"${tmpdir}\"\n+\n+  # nvSHMEM license: https://docs.nvidia.com/nvshmem/api/sla.html\n+  filename=\"libnvshmem_cuda${cuda_major_version}-linux-${arch_path}-${nvshmem_version}\"\n+  url=\"https://developer.download.nvidia.com/compute/redist/nvshmem/${nvshmem_version}/builds/cuda${cuda_major_version}/txz/agnostic/${dl_arch}/${filename}.tar.gz\"\n+\n+  # download, unpack, install\n+  wget -q \"${url}\"\n+  tar xf \"${filename}.tar.gz\"\n+  cp -a \"libnvshmem/include/\"* /usr/local/include/\n+  cp -a \"libnvshmem/lib/\"*     /usr/local/lib/",
        "comment_created_at": "2025-07-02T19:55:35+00:00",
        "comment_author": "Skylion007",
        "comment_body": "@kwen2501 Proper way is just do CMake. It will work pip install thanks the to the rpath changes we made.",
        "pr_file_module": null
      },
      {
        "comment_id": "2181093318",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157453,
        "pr_file": ".ci/docker/common/install_cuda.sh",
        "discussion_id": "2180603267",
        "commented_code": "@@ -40,13 +42,52 @@ function install_cudnn {\n   rm -rf tmp_cudnn\n }\n \n+function install_nvshmem {\n+  cuda_major_version=$1      # e.g. \"12\"\n+  nvshmem_version=$2         # e.g. \"3.3.9\"\n+\n+  case \"${arch_path}\" in\n+    sbsa)\n+      dl_arch=\"aarch64\"\n+      ;;\n+    x86_64)\n+      dl_arch=\"x64\"\n+      ;;\n+    *)\n+      dl_arch=\"${arch}\"\n+      ;;\n+  esac\n+\n+  tmpdir=\"tmp_nvshmem\"\n+  mkdir -p \"${tmpdir}\" && cd \"${tmpdir}\"\n+\n+  # nvSHMEM license: https://docs.nvidia.com/nvshmem/api/sla.html\n+  filename=\"libnvshmem_cuda${cuda_major_version}-linux-${arch_path}-${nvshmem_version}\"\n+  url=\"https://developer.download.nvidia.com/compute/redist/nvshmem/${nvshmem_version}/builds/cuda${cuda_major_version}/txz/agnostic/${dl_arch}/${filename}.tar.gz\"\n+\n+  # download, unpack, install\n+  wget -q \"${url}\"\n+  tar xf \"${filename}.tar.gz\"\n+  cp -a \"libnvshmem/include/\"* /usr/local/include/\n+  cp -a \"libnvshmem/lib/\"*     /usr/local/lib/",
        "comment_created_at": "2025-07-02T22:35:09+00:00",
        "comment_author": "kwen2501",
        "comment_body": "Thanks. I added CMake search here: #157513.\r\nDo you mind taking a look? Thank you!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2167676590",
    "pr_number": 156626,
    "pr_file": ".ci/pytorch/test.sh",
    "created_at": "2025-06-25T21:35:21+00:00",
    "commented_code": "assert_git_not_dirty\n }\n \n+test_cutlass_backend() {\n+  # cutlass backend tests for H100\n+  folder_name=\"third_party/cutlass/python\"\n+  start_dir=\".\"\n+  folder_path=$(find \"$start_dir\" -type d -path \"$folder_name\" -print -quit)\n+  TORCHINDUCTOR_CUTLASS_DIR=$relative_path python test/run_test.py --include inductor/test_cutlass_backend -k 'test_max_autotune_cutlass_backend_regular_mm and not test_max_autotune_cutlass_backend_regular_mm_streamk' $PYTHON_TEST_EXTRA_OPTION --upload-artifacts-while-running",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2167676590",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156626,
        "pr_file": ".ci/pytorch/test.sh",
        "discussion_id": "2167676590",
        "commented_code": "@@ -333,6 +333,14 @@ test_h100_distributed() {\n   assert_git_not_dirty\n }\n \n+test_cutlass_backend() {\n+  # cutlass backend tests for H100\n+  folder_name=\"third_party/cutlass/python\"\n+  start_dir=\".\"\n+  folder_path=$(find \"$start_dir\" -type d -path \"$folder_name\" -print -quit)\n+  TORCHINDUCTOR_CUTLASS_DIR=$relative_path python test/run_test.py --include inductor/test_cutlass_backend -k 'test_max_autotune_cutlass_backend_regular_mm and not test_max_autotune_cutlass_backend_regular_mm_streamk' $PYTHON_TEST_EXTRA_OPTION --upload-artifacts-while-running",
        "comment_created_at": "2025-06-25T21:35:21+00:00",
        "comment_author": "clee2000",
        "comment_body": "I don't see where `relative_path` is defined?",
        "pr_file_module": null
      },
      {
        "comment_id": "2167693175",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156626,
        "pr_file": ".ci/pytorch/test.sh",
        "discussion_id": "2167676590",
        "commented_code": "@@ -333,6 +333,14 @@ test_h100_distributed() {\n   assert_git_not_dirty\n }\n \n+test_cutlass_backend() {\n+  # cutlass backend tests for H100\n+  folder_name=\"third_party/cutlass/python\"\n+  start_dir=\".\"\n+  folder_path=$(find \"$start_dir\" -type d -path \"$folder_name\" -print -quit)\n+  TORCHINDUCTOR_CUTLASS_DIR=$relative_path python test/run_test.py --include inductor/test_cutlass_backend -k 'test_max_autotune_cutlass_backend_regular_mm and not test_max_autotune_cutlass_backend_regular_mm_streamk' $PYTHON_TEST_EXTRA_OPTION --upload-artifacts-while-running",
        "comment_created_at": "2025-06-25T21:46:52+00:00",
        "comment_author": "henrylhtsang",
        "comment_body": "> I don't see where `relative_path` is defined?\r\n\r\nsure, but if you look at the logs:\r\n```\r\n2025-06-25T20:57:47.9637124Z + folder_name=third_party/cutlass/python\r\n2025-06-25T20:57:47.9637360Z + start_dir=.\r\n2025-06-25T20:57:47.9637622Z ++ find . -type d -path third_party/cutlass/python -print -quit\r\n2025-06-25T20:57:48.3304017Z + folder_path=\r\n2025-06-25T20:57:48.3304497Z + TORCHINDUCTOR_CUTLASS_DIR=\r\n2025-06-25T20:57:48.3305760Z + python test/run_test.py --include inductor/test_cutlass_backend -k 'test_max_autotune_cutlass_backend_regular_mm and not test_max_autotune_cutlass_backend_regular_mm_streamk' --upload-artifacts-while-running\r\n```\r\nfolder_path is still empty?",
        "pr_file_module": null
      },
      {
        "comment_id": "2167746862",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156626,
        "pr_file": ".ci/pytorch/test.sh",
        "discussion_id": "2167676590",
        "commented_code": "@@ -333,6 +333,14 @@ test_h100_distributed() {\n   assert_git_not_dirty\n }\n \n+test_cutlass_backend() {\n+  # cutlass backend tests for H100\n+  folder_name=\"third_party/cutlass/python\"\n+  start_dir=\".\"\n+  folder_path=$(find \"$start_dir\" -type d -path \"$folder_name\" -print -quit)\n+  TORCHINDUCTOR_CUTLASS_DIR=$relative_path python test/run_test.py --include inductor/test_cutlass_backend -k 'test_max_autotune_cutlass_backend_regular_mm and not test_max_autotune_cutlass_backend_regular_mm_streamk' $PYTHON_TEST_EXTRA_OPTION --upload-artifacts-while-running",
        "comment_created_at": "2025-06-25T22:28:59+00:00",
        "comment_author": "clee2000",
        "comment_body": "`find . -type d -path third_party/cutlass/python -print -quit` doesn't print anything for me when I run locally, you probably want `./third_party/cutlass/python` or some wildcards\r\n\r\nI've also historically had some issues with find where I think it was buffering output or something so be careful",
        "pr_file_module": null
      },
      {
        "comment_id": "2169841036",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156626,
        "pr_file": ".ci/pytorch/test.sh",
        "discussion_id": "2167676590",
        "commented_code": "@@ -333,6 +333,14 @@ test_h100_distributed() {\n   assert_git_not_dirty\n }\n \n+test_cutlass_backend() {\n+  # cutlass backend tests for H100\n+  folder_name=\"third_party/cutlass/python\"\n+  start_dir=\".\"\n+  folder_path=$(find \"$start_dir\" -type d -path \"$folder_name\" -print -quit)\n+  TORCHINDUCTOR_CUTLASS_DIR=$relative_path python test/run_test.py --include inductor/test_cutlass_backend -k 'test_max_autotune_cutlass_backend_regular_mm and not test_max_autotune_cutlass_backend_regular_mm_streamk' $PYTHON_TEST_EXTRA_OPTION --upload-artifacts-while-running",
        "comment_created_at": "2025-06-26T19:41:44+00:00",
        "comment_author": "henrylhtsang",
        "comment_body": "@clee2000  in the end looks like I need absolute path LOL\r\n\r\nthe path that works `TORCHINDUCTOR_CUTLASS_DIR=/var/lib/jenkins/workspace/third_party/cutlass` saw from raw logs ",
        "pr_file_module": null
      },
      {
        "comment_id": "2170431597",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156626,
        "pr_file": ".ci/pytorch/test.sh",
        "discussion_id": "2167676590",
        "commented_code": "@@ -333,6 +333,14 @@ test_h100_distributed() {\n   assert_git_not_dirty\n }\n \n+test_cutlass_backend() {\n+  # cutlass backend tests for H100\n+  folder_name=\"third_party/cutlass/python\"\n+  start_dir=\".\"\n+  folder_path=$(find \"$start_dir\" -type d -path \"$folder_name\" -print -quit)\n+  TORCHINDUCTOR_CUTLASS_DIR=$relative_path python test/run_test.py --include inductor/test_cutlass_backend -k 'test_max_autotune_cutlass_backend_regular_mm and not test_max_autotune_cutlass_backend_regular_mm_streamk' $PYTHON_TEST_EXTRA_OPTION --upload-artifacts-while-running",
        "comment_created_at": "2025-06-27T01:18:19+00:00",
        "comment_author": "huydhn",
        "comment_body": "I was about to say you could use $GITHUB_WORKSPACE, but it seems to hard code to `/var/lib/jenkins/workspace` anyway https://github.com/pytorch/pytorch/blob/main/.github/workflows/_linux-test.yml#L361C19-L361C35",
        "pr_file_module": null
      }
    ]
  }
]