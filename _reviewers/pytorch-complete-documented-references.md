---
title: Complete documented references
description: 'PyTorch documentation should be comprehensive and include proper cross-references
  to related content. This means:


  1. Including step-by-step instructions for tools and features'
repository: pytorch/pytorch
label: Pytorch
language: Markdown
comments_count: 2
repository_stars: 91169
---

PyTorch documentation should be comprehensive and include proper cross-references to related content. This means:

1. Including step-by-step instructions for tools and features
2. Using proper cross-reference formatting (`{ref}`) to link related documentation
3. Providing clear guidance for common use cases

For example, when documenting analysis tools:
```markdown
# `torch._inductor.analysis`
Contains scripts for inductor performance analysis.

## Usage
1. Profile capture: [steps for capturing profiles]
2. Profile augmenting: [steps for augmenting profiles]
3. Profile comparison: [steps for comparing profiles]
```

When referencing other sections in documentation, use proper cross-reference syntax:
```markdown
The schema for built-in functions like `aten::zeros` can be found at {ref}`builtin functions`.
```

This helps users navigate through PyTorch's extensive documentation and find relevant information quickly, which is essential for effectively using the framework's complex features and tools.


[
  {
    "discussion_id": "2124660049",
    "pr_number": 149697,
    "pr_file": "torch/_inductor/analysis/README.md",
    "created_at": "2025-06-03T18:49:30+00:00",
    "commented_code": "# `torch._inductor.analysis`\nContains scripts for inductor performance analysis.",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2124660049",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149697,
        "pr_file": "torch/_inductor/analysis/README.md",
        "discussion_id": "2124660049",
        "commented_code": "@@ -0,0 +1,2 @@\n+# `torch._inductor.analysis`\n+Contains scripts for inductor performance analysis.",
        "comment_created_at": "2025-06-03T18:49:30+00:00",
        "comment_author": "shunting314",
        "comment_body": "maybe a following: can we add steps for profile capture, profile augmenting, profile comparison here to make it easier to find a reference",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2154769604",
    "pr_number": 156094,
    "pr_file": "docs/source/jit.md",
    "created_at": "2025-06-18T14:31:31+00:00",
    "commented_code": "# TorchScript\n\n```{toctree}\n:maxdepth: 1\n:caption: Builtin Functions\n:hidden:\n\ntorch.jit.supported_ops <jit_builtin_functions>\n```\n\n```{toctree}\n:maxdepth: 1\n:caption: Language Reference\n:hidden:\n\njit_language_reference\n```\n\n```{toctree}\n:maxdepth: 1\n\njit_language_reference_v2\n```\n\n```{contents}\n:local:\n:depth: 2\n```\n\n```{eval-rst}\n.. automodule:: torch.jit\n.. currentmodule:: torch.jit\n```\n\nTorchScript is a way to create serializable and optimizable models from PyTorch code.\nAny TorchScript program can be saved from a Python\nprocess and loaded in a process where there is no Python dependency.\n\nWe provide tools to incrementally transition a model from a pure Python program\nto a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\nThis makes it possible to train models in PyTorch using familiar tools in Python and then export\nthe model via TorchScript to a production environment where Python programs may be disadvantageous\nfor performance and multi-threading reasons.\n\nFor a gentle introduction to TorchScript, see the [Introduction to TorchScript](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html) tutorial.\n\nFor an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see the\n[Loading a PyTorch Model in C++](https://pytorch.org/tutorials/advanced/cpp_export.html) tutorial.\n\n## Creating TorchScript Code\n\n```{eval-rst}\n.. autosummary::\n    :toctree: generated\n    :nosignatures:\n\n    script\n    trace\n    script_if_tracing\n    trace_module\n    fork\n    wait\n    ScriptModule\n    ScriptFunction\n    freeze\n    optimize_for_inference\n    enable_onednn_fusion\n    onednn_fusion_enabled\n    set_fusion_strategy\n    strict_fusion\n    save\n    load\n    ignore\n    unused\n    interface\n    isinstance\n    Attribute\n    annotate\n```\n\n## Mixing Tracing and Scripting\n\nIn many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\nTracing and scripting can be composed to suit the particular requirements\nof a part of a model.\n\nScripted functions can call traced functions. This is particularly useful when you need\nto use control-flow around a simple feed-forward model. For instance the beam search\nof a sequence to sequence model will typically be written in script but can call an\nencoder module generated using tracing.\n\n```{testsetup}\n# These are hidden from the docs, but these are necessary for `doctest`\n# since the `inspect` module doesn't play nicely with the execution\n# environment for `doctest`\nimport torch\n\noriginal_script = torch.jit.script\ndef script_wrapper(obj, *args, **kwargs):\n    obj.__module__ = 'FakeMod'\n    return original_script(obj, *args, **kwargs)\n\ntorch.jit.script = script_wrapper\n\noriginal_trace = torch.jit.trace\ndef trace_wrapper(obj, *args, **kwargs):\n    obj.__module__ = 'FakeMod'\n    return original_trace(obj, *args, **kwargs)\n\ntorch.jit.trace = trace_wrapper\n```\n\nExample (calling a traced function in script):\n\n```{testcode}\nimport torch\n\ndef foo(x, y):\n    return 2 * x + y\n\ntraced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))\n\n@torch.jit.script\ndef bar(x):\n    return traced_foo(x, x)\n```\n\nTraced functions can call script functions. This is useful when a small part of\na model requires some control-flow even though most of the model is just a feed-forward\nnetwork. Control-flow inside of a script function called by a traced function is\npreserved correctly.\n\nExample (calling a script function in a traced function):\n\n```{testcode}\nimport torch\n\n@torch.jit.script\ndef foo(x, y):\n    if x.max() > y.max():\n        r = x\n    else:\n        r = y\n    return r\n\n\ndef bar(x, y, z):\n    return foo(x, y) + z\n\ntraced_bar = torch.jit.trace(bar, (torch.rand(3), torch.rand(3), torch.rand(3)))\n```\n\nThis composition also works for `nn.Module`s as well, where it can be used to generate\na submodule using tracing that can be called from the methods of a script module.\n\nExample (using a traced module):\n\n```{testcode}\nimport torch\nimport torchvision\n:skipif: torchvision is None\n\nclass MyScriptModule(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.means = torch.nn.Parameter(torch.tensor([103.939, 116.779, 123.68])\n                                        .resize_(1, 3, 1, 1))\n        self.resnet = torch.jit.trace(torchvision.models.resnet18(),\n                                    torch.rand(1, 3, 224, 224))\n\n    def forward(self, input):\n        return self.resnet(input - self.means)\n\nmy_script_module = torch.jit.script(MyScriptModule())\n```\n\n## TorchScript Language\n\nTorchScript is a statically typed subset of Python, so many Python features apply\ndirectly to TorchScript. See the full {ref}`language-reference-v2` for details.\n\n(builtin functions)=\n\n## Built-in Functions and Modules\n\nTorchScript supports the use of most PyTorch functions and many Python built-ins.\nSee {ref}`builtin-functions` for a full reference of supported functions.\n\n### PyTorch Functions and Modules\n\nTorchScript supports a subset of the tensor and neural network\nfunctions that PyTorch provides. Most methods on Tensor as well as functions in\nthe `torch` namespace, all functions in `torch.nn.functional` and\nmost modules from `torch.nn` are supported in TorchScript.\n\nSee {ref}`jit_unsupported` for a list of unsupported PyTorch functions and modules.\n\n### Python Functions and Modules\n\nMany of Python's [built-in functions](https://docs.python.org/3/library/functions.html) are supported in TorchScript.\nThe {any}`math` module is also supported (see {ref}`math-module` for details), but no other Python modules\n(built-in or third party) are supported.\n\n### Python Language Reference Comparison\n\nFor a full listing of supported Python features, see {ref}`python-language-reference`.\n\n## Debugging\n\n(disable TorchScript)=\n\n### Disable JIT for Debugging\n\n```{eval-rst}\n.. envvar:: PYTORCH_JIT\n```\n\nSetting the environment variable `PYTORCH_JIT=0` will disable all script\nand tracing annotations. If there is hard-to-debug error in one of your\nTorchScript models, you can use this flag to force everything to run using native\nPython. Since TorchScript (scripting and tracing) is disabled with this flag,\nyou can use tools like `pdb` to debug the model code. For example:\n\n```python\n@torch.jit.script\ndef scripted_fn(x : torch.Tensor):\n    for i in range(12):\n        x = x + x\n    return x\n\ndef fn(x):\n    x = torch.neg(x)\n    import pdb; pdb.set_trace()\n    return scripted_fn(x)\n\ntraced_fn = torch.jit.trace(fn, (torch.rand(4, 5),))\ntraced_fn(torch.rand(3, 4))\n```\n\nDebugging this script with `pdb` works except for when we invoke the\n{func}`@torch.jit.script <torch.jit.script>` function. We can globally disable\nJIT, so that we can call the {func}`@torch.jit.script <torch.jit.script>`\nfunction as a normal Python function and not compile it. If the above script\nis called `disable_jit_example.py`, we can invoke it like so:\n\n```bash\n$ PYTORCH_JIT=0 python disable_jit_example.py\n```\n\nand we will be able to step into the {func}`@torch.jit.script <torch.jit.script>`\nfunction as a normal Python function. To disable the\nTorchScript compiler for a specific function, see\n{func}`@torch.jit.ignore <torch.jit.ignore>`.\n\n(inspecting-code)=\n\n### Inspecting Code\n\nTorchScript provides a code pretty-printer for all {class}`ScriptModule` instances. This\npretty-printer gives an interpretation of the script method's code as valid\nPython syntax. For example:\n\n```{testcode}\n@torch.jit.script\ndef foo(len):\n    # type: (int) -> torch.Tensor\n    rv = torch.zeros(3, 4)\n    for i in range(len):\n        if i < 10:\n            rv = rv - 1.0\n        else:\n            rv = rv + 1.0\n    return rv\n\nprint(foo.code)\n```\n\n```{testoutput}\n:hide:\n\n...\n```\n\nA {class}`ScriptModule` with a single `forward` method will have an attribute\n`code`, which you can use to inspect the {class}`ScriptModule`'s code.\nIf the {class}`ScriptModule` has more than one method, you will need to access\n`.code` on the method itself and not the module. We can inspect the\ncode of a method named `foo` on a {class}`ScriptModule` by accessing `.foo.code`.\nThe example above produces this output:\n\n```python\ndef foo(len: int) -> Tensor:\n    rv = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n    rv0 = rv\n    for i in range(len):\n        if torch.lt(i, 10):\n            rv1 = torch.sub(rv0, 1., 1)\n        else:\n            rv1 = torch.add(rv0, 1., 1)\n        rv0 = rv1\n    return rv0\n```\n\nThis is TorchScript's compilation of the code for the `forward` method.\nYou can use this to ensure TorchScript (tracing or scripting) has captured\nyour model code correctly.\n\n(interpreting-graphs)=\n\n### Interpreting Graphs\n\nTorchScript also has a representation at a lower level than the code pretty-printer, in the form of IR graphs.\n\nTorchScript uses a static single assignment (SSA) intermediate representation\n(IR) to represent computation. The instructions in this format consist of\nATen (the C++ backend of PyTorch) operators and other primitive operators,\nincluding control flow operators for loops and conditionals. As an example:\n\n```{testcode}\n@torch.jit.script\ndef foo(len):\n    # type: (int) -> torch.Tensor\n    rv = torch.zeros(3, 4)\n    for i in range(len):\n        if i < 10:\n            rv = rv - 1.0\n        else:\n            rv = rv + 1.0\n    return rv\n\nprint(foo.graph)\n```\n\n```{testoutput}\n:hide:\n\n...\n```\n\n`graph` follows the same rules described in the {ref}`inspecting-code` section\nwith regard to `forward` method lookup.\n\nThe example script above produces the graph:\n\n```\ngraph(%len.1 : int):\n  %24 : int = prim::Constant[value=1]()\n  %17 : bool = prim::Constant[value=1]() # test.py:10:5\n  %12 : bool? = prim::Constant()\n  %10 : Device? = prim::Constant()\n  %6 : int? = prim::Constant()\n  %1 : int = prim::Constant[value=3]() # test.py:9:22\n  %2 : int = prim::Constant[value=4]() # test.py:9:25\n  %20 : int = prim::Constant[value=10]() # test.py:11:16\n  %23 : float = prim::Constant[value=1]() # test.py:12:23\n  %4 : int[] = prim::ListConstruct(%1, %2)\n  %rv.1 : Tensor = aten::zeros(%4, %6, %6, %10, %12) # test.py:9:10\n  %rv : Tensor = prim::Loop(%len.1, %17, %rv.1) # test.py:10:5\n    block0(%i.1 : int, %rv.14 : Tensor):\n      %21 : bool = aten::lt(%i.1, %20) # test.py:11:12\n      %rv.13 : Tensor = prim::If(%21) # test.py:11:9\n        block0():\n          %rv.3 : Tensor = aten::sub(%rv.14, %23, %24) # test.py:12:18\n          -> (%rv.3)\n        block1():\n          %rv.6 : Tensor = aten::add(%rv.14, %23, %24) # test.py:14:18\n          -> (%rv.6)\n      -> (%17, %rv.13)\n  return (%rv)\n```\n\nTake the instruction `%rv.1 : Tensor = aten::zeros(%4, %6, %6, %10, %12) # test.py:9:10` for\nexample.\n\n- `%rv.1 : Tensor` means we assign the output to a (unique) value named `rv.1`, that value is of `Tensor` type and that we do not know its concrete shape.\n- `aten::zeros` is the operator (equivalent to `torch.zeros`) and the input list `(%4, %6, %6, %10, %12)` specifies which values in scope should be passed as inputs. The schema for built-in functions like `aten::zeros` can be found at Builtin Functions.",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2154769604",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156094,
        "pr_file": "docs/source/jit.md",
        "discussion_id": "2154769604",
        "commented_code": "@@ -0,0 +1,892 @@\n+# TorchScript\n+\n+```{toctree}\n+:maxdepth: 1\n+:caption: Builtin Functions\n+:hidden:\n+\n+torch.jit.supported_ops <jit_builtin_functions>\n+```\n+\n+```{toctree}\n+:maxdepth: 1\n+:caption: Language Reference\n+:hidden:\n+\n+jit_language_reference\n+```\n+\n+```{toctree}\n+:maxdepth: 1\n+\n+jit_language_reference_v2\n+```\n+\n+```{contents}\n+:local:\n+:depth: 2\n+```\n+\n+```{eval-rst}\n+.. automodule:: torch.jit\n+.. currentmodule:: torch.jit\n+```\n+\n+TorchScript is a way to create serializable and optimizable models from PyTorch code.\n+Any TorchScript program can be saved from a Python\n+process and loaded in a process where there is no Python dependency.\n+\n+We provide tools to incrementally transition a model from a pure Python program\n+to a TorchScript program that can be run independently from Python, such as in a standalone C++ program.\n+This makes it possible to train models in PyTorch using familiar tools in Python and then export\n+the model via TorchScript to a production environment where Python programs may be disadvantageous\n+for performance and multi-threading reasons.\n+\n+For a gentle introduction to TorchScript, see the [Introduction to TorchScript](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html) tutorial.\n+\n+For an end-to-end example of converting a PyTorch model to TorchScript and running it in C++, see the\n+[Loading a PyTorch Model in C++](https://pytorch.org/tutorials/advanced/cpp_export.html) tutorial.\n+\n+## Creating TorchScript Code\n+\n+```{eval-rst}\n+.. autosummary::\n+    :toctree: generated\n+    :nosignatures:\n+\n+    script\n+    trace\n+    script_if_tracing\n+    trace_module\n+    fork\n+    wait\n+    ScriptModule\n+    ScriptFunction\n+    freeze\n+    optimize_for_inference\n+    enable_onednn_fusion\n+    onednn_fusion_enabled\n+    set_fusion_strategy\n+    strict_fusion\n+    save\n+    load\n+    ignore\n+    unused\n+    interface\n+    isinstance\n+    Attribute\n+    annotate\n+```\n+\n+## Mixing Tracing and Scripting\n+\n+In many cases either tracing or scripting is an easier approach for converting a model to TorchScript.\n+Tracing and scripting can be composed to suit the particular requirements\n+of a part of a model.\n+\n+Scripted functions can call traced functions. This is particularly useful when you need\n+to use control-flow around a simple feed-forward model. For instance the beam search\n+of a sequence to sequence model will typically be written in script but can call an\n+encoder module generated using tracing.\n+\n+```{testsetup}\n+# These are hidden from the docs, but these are necessary for `doctest`\n+# since the `inspect` module doesn't play nicely with the execution\n+# environment for `doctest`\n+import torch\n+\n+original_script = torch.jit.script\n+def script_wrapper(obj, *args, **kwargs):\n+    obj.__module__ = 'FakeMod'\n+    return original_script(obj, *args, **kwargs)\n+\n+torch.jit.script = script_wrapper\n+\n+original_trace = torch.jit.trace\n+def trace_wrapper(obj, *args, **kwargs):\n+    obj.__module__ = 'FakeMod'\n+    return original_trace(obj, *args, **kwargs)\n+\n+torch.jit.trace = trace_wrapper\n+```\n+\n+Example (calling a traced function in script):\n+\n+```{testcode}\n+import torch\n+\n+def foo(x, y):\n+    return 2 * x + y\n+\n+traced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))\n+\n+@torch.jit.script\n+def bar(x):\n+    return traced_foo(x, x)\n+```\n+\n+Traced functions can call script functions. This is useful when a small part of\n+a model requires some control-flow even though most of the model is just a feed-forward\n+network. Control-flow inside of a script function called by a traced function is\n+preserved correctly.\n+\n+Example (calling a script function in a traced function):\n+\n+```{testcode}\n+import torch\n+\n+@torch.jit.script\n+def foo(x, y):\n+    if x.max() > y.max():\n+        r = x\n+    else:\n+        r = y\n+    return r\n+\n+\n+def bar(x, y, z):\n+    return foo(x, y) + z\n+\n+traced_bar = torch.jit.trace(bar, (torch.rand(3), torch.rand(3), torch.rand(3)))\n+```\n+\n+This composition also works for `nn.Module`s as well, where it can be used to generate\n+a submodule using tracing that can be called from the methods of a script module.\n+\n+Example (using a traced module):\n+\n+```{testcode}\n+import torch\n+import torchvision\n+:skipif: torchvision is None\n+\n+class MyScriptModule(torch.nn.Module):\n+    def __init__(self):\n+        super().__init__()\n+        self.means = torch.nn.Parameter(torch.tensor([103.939, 116.779, 123.68])\n+                                        .resize_(1, 3, 1, 1))\n+        self.resnet = torch.jit.trace(torchvision.models.resnet18(),\n+                                    torch.rand(1, 3, 224, 224))\n+\n+    def forward(self, input):\n+        return self.resnet(input - self.means)\n+\n+my_script_module = torch.jit.script(MyScriptModule())\n+```\n+\n+## TorchScript Language\n+\n+TorchScript is a statically typed subset of Python, so many Python features apply\n+directly to TorchScript. See the full {ref}`language-reference-v2` for details.\n+\n+(builtin functions)=\n+\n+## Built-in Functions and Modules\n+\n+TorchScript supports the use of most PyTorch functions and many Python built-ins.\n+See {ref}`builtin-functions` for a full reference of supported functions.\n+\n+### PyTorch Functions and Modules\n+\n+TorchScript supports a subset of the tensor and neural network\n+functions that PyTorch provides. Most methods on Tensor as well as functions in\n+the `torch` namespace, all functions in `torch.nn.functional` and\n+most modules from `torch.nn` are supported in TorchScript.\n+\n+See {ref}`jit_unsupported` for a list of unsupported PyTorch functions and modules.\n+\n+### Python Functions and Modules\n+\n+Many of Python's [built-in functions](https://docs.python.org/3/library/functions.html) are supported in TorchScript.\n+The {any}`math` module is also supported (see {ref}`math-module` for details), but no other Python modules\n+(built-in or third party) are supported.\n+\n+### Python Language Reference Comparison\n+\n+For a full listing of supported Python features, see {ref}`python-language-reference`.\n+\n+## Debugging\n+\n+(disable TorchScript)=\n+\n+### Disable JIT for Debugging\n+\n+```{eval-rst}\n+.. envvar:: PYTORCH_JIT\n+```\n+\n+Setting the environment variable `PYTORCH_JIT=0` will disable all script\n+and tracing annotations. If there is hard-to-debug error in one of your\n+TorchScript models, you can use this flag to force everything to run using native\n+Python. Since TorchScript (scripting and tracing) is disabled with this flag,\n+you can use tools like `pdb` to debug the model code. For example:\n+\n+```python\n+@torch.jit.script\n+def scripted_fn(x : torch.Tensor):\n+    for i in range(12):\n+        x = x + x\n+    return x\n+\n+def fn(x):\n+    x = torch.neg(x)\n+    import pdb; pdb.set_trace()\n+    return scripted_fn(x)\n+\n+traced_fn = torch.jit.trace(fn, (torch.rand(4, 5),))\n+traced_fn(torch.rand(3, 4))\n+```\n+\n+Debugging this script with `pdb` works except for when we invoke the\n+{func}`@torch.jit.script <torch.jit.script>` function. We can globally disable\n+JIT, so that we can call the {func}`@torch.jit.script <torch.jit.script>`\n+function as a normal Python function and not compile it. If the above script\n+is called `disable_jit_example.py`, we can invoke it like so:\n+\n+```bash\n+$ PYTORCH_JIT=0 python disable_jit_example.py\n+```\n+\n+and we will be able to step into the {func}`@torch.jit.script <torch.jit.script>`\n+function as a normal Python function. To disable the\n+TorchScript compiler for a specific function, see\n+{func}`@torch.jit.ignore <torch.jit.ignore>`.\n+\n+(inspecting-code)=\n+\n+### Inspecting Code\n+\n+TorchScript provides a code pretty-printer for all {class}`ScriptModule` instances. This\n+pretty-printer gives an interpretation of the script method's code as valid\n+Python syntax. For example:\n+\n+```{testcode}\n+@torch.jit.script\n+def foo(len):\n+    # type: (int) -> torch.Tensor\n+    rv = torch.zeros(3, 4)\n+    for i in range(len):\n+        if i < 10:\n+            rv = rv - 1.0\n+        else:\n+            rv = rv + 1.0\n+    return rv\n+\n+print(foo.code)\n+```\n+\n+```{testoutput}\n+:hide:\n+\n+...\n+```\n+\n+A {class}`ScriptModule` with a single `forward` method will have an attribute\n+`code`, which you can use to inspect the {class}`ScriptModule`'s code.\n+If the {class}`ScriptModule` has more than one method, you will need to access\n+`.code` on the method itself and not the module. We can inspect the\n+code of a method named `foo` on a {class}`ScriptModule` by accessing `.foo.code`.\n+The example above produces this output:\n+\n+```python\n+def foo(len: int) -> Tensor:\n+    rv = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n+    rv0 = rv\n+    for i in range(len):\n+        if torch.lt(i, 10):\n+            rv1 = torch.sub(rv0, 1., 1)\n+        else:\n+            rv1 = torch.add(rv0, 1., 1)\n+        rv0 = rv1\n+    return rv0\n+```\n+\n+This is TorchScript's compilation of the code for the `forward` method.\n+You can use this to ensure TorchScript (tracing or scripting) has captured\n+your model code correctly.\n+\n+(interpreting-graphs)=\n+\n+### Interpreting Graphs\n+\n+TorchScript also has a representation at a lower level than the code pretty-printer, in the form of IR graphs.\n+\n+TorchScript uses a static single assignment (SSA) intermediate representation\n+(IR) to represent computation. The instructions in this format consist of\n+ATen (the C++ backend of PyTorch) operators and other primitive operators,\n+including control flow operators for loops and conditionals. As an example:\n+\n+```{testcode}\n+@torch.jit.script\n+def foo(len):\n+    # type: (int) -> torch.Tensor\n+    rv = torch.zeros(3, 4)\n+    for i in range(len):\n+        if i < 10:\n+            rv = rv - 1.0\n+        else:\n+            rv = rv + 1.0\n+    return rv\n+\n+print(foo.graph)\n+```\n+\n+```{testoutput}\n+:hide:\n+\n+...\n+```\n+\n+`graph` follows the same rules described in the {ref}`inspecting-code` section\n+with regard to `forward` method lookup.\n+\n+The example script above produces the graph:\n+\n+```\n+graph(%len.1 : int):\n+  %24 : int = prim::Constant[value=1]()\n+  %17 : bool = prim::Constant[value=1]() # test.py:10:5\n+  %12 : bool? = prim::Constant()\n+  %10 : Device? = prim::Constant()\n+  %6 : int? = prim::Constant()\n+  %1 : int = prim::Constant[value=3]() # test.py:9:22\n+  %2 : int = prim::Constant[value=4]() # test.py:9:25\n+  %20 : int = prim::Constant[value=10]() # test.py:11:16\n+  %23 : float = prim::Constant[value=1]() # test.py:12:23\n+  %4 : int[] = prim::ListConstruct(%1, %2)\n+  %rv.1 : Tensor = aten::zeros(%4, %6, %6, %10, %12) # test.py:9:10\n+  %rv : Tensor = prim::Loop(%len.1, %17, %rv.1) # test.py:10:5\n+    block0(%i.1 : int, %rv.14 : Tensor):\n+      %21 : bool = aten::lt(%i.1, %20) # test.py:11:12\n+      %rv.13 : Tensor = prim::If(%21) # test.py:11:9\n+        block0():\n+          %rv.3 : Tensor = aten::sub(%rv.14, %23, %24) # test.py:12:18\n+          -> (%rv.3)\n+        block1():\n+          %rv.6 : Tensor = aten::add(%rv.14, %23, %24) # test.py:14:18\n+          -> (%rv.6)\n+      -> (%17, %rv.13)\n+  return (%rv)\n+```\n+\n+Take the instruction `%rv.1 : Tensor = aten::zeros(%4, %6, %6, %10, %12) # test.py:9:10` for\n+example.\n+\n+- `%rv.1 : Tensor` means we assign the output to a (unique) value named `rv.1`, that value is of `Tensor` type and that we do not know its concrete shape.\n+- `aten::zeros` is the operator (equivalent to `torch.zeros`) and the input list `(%4, %6, %6, %10, %12)` specifies which values in scope should be passed as inputs. The schema for built-in functions like `aten::zeros` can be found at Builtin Functions.",
        "comment_created_at": "2025-06-18T14:31:31+00:00",
        "comment_author": "svekars",
        "comment_body": "```suggestion\r\n- `aten::zeros` is the operator (equivalent to `torch.zeros`) and the input list `(%4, %6, %6, %10, %12)` specifies which values in scope should be passed as inputs. The schema for built-in functions like `aten::zeros` can be found at {ref}`<builtin functions>`.\r\n```",
        "pr_file_module": null
      }
    ]
  }
]
