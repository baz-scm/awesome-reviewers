[
  {
    "discussion_id": "2049250850",
    "pr_number": 149697,
    "pr_file": "torch/_inductor/utils.py",
    "created_at": "2025-04-17T15:57:52+00:00",
    "commented_code": "@functools.lru_cache(None)\n-def get_device_tflops(dtype: torch.dtype) -> int:\n+def get_device_tflops(dtype: torch.dtype) -> float:\n+    \"\"\"\n+    We don't want to throw errors in this function. First check to see if the device is in device_info.py,\n+    then fall back to the inaccurate triton estimation.\n+    \"\"\"\n+    try:",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2049250850",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149697,
        "pr_file": "torch/_inductor/utils.py",
        "discussion_id": "2049250850",
        "commented_code": "@@ -1887,16 +1895,26 @@ def get_backend_num_stages() -> int:\n \n \n @functools.lru_cache(None)\n-def get_device_tflops(dtype: torch.dtype) -> int:\n+def get_device_tflops(dtype: torch.dtype) -> float:\n+    \"\"\"\n+    We don't want to throw errors in this function. First check to see if the device is in device_info.py,\n+    then fall back to the inaccurate triton estimation.\n+    \"\"\"\n+    try:",
        "comment_created_at": "2025-04-17T15:57:52+00:00",
        "comment_author": "eellison",
        "comment_body": "Can we have datasheet_tops just return None if unsuccessful ? I prefer to avoid pattern where we're catching arbitrary exceptions. ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2159235161",
    "pr_number": 156148,
    "pr_file": "torch/_dynamo/variables/builtin.py",
    "created_at": "2025-06-20T15:24:28+00:00",
    "commented_code": "def expand_list_like(tx: \"InstructionTranslator\", lst, const):\n             if isinstance(lst, ConstantVariable):\n                 lst, const = const, lst\n-            return lst.__class__(\n-                items=lst.items * const.as_python_constant(),\n-                mutation_type=ValueMutationNew(),\n-            )\n+            try:\n+                return lst.__class__(\n+                    items=lst.items * const.as_python_constant(),\n+                    mutation_type=ValueMutationNew(),\n+                )\n+            except Exception as exc:\n+                # MemoryError\n+                raise_observed_exception(\n+                    type(exc),\n+                    tx,\n+                    args=list(map(ConstantVariable.create, exc.args)),\n+                )",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2159235161",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156148,
        "pr_file": "torch/_dynamo/variables/builtin.py",
        "discussion_id": "2159235161",
        "commented_code": "@@ -542,10 +542,18 @@ def list_iadd_handler(tx: \"InstructionTranslator\", a, b):\n         def expand_list_like(tx: \"InstructionTranslator\", lst, const):\n             if isinstance(lst, ConstantVariable):\n                 lst, const = const, lst\n-            return lst.__class__(\n-                items=lst.items * const.as_python_constant(),\n-                mutation_type=ValueMutationNew(),\n-            )\n+            try:\n+                return lst.__class__(\n+                    items=lst.items * const.as_python_constant(),\n+                    mutation_type=ValueMutationNew(),\n+                )\n+            except Exception as exc:\n+                # MemoryError\n+                raise_observed_exception(\n+                    type(exc),\n+                    tx,\n+                    args=list(map(ConstantVariable.create, exc.args)),\n+                )",
        "comment_created_at": "2025-06-20T15:24:28+00:00",
        "comment_author": "zou3519",
        "comment_body": "What exceptions are we trying to catch here? If it's just MemoryError then we should use that in the except block.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1900929369",
    "pr_number": 139171,
    "pr_file": "torch/_dynamo/eval_frame.py",
    "created_at": "2025-01-02T14:24:57+00:00",
    "commented_code": "return False\n \n \n-def check_if_inductor_supported():\n+def check_if_inductor_supported(device: torch.device | str | None = None):\n+    from torch._inductor.codegen.common import (\n+        get_scheduling_for_device,\n+        init_backend_registration,\n+    )\n+\n     check_if_dynamo_supported()\n \n+    init_backend_registration()\n+\n+    if device is None:\n+        device = torch.get_default_device()\n+    elif isinstance(device, str):\n+        device = torch.device(device)\n+\n+    scheduling_factory = get_scheduling_for_device(device.type)\n+    if scheduling_factory is None:\n+        return False",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "1900929369",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 139171,
        "pr_file": "torch/_dynamo/eval_frame.py",
        "discussion_id": "1900929369",
        "commented_code": "@@ -825,11 +825,28 @@ def is_dynamo_supported():\n         return False\n \n \n-def check_if_inductor_supported():\n+def check_if_inductor_supported(device: torch.device | str | None = None):\n+    from torch._inductor.codegen.common import (\n+        get_scheduling_for_device,\n+        init_backend_registration,\n+    )\n+\n     check_if_dynamo_supported()\n \n+    init_backend_registration()\n+\n+    if device is None:\n+        device = torch.get_default_device()\n+    elif isinstance(device, str):\n+        device = torch.device(device)\n+\n+    scheduling_factory = get_scheduling_for_device(device.type)\n+    if scheduling_factory is None:\n+        return False",
        "comment_created_at": "2025-01-02T14:24:57+00:00",
        "comment_author": "EikanWang",
        "comment_body": "It should raise a runtime error rather than `return False`. Otherwise, the `is_inductor_supported` will return `True`.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2191263090",
    "pr_number": 154793,
    "pr_file": "torch/_dynamo/variables/dicts.py",
    "created_at": "2025-07-08T00:55:27+00:00",
    "commented_code": "self.should_reconstruct_all = True\n             tx.output.side_effects.mutation(self)\n             return self.items.pop(Hashable(args[0]))\n+        elif name == \"popitem\" and self.is_mutable():\n+            if len(args):\n+                raise_args_mismatch(tx, name)\n+            self.should_reconstruct_all = True\n+            tx.output.side_effects.mutation(self)",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2191263090",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 154793,
        "pr_file": "torch/_dynamo/variables/dicts.py",
        "discussion_id": "2191263090",
        "commented_code": "@@ -529,6 +529,16 @@ def call_method(\n             self.should_reconstruct_all = True\n             tx.output.side_effects.mutation(self)\n             return self.items.pop(Hashable(args[0]))\n+        elif name == \"popitem\" and self.is_mutable():\n+            if len(args):\n+                raise_args_mismatch(tx, name)\n+            self.should_reconstruct_all = True\n+            tx.output.side_effects.mutation(self)",
        "comment_created_at": "2025-07-08T00:55:27+00:00",
        "comment_author": "mlazos",
        "comment_body": "nit: you should put the mutation registration after the possible exception being raised, just to prevent anything from being in an invalid state if the exception ends up being caught in the future (I don't think it is today, but that might not always be the case)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2164974972",
    "pr_number": 156187,
    "pr_file": "torch/_inductor/compile_worker/subproc_pool.py",
    "created_at": "2025-06-24T21:46:07+00:00",
    "commented_code": "_T = TypeVar(\"_T\")\n \n \n-def _pack_msg(job_id: int, length: int) -> bytes:\n-    return struct.pack(\"nn\", job_id, length)\n+class MsgType(IntEnum):",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2164974972",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156187,
        "pr_file": "torch/_inductor/compile_worker/subproc_pool.py",
        "discussion_id": "2164974972",
        "commented_code": "@@ -36,31 +36,42 @@\n _T = TypeVar(\"_T\")\n \n \n-def _pack_msg(job_id: int, length: int) -> bytes:\n-    return struct.pack(\"nn\", job_id, length)\n+class MsgType(IntEnum):",
        "comment_created_at": "2025-06-24T21:46:07+00:00",
        "comment_author": "masnesral",
        "comment_body": "Previously we were using job_id -1 to signal error / shutdown. This change adds explicit message types in the form of this enum.",
        "pr_file_module": null
      }
    ]
  }
]