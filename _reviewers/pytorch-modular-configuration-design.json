[
  {
    "discussion_id": "2167718530",
    "pr_number": 149601,
    "pr_file": "c10/core/AllocatorConfig.h",
    "created_at": "2025-06-25T22:03:42+00:00",
    "commented_code": "+#pragma once\n+\n+#include <c10/core/DeviceType.h>\n+#include <c10/util/Exception.h>\n+#include <c10/util/llvmMathExtras.h>\n+\n+#include <array>\n+#include <atomic>\n+#include <mutex>\n+#include <string>\n+#include <vector>\n+\n+namespace c10::CachingAllocator {\n+\n+// \"large\" allocations may be packed in 20 MiB blocks\n+const size_t kLargeBuffer = 20971520;\n+\n+/**\n+ * Note [AllocatorConfig design]\n+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+ * This class configures the allocator for both device and host memory\n+ * management. A single AllocatorConfig is used across all devices, such as CUDA\n+ * and XPU, assuming that environment variables apply universally.\n+ *\n+ * It is designed to *ONLY* contain configuration options that can be set via\n+ * environment variables.\n+ *\n+ * Naming Convention:\n+ * - Public API names in AllocatorConfig should be device-generic. For example,\n+ *     `use_release_lock_on_cudamalloc` is not ideal; instead, use\n+ *     `use_release_lock_on_device_malloc` to maintain neutrality.\n+ * - Members prefixed with `pinned_` are specific to the host/pinned allocator.\n+ * - Environment variable names should also be device-generic to ensure\n+ *     consistency across different hardware backends.\n+ *\n+ * Environment Variables:\n+ * - The default environment variable for configuration is `PYTORCH_ALLOC_CONF`.\n+ * - For backward compatibility, `PYTORCH_CUDA_ALLOC_CONF` is also supported\n+ *     with lower priority.\n+ */\n+\n+class C10_API AllocatorConfig {",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2167718530",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149601,
        "pr_file": "c10/core/AllocatorConfig.h",
        "discussion_id": "2167718530",
        "commented_code": "@@ -0,0 +1,217 @@\n+#pragma once\n+\n+#include <c10/core/DeviceType.h>\n+#include <c10/util/Exception.h>\n+#include <c10/util/llvmMathExtras.h>\n+\n+#include <array>\n+#include <atomic>\n+#include <mutex>\n+#include <string>\n+#include <vector>\n+\n+namespace c10::CachingAllocator {\n+\n+// \"large\" allocations may be packed in 20 MiB blocks\n+const size_t kLargeBuffer = 20971520;\n+\n+/**\n+ * Note [AllocatorConfig design]\n+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+ * This class configures the allocator for both device and host memory\n+ * management. A single AllocatorConfig is used across all devices, such as CUDA\n+ * and XPU, assuming that environment variables apply universally.\n+ *\n+ * It is designed to *ONLY* contain configuration options that can be set via\n+ * environment variables.\n+ *\n+ * Naming Convention:\n+ * - Public API names in AllocatorConfig should be device-generic. For example,\n+ *     `use_release_lock_on_cudamalloc` is not ideal; instead, use\n+ *     `use_release_lock_on_device_malloc` to maintain neutrality.\n+ * - Members prefixed with `pinned_` are specific to the host/pinned allocator.\n+ * - Environment variable names should also be device-generic to ensure\n+ *     consistency across different hardware backends.\n+ *\n+ * Environment Variables:\n+ * - The default environment variable for configuration is `PYTORCH_ALLOC_CONF`.\n+ * - For backward compatibility, `PYTORCH_CUDA_ALLOC_CONF` is also supported\n+ *     with lower priority.\n+ */\n+\n+class C10_API AllocatorConfig {",
        "comment_created_at": "2025-06-25T22:03:42+00:00",
        "comment_author": "albanD",
        "comment_body": "I feel like this is very much about accelerator devices only? If so, I would suggest updating the name here.\r\n\r\nAlso update the doc above to be less about the history (cuda vs not) and more about the current state: any generic accelerator uses this.",
        "pr_file_module": null
      },
      {
        "comment_id": "2168624248",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149601,
        "pr_file": "c10/core/AllocatorConfig.h",
        "discussion_id": "2167718530",
        "commented_code": "@@ -0,0 +1,217 @@\n+#pragma once\n+\n+#include <c10/core/DeviceType.h>\n+#include <c10/util/Exception.h>\n+#include <c10/util/llvmMathExtras.h>\n+\n+#include <array>\n+#include <atomic>\n+#include <mutex>\n+#include <string>\n+#include <vector>\n+\n+namespace c10::CachingAllocator {\n+\n+// \"large\" allocations may be packed in 20 MiB blocks\n+const size_t kLargeBuffer = 20971520;\n+\n+/**\n+ * Note [AllocatorConfig design]\n+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+ * This class configures the allocator for both device and host memory\n+ * management. A single AllocatorConfig is used across all devices, such as CUDA\n+ * and XPU, assuming that environment variables apply universally.\n+ *\n+ * It is designed to *ONLY* contain configuration options that can be set via\n+ * environment variables.\n+ *\n+ * Naming Convention:\n+ * - Public API names in AllocatorConfig should be device-generic. For example,\n+ *     `use_release_lock_on_cudamalloc` is not ideal; instead, use\n+ *     `use_release_lock_on_device_malloc` to maintain neutrality.\n+ * - Members prefixed with `pinned_` are specific to the host/pinned allocator.\n+ * - Environment variable names should also be device-generic to ensure\n+ *     consistency across different hardware backends.\n+ *\n+ * Environment Variables:\n+ * - The default environment variable for configuration is `PYTORCH_ALLOC_CONF`.\n+ * - For backward compatibility, `PYTORCH_CUDA_ALLOC_CONF` is also supported\n+ *     with lower priority.\n+ */\n+\n+class C10_API AllocatorConfig {",
        "comment_created_at": "2025-06-26T09:27:00+00:00",
        "comment_author": "guangyey",
        "comment_body": "The original `CUDAAllocatorConfig` includes configurations for both device and host (pinned) memory.\r\nFor pinned memory, the following options are provided:\r\n- pinned_use_device_host_register: Enables the use of cudaHostRegister. Currently supported only on CUDA.\r\n- pinned_num_register_threads and pinned_max_register_threads: Control the number of threads used for host memory registration.\r\n- pinned_use_background_threads: Indicates whether background threads should be used for processing events. This is a generic option that can be supported by other backends as well.\r\n\r\nWhile `pinned_use_device_host_register` is currently CUDA-specific, other backends should consider adding support for similar functionality on demand.\r\n\r\nFor device memory, the following options are CUDA-specific:\r\n- use_release_lock_on_device_malloc_\r\n- use_async_allocator_",
        "pr_file_module": null
      },
      {
        "comment_id": "2169138926",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149601,
        "pr_file": "c10/core/AllocatorConfig.h",
        "discussion_id": "2167718530",
        "commented_code": "@@ -0,0 +1,217 @@\n+#pragma once\n+\n+#include <c10/core/DeviceType.h>\n+#include <c10/util/Exception.h>\n+#include <c10/util/llvmMathExtras.h>\n+\n+#include <array>\n+#include <atomic>\n+#include <mutex>\n+#include <string>\n+#include <vector>\n+\n+namespace c10::CachingAllocator {\n+\n+// \"large\" allocations may be packed in 20 MiB blocks\n+const size_t kLargeBuffer = 20971520;\n+\n+/**\n+ * Note [AllocatorConfig design]\n+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+ * This class configures the allocator for both device and host memory\n+ * management. A single AllocatorConfig is used across all devices, such as CUDA\n+ * and XPU, assuming that environment variables apply universally.\n+ *\n+ * It is designed to *ONLY* contain configuration options that can be set via\n+ * environment variables.\n+ *\n+ * Naming Convention:\n+ * - Public API names in AllocatorConfig should be device-generic. For example,\n+ *     `use_release_lock_on_cudamalloc` is not ideal; instead, use\n+ *     `use_release_lock_on_device_malloc` to maintain neutrality.\n+ * - Members prefixed with `pinned_` are specific to the host/pinned allocator.\n+ * - Environment variable names should also be device-generic to ensure\n+ *     consistency across different hardware backends.\n+ *\n+ * Environment Variables:\n+ * - The default environment variable for configuration is `PYTORCH_ALLOC_CONF`.\n+ * - For backward compatibility, `PYTORCH_CUDA_ALLOC_CONF` is also supported\n+ *     with lower priority.\n+ */\n+\n+class C10_API AllocatorConfig {",
        "comment_created_at": "2025-06-26T13:55:36+00:00",
        "comment_author": "guangyey",
        "comment_body": "It feels a bit forced to move the current CUDA-specific configurations (the other backend maybe support or not) into the generic `AllocatorConfig`. Instead, I suggest that we keep only the common configurations in `AllocatorConfig` and retain the CUDA-specific ones in `CUDAAllocatorConfig`. Meanwhile, `CUDAAllocatorConfig` will remain internal to `CUDACachingAllocator` and not be exposed beyond it.\r\nAnd `AllocatorConfig` will be responsible for both device and pin memory allocator. Is this reasonable to you?",
        "pr_file_module": null
      },
      {
        "comment_id": "2174095186",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149601,
        "pr_file": "c10/core/AllocatorConfig.h",
        "discussion_id": "2167718530",
        "commented_code": "@@ -0,0 +1,217 @@\n+#pragma once\n+\n+#include <c10/core/DeviceType.h>\n+#include <c10/util/Exception.h>\n+#include <c10/util/llvmMathExtras.h>\n+\n+#include <array>\n+#include <atomic>\n+#include <mutex>\n+#include <string>\n+#include <vector>\n+\n+namespace c10::CachingAllocator {\n+\n+// \"large\" allocations may be packed in 20 MiB blocks\n+const size_t kLargeBuffer = 20971520;\n+\n+/**\n+ * Note [AllocatorConfig design]\n+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+ * This class configures the allocator for both device and host memory\n+ * management. A single AllocatorConfig is used across all devices, such as CUDA\n+ * and XPU, assuming that environment variables apply universally.\n+ *\n+ * It is designed to *ONLY* contain configuration options that can be set via\n+ * environment variables.\n+ *\n+ * Naming Convention:\n+ * - Public API names in AllocatorConfig should be device-generic. For example,\n+ *     `use_release_lock_on_cudamalloc` is not ideal; instead, use\n+ *     `use_release_lock_on_device_malloc` to maintain neutrality.\n+ * - Members prefixed with `pinned_` are specific to the host/pinned allocator.\n+ * - Environment variable names should also be device-generic to ensure\n+ *     consistency across different hardware backends.\n+ *\n+ * Environment Variables:\n+ * - The default environment variable for configuration is `PYTORCH_ALLOC_CONF`.\n+ * - For backward compatibility, `PYTORCH_CUDA_ALLOC_CONF` is also supported\n+ *     with lower priority.\n+ */\n+\n+class C10_API AllocatorConfig {",
        "comment_created_at": "2025-06-30T02:22:30+00:00",
        "comment_author": "guangyey",
        "comment_body": "Renamed the class to `AcceleratorAllocatorConfig` to clarify its scope as a configuration manager for accelerator backends (e.g., CUDA, XPU). The original name `AllocatorConfig` is now reserved for a potential future base class that can unify configuration handling for both CPU and accelerator allocators, should similar requirements arise for the CPU path.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2167728709",
    "pr_number": 149601,
    "pr_file": "c10/core/AllocatorConfig.h",
    "created_at": "2025-06-25T22:12:46+00:00",
    "commented_code": "+#pragma once\n+\n+#include <c10/core/DeviceType.h>\n+#include <c10/util/Exception.h>\n+#include <c10/util/llvmMathExtras.h>\n+\n+#include <array>\n+#include <atomic>\n+#include <mutex>\n+#include <string>\n+#include <vector>\n+\n+namespace c10::CachingAllocator {\n+\n+// \"large\" allocations may be packed in 20 MiB blocks\n+const size_t kLargeBuffer = 20971520;\n+\n+/**\n+ * Note [AllocatorConfig design]\n+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+ * This class configures the allocator for both device and host memory\n+ * management. A single AllocatorConfig is used across all devices, such as CUDA\n+ * and XPU, assuming that environment variables apply universally.\n+ *\n+ * It is designed to *ONLY* contain configuration options that can be set via\n+ * environment variables.\n+ *\n+ * Naming Convention:\n+ * - Public API names in AllocatorConfig should be device-generic. For example,\n+ *     `use_release_lock_on_cudamalloc` is not ideal; instead, use\n+ *     `use_release_lock_on_device_malloc` to maintain neutrality.\n+ * - Members prefixed with `pinned_` are specific to the host/pinned allocator.\n+ * - Environment variable names should also be device-generic to ensure\n+ *     consistency across different hardware backends.\n+ *\n+ * Environment Variables:\n+ * - The default environment variable for configuration is `PYTORCH_ALLOC_CONF`.\n+ * - For backward compatibility, `PYTORCH_CUDA_ALLOC_CONF` is also supported\n+ *     with lower priority.\n+ */\n+\n+class C10_API AllocatorConfig {\n+ public:\n+  static AllocatorConfig& instance();\n+\n+  C10_DISABLE_COPY_AND_ASSIGN(AllocatorConfig);\n+  AllocatorConfig(AllocatorConfig&&) = delete;\n+  AllocatorConfig& operator=(AllocatorConfig&&) = delete;\n+  ~AllocatorConfig() = default;\n+\n+  /* Device allocator settings */",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2167728709",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149601,
        "pr_file": "c10/core/AllocatorConfig.h",
        "discussion_id": "2167728709",
        "commented_code": "@@ -0,0 +1,217 @@\n+#pragma once\n+\n+#include <c10/core/DeviceType.h>\n+#include <c10/util/Exception.h>\n+#include <c10/util/llvmMathExtras.h>\n+\n+#include <array>\n+#include <atomic>\n+#include <mutex>\n+#include <string>\n+#include <vector>\n+\n+namespace c10::CachingAllocator {\n+\n+// \"large\" allocations may be packed in 20 MiB blocks\n+const size_t kLargeBuffer = 20971520;\n+\n+/**\n+ * Note [AllocatorConfig design]\n+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+ * This class configures the allocator for both device and host memory\n+ * management. A single AllocatorConfig is used across all devices, such as CUDA\n+ * and XPU, assuming that environment variables apply universally.\n+ *\n+ * It is designed to *ONLY* contain configuration options that can be set via\n+ * environment variables.\n+ *\n+ * Naming Convention:\n+ * - Public API names in AllocatorConfig should be device-generic. For example,\n+ *     `use_release_lock_on_cudamalloc` is not ideal; instead, use\n+ *     `use_release_lock_on_device_malloc` to maintain neutrality.\n+ * - Members prefixed with `pinned_` are specific to the host/pinned allocator.\n+ * - Environment variable names should also be device-generic to ensure\n+ *     consistency across different hardware backends.\n+ *\n+ * Environment Variables:\n+ * - The default environment variable for configuration is `PYTORCH_ALLOC_CONF`.\n+ * - For backward compatibility, `PYTORCH_CUDA_ALLOC_CONF` is also supported\n+ *     with lower priority.\n+ */\n+\n+class C10_API AllocatorConfig {\n+ public:\n+  static AllocatorConfig& instance();\n+\n+  C10_DISABLE_COPY_AND_ASSIGN(AllocatorConfig);\n+  AllocatorConfig(AllocatorConfig&&) = delete;\n+  AllocatorConfig& operator=(AllocatorConfig&&) = delete;\n+  ~AllocatorConfig() = default;\n+\n+  /* Device allocator settings */",
        "comment_created_at": "2025-06-25T22:12:46+00:00",
        "comment_author": "albanD",
        "comment_body": "I feel like we want to add documentation for all of these?\r\nAlso you're confident all of these are relevant for all accelerators? A lot of these feel very cuda specific and I don't really see a benefit with moving them here?",
        "pr_file_module": null
      },
      {
        "comment_id": "2174093569",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149601,
        "pr_file": "c10/core/AllocatorConfig.h",
        "discussion_id": "2167728709",
        "commented_code": "@@ -0,0 +1,217 @@\n+#pragma once\n+\n+#include <c10/core/DeviceType.h>\n+#include <c10/util/Exception.h>\n+#include <c10/util/llvmMathExtras.h>\n+\n+#include <array>\n+#include <atomic>\n+#include <mutex>\n+#include <string>\n+#include <vector>\n+\n+namespace c10::CachingAllocator {\n+\n+// \"large\" allocations may be packed in 20 MiB blocks\n+const size_t kLargeBuffer = 20971520;\n+\n+/**\n+ * Note [AllocatorConfig design]\n+ * ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+ * This class configures the allocator for both device and host memory\n+ * management. A single AllocatorConfig is used across all devices, such as CUDA\n+ * and XPU, assuming that environment variables apply universally.\n+ *\n+ * It is designed to *ONLY* contain configuration options that can be set via\n+ * environment variables.\n+ *\n+ * Naming Convention:\n+ * - Public API names in AllocatorConfig should be device-generic. For example,\n+ *     `use_release_lock_on_cudamalloc` is not ideal; instead, use\n+ *     `use_release_lock_on_device_malloc` to maintain neutrality.\n+ * - Members prefixed with `pinned_` are specific to the host/pinned allocator.\n+ * - Environment variable names should also be device-generic to ensure\n+ *     consistency across different hardware backends.\n+ *\n+ * Environment Variables:\n+ * - The default environment variable for configuration is `PYTORCH_ALLOC_CONF`.\n+ * - For backward compatibility, `PYTORCH_CUDA_ALLOC_CONF` is also supported\n+ *     with lower priority.\n+ */\n+\n+class C10_API AllocatorConfig {\n+ public:\n+  static AllocatorConfig& instance();\n+\n+  C10_DISABLE_COPY_AND_ASSIGN(AllocatorConfig);\n+  AllocatorConfig(AllocatorConfig&&) = delete;\n+  AllocatorConfig& operator=(AllocatorConfig&&) = delete;\n+  ~AllocatorConfig() = default;\n+\n+  /* Device allocator settings */",
        "comment_created_at": "2025-06-30T02:20:01+00:00",
        "comment_author": "guangyey",
        "comment_body": "Update the documentation.\r\nRefactored allocator configuration handling by isolating CUDA-specific options into `CUDAAllocatorConfig`. Introduced a hook mechanism that allows `c10::CachingAllocator::setAllocatorSettings` to invoke `parseArgs` of both the common `AcceleratorAllocatorConfig` and backend-specific extensions such as `CUDAAllocatorConfig`.\r\nThis improves modularity and enables extensibility for other accelerators.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2010992676",
    "pr_number": 149861,
    "pr_file": "cmake/public/cuda.cmake.in",
    "created_at": "2025-03-24T22:10:52+00:00",
    "commented_code": "endif()\n \n # nvToolsExt\n-if(USE_SYSTEM_NVTX)\n+if(@USE_SYSTEM_NVTX@)",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2010992676",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149861,
        "pr_file": "cmake/public/cuda.cmake.in",
        "discussion_id": "2010992676",
        "commented_code": "@@ -170,7 +170,7 @@ else()\n endif()\n \n # nvToolsExt\n-if(USE_SYSTEM_NVTX)\n+if(@USE_SYSTEM_NVTX@)",
        "comment_created_at": "2025-03-24T22:10:52+00:00",
        "comment_author": "jeongseok-meta",
        "comment_body": "The key change is in this line. The `cuda.cmake.in` file is configured to generate `cuda.cmake`, modifying this line to either `if(TRUE)` or `if(FALSE)` based on the `USE_SYSTEM_NVTX` option set during the PyTorch build, and then the generated file `cuda.cmake` is installed for downstream.\r\n\r\nThis ensures that downstream users inherit the same configuration, as the value of `USE_SYSTEM_NVTX` is \"hard-coded\" into the generated `cuda.cmake` file.",
        "pr_file_module": null
      }
    ]
  }
]