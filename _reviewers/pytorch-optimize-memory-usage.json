[
  {
    "discussion_id": "2180862167",
    "pr_number": 157290,
    "pr_file": "torch/nativert/executor/memory/AliasAnalyzer.cpp",
    "created_at": "2025-07-02T19:54:08+00:00",
    "commented_code": "create_or_update_lifetime(output, i);\n     }\n \n-    if (update_aliases_if_packed_listunpack(node, i) /* applied? */) {\n+    if (update_aliases_if_packed_listunpack(aliases, node, i) /* applied? */) {\n       continue;\n     }\n \n-    maybe_update_aliases_from_schema(node, schemas);\n+    maybe_update_aliases_from_schema(aliases, node, schemas);\n   }\n \n+  maybe_extend_lifetimes(aliases, graph);\n+  // squash_deep_aliases this will populate aliases_\n+  // with a mapping from each alias to its backed\n+  // source (i.e., the value that owns the underlying\n+  // dataptr for said alias)\n+  squash_deep_aliases(std::move(aliases), graph);\n+\n   // set all non-aliasing outputs. outputs\n   // that are aliased will be set later when\n   // lifetimes are extended\n   for (const auto* output : graph.outputs()) {\n     if (!is_alias(output)) {\n-      values_associated_with_outputs_.insert(output);\n+      values_associated_with_outputs_.emplace(output);\n     }\n   }\n \n-  maybe_extend_lifetimes(graph);\n   log_state();\n+\n+  for (const auto& [v, lifetime] : lifetimes_) {\n+    for (const auto t : c10::irange(lifetime.start, lifetime.end + 1)) {\n+      alive_values_at_time_[t].emplace_back(v);",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2180862167",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157290,
        "pr_file": "torch/nativert/executor/memory/AliasAnalyzer.cpp",
        "discussion_id": "2180862167",
        "commented_code": "@@ -16,27 +19,40 @@ AliasAnalyzer::AliasAnalyzer(\n       create_or_update_lifetime(output, i);\n     }\n \n-    if (update_aliases_if_packed_listunpack(node, i) /* applied? */) {\n+    if (update_aliases_if_packed_listunpack(aliases, node, i) /* applied? */) {\n       continue;\n     }\n \n-    maybe_update_aliases_from_schema(node, schemas);\n+    maybe_update_aliases_from_schema(aliases, node, schemas);\n   }\n \n+  maybe_extend_lifetimes(aliases, graph);\n+  // squash_deep_aliases this will populate aliases_\n+  // with a mapping from each alias to its backed\n+  // source (i.e., the value that owns the underlying\n+  // dataptr for said alias)\n+  squash_deep_aliases(std::move(aliases), graph);\n+\n   // set all non-aliasing outputs. outputs\n   // that are aliased will be set later when\n   // lifetimes are extended\n   for (const auto* output : graph.outputs()) {\n     if (!is_alias(output)) {\n-      values_associated_with_outputs_.insert(output);\n+      values_associated_with_outputs_.emplace(output);\n     }\n   }\n \n-  maybe_extend_lifetimes(graph);\n   log_state();\n+\n+  for (const auto& [v, lifetime] : lifetimes_) {\n+    for (const auto t : c10::irange(lifetime.start, lifetime.end + 1)) {\n+      alive_values_at_time_[t].emplace_back(v);",
        "comment_created_at": "2025-07-02T19:54:08+00:00",
        "comment_author": "SherlockNoMad",
        "comment_body": "this object would be pretty big. \r\nshould I be worried about it's memory usage? \r\nalso, is this for debug only? ",
        "pr_file_module": null
      },
      {
        "comment_id": "2180864516",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157290,
        "pr_file": "torch/nativert/executor/memory/AliasAnalyzer.cpp",
        "discussion_id": "2180862167",
        "commented_code": "@@ -16,27 +19,40 @@ AliasAnalyzer::AliasAnalyzer(\n       create_or_update_lifetime(output, i);\n     }\n \n-    if (update_aliases_if_packed_listunpack(node, i) /* applied? */) {\n+    if (update_aliases_if_packed_listunpack(aliases, node, i) /* applied? */) {\n       continue;\n     }\n \n-    maybe_update_aliases_from_schema(node, schemas);\n+    maybe_update_aliases_from_schema(aliases, node, schemas);\n   }\n \n+  maybe_extend_lifetimes(aliases, graph);\n+  // squash_deep_aliases this will populate aliases_\n+  // with a mapping from each alias to its backed\n+  // source (i.e., the value that owns the underlying\n+  // dataptr for said alias)\n+  squash_deep_aliases(std::move(aliases), graph);\n+\n   // set all non-aliasing outputs. outputs\n   // that are aliased will be set later when\n   // lifetimes are extended\n   for (const auto* output : graph.outputs()) {\n     if (!is_alias(output)) {\n-      values_associated_with_outputs_.insert(output);\n+      values_associated_with_outputs_.emplace(output);\n     }\n   }\n \n-  maybe_extend_lifetimes(graph);\n   log_state();\n+\n+  for (const auto& [v, lifetime] : lifetimes_) {\n+    for (const auto t : c10::irange(lifetime.start, lifetime.end + 1)) {\n+      alive_values_at_time_[t].emplace_back(v);",
        "comment_created_at": "2025-07-02T19:55:46+00:00",
        "comment_author": "dolpm",
        "comment_body": "let me make this debug only - i agree this will be quite large. good catch.",
        "pr_file_module": null
      },
      {
        "comment_id": "2180893862",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157290,
        "pr_file": "torch/nativert/executor/memory/AliasAnalyzer.cpp",
        "discussion_id": "2180862167",
        "commented_code": "@@ -16,27 +19,40 @@ AliasAnalyzer::AliasAnalyzer(\n       create_or_update_lifetime(output, i);\n     }\n \n-    if (update_aliases_if_packed_listunpack(node, i) /* applied? */) {\n+    if (update_aliases_if_packed_listunpack(aliases, node, i) /* applied? */) {\n       continue;\n     }\n \n-    maybe_update_aliases_from_schema(node, schemas);\n+    maybe_update_aliases_from_schema(aliases, node, schemas);\n   }\n \n+  maybe_extend_lifetimes(aliases, graph);\n+  // squash_deep_aliases this will populate aliases_\n+  // with a mapping from each alias to its backed\n+  // source (i.e., the value that owns the underlying\n+  // dataptr for said alias)\n+  squash_deep_aliases(std::move(aliases), graph);\n+\n   // set all non-aliasing outputs. outputs\n   // that are aliased will be set later when\n   // lifetimes are extended\n   for (const auto* output : graph.outputs()) {\n     if (!is_alias(output)) {\n-      values_associated_with_outputs_.insert(output);\n+      values_associated_with_outputs_.emplace(output);\n     }\n   }\n \n-  maybe_extend_lifetimes(graph);\n   log_state();\n+\n+  for (const auto& [v, lifetime] : lifetimes_) {\n+    for (const auto t : c10::irange(lifetime.start, lifetime.end + 1)) {\n+      alive_values_at_time_[t].emplace_back(v);",
        "comment_created_at": "2025-07-02T20:12:59+00:00",
        "comment_author": "dolpm",
        "comment_body": "upon further reivew, we can do this with the entire alias analyzer... we can only store it in the planner when debug mode is enabled..",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1976031723",
    "pr_number": 147907,
    "pr_file": "torch/csrc/Generator.cpp",
    "created_at": "2025-02-28T21:32:28+00:00",
    "commented_code": "PyTuple_SET_ITEM(state.get(), 2, THPGenerator_getState(_self, nullptr));\n   PyTuple_SET_ITEM(ret.get(), 2, state.release());\n \n+  Py_INCREF(ret);",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "1976031723",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 147907,
        "pr_file": "torch/csrc/Generator.cpp",
        "discussion_id": "1976031723",
        "commented_code": "@@ -259,6 +259,7 @@ static PyObject* THPGenerator_reduce(PyObject* _self, PyObject* noargs) {\n   PyTuple_SET_ITEM(state.get(), 2, THPGenerator_getState(_self, nullptr));\n   PyTuple_SET_ITEM(ret.get(), 2, state.release());\n \n+  Py_INCREF(ret);",
        "comment_created_at": "2025-02-28T21:32:28+00:00",
        "comment_author": "albanD",
        "comment_body": "I would expect that:\r\n- PyTupleNew returns a new ref\r\n- THPObjectPtr steals that on construction\r\n- The .release() below give that single ref to the returned PyObject*\r\n\r\n?",
        "pr_file_module": null
      },
      {
        "comment_id": "1976112387",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 147907,
        "pr_file": "torch/csrc/Generator.cpp",
        "discussion_id": "1976031723",
        "commented_code": "@@ -259,6 +259,7 @@ static PyObject* THPGenerator_reduce(PyObject* _self, PyObject* noargs) {\n   PyTuple_SET_ITEM(state.get(), 2, THPGenerator_getState(_self, nullptr));\n   PyTuple_SET_ITEM(ret.get(), 2, state.release());\n \n+  Py_INCREF(ret);",
        "comment_created_at": "2025-02-28T23:23:57+00:00",
        "comment_author": "ringohoffman",
        "comment_body": "The [C++ implementation of `__reduce__` for device](https://github.com/pytorch/pytorch/blob/e74fdbe6d086d0b2f0ebfddd1a3bf4d19495a830/torch/csrc/Device.cpp#L151-L177) is similar and also does not do a `Py_INCREF` on the return tuple, so I think you are right that this is not necessary. One big difference though is that this tuple contains a tensor.\r\n\r\n2 lines up, if I change:\r\n\r\n```python\r\n  PyTuple_SET_ITEM(state.get(), 2, THPGenerator_getState(_self, nullptr));\r\n```\r\n\r\nto:\r\n\r\n```python\r\n  auto state_tensor = THPGenerator_getState(_self, nullptr);\r\n  Py_INCREF(state_tensor);\r\n  PyTuple_SET_ITEM(state.get(), 2, state_tensor);\r\n```\r\n\r\nIt also resolves the issue. So I am fairly certain that the reference counts on this specific tensor is the source of the issue.\r\n\r\nhttps://github.com/pytorch/pytorch/blob/1ae7cc41ca3c9a55faab7033e11a6115318cba8f/torch/csrc/Generator.cpp#L67-L78\r\n\r\nWe can see that the return of `THPGenerator_getState` is wrapped with `THPVariable_Wrap`, and as you told me [PyTuple_SET_ITEM](https://docs.python.org/3/c-api/tuple.html#c.PyTuple_SET_ITEM) should be stealing that reference. So is that a more proper solution--to increase the reference count on the state tensor before packing it into the tuple?",
        "pr_file_module": null
      },
      {
        "comment_id": "1976376158",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 147907,
        "pr_file": "torch/csrc/Generator.cpp",
        "discussion_id": "1976031723",
        "commented_code": "@@ -259,6 +259,7 @@ static PyObject* THPGenerator_reduce(PyObject* _self, PyObject* noargs) {\n   PyTuple_SET_ITEM(state.get(), 2, THPGenerator_getState(_self, nullptr));\n   PyTuple_SET_ITEM(ret.get(), 2, state.release());\n \n+  Py_INCREF(ret);",
        "comment_created_at": "2025-03-01T09:43:33+00:00",
        "comment_author": "ringohoffman",
        "comment_body": "In the case of `set_start_method(\"fork\")`, `__reduce__` and `__setstate__` are not actually called when spawning another process.\r\n\r\nWith the code in `main` now, without any `Py_INCREF`:\r\n\r\n```python\r\nimport torch\r\n\r\ngenerator = torch.Generator(\"cpu\").manual_seed(2059666523504992)\r\ntorch.save(generator, \"generator.pt\")\r\n```\r\n\r\nUsing `Py_REFCNT`, you can inspect the reference count of the state tensor to be 1 for the duration of `__reduce__`.\r\n\r\n```python\r\nimport torch\r\n\r\ngenerator = torch.load(\"generator.pt\", weights_only=False)\r\n```\r\n\r\nThe reference count of the state tensor is 2 for the duration of `__setstate__`.\r\n\r\n---\r\n\r\nWe know that when we use `\"forkeserver\"` or `\"spawn\"` start methods with the current code, we get the error `RuntimeError: unable to resize file <filename not specified> to the right size: Invalid argument (22)`. `__setstate__` does not even run in the other process.\r\n\r\nWhat we observe with this change:\r\n\r\n```c++\r\n  auto state_tensor = THPGenerator_getState(_self, nullptr);\r\n  Py_INCREF(state_tensor);\r\n  PyTuple_SET_ITEM(state.get(), 2, state_tensor);\r\n```\r\n\r\nIs that in `__reduce__`, the state tensor reference count increases from 1 to 2. You no longer get the error, and `__setstate__` is actually able to run in the other process. The reference count of `state_tensor` is 2 the entire time, exactly as in the case of `torch.load` without `Py_INCREF`. \r\n\r\nAdditionally, whether or not you `Py_INCREF` the state tensor, the reference count of the `state` 3-ple in `__setstate__` is also 2.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1857785641",
    "pr_number": 140979,
    "pr_file": "aten/src/ATen/cuda/CUDAGraph.cpp",
    "created_at": "2024-11-26T05:17:24+00:00",
    "commented_code": "namespace at::cuda {\n \n+namespace {\n+cudaStream_t create_external_stream() {\n+  // From:\n+  // https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g793d7d4e474388ddfda531603dc34aa3\n+  // \"Capture must be ended on the same stream in which it was initiated, and it\n+  // may only be initiated if the stream is not already in capture mode.\"\n+\n+  // Since pytorch uses a pool of 32 pre-allocated cuda streams,\n+  // should a user nest 32 conditional nodes, there would be an error\n+  // for the 32nd node, since that node's stream would already be in\n+  // capture mode. The easiest solution is to handle stream creation\n+  // and deletion ourselves.\n+\n+  // Be sure to call cudaStreamDestroy on this when it is finished",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "1857785641",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 140979,
        "pr_file": "aten/src/ATen/cuda/CUDAGraph.cpp",
        "discussion_id": "1857785641",
        "commented_code": "@@ -11,6 +11,27 @@\n \n namespace at::cuda {\n \n+namespace {\n+cudaStream_t create_external_stream() {\n+  // From:\n+  // https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g793d7d4e474388ddfda531603dc34aa3\n+  // \"Capture must be ended on the same stream in which it was initiated, and it\n+  // may only be initiated if the stream is not already in capture mode.\"\n+\n+  // Since pytorch uses a pool of 32 pre-allocated cuda streams,\n+  // should a user nest 32 conditional nodes, there would be an error\n+  // for the 32nd node, since that node's stream would already be in\n+  // capture mode. The easiest solution is to handle stream creation\n+  // and deletion ourselves.\n+\n+  // Be sure to call cudaStreamDestroy on this when it is finished",
        "comment_created_at": "2024-11-26T05:17:24+00:00",
        "comment_author": "eellison",
        "comment_body": "Where do we call `cudaStreamDestroy` ?  I don't see it.",
        "pr_file_module": null
      },
      {
        "comment_id": "1866611617",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 140979,
        "pr_file": "aten/src/ATen/cuda/CUDAGraph.cpp",
        "discussion_id": "1857785641",
        "commented_code": "@@ -11,6 +11,27 @@\n \n namespace at::cuda {\n \n+namespace {\n+cudaStream_t create_external_stream() {\n+  // From:\n+  // https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g793d7d4e474388ddfda531603dc34aa3\n+  // \"Capture must be ended on the same stream in which it was initiated, and it\n+  // may only be initiated if the stream is not already in capture mode.\"\n+\n+  // Since pytorch uses a pool of 32 pre-allocated cuda streams,\n+  // should a user nest 32 conditional nodes, there would be an error\n+  // for the 32nd node, since that node's stream would already be in\n+  // capture mode. The easiest solution is to handle stream creation\n+  // and deletion ourselves.\n+\n+  // Be sure to call cudaStreamDestroy on this when it is finished",
        "comment_created_at": "2024-12-02T21:01:56+00:00",
        "comment_author": "galv",
        "comment_body": "It is inside `end_capture_to_conditional_node`. https://github.com/pytorch/pytorch/pull/140979/files#diff-d7302d133bb5e0890fc94de9aeea4d9d442555a3b40772c9db10edb5cf36a35cR561\r\n\r\nAnother possibility is to make this return a unique_ptr<cudaStream_t> with a custom destructor. That would be a little bit awkward since the `std::stack<at::cuda::CUDAStreamGuard> conditional_node_streams_` would need an additional stack just containing these unique pointers (CUDAStreamGuard lacks a move constructor, so I'm not sure that having a std::pair of CUDAStreamGuard and a unique_ptr would work here).",
        "pr_file_module": null
      },
      {
        "comment_id": "1868641454",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 140979,
        "pr_file": "aten/src/ATen/cuda/CUDAGraph.cpp",
        "discussion_id": "1857785641",
        "commented_code": "@@ -11,6 +11,27 @@\n \n namespace at::cuda {\n \n+namespace {\n+cudaStream_t create_external_stream() {\n+  // From:\n+  // https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__STREAM.html#group__CUDART__STREAM_1g793d7d4e474388ddfda531603dc34aa3\n+  // \"Capture must be ended on the same stream in which it was initiated, and it\n+  // may only be initiated if the stream is not already in capture mode.\"\n+\n+  // Since pytorch uses a pool of 32 pre-allocated cuda streams,\n+  // should a user nest 32 conditional nodes, there would be an error\n+  // for the 32nd node, since that node's stream would already be in\n+  // capture mode. The easiest solution is to handle stream creation\n+  // and deletion ourselves.\n+\n+  // Be sure to call cudaStreamDestroy on this when it is finished",
        "comment_created_at": "2024-12-04T02:45:08+00:00",
        "comment_author": "galv",
        "comment_body": "So I did try your suggestion: https://github.com/pytorch/pytorch/pull/140979/commits/7cdced5139de61172aca2ba681cc67c54f0a7b39\r\n\r\nTo be honest, I think it makes things more opaque and confusing in this instance to use smart pointers. In particular, I almost accidentally depended upon the ordering of calculation of the arguments of a function here (std::move(child_stream) means that *child_stream might return NULL): https://github.com/pytorch/pytorch/pull/140979/commits/7cdced5139de61172aca2ba681cc67c54f0a7b39#diff-d7302d133bb5e0890fc94de9aeea4d9d442555a3b40772c9db10edb5cf36a35cR456-R462\r\n\r\nI'm thinking of reverting the change personally, but would be happy to keep it if you feel strongly about it.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2109841015",
    "pr_number": 153150,
    "pr_file": "torch/csrc/dynamo/guards.cpp",
    "created_at": "2025-05-27T18:06:14+00:00",
    "commented_code": "Py_ssize_t _index{-1};\n };\n \n+/**\n+ * Represents set[index] accessor by converting the set into a dictionary.\n+ */\n+class SetGetItemGuardAccessor : public GuardAccessor {\n+ public:\n+  SetGetItemGuardAccessor(\n+      RootGuardManager* root,\n+      const py::object& index,\n+      std::string source,\n+      py::handle example_value,\n+      py::handle guard_manager_enum)\n+      : GuardAccessor(\n+            root,\n+            index,\n+            std::move(source),\n+            example_value,\n+            guard_manager_enum),\n+        _index(py::cast<Py_ssize_t>(index)) {}\n+\n+  // NB: Intentional duplication between check_nopybind and\n+  // check_verbose_nopybind.\n+  bool check_nopybind(PyObject* obj, bool matches_dict_tag = false)\n+      override { // borrowed ref\n+    PyObject* PyDict = (PyObject*)&PyDict_Type;\n+    PyObject* dict =",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2109841015",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 153150,
        "pr_file": "torch/csrc/dynamo/guards.cpp",
        "discussion_id": "2109841015",
        "commented_code": "@@ -4117,6 +4141,85 @@ class ListGetItemGuardAccessor : public GuardAccessor {\n   Py_ssize_t _index{-1};\n };\n \n+/**\n+ * Represents set[index] accessor by converting the set into a dictionary.\n+ */\n+class SetGetItemGuardAccessor : public GuardAccessor {\n+ public:\n+  SetGetItemGuardAccessor(\n+      RootGuardManager* root,\n+      const py::object& index,\n+      std::string source,\n+      py::handle example_value,\n+      py::handle guard_manager_enum)\n+      : GuardAccessor(\n+            root,\n+            index,\n+            std::move(source),\n+            example_value,\n+            guard_manager_enum),\n+        _index(py::cast<Py_ssize_t>(index)) {}\n+\n+  // NB: Intentional duplication between check_nopybind and\n+  // check_verbose_nopybind.\n+  bool check_nopybind(PyObject* obj, bool matches_dict_tag = false)\n+      override { // borrowed ref\n+    PyObject* PyDict = (PyObject*)&PyDict_Type;\n+    PyObject* dict =",
        "comment_created_at": "2025-05-27T18:06:14+00:00",
        "comment_author": "williamwen42",
        "comment_body": "Borrowed/new references don't seem to be handled correctly here. Either use `py::object` to automatically delete or manually call `Py_[X]DECREF`.",
        "pr_file_module": null
      }
    ]
  }
]