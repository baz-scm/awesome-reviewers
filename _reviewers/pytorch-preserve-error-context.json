[
  {
    "discussion_id": "2110667766",
    "pr_number": 152023,
    "pr_file": "c10/cuda/CUDAException.cpp",
    "created_at": "2025-05-28T01:27:54+00:00",
    "commented_code": "\"Device-side assertions were explicitly omitted for this error check; the error probably arose while initializing the DSA handlers.\");\n  }\n#endif\n\n  TORCH_CHECK(false, check_message);\n  throw c10::DeviceError(err, check_message);",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2110667766",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 152023,
        "pr_file": "c10/cuda/CUDAException.cpp",
        "discussion_id": "2110667766",
        "commented_code": "@@ -38,8 +38,7 @@ void c10_cuda_check_implementation(\n         \"Device-side assertions were explicitly omitted for this error check; the error probably arose while initializing the DSA handlers.\");\n   }\n #endif\n-\n-  TORCH_CHECK(false, check_message);\n+  throw c10::DeviceError(err, check_message);",
        "comment_created_at": "2025-05-28T01:27:54+00:00",
        "comment_author": "ngimel",
        "comment_body": "TORCH_CHECK also provides information about the callsite that this will lose? https://github.com/pytorch/pytorch/blob/e9e1aacef8913bc3baabe502e2858b776e6aea3f/c10/util/Exception.cpp#L109",
        "pr_file_module": null
      },
      {
        "comment_id": "2110685549",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 152023,
        "pr_file": "c10/cuda/CUDAException.cpp",
        "discussion_id": "2110667766",
        "commented_code": "@@ -38,8 +38,7 @@ void c10_cuda_check_implementation(\n         \"Device-side assertions were explicitly omitted for this error check; the error probably arose while initializing the DSA handlers.\");\n   }\n #endif\n-\n-  TORCH_CHECK(false, check_message);\n+  throw c10::DeviceError(err, check_message);",
        "comment_created_at": "2025-05-28T01:41:55+00:00",
        "comment_author": "ngimel",
        "comment_body": "TORCH_CHECK_WITH(DeviceError, false, message)",
        "pr_file_module": null
      },
      {
        "comment_id": "2110945768",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 152023,
        "pr_file": "c10/cuda/CUDAException.cpp",
        "discussion_id": "2110667766",
        "commented_code": "@@ -38,8 +38,7 @@ void c10_cuda_check_implementation(\n         \"Device-side assertions were explicitly omitted for this error check; the error probably arose while initializing the DSA handlers.\");\n   }\n #endif\n-\n-  TORCH_CHECK(false, check_message);\n+  throw c10::DeviceError(err, check_message);",
        "comment_created_at": "2025-05-28T05:24:01+00:00",
        "comment_author": "mradmila",
        "comment_body": "Actually, wouldn't that leave \"err\" behind? We want all of it, no?",
        "pr_file_module": null
      },
      {
        "comment_id": "2110961413",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 152023,
        "pr_file": "c10/cuda/CUDAException.cpp",
        "discussion_id": "2110667766",
        "commented_code": "@@ -38,8 +38,7 @@ void c10_cuda_check_implementation(\n         \"Device-side assertions were explicitly omitted for this error check; the error probably arose while initializing the DSA handlers.\");\n   }\n #endif\n-\n-  TORCH_CHECK(false, check_message);\n+  throw c10::DeviceError(err, check_message);",
        "comment_created_at": "2025-05-28T05:36:26+00:00",
        "comment_author": "mradmila",
        "comment_body": "Also, I hope we don't strip error messages on the use side?",
        "pr_file_module": null
      },
      {
        "comment_id": "2111059460",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 152023,
        "pr_file": "c10/cuda/CUDAException.cpp",
        "discussion_id": "2110667766",
        "commented_code": "@@ -38,8 +38,7 @@ void c10_cuda_check_implementation(\n         \"Device-side assertions were explicitly omitted for this error check; the error probably arose while initializing the DSA handlers.\");\n   }\n #endif\n-\n-  TORCH_CHECK(false, check_message);\n+  throw c10::DeviceError(err, check_message);",
        "comment_created_at": "2025-05-28T06:45:02+00:00",
        "comment_author": "malfet",
        "comment_body": "@ngimel TORCH_CHECK will not preserve the exist code. And callsite was already stripped in the existing code (it was passed as arguments to that function, but ignored) I can add it back as prerequisite/followup PR",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2089785335",
    "pr_number": 150218,
    "pr_file": "torch/csrc/Module.cpp",
    "created_at": "2025-05-14T21:31:27+00:00",
    "commented_code": "END_HANDLE_TH_ERRORS\n}\n\nstatic PyObject* THPModule_torchDeviceToDLDevice(\n    PyObject* _unused,\n    PyObject* data) {\n  HANDLE_TH_ERRORS\n  TORCH_CHECK(\n      THPDevice_Check(data),\n      \"torchDeviceToDLDevice: expected torch.device argument.\");\n  auto device = reinterpret_cast<THPDevice*>(data)->device;\n  auto dl_device = at::torchDeviceToDLDevice(device);\n  auto tuple = PyTuple_New(2);",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2089785335",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 150218,
        "pr_file": "torch/csrc/Module.cpp",
        "discussion_id": "2089785335",
        "commented_code": "@@ -636,6 +668,22 @@ static PyObject* THPModule_fromDLPack(PyObject* _unused, PyObject* data) {\n   END_HANDLE_TH_ERRORS\n }\n \n+static PyObject* THPModule_torchDeviceToDLDevice(\n+    PyObject* _unused,\n+    PyObject* data) {\n+  HANDLE_TH_ERRORS\n+  TORCH_CHECK(\n+      THPDevice_Check(data),\n+      \"torchDeviceToDLDevice: expected torch.device argument.\");\n+  auto device = reinterpret_cast<THPDevice*>(data)->device;\n+  auto dl_device = at::torchDeviceToDLDevice(device);\n+  auto tuple = PyTuple_New(2);",
        "comment_created_at": "2025-05-14T21:31:27+00:00",
        "comment_author": "albanD",
        "comment_body": "Add error checking in case this failed",
        "pr_file_module": null
      },
      {
        "comment_id": "2105840117",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 150218,
        "pr_file": "torch/csrc/Module.cpp",
        "discussion_id": "2089785335",
        "commented_code": "@@ -636,6 +668,22 @@ static PyObject* THPModule_fromDLPack(PyObject* _unused, PyObject* data) {\n   END_HANDLE_TH_ERRORS\n }\n \n+static PyObject* THPModule_torchDeviceToDLDevice(\n+    PyObject* _unused,\n+    PyObject* data) {\n+  HANDLE_TH_ERRORS\n+  TORCH_CHECK(\n+      THPDevice_Check(data),\n+      \"torchDeviceToDLDevice: expected torch.device argument.\");\n+  auto device = reinterpret_cast<THPDevice*>(data)->device;\n+  auto dl_device = at::torchDeviceToDLDevice(device);\n+  auto tuple = PyTuple_New(2);",
        "comment_created_at": "2025-05-24T14:28:55+00:00",
        "comment_author": "ysiraichi",
        "comment_body": "Not sure I get what you mean. If `at::torchDeviceToDLDevice` errors, the error will bubble up to Python, won't it?",
        "pr_file_module": null
      },
      {
        "comment_id": "2150360414",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 150218,
        "pr_file": "torch/csrc/Module.cpp",
        "discussion_id": "2089785335",
        "commented_code": "@@ -636,6 +668,22 @@ static PyObject* THPModule_fromDLPack(PyObject* _unused, PyObject* data) {\n   END_HANDLE_TH_ERRORS\n }\n \n+static PyObject* THPModule_torchDeviceToDLDevice(\n+    PyObject* _unused,\n+    PyObject* data) {\n+  HANDLE_TH_ERRORS\n+  TORCH_CHECK(\n+      THPDevice_Check(data),\n+      \"torchDeviceToDLDevice: expected torch.device argument.\");\n+  auto device = reinterpret_cast<THPDevice*>(data)->device;\n+  auto dl_device = at::torchDeviceToDLDevice(device);\n+  auto tuple = PyTuple_New(2);",
        "comment_created_at": "2025-06-16T16:00:19+00:00",
        "comment_author": "albanD",
        "comment_body": "CPython is C API, not C++. There is no error throwing here, you need to check the tuple is not null and if so, make this a c++ error\r\n\r\n```cpp\r\nif (!tuple) {\r\n  throw python_error();\r\n}\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2089799016",
    "pr_number": 150218,
    "pr_file": "torch/csrc/Module.cpp",
    "created_at": "2025-05-14T21:44:38+00:00",
    "commented_code": "}\n\ntemplate <class T>\nPyObject* THPModule_toDLPackImpl(PyObject* _unused, PyObject* data) {\nPyObject* THPModule_toDLPackImpl(\n    PyObject* self,\n    PyObject* args,\n    PyObject* kwargs) {\n  HANDLE_TH_ERRORS\n  TORCH_CHECK(THPVariable_Check(data), \"data must be a Tensor\");\n  auto tensor = at::DLPackTraits<T>::toDLPack(THPVariable_Unpack(data));\n  return PyCapsule_New(\n      tensor, at::DLPackTraits<T>::capsule, DLPack_Capsule_Destructor<T>);\n  static torch::PythonArgParser parser(\n      {\"_to_dlpack(Tensor data, *, IntArrayRef? dl_device=None, bool? copy=None)\"});\n  torch::ParsedArgs<3> parsed_args{};\n  auto r = parser.parse(args, kwargs, parsed_args);\n\n  if (r.idx == 0) {\n    auto data = r.tensor(0);\n    auto dl_device = r.intlist(1);\n    auto copy = r.toBoolOptional(2);\n\n    // Parse the int list into a tuple.\n    std::optional<DLDevice> optional_dl_device;\n\n    if (!dl_device.empty()) {\n      TORCH_CHECK(\n          dl_device.size() == 2,\n          \"dl_device must be either None or a tuple of ints\");\n      optional_dl_device = DLDevice{\n          static_cast<DLDeviceType>(dl_device[0]),\n          static_cast<int32_t>(dl_device[1])};\n    }\n\n    auto tensor = at::DLPackTraits<T>::toDLPack(\n        at::maybeCopyTensor(data, optional_dl_device, copy));\n    return PyCapsule_New(\n        tensor, at::DLPackTraits<T>::capsule, DLPack_Capsule_Destructor<T>);\n  }\n\n  return nullptr;",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2089799016",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 150218,
        "pr_file": "torch/csrc/Module.cpp",
        "discussion_id": "2089799016",
        "commented_code": "@@ -607,25 +607,57 @@ void DLPack_Capsule_Destructor(PyObject* data) {\n }\n \n template <class T>\n-PyObject* THPModule_toDLPackImpl(PyObject* _unused, PyObject* data) {\n+PyObject* THPModule_toDLPackImpl(\n+    PyObject* self,\n+    PyObject* args,\n+    PyObject* kwargs) {\n   HANDLE_TH_ERRORS\n-  TORCH_CHECK(THPVariable_Check(data), \"data must be a Tensor\");\n-  auto tensor = at::DLPackTraits<T>::toDLPack(THPVariable_Unpack(data));\n-  return PyCapsule_New(\n-      tensor, at::DLPackTraits<T>::capsule, DLPack_Capsule_Destructor<T>);\n+  static torch::PythonArgParser parser(\n+      {\"_to_dlpack(Tensor data, *, IntArrayRef? dl_device=None, bool? copy=None)\"});\n+  torch::ParsedArgs<3> parsed_args{};\n+  auto r = parser.parse(args, kwargs, parsed_args);\n+\n+  if (r.idx == 0) {\n+    auto data = r.tensor(0);\n+    auto dl_device = r.intlist(1);\n+    auto copy = r.toBoolOptional(2);\n+\n+    // Parse the int list into a tuple.\n+    std::optional<DLDevice> optional_dl_device;\n+\n+    if (!dl_device.empty()) {\n+      TORCH_CHECK(\n+          dl_device.size() == 2,\n+          \"dl_device must be either None or a tuple of ints\");\n+      optional_dl_device = DLDevice{\n+          static_cast<DLDeviceType>(dl_device[0]),\n+          static_cast<int32_t>(dl_device[1])};\n+    }\n+\n+    auto tensor = at::DLPackTraits<T>::toDLPack(\n+        at::maybeCopyTensor(data, optional_dl_device, copy));\n+    return PyCapsule_New(\n+        tensor, at::DLPackTraits<T>::capsule, DLPack_Capsule_Destructor<T>);\n+  }\n+\n+  return nullptr;",
        "comment_created_at": "2025-05-14T21:44:38+00:00",
        "comment_author": "albanD",
        "comment_body": "I'm don't recall, will this have the right python err set?",
        "pr_file_module": null
      },
      {
        "comment_id": "2105839664",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 150218,
        "pr_file": "torch/csrc/Module.cpp",
        "discussion_id": "2089799016",
        "commented_code": "@@ -607,25 +607,57 @@ void DLPack_Capsule_Destructor(PyObject* data) {\n }\n \n template <class T>\n-PyObject* THPModule_toDLPackImpl(PyObject* _unused, PyObject* data) {\n+PyObject* THPModule_toDLPackImpl(\n+    PyObject* self,\n+    PyObject* args,\n+    PyObject* kwargs) {\n   HANDLE_TH_ERRORS\n-  TORCH_CHECK(THPVariable_Check(data), \"data must be a Tensor\");\n-  auto tensor = at::DLPackTraits<T>::toDLPack(THPVariable_Unpack(data));\n-  return PyCapsule_New(\n-      tensor, at::DLPackTraits<T>::capsule, DLPack_Capsule_Destructor<T>);\n+  static torch::PythonArgParser parser(\n+      {\"_to_dlpack(Tensor data, *, IntArrayRef? dl_device=None, bool? copy=None)\"});\n+  torch::ParsedArgs<3> parsed_args{};\n+  auto r = parser.parse(args, kwargs, parsed_args);\n+\n+  if (r.idx == 0) {\n+    auto data = r.tensor(0);\n+    auto dl_device = r.intlist(1);\n+    auto copy = r.toBoolOptional(2);\n+\n+    // Parse the int list into a tuple.\n+    std::optional<DLDevice> optional_dl_device;\n+\n+    if (!dl_device.empty()) {\n+      TORCH_CHECK(\n+          dl_device.size() == 2,\n+          \"dl_device must be either None or a tuple of ints\");\n+      optional_dl_device = DLDevice{\n+          static_cast<DLDeviceType>(dl_device[0]),\n+          static_cast<int32_t>(dl_device[1])};\n+    }\n+\n+    auto tensor = at::DLPackTraits<T>::toDLPack(\n+        at::maybeCopyTensor(data, optional_dl_device, copy));\n+    return PyCapsule_New(\n+        tensor, at::DLPackTraits<T>::capsule, DLPack_Capsule_Destructor<T>);\n+  }\n+\n+  return nullptr;",
        "comment_created_at": "2025-05-24T14:26:49+00:00",
        "comment_author": "ysiraichi",
        "comment_body": "I think so. At least, it will throw an error inside the parser. I will replace it with `Py_RETURN_NONE`, just for consistency.",
        "pr_file_module": null
      },
      {
        "comment_id": "2147035848",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 150218,
        "pr_file": "torch/csrc/Module.cpp",
        "discussion_id": "2089799016",
        "commented_code": "@@ -607,25 +607,57 @@ void DLPack_Capsule_Destructor(PyObject* data) {\n }\n \n template <class T>\n-PyObject* THPModule_toDLPackImpl(PyObject* _unused, PyObject* data) {\n+PyObject* THPModule_toDLPackImpl(\n+    PyObject* self,\n+    PyObject* args,\n+    PyObject* kwargs) {\n   HANDLE_TH_ERRORS\n-  TORCH_CHECK(THPVariable_Check(data), \"data must be a Tensor\");\n-  auto tensor = at::DLPackTraits<T>::toDLPack(THPVariable_Unpack(data));\n-  return PyCapsule_New(\n-      tensor, at::DLPackTraits<T>::capsule, DLPack_Capsule_Destructor<T>);\n+  static torch::PythonArgParser parser(\n+      {\"_to_dlpack(Tensor data, *, IntArrayRef? dl_device=None, bool? copy=None)\"});\n+  torch::ParsedArgs<3> parsed_args{};\n+  auto r = parser.parse(args, kwargs, parsed_args);\n+\n+  if (r.idx == 0) {\n+    auto data = r.tensor(0);\n+    auto dl_device = r.intlist(1);\n+    auto copy = r.toBoolOptional(2);\n+\n+    // Parse the int list into a tuple.\n+    std::optional<DLDevice> optional_dl_device;\n+\n+    if (!dl_device.empty()) {\n+      TORCH_CHECK(\n+          dl_device.size() == 2,\n+          \"dl_device must be either None or a tuple of ints\");\n+      optional_dl_device = DLDevice{\n+          static_cast<DLDeviceType>(dl_device[0]),\n+          static_cast<int32_t>(dl_device[1])};\n+    }\n+\n+    auto tensor = at::DLPackTraits<T>::toDLPack(\n+        at::maybeCopyTensor(data, optional_dl_device, copy));\n+    return PyCapsule_New(\n+        tensor, at::DLPackTraits<T>::capsule, DLPack_Capsule_Destructor<T>);\n+  }\n+\n+  return nullptr;",
        "comment_created_at": "2025-06-14T17:36:14+00:00",
        "comment_author": "ysiraichi",
        "comment_body": "I think I hadn't understood you question earlier. If you are asking whether a C++ exception will be mapped the correct Python error set, the answer is: yes! `END_HANDLE_TH_ERRORS` will take care of that. Specifically, `torch::translate_exception_to_python(std::current_exception())` call will do the job.",
        "pr_file_module": null
      },
      {
        "comment_id": "2150371678",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 150218,
        "pr_file": "torch/csrc/Module.cpp",
        "discussion_id": "2089799016",
        "commented_code": "@@ -607,25 +607,57 @@ void DLPack_Capsule_Destructor(PyObject* data) {\n }\n \n template <class T>\n-PyObject* THPModule_toDLPackImpl(PyObject* _unused, PyObject* data) {\n+PyObject* THPModule_toDLPackImpl(\n+    PyObject* self,\n+    PyObject* args,\n+    PyObject* kwargs) {\n   HANDLE_TH_ERRORS\n-  TORCH_CHECK(THPVariable_Check(data), \"data must be a Tensor\");\n-  auto tensor = at::DLPackTraits<T>::toDLPack(THPVariable_Unpack(data));\n-  return PyCapsule_New(\n-      tensor, at::DLPackTraits<T>::capsule, DLPack_Capsule_Destructor<T>);\n+  static torch::PythonArgParser parser(\n+      {\"_to_dlpack(Tensor data, *, IntArrayRef? dl_device=None, bool? copy=None)\"});\n+  torch::ParsedArgs<3> parsed_args{};\n+  auto r = parser.parse(args, kwargs, parsed_args);\n+\n+  if (r.idx == 0) {\n+    auto data = r.tensor(0);\n+    auto dl_device = r.intlist(1);\n+    auto copy = r.toBoolOptional(2);\n+\n+    // Parse the int list into a tuple.\n+    std::optional<DLDevice> optional_dl_device;\n+\n+    if (!dl_device.empty()) {\n+      TORCH_CHECK(\n+          dl_device.size() == 2,\n+          \"dl_device must be either None or a tuple of ints\");\n+      optional_dl_device = DLDevice{\n+          static_cast<DLDeviceType>(dl_device[0]),\n+          static_cast<int32_t>(dl_device[1])};\n+    }\n+\n+    auto tensor = at::DLPackTraits<T>::toDLPack(\n+        at::maybeCopyTensor(data, optional_dl_device, copy));\n+    return PyCapsule_New(\n+        tensor, at::DLPackTraits<T>::capsule, DLPack_Capsule_Destructor<T>);\n+  }\n+\n+  return nullptr;",
        "comment_created_at": "2025-06-16T16:06:38+00:00",
        "comment_author": "albanD",
        "comment_body": "Returning None here is completely different. These are in no way interchangeable.\r\nReturning `nullptr` from these APIs mean that something went wrong and the caller should check the globally set error for more info. Returning None means that all went well and the result is \"None\".\r\nYou either want one or the other :D \r\nOr maybe you're saying this is dead code?",
        "pr_file_module": null
      },
      {
        "comment_id": "2158931025",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 150218,
        "pr_file": "torch/csrc/Module.cpp",
        "discussion_id": "2089799016",
        "commented_code": "@@ -607,25 +607,57 @@ void DLPack_Capsule_Destructor(PyObject* data) {\n }\n \n template <class T>\n-PyObject* THPModule_toDLPackImpl(PyObject* _unused, PyObject* data) {\n+PyObject* THPModule_toDLPackImpl(\n+    PyObject* self,\n+    PyObject* args,\n+    PyObject* kwargs) {\n   HANDLE_TH_ERRORS\n-  TORCH_CHECK(THPVariable_Check(data), \"data must be a Tensor\");\n-  auto tensor = at::DLPackTraits<T>::toDLPack(THPVariable_Unpack(data));\n-  return PyCapsule_New(\n-      tensor, at::DLPackTraits<T>::capsule, DLPack_Capsule_Destructor<T>);\n+  static torch::PythonArgParser parser(\n+      {\"_to_dlpack(Tensor data, *, IntArrayRef? dl_device=None, bool? copy=None)\"});\n+  torch::ParsedArgs<3> parsed_args{};\n+  auto r = parser.parse(args, kwargs, parsed_args);\n+\n+  if (r.idx == 0) {\n+    auto data = r.tensor(0);\n+    auto dl_device = r.intlist(1);\n+    auto copy = r.toBoolOptional(2);\n+\n+    // Parse the int list into a tuple.\n+    std::optional<DLDevice> optional_dl_device;\n+\n+    if (!dl_device.empty()) {\n+      TORCH_CHECK(\n+          dl_device.size() == 2,\n+          \"dl_device must be either None or a tuple of ints\");\n+      optional_dl_device = DLDevice{\n+          static_cast<DLDeviceType>(dl_device[0]),\n+          static_cast<int32_t>(dl_device[1])};\n+    }\n+\n+    auto tensor = at::DLPackTraits<T>::toDLPack(\n+        at::maybeCopyTensor(data, optional_dl_device, copy));\n+    return PyCapsule_New(\n+        tensor, at::DLPackTraits<T>::capsule, DLPack_Capsule_Destructor<T>);\n+  }\n+\n+  return nullptr;",
        "comment_created_at": "2025-06-20T13:08:36+00:00",
        "comment_author": "ysiraichi",
        "comment_body": "This is essentially deadcode.\r\nOn second thoughts, it would be better to just `TORCH_INTERNAL_ASSERT(r.idx == 0);`. Then, there would be no need to return None, since the bug would be in the arg parser.",
        "pr_file_module": null
      }
    ]
  }
]