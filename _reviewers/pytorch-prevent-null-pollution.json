[
  {
    "discussion_id": "2190205697",
    "pr_number": 157682,
    "pr_file": "torch/distributed/tensor/_ops/_pointwise_ops.py",
    "created_at": "2025-07-07T13:59:35+00:00",
    "commented_code": "raise RuntimeError(\n                         f\"list op only supports tuple strategy! {op_schema}\"\n                     )\n+            else:\n+                # insert None as placeholder so that the idx of arg is kept\n+                tuple_strategies.append(None)\n         return tuple_strategies\n \n     args_strategies = args_tuple_strategies(op_schema.args_schema)\n-    follow_strategy: TupleStrategy = args_strategies[0]\n+    follow_strategy: TupleStrategy = cast(TupleStrategy, args_strategies[0])",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2190205697",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157682,
        "pr_file": "torch/distributed/tensor/_ops/_pointwise_ops.py",
        "discussion_id": "2190205697",
        "commented_code": "@@ -699,19 +722,28 @@ def args_tuple_strategies(args_schema: tuple[object, ...]) -> list[TupleStrategy\n                     raise RuntimeError(\n                         f\"list op only supports tuple strategy! {op_schema}\"\n                     )\n+            else:\n+                # insert None as placeholder so that the idx of arg is kept\n+                tuple_strategies.append(None)\n         return tuple_strategies\n \n     args_strategies = args_tuple_strategies(op_schema.args_schema)\n-    follow_strategy: TupleStrategy = args_strategies[0]\n+    follow_strategy: TupleStrategy = cast(TupleStrategy, args_strategies[0])",
        "comment_created_at": "2025-07-07T13:59:35+00:00",
        "comment_author": "Skylion007",
        "comment_body": "Do we know the first value is always not_none? We do allow Optional strategies now. Eitehr should be ```\r\n```suggestion\r\n    follow_strategy: Optional[TupleStrategy] = args_strategies[0]\r\n```\r\n\r\nor use the not_none utility to assert not_none from typing_utils\r\n\r\n```suggestion\r\n    follow_strategy: TupleStrategy = not_none(args_strategies[0])\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2191398257",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157682,
        "pr_file": "torch/distributed/tensor/_ops/_pointwise_ops.py",
        "discussion_id": "2190205697",
        "commented_code": "@@ -699,19 +722,28 @@ def args_tuple_strategies(args_schema: tuple[object, ...]) -> list[TupleStrategy\n                     raise RuntimeError(\n                         f\"list op only supports tuple strategy! {op_schema}\"\n                     )\n+            else:\n+                # insert None as placeholder so that the idx of arg is kept\n+                tuple_strategies.append(None)\n         return tuple_strategies\n \n     args_strategies = args_tuple_strategies(op_schema.args_schema)\n-    follow_strategy: TupleStrategy = args_strategies[0]\n+    follow_strategy: TupleStrategy = cast(TupleStrategy, args_strategies[0])",
        "comment_created_at": "2025-07-08T03:27:33+00:00",
        "comment_author": "tianyu-l",
        "comment_body": "good to know!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2186219872",
    "pr_number": 157614,
    "pr_file": "torch/_inductor/compile_fx_async.py",
    "created_at": "2025-07-04T23:46:59+00:00",
    "commented_code": ") -> None:\n         self._fast_output_code = fast_output_code\n         self._optimized_output_code = None\n-        self._progression_futures = list(progression_futures)\n+        self._progression_futures = deque(progression_futures)",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2186219872",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157614,
        "pr_file": "torch/_inductor/compile_fx_async.py",
        "discussion_id": "2186219872",
        "commented_code": "@@ -211,9 +211,8 @@ def __init__(\n     ) -> None:\n         self._fast_output_code = fast_output_code\n         self._optimized_output_code = None\n-        self._progression_futures = list(progression_futures)\n+        self._progression_futures = deque(progression_futures)",
        "comment_created_at": "2025-07-04T23:46:59+00:00",
        "comment_author": "aorenste",
        "comment_body": "nit: Above (github won't let me comment on unchanged lines):\r\n```\r\n    progression_futures: Sequence[Future[_WireProtocolPickledOutput]],\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2186262027",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157614,
        "pr_file": "torch/_inductor/compile_fx_async.py",
        "discussion_id": "2186219872",
        "commented_code": "@@ -211,9 +211,8 @@ def __init__(\n     ) -> None:\n         self._fast_output_code = fast_output_code\n         self._optimized_output_code = None\n-        self._progression_futures = list(progression_futures)\n+        self._progression_futures = deque(progression_futures)",
        "comment_created_at": "2025-07-05T00:42:17+00:00",
        "comment_author": "bobrenjc93",
        "comment_body": "Problem is then mypy complains about no popleft\r\n\r\n```\r\n  Error (MYPY) [attr-defined]\r\n    \"Sequence[Future[_WireProtocolPickledOutput]]\" has no attribute \"popleft\"\r\n\r\n        268  |\r\n        269  |        # Clear earlier progression futures to free memory\r\n        270  |        for _ in range(stage_index + 1):\r\n    >>> 271  |            self._progression_futures.popleft()\r\n        272  |\r\n        273  |    @override\r\n        274  |    def post_compile(\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2186283591",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157614,
        "pr_file": "torch/_inductor/compile_fx_async.py",
        "discussion_id": "2186219872",
        "commented_code": "@@ -211,9 +211,8 @@ def __init__(\n     ) -> None:\n         self._fast_output_code = fast_output_code\n         self._optimized_output_code = None\n-        self._progression_futures = list(progression_futures)\n+        self._progression_futures = deque(progression_futures)",
        "comment_created_at": "2025-07-05T00:57:53+00:00",
        "comment_author": "aorenste",
        "comment_body": "I think you misunderstood. I meant the __init__ signature should take Sequence. The instance member should still be deque. (I can see that what I wrote wasn't clear)",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2089801840",
    "pr_number": 150218,
    "pr_file": "torch/utils/dlpack.py",
    "created_at": "2025-05-14T21:47:08+00:00",
    "commented_code": "# Try running __dlpack__ while specifying `max_version` argument.\n             dlpack = ext_tensor.__dlpack__(**kwargs)\n         except TypeError:\n-            # If that doesn't work, try removing the `max_version` argument.\n+            # If that doesn't work, try removing the all the arguments but those\n+            # corresponding to DLPack 2022.12 specification.\n             kwargs.pop(\"max_version\")\n+            kwargs.pop(\"dl_device\")\n+            kwargs.pop(\"copy\")",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2089801840",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 150218,
        "pr_file": "torch/utils/dlpack.py",
        "discussion_id": "2089801840",
        "commented_code": "@@ -129,11 +144,18 @@ def from_dlpack(ext_tensor: Any) -> 'torch.Tensor':\n             # Try running __dlpack__ while specifying `max_version` argument.\n             dlpack = ext_tensor.__dlpack__(**kwargs)\n         except TypeError:\n-            # If that doesn't work, try removing the `max_version` argument.\n+            # If that doesn't work, try removing the all the arguments but those\n+            # corresponding to DLPack 2022.12 specification.\n             kwargs.pop(\"max_version\")\n+            kwargs.pop(\"dl_device\")\n+            kwargs.pop(\"copy\")",
        "comment_created_at": "2025-05-14T21:47:08+00:00",
        "comment_author": "albanD",
        "comment_body": "Is it actually ok to ignore these arguments?!",
        "pr_file_module": null
      },
      {
        "comment_id": "2105842387",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 150218,
        "pr_file": "torch/utils/dlpack.py",
        "discussion_id": "2089801840",
        "commented_code": "@@ -129,11 +144,18 @@ def from_dlpack(ext_tensor: Any) -> 'torch.Tensor':\n             # Try running __dlpack__ while specifying `max_version` argument.\n             dlpack = ext_tensor.__dlpack__(**kwargs)\n         except TypeError:\n-            # If that doesn't work, try removing the `max_version` argument.\n+            # If that doesn't work, try removing the all the arguments but those\n+            # corresponding to DLPack 2022.12 specification.\n             kwargs.pop(\"max_version\")\n+            kwargs.pop(\"dl_device\")\n+            kwargs.pop(\"copy\")",
        "comment_created_at": "2025-05-24T14:40:44+00:00",
        "comment_author": "ysiraichi",
        "comment_body": "Ah, good catch. I will refactor this code so that we only add to `kwargs` if they are actually different than None.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2167325698",
    "pr_number": 156016,
    "pr_file": "torch/profiler/_utils.py",
    "created_at": "2025-06-25T18:13:38+00:00",
    "commented_code": "cuda_event_list = self.profile.kineto_results.events()\n \n         def is_cuda_launch_kernel(e):\n-            # TODO: find a better way to identify cudaLaunchKernel\n-            return e.name == \"cudaLaunchKernel\"\n+            \"\"\"Check if the event is a CUDA launch kernel.\"\"\"\n+            launch_patterns = {\n+                \"cudaLaunchKernel\",  # Standard CUDA\n+                \"cudaLaunchKernelExC\",  # Extended C\n+                \"__cudaLaunchKernel\",  # Internal\n+                \"cudaLaunchCooperativeKernel\",  # Collaborative (single-device)\n+                \"cudaLaunchCooperativeKernelMultiDevice\",  # Collaborative (multi-devices)\n+            }\n+            name = str(e.name) if hasattr(e, 'name') else str(e)",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2167325698",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156016,
        "pr_file": "torch/profiler/_utils.py",
        "discussion_id": "2167325698",
        "commented_code": "@@ -142,8 +142,16 @@ def compute_queue_depth(self):\n         cuda_event_list = self.profile.kineto_results.events()\n \n         def is_cuda_launch_kernel(e):\n-            # TODO: find a better way to identify cudaLaunchKernel\n-            return e.name == \"cudaLaunchKernel\"\n+            \"\"\"Check if the event is a CUDA launch kernel.\"\"\"\n+            launch_patterns = {\n+                \"cudaLaunchKernel\",  # Standard CUDA\n+                \"cudaLaunchKernelExC\",  # Extended C\n+                \"__cudaLaunchKernel\",  # Internal\n+                \"cudaLaunchCooperativeKernel\",  # Collaborative (single-device)\n+                \"cudaLaunchCooperativeKernelMultiDevice\",  # Collaborative (multi-devices)\n+            }\n+            name = str(e.name) if hasattr(e, 'name') else str(e)",
        "comment_created_at": "2025-06-25T18:13:38+00:00",
        "comment_author": "albanD",
        "comment_body": "```suggestion\r\n            name = str(getattr(e, \"name\", e))\r\n```\r\nnit",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2181055200",
    "pr_number": 157424,
    "pr_file": "torch/_inductor/compile_fx_async.py",
    "created_at": "2025-07-02T22:05:54+00:00",
    "commented_code": ") -> None:\n         self._fast_output_code = fast_output_code\n         self._optimized_output_code = None\n-        self._progression_futures = progression_futures\n+        self._progression_futures = list(progression_futures)",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2181055200",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157424,
        "pr_file": "torch/_inductor/compile_fx_async.py",
        "discussion_id": "2181055200",
        "commented_code": "@@ -204,9 +206,8 @@ def __init__(\n     ) -> None:\n         self._fast_output_code = fast_output_code\n         self._optimized_output_code = None\n-        self._progression_futures = progression_futures\n+        self._progression_futures = list(progression_futures)",
        "comment_created_at": "2025-07-02T22:05:54+00:00",
        "comment_author": "bobrenjc93",
        "comment_body": "I really wish this weren’t necessary, but mypy is right to complain since we’re mutating the list by inserting Nones, which means anyone holding a reference to it now sees a List[Optional[...]], potentially violating their expectations.",
        "pr_file_module": null
      },
      {
        "comment_id": "2181275766",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157424,
        "pr_file": "torch/_inductor/compile_fx_async.py",
        "discussion_id": "2181055200",
        "commented_code": "@@ -204,9 +206,8 @@ def __init__(\n     ) -> None:\n         self._fast_output_code = fast_output_code\n         self._optimized_output_code = None\n-        self._progression_futures = progression_futures\n+        self._progression_futures = list(progression_futures)",
        "comment_created_at": "2025-07-03T01:00:56+00:00",
        "comment_author": "aorenste",
        "comment_body": "Maybe change the type of progression_futures to a `Sequence[Future[...]]` so the caller knows it won't be mutated...",
        "pr_file_module": null
      }
    ]
  }
]