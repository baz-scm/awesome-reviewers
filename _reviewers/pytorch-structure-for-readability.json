[
  {
    "discussion_id": "2019529371",
    "pr_number": 149697,
    "pr_file": "torch/_inductor/scheduler.py",
    "created_at": "2025-03-28T22:54:18+00:00",
    "commented_code": "return buf_byte_accesses\n \n+    @cache_on_self\n+    def estimate_flops(self) -> int | None:\n+        from torch._subclasses.fake_tensor import FakeTensorMode\n+        from torch.utils.flop_counter import FlopCounterMode\n+\n+        op = kernel_name_to_op.get(getattr(self.node, \"python_kernel_name\", \"\"), None)\n+\n+        if isinstance(self, ExternKernel):\n+            if op is not None:",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2019529371",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149697,
        "pr_file": "torch/_inductor/scheduler.py",
        "discussion_id": "2019529371",
        "commented_code": "@@ -736,6 +737,48 @@ def get_buf_bytes(\n \n         return buf_byte_accesses\n \n+    @cache_on_self\n+    def estimate_flops(self) -> int | None:\n+        from torch._subclasses.fake_tensor import FakeTensorMode\n+        from torch.utils.flop_counter import FlopCounterMode\n+\n+        op = kernel_name_to_op.get(getattr(self.node, \"python_kernel_name\", \"\"), None)\n+\n+        if isinstance(self, ExternKernel):\n+            if op is not None:",
        "comment_created_at": "2025-03-28T22:54:18+00:00",
        "comment_author": "eellison",
        "comment_body": " nit? can we reduce nesting. \r\n\r\n```\r\nif not isinstance(self, ExternKernel) or op is None:\r\n     return None\r\n```\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2186213271",
    "pr_number": 157614,
    "pr_file": "torch/_inductor/compile_fx_async.py",
    "created_at": "2025-07-04T23:43:53+00:00",
    "commented_code": "return res\n \n     def _check_and_switch_progression(self) -> None:\n-        # Check if any newer progression stage is ready (in order from latest to earliest)\n-        for i in range(\n-            len(self._progression_futures) - 1, self._current_progression_index, -1\n-        ):\n-            future = self._progression_futures[i]\n-            if self._post_compile_data and future and future.done():\n-                self._switch_to_progression_stage(i)\n-                break\n+        if not self._progression_futures:\n+            return\n+\n+        stage_index = -1\n+        for i, future in enumerate(self._progression_futures):\n+            if self._post_compile_data and future.done():",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2186213271",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 157614,
        "pr_file": "torch/_inductor/compile_fx_async.py",
        "discussion_id": "2186213271",
        "commented_code": "@@ -236,14 +235,19 @@ def __call__(self, args: Sequence[Any]) -> Any:\n         return res\n \n     def _check_and_switch_progression(self) -> None:\n-        # Check if any newer progression stage is ready (in order from latest to earliest)\n-        for i in range(\n-            len(self._progression_futures) - 1, self._current_progression_index, -1\n-        ):\n-            future = self._progression_futures[i]\n-            if self._post_compile_data and future and future.done():\n-                self._switch_to_progression_stage(i)\n-                break\n+        if not self._progression_futures:\n+            return\n+\n+        stage_index = -1\n+        for i, future in enumerate(self._progression_futures):\n+            if self._post_compile_data and future.done():",
        "comment_created_at": "2025-07-04T23:43:53+00:00",
        "comment_author": "aorenste",
        "comment_body": "nit: Move the check for _post_compile_data out of the loop",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2114809722",
    "pr_number": 154540,
    "pr_file": "tools/dynamo/gb_id_mapping.py",
    "created_at": "2025-05-29T21:55:57+00:00",
    "commented_code": "+import ast\n+import json\n+import re\n+from pathlib import Path\n+\n+\n+def get_source_segment(source, node):\n+    if hasattr(ast, \"get_source_segment\"):\n+        return ast.get_source_segment(source, node)\n+    else:\n+        return source[node.lineno - 1][node.col_offset : node.end_col_offset]\n+\n+\n+def clean_string(s):\n+    if s is None:\n+        return None\n+    if isinstance(s, str):\n+        s = re.sub(r'^f[\"\\']', r'\"', s)\n+        s = re.sub(r'[\"\\'] f[\"\\']', \" \", s)\n+        s = re.sub(r'^[\"\\'](.*)[\"\\']$', r\"\\1\", s)\n+        s = re.sub(r\"\\s*\n\\s*\", \" \", s)\n+        s = s.replace('\\\\\"', '\"').replace(\"\\\\'\", \"'\")\n+        s = s.replace(\"\\\\\", \"\")\n+        s = re.sub(r'\" \"', \" \", s)\n+        return s\n+    return s\n+\n+\n+def expand_hints(hints):\n+    from torch._dynamo import graph_break_hints\n+\n+    expanded_hints = []\n+    for hint in hints:\n+        if isinstance(hint, str):\n+            if \"*graph_break_hints.USER_ERROR\" or \"graph_break_hints.USER_ERROR\" in hint:\n+                expanded_hints.extend(graph_break_hints.USER_ERROR)\n+            elif \"*graph_break_hints.DYNAMO_BUG\" or \"graph_break_hints.DYNAMO_BUG\" in hint:\n+                expanded_hints.extend(graph_break_hints.DYNAMO_BUG)\n+            elif \"*graph_break_hints.DIFFICULT\" or \"graph_break_hints.DIFFICULT\" in hint:\n+                expanded_hints.extend(graph_break_hints.DIFFICULT)\n+            elif \"*graph_break_hints.FUNDAMENTAL\" or \"graph_break_hints.FUNDAMENTAL\" in hint:\n+                expanded_hints.extend(graph_break_hints.FUNDAMENTAL)\n+            elif \"*graph_break_hints.SUPPORTABLE\" or \"graph_break_hints.SUPPORTABLE\" in hint:\n+                expanded_hints.extend(graph_break_hints.SUPPORTABLE)\n+            elif \"*graph_break_hints.CAUSED_BY_EARLIER_GRAPH_BREAK\" or \"graph_break_hints.CAUSED_BY_EARLIER_GRAPH_BREAK\" in hint:\n+                expanded_hints.extend(graph_break_hints.CAUSED_BY_EARLIER_GRAPH_BREAK)\n+            elif \"*graph_break_hints.INFERENCE_MODE\" or \"graph_break_hints.INFERENCE_MODE\" in hint:\n+                expanded_hints.extend(graph_break_hints.INFERENCE_MODE)\n+            else:\n+                expanded_hints.append(hint)\n+        else:\n+            expanded_hints.append(hint)\n+\n+    return expanded_hints\n+\n+\n+def find_unimplemented_v2_calls():\n+    dynamo_dir = Path(__file__).parent.parent.parent / \"torch\" / \"_dynamo\"\n+    results = []\n+\n+    for file_path in dynamo_dir.glob(\"**/*.py\"):\n+        with open(file_path, \"r\") as f:\n+            source = f.read()\n+            try:\n+                tree = ast.parse(source)\n+\n+                for node in ast.walk(tree):\n+                    if isinstance(node, ast.Call) and hasattr(node, \"func\"):\n+                        is_unimplemented = False\n+                        if (\n+                            isinstance(node.func, ast.Name)\n+                            and node.func.id == \"unimplemented_v2\"\n+                        ):\n+                            is_unimplemented = True\n+                        elif (\n+                            isinstance(node.func, ast.Attribute)\n+                            and node.func.attr == \"unimplemented_v2\"\n+                        ):\n+                            is_unimplemented = True\n+\n+                        if is_unimplemented:\n+                            info = {\n+                                \"gb_type\": None,\n+                                \"context\": None,\n+                                \"explanation\": None,\n+                                \"hints\": [],\n+                                \"from_exc\": None,\n+                            }\n+\n+                            for kw in node.keywords:\n+                                if kw.arg in info:\n+                                    param_source = get_source_segment(source, kw.value)\n+                                    if param_source:\n+                                        info[kw.arg] = clean_string(param_source)\n+                                    elif isinstance(kw.value, ast.Constant):\n+                                        info[kw.arg] = kw.value.value\n+                                    else:\n+                                        info[kw.arg] = \"DYNAMIC_CONTEXT\"\n+\n+                            results.append((file_path, node.lineno, info))\n+            except SyntaxError:\n+                print(f\"Syntax error in {file_path}\")\n+\n+    return results\n+\n+\n+def create_registry():\n+    calls = find_unimplemented_v2_calls()\n+    registry = {}\n+\n+    gb_types = {}\n+    for file_path, line, info in calls:\n+        if info[\"gb_type\"] and info[\"gb_type\"] not in gb_types:\n+            gb_types[info[\"gb_type\"]] = info\n+\n+    for i, (gb_type, info) in enumerate(sorted(gb_types.items()), 1001):",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2114809722",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 154540,
        "pr_file": "tools/dynamo/gb_id_mapping.py",
        "discussion_id": "2114809722",
        "commented_code": "@@ -0,0 +1,146 @@\n+import ast\n+import json\n+import re\n+from pathlib import Path\n+\n+\n+def get_source_segment(source, node):\n+    if hasattr(ast, \"get_source_segment\"):\n+        return ast.get_source_segment(source, node)\n+    else:\n+        return source[node.lineno - 1][node.col_offset : node.end_col_offset]\n+\n+\n+def clean_string(s):\n+    if s is None:\n+        return None\n+    if isinstance(s, str):\n+        s = re.sub(r'^f[\"\\']', r'\"', s)\n+        s = re.sub(r'[\"\\'] f[\"\\']', \" \", s)\n+        s = re.sub(r'^[\"\\'](.*)[\"\\']$', r\"\\1\", s)\n+        s = re.sub(r\"\\s*\\n\\s*\", \" \", s)\n+        s = s.replace('\\\\\"', '\"').replace(\"\\\\'\", \"'\")\n+        s = s.replace(\"\\\\\", \"\")\n+        s = re.sub(r'\" \"', \" \", s)\n+        return s\n+    return s\n+\n+\n+def expand_hints(hints):\n+    from torch._dynamo import graph_break_hints\n+\n+    expanded_hints = []\n+    for hint in hints:\n+        if isinstance(hint, str):\n+            if \"*graph_break_hints.USER_ERROR\" or \"graph_break_hints.USER_ERROR\" in hint:\n+                expanded_hints.extend(graph_break_hints.USER_ERROR)\n+            elif \"*graph_break_hints.DYNAMO_BUG\" or \"graph_break_hints.DYNAMO_BUG\" in hint:\n+                expanded_hints.extend(graph_break_hints.DYNAMO_BUG)\n+            elif \"*graph_break_hints.DIFFICULT\" or \"graph_break_hints.DIFFICULT\" in hint:\n+                expanded_hints.extend(graph_break_hints.DIFFICULT)\n+            elif \"*graph_break_hints.FUNDAMENTAL\" or \"graph_break_hints.FUNDAMENTAL\" in hint:\n+                expanded_hints.extend(graph_break_hints.FUNDAMENTAL)\n+            elif \"*graph_break_hints.SUPPORTABLE\" or \"graph_break_hints.SUPPORTABLE\" in hint:\n+                expanded_hints.extend(graph_break_hints.SUPPORTABLE)\n+            elif \"*graph_break_hints.CAUSED_BY_EARLIER_GRAPH_BREAK\" or \"graph_break_hints.CAUSED_BY_EARLIER_GRAPH_BREAK\" in hint:\n+                expanded_hints.extend(graph_break_hints.CAUSED_BY_EARLIER_GRAPH_BREAK)\n+            elif \"*graph_break_hints.INFERENCE_MODE\" or \"graph_break_hints.INFERENCE_MODE\" in hint:\n+                expanded_hints.extend(graph_break_hints.INFERENCE_MODE)\n+            else:\n+                expanded_hints.append(hint)\n+        else:\n+            expanded_hints.append(hint)\n+\n+    return expanded_hints\n+\n+\n+def find_unimplemented_v2_calls():\n+    dynamo_dir = Path(__file__).parent.parent.parent / \"torch\" / \"_dynamo\"\n+    results = []\n+\n+    for file_path in dynamo_dir.glob(\"**/*.py\"):\n+        with open(file_path, \"r\") as f:\n+            source = f.read()\n+            try:\n+                tree = ast.parse(source)\n+\n+                for node in ast.walk(tree):\n+                    if isinstance(node, ast.Call) and hasattr(node, \"func\"):\n+                        is_unimplemented = False\n+                        if (\n+                            isinstance(node.func, ast.Name)\n+                            and node.func.id == \"unimplemented_v2\"\n+                        ):\n+                            is_unimplemented = True\n+                        elif (\n+                            isinstance(node.func, ast.Attribute)\n+                            and node.func.attr == \"unimplemented_v2\"\n+                        ):\n+                            is_unimplemented = True\n+\n+                        if is_unimplemented:\n+                            info = {\n+                                \"gb_type\": None,\n+                                \"context\": None,\n+                                \"explanation\": None,\n+                                \"hints\": [],\n+                                \"from_exc\": None,\n+                            }\n+\n+                            for kw in node.keywords:\n+                                if kw.arg in info:\n+                                    param_source = get_source_segment(source, kw.value)\n+                                    if param_source:\n+                                        info[kw.arg] = clean_string(param_source)\n+                                    elif isinstance(kw.value, ast.Constant):\n+                                        info[kw.arg] = kw.value.value\n+                                    else:\n+                                        info[kw.arg] = \"DYNAMIC_CONTEXT\"\n+\n+                            results.append((file_path, node.lineno, info))\n+            except SyntaxError:\n+                print(f\"Syntax error in {file_path}\")\n+\n+    return results\n+\n+\n+def create_registry():\n+    calls = find_unimplemented_v2_calls()\n+    registry = {}\n+\n+    gb_types = {}\n+    for file_path, line, info in calls:\n+        if info[\"gb_type\"] and info[\"gb_type\"] not in gb_types:\n+            gb_types[info[\"gb_type\"]] = info\n+\n+    for i, (gb_type, info) in enumerate(sorted(gb_types.items()), 1001):",
        "comment_created_at": "2025-05-29T21:55:57+00:00",
        "comment_author": "StrongerXi",
        "comment_body": "1001 feels like an arbitrary literal. Can you make this a constant variable instead?",
        "pr_file_module": null
      }
    ]
  }
]