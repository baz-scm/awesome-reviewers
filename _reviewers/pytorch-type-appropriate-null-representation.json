[
  {
    "discussion_id": "2112331194",
    "pr_number": 153977,
    "pr_file": "torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp",
    "created_at": "2025-05-28T16:40:25+00:00",
    "commented_code": "\"bugs in the communications library (e.g. NCCL), etc. \");\n }\n \n-std::string ProcessGroupNCCL::getNCCLWatchdogTimeoutExitMsg(\n+std::string ProcessGroupNCCL::HeartbeatMonitor::getNCCLWatchdogTimeoutExitMsg(\n     const std::string& exitReason) {\n   return c10::str(\n-      logPrefix(),\n+      pg_->logPrefix(),\n       \"Terminating the process after attempting to dump debug info, due to \",\n       exitReason,\n       \".\");\n }\n \n-void ProcessGroupNCCL::setEnableNanCheck(bool enableNanCheck) {\n-  enableNanCheck_ = enableNanCheck;\n+void ProcessGroupNCCL::HeartbeatMonitor::setLastWorkListUpdateTime(\n+    std::chrono::time_point<std::chrono::steady_clock> time) {\n+  // We intentially let the race condition to happen but this is ok\n+  // as long as we update the time, we know we are making progress.\n+  lastWorkListUpdateTime_ = time;\n+}\n+\n+ProcessGroupNCCL::HeartbeatMonitor::HeartbeatMonitor(ProcessGroupNCCL* pg) {\n+  pg_ = pg;\n+  heartbeatTimeoutInSec_ =\n+      getCvarInt(TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC, 60 * 8 /*8 Mins*/);\n+  waitTimeoutDumpInMilSec_ =\n+      getCvarInt(TORCH_NCCL_WAIT_TIMEOUT_DUMP_MILSEC, 15 * 1000 /*15 Sec*/);\n+  coordCheckIntervalMilSec_ = getCvarInt(TORCH_NCCL_COORD_CHECK_MILSEC, 1000);\n+  // TODO, we should either deprecate TORCH_NCCL_DUMP_ON_TIMEOUT\n+  // or change its name to reflect that dump happens on exception including\n+  // both timeout and other errors.\n+  dumpOnTimeoutOrEx_ = getCvarBool(TORCH_NCCL_DUMP_ON_TIMEOUT, true);\n+  // logging C++ stack isn't safe. Gate it with an ENV.\n+  logCppStackOnUncleanShutdown_ =\n+      getCvarBool(TORCH_NCCL_LOG_CPP_STACK_ON_UNCLEAN_SHUTDOWN, true);\n+  watchdogHeartbeatMonitorEnabled_.store(\n+      getCvarBool(TORCH_NCCL_ENABLE_MONITORING, true));\n }\n \n-void ProcessGroupNCCL::heartbeatMonitor() {\n+void ProcessGroupNCCL::HeartbeatMonitor::printLogMsg() {\n+  LOG(INFO)\n+      << pg_->logPrefix() << \"HeartbeatMonitor environments: \"\n+      << \"TORCH_NCCL_ENABLE_MONITORING (Whether to kill program when no watchdog heartbeat detected): \"\n+      << watchdogHeartbeatMonitorEnabled_.load()\n+      << \", TORCH_NCCL_DUMP_ON_TIMEOUT: \" << dumpOnTimeoutOrEx_\n+      << \", TORCH_NCCL_WAIT_TIMEOUT_DUMP_MILSEC: \" << waitTimeoutDumpInMilSec_\n+      << \", TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC: \" << heartbeatTimeoutInSec_\n+      << \", TORCH_NCCL_COORD_CHECK_MILSEC: \" << coordCheckIntervalMilSec_\n+      << \", TORCH_NCCL_LOG_CPP_STACK_ON_UNCLEAN_SHUTDOWN: \"\n+      << logCppStackOnUncleanShutdown_;\n+}\n+\n+void ProcessGroupNCCL::HeartbeatMonitor::stop() {\n+  terminateHeartbeatMonitorThread_.store(true);\n+  monitorWakeUpCV_.notify_one();\n+}\n+\n+void ProcessGroupNCCL::HeartbeatMonitor::start() {\n+  ncclHeartbeatMonitorThread_ =\n+      std::thread(&ProcessGroupNCCL::HeartbeatMonitor::runLoop, this);\n+}",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2112331194",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 153977,
        "pr_file": "torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp",
        "discussion_id": "2112331194",
        "commented_code": "@@ -1643,37 +1613,89 @@ std::string ProcessGroupNCCL::getNCCLWatchdogTimeoutErrorMsg(\n       \"bugs in the communications library (e.g. NCCL), etc. \");\n }\n \n-std::string ProcessGroupNCCL::getNCCLWatchdogTimeoutExitMsg(\n+std::string ProcessGroupNCCL::HeartbeatMonitor::getNCCLWatchdogTimeoutExitMsg(\n     const std::string& exitReason) {\n   return c10::str(\n-      logPrefix(),\n+      pg_->logPrefix(),\n       \"Terminating the process after attempting to dump debug info, due to \",\n       exitReason,\n       \".\");\n }\n \n-void ProcessGroupNCCL::setEnableNanCheck(bool enableNanCheck) {\n-  enableNanCheck_ = enableNanCheck;\n+void ProcessGroupNCCL::HeartbeatMonitor::setLastWorkListUpdateTime(\n+    std::chrono::time_point<std::chrono::steady_clock> time) {\n+  // We intentially let the race condition to happen but this is ok\n+  // as long as we update the time, we know we are making progress.\n+  lastWorkListUpdateTime_ = time;\n+}\n+\n+ProcessGroupNCCL::HeartbeatMonitor::HeartbeatMonitor(ProcessGroupNCCL* pg) {\n+  pg_ = pg;\n+  heartbeatTimeoutInSec_ =\n+      getCvarInt(TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC, 60 * 8 /*8 Mins*/);\n+  waitTimeoutDumpInMilSec_ =\n+      getCvarInt(TORCH_NCCL_WAIT_TIMEOUT_DUMP_MILSEC, 15 * 1000 /*15 Sec*/);\n+  coordCheckIntervalMilSec_ = getCvarInt(TORCH_NCCL_COORD_CHECK_MILSEC, 1000);\n+  // TODO, we should either deprecate TORCH_NCCL_DUMP_ON_TIMEOUT\n+  // or change its name to reflect that dump happens on exception including\n+  // both timeout and other errors.\n+  dumpOnTimeoutOrEx_ = getCvarBool(TORCH_NCCL_DUMP_ON_TIMEOUT, true);\n+  // logging C++ stack isn't safe. Gate it with an ENV.\n+  logCppStackOnUncleanShutdown_ =\n+      getCvarBool(TORCH_NCCL_LOG_CPP_STACK_ON_UNCLEAN_SHUTDOWN, true);\n+  watchdogHeartbeatMonitorEnabled_.store(\n+      getCvarBool(TORCH_NCCL_ENABLE_MONITORING, true));\n }\n \n-void ProcessGroupNCCL::heartbeatMonitor() {\n+void ProcessGroupNCCL::HeartbeatMonitor::printLogMsg() {\n+  LOG(INFO)\n+      << pg_->logPrefix() << \"HeartbeatMonitor environments: \"\n+      << \"TORCH_NCCL_ENABLE_MONITORING (Whether to kill program when no watchdog heartbeat detected): \"\n+      << watchdogHeartbeatMonitorEnabled_.load()\n+      << \", TORCH_NCCL_DUMP_ON_TIMEOUT: \" << dumpOnTimeoutOrEx_\n+      << \", TORCH_NCCL_WAIT_TIMEOUT_DUMP_MILSEC: \" << waitTimeoutDumpInMilSec_\n+      << \", TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC: \" << heartbeatTimeoutInSec_\n+      << \", TORCH_NCCL_COORD_CHECK_MILSEC: \" << coordCheckIntervalMilSec_\n+      << \", TORCH_NCCL_LOG_CPP_STACK_ON_UNCLEAN_SHUTDOWN: \"\n+      << logCppStackOnUncleanShutdown_;\n+}\n+\n+void ProcessGroupNCCL::HeartbeatMonitor::stop() {\n+  terminateHeartbeatMonitorThread_.store(true);\n+  monitorWakeUpCV_.notify_one();\n+}\n+\n+void ProcessGroupNCCL::HeartbeatMonitor::start() {\n+  ncclHeartbeatMonitorThread_ =\n+      std::thread(&ProcessGroupNCCL::HeartbeatMonitor::runLoop, this);\n+}",
        "comment_created_at": "2025-05-28T16:40:25+00:00",
        "comment_author": "kwen2501",
        "comment_body": "check for null'ness of `ncclHeartbeatMonitorThread_` before assignment, to defend against second call of start().",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2123036514",
    "pr_number": 154977,
    "pr_file": "aten/src/ATen/native/mkldnn/xpu/detail/Matmul.cpp",
    "created_at": "2025-06-03T07:55:20+00:00",
    "commented_code": "#include <oneapi/dnnl/dnnl.hpp>\n \n namespace at::native::onednn {\n+class BiasHandler {\n+ public:\n+  BiasHandler(at::Tensor& bias, int64_t mb, int64_t m, int64_t k, int64_t n)\n+      : b(bias), mb(mb), m(m), k(k), n(n), with_bias(bias.defined()) {}\n+\n+  void handle0D() {\n+    TORCH_CHECK(\n+        b.numel() == 1, \"matmul supports 1 numel when bias dim is [] ...\");\n+    if (gemm_dim == 3) {\n+      b = b.expand({mb, m, n}).contiguous();\n+    } else {\n+      b = b.expand({1, n}).contiguous();\n+    }\n+  }\n+\n+  void handle1D() {\n+    TORCH_CHECK(\n+        b.size(0) == n || b.size(0) == 1,\n+        \"matmul supports [n] or [1] when bias dim is 1...\");\n+    if (b.size(0) == 0) {\n+      with_bias = false;\n+    } else if (gemm_dim == 3) {\n+      b = b.expand({mb, m, n}).contiguous();\n+    } else if (gemm_dim == 2) {\n+      b = b.expand({1, n}).contiguous();\n+    }\n+  }\n+\n+  void handle2D() {\n+    TORCH_CHECK(\n+        (b.size(0) == m && b.size(1) == n) ||\n+            (b.size(0) == 1 && b.size(1) == n) ||\n+            (b.size(0) == m && b.size(1) == 1) ||\n+            (b.size(0) == 1 && b.size(1) == 1),\n+        \"matmul supports [m, n] or [1, n] or [m, 1] or [1, 1] when bias dim is 2 ...\");\n+    if (b.size(0) == 1 && b.size(1) == 1)\n+      b = b.expand({1, n}).contiguous();\n+  }\n+\n+  void handle3D() {\n+    TORCH_CHECK(\n+        at::are_expandable({mb, m, n}, b.sizes()),\n+        \"matmul bias must be expandable to:\",\n+        \"{mb, m, n} where mb is the batch size, m is the number of rows, and n is the number of columns.\",\n+        \" but got:\",\n+        b.sizes());\n+    b = b.expand({mb, m, n}).contiguous();\n+  }\n+\n+  bool is_with_bias() {\n+    return with_bias;\n+  }\n+\n+  void handle() {\n+    with_bias = b.defined();\n+    if (!with_bias)\n+      return;\n+    using HandlerFn = void (BiasHandler::*)();\n+    std::unordered_map<int, HandlerFn> handler_map = {\n+        {0, &BiasHandler::handle0D},\n+        {1, &BiasHandler::handle1D},\n+        {2, &BiasHandler::handle2D},\n+        {3, &BiasHandler::handle3D}};\n+\n+    auto iter = handler_map.find(b.dim());\n+    TORCH_CHECK(iter != handler_map.end(), \"invalid bias dim:\", b.dim());\n+    (this->*(iter->second))();\n+  }\n+\n+ private:\n+  at::Tensor& b;\n+  int mb, m, k, n, gemm_dim;\n+  bool with_bias;\n+};\n+class GEMMMemoryCreator {\n+ public:\n+  GEMMMemoryCreator(\n+      int64_t dim,\n+      int64_t m,\n+      int64_t k,\n+      int64_t n,\n+      int64_t mb,\n+      int64_t bsA,\n+      int64_t bsB,\n+      bool m2_trans,\n+      bool with_bias)\n+      : ndim(dim),\n+        m(m),\n+        k(k),\n+        n{n},\n+        mb{mb},\n+        bsA(bsA),\n+        bsB(bsB),\n+        m2_trans(m2_trans),\n+        with_bias(with_bias) {}\n+\n+  using arg_map_t = std::unordered_map<int, dnnl::memory>;\n+  using md_t = dnnl::memory::desc;\n+\n+  void handle2D(\n+      const at::Tensor& m1,\n+      const at::Tensor& m2,\n+      const at::Tensor& dst) {\n+    m1_dims = {m, k};\n+    m2_dims = {k, n};\n+    dst_dims = {m, n};\n+\n+    m1_strides = {m1.stride(0), m1.stride(1)};\n+\n+    m2_strides = m2_trans ? std::vector<int64_t>{m2.stride(0), m2.stride(1)}\n+                          : std::vector<int64_t>{m2.stride(1), m2.stride(0)};\n+\n+    dst_strides = {dst.stride(0), dst.stride(1)};\n+  }\n+\n+  void handle3D(\n+      const at::Tensor& m1,\n+      const at::Tensor& m2,\n+      const at::Tensor& dst) {\n+    m1_dims = dnnl::memory::dims({bsA, m, k});\n+    m2_dims = dnnl::memory::dims({bsB, k, n});\n+    dst_dims = dnnl::memory::dims({mb, m, n});\n+\n+    m1_strides = {m1.stride(0), m1.stride(1), m1.stride(2)};\n+    m2_strides = m2_trans\n+        ? std::vector<int64_t>{m2.stride(0), m2.stride(1), m2.stride(2)}\n+        : std::vector<int64_t>{m2.stride(0), m2.stride(2), m2.stride(1)};\n+\n+    dst_strides = {dst.stride(0), dst.stride(1), dst.stride(2)};\n+  }\n+\n+  void initialize_md(\n+      const at::Tensor& m1,\n+      const at::Tensor& m2,\n+      const at::Tensor& dst) {\n+    m1_md = create_md(m1, m1_dims, m1_strides);\n+    m2_md = create_md(m2, m2_dims, m2_strides);\n+    dst_md = create_md(dst, dst_dims, dst_strides);\n+  }\n+\n+  std::tuple<md_t, md_t, md_t, md_t> query_md() {\n+    return {m1_md, m2_md, dst_md, bias_md};\n+  }\n+\n+  void initialize(\n+      const at::Tensor& m1,\n+      const at::Tensor& m2,\n+      const at::Tensor& dst,\n+      const at::Tensor& bias) {\n+    if (ndim == 2) {\n+      handle2D(m1, m2, dst);\n+    } else if (ndim == 3) {\n+      handle3D(m1, m2, dst);\n+    } else {\n+      TORCH_CHECK(false, \"only support 2D or 3D matmul, got ndim:\", ndim);\n+    }\n+    initialize_md(m1, m2, dst);\n+\n+    if (with_bias) {\n+      bias_dims = get_onednn_dims(bias);\n+      bias_strides = get_onednn_strides(bias);\n+      bias_md = dnnl::memory::desc(\n+          bias_dims, get_onednn_dtype_include_double(bias), bias_strides);\n+    } else {\n+      bias_md = nullptr;",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2123178411",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 154977,
        "pr_file": "aten/src/ATen/native/mkldnn/xpu/detail/Matmul.cpp",
        "discussion_id": "2123036514",
        "commented_code": "@@ -11,6 +11,207 @@\n #include <oneapi/dnnl/dnnl.hpp>\n \n namespace at::native::onednn {\n+class BiasHandler {\n+ public:\n+  BiasHandler(at::Tensor& bias, int64_t mb, int64_t m, int64_t k, int64_t n)\n+      : b(bias), mb(mb), m(m), k(k), n(n), with_bias(bias.defined()) {}\n+\n+  void handle0D() {\n+    TORCH_CHECK(\n+        b.numel() == 1, \"matmul supports 1 numel when bias dim is [] ...\");\n+    if (gemm_dim == 3) {\n+      b = b.expand({mb, m, n}).contiguous();\n+    } else {\n+      b = b.expand({1, n}).contiguous();\n+    }\n+  }\n+\n+  void handle1D() {\n+    TORCH_CHECK(\n+        b.size(0) == n || b.size(0) == 1,\n+        \"matmul supports [n] or [1] when bias dim is 1...\");\n+    if (b.size(0) == 0) {\n+      with_bias = false;\n+    } else if (gemm_dim == 3) {\n+      b = b.expand({mb, m, n}).contiguous();\n+    } else if (gemm_dim == 2) {\n+      b = b.expand({1, n}).contiguous();\n+    }\n+  }\n+\n+  void handle2D() {\n+    TORCH_CHECK(\n+        (b.size(0) == m && b.size(1) == n) ||\n+            (b.size(0) == 1 && b.size(1) == n) ||\n+            (b.size(0) == m && b.size(1) == 1) ||\n+            (b.size(0) == 1 && b.size(1) == 1),\n+        \"matmul supports [m, n] or [1, n] or [m, 1] or [1, 1] when bias dim is 2 ...\");\n+    if (b.size(0) == 1 && b.size(1) == 1)\n+      b = b.expand({1, n}).contiguous();\n+  }\n+\n+  void handle3D() {\n+    TORCH_CHECK(\n+        at::are_expandable({mb, m, n}, b.sizes()),\n+        \"matmul bias must be expandable to:\",\n+        \"{mb, m, n} where mb is the batch size, m is the number of rows, and n is the number of columns.\",\n+        \" but got:\",\n+        b.sizes());\n+    b = b.expand({mb, m, n}).contiguous();\n+  }\n+\n+  bool is_with_bias() {\n+    return with_bias;\n+  }\n+\n+  void handle() {\n+    with_bias = b.defined();\n+    if (!with_bias)\n+      return;\n+    using HandlerFn = void (BiasHandler::*)();\n+    std::unordered_map<int, HandlerFn> handler_map = {\n+        {0, &BiasHandler::handle0D},\n+        {1, &BiasHandler::handle1D},\n+        {2, &BiasHandler::handle2D},\n+        {3, &BiasHandler::handle3D}};\n+\n+    auto iter = handler_map.find(b.dim());\n+    TORCH_CHECK(iter != handler_map.end(), \"invalid bias dim:\", b.dim());\n+    (this->*(iter->second))();\n+  }\n+\n+ private:\n+  at::Tensor& b;\n+  int mb, m, k, n, gemm_dim;\n+  bool with_bias;\n+};\n+class GEMMMemoryCreator {\n+ public:\n+  GEMMMemoryCreator(\n+      int64_t dim,\n+      int64_t m,\n+      int64_t k,\n+      int64_t n,\n+      int64_t mb,\n+      int64_t bsA,\n+      int64_t bsB,\n+      bool m2_trans,\n+      bool with_bias)\n+      : ndim(dim),\n+        m(m),\n+        k(k),\n+        n{n},\n+        mb{mb},\n+        bsA(bsA),\n+        bsB(bsB),\n+        m2_trans(m2_trans),\n+        with_bias(with_bias) {}\n+\n+  using arg_map_t = std::unordered_map<int, dnnl::memory>;\n+  using md_t = dnnl::memory::desc;\n+\n+  void handle2D(\n+      const at::Tensor& m1,\n+      const at::Tensor& m2,\n+      const at::Tensor& dst) {\n+    m1_dims = {m, k};\n+    m2_dims = {k, n};\n+    dst_dims = {m, n};\n+\n+    m1_strides = {m1.stride(0), m1.stride(1)};\n+\n+    m2_strides = m2_trans ? std::vector<int64_t>{m2.stride(0), m2.stride(1)}\n+                          : std::vector<int64_t>{m2.stride(1), m2.stride(0)};\n+\n+    dst_strides = {dst.stride(0), dst.stride(1)};\n+  }\n+\n+  void handle3D(\n+      const at::Tensor& m1,\n+      const at::Tensor& m2,\n+      const at::Tensor& dst) {\n+    m1_dims = dnnl::memory::dims({bsA, m, k});\n+    m2_dims = dnnl::memory::dims({bsB, k, n});\n+    dst_dims = dnnl::memory::dims({mb, m, n});\n+\n+    m1_strides = {m1.stride(0), m1.stride(1), m1.stride(2)};\n+    m2_strides = m2_trans\n+        ? std::vector<int64_t>{m2.stride(0), m2.stride(1), m2.stride(2)}\n+        : std::vector<int64_t>{m2.stride(0), m2.stride(2), m2.stride(1)};\n+\n+    dst_strides = {dst.stride(0), dst.stride(1), dst.stride(2)};\n+  }\n+\n+  void initialize_md(\n+      const at::Tensor& m1,\n+      const at::Tensor& m2,\n+      const at::Tensor& dst) {\n+    m1_md = create_md(m1, m1_dims, m1_strides);\n+    m2_md = create_md(m2, m2_dims, m2_strides);\n+    dst_md = create_md(dst, dst_dims, dst_strides);\n+  }\n+\n+  std::tuple<md_t, md_t, md_t, md_t> query_md() {\n+    return {m1_md, m2_md, dst_md, bias_md};\n+  }\n+\n+  void initialize(\n+      const at::Tensor& m1,\n+      const at::Tensor& m2,\n+      const at::Tensor& dst,\n+      const at::Tensor& bias) {\n+    if (ndim == 2) {\n+      handle2D(m1, m2, dst);\n+    } else if (ndim == 3) {\n+      handle3D(m1, m2, dst);\n+    } else {\n+      TORCH_CHECK(false, \"only support 2D or 3D matmul, got ndim:\", ndim);\n+    }\n+    initialize_md(m1, m2, dst);\n+\n+    if (with_bias) {\n+      bias_dims = get_onednn_dims(bias);\n+      bias_strides = get_onednn_strides(bias);\n+      bias_md = dnnl::memory::desc(\n+          bias_dims, get_onednn_dtype_include_double(bias), bias_strides);\n+    } else {\n+      bias_md = nullptr;",
        "comment_created_at": "2025-06-03T08:54:13+00:00",
        "comment_author": "ZhiweiYan-96",
        "comment_body": "modified",
        "pr_file_module": null
      }
    ]
  }
]