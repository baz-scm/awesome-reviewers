---
title: Validate performance metrics
description: 'Always validate performance measurements against expected ranges and
  understand hardware limitations. When implementing performance optimization:


  1. **Verify benchmarks produce reasonable metrics** - Be suspicious of numbers that
  seem too good (>90% utilization) or too poor (<10% utilization)'
repository: pytorch/pytorch
label: Performance Optimization
language: Python
comments_count: 8
repository_stars: 91169
---

Always validate performance measurements against expected ranges and understand hardware limitations. When implementing performance optimization:

1. **Verify benchmarks produce reasonable metrics** - Be suspicious of numbers that seem too good (>90% utilization) or too poor (<10% utilization)
2. **Adjust for hardware specifics** - Consider system limitations like clock-rate throttling and adjust metrics accordingly using `current_clock_rate/default_clock_rate`
3. **Optimize profiling code** - Check if operations need profiling at all (e.g., only profile nodes with `flop_counter` registrations)
4. **Consider all performance factors** - Don't prune configurations automatically (like register spilling) without verifying actual impact
5. **Use efficient performance tooling** - Heavy dependencies like Pandas in performance measurement code can introduce significant overhead

Example:
```python
# Before: Running expensive profiling unconditionally
def count_flops_fx(node):
    success, args, kwargs = get_fake_args_kwargs(node)
    if success:
        with FlopCounterMode(display=False) as flop_counter:
            with fake_mode:
                node.target(*args, **kwargs)
        return flop_counter.get_total_flops()
    return 0

# After: Only profile when needed
def count_flops_fx(node):
    # Check if node has flop counter registration before running
    if node.target.__name__ not in flop_registry:
        return 0
    
    success, args, kwargs = get_fake_args_kwargs(node)
    if success:
        with FlopCounterMode(display=False) as flop_counter:
            with fake_mode:
                node.target(*args, **kwargs)
        return flop_counter.get_total_flops()
    return 0
```


[
  {
    "discussion_id": "2049183436",
    "pr_number": 149697,
    "pr_file": "torch/_inductor/analysis/device_info.py",
    "created_at": "2025-04-17T15:20:04+00:00",
    "commented_code": "from dataclasses import dataclass\n\nimport torch\n\n\n@dataclass(frozen=True)\nclass DeviceInfo:\n    \"\"\"\n    Theoretical Numbers from data sheet. If two numbers are given, Tensor/Matrix Core vs not,\n    then the higher number is reported. Sparsity is not considered.\n\n\n    Bandwidth numbers are tricky, because there are platform differences that may not show up in the profiler trace.\n    For example,\n    \"\"\"\n\n    tops: dict[torch.dtype, float]\n    dram_bw_gbs: float\n    dram_gb: float\n\n\n# TODO investigate profiler support for tf32 and allow device to report correct number when it's turned on.\n_device_mapping: dict[str, DeviceInfo] = {\n    # Source: https://resources.nvidia.com/en-us-tensor-core/nvidia-tensor-core-gpu-datasheet\n    \"NVIDIA H100\": DeviceInfo(\n        tops={\n            torch.float64: 9.7,\n            torch.float32: 19.5,\n            torch.bfloat16: 1979.0,\n            torch.float16: 1979.0,\n            torch.float8_e8m0fnu: 3958.0,\n            torch.float8_e8m0fnu: 3958.0,\n            torch.float8_e4m3fnuz: 3958.0,",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2049183436",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149697,
        "pr_file": "torch/_inductor/analysis/device_info.py",
        "discussion_id": "2049183436",
        "commented_code": "@@ -0,0 +1,136 @@\n+from dataclasses import dataclass\n+\n+import torch\n+\n+\n+@dataclass(frozen=True)\n+class DeviceInfo:\n+    \"\"\"\n+    Theoretical Numbers from data sheet. If two numbers are given, Tensor/Matrix Core vs not,\n+    then the higher number is reported. Sparsity is not considered.\n+\n+\n+    Bandwidth numbers are tricky, because there are platform differences that may not show up in the profiler trace.\n+    For example,\n+    \"\"\"\n+\n+    tops: dict[torch.dtype, float]\n+    dram_bw_gbs: float\n+    dram_gb: float\n+\n+\n+# TODO investigate profiler support for tf32 and allow device to report correct number when it's turned on.\n+_device_mapping: dict[str, DeviceInfo] = {\n+    # Source: https://resources.nvidia.com/en-us-tensor-core/nvidia-tensor-core-gpu-datasheet\n+    \"NVIDIA H100\": DeviceInfo(\n+        tops={\n+            torch.float64: 9.7,\n+            torch.float32: 19.5,\n+            torch.bfloat16: 1979.0,\n+            torch.float16: 1979.0,\n+            torch.float8_e8m0fnu: 3958.0,\n+            torch.float8_e8m0fnu: 3958.0,\n+            torch.float8_e4m3fnuz: 3958.0,",
        "comment_created_at": "2025-04-17T15:20:04+00:00",
        "comment_author": "eellison",
        "comment_body": "I know the fbcode servers are clock rate limited. So, the numbers will be off for those.. I think this is actually somewhat important for getting accurate numbers. \r\n\r\ncc @bertmaher - who did similar analysis here - https://fb.workplace.com/groups/420659799592399/posts/761265522198490/\r\n\r\nHow would you adjust for clock rate ? Is something simple like current_clock_rate/default sufficient ? I dont have a good sense of this.",
        "pr_file_module": null
      },
      {
        "comment_id": "2049374582",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149697,
        "pr_file": "torch/_inductor/analysis/device_info.py",
        "discussion_id": "2049183436",
        "commented_code": "@@ -0,0 +1,136 @@\n+from dataclasses import dataclass\n+\n+import torch\n+\n+\n+@dataclass(frozen=True)\n+class DeviceInfo:\n+    \"\"\"\n+    Theoretical Numbers from data sheet. If two numbers are given, Tensor/Matrix Core vs not,\n+    then the higher number is reported. Sparsity is not considered.\n+\n+\n+    Bandwidth numbers are tricky, because there are platform differences that may not show up in the profiler trace.\n+    For example,\n+    \"\"\"\n+\n+    tops: dict[torch.dtype, float]\n+    dram_bw_gbs: float\n+    dram_gb: float\n+\n+\n+# TODO investigate profiler support for tf32 and allow device to report correct number when it's turned on.\n+_device_mapping: dict[str, DeviceInfo] = {\n+    # Source: https://resources.nvidia.com/en-us-tensor-core/nvidia-tensor-core-gpu-datasheet\n+    \"NVIDIA H100\": DeviceInfo(\n+        tops={\n+            torch.float64: 9.7,\n+            torch.float32: 19.5,\n+            torch.bfloat16: 1979.0,\n+            torch.float16: 1979.0,\n+            torch.float8_e8m0fnu: 3958.0,\n+            torch.float8_e8m0fnu: 3958.0,\n+            torch.float8_e4m3fnuz: 3958.0,",
        "comment_created_at": "2025-04-17T17:19:17+00:00",
        "comment_author": "exclamaforte",
        "comment_body": "interested in Bert's opinion too, I would think that `current_clock_rate/default sufficient` would be fine considering that most of the flops calculation are just clockrate * core count * flops per core.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2049248412",
    "pr_number": 149697,
    "pr_file": "torch/_inductor/scheduler.py",
    "created_at": "2025-04-17T15:56:09+00:00",
    "commented_code": "if isinstance(self, ExternKernelSchedulerNode):",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2049248412",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149697,
        "pr_file": "torch/_inductor/scheduler.py",
        "discussion_id": "2049248412",
        "commented_code": "@@ -819,15 +854,13 @@ def get_estimated_runtime(self) -> float:\n \n         if isinstance(self, ExternKernelSchedulerNode):",
        "comment_created_at": "2025-04-17T15:56:09+00:00",
        "comment_author": "eellison",
        "comment_body": "This is going to skip any triton template we codegen.\r\n\r\nWhat about instead:\r\n\r\n- check the nodes origins and see if any of them are in flop counter\r\n- use the fx node to get flops\r\n\r\nIn some cases, we populate origins for things like layout conversions for inputs to matmul, or also, unfusing bias. to handle that lets just skip nodes which are not either `is_template()` or ExternKernels.\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2049274487",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149697,
        "pr_file": "torch/_inductor/scheduler.py",
        "discussion_id": "2049248412",
        "commented_code": "@@ -819,15 +854,13 @@ def get_estimated_runtime(self) -> float:\n \n         if isinstance(self, ExternKernelSchedulerNode):",
        "comment_created_at": "2025-04-17T16:14:57+00:00",
        "comment_author": "eellison",
        "comment_body": "Looks like that will also fix the failures with this pr. \r\n\r\nYou can reuse/factor out this:\r\n\r\nhttps://github.com/pytorch/pytorch/blob/4843ce7611b5b9e85b16f1c05cd3b4959c166fce/torch/_inductor/graph.py#L632-L655",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2092021006",
    "pr_number": 149697,
    "pr_file": "torch/_inductor/graph.py",
    "created_at": "2025-05-15T22:03:53+00:00",
    "commented_code": "# only grouped convolutions benchmarked as slower in conv samples for inference only\n        if is_inference:\n            from torch.utils.flop_counter import FlopCounterMode\n\n            flop_counts: dict[str, float] = defaultdict(float)\n            for node in conv_nodes:\n                success, args, kwargs = torch._inductor.fx_utils.get_fake_args_kwargs(\n                    node\n                )\n\n                if success:\n                    with FlopCounterMode(display=False) as flop_counter_mode:\n                        with V.fake_mode:\n                            node.target(*args, **kwargs)\n\n                    counted_flops = flop_counter_mode.get_total_flops()\n                    if is_grouped(node):\n                        node_type = \"grouped\"\n                    elif is_small_channel(node):\n                        node_type = \"small\"\n                    elif is_in_out_channel(node):\n                        node_type = \"in_out\"\n                    else:\n                        node_type = \"default\"\n                counted_flops = count_flops_fx(node)",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2092021006",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149697,
        "pr_file": "torch/_inductor/graph.py",
        "discussion_id": "2092021006",
        "commented_code": "@@ -652,32 +653,24 @@ def is_small_channel(n: torch.fx.Node) -> bool:\n \n         # only grouped convolutions benchmarked as slower in conv samples for inference only\n         if is_inference:\n-            from torch.utils.flop_counter import FlopCounterMode\n-\n             flop_counts: dict[str, float] = defaultdict(float)\n             for node in conv_nodes:\n-                success, args, kwargs = torch._inductor.fx_utils.get_fake_args_kwargs(\n-                    node\n-                )\n-\n-                if success:\n-                    with FlopCounterMode(display=False) as flop_counter_mode:\n-                        with V.fake_mode:\n-                            node.target(*args, **kwargs)\n-\n-                    counted_flops = flop_counter_mode.get_total_flops()\n-                    if is_grouped(node):\n-                        node_type = \"grouped\"\n-                    elif is_small_channel(node):\n-                        node_type = \"small\"\n-                    elif is_in_out_channel(node):\n-                        node_type = \"in_out\"\n-                    else:\n-                        node_type = \"default\"\n+                counted_flops = count_flops_fx(node)",
        "comment_created_at": "2025-05-15T22:03:53+00:00",
        "comment_author": "eellison",
        "comment_body": "Can we make `count_flops_fx` a little bit smarter where it does not try to run this unless the node has a registration in flop_counter ? currently we always instantiate the tensors, and faketensormode, and run ?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2105535986",
    "pr_number": 149697,
    "pr_file": "test/inductor/test_analysis.py",
    "created_at": "2025-05-24T00:01:29+00:00",
    "commented_code": "# Owner(s): [\"module: inductor\"]\n\nimport json\nimport re\nimport tempfile\nimport unittest\nimport uuid\nfrom io import StringIO\nfrom unittest.mock import patch\n\nimport torch\nimport torch.nn.functional as F\nfrom torch._inductor.analysis.profile_analysis import (\n    _augment_trace_helper,\n    _create_extern_mapping,\n    JsonProfile,\n    main,\n)\nfrom torch._inductor.utils import (\n    fresh_inductor_cache,\n    run_and_get_code,\n    tabulate_2d,\n    zip_dicts,\n)\nfrom torch.testing._internal.common_cuda import SM70OrLater\nfrom torch.testing._internal.common_device_type import (\n    dtypes,\n    instantiate_device_type_tests,\n    skipIf,\n)\nfrom torch.testing._internal.common_utils import parametrize, run_tests, TestCase\nfrom torch.testing._internal.inductor_utils import IS_BIG_GPU\n\n\nexample_profile = \"\"\"\n{\n  \"schemaVersion\": 1,\n  \"deviceProperties\": [\n    {\n      \"id\": 0, \"name\": \"NVIDIA H100\", \"totalGlobalMem\": 101997215744,\n      \"computeMajor\": 9, \"computeMinor\": 0,\n      \"maxThreadsPerBlock\": 1024, \"maxThreadsPerMultiprocessor\": 2048,\n      \"regsPerBlock\": 65536, \"warpSize\": 32,\n      \"sharedMemPerBlock\": 49152, \"numSms\": 132\n    , \"regsPerMultiprocessor\": 65536, \"sharedMemPerBlockOptin\": 232448, \"sharedMemPerMultiprocessor\": 233472\n    }\n  ],\n  \"cupti_version\": 24,\n  \"cuda_runtime_version\": 12060,\n  \"with_flops\": 1,\n  \"record_shapes\": 1,\n  \"cuda_driver_version\": 12040,\n  \"profile_memory\": 1,\n  \"trace_id\": \"301995E163ED42048FBD783860E6E7DC\",\n  \"displayTimeUnit\": \"ms\",\n  \"baseTimeNanoseconds\": 1743521598000000000,\n  \"traceEvents\": [\n  {\n    \"ph\": \"X\", \"cat\": \"cpu_op\", \"name\": \"aten::convolution\", \"pid\": 1147039, \"tid\": 1147039,\n    \"ts\": 198093488368.463, \"dur\": 425.453,\n    \"args\": {\n      \"External id\": 1340,\"Sequence number\": 0, \"Fwd thread id\": 0, \"Record function id\": 0, \"Concrete Inputs\": \\\n[\"\", \"\", \"\", \"[2, 2]\", \"[3, 3]\", \"[1, 1]\", \"False\", \"[0, 0]\", \"1\"], \"Input type\": [\"float\", \"float\", \"\", \\\n\"ScalarList\", \"ScalarList\", \"ScalarList\", \"Scalar\", \"ScalarList\", \"Scalar\"], \"Input Strides\": [[150528, 1, 672, 3],\\\n[147, 1, 21, 3], [], [], [], [], [], [], []], \"Input Dims\": [[1, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], \\\n[], []], \"Ev Idx\": 1339\n    }\n  },\n  {\n    \"ph\": \"X\", \"cat\": \"cpu_op\", \"name\": \"aten::_convolution\", \"pid\": 1147039, \"tid\": 1147039,\n    \"ts\": 198093488444.498, \"dur\": 341.867,\n    \"args\": {\n      \"External id\": 1341,\"Record function id\": 0, \"Concrete Inputs\": [\"\", \"\", \"\", \"[2, 2]\", \"[3, 3]\", \"[1, 1]\",\\\n \"False\", \"[0, 0]\", \"1\", \"False\", \"False\", \"True\", \"True\"], \"Input type\": [\"float\", \"float\", \"\", \"ScalarList\",\\\n \"ScalarList\", \"ScalarList\", \"Scalar\", \"ScalarList\", \"Scalar\", \"Scalar\", \"Scalar\", \"Scalar\", \"Scalar\"], \"Input Strides\": \\\n[[150528, 1, 672, 3], [147, 1, 21, 3], [], [], [], [], [], [], [], [], [], [], []], \"Input Dims\": [[1, 3, 224, 224], \\\n[64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []], \"Ev Idx\": 1340\n    }\n  },\n  {\n    \"ph\": \"X\", \"cat\": \"cpu_op\", \"name\": \"aten::addmm\", \"pid\": 1147039, \"tid\": 1147039,\n    \"ts\": 198093513655.849, \"dur\": 251.130,\n    \"args\": {\n      \"External id\": 1619,\"Sequence number\": 0, \"Fwd thread id\": 0, \"Record function id\": 0, \"Concrete Inputs\": \\\n[\"\", \"\", \"\", \"1\", \"1\", \"\"], \"Input type\": [\"float\", \"float\", \"float\", \"Scalar\", \"Scalar\", \"float\"], \"Input Strides\":\\\n [[1], [0, 1], [1, 2048], [], [], [1000, 1]], \"Input Dims\": [[1000], [1, 2048], [2048, 1000], [], [], [1, 1000]], \\\n\"Ev Idx\": 1618\n    }\n  },\n  {\n    \"ph\": \"X\", \"cat\": \"kernel\", \"name\": \"void cutlass_addmm\", \"pid\": 1147039, \"tid\": 1147039,\n    \"ts\": 198093513655.849, \"dur\": 251.130,\n    \"args\": {\n      \"External id\": 1619,\"Sequence number\": 0, \"Fwd thread id\": 0, \"Record function id\": 0,  \"Ev Idx\": 1618\n    }\n  },\n  {\n    \"ph\": \"X\", \"cat\": \"kernel\", \"name\": \"void convolution_kernel\", \"pid\": 1147039, \"tid\": 1147039,\n    \"ts\": 198093513655.849, \"dur\": 200.130,\n    \"args\": {\n      \"External id\": 1342, \"Sequence number\": 0, \"Fwd thread id\": 0, \"Record function id\": 0,  \"Ev Idx\": 1618\n    }\n  },\n  {\n    \"ph\": \"X\", \"cat\": \"cpu_op\", \"name\": \"aten::convolution\", \"pid\": 1147039, \"tid\": 1147039,\n    \"ts\": 198093488444.498, \"dur\": 341.867,\n    \"args\": {\n      \"External id\": 1342,\"Record function id\": 0, \"Concrete Inputs\": [\"\", \"\", \"\", \"[2, 2]\", \"[3, 3]\", \"[1, 1]\", \\\n\"False\", \"[0, 0]\", \"1\", \"False\", \"False\", \"True\", \"True\"], \"Input type\": [\"float\", \"float\", \"\", \"ScalarList\", \\\n\"ScalarList\", \"ScalarList\", \"Scalar\", \"ScalarList\", \"Scalar\", \"Scalar\", \"Scalar\", \"Scalar\", \"Scalar\"], \"Input \\\nStrides\": [[150528, 1, 672, 3], [147, 1, 21, 3], [], [], [], [], [], [], [], [], [], [], []], \"Input Dims\": \\\n[[1, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []], \"Ev Idx\": 1340\n    }\n  }\n],\n  \"traceName\": \"/tmp/compiled_module_profile.json\"\n}\n\"\"\"\n\n\ndef verify_flops(self, expected_flops, out_profile):\n    j = 0\n    for i in range(len(out_profile[\"traceEvents\"])):\n        if \"kernel_flop\" in out_profile[\"traceEvents\"][i][\"args\"]:\n            self.assertEqual(\n                out_profile[\"traceEvents\"][i][\"args\"][\"kernel_flop\"],\n                expected_flops[j],\n            )\n            j += 1\n\n\ndef random_tensor(size, dtype, **kwargs):\n    if dtype in [torch.half, torch.bfloat16, torch.float, torch.double]:\n        return torch.randn(size, dtype=dtype, **kwargs)\n    elif dtype in [torch.uint8, torch.int8, torch.short, torch.int, torch.long]:\n        return torch.randint(0, 100, size, dtype=dtype, **kwargs)\n    else:\n        raise ValueError(\"Unsupported data type\")\n\n\ndef cT(device, dtype):\n    def T(*shape, requires_grad=False):\n        return random_tensor(\n            shape, requires_grad=requires_grad, device=device, dtype=dtype\n        )\n\n    return T\n\n\ndef FlopCounterMode(*args, **kwargs):\n    return torch.utils.flop_counter.FlopCounterMode(*args, **kwargs, display=False)\n\n\nTMP_DIR = tempfile.mkdtemp()\n\n\ndef trace_files():\n    TRACE1 = f\"{TMP_DIR}/trace1-{uuid.uuid4()}.json\"\n    TRACE2 = f\"{TMP_DIR}/trace2-{uuid.uuid4()}.json\"\n    return TRACE1, TRACE2\n\n\ndef omni_model(device, dtype, compile=True, addmm=True, bmm=True):\n    T = cT(device, dtype)\n\n    def model():\n        input_conv = T(1, 3, 56, 56)\n        conv_weight = T(12, 3, 5, 5)\n\n        # Increased matrix sizes\n        B = 8\n        M = 256\n        N = 512\n        K = 768\n        mat1 = T(M, N)\n        mat2 = T(N, K)\n\n        batch_mat1 = T(B, M, N)\n        batch_mat2 = T(B, N, K)\n\n        conv_output = F.conv2d(input_conv, conv_weight)\n\n        conv_output = conv_output * 10\n        mm_output = torch.mm(mat1, mat2)\n        ret = [\n            conv_output.flatten(),\n            mm_output.flatten(),\n        ]\n\n        if addmm:\n            addmm_output = torch.addmm(\n                torch.zeros(mm_output.shape, device=mat1.device, dtype=mat1.dtype),\n                mat1,\n                mat2,\n            )\n            ret.append(addmm_output.flatten())\n\n        if bmm:\n            bmm_output = torch.bmm(batch_mat1, batch_mat2)\n            ret.append(bmm_output.flatten())\n\n        if bmm and addmm:\n            baddbmm_output = torch.baddbmm(\n                torch.zeros(\n                    1,\n                    *mm_output.shape,\n                    device=batch_mat1.device,\n                    dtype=batch_mat1.dtype,\n                ),\n                batch_mat1,\n                batch_mat2,\n            )\n            ret.append(baddbmm_output.flatten())\n\n        return torch.cat(ret)\n\n    if compile:\n        return torch.compile(\n            model, options={\"benchmark_kernel\": True, \"profile_bandwidth\": True}\n        )\n    return model\n\n\nprefix = [\"profile.py\"]\n\n\nclass TestUtils(TestCase):\n    def test_tabulate2d(self):\n        headers = [\"Kernel\", \"Self H100 TIME (ms)\", \"Count\", \"Percent\"]\n        rows = [\n            [\"aten::mm\", 0.500, 7, 0.0],\n            [\"aten::bmm\", 0.400, 6, 0.0],\n            [\"aten::baddbmm\", 0.300, 5, 0.0],\n            [\"aten::convolution\", 0.200, 4, 0.0],\n            [\"aten::cudnn_convolution\", 0.100, 3, 0.0],\n        ]\n        table = [\n            \" Kernel                  | Self H100 TIME (ms) | Count | Percent \",\n            \"-----------------------------------------------------------------\",\n            \" aten::mm                |                 0.5 |     7 |     0.0 \",\n            \" aten::bmm               |                 0.4 |     6 |     0.0 \",\n            \" aten::baddbmm           |                 0.3 |     5 |     0.0 \",\n            \" aten::convolution       |                 0.2 |     4 |     0.0 \",\n            \" aten::cudnn_convolution |                 0.1 |     3 |     0.0 \",\n        ]\n        res = tabulate_2d(rows, headers)\n        for r, t in zip(res.split(\"\\n\"), table):\n            self.assertEqual(r, t)\n\n    def test_zip_dicts(self):\n        d1 = {\"a\": 1, \"b\": 2}\n        d2 = {\"a\": 3, \"c\": 4}\n        res = zip_dicts(d1, d2, d1_default=\"foo\", d2_default=\"bar\")\n        self.assertEqual(set(res), {(\"a\", 1, 3), (\"b\", 2, \"bar\"), (\"c\", \"foo\", 4)})\n        res = zip_dicts(d1, d2)\n        self.assertEqual(set(res), {(\"a\", 1, 3), (\"b\", 2, None), (\"c\", None, 4)})\n\n\nclass TestAnalysis(TestCase):\n    @skipIf(not SM70OrLater, \"Requires sm70\")\n    def test_noop(self):\n        with (\n            patch(\"sys.stdout\", new_callable=StringIO) as mock_stdout,\n            patch(\"sys.argv\", [*prefix]),\n        ):\n            main()\n            self.assertEqual(mock_stdout.getvalue(), \"\")\n\n    @skipIf(not SM70OrLater, \"Requires sm70\")\n    @dtypes(torch.float, torch.double, torch.float16)\n    def test_diff(self, device, dtype):\n        \"\"\"\n        diff, testing out the nruns feature too.\n        \"\"\"\n        if device == \"cpu\":\n            # TODO cpu support\n            return\n        om = omni_model(device, dtype)\n        REPEAT = 5\n        trace1, trace2 = trace_files()\n        print(\"first trace\")\n        torch._dynamo.reset()  # reset the cache\n        with fresh_inductor_cache():\n            with torch.profiler.profile(record_shapes=True) as p:\n                om()\n        p.export_chrome_trace(trace1)\n\n        print(\"second trace\")\n        torch._dynamo.reset()  # reset the cache\n        with fresh_inductor_cache():\n            with torch.profiler.profile(record_shapes=True) as p:\n                for _ in range(REPEAT):\n                    om()\n        p.export_chrome_trace(trace2)\n\n        print(\"diffing...\")\n        with patch(",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2105535986",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149697,
        "pr_file": "test/inductor/test_analysis.py",
        "discussion_id": "2105535986",
        "commented_code": "@@ -0,0 +1,601 @@\n+# Owner(s): [\"module: inductor\"]\n+\n+import json\n+import re\n+import tempfile\n+import unittest\n+import uuid\n+from io import StringIO\n+from unittest.mock import patch\n+\n+import torch\n+import torch.nn.functional as F\n+from torch._inductor.analysis.profile_analysis import (\n+    _augment_trace_helper,\n+    _create_extern_mapping,\n+    JsonProfile,\n+    main,\n+)\n+from torch._inductor.utils import (\n+    fresh_inductor_cache,\n+    run_and_get_code,\n+    tabulate_2d,\n+    zip_dicts,\n+)\n+from torch.testing._internal.common_cuda import SM70OrLater\n+from torch.testing._internal.common_device_type import (\n+    dtypes,\n+    instantiate_device_type_tests,\n+    skipIf,\n+)\n+from torch.testing._internal.common_utils import parametrize, run_tests, TestCase\n+from torch.testing._internal.inductor_utils import IS_BIG_GPU\n+\n+\n+example_profile = \"\"\"\n+{\n+  \"schemaVersion\": 1,\n+  \"deviceProperties\": [\n+    {\n+      \"id\": 0, \"name\": \"NVIDIA H100\", \"totalGlobalMem\": 101997215744,\n+      \"computeMajor\": 9, \"computeMinor\": 0,\n+      \"maxThreadsPerBlock\": 1024, \"maxThreadsPerMultiprocessor\": 2048,\n+      \"regsPerBlock\": 65536, \"warpSize\": 32,\n+      \"sharedMemPerBlock\": 49152, \"numSms\": 132\n+    , \"regsPerMultiprocessor\": 65536, \"sharedMemPerBlockOptin\": 232448, \"sharedMemPerMultiprocessor\": 233472\n+    }\n+  ],\n+  \"cupti_version\": 24,\n+  \"cuda_runtime_version\": 12060,\n+  \"with_flops\": 1,\n+  \"record_shapes\": 1,\n+  \"cuda_driver_version\": 12040,\n+  \"profile_memory\": 1,\n+  \"trace_id\": \"301995E163ED42048FBD783860E6E7DC\",\n+  \"displayTimeUnit\": \"ms\",\n+  \"baseTimeNanoseconds\": 1743521598000000000,\n+  \"traceEvents\": [\n+  {\n+    \"ph\": \"X\", \"cat\": \"cpu_op\", \"name\": \"aten::convolution\", \"pid\": 1147039, \"tid\": 1147039,\n+    \"ts\": 198093488368.463, \"dur\": 425.453,\n+    \"args\": {\n+      \"External id\": 1340,\"Sequence number\": 0, \"Fwd thread id\": 0, \"Record function id\": 0, \"Concrete Inputs\": \\\n+[\"\", \"\", \"\", \"[2, 2]\", \"[3, 3]\", \"[1, 1]\", \"False\", \"[0, 0]\", \"1\"], \"Input type\": [\"float\", \"float\", \"\", \\\n+\"ScalarList\", \"ScalarList\", \"ScalarList\", \"Scalar\", \"ScalarList\", \"Scalar\"], \"Input Strides\": [[150528, 1, 672, 3],\\\n+[147, 1, 21, 3], [], [], [], [], [], [], []], \"Input Dims\": [[1, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], \\\n+[], []], \"Ev Idx\": 1339\n+    }\n+  },\n+  {\n+    \"ph\": \"X\", \"cat\": \"cpu_op\", \"name\": \"aten::_convolution\", \"pid\": 1147039, \"tid\": 1147039,\n+    \"ts\": 198093488444.498, \"dur\": 341.867,\n+    \"args\": {\n+      \"External id\": 1341,\"Record function id\": 0, \"Concrete Inputs\": [\"\", \"\", \"\", \"[2, 2]\", \"[3, 3]\", \"[1, 1]\",\\\n+ \"False\", \"[0, 0]\", \"1\", \"False\", \"False\", \"True\", \"True\"], \"Input type\": [\"float\", \"float\", \"\", \"ScalarList\",\\\n+ \"ScalarList\", \"ScalarList\", \"Scalar\", \"ScalarList\", \"Scalar\", \"Scalar\", \"Scalar\", \"Scalar\", \"Scalar\"], \"Input Strides\": \\\n+[[150528, 1, 672, 3], [147, 1, 21, 3], [], [], [], [], [], [], [], [], [], [], []], \"Input Dims\": [[1, 3, 224, 224], \\\n+[64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []], \"Ev Idx\": 1340\n+    }\n+  },\n+  {\n+    \"ph\": \"X\", \"cat\": \"cpu_op\", \"name\": \"aten::addmm\", \"pid\": 1147039, \"tid\": 1147039,\n+    \"ts\": 198093513655.849, \"dur\": 251.130,\n+    \"args\": {\n+      \"External id\": 1619,\"Sequence number\": 0, \"Fwd thread id\": 0, \"Record function id\": 0, \"Concrete Inputs\": \\\n+[\"\", \"\", \"\", \"1\", \"1\", \"\"], \"Input type\": [\"float\", \"float\", \"float\", \"Scalar\", \"Scalar\", \"float\"], \"Input Strides\":\\\n+ [[1], [0, 1], [1, 2048], [], [], [1000, 1]], \"Input Dims\": [[1000], [1, 2048], [2048, 1000], [], [], [1, 1000]], \\\n+\"Ev Idx\": 1618\n+    }\n+  },\n+  {\n+    \"ph\": \"X\", \"cat\": \"kernel\", \"name\": \"void cutlass_addmm\", \"pid\": 1147039, \"tid\": 1147039,\n+    \"ts\": 198093513655.849, \"dur\": 251.130,\n+    \"args\": {\n+      \"External id\": 1619,\"Sequence number\": 0, \"Fwd thread id\": 0, \"Record function id\": 0,  \"Ev Idx\": 1618\n+    }\n+  },\n+  {\n+    \"ph\": \"X\", \"cat\": \"kernel\", \"name\": \"void convolution_kernel\", \"pid\": 1147039, \"tid\": 1147039,\n+    \"ts\": 198093513655.849, \"dur\": 200.130,\n+    \"args\": {\n+      \"External id\": 1342, \"Sequence number\": 0, \"Fwd thread id\": 0, \"Record function id\": 0,  \"Ev Idx\": 1618\n+    }\n+  },\n+  {\n+    \"ph\": \"X\", \"cat\": \"cpu_op\", \"name\": \"aten::convolution\", \"pid\": 1147039, \"tid\": 1147039,\n+    \"ts\": 198093488444.498, \"dur\": 341.867,\n+    \"args\": {\n+      \"External id\": 1342,\"Record function id\": 0, \"Concrete Inputs\": [\"\", \"\", \"\", \"[2, 2]\", \"[3, 3]\", \"[1, 1]\", \\\n+\"False\", \"[0, 0]\", \"1\", \"False\", \"False\", \"True\", \"True\"], \"Input type\": [\"float\", \"float\", \"\", \"ScalarList\", \\\n+\"ScalarList\", \"ScalarList\", \"Scalar\", \"ScalarList\", \"Scalar\", \"Scalar\", \"Scalar\", \"Scalar\", \"Scalar\"], \"Input \\\n+Strides\": [[150528, 1, 672, 3], [147, 1, 21, 3], [], [], [], [], [], [], [], [], [], [], []], \"Input Dims\": \\\n+[[1, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []], \"Ev Idx\": 1340\n+    }\n+  }\n+],\n+  \"traceName\": \"/tmp/compiled_module_profile.json\"\n+}\n+\"\"\"\n+\n+\n+def verify_flops(self, expected_flops, out_profile):\n+    j = 0\n+    for i in range(len(out_profile[\"traceEvents\"])):\n+        if \"kernel_flop\" in out_profile[\"traceEvents\"][i][\"args\"]:\n+            self.assertEqual(\n+                out_profile[\"traceEvents\"][i][\"args\"][\"kernel_flop\"],\n+                expected_flops[j],\n+            )\n+            j += 1\n+\n+\n+def random_tensor(size, dtype, **kwargs):\n+    if dtype in [torch.half, torch.bfloat16, torch.float, torch.double]:\n+        return torch.randn(size, dtype=dtype, **kwargs)\n+    elif dtype in [torch.uint8, torch.int8, torch.short, torch.int, torch.long]:\n+        return torch.randint(0, 100, size, dtype=dtype, **kwargs)\n+    else:\n+        raise ValueError(\"Unsupported data type\")\n+\n+\n+def cT(device, dtype):\n+    def T(*shape, requires_grad=False):\n+        return random_tensor(\n+            shape, requires_grad=requires_grad, device=device, dtype=dtype\n+        )\n+\n+    return T\n+\n+\n+def FlopCounterMode(*args, **kwargs):\n+    return torch.utils.flop_counter.FlopCounterMode(*args, **kwargs, display=False)\n+\n+\n+TMP_DIR = tempfile.mkdtemp()\n+\n+\n+def trace_files():\n+    TRACE1 = f\"{TMP_DIR}/trace1-{uuid.uuid4()}.json\"\n+    TRACE2 = f\"{TMP_DIR}/trace2-{uuid.uuid4()}.json\"\n+    return TRACE1, TRACE2\n+\n+\n+def omni_model(device, dtype, compile=True, addmm=True, bmm=True):\n+    T = cT(device, dtype)\n+\n+    def model():\n+        input_conv = T(1, 3, 56, 56)\n+        conv_weight = T(12, 3, 5, 5)\n+\n+        # Increased matrix sizes\n+        B = 8\n+        M = 256\n+        N = 512\n+        K = 768\n+        mat1 = T(M, N)\n+        mat2 = T(N, K)\n+\n+        batch_mat1 = T(B, M, N)\n+        batch_mat2 = T(B, N, K)\n+\n+        conv_output = F.conv2d(input_conv, conv_weight)\n+\n+        conv_output = conv_output * 10\n+        mm_output = torch.mm(mat1, mat2)\n+        ret = [\n+            conv_output.flatten(),\n+            mm_output.flatten(),\n+        ]\n+\n+        if addmm:\n+            addmm_output = torch.addmm(\n+                torch.zeros(mm_output.shape, device=mat1.device, dtype=mat1.dtype),\n+                mat1,\n+                mat2,\n+            )\n+            ret.append(addmm_output.flatten())\n+\n+        if bmm:\n+            bmm_output = torch.bmm(batch_mat1, batch_mat2)\n+            ret.append(bmm_output.flatten())\n+\n+        if bmm and addmm:\n+            baddbmm_output = torch.baddbmm(\n+                torch.zeros(\n+                    1,\n+                    *mm_output.shape,\n+                    device=batch_mat1.device,\n+                    dtype=batch_mat1.dtype,\n+                ),\n+                batch_mat1,\n+                batch_mat2,\n+            )\n+            ret.append(baddbmm_output.flatten())\n+\n+        return torch.cat(ret)\n+\n+    if compile:\n+        return torch.compile(\n+            model, options={\"benchmark_kernel\": True, \"profile_bandwidth\": True}\n+        )\n+    return model\n+\n+\n+prefix = [\"profile.py\"]\n+\n+\n+class TestUtils(TestCase):\n+    def test_tabulate2d(self):\n+        headers = [\"Kernel\", \"Self H100 TIME (ms)\", \"Count\", \"Percent\"]\n+        rows = [\n+            [\"aten::mm\", 0.500, 7, 0.0],\n+            [\"aten::bmm\", 0.400, 6, 0.0],\n+            [\"aten::baddbmm\", 0.300, 5, 0.0],\n+            [\"aten::convolution\", 0.200, 4, 0.0],\n+            [\"aten::cudnn_convolution\", 0.100, 3, 0.0],\n+        ]\n+        table = [\n+            \" Kernel                  | Self H100 TIME (ms) | Count | Percent \",\n+            \"-----------------------------------------------------------------\",\n+            \" aten::mm                |                 0.5 |     7 |     0.0 \",\n+            \" aten::bmm               |                 0.4 |     6 |     0.0 \",\n+            \" aten::baddbmm           |                 0.3 |     5 |     0.0 \",\n+            \" aten::convolution       |                 0.2 |     4 |     0.0 \",\n+            \" aten::cudnn_convolution |                 0.1 |     3 |     0.0 \",\n+        ]\n+        res = tabulate_2d(rows, headers)\n+        for r, t in zip(res.split(\"\\n\"), table):\n+            self.assertEqual(r, t)\n+\n+    def test_zip_dicts(self):\n+        d1 = {\"a\": 1, \"b\": 2}\n+        d2 = {\"a\": 3, \"c\": 4}\n+        res = zip_dicts(d1, d2, d1_default=\"foo\", d2_default=\"bar\")\n+        self.assertEqual(set(res), {(\"a\", 1, 3), (\"b\", 2, \"bar\"), (\"c\", \"foo\", 4)})\n+        res = zip_dicts(d1, d2)\n+        self.assertEqual(set(res), {(\"a\", 1, 3), (\"b\", 2, None), (\"c\", None, 4)})\n+\n+\n+class TestAnalysis(TestCase):\n+    @skipIf(not SM70OrLater, \"Requires sm70\")\n+    def test_noop(self):\n+        with (\n+            patch(\"sys.stdout\", new_callable=StringIO) as mock_stdout,\n+            patch(\"sys.argv\", [*prefix]),\n+        ):\n+            main()\n+            self.assertEqual(mock_stdout.getvalue(), \"\")\n+\n+    @skipIf(not SM70OrLater, \"Requires sm70\")\n+    @dtypes(torch.float, torch.double, torch.float16)\n+    def test_diff(self, device, dtype):\n+        \"\"\"\n+        diff, testing out the nruns feature too.\n+        \"\"\"\n+        if device == \"cpu\":\n+            # TODO cpu support\n+            return\n+        om = omni_model(device, dtype)\n+        REPEAT = 5\n+        trace1, trace2 = trace_files()\n+        print(\"first trace\")\n+        torch._dynamo.reset()  # reset the cache\n+        with fresh_inductor_cache():\n+            with torch.profiler.profile(record_shapes=True) as p:\n+                om()\n+        p.export_chrome_trace(trace1)\n+\n+        print(\"second trace\")\n+        torch._dynamo.reset()  # reset the cache\n+        with fresh_inductor_cache():\n+            with torch.profiler.profile(record_shapes=True) as p:\n+                for _ in range(REPEAT):\n+                    om()\n+        p.export_chrome_trace(trace2)\n+\n+        print(\"diffing...\")\n+        with patch(",
        "comment_created_at": "2025-05-24T00:01:29+00:00",
        "comment_author": "eellison",
        "comment_body": "I ran this test and I see all the achieved bandwidth being < .10. this seems wrong - can we double check the numbers. I think i mentioned this in our 1-1 but anything <.01 or > 1 is probably off.",
        "pr_file_module": null
      },
      {
        "comment_id": "2117123016",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 149697,
        "pr_file": "test/inductor/test_analysis.py",
        "discussion_id": "2105535986",
        "commented_code": "@@ -0,0 +1,601 @@\n+# Owner(s): [\"module: inductor\"]\n+\n+import json\n+import re\n+import tempfile\n+import unittest\n+import uuid\n+from io import StringIO\n+from unittest.mock import patch\n+\n+import torch\n+import torch.nn.functional as F\n+from torch._inductor.analysis.profile_analysis import (\n+    _augment_trace_helper,\n+    _create_extern_mapping,\n+    JsonProfile,\n+    main,\n+)\n+from torch._inductor.utils import (\n+    fresh_inductor_cache,\n+    run_and_get_code,\n+    tabulate_2d,\n+    zip_dicts,\n+)\n+from torch.testing._internal.common_cuda import SM70OrLater\n+from torch.testing._internal.common_device_type import (\n+    dtypes,\n+    instantiate_device_type_tests,\n+    skipIf,\n+)\n+from torch.testing._internal.common_utils import parametrize, run_tests, TestCase\n+from torch.testing._internal.inductor_utils import IS_BIG_GPU\n+\n+\n+example_profile = \"\"\"\n+{\n+  \"schemaVersion\": 1,\n+  \"deviceProperties\": [\n+    {\n+      \"id\": 0, \"name\": \"NVIDIA H100\", \"totalGlobalMem\": 101997215744,\n+      \"computeMajor\": 9, \"computeMinor\": 0,\n+      \"maxThreadsPerBlock\": 1024, \"maxThreadsPerMultiprocessor\": 2048,\n+      \"regsPerBlock\": 65536, \"warpSize\": 32,\n+      \"sharedMemPerBlock\": 49152, \"numSms\": 132\n+    , \"regsPerMultiprocessor\": 65536, \"sharedMemPerBlockOptin\": 232448, \"sharedMemPerMultiprocessor\": 233472\n+    }\n+  ],\n+  \"cupti_version\": 24,\n+  \"cuda_runtime_version\": 12060,\n+  \"with_flops\": 1,\n+  \"record_shapes\": 1,\n+  \"cuda_driver_version\": 12040,\n+  \"profile_memory\": 1,\n+  \"trace_id\": \"301995E163ED42048FBD783860E6E7DC\",\n+  \"displayTimeUnit\": \"ms\",\n+  \"baseTimeNanoseconds\": 1743521598000000000,\n+  \"traceEvents\": [\n+  {\n+    \"ph\": \"X\", \"cat\": \"cpu_op\", \"name\": \"aten::convolution\", \"pid\": 1147039, \"tid\": 1147039,\n+    \"ts\": 198093488368.463, \"dur\": 425.453,\n+    \"args\": {\n+      \"External id\": 1340,\"Sequence number\": 0, \"Fwd thread id\": 0, \"Record function id\": 0, \"Concrete Inputs\": \\\n+[\"\", \"\", \"\", \"[2, 2]\", \"[3, 3]\", \"[1, 1]\", \"False\", \"[0, 0]\", \"1\"], \"Input type\": [\"float\", \"float\", \"\", \\\n+\"ScalarList\", \"ScalarList\", \"ScalarList\", \"Scalar\", \"ScalarList\", \"Scalar\"], \"Input Strides\": [[150528, 1, 672, 3],\\\n+[147, 1, 21, 3], [], [], [], [], [], [], []], \"Input Dims\": [[1, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], \\\n+[], []], \"Ev Idx\": 1339\n+    }\n+  },\n+  {\n+    \"ph\": \"X\", \"cat\": \"cpu_op\", \"name\": \"aten::_convolution\", \"pid\": 1147039, \"tid\": 1147039,\n+    \"ts\": 198093488444.498, \"dur\": 341.867,\n+    \"args\": {\n+      \"External id\": 1341,\"Record function id\": 0, \"Concrete Inputs\": [\"\", \"\", \"\", \"[2, 2]\", \"[3, 3]\", \"[1, 1]\",\\\n+ \"False\", \"[0, 0]\", \"1\", \"False\", \"False\", \"True\", \"True\"], \"Input type\": [\"float\", \"float\", \"\", \"ScalarList\",\\\n+ \"ScalarList\", \"ScalarList\", \"Scalar\", \"ScalarList\", \"Scalar\", \"Scalar\", \"Scalar\", \"Scalar\", \"Scalar\"], \"Input Strides\": \\\n+[[150528, 1, 672, 3], [147, 1, 21, 3], [], [], [], [], [], [], [], [], [], [], []], \"Input Dims\": [[1, 3, 224, 224], \\\n+[64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []], \"Ev Idx\": 1340\n+    }\n+  },\n+  {\n+    \"ph\": \"X\", \"cat\": \"cpu_op\", \"name\": \"aten::addmm\", \"pid\": 1147039, \"tid\": 1147039,\n+    \"ts\": 198093513655.849, \"dur\": 251.130,\n+    \"args\": {\n+      \"External id\": 1619,\"Sequence number\": 0, \"Fwd thread id\": 0, \"Record function id\": 0, \"Concrete Inputs\": \\\n+[\"\", \"\", \"\", \"1\", \"1\", \"\"], \"Input type\": [\"float\", \"float\", \"float\", \"Scalar\", \"Scalar\", \"float\"], \"Input Strides\":\\\n+ [[1], [0, 1], [1, 2048], [], [], [1000, 1]], \"Input Dims\": [[1000], [1, 2048], [2048, 1000], [], [], [1, 1000]], \\\n+\"Ev Idx\": 1618\n+    }\n+  },\n+  {\n+    \"ph\": \"X\", \"cat\": \"kernel\", \"name\": \"void cutlass_addmm\", \"pid\": 1147039, \"tid\": 1147039,\n+    \"ts\": 198093513655.849, \"dur\": 251.130,\n+    \"args\": {\n+      \"External id\": 1619,\"Sequence number\": 0, \"Fwd thread id\": 0, \"Record function id\": 0,  \"Ev Idx\": 1618\n+    }\n+  },\n+  {\n+    \"ph\": \"X\", \"cat\": \"kernel\", \"name\": \"void convolution_kernel\", \"pid\": 1147039, \"tid\": 1147039,\n+    \"ts\": 198093513655.849, \"dur\": 200.130,\n+    \"args\": {\n+      \"External id\": 1342, \"Sequence number\": 0, \"Fwd thread id\": 0, \"Record function id\": 0,  \"Ev Idx\": 1618\n+    }\n+  },\n+  {\n+    \"ph\": \"X\", \"cat\": \"cpu_op\", \"name\": \"aten::convolution\", \"pid\": 1147039, \"tid\": 1147039,\n+    \"ts\": 198093488444.498, \"dur\": 341.867,\n+    \"args\": {\n+      \"External id\": 1342,\"Record function id\": 0, \"Concrete Inputs\": [\"\", \"\", \"\", \"[2, 2]\", \"[3, 3]\", \"[1, 1]\", \\\n+\"False\", \"[0, 0]\", \"1\", \"False\", \"False\", \"True\", \"True\"], \"Input type\": [\"float\", \"float\", \"\", \"ScalarList\", \\\n+\"ScalarList\", \"ScalarList\", \"Scalar\", \"ScalarList\", \"Scalar\", \"Scalar\", \"Scalar\", \"Scalar\", \"Scalar\"], \"Input \\\n+Strides\": [[150528, 1, 672, 3], [147, 1, 21, 3], [], [], [], [], [], [], [], [], [], [], []], \"Input Dims\": \\\n+[[1, 3, 224, 224], [64, 3, 7, 7], [], [], [], [], [], [], [], [], [], [], []], \"Ev Idx\": 1340\n+    }\n+  }\n+],\n+  \"traceName\": \"/tmp/compiled_module_profile.json\"\n+}\n+\"\"\"\n+\n+\n+def verify_flops(self, expected_flops, out_profile):\n+    j = 0\n+    for i in range(len(out_profile[\"traceEvents\"])):\n+        if \"kernel_flop\" in out_profile[\"traceEvents\"][i][\"args\"]:\n+            self.assertEqual(\n+                out_profile[\"traceEvents\"][i][\"args\"][\"kernel_flop\"],\n+                expected_flops[j],\n+            )\n+            j += 1\n+\n+\n+def random_tensor(size, dtype, **kwargs):\n+    if dtype in [torch.half, torch.bfloat16, torch.float, torch.double]:\n+        return torch.randn(size, dtype=dtype, **kwargs)\n+    elif dtype in [torch.uint8, torch.int8, torch.short, torch.int, torch.long]:\n+        return torch.randint(0, 100, size, dtype=dtype, **kwargs)\n+    else:\n+        raise ValueError(\"Unsupported data type\")\n+\n+\n+def cT(device, dtype):\n+    def T(*shape, requires_grad=False):\n+        return random_tensor(\n+            shape, requires_grad=requires_grad, device=device, dtype=dtype\n+        )\n+\n+    return T\n+\n+\n+def FlopCounterMode(*args, **kwargs):\n+    return torch.utils.flop_counter.FlopCounterMode(*args, **kwargs, display=False)\n+\n+\n+TMP_DIR = tempfile.mkdtemp()\n+\n+\n+def trace_files():\n+    TRACE1 = f\"{TMP_DIR}/trace1-{uuid.uuid4()}.json\"\n+    TRACE2 = f\"{TMP_DIR}/trace2-{uuid.uuid4()}.json\"\n+    return TRACE1, TRACE2\n+\n+\n+def omni_model(device, dtype, compile=True, addmm=True, bmm=True):\n+    T = cT(device, dtype)\n+\n+    def model():\n+        input_conv = T(1, 3, 56, 56)\n+        conv_weight = T(12, 3, 5, 5)\n+\n+        # Increased matrix sizes\n+        B = 8\n+        M = 256\n+        N = 512\n+        K = 768\n+        mat1 = T(M, N)\n+        mat2 = T(N, K)\n+\n+        batch_mat1 = T(B, M, N)\n+        batch_mat2 = T(B, N, K)\n+\n+        conv_output = F.conv2d(input_conv, conv_weight)\n+\n+        conv_output = conv_output * 10\n+        mm_output = torch.mm(mat1, mat2)\n+        ret = [\n+            conv_output.flatten(),\n+            mm_output.flatten(),\n+        ]\n+\n+        if addmm:\n+            addmm_output = torch.addmm(\n+                torch.zeros(mm_output.shape, device=mat1.device, dtype=mat1.dtype),\n+                mat1,\n+                mat2,\n+            )\n+            ret.append(addmm_output.flatten())\n+\n+        if bmm:\n+            bmm_output = torch.bmm(batch_mat1, batch_mat2)\n+            ret.append(bmm_output.flatten())\n+\n+        if bmm and addmm:\n+            baddbmm_output = torch.baddbmm(\n+                torch.zeros(\n+                    1,\n+                    *mm_output.shape,\n+                    device=batch_mat1.device,\n+                    dtype=batch_mat1.dtype,\n+                ),\n+                batch_mat1,\n+                batch_mat2,\n+            )\n+            ret.append(baddbmm_output.flatten())\n+\n+        return torch.cat(ret)\n+\n+    if compile:\n+        return torch.compile(\n+            model, options={\"benchmark_kernel\": True, \"profile_bandwidth\": True}\n+        )\n+    return model\n+\n+\n+prefix = [\"profile.py\"]\n+\n+\n+class TestUtils(TestCase):\n+    def test_tabulate2d(self):\n+        headers = [\"Kernel\", \"Self H100 TIME (ms)\", \"Count\", \"Percent\"]\n+        rows = [\n+            [\"aten::mm\", 0.500, 7, 0.0],\n+            [\"aten::bmm\", 0.400, 6, 0.0],\n+            [\"aten::baddbmm\", 0.300, 5, 0.0],\n+            [\"aten::convolution\", 0.200, 4, 0.0],\n+            [\"aten::cudnn_convolution\", 0.100, 3, 0.0],\n+        ]\n+        table = [\n+            \" Kernel                  | Self H100 TIME (ms) | Count | Percent \",\n+            \"-----------------------------------------------------------------\",\n+            \" aten::mm                |                 0.5 |     7 |     0.0 \",\n+            \" aten::bmm               |                 0.4 |     6 |     0.0 \",\n+            \" aten::baddbmm           |                 0.3 |     5 |     0.0 \",\n+            \" aten::convolution       |                 0.2 |     4 |     0.0 \",\n+            \" aten::cudnn_convolution |                 0.1 |     3 |     0.0 \",\n+        ]\n+        res = tabulate_2d(rows, headers)\n+        for r, t in zip(res.split(\"\\n\"), table):\n+            self.assertEqual(r, t)\n+\n+    def test_zip_dicts(self):\n+        d1 = {\"a\": 1, \"b\": 2}\n+        d2 = {\"a\": 3, \"c\": 4}\n+        res = zip_dicts(d1, d2, d1_default=\"foo\", d2_default=\"bar\")\n+        self.assertEqual(set(res), {(\"a\", 1, 3), (\"b\", 2, \"bar\"), (\"c\", \"foo\", 4)})\n+        res = zip_dicts(d1, d2)\n+        self.assertEqual(set(res), {(\"a\", 1, 3), (\"b\", 2, None), (\"c\", None, 4)})\n+\n+\n+class TestAnalysis(TestCase):\n+    @skipIf(not SM70OrLater, \"Requires sm70\")\n+    def test_noop(self):\n+        with (\n+            patch(\"sys.stdout\", new_callable=StringIO) as mock_stdout,\n+            patch(\"sys.argv\", [*prefix]),\n+        ):\n+            main()\n+            self.assertEqual(mock_stdout.getvalue(), \"\")\n+\n+    @skipIf(not SM70OrLater, \"Requires sm70\")\n+    @dtypes(torch.float, torch.double, torch.float16)\n+    def test_diff(self, device, dtype):\n+        \"\"\"\n+        diff, testing out the nruns feature too.\n+        \"\"\"\n+        if device == \"cpu\":\n+            # TODO cpu support\n+            return\n+        om = omni_model(device, dtype)\n+        REPEAT = 5\n+        trace1, trace2 = trace_files()\n+        print(\"first trace\")\n+        torch._dynamo.reset()  # reset the cache\n+        with fresh_inductor_cache():\n+            with torch.profiler.profile(record_shapes=True) as p:\n+                om()\n+        p.export_chrome_trace(trace1)\n+\n+        print(\"second trace\")\n+        torch._dynamo.reset()  # reset the cache\n+        with fresh_inductor_cache():\n+            with torch.profiler.profile(record_shapes=True) as p:\n+                for _ in range(REPEAT):\n+                    om()\n+        p.export_chrome_trace(trace2)\n+\n+        print(\"diffing...\")\n+        with patch(",
        "comment_created_at": "2025-05-31T03:08:54+00:00",
        "comment_author": "exclamaforte",
        "comment_body": "I think it looks good now!\r\n```\r\n Kernel Name                    | foo Kernel Count | foo FLOPS          | foo Kernel Reads (GB) | foo Dur (us)       | foo Achieved FLOPS % | foo Achieved Bandwidth % | bar Kernel Count | bar FLOPS          | bar Kernel Reads (GB) | bar Dur (us)       | bar Achieved FLOPS % | bar Achieved Bandwidth % \r\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n void at::native::vectorized_el | 141              | 0                  | 2291.3034663102667    | 27.48305673758865  | 0                    | 68.39711839732142        | 140              | 0                  | 2296.773433304663     | 27.408307142857144 | 0                    | 68.56040099416907        \r\n triton_poi_fused_cat_8         | 78               | 0                  | 1574.7606227700633    | 9.219589743589747  | 0                    | 47.007779784181          | 78               | 0                  | 1562.5378211858626    | 9.225320512820513  | 0                    | 46.64292003539889        \r\n triton_poi_fused_zeros_4       | 20               | 0                  | 252.8315785679245     | 1.5600000000000003 | 0                    | 7.547211300535059        | 22               | 0                  | 247.92602043168762    | 1.591227272727273  | 0                    | 7.4007767293041065       \r\n nvjet_hsh_64x32_64x16_2x4_v_ba | 1                | 44306028169014.09  | 360.5633802816902     | 4.544              | 2.238808901920874    | 10.763085978557916       | 4                | 50766875540146.125 | 413.14189078894964    | 3.992              | 2.5652792086986422   | 12.332593754894019       \r\n triton_poi_fused_randn_5       | 22               | 0                  | 272.44196070060616    | 7.698772727272726  | 0                    | 8.13259584180914         | 24               | 0                  | 272.03694126279845    | 7.7105             | 0                    | 8.120505709337268        \r\n triton_poi_fused_randn_6       | 30               | 0                  | 328.2370610588902     | 19.173099999999998 | 0                    | 9.798121225638516        | 35               | 0                  | 327.5356462783756     | 19.21434285714286  | 0                    | 9.777183470996286        \r\n nvjet_hsh_96x128_64x6_2x1_v_bz | 1                | 227745013574660.62 | 1779.2579185520362    | 7.072              | 11.508085577294626   | 53.112176673195115       | 5                | 188095526438492.2  | 1469.4963003007203    | 8.633600000000001  | 9.504574352627197    | 43.86556120300658        \r\n triton_poi_fused_zeros_7       | 21               | 0                  | 253.7686410608481     | 1.5543333333333336 | 0                    | 7.575183315249197        | 22               | 0                  | 249.15748848030734    | 1.5841363636363637 | 0                    | 7.437536969561413        \r\n void at::native::elementwise_k | 3                | 0                  | 194.78879307640364    | 3.936              | 0                    | 5.814590838101601        | 13               | 0                  | 181.2755167170482     | 3.7068461538461532 | 0                    | 5.411209454240244        \r\n nvjet_hsh_96x128_64x6_2x1_v_ba | 1                | 167772160000000.0  | 1365.3333333333333    | 9.6                | 8.477623041940374    | 40.75621890547263        | 5                | 253727683090235.0  | 2064.84117098173      | 6.5405999999999995 | 12.82100470390273    | 61.63704988005164        \r\n triton_poi_fused_randn_1       | 86               | 0                  | 0.6861092067063755    | 2.8322325581395353 | 0                    | 0.020480871841981354     | 91               | 0                  | 0.7055919536190854    | 2.7624175824175823 | 0                    | 0.02106244637668912      \r\n void at::native::vectorized_el | 2                | 0                  | 9.567026991614258     | 1.568              | 0                    | 0.28558289527206737      | 7                | 0                  | 15.017761845823944    | 1.5178571428571428 | 0                    | 0.44829139838280435      \r\n void at::native::im2col_kernel | 1                | 551086956521.739   | 275.64538043478257    | 8.832              | 0.02784673858118944  | 8.228220311486046        | 3                | 540686595521.0607  | 270.4432767907672     | 9.002666666666668  | 0.027321202401266332 | 8.07293363554529         \r\n void cutlass::Kernel2<cutlass_ | 1                | 1216800000000.0    | 608.625               | 4.0                | 0.061485598787266296 | 18.167910447761194       | 4                | 1214465473575.7744 | 607.4573051077053     | 4.00825            | 0.06136763383404621  | 18.1330538838121         \r\n triton_poi_fused_randn_2       | 34               | 0                  | 96.43037673633363     | 2.7406764705882356 | 0                    | 2.878518708547272        | 37               | 0                  | 96.54534998578342     | 2.7354864864864865 | 0                    | 2.8819507458442812       \r\n triton_poi_fused_randn_3       | 30               | 0                  | 193.29281333769137    | 4.074533333333333  | 0                    | 5.769934726498249        | 36               | 0                  | 192.07911360388067    | 4.100305555555556  | 0                    | 5.733704883697929        \r\n nvjet_hsh_64x32_64x16_2x4_v_bz | 1                | 50737548387096.77  | 363.3548387096774     | 3.968              | 2.563797290909387    | 10.846413095811265       | 5                | 48275325180404.72  | 345.7217298075858     | 4.1857999999999995 | 2.4393797463569844   | 10.320051636047339       \r\n void at::native::(anonymous na | 1                | 0                  | 0.004464285714285714  | 2.016              | 0                    | 0.00013326226012793177   | 2                | 0                  | 0.003938381316098707  | 2.2880000000000003 | 0                    | 0.0001175636213760808    \r\n triton_poi_fused_randn_0       | 58               | 0                  | 6.133342468067014     | 3.646706896551724  | 0                    | 0.1830848497930452       | 70               | 0                  | 6.222644879418961     | 3.6446714285714283 | 0                    | 0.18575059341549136      \r\n ```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2176455141",
    "pr_number": 156610,
    "pr_file": "torch/_inductor/template_heuristics.py",
    "created_at": "2025-07-01T05:23:57+00:00",
    "commented_code": "return scaled_configs\n\n    def _prune_exhaustive_configs(\n        self,\n        configs: list[BaseConfig],\n        dtype_size: int,\n    ) -> list[BaseConfig]:\n        import torch\n\n        pruned_configs = []\n        for gemm_config in configs:\n            device = torch.cuda.current_device()\n            props = torch.cuda.get_device_properties(device)\n            sm_available = props.shared_memory_per_block_optin  # type: ignore[attr-defined]\n            NUM_REG = 255\n\n            acc_regs = math.ceil(\n                gemm_config.block_m * gemm_config.block_n / (gemm_config.num_warps * 32)\n            )\n\n            shared_mem_accum = dtype_size * (\n                gemm_config.block_m * gemm_config.block_k\n                + gemm_config.block_n * gemm_config.block_k\n            )\n\n            # Will use more shared memory than available\n            if shared_mem_accum * gemm_config.num_stages > sm_available:\n                continue\n            # Lower bound for register spillage, if exceeds the kernel will certainly spill\n            elif acc_regs > NUM_REG:\n                continue",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2176455141",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156610,
        "pr_file": "torch/_inductor/template_heuristics.py",
        "discussion_id": "2176455141",
        "commented_code": "@@ -519,6 +520,40 @@ def _scale_mm_configs(\n \n         return scaled_configs\n \n+    def _prune_exhaustive_configs(\n+        self,\n+        configs: list[BaseConfig],\n+        dtype_size: int,\n+    ) -> list[BaseConfig]:\n+        import torch\n+\n+        pruned_configs = []\n+        for gemm_config in configs:\n+            device = torch.cuda.current_device()\n+            props = torch.cuda.get_device_properties(device)\n+            sm_available = props.shared_memory_per_block_optin  # type: ignore[attr-defined]\n+            NUM_REG = 255\n+\n+            acc_regs = math.ceil(\n+                gemm_config.block_m * gemm_config.block_n / (gemm_config.num_warps * 32)\n+            )\n+\n+            shared_mem_accum = dtype_size * (\n+                gemm_config.block_m * gemm_config.block_k\n+                + gemm_config.block_n * gemm_config.block_k\n+            )\n+\n+            # Will use more shared memory than available\n+            if shared_mem_accum * gemm_config.num_stages > sm_available:\n+                continue\n+            # Lower bound for register spillage, if exceeds the kernel will certainly spill\n+            elif acc_regs > NUM_REG:\n+                continue",
        "comment_created_at": "2025-07-01T05:23:57+00:00",
        "comment_author": "nmacchioni",
        "comment_body": "If I understand correctly this prunes all spilling config, are we sure we want to do this? Spilled registers does not necessarily mean that performance is bad, although we could potentially prune when # spilled >> some metric.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2165669923",
    "pr_number": 156785,
    "pr_file": "torch/_inductor/kernel/mm.py",
    "created_at": "2025-06-25T04:13:25+00:00",
    "commented_code": "mm_configs = V.choices.get_base_mm_configs(device_type)\n    persistent_mm_configs = V.choices.get_persistent_mm_configs(device_type)\n    extra_mm_configs = V.choices.get_extra_mm_configs(device_type)\n    lookup_dict = get_lookup_table([mat1, mat2], name)",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2165669923",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156785,
        "pr_file": "torch/_inductor/kernel/mm.py",
        "discussion_id": "2165669923",
        "commented_code": "@@ -696,14 +699,18 @@ def tuned_mm(mat1, mat2, *, layout=None):\n     mm_configs = V.choices.get_base_mm_configs(device_type)\n     persistent_mm_configs = V.choices.get_persistent_mm_configs(device_type)\n     extra_mm_configs = V.choices.get_extra_mm_configs(device_type)\n+    lookup_dict = get_lookup_table([mat1, mat2], name)",
        "comment_created_at": "2025-06-25T04:13:25+00:00",
        "comment_author": "jansel",
        "comment_body": "Do we need to take into account the epilogue in the lookup table?",
        "pr_file_module": null
      },
      {
        "comment_id": "2165867537",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156785,
        "pr_file": "torch/_inductor/kernel/mm.py",
        "discussion_id": "2165669923",
        "commented_code": "@@ -696,14 +699,18 @@ def tuned_mm(mat1, mat2, *, layout=None):\n     mm_configs = V.choices.get_base_mm_configs(device_type)\n     persistent_mm_configs = V.choices.get_persistent_mm_configs(device_type)\n     extra_mm_configs = V.choices.get_extra_mm_configs(device_type)\n+    lookup_dict = get_lookup_table([mat1, mat2], name)",
        "comment_created_at": "2025-06-25T06:11:01+00:00",
        "comment_author": "coconutruben",
        "comment_body": "IIUC no. This is if you mean the template epilogue (e.g. addmm) because the table is function specific right now, so config e.g. for addmm will be picked specifically for addmm, and is found in the lookup table under the addmm key.",
        "pr_file_module": null
      },
      {
        "comment_id": "2166929857",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156785,
        "pr_file": "torch/_inductor/kernel/mm.py",
        "discussion_id": "2165669923",
        "commented_code": "@@ -696,14 +699,18 @@ def tuned_mm(mat1, mat2, *, layout=None):\n     mm_configs = V.choices.get_base_mm_configs(device_type)\n     persistent_mm_configs = V.choices.get_persistent_mm_configs(device_type)\n     extra_mm_configs = V.choices.get_extra_mm_configs(device_type)\n+    lookup_dict = get_lookup_table([mat1, mat2], name)",
        "comment_created_at": "2025-06-25T14:50:42+00:00",
        "comment_author": "jansel",
        "comment_body": "But doesn't the autotuning measure using the epilogue?  I recall @eellison added that.  This can affect the performance (sometimes a lot of the epilogue causes register spills).",
        "pr_file_module": null
      },
      {
        "comment_id": "2167362851",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156785,
        "pr_file": "torch/_inductor/kernel/mm.py",
        "discussion_id": "2165669923",
        "commented_code": "@@ -696,14 +699,18 @@ def tuned_mm(mat1, mat2, *, layout=None):\n     mm_configs = V.choices.get_base_mm_configs(device_type)\n     persistent_mm_configs = V.choices.get_persistent_mm_configs(device_type)\n     extra_mm_configs = V.choices.get_extra_mm_configs(device_type)\n+    lookup_dict = get_lookup_table([mat1, mat2], name)",
        "comment_created_at": "2025-06-25T18:36:37+00:00",
        "comment_author": "coconutruben",
        "comment_body": "IIUC what @eellison explained to me this should be safe because it happens in two stages. We first find the best config (here) and then we benchmark using that best config + epilogue vs not fusing the epilogue. So in this stage we're not interfering with that decision. We don't do a NxN comparison of configs + epilogue vs configs",
        "pr_file_module": null
      },
      {
        "comment_id": "2167450658",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156785,
        "pr_file": "torch/_inductor/kernel/mm.py",
        "discussion_id": "2165669923",
        "commented_code": "@@ -696,14 +699,18 @@ def tuned_mm(mat1, mat2, *, layout=None):\n     mm_configs = V.choices.get_base_mm_configs(device_type)\n     persistent_mm_configs = V.choices.get_persistent_mm_configs(device_type)\n     extra_mm_configs = V.choices.get_extra_mm_configs(device_type)\n+    lookup_dict = get_lookup_table([mat1, mat2], name)",
        "comment_created_at": "2025-06-25T19:21:28+00:00",
        "comment_author": "PaulZhang12",
        "comment_body": "@jansel It depends on how we construct the lookup table. If we take the autotune logs for example, then it is not fusion aware. However, if we look at whether the scheduler does a fusion with a certain config in a previous max-autotune run, we can use that config in the lookup table.\r\n\r\nThe lookup table just uses whichever config(s) we give it. There is no benchmarking of epilogues by default as that can lead to significant compile time overhead.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2175414212",
    "pr_number": 156851,
    "pr_file": "torch/_inductor/models/mm_kernel_prediction_model.py",
    "created_at": "2025-06-30T15:55:10+00:00",
    "commented_code": "\"\"\"\nNeural network model for predicting triton kernel performance.\n\nThis module provides functionality to load and use a pre-trained neural network\nfor predicting the performance of triton kernels.\n\"\"\"\n\nimport os\nimport time\nfrom collections.abc import Sequence\nfrom typing import Any\n\nimport numpy as np\nimport pandas as pd  # type: ignore[import-untyped]\n\nimport torch\nimport torch.nn as nn\nfrom torch._inductor.kernel_lut import TritonGEMMConfig\n\n# Default model path - can be overridden by environment variable\nscript_dir = os.path.dirname(__file__)\nDEFAULT_MODEL_PATH = os.path.join(os.path.dirname(__file__), \"aoti_mm_model.pt2\")\nMODEL_PATH = os.environ.get(\"TRITON_KERNEL_SELECTION_MODEL_PATH\", DEFAULT_MODEL_PATH)\nimport logging\n\n\nlog = logging.getLogger(__name__)\n# turn on info logging\nlogging.basicConfig(level=logging.INFO)\n\n\nclass NeuralNetwork(nn.Module):\n    \"\"\"\n    Multilayer perceptron with a single output.\n\n    It is designed for modeling runtime when there is a constant overhead of\n    `kernel_overhead` and the non-overhead runtime tends to be easier to model\n    on a log scale (e.g.  doubling a dimension involved in a matrix\n    multiplication results in runtime roughly doubling.)\n    \"\"\"\n\n    def __init__(\n        self,\n        n_inputs: int,\n        hidden_layer_widths: Sequence[int],\n        kernel_overhead: float = 0.00541,\n    ) -> None:\n        \"\"\"\n        Args:\n            n_inputs: Number of inputs\n            hidden_layer_widths: Hidden layer widths\n            kernel_overhead: Overhead of the kernel, assumed to be constant. The\n                default of 0.00541 is the lowest runtime seen in Triton H100 data.\n        \"\"\"\n        super().__init__()\n        self.n_inputs = n_inputs\n        self.kernel_overhead = kernel_overhead\n        self.log_kernel_overhead: float = torch.log(\n            torch.tensor(kernel_overhead, device=\"cuda\")\n        ).item()\n        all_layer_widths = list(hidden_layer_widths) + [1]\n        all_input_widths = [n_inputs] + list(hidden_layer_widths)\n        layers: list[nn.Module] = []\n        for n_in, n_out in zip(all_input_widths, all_layer_widths, strict=True):\n            layers.append(nn.Linear(n_in, n_out))\n            layers.append(nn.BatchNorm1d(n_out))\n            layers.append(nn.ReLU())\n\n        self.linear_relu_stack = nn.Sequential(*layers[:-2])\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Predict as log(exp(inputs) + self.kernel_overhead).\n\n        Works well for predicting log(runtime) when runtime contains a constant\n        overhead of `kernel_overhead`. (The log specification means that this\n        wouldn't be trivially modeled with a bias term.)\n\n        Probably could have fit the overhead rather than hard-coding it by\n        having `self.kernel_overhead` be a tunable parameter or by having exp\n        and log layers.\n        \"\"\"\n        log_base_pred = self.linear_relu_stack(x)\n        log_overhead_tsr = torch.full_like(\n            input=log_base_pred, fill_value=self.log_kernel_overhead, device=\"cuda\"\n        )\n        return torch.logsumexp(\n            torch.stack([log_base_pred, log_overhead_tsr], dim=-1), dim=-1\n        )\n\n\ndef get_nn_x(\n    df: pd.DataFrame, mean: torch.Tensor | None = None, std: torch.Tensor | None = None\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Standardize the data and convert it to a tensor.\"\"\"\n    x_df = df[\n        [\n            \"dtype_size\",\n            \"dim_m\",\n            \"dim_n\",\n            \"dim_k\",\n            \"total_gb\",\n            \"total_gflop\",\n            \"flops_per_byte\",\n            \"config_block_k\",\n            \"config_block_m\",\n            \"config_block_n\",\n            \"config_num_stages\",\n            \"config_num_warps\",\n        ]\n    ].copy()\n    for col in x_df.columns:\n        x_df[col] = np.log(x_df[col])\n\n    x_tens = torch.from_numpy(x_df.astype(float).to_numpy()).to(device=\"cuda\")\n    if mean is None:\n        mean = torch.from_numpy(x_df.mean().to_numpy()).to(device=\"cuda\")\n    if std is None:\n        std = torch.from_numpy(x_df.std().to_numpy()).to(device=\"cuda\")\n    x_tens -= mean\n    x_tens /= std\n    return x_tens.to(torch.float32), mean, std\n\n\ndef get_total_gb_feature(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Calculate the total gigabytes feature from the dataframe.\n\n    Args:\n        df: DataFrame containing the necessary columns for calculation\n\n    Returns:\n        Series containing the calculated total gigabytes\n    \"\"\"\n    # Calculate memory access in bytes\n    m, n, k = df[\"dim_m\"], df[\"dim_n\"], df[\"dim_k\"]\n    dtype_size = df[\"dtype_size\"] / 8  # Convert bits to bytes\n\n    # A: m\u00d7k, B: k\u00d7n, C: m\u00d7n\n    return ((m * k + k * n + m * n) * dtype_size) / 1e9  # Convert to GB\n\n\ndef get_total_gflop_feature(df: pd.DataFrame) -> pd.Series:\n    \"\"\"\n    Calculate the total gigaflops feature from the dataframe.\n\n    Args:\n        df: DataFrame containing the necessary columns for calculation\n\n    Returns:\n        Series containing the calculated total gigaflops\n    \"\"\"\n    # For matrix multiplication, flops = 2 * m * n * k\n    m, n, k = df[\"dim_m\"], df[\"dim_n\"], df[\"dim_k\"]\n    return (2 * m * n * k) / 1e9  # Convert to GFLOP\n\n\nclass ModelWrapper:\n    \"\"\"\n    Wrapper for the neural network model that handles encoding inputs and decoding outputs.\n\n    This class provides methods to prepare inputs for the model and interpret its outputs,\n    handling the necessary standardization and feature engineering.\n    \"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Initialize the model wrapper with the pre-trained model and standardization parameters.\"\"\"\n        start_time = time.time()\n        self.model = NeuralNetwork(\n            n_inputs=12, hidden_layer_widths=[2**8 for _ in range(6)]\n        )\n        self.model: NeuralNetwork = torch._inductor.aoti_load_package(MODEL_PATH)\n        end_time = time.time()\n\n        log.info(\"NN Kernel Prediction Model loaded.\")\n        log.info(\"Took: %s seconds\", end_time - start_time)\n\n        # Mean values for standardizing input features\n        self.mean_for_standardization = torch.tensor(\n            [\n                2.78275084,\n                8.23996746,\n                7.27791873,\n                7.92035942,\n                -2.39558163,\n                3.40679233,\n                5.80237395,\n                3.95781827,\n                4.19478321,\n                4.19098234,\n                0.9045909,\n                1.28331208,\n            ],\n            device=\"cuda\",\n        )\n\n        # Standard deviation values for standardizing input features\n        self.std_for_standardization = torch.tensor(\n            [\n                0.08322756,\n                2.31893439,\n                1.65605574,\n                2.15447078,\n                2.19682881,\n                2.99600806,\n                1.24328795,\n                0.92352521,\n                0.93849802,\n                0.93872011,\n                0.57455891,\n                0.5837217,\n            ],\n            device=\"cuda\",\n        )\n\n    def vec(\n        self, m: int, n: int, k: int, dsize: int, config: Any\n    ) -> tuple[int, int, int, int, int, int, int, int, int]:\n        \"\"\"\n        Convert matrix multiplication parameters and config to a feature vector.\n\n        Args:\n            m: First dimension of matrix multiplication\n            n: Second dimension of matrix multiplication\n            k: Third dimension of matrix multiplication\n            dsize: Data size in bits (e.g., 16 for float16, 32 for float32)\n            config: Configuration object containing kernel parameters\n\n        Returns:\n            Tuple containing the extracted features\n        \"\"\"\n        kwargs = config.all_kwargs()\n\n        return (\n            int(m),\n            int(n),\n            int(k),\n            int(dsize),\n            int(kwargs[\"BLOCK_M\"]),\n            int(kwargs[\"BLOCK_N\"]),\n            int(kwargs[\"BLOCK_K\"]),\n            int(kwargs[\"num_stages\"]),\n            int(kwargs[\"num_warps\"]),\n        )\n\n    @staticmethod\n    def vec_params(\n        m: int, n: int, k: int, dsize: int, params: TritonGEMMConfig\n    ) -> tuple[int, int, int, int, int, int, int, int, int]:\n        \"\"\"\n        Convert matrix multiplication parameters and config to a feature vector.\n\n        Args:\n            m: First dimension of matrix multiplication\n            n: Second dimension of matrix multiplication\n            k: Third dimension of matrix multiplication\n            dsize: Data size in bits (e.g., 16 for float16, 32 for float32)\n            config: Configuration object containing kernel parameters\n\n        Returns:\n            Tuple containing the extracted features\n        \"\"\"\n\n        return (\n            int(m),\n            int(n),\n            int(k),\n            int(dsize),\n            int(params.block_m),\n            int(params.block_n),\n            int(params.block_k),\n            int(params.num_stages),\n            int(params.num_warps),\n        )\n\n    def encode(\n        self, m: int, n: int, k: int, dtype: torch.dtype, configs: list[Any]\n    ) -> torch.Tensor:\n        \"\"\"\n        Encode the matrix multiplication parameters and configs as input tensors for the model.\n\n        Args:\n            m: First dimension of matrix multiplication\n            n: Second dimension of matrix multiplication\n            k: Third dimension of matrix multiplication\n            dtype: Data type of the matrices\n            configs: List of configuration objects\n\n        Returns:\n            Tensor containing the encoded inputs ready for the model\n\n        Raises:\n            ValueError: If the dtype is not supported\n        \"\"\"\n        # Determine data size based on dtype\n        if dtype == torch.bfloat16 or dtype == torch.float16:\n            dsize = 16\n        elif dtype == torch.float32:\n            dsize = 32\n        else:\n            raise ValueError(f\"Unsupported dtype: {dtype}. Add support for this dtype.\")\n\n        # Create feature dataframe\n        df = pd.DataFrame(",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2175414212",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 156851,
        "pr_file": "torch/_inductor/models/mm_kernel_prediction_model.py",
        "discussion_id": "2175414212",
        "commented_code": "@@ -0,0 +1,364 @@\n+\"\"\"\n+Neural network model for predicting triton kernel performance.\n+\n+This module provides functionality to load and use a pre-trained neural network\n+for predicting the performance of triton kernels.\n+\"\"\"\n+\n+import os\n+import time\n+from collections.abc import Sequence\n+from typing import Any\n+\n+import numpy as np\n+import pandas as pd  # type: ignore[import-untyped]\n+\n+import torch\n+import torch.nn as nn\n+from torch._inductor.kernel_lut import TritonGEMMConfig\n+\n+# Default model path - can be overridden by environment variable\n+script_dir = os.path.dirname(__file__)\n+DEFAULT_MODEL_PATH = os.path.join(os.path.dirname(__file__), \"aoti_mm_model.pt2\")\n+MODEL_PATH = os.environ.get(\"TRITON_KERNEL_SELECTION_MODEL_PATH\", DEFAULT_MODEL_PATH)\n+import logging\n+\n+\n+log = logging.getLogger(__name__)\n+# turn on info logging\n+logging.basicConfig(level=logging.INFO)\n+\n+\n+class NeuralNetwork(nn.Module):\n+    \"\"\"\n+    Multilayer perceptron with a single output.\n+\n+    It is designed for modeling runtime when there is a constant overhead of\n+    `kernel_overhead` and the non-overhead runtime tends to be easier to model\n+    on a log scale (e.g.  doubling a dimension involved in a matrix\n+    multiplication results in runtime roughly doubling.)\n+    \"\"\"\n+\n+    def __init__(\n+        self,\n+        n_inputs: int,\n+        hidden_layer_widths: Sequence[int],\n+        kernel_overhead: float = 0.00541,\n+    ) -> None:\n+        \"\"\"\n+        Args:\n+            n_inputs: Number of inputs\n+            hidden_layer_widths: Hidden layer widths\n+            kernel_overhead: Overhead of the kernel, assumed to be constant. The\n+                default of 0.00541 is the lowest runtime seen in Triton H100 data.\n+        \"\"\"\n+        super().__init__()\n+        self.n_inputs = n_inputs\n+        self.kernel_overhead = kernel_overhead\n+        self.log_kernel_overhead: float = torch.log(\n+            torch.tensor(kernel_overhead, device=\"cuda\")\n+        ).item()\n+        all_layer_widths = list(hidden_layer_widths) + [1]\n+        all_input_widths = [n_inputs] + list(hidden_layer_widths)\n+        layers: list[nn.Module] = []\n+        for n_in, n_out in zip(all_input_widths, all_layer_widths, strict=True):\n+            layers.append(nn.Linear(n_in, n_out))\n+            layers.append(nn.BatchNorm1d(n_out))\n+            layers.append(nn.ReLU())\n+\n+        self.linear_relu_stack = nn.Sequential(*layers[:-2])\n+\n+    def forward(self, x: torch.Tensor) -> torch.Tensor:\n+        \"\"\"\n+        Predict as log(exp(inputs) + self.kernel_overhead).\n+\n+        Works well for predicting log(runtime) when runtime contains a constant\n+        overhead of `kernel_overhead`. (The log specification means that this\n+        wouldn't be trivially modeled with a bias term.)\n+\n+        Probably could have fit the overhead rather than hard-coding it by\n+        having `self.kernel_overhead` be a tunable parameter or by having exp\n+        and log layers.\n+        \"\"\"\n+        log_base_pred = self.linear_relu_stack(x)\n+        log_overhead_tsr = torch.full_like(\n+            input=log_base_pred, fill_value=self.log_kernel_overhead, device=\"cuda\"\n+        )\n+        return torch.logsumexp(\n+            torch.stack([log_base_pred, log_overhead_tsr], dim=-1), dim=-1\n+        )\n+\n+\n+def get_nn_x(\n+    df: pd.DataFrame, mean: torch.Tensor | None = None, std: torch.Tensor | None = None\n+) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n+    \"\"\"Standardize the data and convert it to a tensor.\"\"\"\n+    x_df = df[\n+        [\n+            \"dtype_size\",\n+            \"dim_m\",\n+            \"dim_n\",\n+            \"dim_k\",\n+            \"total_gb\",\n+            \"total_gflop\",\n+            \"flops_per_byte\",\n+            \"config_block_k\",\n+            \"config_block_m\",\n+            \"config_block_n\",\n+            \"config_num_stages\",\n+            \"config_num_warps\",\n+        ]\n+    ].copy()\n+    for col in x_df.columns:\n+        x_df[col] = np.log(x_df[col])\n+\n+    x_tens = torch.from_numpy(x_df.astype(float).to_numpy()).to(device=\"cuda\")\n+    if mean is None:\n+        mean = torch.from_numpy(x_df.mean().to_numpy()).to(device=\"cuda\")\n+    if std is None:\n+        std = torch.from_numpy(x_df.std().to_numpy()).to(device=\"cuda\")\n+    x_tens -= mean\n+    x_tens /= std\n+    return x_tens.to(torch.float32), mean, std\n+\n+\n+def get_total_gb_feature(df: pd.DataFrame) -> pd.Series:\n+    \"\"\"\n+    Calculate the total gigabytes feature from the dataframe.\n+\n+    Args:\n+        df: DataFrame containing the necessary columns for calculation\n+\n+    Returns:\n+        Series containing the calculated total gigabytes\n+    \"\"\"\n+    # Calculate memory access in bytes\n+    m, n, k = df[\"dim_m\"], df[\"dim_n\"], df[\"dim_k\"]\n+    dtype_size = df[\"dtype_size\"] / 8  # Convert bits to bytes\n+\n+    # A: m\u00d7k, B: k\u00d7n, C: m\u00d7n\n+    return ((m * k + k * n + m * n) * dtype_size) / 1e9  # Convert to GB\n+\n+\n+def get_total_gflop_feature(df: pd.DataFrame) -> pd.Series:\n+    \"\"\"\n+    Calculate the total gigaflops feature from the dataframe.\n+\n+    Args:\n+        df: DataFrame containing the necessary columns for calculation\n+\n+    Returns:\n+        Series containing the calculated total gigaflops\n+    \"\"\"\n+    # For matrix multiplication, flops = 2 * m * n * k\n+    m, n, k = df[\"dim_m\"], df[\"dim_n\"], df[\"dim_k\"]\n+    return (2 * m * n * k) / 1e9  # Convert to GFLOP\n+\n+\n+class ModelWrapper:\n+    \"\"\"\n+    Wrapper for the neural network model that handles encoding inputs and decoding outputs.\n+\n+    This class provides methods to prepare inputs for the model and interpret its outputs,\n+    handling the necessary standardization and feature engineering.\n+    \"\"\"\n+\n+    def __init__(self) -> None:\n+        \"\"\"Initialize the model wrapper with the pre-trained model and standardization parameters.\"\"\"\n+        start_time = time.time()\n+        self.model = NeuralNetwork(\n+            n_inputs=12, hidden_layer_widths=[2**8 for _ in range(6)]\n+        )\n+        self.model: NeuralNetwork = torch._inductor.aoti_load_package(MODEL_PATH)\n+        end_time = time.time()\n+\n+        log.info(\"NN Kernel Prediction Model loaded.\")\n+        log.info(\"Took: %s seconds\", end_time - start_time)\n+\n+        # Mean values for standardizing input features\n+        self.mean_for_standardization = torch.tensor(\n+            [\n+                2.78275084,\n+                8.23996746,\n+                7.27791873,\n+                7.92035942,\n+                -2.39558163,\n+                3.40679233,\n+                5.80237395,\n+                3.95781827,\n+                4.19478321,\n+                4.19098234,\n+                0.9045909,\n+                1.28331208,\n+            ],\n+            device=\"cuda\",\n+        )\n+\n+        # Standard deviation values for standardizing input features\n+        self.std_for_standardization = torch.tensor(\n+            [\n+                0.08322756,\n+                2.31893439,\n+                1.65605574,\n+                2.15447078,\n+                2.19682881,\n+                2.99600806,\n+                1.24328795,\n+                0.92352521,\n+                0.93849802,\n+                0.93872011,\n+                0.57455891,\n+                0.5837217,\n+            ],\n+            device=\"cuda\",\n+        )\n+\n+    def vec(\n+        self, m: int, n: int, k: int, dsize: int, config: Any\n+    ) -> tuple[int, int, int, int, int, int, int, int, int]:\n+        \"\"\"\n+        Convert matrix multiplication parameters and config to a feature vector.\n+\n+        Args:\n+            m: First dimension of matrix multiplication\n+            n: Second dimension of matrix multiplication\n+            k: Third dimension of matrix multiplication\n+            dsize: Data size in bits (e.g., 16 for float16, 32 for float32)\n+            config: Configuration object containing kernel parameters\n+\n+        Returns:\n+            Tuple containing the extracted features\n+        \"\"\"\n+        kwargs = config.all_kwargs()\n+\n+        return (\n+            int(m),\n+            int(n),\n+            int(k),\n+            int(dsize),\n+            int(kwargs[\"BLOCK_M\"]),\n+            int(kwargs[\"BLOCK_N\"]),\n+            int(kwargs[\"BLOCK_K\"]),\n+            int(kwargs[\"num_stages\"]),\n+            int(kwargs[\"num_warps\"]),\n+        )\n+\n+    @staticmethod\n+    def vec_params(\n+        m: int, n: int, k: int, dsize: int, params: TritonGEMMConfig\n+    ) -> tuple[int, int, int, int, int, int, int, int, int]:\n+        \"\"\"\n+        Convert matrix multiplication parameters and config to a feature vector.\n+\n+        Args:\n+            m: First dimension of matrix multiplication\n+            n: Second dimension of matrix multiplication\n+            k: Third dimension of matrix multiplication\n+            dsize: Data size in bits (e.g., 16 for float16, 32 for float32)\n+            config: Configuration object containing kernel parameters\n+\n+        Returns:\n+            Tuple containing the extracted features\n+        \"\"\"\n+\n+        return (\n+            int(m),\n+            int(n),\n+            int(k),\n+            int(dsize),\n+            int(params.block_m),\n+            int(params.block_n),\n+            int(params.block_k),\n+            int(params.num_stages),\n+            int(params.num_warps),\n+        )\n+\n+    def encode(\n+        self, m: int, n: int, k: int, dtype: torch.dtype, configs: list[Any]\n+    ) -> torch.Tensor:\n+        \"\"\"\n+        Encode the matrix multiplication parameters and configs as input tensors for the model.\n+\n+        Args:\n+            m: First dimension of matrix multiplication\n+            n: Second dimension of matrix multiplication\n+            k: Third dimension of matrix multiplication\n+            dtype: Data type of the matrices\n+            configs: List of configuration objects\n+\n+        Returns:\n+            Tensor containing the encoded inputs ready for the model\n+\n+        Raises:\n+            ValueError: If the dtype is not supported\n+        \"\"\"\n+        # Determine data size based on dtype\n+        if dtype == torch.bfloat16 or dtype == torch.float16:\n+            dsize = 16\n+        elif dtype == torch.float32:\n+            dsize = 32\n+        else:\n+            raise ValueError(f\"Unsupported dtype: {dtype}. Add support for this dtype.\")\n+\n+        # Create feature dataframe\n+        df = pd.DataFrame(",
        "comment_created_at": "2025-06-30T15:55:10+00:00",
        "comment_author": "esantorella",
        "comment_body": "Not something that needs to be addressed right now, but I wonder if a lot of the overhead we're seeing is from using Pandas, which can be super slow and may introduce a new dependency. We can easily rewrite this to use solely PyTorch.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2064234144",
    "pr_number": 152197,
    "pr_file": "torch/_inductor/runtime/triton_heuristics.py",
    "created_at": "2025-04-28T18:12:34+00:00",
    "commented_code": "if autotune_cache:\n            if best_config := autotune_cache.read_best(inductor_meta, configs):\n                configs = [best_config]\n\n                autotune_cache_info[\"best_config\"] = triton_config_to_hashable(\n                    best_config\n                )\n                autotune_cache_info[\"autotune_cache_state\"] = \"hit\"\n            else:\n                autotune_cache_info[\"autotune_cache_state\"] = \"miss\"\n                autotune_cache_info[\"num_configs\"] = len(configs)\n                if inductor_meta.get(\"coordinate_descent_tuning\"):\n                    autotune_cache_info[\"coordesc_tuning\"] = True\n                    if len(configs) == 1:",
    "repo_full_name": "pytorch/pytorch",
    "discussion_comments": [
      {
        "comment_id": "2064234144",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 152197,
        "pr_file": "torch/_inductor/runtime/triton_heuristics.py",
        "discussion_id": "2064234144",
        "commented_code": "@@ -1698,9 +1701,28 @@ def cached_autotune(\n         if autotune_cache:\n             if best_config := autotune_cache.read_best(inductor_meta, configs):\n                 configs = [best_config]\n-\n+                autotune_cache_info[\"best_config\"] = triton_config_to_hashable(\n+                    best_config\n+                )\n+                autotune_cache_info[\"autotune_cache_state\"] = \"hit\"\n+            else:\n+                autotune_cache_info[\"autotune_cache_state\"] = \"miss\"\n+                autotune_cache_info[\"num_configs\"] = len(configs)\n+                if inductor_meta.get(\"coordinate_descent_tuning\"):\n+                    autotune_cache_info[\"coordesc_tuning\"] = True\n+                    if len(configs) == 1:",
        "comment_created_at": "2025-04-28T18:12:34+00:00",
        "comment_author": "bdhirsh",
        "comment_body": "basic question: given that we are logging the results of autotuning, what does it actually mean for there to be more than one config here? (shouldn't autotuning always end in a single config we can log?) ",
        "pr_file_module": null
      },
      {
        "comment_id": "2066787922",
        "repo_full_name": "pytorch/pytorch",
        "pr_number": 152197,
        "pr_file": "torch/_inductor/runtime/triton_heuristics.py",
        "discussion_id": "2064234144",
        "commented_code": "@@ -1698,9 +1701,28 @@ def cached_autotune(\n         if autotune_cache:\n             if best_config := autotune_cache.read_best(inductor_meta, configs):\n                 configs = [best_config]\n-\n+                autotune_cache_info[\"best_config\"] = triton_config_to_hashable(\n+                    best_config\n+                )\n+                autotune_cache_info[\"autotune_cache_state\"] = \"hit\"\n+            else:\n+                autotune_cache_info[\"autotune_cache_state\"] = \"miss\"\n+                autotune_cache_info[\"num_configs\"] = len(configs)\n+                if inductor_meta.get(\"coordinate_descent_tuning\"):\n+                    autotune_cache_info[\"coordesc_tuning\"] = True\n+                    if len(configs) == 1:",
        "comment_created_at": "2025-04-29T15:11:20+00:00",
        "comment_author": "jamesjwu",
        "comment_body": "We're logging the compile time \"results\", in that we're logging all the possible configs we need to actually autotune when the function is actually called. But we haven't run autotuning yet, so there can be more than one config. \r\n\r\nWe run autotuning later after dynamo returns, in CachingAutotuner.benchmark_all_configs. There, it should be possible to log just the best config. ",
        "pr_file_module": null
      }
    ]
  }
]
