[
  {
    "discussion_id": "2177948813",
    "pr_number": 5172,
    "pr_file": "src/core/tools/readFileTool.ts",
    "created_at": "2025-07-01T15:50:38+00:00",
    "commented_code": "const fileExtension = path.extname(relPath).toLowerCase()\n \t\t\t\t\tconst supportedBinaryFormats = getSupportedBinaryFormats()\n \n-\t\t\t\t\tif (!supportedBinaryFormats.includes(fileExtension)) {\n+\t\t\t\t\t// Check if it's a supported image format\n+\t\t\t\t\tif (SUPPORTED_IMAGE_FORMATS.includes(fileExtension as any)) {\n+\t\t\t\t\t\ttry {\n+\t\t\t\t\t\t\tconst imageStats = await fs.stat(fullPath)\n+\n+\t\t\t\t\t\t\t// Check if image file exceeds size limit\n+\t\t\t\t\t\t\tif (imageStats.size > MAX_IMAGE_FILE_SIZE_BYTES) {\n+\t\t\t\t\t\t\t\tconst imageSizeInMB = (imageStats.size / (1024 * 1024)).toFixed(1)\n+\t\t\t\t\t\t\t\tconst notice = `Image file is too large (${imageSizeInMB} MB). The maximum allowed size is 5 MB.`\n+\n+\t\t\t\t\t\t\t\t// Track file read\n+\t\t\t\t\t\t\t\tawait cline.fileContextTracker.trackFileContext(relPath, \"read_tool\" as RecordSource)\n+\n+\t\t\t\t\t\t\t\tupdateFileResult(relPath, {\n+\t\t\t\t\t\t\t\t\txmlContent: `<file><path>${relPath}</path>\n<notice>${notice}</notice>\n</file>`,\n+\t\t\t\t\t\t\t\t})\n+\t\t\t\t\t\t\t\tcontinue\n+\t\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t\tconst imageDataUrl = await readImageAsDataUrl(fullPath)\n+\t\t\t\t\t\t\tconst imageSizeInKB = Math.round(imageStats.size / 1024)\n+\n+\t\t\t\t\t\t\t// For images, get dimensions if possible\n+\t\t\t\t\t\t\tlet dimensionsInfo = \"\"\n+\t\t\t\t\t\t\tif (fileExtension === \".png\") {\n+\t\t\t\t\t\t\t\t// Simple PNG dimension extraction (first 24 bytes contain width/height)\n+\t\t\t\t\t\t\t\tconst buffer = await fs.readFile(fullPath)",
    "repo_full_name": "RooCodeInc/Roo-Code",
    "discussion_comments": [
      {
        "comment_id": "2177948813",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5172,
        "pr_file": "src/core/tools/readFileTool.ts",
        "discussion_id": "2177948813",
        "commented_code": "@@ -440,14 +491,83 @@ export async function readFileTool(\n \t\t\t\t\tconst fileExtension = path.extname(relPath).toLowerCase()\n \t\t\t\t\tconst supportedBinaryFormats = getSupportedBinaryFormats()\n \n-\t\t\t\t\tif (!supportedBinaryFormats.includes(fileExtension)) {\n+\t\t\t\t\t// Check if it's a supported image format\n+\t\t\t\t\tif (SUPPORTED_IMAGE_FORMATS.includes(fileExtension as any)) {\n+\t\t\t\t\t\ttry {\n+\t\t\t\t\t\t\tconst imageStats = await fs.stat(fullPath)\n+\n+\t\t\t\t\t\t\t// Check if image file exceeds size limit\n+\t\t\t\t\t\t\tif (imageStats.size > MAX_IMAGE_FILE_SIZE_BYTES) {\n+\t\t\t\t\t\t\t\tconst imageSizeInMB = (imageStats.size / (1024 * 1024)).toFixed(1)\n+\t\t\t\t\t\t\t\tconst notice = `Image file is too large (${imageSizeInMB} MB). The maximum allowed size is 5 MB.`\n+\n+\t\t\t\t\t\t\t\t// Track file read\n+\t\t\t\t\t\t\t\tawait cline.fileContextTracker.trackFileContext(relPath, \"read_tool\" as RecordSource)\n+\n+\t\t\t\t\t\t\t\tupdateFileResult(relPath, {\n+\t\t\t\t\t\t\t\t\txmlContent: `<file><path>${relPath}</path>\\n<notice>${notice}</notice>\\n</file>`,\n+\t\t\t\t\t\t\t\t})\n+\t\t\t\t\t\t\t\tcontinue\n+\t\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t\tconst imageDataUrl = await readImageAsDataUrl(fullPath)\n+\t\t\t\t\t\t\tconst imageSizeInKB = Math.round(imageStats.size / 1024)\n+\n+\t\t\t\t\t\t\t// For images, get dimensions if possible\n+\t\t\t\t\t\t\tlet dimensionsInfo = \"\"\n+\t\t\t\t\t\t\tif (fileExtension === \".png\") {\n+\t\t\t\t\t\t\t\t// Simple PNG dimension extraction (first 24 bytes contain width/height)\n+\t\t\t\t\t\t\t\tconst buffer = await fs.readFile(fullPath)",
        "comment_created_at": "2025-07-01T15:50:38+00:00",
        "comment_author": "ellipsis-dev[bot]",
        "comment_body": "The code calls fs.readFile again for PNG dimension extraction even though the file was already read in readImageAsDataUrl. Consider refactoring to reuse the file buffer to avoid redundant I/O.\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2172828564",
    "pr_number": 5185,
    "pr_file": "src/core/tools/useMcpToolTool.ts",
    "created_at": "2025-06-27T20:26:08+00:00",
    "commented_code": "})\n }\n \n-function processToolContent(toolResult: any): string {\n+function processToolContent(toolResult: any): { text: string; images: string[] } {\n \tif (!toolResult?.content || toolResult.content.length === 0) {\n-\t\treturn \"\"\n+\t\treturn { text: \"\", images: [] }\n \t}\n \n-\treturn toolResult.content\n-\t\t.map((item: any) => {\n-\t\t\tif (item.type === \"text\") {\n-\t\t\t\treturn item.text\n+\tconst textParts: string[] = []\n+\tconst images: string[] = []",
    "repo_full_name": "RooCodeInc/Roo-Code",
    "discussion_comments": [
      {
        "comment_id": "2172828564",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5185,
        "pr_file": "src/core/tools/useMcpToolTool.ts",
        "discussion_id": "2172828564",
        "commented_code": "@@ -89,24 +89,39 @@ async function sendExecutionStatus(cline: Task, status: McpExecutionStatus): Pro\n \t})\n }\n \n-function processToolContent(toolResult: any): string {\n+function processToolContent(toolResult: any): { text: string; images: string[] } {\n \tif (!toolResult?.content || toolResult.content.length === 0) {\n-\t\treturn \"\"\n+\t\treturn { text: \"\", images: [] }\n \t}\n \n-\treturn toolResult.content\n-\t\t.map((item: any) => {\n-\t\t\tif (item.type === \"text\") {\n-\t\t\t\treturn item.text\n+\tconst textParts: string[] = []\n+\tconst images: string[] = []",
        "comment_created_at": "2025-06-27T20:26:08+00:00",
        "comment_author": "daniel-lxs",
        "comment_body": "Should we consider implementing a limit on the number of images that can be returned in a single response? Without a limit, a malicious or buggy MCP server could potentially return hundreds of images, causing performance issues. Maybe add a configurable maximum (e.g., 10-20 images) and log a warning if exceeded?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2207876464",
    "pr_number": 5723,
    "pr_file": "src/services/search/file-search.ts",
    "created_at": "2025-07-15T15:39:26+00:00",
    "commented_code": "export async function executeRipgrepForFiles(\n \tworkspacePath: string,\n \tlimit: number = 5000,",
    "repo_full_name": "RooCodeInc/Roo-Code",
    "discussion_comments": [
      {
        "comment_id": "2207876464",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5723,
        "pr_file": "src/services/search/file-search.ts",
        "discussion_id": "2207876464",
        "commented_code": "@@ -88,11 +88,13 @@ export async function executeRipgrep({\n export async function executeRipgrepForFiles(\n \tworkspacePath: string,\n \tlimit: number = 5000,",
        "comment_created_at": "2025-07-15T15:39:26+00:00",
        "comment_author": "daniel-lxs",
        "comment_body": "With the increased limit of 500,000 files, have you considered the memory implications? Each FileResult object contains path, type, and label properties. For a project with 500K files, this could consume significant memory (potentially hundreds of MB).\n\nWould it make sense to:\n1. Make this limit configurable via VSCode settings?\n2. Implement streaming or pagination for extremely large file lists?\n3. Add memory usage monitoring/warnings?",
        "pr_file_module": null
      },
      {
        "comment_id": "2210997412",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5723,
        "pr_file": "src/services/search/file-search.ts",
        "discussion_id": "2207876464",
        "commented_code": "@@ -88,11 +88,13 @@ export async function executeRipgrep({\n export async function executeRipgrepForFiles(\n \tworkspacePath: string,\n \tlimit: number = 5000,",
        "comment_created_at": "2025-07-16T17:02:53+00:00",
        "comment_author": "Naituw",
        "comment_body": "Thanks for pointing out the memory concerns. To optimize memory usage, I\u2019ve updated the implementation to use a tree structure for caching:\r\n\r\n* Based on my testing, the tree-based structure enables slightly faster construction, and saves nearly **50%** of memory usage.\r\n\r\n  * If you're interested, I created a small benchmark to compare both approaches: [https://github.com/Naituw/RipgrepCache](https://github.com/Naituw/RipgrepCache)\r\n\r\n* To keep the code clean, I moved the ripgrep-related state management into a dedicated `RipgrepResultCache` class, while the entry point remains in `WorkspaceTrack`.\r\n\r\nIn addition, I\u2019ve added a new VSCode setting to make the file indexing limit configurable:\r\n`roo-cline.maximumIndexedFilesForFileSearch`\r\nIt now defaults to 200K, with a minimum of 5K and a maximum of 500K.\r\n\r\nI think implementing data pagination will be quite challenging, because we need to find the top 20 most relevant matches across the entire list. If we paginate, the files we're trying to search for might not appear on the first page. I currently don\u2019t have a good idea on how to implement this.\r\n\r\nAs for memory warnings \u2014 I\u2019m not entirely sure what form you were referring to, so I haven\u2019t implemented that part yet. Based on my testing, in a project with 140,000 files, the tree-structured cache consumes about **11MB** of memory. I estimate that for 500,000 files it should typically stay under **50MB**. Do you think that level of usage would be acceptable now?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2180651698",
    "pr_number": 5341,
    "pr_file": "src/core/assistant-message/AssistantMessageParser.ts",
    "created_at": "2025-07-02T17:54:20+00:00",
    "commented_code": "+import { type ToolName, toolNames } from \"@roo-code/types\"\n+import { TextContent, ToolUse, ToolParamName, toolParamNames } from \"../../shared/tools\"\n+import { AssistantMessageContent } from \"./parseAssistantMessage\"\n+\n+/**\n+ * Parser for assistant messages. Maintains state between chunks\n+ * to avoid reprocessing the entire message on each update.\n+ */\n+export class AssistantMessageParser {\n+\tprivate contentBlocks: AssistantMessageContent[] = []\n+\tprivate currentTextContent: TextContent | undefined = undefined\n+\tprivate currentTextContentStartIndex = 0\n+\tprivate currentToolUse: ToolUse | undefined = undefined\n+\tprivate currentToolUseStartIndex = 0\n+\tprivate currentParamName: ToolParamName | undefined = undefined\n+\tprivate currentParamValueStartIndex = 0\n+\tprivate accumulator = \"\"",
    "repo_full_name": "RooCodeInc/Roo-Code",
    "discussion_comments": [
      {
        "comment_id": "2180651698",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5341,
        "pr_file": "src/core/assistant-message/AssistantMessageParser.ts",
        "discussion_id": "2180651698",
        "commented_code": "@@ -0,0 +1,237 @@\n+import { type ToolName, toolNames } from \"@roo-code/types\"\n+import { TextContent, ToolUse, ToolParamName, toolParamNames } from \"../../shared/tools\"\n+import { AssistantMessageContent } from \"./parseAssistantMessage\"\n+\n+/**\n+ * Parser for assistant messages. Maintains state between chunks\n+ * to avoid reprocessing the entire message on each update.\n+ */\n+export class AssistantMessageParser {\n+\tprivate contentBlocks: AssistantMessageContent[] = []\n+\tprivate currentTextContent: TextContent | undefined = undefined\n+\tprivate currentTextContentStartIndex = 0\n+\tprivate currentToolUse: ToolUse | undefined = undefined\n+\tprivate currentToolUseStartIndex = 0\n+\tprivate currentParamName: ToolParamName | undefined = undefined\n+\tprivate currentParamValueStartIndex = 0\n+\tprivate accumulator = \"\"",
        "comment_created_at": "2025-07-02T17:54:20+00:00",
        "comment_author": "daniel-lxs",
        "comment_body": "The accumulator still stores the entire conversation history, which matches the original behavior, so this isn't a regression. But it could become a memory concern for long-running chats.\r\n\r\nThis PR avoids re-parsing, which is great for performance. Should we try adding a bounded accumulator or sliding window to help with memory usage?",
        "pr_file_module": null
      },
      {
        "comment_id": "2180895236",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5341,
        "pr_file": "src/core/assistant-message/AssistantMessageParser.ts",
        "discussion_id": "2180651698",
        "commented_code": "@@ -0,0 +1,237 @@\n+import { type ToolName, toolNames } from \"@roo-code/types\"\n+import { TextContent, ToolUse, ToolParamName, toolParamNames } from \"../../shared/tools\"\n+import { AssistantMessageContent } from \"./parseAssistantMessage\"\n+\n+/**\n+ * Parser for assistant messages. Maintains state between chunks\n+ * to avoid reprocessing the entire message on each update.\n+ */\n+export class AssistantMessageParser {\n+\tprivate contentBlocks: AssistantMessageContent[] = []\n+\tprivate currentTextContent: TextContent | undefined = undefined\n+\tprivate currentTextContentStartIndex = 0\n+\tprivate currentToolUse: ToolUse | undefined = undefined\n+\tprivate currentToolUseStartIndex = 0\n+\tprivate currentParamName: ToolParamName | undefined = undefined\n+\tprivate currentParamValueStartIndex = 0\n+\tprivate accumulator = \"\"",
        "comment_created_at": "2025-07-02T20:13:50+00:00",
        "comment_author": "qdaxb",
        "comment_body": "parser will be reset before attemptApiRequest. Therefore, the accumulator will only retain the content of one message.\r\nA message is probably < 50kb long, so I don't think it's necessary to use more complicated mechanisms here.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2193460559",
    "pr_number": 5341,
    "pr_file": "src/core/assistant-message/AssistantMessageParser.ts",
    "created_at": "2025-07-08T21:18:45+00:00",
    "commented_code": "+import { type ToolName, toolNames } from \"@roo-code/types\"\n+import { TextContent, ToolUse, ToolParamName, toolParamNames } from \"../../shared/tools\"\n+import { AssistantMessageContent } from \"./parseAssistantMessage\"\n+\n+/**\n+ * Parser for assistant messages. Maintains state between chunks\n+ * to avoid reprocessing the entire message on each update.\n+ */\n+export class AssistantMessageParser {\n+\tprivate contentBlocks: AssistantMessageContent[] = []\n+\tprivate currentTextContent: TextContent | undefined = undefined\n+\tprivate currentTextContentStartIndex = 0\n+\tprivate currentToolUse: ToolUse | undefined = undefined\n+\tprivate currentToolUseStartIndex = 0\n+\tprivate currentParamName: ToolParamName | undefined = undefined",
    "repo_full_name": "RooCodeInc/Roo-Code",
    "discussion_comments": [
      {
        "comment_id": "2193460559",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5341,
        "pr_file": "src/core/assistant-message/AssistantMessageParser.ts",
        "discussion_id": "2193460559",
        "commented_code": "@@ -0,0 +1,228 @@\n+import { type ToolName, toolNames } from \"@roo-code/types\"\n+import { TextContent, ToolUse, ToolParamName, toolParamNames } from \"../../shared/tools\"\n+import { AssistantMessageContent } from \"./parseAssistantMessage\"\n+\n+/**\n+ * Parser for assistant messages. Maintains state between chunks\n+ * to avoid reprocessing the entire message on each update.\n+ */\n+export class AssistantMessageParser {\n+\tprivate contentBlocks: AssistantMessageContent[] = []\n+\tprivate currentTextContent: TextContent | undefined = undefined\n+\tprivate currentTextContentStartIndex = 0\n+\tprivate currentToolUse: ToolUse | undefined = undefined\n+\tprivate currentToolUseStartIndex = 0\n+\tprivate currentParamName: ToolParamName | undefined = undefined",
        "comment_created_at": "2025-07-08T21:18:45+00:00",
        "comment_author": "daniel-lxs",
        "comment_body": "While the accumulator is reset before each `attemptApiRequest`, consider adding a maximum size check as a safety measure against edge cases where the parser might be reused without proper reset:\n\n```typescript\nprivate readonly MAX_ACCUMULATOR_SIZE = 1024 * 1024; // 1MB limit\n\nprocessChunk(chunk: string): AssistantMessageContent[] {\n    if (this.accumulator.length + chunk.length > this.MAX_ACCUMULATOR_SIZE) {\n        throw new Error('Assistant message exceeds maximum allowed size');\n    }\n    this.accumulator += chunk;\n    // ...\n}\n```\n\nThis would prevent potential memory issues if the parser state isn't properly managed in all code paths.",
        "pr_file_module": null
      },
      {
        "comment_id": "2196671973",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5341,
        "pr_file": "src/core/assistant-message/AssistantMessageParser.ts",
        "discussion_id": "2193460559",
        "commented_code": "@@ -0,0 +1,228 @@\n+import { type ToolName, toolNames } from \"@roo-code/types\"\n+import { TextContent, ToolUse, ToolParamName, toolParamNames } from \"../../shared/tools\"\n+import { AssistantMessageContent } from \"./parseAssistantMessage\"\n+\n+/**\n+ * Parser for assistant messages. Maintains state between chunks\n+ * to avoid reprocessing the entire message on each update.\n+ */\n+export class AssistantMessageParser {\n+\tprivate contentBlocks: AssistantMessageContent[] = []\n+\tprivate currentTextContent: TextContent | undefined = undefined\n+\tprivate currentTextContentStartIndex = 0\n+\tprivate currentToolUse: ToolUse | undefined = undefined\n+\tprivate currentToolUseStartIndex = 0\n+\tprivate currentParamName: ToolParamName | undefined = undefined",
        "comment_created_at": "2025-07-10T06:05:05+00:00",
        "comment_author": "qdaxb",
        "comment_body": "done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2177867677",
    "pr_number": 5307,
    "pr_file": "webview-ui/src/components/chat/hooks/useChatTextDraft.ts",
    "created_at": "2025-07-01T15:12:23+00:00",
    "commented_code": "+import { useCallback, useEffect, useRef } from \"react\"\n+\n+/**\n+ * Hook for chat textarea draft persistence (localStorage).\n+ * Handles auto-save, restore on mount, and clear on send.\n+ * @param draftKey localStorage key for draft persistence\n+ * @param inputValue current textarea value\n+ * @param setInputValue setter for textarea value\n+ * @param onSend send callback\n+ */\n+export function useChatTextDraft(\n+\tdraftKey: string,\n+\tinputValue: string,\n+\tsetInputValue: (value: string) => void,\n+\tonSend: () => void,\n+) {\n+\tconst saveDraftTimerRef = useRef<NodeJS.Timeout | null>(null)\n+\n+\t// Restore draft on mount\n+\tuseEffect(() => {\n+\t\ttry {\n+\t\t\tconst draft = localStorage.getItem(draftKey)\n+\t\t\tif (draft && !inputValue) {\n+\t\t\t\tsetInputValue(draft)\n+\t\t\t}\n+\t\t} catch (_) {\n+\t\t\t// ignore\n+\t\t}\n+\t\t// Only run on initial mount\n+\t\t// eslint-disable-next-line react-hooks/exhaustive-deps\n+\t}, [])\n+\n+\t// Periodically save draft\n+\tuseEffect(() => {\n+\t\tif (saveDraftTimerRef.current) {\n+\t\t\tclearInterval(saveDraftTimerRef.current)\n+\t\t}\n+\t\tif (inputValue && inputValue.trim()) {\n+\t\t\tsaveDraftTimerRef.current = setInterval(() => {\n+\t\t\t\ttry {\n+\t\t\t\t\tlocalStorage.setItem(draftKey, inputValue)",
    "repo_full_name": "RooCodeInc/Roo-Code",
    "discussion_comments": [
      {
        "comment_id": "2177867677",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5307,
        "pr_file": "webview-ui/src/components/chat/hooks/useChatTextDraft.ts",
        "discussion_id": "2177867677",
        "commented_code": "@@ -0,0 +1,72 @@\n+import { useCallback, useEffect, useRef } from \"react\"\n+\n+/**\n+ * Hook for chat textarea draft persistence (localStorage).\n+ * Handles auto-save, restore on mount, and clear on send.\n+ * @param draftKey localStorage key for draft persistence\n+ * @param inputValue current textarea value\n+ * @param setInputValue setter for textarea value\n+ * @param onSend send callback\n+ */\n+export function useChatTextDraft(\n+\tdraftKey: string,\n+\tinputValue: string,\n+\tsetInputValue: (value: string) => void,\n+\tonSend: () => void,\n+) {\n+\tconst saveDraftTimerRef = useRef<NodeJS.Timeout | null>(null)\n+\n+\t// Restore draft on mount\n+\tuseEffect(() => {\n+\t\ttry {\n+\t\t\tconst draft = localStorage.getItem(draftKey)\n+\t\t\tif (draft && !inputValue) {\n+\t\t\t\tsetInputValue(draft)\n+\t\t\t}\n+\t\t} catch (_) {\n+\t\t\t// ignore\n+\t\t}\n+\t\t// Only run on initial mount\n+\t\t// eslint-disable-next-line react-hooks/exhaustive-deps\n+\t}, [])\n+\n+\t// Periodically save draft\n+\tuseEffect(() => {\n+\t\tif (saveDraftTimerRef.current) {\n+\t\t\tclearInterval(saveDraftTimerRef.current)\n+\t\t}\n+\t\tif (inputValue && inputValue.trim()) {\n+\t\t\tsaveDraftTimerRef.current = setInterval(() => {\n+\t\t\t\ttry {\n+\t\t\t\t\tlocalStorage.setItem(draftKey, inputValue)",
        "comment_created_at": "2025-07-01T15:12:23+00:00",
        "comment_author": "daniel-lxs",
        "comment_body": "Should we consider adding a maximum draft size limit just in case? localStorage typically has a 5-10MB quota, and very large drafts could potentially cause issues. What do you think about truncating or warning when drafts exceed a reasonable size (e.g., 100KB)?",
        "pr_file_module": null
      },
      {
        "comment_id": "2178027561",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5307,
        "pr_file": "webview-ui/src/components/chat/hooks/useChatTextDraft.ts",
        "discussion_id": "2177867677",
        "commented_code": "@@ -0,0 +1,72 @@\n+import { useCallback, useEffect, useRef } from \"react\"\n+\n+/**\n+ * Hook for chat textarea draft persistence (localStorage).\n+ * Handles auto-save, restore on mount, and clear on send.\n+ * @param draftKey localStorage key for draft persistence\n+ * @param inputValue current textarea value\n+ * @param setInputValue setter for textarea value\n+ * @param onSend send callback\n+ */\n+export function useChatTextDraft(\n+\tdraftKey: string,\n+\tinputValue: string,\n+\tsetInputValue: (value: string) => void,\n+\tonSend: () => void,\n+) {\n+\tconst saveDraftTimerRef = useRef<NodeJS.Timeout | null>(null)\n+\n+\t// Restore draft on mount\n+\tuseEffect(() => {\n+\t\ttry {\n+\t\t\tconst draft = localStorage.getItem(draftKey)\n+\t\t\tif (draft && !inputValue) {\n+\t\t\t\tsetInputValue(draft)\n+\t\t\t}\n+\t\t} catch (_) {\n+\t\t\t// ignore\n+\t\t}\n+\t\t// Only run on initial mount\n+\t\t// eslint-disable-next-line react-hooks/exhaustive-deps\n+\t}, [])\n+\n+\t// Periodically save draft\n+\tuseEffect(() => {\n+\t\tif (saveDraftTimerRef.current) {\n+\t\t\tclearInterval(saveDraftTimerRef.current)\n+\t\t}\n+\t\tif (inputValue && inputValue.trim()) {\n+\t\t\tsaveDraftTimerRef.current = setInterval(() => {\n+\t\t\t\ttry {\n+\t\t\t\t\tlocalStorage.setItem(draftKey, inputValue)",
        "comment_created_at": "2025-07-01T16:18:04+00:00",
        "comment_author": "qdaxb",
        "comment_body": "added size check of 100KB",
        "pr_file_module": null
      }
    ]
  }
]