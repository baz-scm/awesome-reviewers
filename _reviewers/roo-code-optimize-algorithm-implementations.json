[
  {
    "discussion_id": "2170106741",
    "pr_number": 3785,
    "pr_file": "src/core/task-persistence/taskHistory.ts",
    "created_at": "2025-06-26T22:01:21+00:00",
    "commented_code": "+import * as path from \"path\"\n+import * as fs from \"fs/promises\"\n+import getFolderSize from \"get-folder-size\"\n+import { safeWriteJson, safeReadJson } from \"../../utils/safeWriteJson\"\n+import { getWorkspacePath } from \"../../utils/path\"\n+import {\n+\tHistoryItem,\n+\tHistorySortOption,\n+\tHistorySearchOptions,\n+\tHistorySearchResults,\n+\tHistorySearchResultItem,\n+\tHistoryWorkspaceItem,\n+\tHistoryScanResults,\n+\tHistoryRebuildOptions,\n+} from \"@roo-code/types\"\n+import { getExtensionContext } from \"../../extension\"\n+import { taskHistorySearch } from \"./taskHistorySearch\"\n+\n+const TASK_HISTORY_MONTH_INDEX_PREFIX = \"task_history-\"\n+const TASK_DIR_NAME = \"tasks\"\n+const TASK_HISTORY_DIR_NAME = \"taskHistory\"\n+const TASK_HISTORY_VERSION_KEY = \"taskHistoryVersion\"\n+const CURRENT_TASK_HISTORY_VERSION = 2 // Version 1: old array, Version 2: new file-based\n+const WORKSPACES_INDEX_FILE = \"workspaces.index.json\"\n+\n+// Configuration for batch processing; empirically, a value of 16 seems to perform best:\n+const BATCH_SIZE = 16\n+\n+const itemObjectCache = new Map<string, HistoryItem>()\n+\n+/**\n+ * Gets the base path for task HistoryItem storage in tasks/<id>/history_item.json\n+ * @returns The base path string for task items.\n+ */\n+function _getTasksBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn path.join(context.globalStorageUri.fsPath, TASK_DIR_NAME)\n+}\n+\n+/**\n+ * Gets the base path for monthly index storage.\n+ * @returns The base path string for monthly indexes.\n+ */\n+function _getHistoryIndexesBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn path.join(context.globalStorageUri.fsPath, TASK_HISTORY_DIR_NAME)\n+}\n+\n+/**\n+ * Gets the base path for backup files.\n+ * @returns The base path string for backup files.\n+ */\n+function _getBackupBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn context.globalStorageUri.fsPath\n+}\n+\n+/**\n+ * Extracts year (YYYY) and month (MM) from a timestamp.\n+ * @param timestamp - Milliseconds since epoch.\n+ * @returns Object with year and month strings.\n+ */\n+function _getYearMonthFromTs(timestamp: number): { year: string; month: string } {\n+\tconst date = new Date(timestamp)\n+\tconst year = date.getFullYear().toString()\n+\tconst month = (date.getMonth() + 1).toString().padStart(2, \"0\")\n+\treturn { year, month }\n+}\n+\n+/**\n+ * Gets the path for a month's index file.\n+ * @param year - YYYY string.\n+ * @param month - MM string.\n+ * @returns The file path string.\n+ */\n+function _getMonthIndexFilePath(year: string, month: string): string {\n+\tconst basePath = _getHistoryIndexesBasePath()\n+\treturn path.join(basePath, `${year}-${month}.index.json`)\n+}\n+\n+/**\n+ * Gets the path for the workspaces index file.\n+ * @returns The file path string.\n+ */\n+function _getWorkspacesIndexFilePath(): string {\n+\tconst basePath = _getHistoryIndexesBasePath()\n+\treturn path.join(basePath, WORKSPACES_INDEX_FILE)\n+}\n+\n+/**\n+ * Constructs the full file path for a history item.\n+ * @param taskId - The ID of the task.\n+ * @returns Full path to the history item's JSON file.\n+ */\n+function _getHistoryItemPath(taskId: string): string {\n+\tconst tasksBasePath = _getTasksBasePath()\n+\treturn path.join(tasksBasePath, taskId, \"history_item.json\")\n+}\n+\n+/**\n+ * Reads the index object for a given month from a JSON file.\n+ * The object maps workspacePath to an inner object, which maps taskId to its timestamp.\n+ * e.g., { \"workspace/path\": { \"task-id-1\": 12345, \"task-id-2\": 67890 } }\n+ * @param year - YYYY string.\n+ * @param month - MM string.\n+ * @returns The Record of {workspacePath: {[taskId: string]: timestamp}}, or an empty object if not found.\n+ */\n+async function _readTaskHistoryMonthIndex(\n+\tyear: string,\n+\tmonth: string,\n+): Promise<Record<string, Record<string, number>>> {\n+\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\ttry {\n+\t\tconst data = await safeReadJson(indexPath)\n+\t\tif (data && typeof data === \"object\" && !Array.isArray(data)) {\n+\t\t\treturn data\n+\t\t}\n+\t} catch (error) {\n+\t\tconsole.error(`[TaskHistory] Error reading month index file for ${year}-${month}:`, error)\n+\t}\n+\treturn {}\n+}\n+\n+/**\n+ * Extracts task references from month data, optionally filtering by workspace.\n+ * @param monthDataByWorkspace - The month data indexed by workspace.\n+ * @param workspacePath - Optional workspace path to filter by.\n+ * @returns Array of task references with id and timestamp.\n+ */\n+function _getTasksByWorkspace(\n+\tmonthDataByWorkspace: Record<string, Record<string, number>>,\n+\tworkspacePath?: string,\n+): Array<{ id: string; ts: number }> {\n+\tconst tasksToFetch: Array<{ id: string; ts: number }> = []\n+\n+\t// Handle special paths\n+\tlet effectiveWorkspacePath = workspacePath\n+\n+\tif (workspacePath === \"all\") {\n+\t\teffectiveWorkspacePath = \"all\"\n+\t} else if (workspacePath === \"current\" || workspacePath === undefined || workspacePath === \"\") {\n+\t\t// Get the current workspace path from VSCode\n+\t\teffectiveWorkspacePath = getWorkspacePath()\n+\t}\n+\n+\t// If effectiveWorkspacePath is undefined, show all workspaces\n+\tif (effectiveWorkspacePath === \"all\") {\n+\t\t// All workspaces for the month\n+\t\tfor (const wsPathKey in monthDataByWorkspace) {\n+\t\t\tconst tasksInCurrentWorkspace = monthDataByWorkspace[wsPathKey]\n+\t\t\tif (tasksInCurrentWorkspace) {\n+\t\t\t\tfor (const id in tasksInCurrentWorkspace) {\n+\t\t\t\t\tif (Object.prototype.hasOwnProperty.call(tasksInCurrentWorkspace, id)) {\n+\t\t\t\t\t\ttasksToFetch.push({ id, ts: tasksInCurrentWorkspace[id] })\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t} else if (effectiveWorkspacePath !== undefined) {\n+\t\t// Filter by single workspace\n+\t\tconst tasksInWorkspace = monthDataByWorkspace[effectiveWorkspacePath]\n+\t\tif (tasksInWorkspace) {\n+\t\t\tfor (const id in tasksInWorkspace) {\n+\t\t\t\tif (Object.prototype.hasOwnProperty.call(tasksInWorkspace, id)) {\n+\t\t\t\t\ttasksToFetch.push({ id, ts: tasksInWorkspace[id] })\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\treturn tasksToFetch\n+}\n+\n+/**\n+ * Prepares task references for processing by filtering by date range and sorting.\n+ * We consider this \"fast\" because it does not read the history item from disk,\n+ * so it is a preliminary sort-filter.\n+ *\n+ * @param tasks - Array of task references with id and timestamp.\n+ * @param dateRange - Optional date range to filter by.\n+ * @param sortOption - Optional sort option (defaults to \"newest\").\n+ * @returns Filtered and sorted array of task references.\n+ */\n+function _fastSortFilterTasks(\n+\ttasks: Array<{ id: string; ts: number }>,\n+\tdateRange?: { fromTs?: number; toTs?: number },\n+\tsortOption: HistorySortOption = \"newest\",\n+): Array<{ id: string; ts: number }> {\n+\tconst fromTsNum = dateRange?.fromTs\n+\tconst toTsNum = dateRange?.toTs\n+\n+\t// Filter by date range\n+\tlet filteredTasks = tasks\n+\tif (fromTsNum || toTsNum) {\n+\t\tfilteredTasks = tasks.filter((taskRef) => {\n+\t\t\tif (fromTsNum && taskRef.ts < fromTsNum) {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t\tif (toTsNum && taskRef.ts > toTsNum) {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t\treturn true\n+\t\t})\n+\t}\n+\n+\t// Sort by timestamp based on sortOption\n+\tif (sortOption === \"oldest\") {\n+\t\treturn filteredTasks.sort((a, b) => a.ts - b.ts)\n+\t} else {\n+\t\t// Default to \"newest\" for all other sort options at this stage\n+\t\t// Other sort options (mostExpensive, mostTokens, mostRelevant) require the full HistoryItem\n+\t\t// and will be handled by _sortHistoryItems after fetching the items\n+\t\treturn filteredTasks.sort((a, b) => b.ts - a.ts)\n+\t}\n+}\n+\n+// Public API Functions\n+\n+/**\n+ * Adds or updates multiple history items.\n+ * This is the primary method for saving items.\n+ * @param items - An array of HistoryItem objects to set.\n+ */\n+export async function setHistoryItems(items: HistoryItem[]): Promise<void> {\n+\tif (!Array.isArray(items)) {\n+\t\tthrow new Error(\"Invalid argument: items must be an array.\")\n+\t}\n+\n+\t// Return early if there's nothing to set\n+\tif (items.length === 0) {\n+\t\treturn\n+\t}\n+\n+\t// Group items by month for efficient processing\n+\tconst itemsByMonth = new Map<string, Map<string, HistoryItem>>()\n+\n+\t// First pass: group items by month\n+\tfor (const item of items) {\n+\t\tif (!item || !item.id || typeof item.ts !== \"number\" || typeof item.task !== \"string\") {\n+\t\t\t// Use console.warn for this since it's not part of the normal operation logs\n+\t\t\tconsole.warn(\n+\t\t\t\t`[setHistoryItems] Invalid HistoryItem skipped (missing id, ts, or task): ${JSON.stringify(item)}`,\n+\t\t\t)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\t// workspace updates - use \"unknown\" instead of empty string\n+\t\tif (item.workspace === undefined || item.workspace === \"\") {\n+\t\t\titem.workspace = \"unknown\"\n+\t\t}\n+\n+\t\t// Group by month for index updates\n+\t\tconst { year, month } = _getYearMonthFromTs(item.ts)\n+\t\tconst monthKey = `${year}-${month}`\n+\n+\t\tif (!itemsByMonth.has(monthKey)) {\n+\t\t\titemsByMonth.set(monthKey, new Map<string, HistoryItem>())\n+\t\t}\n+\t\titemsByMonth.get(monthKey)!.set(item.id, item)\n+\t}\n+\n+\t// Use a single set to track all pending promises with a maximum of BATCH_SIZE in flight\n+\tconst pendingPromises = new Set<Promise<any>>()\n+\tconst workspaceUpdates: Record<string, number> = {}\n+\n+\t// Second pass: save individual item files\n+\tfor (const [monthKey, itemsInMonth] of itemsByMonth.entries()) {\n+\t\tconst count = itemsInMonth.size\n+\t\tif (count > 1) {\n+\t\t\tconsole.debug(`[setHistoryItems] Processing ${itemsInMonth.size} items for month ${monthKey}`)\n+\t\t}\n+\n+\t\t// Process all items in the month\n+\t\tfor (const [itemId, item] of itemsInMonth.entries()) {\n+\t\t\t// Collect workspace updates; item.workspace is guaranteed to be defined in the first pass:\n+\t\t\tconst workspacePathForIndex = item.workspace!\n+\n+\t\t\tif (!workspaceUpdates[workspacePathForIndex] || item.ts > workspaceUpdates[workspacePathForIndex]) {\n+\t\t\t\tworkspaceUpdates[workspacePathForIndex] = item.ts\n+\t\t\t}\n+\n+\t\t\t// Start a new operation\n+\t\t\tconst itemPath = _getHistoryItemPath(item.id)\n+\t\t\tconst promise = safeWriteJson(itemPath, item)\n+\n+\t\t\t// Add to pending set first\n+\t\t\tpendingPromises.add(promise)\n+\n+\t\t\t// Then attach the cleanup handlers to prevent any possible races\n+\t\t\tpromise\n+\t\t\t\t.then(() => {\n+\t\t\t\t\t// Cache the item after successful save\n+\t\t\t\t\titemObjectCache.set(item.id, item)\n+\t\t\t\t\t// Remove this promise from the pending set\n+\t\t\t\t\tpendingPromises.delete(promise)\n+\t\t\t\t\treturn item.id\n+\t\t\t\t})\n+\t\t\t\t.catch((error) => {\n+\t\t\t\t\tconsole.error(`[setHistoryItems] Error processing history item ${item.id}:`, error)\n+\t\t\t\t\t// Remove this promise from the pending set\n+\t\t\t\t\tpendingPromises.delete(promise)\n+\t\t\t\t\treturn undefined\n+\t\t\t\t})\n+\n+\t\t\t// Wait while we've reached the maximum in-flight operations\n+\t\t\twhile (pendingPromises.size >= BATCH_SIZE) {\n+\t\t\t\tawait Promise.race(pendingPromises)\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// Third pass: update month indexes\n+\tfor (const [monthKey, itemsInMonth] of itemsByMonth.entries()) {\n+\t\tconst [year, month] = monthKey.split(\"-\")\n+\t\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\n+\t\t// Create a promise for this month's update\n+\t\tconst monthUpdatePromise = safeWriteJson(indexPath, {}, async (currentMonthData) => {\n+\t\t\t// Update each item in this month\n+\t\t\tfor (const [itemId, item] of itemsInMonth.entries()) {\n+\t\t\t\t// Use \"unknown\" as the index key if item.workspace is undefined or empty\n+\t\t\t\tlet workspacePathForIndex\n+\t\t\t\tif (item.workspace === undefined || item.workspace === \"\") {\n+\t\t\t\t\tworkspacePathForIndex = \"unknown\"\n+\t\t\t\t} else {\n+\t\t\t\t\tworkspacePathForIndex = item.workspace\n+\t\t\t\t}\n+\n+\t\t\t\t// Initialize workspace if needed - TypeScript requires explicit initialization\n+\t\t\t\tif (!currentMonthData[workspacePathForIndex]) {\n+\t\t\t\t\tcurrentMonthData[workspacePathForIndex] = {}\n+\t\t\t\t}\n+\n+\t\t\t\t// Update the item reference\n+\t\t\t\tcurrentMonthData[workspacePathForIndex][itemId] = item.ts\n+\t\t\t}\n+\n+\t\t\treturn true // Return true to write\n+\t\t})\n+\n+\t\t// Add to the collection of promises first\n+\t\tpendingPromises.add(monthUpdatePromise)\n+\n+\t\t// Then attach the cleanup handlers to prevent any possible races\n+\t\tmonthUpdatePromise\n+\t\t\t.then(() => {\n+\t\t\t\tpendingPromises.delete(monthUpdatePromise)\n+\t\t\t})\n+\t\t\t.catch((error) => {\n+\t\t\t\tconsole.error(`[setHistoryItems] Error updating month index for ${monthKey}:`, error)\n+\t\t\t\tpendingPromises.delete(monthUpdatePromise)\n+\t\t\t})\n+\t}\n+\n+\t// Add workspaces index update\n+\tconst workspacesIndexPath = _getWorkspacesIndexFilePath()\n+\tconst workspacesUpdatePromise = safeWriteJson(workspacesIndexPath, {}, async (currentWorkspacesData) => {\n+\t\t// Update each workspace timestamp from the collected data\n+\t\tfor (const [workspacePath, timestamp] of Object.entries(workspaceUpdates)) {\n+\t\t\t// Update the workspace timestamp if it's newer\n+\t\t\tif (!currentWorkspacesData[workspacePath] || timestamp > currentWorkspacesData[workspacePath]) {\n+\t\t\t\tcurrentWorkspacesData[workspacePath] = timestamp\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn true // Return true to write\n+\t})\n+\n+\t// Add to the collection of promises first\n+\tpendingPromises.add(workspacesUpdatePromise)\n+\n+\t// Then attach the cleanup handlers to prevent any possible races\n+\tworkspacesUpdatePromise\n+\t\t.then(() => {\n+\t\t\tpendingPromises.delete(workspacesUpdatePromise)\n+\t\t})\n+\t\t.catch((error) => {\n+\t\t\tconsole.error(`[setHistoryItems] Error updating workspaces index:`, error)\n+\t\t\tpendingPromises.delete(workspacesUpdatePromise)\n+\t\t})\n+\n+\t// Wait for all remaining operations to complete\n+\tif (pendingPromises.size > 0) {\n+\t\tawait Promise.all(pendingPromises)\n+\t}\n+}\n+\n+/**\n+ * Retrieves a specific history item by its ID.\n+ * Uses an in-memory cache first, then falls back to file storage.\n+ * @param taskId - The ID of the task to retrieve.\n+ * @returns The HistoryItem if found, otherwise undefined.\n+ */\n+export async function getHistoryItem(taskId: string, useCache: boolean = true): Promise<HistoryItem | undefined> {\n+\t// Check cache first (fast path)\n+\tif (useCache && itemObjectCache.has(taskId)) {\n+\t\treturn itemObjectCache.get(taskId)\n+\t}\n+\n+\t// Cache miss - read from file using safeReadJson\n+\tconst itemPath = _getHistoryItemPath(taskId)\n+\ttry {\n+\t\tconst historyItem = await safeReadJson(itemPath)\n+\n+\t\tif (historyItem && historyItem.id && historyItem.ts !== undefined && historyItem.ts > 0) {\n+\t\t\tif (useCache) {\n+\t\t\t\titemObjectCache.set(taskId, historyItem)\n+\t\t\t}\n+\n+\t\t\treturn historyItem\n+\t\t} else {\n+\t\t\tconsole.error(`[TaskHistory] [getHistoryItem] [${taskId}] ${itemPath} content is invalid:`, historyItem)\n+\t\t\treturn undefined\n+\t\t}\n+\t} catch (error: any) {\n+\t\t// Suppress ENOENT (file not found) errors, but log other errors\n+\t\tif (error.code !== \"ENOENT\") {\n+\t\t\tconsole.error(`[TaskHistory] [getHistoryItem] [${taskId}] error reading file ${itemPath}:`, error)\n+\t\t}\n+\t\treturn undefined\n+\t}\n+}\n+\n+/**\n+ * Deletes a history item by its ID.\n+ * This involves deleting the item's file and removing its references from ALL globalState month indexes.\n+ * @param taskId - The ID of the task to delete.\n+ */\n+export async function deleteHistoryItem(taskId: string): Promise<void> {\n+\tif (!taskId) {\n+\t\tthrow new Error(\"Invalid arguments: taskId is required.\")\n+\t}\n+\n+\tconst itemPath = _getHistoryItemPath(taskId)\n+\tconst itemDir = path.dirname(itemPath)\n+\n+\ttry {\n+\t\tawait fs.rm(itemDir, { recursive: true, force: true })\n+\t} catch (error: any) {\n+\t\tif (error.code !== \"ENOENT\") {\n+\t\t\tconsole.warn(\n+\t\t\t\t`[TaskHistory Migration] Error deleting history item directory ${itemDir} (may be benign if already deleted):`,\n+\t\t\t\terror,\n+\t\t\t)\n+\t\t}\n+\t}\n+\n+\titemObjectCache.delete(taskId)\n+\n+\t// Iterate all monthly indexes to ensure comprehensive cleanup of the taskId.\n+\t// We don't use getHistoryItem() here to get workspace/ts for a targeted update\n+\t// because historical index states is intentionally inconsistent (\"fuzzy\"), and we want to ensure\n+\t// the ID is removed wherever it might appear as the latest for any workspace in any month.\n+\t// Tasks may exist in multiple workspaces and this is a normal workflow when the user loads\n+\t// a task from one workspace and continues using it in another.\n+\tconst availableMonths = await getAvailableHistoryMonths()\n+\n+\tfor (const { year, month } of availableMonths) {\n+\t\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\n+\t\ttry {\n+\t\t\t// Atomic read-modify-write operation for each month\n+\t\t\tawait safeWriteJson(indexPath, {}, async (monthData) => {\n+\t\t\t\tlet updatedInThisMonth = false\n+\n+\t\t\t\tfor (const workspacePath in monthData) {\n+\t\t\t\t\tif (Object.prototype.hasOwnProperty.call(monthData, workspacePath)) {\n+\t\t\t\t\t\tconst tasksInWorkspace = monthData[workspacePath]\n+\n+\t\t\t\t\t\t// Ensure tasksInWorkspace exists and then check for taskId\n+\t\t\t\t\t\tif (tasksInWorkspace && tasksInWorkspace[taskId] !== undefined) {\n+\t\t\t\t\t\t\tdelete tasksInWorkspace[taskId]\n+\n+\t\t\t\t\t\t\t// If the workspacePath entry becomes empty after deleting the task,\n+\t\t\t\t\t\t\t// remove the workspacePath key itself\n+\t\t\t\t\t\t\tif (Object.keys(tasksInWorkspace).length === 0) {\n+\t\t\t\t\t\t\t\tdelete monthData[workspacePath]\n+\t\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t\tupdatedInThisMonth = true\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\t// Return true only if changes were made, false otherwise\n+\t\t\t\t// This prevents unnecessary file writes when nothing changed\n+\t\t\t\treturn updatedInThisMonth\n+\t\t\t})\n+\t\t} catch (error) {\n+\t\t\tconsole.error(\n+\t\t\t\t`[TaskHistory] Error updating month index for ${year}-${month} when deleting task ${taskId}:`,\n+\t\t\t\terror,\n+\t\t\t)\n+\t\t}\n+\t}\n+}\n+\n+/**\n+ * Generates a timestamp string in the format YYYY-MM-DD_HH-MM-SS\n+ * @returns Formatted timestamp string\n+ */\n+function _getTimestampString(): string {\n+\tconst now = new Date()\n+\treturn `${now.getFullYear()}-${(now.getMonth() + 1).toString().padStart(2, \"0\")}-${now.getDate().toString().padStart(2, \"0\")}_${now.getHours().toString().padStart(2, \"0\")}-${now.getMinutes().toString().padStart(2, \"0\")}-${now.getSeconds().toString().padStart(2, \"0\")}`\n+}\n+\n+/**\n+ * Helper function to log a message both to console and to an array\n+ * @param logs Array to accumulate logs\n+ * @param message The message to log\n+ * @returns The message (for convenience)\n+ */\n+/**\n+ * Logs a message to both console and an array of logs.\n+ * Tags in square brackets at the beginning of the message are shown\n+ * in the console but omitted from the logs array.\n+ */\n+function logMessage(logs: string[], message: string): string {\n+\t// Display full message including tags in console\n+\tconsole.log(message)\n+\n+\t// Extract tags and strip them from the message stored in logs array\n+\t// Using a more specific regex pattern to avoid potential ReDoS vulnerability\n+\t// Original: /^\\[(.*?)\\]\\s*(.*)$/\n+\tconst tagMatch = message.match(/^\\[([^\\]]*)\\]\\s*(.*)$/)",
    "repo_full_name": "RooCodeInc/Roo-Code",
    "discussion_comments": [
      {
        "comment_id": "2170154602",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 3785,
        "pr_file": "src/core/task-persistence/taskHistory.ts",
        "discussion_id": "2170106741",
        "commented_code": "@@ -0,0 +1,1487 @@\n+import * as path from \"path\"\n+import * as fs from \"fs/promises\"\n+import getFolderSize from \"get-folder-size\"\n+import { safeWriteJson, safeReadJson } from \"../../utils/safeWriteJson\"\n+import { getWorkspacePath } from \"../../utils/path\"\n+import {\n+\tHistoryItem,\n+\tHistorySortOption,\n+\tHistorySearchOptions,\n+\tHistorySearchResults,\n+\tHistorySearchResultItem,\n+\tHistoryWorkspaceItem,\n+\tHistoryScanResults,\n+\tHistoryRebuildOptions,\n+} from \"@roo-code/types\"\n+import { getExtensionContext } from \"../../extension\"\n+import { taskHistorySearch } from \"./taskHistorySearch\"\n+\n+const TASK_HISTORY_MONTH_INDEX_PREFIX = \"task_history-\"\n+const TASK_DIR_NAME = \"tasks\"\n+const TASK_HISTORY_DIR_NAME = \"taskHistory\"\n+const TASK_HISTORY_VERSION_KEY = \"taskHistoryVersion\"\n+const CURRENT_TASK_HISTORY_VERSION = 2 // Version 1: old array, Version 2: new file-based\n+const WORKSPACES_INDEX_FILE = \"workspaces.index.json\"\n+\n+// Configuration for batch processing; empirically, a value of 16 seems to perform best:\n+const BATCH_SIZE = 16\n+\n+const itemObjectCache = new Map<string, HistoryItem>()\n+\n+/**\n+ * Gets the base path for task HistoryItem storage in tasks/<id>/history_item.json\n+ * @returns The base path string for task items.\n+ */\n+function _getTasksBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn path.join(context.globalStorageUri.fsPath, TASK_DIR_NAME)\n+}\n+\n+/**\n+ * Gets the base path for monthly index storage.\n+ * @returns The base path string for monthly indexes.\n+ */\n+function _getHistoryIndexesBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn path.join(context.globalStorageUri.fsPath, TASK_HISTORY_DIR_NAME)\n+}\n+\n+/**\n+ * Gets the base path for backup files.\n+ * @returns The base path string for backup files.\n+ */\n+function _getBackupBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn context.globalStorageUri.fsPath\n+}\n+\n+/**\n+ * Extracts year (YYYY) and month (MM) from a timestamp.\n+ * @param timestamp - Milliseconds since epoch.\n+ * @returns Object with year and month strings.\n+ */\n+function _getYearMonthFromTs(timestamp: number): { year: string; month: string } {\n+\tconst date = new Date(timestamp)\n+\tconst year = date.getFullYear().toString()\n+\tconst month = (date.getMonth() + 1).toString().padStart(2, \"0\")\n+\treturn { year, month }\n+}\n+\n+/**\n+ * Gets the path for a month's index file.\n+ * @param year - YYYY string.\n+ * @param month - MM string.\n+ * @returns The file path string.\n+ */\n+function _getMonthIndexFilePath(year: string, month: string): string {\n+\tconst basePath = _getHistoryIndexesBasePath()\n+\treturn path.join(basePath, `${year}-${month}.index.json`)\n+}\n+\n+/**\n+ * Gets the path for the workspaces index file.\n+ * @returns The file path string.\n+ */\n+function _getWorkspacesIndexFilePath(): string {\n+\tconst basePath = _getHistoryIndexesBasePath()\n+\treturn path.join(basePath, WORKSPACES_INDEX_FILE)\n+}\n+\n+/**\n+ * Constructs the full file path for a history item.\n+ * @param taskId - The ID of the task.\n+ * @returns Full path to the history item's JSON file.\n+ */\n+function _getHistoryItemPath(taskId: string): string {\n+\tconst tasksBasePath = _getTasksBasePath()\n+\treturn path.join(tasksBasePath, taskId, \"history_item.json\")\n+}\n+\n+/**\n+ * Reads the index object for a given month from a JSON file.\n+ * The object maps workspacePath to an inner object, which maps taskId to its timestamp.\n+ * e.g., { \"workspace/path\": { \"task-id-1\": 12345, \"task-id-2\": 67890 } }\n+ * @param year - YYYY string.\n+ * @param month - MM string.\n+ * @returns The Record of {workspacePath: {[taskId: string]: timestamp}}, or an empty object if not found.\n+ */\n+async function _readTaskHistoryMonthIndex(\n+\tyear: string,\n+\tmonth: string,\n+): Promise<Record<string, Record<string, number>>> {\n+\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\ttry {\n+\t\tconst data = await safeReadJson(indexPath)\n+\t\tif (data && typeof data === \"object\" && !Array.isArray(data)) {\n+\t\t\treturn data\n+\t\t}\n+\t} catch (error) {\n+\t\tconsole.error(`[TaskHistory] Error reading month index file for ${year}-${month}:`, error)\n+\t}\n+\treturn {}\n+}\n+\n+/**\n+ * Extracts task references from month data, optionally filtering by workspace.\n+ * @param monthDataByWorkspace - The month data indexed by workspace.\n+ * @param workspacePath - Optional workspace path to filter by.\n+ * @returns Array of task references with id and timestamp.\n+ */\n+function _getTasksByWorkspace(\n+\tmonthDataByWorkspace: Record<string, Record<string, number>>,\n+\tworkspacePath?: string,\n+): Array<{ id: string; ts: number }> {\n+\tconst tasksToFetch: Array<{ id: string; ts: number }> = []\n+\n+\t// Handle special paths\n+\tlet effectiveWorkspacePath = workspacePath\n+\n+\tif (workspacePath === \"all\") {\n+\t\teffectiveWorkspacePath = \"all\"\n+\t} else if (workspacePath === \"current\" || workspacePath === undefined || workspacePath === \"\") {\n+\t\t// Get the current workspace path from VSCode\n+\t\teffectiveWorkspacePath = getWorkspacePath()\n+\t}\n+\n+\t// If effectiveWorkspacePath is undefined, show all workspaces\n+\tif (effectiveWorkspacePath === \"all\") {\n+\t\t// All workspaces for the month\n+\t\tfor (const wsPathKey in monthDataByWorkspace) {\n+\t\t\tconst tasksInCurrentWorkspace = monthDataByWorkspace[wsPathKey]\n+\t\t\tif (tasksInCurrentWorkspace) {\n+\t\t\t\tfor (const id in tasksInCurrentWorkspace) {\n+\t\t\t\t\tif (Object.prototype.hasOwnProperty.call(tasksInCurrentWorkspace, id)) {\n+\t\t\t\t\t\ttasksToFetch.push({ id, ts: tasksInCurrentWorkspace[id] })\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t} else if (effectiveWorkspacePath !== undefined) {\n+\t\t// Filter by single workspace\n+\t\tconst tasksInWorkspace = monthDataByWorkspace[effectiveWorkspacePath]\n+\t\tif (tasksInWorkspace) {\n+\t\t\tfor (const id in tasksInWorkspace) {\n+\t\t\t\tif (Object.prototype.hasOwnProperty.call(tasksInWorkspace, id)) {\n+\t\t\t\t\ttasksToFetch.push({ id, ts: tasksInWorkspace[id] })\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\treturn tasksToFetch\n+}\n+\n+/**\n+ * Prepares task references for processing by filtering by date range and sorting.\n+ * We consider this \"fast\" because it does not read the history item from disk,\n+ * so it is a preliminary sort-filter.\n+ *\n+ * @param tasks - Array of task references with id and timestamp.\n+ * @param dateRange - Optional date range to filter by.\n+ * @param sortOption - Optional sort option (defaults to \"newest\").\n+ * @returns Filtered and sorted array of task references.\n+ */\n+function _fastSortFilterTasks(\n+\ttasks: Array<{ id: string; ts: number }>,\n+\tdateRange?: { fromTs?: number; toTs?: number },\n+\tsortOption: HistorySortOption = \"newest\",\n+): Array<{ id: string; ts: number }> {\n+\tconst fromTsNum = dateRange?.fromTs\n+\tconst toTsNum = dateRange?.toTs\n+\n+\t// Filter by date range\n+\tlet filteredTasks = tasks\n+\tif (fromTsNum || toTsNum) {\n+\t\tfilteredTasks = tasks.filter((taskRef) => {\n+\t\t\tif (fromTsNum && taskRef.ts < fromTsNum) {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t\tif (toTsNum && taskRef.ts > toTsNum) {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t\treturn true\n+\t\t})\n+\t}\n+\n+\t// Sort by timestamp based on sortOption\n+\tif (sortOption === \"oldest\") {\n+\t\treturn filteredTasks.sort((a, b) => a.ts - b.ts)\n+\t} else {\n+\t\t// Default to \"newest\" for all other sort options at this stage\n+\t\t// Other sort options (mostExpensive, mostTokens, mostRelevant) require the full HistoryItem\n+\t\t// and will be handled by _sortHistoryItems after fetching the items\n+\t\treturn filteredTasks.sort((a, b) => b.ts - a.ts)\n+\t}\n+}\n+\n+// Public API Functions\n+\n+/**\n+ * Adds or updates multiple history items.\n+ * This is the primary method for saving items.\n+ * @param items - An array of HistoryItem objects to set.\n+ */\n+export async function setHistoryItems(items: HistoryItem[]): Promise<void> {\n+\tif (!Array.isArray(items)) {\n+\t\tthrow new Error(\"Invalid argument: items must be an array.\")\n+\t}\n+\n+\t// Return early if there's nothing to set\n+\tif (items.length === 0) {\n+\t\treturn\n+\t}\n+\n+\t// Group items by month for efficient processing\n+\tconst itemsByMonth = new Map<string, Map<string, HistoryItem>>()\n+\n+\t// First pass: group items by month\n+\tfor (const item of items) {\n+\t\tif (!item || !item.id || typeof item.ts !== \"number\" || typeof item.task !== \"string\") {\n+\t\t\t// Use console.warn for this since it's not part of the normal operation logs\n+\t\t\tconsole.warn(\n+\t\t\t\t`[setHistoryItems] Invalid HistoryItem skipped (missing id, ts, or task): ${JSON.stringify(item)}`,\n+\t\t\t)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\t// workspace updates - use \"unknown\" instead of empty string\n+\t\tif (item.workspace === undefined || item.workspace === \"\") {\n+\t\t\titem.workspace = \"unknown\"\n+\t\t}\n+\n+\t\t// Group by month for index updates\n+\t\tconst { year, month } = _getYearMonthFromTs(item.ts)\n+\t\tconst monthKey = `${year}-${month}`\n+\n+\t\tif (!itemsByMonth.has(monthKey)) {\n+\t\t\titemsByMonth.set(monthKey, new Map<string, HistoryItem>())\n+\t\t}\n+\t\titemsByMonth.get(monthKey)!.set(item.id, item)\n+\t}\n+\n+\t// Use a single set to track all pending promises with a maximum of BATCH_SIZE in flight\n+\tconst pendingPromises = new Set<Promise<any>>()\n+\tconst workspaceUpdates: Record<string, number> = {}\n+\n+\t// Second pass: save individual item files\n+\tfor (const [monthKey, itemsInMonth] of itemsByMonth.entries()) {\n+\t\tconst count = itemsInMonth.size\n+\t\tif (count > 1) {\n+\t\t\tconsole.debug(`[setHistoryItems] Processing ${itemsInMonth.size} items for month ${monthKey}`)\n+\t\t}\n+\n+\t\t// Process all items in the month\n+\t\tfor (const [itemId, item] of itemsInMonth.entries()) {\n+\t\t\t// Collect workspace updates; item.workspace is guaranteed to be defined in the first pass:\n+\t\t\tconst workspacePathForIndex = item.workspace!\n+\n+\t\t\tif (!workspaceUpdates[workspacePathForIndex] || item.ts > workspaceUpdates[workspacePathForIndex]) {\n+\t\t\t\tworkspaceUpdates[workspacePathForIndex] = item.ts\n+\t\t\t}\n+\n+\t\t\t// Start a new operation\n+\t\t\tconst itemPath = _getHistoryItemPath(item.id)\n+\t\t\tconst promise = safeWriteJson(itemPath, item)\n+\n+\t\t\t// Add to pending set first\n+\t\t\tpendingPromises.add(promise)\n+\n+\t\t\t// Then attach the cleanup handlers to prevent any possible races\n+\t\t\tpromise\n+\t\t\t\t.then(() => {\n+\t\t\t\t\t// Cache the item after successful save\n+\t\t\t\t\titemObjectCache.set(item.id, item)\n+\t\t\t\t\t// Remove this promise from the pending set\n+\t\t\t\t\tpendingPromises.delete(promise)\n+\t\t\t\t\treturn item.id\n+\t\t\t\t})\n+\t\t\t\t.catch((error) => {\n+\t\t\t\t\tconsole.error(`[setHistoryItems] Error processing history item ${item.id}:`, error)\n+\t\t\t\t\t// Remove this promise from the pending set\n+\t\t\t\t\tpendingPromises.delete(promise)\n+\t\t\t\t\treturn undefined\n+\t\t\t\t})\n+\n+\t\t\t// Wait while we've reached the maximum in-flight operations\n+\t\t\twhile (pendingPromises.size >= BATCH_SIZE) {\n+\t\t\t\tawait Promise.race(pendingPromises)\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// Third pass: update month indexes\n+\tfor (const [monthKey, itemsInMonth] of itemsByMonth.entries()) {\n+\t\tconst [year, month] = monthKey.split(\"-\")\n+\t\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\n+\t\t// Create a promise for this month's update\n+\t\tconst monthUpdatePromise = safeWriteJson(indexPath, {}, async (currentMonthData) => {\n+\t\t\t// Update each item in this month\n+\t\t\tfor (const [itemId, item] of itemsInMonth.entries()) {\n+\t\t\t\t// Use \"unknown\" as the index key if item.workspace is undefined or empty\n+\t\t\t\tlet workspacePathForIndex\n+\t\t\t\tif (item.workspace === undefined || item.workspace === \"\") {\n+\t\t\t\t\tworkspacePathForIndex = \"unknown\"\n+\t\t\t\t} else {\n+\t\t\t\t\tworkspacePathForIndex = item.workspace\n+\t\t\t\t}\n+\n+\t\t\t\t// Initialize workspace if needed - TypeScript requires explicit initialization\n+\t\t\t\tif (!currentMonthData[workspacePathForIndex]) {\n+\t\t\t\t\tcurrentMonthData[workspacePathForIndex] = {}\n+\t\t\t\t}\n+\n+\t\t\t\t// Update the item reference\n+\t\t\t\tcurrentMonthData[workspacePathForIndex][itemId] = item.ts\n+\t\t\t}\n+\n+\t\t\treturn true // Return true to write\n+\t\t})\n+\n+\t\t// Add to the collection of promises first\n+\t\tpendingPromises.add(monthUpdatePromise)\n+\n+\t\t// Then attach the cleanup handlers to prevent any possible races\n+\t\tmonthUpdatePromise\n+\t\t\t.then(() => {\n+\t\t\t\tpendingPromises.delete(monthUpdatePromise)\n+\t\t\t})\n+\t\t\t.catch((error) => {\n+\t\t\t\tconsole.error(`[setHistoryItems] Error updating month index for ${monthKey}:`, error)\n+\t\t\t\tpendingPromises.delete(monthUpdatePromise)\n+\t\t\t})\n+\t}\n+\n+\t// Add workspaces index update\n+\tconst workspacesIndexPath = _getWorkspacesIndexFilePath()\n+\tconst workspacesUpdatePromise = safeWriteJson(workspacesIndexPath, {}, async (currentWorkspacesData) => {\n+\t\t// Update each workspace timestamp from the collected data\n+\t\tfor (const [workspacePath, timestamp] of Object.entries(workspaceUpdates)) {\n+\t\t\t// Update the workspace timestamp if it's newer\n+\t\t\tif (!currentWorkspacesData[workspacePath] || timestamp > currentWorkspacesData[workspacePath]) {\n+\t\t\t\tcurrentWorkspacesData[workspacePath] = timestamp\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn true // Return true to write\n+\t})\n+\n+\t// Add to the collection of promises first\n+\tpendingPromises.add(workspacesUpdatePromise)\n+\n+\t// Then attach the cleanup handlers to prevent any possible races\n+\tworkspacesUpdatePromise\n+\t\t.then(() => {\n+\t\t\tpendingPromises.delete(workspacesUpdatePromise)\n+\t\t})\n+\t\t.catch((error) => {\n+\t\t\tconsole.error(`[setHistoryItems] Error updating workspaces index:`, error)\n+\t\t\tpendingPromises.delete(workspacesUpdatePromise)\n+\t\t})\n+\n+\t// Wait for all remaining operations to complete\n+\tif (pendingPromises.size > 0) {\n+\t\tawait Promise.all(pendingPromises)\n+\t}\n+}\n+\n+/**\n+ * Retrieves a specific history item by its ID.\n+ * Uses an in-memory cache first, then falls back to file storage.\n+ * @param taskId - The ID of the task to retrieve.\n+ * @returns The HistoryItem if found, otherwise undefined.\n+ */\n+export async function getHistoryItem(taskId: string, useCache: boolean = true): Promise<HistoryItem | undefined> {\n+\t// Check cache first (fast path)\n+\tif (useCache && itemObjectCache.has(taskId)) {\n+\t\treturn itemObjectCache.get(taskId)\n+\t}\n+\n+\t// Cache miss - read from file using safeReadJson\n+\tconst itemPath = _getHistoryItemPath(taskId)\n+\ttry {\n+\t\tconst historyItem = await safeReadJson(itemPath)\n+\n+\t\tif (historyItem && historyItem.id && historyItem.ts !== undefined && historyItem.ts > 0) {\n+\t\t\tif (useCache) {\n+\t\t\t\titemObjectCache.set(taskId, historyItem)\n+\t\t\t}\n+\n+\t\t\treturn historyItem\n+\t\t} else {\n+\t\t\tconsole.error(`[TaskHistory] [getHistoryItem] [${taskId}] ${itemPath} content is invalid:`, historyItem)\n+\t\t\treturn undefined\n+\t\t}\n+\t} catch (error: any) {\n+\t\t// Suppress ENOENT (file not found) errors, but log other errors\n+\t\tif (error.code !== \"ENOENT\") {\n+\t\t\tconsole.error(`[TaskHistory] [getHistoryItem] [${taskId}] error reading file ${itemPath}:`, error)\n+\t\t}\n+\t\treturn undefined\n+\t}\n+}\n+\n+/**\n+ * Deletes a history item by its ID.\n+ * This involves deleting the item's file and removing its references from ALL globalState month indexes.\n+ * @param taskId - The ID of the task to delete.\n+ */\n+export async function deleteHistoryItem(taskId: string): Promise<void> {\n+\tif (!taskId) {\n+\t\tthrow new Error(\"Invalid arguments: taskId is required.\")\n+\t}\n+\n+\tconst itemPath = _getHistoryItemPath(taskId)\n+\tconst itemDir = path.dirname(itemPath)\n+\n+\ttry {\n+\t\tawait fs.rm(itemDir, { recursive: true, force: true })\n+\t} catch (error: any) {\n+\t\tif (error.code !== \"ENOENT\") {\n+\t\t\tconsole.warn(\n+\t\t\t\t`[TaskHistory Migration] Error deleting history item directory ${itemDir} (may be benign if already deleted):`,\n+\t\t\t\terror,\n+\t\t\t)\n+\t\t}\n+\t}\n+\n+\titemObjectCache.delete(taskId)\n+\n+\t// Iterate all monthly indexes to ensure comprehensive cleanup of the taskId.\n+\t// We don't use getHistoryItem() here to get workspace/ts for a targeted update\n+\t// because historical index states is intentionally inconsistent (\"fuzzy\"), and we want to ensure\n+\t// the ID is removed wherever it might appear as the latest for any workspace in any month.\n+\t// Tasks may exist in multiple workspaces and this is a normal workflow when the user loads\n+\t// a task from one workspace and continues using it in another.\n+\tconst availableMonths = await getAvailableHistoryMonths()\n+\n+\tfor (const { year, month } of availableMonths) {\n+\t\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\n+\t\ttry {\n+\t\t\t// Atomic read-modify-write operation for each month\n+\t\t\tawait safeWriteJson(indexPath, {}, async (monthData) => {\n+\t\t\t\tlet updatedInThisMonth = false\n+\n+\t\t\t\tfor (const workspacePath in monthData) {\n+\t\t\t\t\tif (Object.prototype.hasOwnProperty.call(monthData, workspacePath)) {\n+\t\t\t\t\t\tconst tasksInWorkspace = monthData[workspacePath]\n+\n+\t\t\t\t\t\t// Ensure tasksInWorkspace exists and then check for taskId\n+\t\t\t\t\t\tif (tasksInWorkspace && tasksInWorkspace[taskId] !== undefined) {\n+\t\t\t\t\t\t\tdelete tasksInWorkspace[taskId]\n+\n+\t\t\t\t\t\t\t// If the workspacePath entry becomes empty after deleting the task,\n+\t\t\t\t\t\t\t// remove the workspacePath key itself\n+\t\t\t\t\t\t\tif (Object.keys(tasksInWorkspace).length === 0) {\n+\t\t\t\t\t\t\t\tdelete monthData[workspacePath]\n+\t\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t\tupdatedInThisMonth = true\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\t// Return true only if changes were made, false otherwise\n+\t\t\t\t// This prevents unnecessary file writes when nothing changed\n+\t\t\t\treturn updatedInThisMonth\n+\t\t\t})\n+\t\t} catch (error) {\n+\t\t\tconsole.error(\n+\t\t\t\t`[TaskHistory] Error updating month index for ${year}-${month} when deleting task ${taskId}:`,\n+\t\t\t\terror,\n+\t\t\t)\n+\t\t}\n+\t}\n+}\n+\n+/**\n+ * Generates a timestamp string in the format YYYY-MM-DD_HH-MM-SS\n+ * @returns Formatted timestamp string\n+ */\n+function _getTimestampString(): string {\n+\tconst now = new Date()\n+\treturn `${now.getFullYear()}-${(now.getMonth() + 1).toString().padStart(2, \"0\")}-${now.getDate().toString().padStart(2, \"0\")}_${now.getHours().toString().padStart(2, \"0\")}-${now.getMinutes().toString().padStart(2, \"0\")}-${now.getSeconds().toString().padStart(2, \"0\")}`\n+}\n+\n+/**\n+ * Helper function to log a message both to console and to an array\n+ * @param logs Array to accumulate logs\n+ * @param message The message to log\n+ * @returns The message (for convenience)\n+ */\n+/**\n+ * Logs a message to both console and an array of logs.\n+ * Tags in square brackets at the beginning of the message are shown\n+ * in the console but omitted from the logs array.\n+ */\n+function logMessage(logs: string[], message: string): string {\n+\t// Display full message including tags in console\n+\tconsole.log(message)\n+\n+\t// Extract tags and strip them from the message stored in logs array\n+\t// Using a more specific regex pattern to avoid potential ReDoS vulnerability\n+\t// Original: /^\\[(.*?)\\]\\s*(.*)$/\n+\tconst tagMatch = message.match(/^\\[([^\\]]*)\\]\\s*(.*)$/)",
        "comment_created_at": "2025-06-26T22:34:18+00:00",
        "comment_author": "KJ7LNW",
        "comment_body": "fixed as much as we can while still maintaining purpose ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2205982544",
    "pr_number": 5503,
    "pr_file": "src/core/tools/ToolRepetitionDetector.ts",
    "created_at": "2025-07-14T23:24:36+00:00",
    "commented_code": "return { allowExecution: true }\n \t}\n \n+\t/**\n+\t * Updates the tool call history with the latest call\n+\t * @param toolCallJson The serialized tool call to add to history\n+\t */\n+\tprivate updateHistory(toolCallJson: string): void {\n+\t\tthis.toolCallHistory.push(toolCallJson)\n+\n+\t\t// Keep history within maximum length\n+\t\tif (this.toolCallHistory.length > this.historyMaxLength) {\n+\t\t\tthis.toolCallHistory.shift() // Remove oldest entry\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Detects repeating patterns in the tool call history using KMP algorithm\n+\t * @returns true if a pattern repetition is detected beyond the allowed limit\n+\t */\n+\tprivate detectPatternRepetition(): boolean {\n+\t\tconst history = this.toolCallHistory\n+\t\tif (history.length < 4) {\n+\t\t\t// Need at least 4 elements for meaningful pattern\n+\t\t\treturn false\n+\t\t}\n+\n+\t\t// Create a simplified representation of the history\n+\t\t// Use the actual tool calls (not indices) to ensure accurate pattern detection\n+\t\tconst historyArray = [...history]\n+\t\t\n+\t\t// Check patterns of various lengths\n+\t\t// Start with longer patterns to avoid false positives with short patterns\n+\t\tconst maxPatternLength = Math.floor(history.length / 2)\n+\t\t\n+\t\tfor (let patternLength = 1; patternLength <= maxPatternLength; patternLength++) {",
    "repo_full_name": "RooCodeInc/Roo-Code",
    "discussion_comments": [
      {
        "comment_id": "2205982544",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5503,
        "pr_file": "src/core/tools/ToolRepetitionDetector.ts",
        "discussion_id": "2205982544",
        "commented_code": "@@ -63,6 +79,104 @@ export class ToolRepetitionDetector {\n \t\treturn { allowExecution: true }\n \t}\n \n+\t/**\n+\t * Updates the tool call history with the latest call\n+\t * @param toolCallJson The serialized tool call to add to history\n+\t */\n+\tprivate updateHistory(toolCallJson: string): void {\n+\t\tthis.toolCallHistory.push(toolCallJson)\n+\n+\t\t// Keep history within maximum length\n+\t\tif (this.toolCallHistory.length > this.historyMaxLength) {\n+\t\t\tthis.toolCallHistory.shift() // Remove oldest entry\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Detects repeating patterns in the tool call history using KMP algorithm\n+\t * @returns true if a pattern repetition is detected beyond the allowed limit\n+\t */\n+\tprivate detectPatternRepetition(): boolean {\n+\t\tconst history = this.toolCallHistory\n+\t\tif (history.length < 4) {\n+\t\t\t// Need at least 4 elements for meaningful pattern\n+\t\t\treturn false\n+\t\t}\n+\n+\t\t// Create a simplified representation of the history\n+\t\t// Use the actual tool calls (not indices) to ensure accurate pattern detection\n+\t\tconst historyArray = [...history]\n+\t\t\n+\t\t// Check patterns of various lengths\n+\t\t// Start with longer patterns to avoid false positives with short patterns\n+\t\tconst maxPatternLength = Math.floor(history.length / 2)\n+\t\t\n+\t\tfor (let patternLength = 1; patternLength <= maxPatternLength; patternLength++) {",
        "comment_created_at": "2025-07-14T23:24:36+00:00",
        "comment_author": "daniel-lxs",
        "comment_body": "**Important**: Starting pattern detection from length 1 could cause false positives. For example, \"AAAA\" would be detected as pattern \"A\" repeated 4 times, which overlaps with consecutive repetition detection.\n\nConsider starting from length 2 to avoid this overlap:\n```typescript\nfor (let patternLength = 2; patternLength <= maxPatternLength; patternLength++) {\n```\n\nThis ensures pattern detection only catches actual patterns like \"AB\", \"ABC\", etc., not single repeated elements.",
        "pr_file_module": null
      }
    ]
  }
]