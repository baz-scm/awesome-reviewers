[
  {
    "discussion_id": "2224079940",
    "pr_number": 6088,
    "pr_file": "webview-ui/src/utils/command-validation.ts",
    "created_at": "2025-07-23T00:41:42+00:00",
    "commented_code": "return longestDeniedMatch.length >= longestAllowedMatch.length\n }\n \n+/**\n+ * Check if a command contains subshell execution that should be blocked.\n+ * Only blocks if there's a denylist configured and the command isn't just outputting text.\n+ */\n+function containsBlockableSubshell(command: string, deniedCommands?: string[]): boolean {\n+\tif (!deniedCommands?.length) return false\n+\n+\tconst trimmedCommand = command.trim()\n+\tconst isTextOutputCommand =\n+\t\t/^(echo|printf|cat|print)\\s+[\"']/.test(trimmedCommand) || /^(echo|printf|cat|print)\\s+\\\\?\"/.test(trimmedCommand)\n+\n+\tif (isTextOutputCommand) return false\n+\n+\t// Look for actual command substitution $()\n+\tconst hasCommandSubstitution = /\\$\\([^)]+\\)/.test(command)\n+\n+\t// For backticks, be more careful - they could be in markdown\n+\tlet hasBacktickSubstitution = false\n+\tif (command.includes(\"`\")) {\n+\t\t// Simple heuristic: if the command has multi-line content or markdown-like\n+\t\t// patterns, the backticks are probably not for command substitution\n+\t\tconst hasMarkdownIndicators =\n+\t\t\tcommand.includes(\"```\") || command.includes(\"\n\") || command.includes(\"##\") || command.includes(\"**\")\n+\n+\t\tif (!hasMarkdownIndicators) {\n+\t\t\t// Check if backticks are likely command substitution\n+\t\t\t// Look for patterns like: cmd `subcmd` or var=`cmd`\n+\t\t\thasBacktickSubstitution = /[^\\\\]`[^`\n]+`/.test(command)",
    "repo_full_name": "RooCodeInc/Roo-Code",
    "discussion_comments": [
      {
        "comment_id": "2224079940",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 6088,
        "pr_file": "webview-ui/src/utils/command-validation.ts",
        "discussion_id": "2224079940",
        "commented_code": "@@ -279,6 +280,40 @@ export function isAutoDeniedSingleCommand(\n \treturn longestDeniedMatch.length >= longestAllowedMatch.length\n }\n \n+/**\n+ * Check if a command contains subshell execution that should be blocked.\n+ * Only blocks if there's a denylist configured and the command isn't just outputting text.\n+ */\n+function containsBlockableSubshell(command: string, deniedCommands?: string[]): boolean {\n+\tif (!deniedCommands?.length) return false\n+\n+\tconst trimmedCommand = command.trim()\n+\tconst isTextOutputCommand =\n+\t\t/^(echo|printf|cat|print)\\s+[\"']/.test(trimmedCommand) || /^(echo|printf|cat|print)\\s+\\\\?\"/.test(trimmedCommand)\n+\n+\tif (isTextOutputCommand) return false\n+\n+\t// Look for actual command substitution $()\n+\tconst hasCommandSubstitution = /\\$\\([^)]+\\)/.test(command)\n+\n+\t// For backticks, be more careful - they could be in markdown\n+\tlet hasBacktickSubstitution = false\n+\tif (command.includes(\"`\")) {\n+\t\t// Simple heuristic: if the command has multi-line content or markdown-like\n+\t\t// patterns, the backticks are probably not for command substitution\n+\t\tconst hasMarkdownIndicators =\n+\t\t\tcommand.includes(\"```\") || command.includes(\"\\n\") || command.includes(\"##\") || command.includes(\"**\")\n+\n+\t\tif (!hasMarkdownIndicators) {\n+\t\t\t// Check if backticks are likely command substitution\n+\t\t\t// Look for patterns like: cmd `subcmd` or var=`cmd`\n+\t\t\thasBacktickSubstitution = /[^\\\\]`[^`\\n]+`/.test(command)",
        "comment_created_at": "2025-07-23T00:41:42+00:00",
        "comment_author": "ellipsis-dev[bot]",
        "comment_body": "The regex /[^\\\\]`[^`\\n]+`/ in containsBlockableSubshell won\u2019t match a backtick at the start of the string. Consider using a pattern like /(?:^|[^\\\\])`[^`\\n]+`/ to correctly capture such cases.\n```suggestion\n\t\t\thasBacktickSubstitution = /(?:^|[^\\\\])`[^`\\n]+`/.test(command)\n```\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2170106741",
    "pr_number": 3785,
    "pr_file": "src/core/task-persistence/taskHistory.ts",
    "created_at": "2025-06-26T22:01:21+00:00",
    "commented_code": "+import * as path from \"path\"\n+import * as fs from \"fs/promises\"\n+import getFolderSize from \"get-folder-size\"\n+import { safeWriteJson, safeReadJson } from \"../../utils/safeWriteJson\"\n+import { getWorkspacePath } from \"../../utils/path\"\n+import {\n+\tHistoryItem,\n+\tHistorySortOption,\n+\tHistorySearchOptions,\n+\tHistorySearchResults,\n+\tHistorySearchResultItem,\n+\tHistoryWorkspaceItem,\n+\tHistoryScanResults,\n+\tHistoryRebuildOptions,\n+} from \"@roo-code/types\"\n+import { getExtensionContext } from \"../../extension\"\n+import { taskHistorySearch } from \"./taskHistorySearch\"\n+\n+const TASK_HISTORY_MONTH_INDEX_PREFIX = \"task_history-\"\n+const TASK_DIR_NAME = \"tasks\"\n+const TASK_HISTORY_DIR_NAME = \"taskHistory\"\n+const TASK_HISTORY_VERSION_KEY = \"taskHistoryVersion\"\n+const CURRENT_TASK_HISTORY_VERSION = 2 // Version 1: old array, Version 2: new file-based\n+const WORKSPACES_INDEX_FILE = \"workspaces.index.json\"\n+\n+// Configuration for batch processing; empirically, a value of 16 seems to perform best:\n+const BATCH_SIZE = 16\n+\n+const itemObjectCache = new Map<string, HistoryItem>()\n+\n+/**\n+ * Gets the base path for task HistoryItem storage in tasks/<id>/history_item.json\n+ * @returns The base path string for task items.\n+ */\n+function _getTasksBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn path.join(context.globalStorageUri.fsPath, TASK_DIR_NAME)\n+}\n+\n+/**\n+ * Gets the base path for monthly index storage.\n+ * @returns The base path string for monthly indexes.\n+ */\n+function _getHistoryIndexesBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn path.join(context.globalStorageUri.fsPath, TASK_HISTORY_DIR_NAME)\n+}\n+\n+/**\n+ * Gets the base path for backup files.\n+ * @returns The base path string for backup files.\n+ */\n+function _getBackupBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn context.globalStorageUri.fsPath\n+}\n+\n+/**\n+ * Extracts year (YYYY) and month (MM) from a timestamp.\n+ * @param timestamp - Milliseconds since epoch.\n+ * @returns Object with year and month strings.\n+ */\n+function _getYearMonthFromTs(timestamp: number): { year: string; month: string } {\n+\tconst date = new Date(timestamp)\n+\tconst year = date.getFullYear().toString()\n+\tconst month = (date.getMonth() + 1).toString().padStart(2, \"0\")\n+\treturn { year, month }\n+}\n+\n+/**\n+ * Gets the path for a month's index file.\n+ * @param year - YYYY string.\n+ * @param month - MM string.\n+ * @returns The file path string.\n+ */\n+function _getMonthIndexFilePath(year: string, month: string): string {\n+\tconst basePath = _getHistoryIndexesBasePath()\n+\treturn path.join(basePath, `${year}-${month}.index.json`)\n+}\n+\n+/**\n+ * Gets the path for the workspaces index file.\n+ * @returns The file path string.\n+ */\n+function _getWorkspacesIndexFilePath(): string {\n+\tconst basePath = _getHistoryIndexesBasePath()\n+\treturn path.join(basePath, WORKSPACES_INDEX_FILE)\n+}\n+\n+/**\n+ * Constructs the full file path for a history item.\n+ * @param taskId - The ID of the task.\n+ * @returns Full path to the history item's JSON file.\n+ */\n+function _getHistoryItemPath(taskId: string): string {\n+\tconst tasksBasePath = _getTasksBasePath()\n+\treturn path.join(tasksBasePath, taskId, \"history_item.json\")\n+}\n+\n+/**\n+ * Reads the index object for a given month from a JSON file.\n+ * The object maps workspacePath to an inner object, which maps taskId to its timestamp.\n+ * e.g., { \"workspace/path\": { \"task-id-1\": 12345, \"task-id-2\": 67890 } }\n+ * @param year - YYYY string.\n+ * @param month - MM string.\n+ * @returns The Record of {workspacePath: {[taskId: string]: timestamp}}, or an empty object if not found.\n+ */\n+async function _readTaskHistoryMonthIndex(\n+\tyear: string,\n+\tmonth: string,\n+): Promise<Record<string, Record<string, number>>> {\n+\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\ttry {\n+\t\tconst data = await safeReadJson(indexPath)\n+\t\tif (data && typeof data === \"object\" && !Array.isArray(data)) {\n+\t\t\treturn data\n+\t\t}\n+\t} catch (error) {\n+\t\tconsole.error(`[TaskHistory] Error reading month index file for ${year}-${month}:`, error)\n+\t}\n+\treturn {}\n+}\n+\n+/**\n+ * Extracts task references from month data, optionally filtering by workspace.\n+ * @param monthDataByWorkspace - The month data indexed by workspace.\n+ * @param workspacePath - Optional workspace path to filter by.\n+ * @returns Array of task references with id and timestamp.\n+ */\n+function _getTasksByWorkspace(\n+\tmonthDataByWorkspace: Record<string, Record<string, number>>,\n+\tworkspacePath?: string,\n+): Array<{ id: string; ts: number }> {\n+\tconst tasksToFetch: Array<{ id: string; ts: number }> = []\n+\n+\t// Handle special paths\n+\tlet effectiveWorkspacePath = workspacePath\n+\n+\tif (workspacePath === \"all\") {\n+\t\teffectiveWorkspacePath = \"all\"\n+\t} else if (workspacePath === \"current\" || workspacePath === undefined || workspacePath === \"\") {\n+\t\t// Get the current workspace path from VSCode\n+\t\teffectiveWorkspacePath = getWorkspacePath()\n+\t}\n+\n+\t// If effectiveWorkspacePath is undefined, show all workspaces\n+\tif (effectiveWorkspacePath === \"all\") {\n+\t\t// All workspaces for the month\n+\t\tfor (const wsPathKey in monthDataByWorkspace) {\n+\t\t\tconst tasksInCurrentWorkspace = monthDataByWorkspace[wsPathKey]\n+\t\t\tif (tasksInCurrentWorkspace) {\n+\t\t\t\tfor (const id in tasksInCurrentWorkspace) {\n+\t\t\t\t\tif (Object.prototype.hasOwnProperty.call(tasksInCurrentWorkspace, id)) {\n+\t\t\t\t\t\ttasksToFetch.push({ id, ts: tasksInCurrentWorkspace[id] })\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t} else if (effectiveWorkspacePath !== undefined) {\n+\t\t// Filter by single workspace\n+\t\tconst tasksInWorkspace = monthDataByWorkspace[effectiveWorkspacePath]\n+\t\tif (tasksInWorkspace) {\n+\t\t\tfor (const id in tasksInWorkspace) {\n+\t\t\t\tif (Object.prototype.hasOwnProperty.call(tasksInWorkspace, id)) {\n+\t\t\t\t\ttasksToFetch.push({ id, ts: tasksInWorkspace[id] })\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\treturn tasksToFetch\n+}\n+\n+/**\n+ * Prepares task references for processing by filtering by date range and sorting.\n+ * We consider this \"fast\" because it does not read the history item from disk,\n+ * so it is a preliminary sort-filter.\n+ *\n+ * @param tasks - Array of task references with id and timestamp.\n+ * @param dateRange - Optional date range to filter by.\n+ * @param sortOption - Optional sort option (defaults to \"newest\").\n+ * @returns Filtered and sorted array of task references.\n+ */\n+function _fastSortFilterTasks(\n+\ttasks: Array<{ id: string; ts: number }>,\n+\tdateRange?: { fromTs?: number; toTs?: number },\n+\tsortOption: HistorySortOption = \"newest\",\n+): Array<{ id: string; ts: number }> {\n+\tconst fromTsNum = dateRange?.fromTs\n+\tconst toTsNum = dateRange?.toTs\n+\n+\t// Filter by date range\n+\tlet filteredTasks = tasks\n+\tif (fromTsNum || toTsNum) {\n+\t\tfilteredTasks = tasks.filter((taskRef) => {\n+\t\t\tif (fromTsNum && taskRef.ts < fromTsNum) {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t\tif (toTsNum && taskRef.ts > toTsNum) {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t\treturn true\n+\t\t})\n+\t}\n+\n+\t// Sort by timestamp based on sortOption\n+\tif (sortOption === \"oldest\") {\n+\t\treturn filteredTasks.sort((a, b) => a.ts - b.ts)\n+\t} else {\n+\t\t// Default to \"newest\" for all other sort options at this stage\n+\t\t// Other sort options (mostExpensive, mostTokens, mostRelevant) require the full HistoryItem\n+\t\t// and will be handled by _sortHistoryItems after fetching the items\n+\t\treturn filteredTasks.sort((a, b) => b.ts - a.ts)\n+\t}\n+}\n+\n+// Public API Functions\n+\n+/**\n+ * Adds or updates multiple history items.\n+ * This is the primary method for saving items.\n+ * @param items - An array of HistoryItem objects to set.\n+ */\n+export async function setHistoryItems(items: HistoryItem[]): Promise<void> {\n+\tif (!Array.isArray(items)) {\n+\t\tthrow new Error(\"Invalid argument: items must be an array.\")\n+\t}\n+\n+\t// Return early if there's nothing to set\n+\tif (items.length === 0) {\n+\t\treturn\n+\t}\n+\n+\t// Group items by month for efficient processing\n+\tconst itemsByMonth = new Map<string, Map<string, HistoryItem>>()\n+\n+\t// First pass: group items by month\n+\tfor (const item of items) {\n+\t\tif (!item || !item.id || typeof item.ts !== \"number\" || typeof item.task !== \"string\") {\n+\t\t\t// Use console.warn for this since it's not part of the normal operation logs\n+\t\t\tconsole.warn(\n+\t\t\t\t`[setHistoryItems] Invalid HistoryItem skipped (missing id, ts, or task): ${JSON.stringify(item)}`,\n+\t\t\t)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\t// workspace updates - use \"unknown\" instead of empty string\n+\t\tif (item.workspace === undefined || item.workspace === \"\") {\n+\t\t\titem.workspace = \"unknown\"\n+\t\t}\n+\n+\t\t// Group by month for index updates\n+\t\tconst { year, month } = _getYearMonthFromTs(item.ts)\n+\t\tconst monthKey = `${year}-${month}`\n+\n+\t\tif (!itemsByMonth.has(monthKey)) {\n+\t\t\titemsByMonth.set(monthKey, new Map<string, HistoryItem>())\n+\t\t}\n+\t\titemsByMonth.get(monthKey)!.set(item.id, item)\n+\t}\n+\n+\t// Use a single set to track all pending promises with a maximum of BATCH_SIZE in flight\n+\tconst pendingPromises = new Set<Promise<any>>()\n+\tconst workspaceUpdates: Record<string, number> = {}\n+\n+\t// Second pass: save individual item files\n+\tfor (const [monthKey, itemsInMonth] of itemsByMonth.entries()) {\n+\t\tconst count = itemsInMonth.size\n+\t\tif (count > 1) {\n+\t\t\tconsole.debug(`[setHistoryItems] Processing ${itemsInMonth.size} items for month ${monthKey}`)\n+\t\t}\n+\n+\t\t// Process all items in the month\n+\t\tfor (const [itemId, item] of itemsInMonth.entries()) {\n+\t\t\t// Collect workspace updates; item.workspace is guaranteed to be defined in the first pass:\n+\t\t\tconst workspacePathForIndex = item.workspace!\n+\n+\t\t\tif (!workspaceUpdates[workspacePathForIndex] || item.ts > workspaceUpdates[workspacePathForIndex]) {\n+\t\t\t\tworkspaceUpdates[workspacePathForIndex] = item.ts\n+\t\t\t}\n+\n+\t\t\t// Start a new operation\n+\t\t\tconst itemPath = _getHistoryItemPath(item.id)\n+\t\t\tconst promise = safeWriteJson(itemPath, item)\n+\n+\t\t\t// Add to pending set first\n+\t\t\tpendingPromises.add(promise)\n+\n+\t\t\t// Then attach the cleanup handlers to prevent any possible races\n+\t\t\tpromise\n+\t\t\t\t.then(() => {\n+\t\t\t\t\t// Cache the item after successful save\n+\t\t\t\t\titemObjectCache.set(item.id, item)\n+\t\t\t\t\t// Remove this promise from the pending set\n+\t\t\t\t\tpendingPromises.delete(promise)\n+\t\t\t\t\treturn item.id\n+\t\t\t\t})\n+\t\t\t\t.catch((error) => {\n+\t\t\t\t\tconsole.error(`[setHistoryItems] Error processing history item ${item.id}:`, error)\n+\t\t\t\t\t// Remove this promise from the pending set\n+\t\t\t\t\tpendingPromises.delete(promise)\n+\t\t\t\t\treturn undefined\n+\t\t\t\t})\n+\n+\t\t\t// Wait while we've reached the maximum in-flight operations\n+\t\t\twhile (pendingPromises.size >= BATCH_SIZE) {\n+\t\t\t\tawait Promise.race(pendingPromises)\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// Third pass: update month indexes\n+\tfor (const [monthKey, itemsInMonth] of itemsByMonth.entries()) {\n+\t\tconst [year, month] = monthKey.split(\"-\")\n+\t\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\n+\t\t// Create a promise for this month's update\n+\t\tconst monthUpdatePromise = safeWriteJson(indexPath, {}, async (currentMonthData) => {\n+\t\t\t// Update each item in this month\n+\t\t\tfor (const [itemId, item] of itemsInMonth.entries()) {\n+\t\t\t\t// Use \"unknown\" as the index key if item.workspace is undefined or empty\n+\t\t\t\tlet workspacePathForIndex\n+\t\t\t\tif (item.workspace === undefined || item.workspace === \"\") {\n+\t\t\t\t\tworkspacePathForIndex = \"unknown\"\n+\t\t\t\t} else {\n+\t\t\t\t\tworkspacePathForIndex = item.workspace\n+\t\t\t\t}\n+\n+\t\t\t\t// Initialize workspace if needed - TypeScript requires explicit initialization\n+\t\t\t\tif (!currentMonthData[workspacePathForIndex]) {\n+\t\t\t\t\tcurrentMonthData[workspacePathForIndex] = {}\n+\t\t\t\t}\n+\n+\t\t\t\t// Update the item reference\n+\t\t\t\tcurrentMonthData[workspacePathForIndex][itemId] = item.ts\n+\t\t\t}\n+\n+\t\t\treturn true // Return true to write\n+\t\t})\n+\n+\t\t// Add to the collection of promises first\n+\t\tpendingPromises.add(monthUpdatePromise)\n+\n+\t\t// Then attach the cleanup handlers to prevent any possible races\n+\t\tmonthUpdatePromise\n+\t\t\t.then(() => {\n+\t\t\t\tpendingPromises.delete(monthUpdatePromise)\n+\t\t\t})\n+\t\t\t.catch((error) => {\n+\t\t\t\tconsole.error(`[setHistoryItems] Error updating month index for ${monthKey}:`, error)\n+\t\t\t\tpendingPromises.delete(monthUpdatePromise)\n+\t\t\t})\n+\t}\n+\n+\t// Add workspaces index update\n+\tconst workspacesIndexPath = _getWorkspacesIndexFilePath()\n+\tconst workspacesUpdatePromise = safeWriteJson(workspacesIndexPath, {}, async (currentWorkspacesData) => {\n+\t\t// Update each workspace timestamp from the collected data\n+\t\tfor (const [workspacePath, timestamp] of Object.entries(workspaceUpdates)) {\n+\t\t\t// Update the workspace timestamp if it's newer\n+\t\t\tif (!currentWorkspacesData[workspacePath] || timestamp > currentWorkspacesData[workspacePath]) {\n+\t\t\t\tcurrentWorkspacesData[workspacePath] = timestamp\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn true // Return true to write\n+\t})\n+\n+\t// Add to the collection of promises first\n+\tpendingPromises.add(workspacesUpdatePromise)\n+\n+\t// Then attach the cleanup handlers to prevent any possible races\n+\tworkspacesUpdatePromise\n+\t\t.then(() => {\n+\t\t\tpendingPromises.delete(workspacesUpdatePromise)\n+\t\t})\n+\t\t.catch((error) => {\n+\t\t\tconsole.error(`[setHistoryItems] Error updating workspaces index:`, error)\n+\t\t\tpendingPromises.delete(workspacesUpdatePromise)\n+\t\t})\n+\n+\t// Wait for all remaining operations to complete\n+\tif (pendingPromises.size > 0) {\n+\t\tawait Promise.all(pendingPromises)\n+\t}\n+}\n+\n+/**\n+ * Retrieves a specific history item by its ID.\n+ * Uses an in-memory cache first, then falls back to file storage.\n+ * @param taskId - The ID of the task to retrieve.\n+ * @returns The HistoryItem if found, otherwise undefined.\n+ */\n+export async function getHistoryItem(taskId: string, useCache: boolean = true): Promise<HistoryItem | undefined> {\n+\t// Check cache first (fast path)\n+\tif (useCache && itemObjectCache.has(taskId)) {\n+\t\treturn itemObjectCache.get(taskId)\n+\t}\n+\n+\t// Cache miss - read from file using safeReadJson\n+\tconst itemPath = _getHistoryItemPath(taskId)\n+\ttry {\n+\t\tconst historyItem = await safeReadJson(itemPath)\n+\n+\t\tif (historyItem && historyItem.id && historyItem.ts !== undefined && historyItem.ts > 0) {\n+\t\t\tif (useCache) {\n+\t\t\t\titemObjectCache.set(taskId, historyItem)\n+\t\t\t}\n+\n+\t\t\treturn historyItem\n+\t\t} else {\n+\t\t\tconsole.error(`[TaskHistory] [getHistoryItem] [${taskId}] ${itemPath} content is invalid:`, historyItem)\n+\t\t\treturn undefined\n+\t\t}\n+\t} catch (error: any) {\n+\t\t// Suppress ENOENT (file not found) errors, but log other errors\n+\t\tif (error.code !== \"ENOENT\") {\n+\t\t\tconsole.error(`[TaskHistory] [getHistoryItem] [${taskId}] error reading file ${itemPath}:`, error)\n+\t\t}\n+\t\treturn undefined\n+\t}\n+}\n+\n+/**\n+ * Deletes a history item by its ID.\n+ * This involves deleting the item's file and removing its references from ALL globalState month indexes.\n+ * @param taskId - The ID of the task to delete.\n+ */\n+export async function deleteHistoryItem(taskId: string): Promise<void> {\n+\tif (!taskId) {\n+\t\tthrow new Error(\"Invalid arguments: taskId is required.\")\n+\t}\n+\n+\tconst itemPath = _getHistoryItemPath(taskId)\n+\tconst itemDir = path.dirname(itemPath)\n+\n+\ttry {\n+\t\tawait fs.rm(itemDir, { recursive: true, force: true })\n+\t} catch (error: any) {\n+\t\tif (error.code !== \"ENOENT\") {\n+\t\t\tconsole.warn(\n+\t\t\t\t`[TaskHistory Migration] Error deleting history item directory ${itemDir} (may be benign if already deleted):`,\n+\t\t\t\terror,\n+\t\t\t)\n+\t\t}\n+\t}\n+\n+\titemObjectCache.delete(taskId)\n+\n+\t// Iterate all monthly indexes to ensure comprehensive cleanup of the taskId.\n+\t// We don't use getHistoryItem() here to get workspace/ts for a targeted update\n+\t// because historical index states is intentionally inconsistent (\"fuzzy\"), and we want to ensure\n+\t// the ID is removed wherever it might appear as the latest for any workspace in any month.\n+\t// Tasks may exist in multiple workspaces and this is a normal workflow when the user loads\n+\t// a task from one workspace and continues using it in another.\n+\tconst availableMonths = await getAvailableHistoryMonths()\n+\n+\tfor (const { year, month } of availableMonths) {\n+\t\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\n+\t\ttry {\n+\t\t\t// Atomic read-modify-write operation for each month\n+\t\t\tawait safeWriteJson(indexPath, {}, async (monthData) => {\n+\t\t\t\tlet updatedInThisMonth = false\n+\n+\t\t\t\tfor (const workspacePath in monthData) {\n+\t\t\t\t\tif (Object.prototype.hasOwnProperty.call(monthData, workspacePath)) {\n+\t\t\t\t\t\tconst tasksInWorkspace = monthData[workspacePath]\n+\n+\t\t\t\t\t\t// Ensure tasksInWorkspace exists and then check for taskId\n+\t\t\t\t\t\tif (tasksInWorkspace && tasksInWorkspace[taskId] !== undefined) {\n+\t\t\t\t\t\t\tdelete tasksInWorkspace[taskId]\n+\n+\t\t\t\t\t\t\t// If the workspacePath entry becomes empty after deleting the task,\n+\t\t\t\t\t\t\t// remove the workspacePath key itself\n+\t\t\t\t\t\t\tif (Object.keys(tasksInWorkspace).length === 0) {\n+\t\t\t\t\t\t\t\tdelete monthData[workspacePath]\n+\t\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t\tupdatedInThisMonth = true\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\t// Return true only if changes were made, false otherwise\n+\t\t\t\t// This prevents unnecessary file writes when nothing changed\n+\t\t\t\treturn updatedInThisMonth\n+\t\t\t})\n+\t\t} catch (error) {\n+\t\t\tconsole.error(\n+\t\t\t\t`[TaskHistory] Error updating month index for ${year}-${month} when deleting task ${taskId}:`,\n+\t\t\t\terror,\n+\t\t\t)\n+\t\t}\n+\t}\n+}\n+\n+/**\n+ * Generates a timestamp string in the format YYYY-MM-DD_HH-MM-SS\n+ * @returns Formatted timestamp string\n+ */\n+function _getTimestampString(): string {\n+\tconst now = new Date()\n+\treturn `${now.getFullYear()}-${(now.getMonth() + 1).toString().padStart(2, \"0\")}-${now.getDate().toString().padStart(2, \"0\")}_${now.getHours().toString().padStart(2, \"0\")}-${now.getMinutes().toString().padStart(2, \"0\")}-${now.getSeconds().toString().padStart(2, \"0\")}`\n+}\n+\n+/**\n+ * Helper function to log a message both to console and to an array\n+ * @param logs Array to accumulate logs\n+ * @param message The message to log\n+ * @returns The message (for convenience)\n+ */\n+/**\n+ * Logs a message to both console and an array of logs.\n+ * Tags in square brackets at the beginning of the message are shown\n+ * in the console but omitted from the logs array.\n+ */\n+function logMessage(logs: string[], message: string): string {\n+\t// Display full message including tags in console\n+\tconsole.log(message)\n+\n+\t// Extract tags and strip them from the message stored in logs array\n+\t// Using a more specific regex pattern to avoid potential ReDoS vulnerability\n+\t// Original: /^\\[(.*?)\\]\\s*(.*)$/\n+\tconst tagMatch = message.match(/^\\[([^\\]]*)\\]\\s*(.*)$/)",
    "repo_full_name": "RooCodeInc/Roo-Code",
    "discussion_comments": [
      {
        "comment_id": "2170106741",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 3785,
        "pr_file": "src/core/task-persistence/taskHistory.ts",
        "discussion_id": "2170106741",
        "commented_code": "@@ -0,0 +1,1487 @@\n+import * as path from \"path\"\n+import * as fs from \"fs/promises\"\n+import getFolderSize from \"get-folder-size\"\n+import { safeWriteJson, safeReadJson } from \"../../utils/safeWriteJson\"\n+import { getWorkspacePath } from \"../../utils/path\"\n+import {\n+\tHistoryItem,\n+\tHistorySortOption,\n+\tHistorySearchOptions,\n+\tHistorySearchResults,\n+\tHistorySearchResultItem,\n+\tHistoryWorkspaceItem,\n+\tHistoryScanResults,\n+\tHistoryRebuildOptions,\n+} from \"@roo-code/types\"\n+import { getExtensionContext } from \"../../extension\"\n+import { taskHistorySearch } from \"./taskHistorySearch\"\n+\n+const TASK_HISTORY_MONTH_INDEX_PREFIX = \"task_history-\"\n+const TASK_DIR_NAME = \"tasks\"\n+const TASK_HISTORY_DIR_NAME = \"taskHistory\"\n+const TASK_HISTORY_VERSION_KEY = \"taskHistoryVersion\"\n+const CURRENT_TASK_HISTORY_VERSION = 2 // Version 1: old array, Version 2: new file-based\n+const WORKSPACES_INDEX_FILE = \"workspaces.index.json\"\n+\n+// Configuration for batch processing; empirically, a value of 16 seems to perform best:\n+const BATCH_SIZE = 16\n+\n+const itemObjectCache = new Map<string, HistoryItem>()\n+\n+/**\n+ * Gets the base path for task HistoryItem storage in tasks/<id>/history_item.json\n+ * @returns The base path string for task items.\n+ */\n+function _getTasksBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn path.join(context.globalStorageUri.fsPath, TASK_DIR_NAME)\n+}\n+\n+/**\n+ * Gets the base path for monthly index storage.\n+ * @returns The base path string for monthly indexes.\n+ */\n+function _getHistoryIndexesBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn path.join(context.globalStorageUri.fsPath, TASK_HISTORY_DIR_NAME)\n+}\n+\n+/**\n+ * Gets the base path for backup files.\n+ * @returns The base path string for backup files.\n+ */\n+function _getBackupBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn context.globalStorageUri.fsPath\n+}\n+\n+/**\n+ * Extracts year (YYYY) and month (MM) from a timestamp.\n+ * @param timestamp - Milliseconds since epoch.\n+ * @returns Object with year and month strings.\n+ */\n+function _getYearMonthFromTs(timestamp: number): { year: string; month: string } {\n+\tconst date = new Date(timestamp)\n+\tconst year = date.getFullYear().toString()\n+\tconst month = (date.getMonth() + 1).toString().padStart(2, \"0\")\n+\treturn { year, month }\n+}\n+\n+/**\n+ * Gets the path for a month's index file.\n+ * @param year - YYYY string.\n+ * @param month - MM string.\n+ * @returns The file path string.\n+ */\n+function _getMonthIndexFilePath(year: string, month: string): string {\n+\tconst basePath = _getHistoryIndexesBasePath()\n+\treturn path.join(basePath, `${year}-${month}.index.json`)\n+}\n+\n+/**\n+ * Gets the path for the workspaces index file.\n+ * @returns The file path string.\n+ */\n+function _getWorkspacesIndexFilePath(): string {\n+\tconst basePath = _getHistoryIndexesBasePath()\n+\treturn path.join(basePath, WORKSPACES_INDEX_FILE)\n+}\n+\n+/**\n+ * Constructs the full file path for a history item.\n+ * @param taskId - The ID of the task.\n+ * @returns Full path to the history item's JSON file.\n+ */\n+function _getHistoryItemPath(taskId: string): string {\n+\tconst tasksBasePath = _getTasksBasePath()\n+\treturn path.join(tasksBasePath, taskId, \"history_item.json\")\n+}\n+\n+/**\n+ * Reads the index object for a given month from a JSON file.\n+ * The object maps workspacePath to an inner object, which maps taskId to its timestamp.\n+ * e.g., { \"workspace/path\": { \"task-id-1\": 12345, \"task-id-2\": 67890 } }\n+ * @param year - YYYY string.\n+ * @param month - MM string.\n+ * @returns The Record of {workspacePath: {[taskId: string]: timestamp}}, or an empty object if not found.\n+ */\n+async function _readTaskHistoryMonthIndex(\n+\tyear: string,\n+\tmonth: string,\n+): Promise<Record<string, Record<string, number>>> {\n+\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\ttry {\n+\t\tconst data = await safeReadJson(indexPath)\n+\t\tif (data && typeof data === \"object\" && !Array.isArray(data)) {\n+\t\t\treturn data\n+\t\t}\n+\t} catch (error) {\n+\t\tconsole.error(`[TaskHistory] Error reading month index file for ${year}-${month}:`, error)\n+\t}\n+\treturn {}\n+}\n+\n+/**\n+ * Extracts task references from month data, optionally filtering by workspace.\n+ * @param monthDataByWorkspace - The month data indexed by workspace.\n+ * @param workspacePath - Optional workspace path to filter by.\n+ * @returns Array of task references with id and timestamp.\n+ */\n+function _getTasksByWorkspace(\n+\tmonthDataByWorkspace: Record<string, Record<string, number>>,\n+\tworkspacePath?: string,\n+): Array<{ id: string; ts: number }> {\n+\tconst tasksToFetch: Array<{ id: string; ts: number }> = []\n+\n+\t// Handle special paths\n+\tlet effectiveWorkspacePath = workspacePath\n+\n+\tif (workspacePath === \"all\") {\n+\t\teffectiveWorkspacePath = \"all\"\n+\t} else if (workspacePath === \"current\" || workspacePath === undefined || workspacePath === \"\") {\n+\t\t// Get the current workspace path from VSCode\n+\t\teffectiveWorkspacePath = getWorkspacePath()\n+\t}\n+\n+\t// If effectiveWorkspacePath is undefined, show all workspaces\n+\tif (effectiveWorkspacePath === \"all\") {\n+\t\t// All workspaces for the month\n+\t\tfor (const wsPathKey in monthDataByWorkspace) {\n+\t\t\tconst tasksInCurrentWorkspace = monthDataByWorkspace[wsPathKey]\n+\t\t\tif (tasksInCurrentWorkspace) {\n+\t\t\t\tfor (const id in tasksInCurrentWorkspace) {\n+\t\t\t\t\tif (Object.prototype.hasOwnProperty.call(tasksInCurrentWorkspace, id)) {\n+\t\t\t\t\t\ttasksToFetch.push({ id, ts: tasksInCurrentWorkspace[id] })\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t} else if (effectiveWorkspacePath !== undefined) {\n+\t\t// Filter by single workspace\n+\t\tconst tasksInWorkspace = monthDataByWorkspace[effectiveWorkspacePath]\n+\t\tif (tasksInWorkspace) {\n+\t\t\tfor (const id in tasksInWorkspace) {\n+\t\t\t\tif (Object.prototype.hasOwnProperty.call(tasksInWorkspace, id)) {\n+\t\t\t\t\ttasksToFetch.push({ id, ts: tasksInWorkspace[id] })\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\treturn tasksToFetch\n+}\n+\n+/**\n+ * Prepares task references for processing by filtering by date range and sorting.\n+ * We consider this \"fast\" because it does not read the history item from disk,\n+ * so it is a preliminary sort-filter.\n+ *\n+ * @param tasks - Array of task references with id and timestamp.\n+ * @param dateRange - Optional date range to filter by.\n+ * @param sortOption - Optional sort option (defaults to \"newest\").\n+ * @returns Filtered and sorted array of task references.\n+ */\n+function _fastSortFilterTasks(\n+\ttasks: Array<{ id: string; ts: number }>,\n+\tdateRange?: { fromTs?: number; toTs?: number },\n+\tsortOption: HistorySortOption = \"newest\",\n+): Array<{ id: string; ts: number }> {\n+\tconst fromTsNum = dateRange?.fromTs\n+\tconst toTsNum = dateRange?.toTs\n+\n+\t// Filter by date range\n+\tlet filteredTasks = tasks\n+\tif (fromTsNum || toTsNum) {\n+\t\tfilteredTasks = tasks.filter((taskRef) => {\n+\t\t\tif (fromTsNum && taskRef.ts < fromTsNum) {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t\tif (toTsNum && taskRef.ts > toTsNum) {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t\treturn true\n+\t\t})\n+\t}\n+\n+\t// Sort by timestamp based on sortOption\n+\tif (sortOption === \"oldest\") {\n+\t\treturn filteredTasks.sort((a, b) => a.ts - b.ts)\n+\t} else {\n+\t\t// Default to \"newest\" for all other sort options at this stage\n+\t\t// Other sort options (mostExpensive, mostTokens, mostRelevant) require the full HistoryItem\n+\t\t// and will be handled by _sortHistoryItems after fetching the items\n+\t\treturn filteredTasks.sort((a, b) => b.ts - a.ts)\n+\t}\n+}\n+\n+// Public API Functions\n+\n+/**\n+ * Adds or updates multiple history items.\n+ * This is the primary method for saving items.\n+ * @param items - An array of HistoryItem objects to set.\n+ */\n+export async function setHistoryItems(items: HistoryItem[]): Promise<void> {\n+\tif (!Array.isArray(items)) {\n+\t\tthrow new Error(\"Invalid argument: items must be an array.\")\n+\t}\n+\n+\t// Return early if there's nothing to set\n+\tif (items.length === 0) {\n+\t\treturn\n+\t}\n+\n+\t// Group items by month for efficient processing\n+\tconst itemsByMonth = new Map<string, Map<string, HistoryItem>>()\n+\n+\t// First pass: group items by month\n+\tfor (const item of items) {\n+\t\tif (!item || !item.id || typeof item.ts !== \"number\" || typeof item.task !== \"string\") {\n+\t\t\t// Use console.warn for this since it's not part of the normal operation logs\n+\t\t\tconsole.warn(\n+\t\t\t\t`[setHistoryItems] Invalid HistoryItem skipped (missing id, ts, or task): ${JSON.stringify(item)}`,\n+\t\t\t)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\t// workspace updates - use \"unknown\" instead of empty string\n+\t\tif (item.workspace === undefined || item.workspace === \"\") {\n+\t\t\titem.workspace = \"unknown\"\n+\t\t}\n+\n+\t\t// Group by month for index updates\n+\t\tconst { year, month } = _getYearMonthFromTs(item.ts)\n+\t\tconst monthKey = `${year}-${month}`\n+\n+\t\tif (!itemsByMonth.has(monthKey)) {\n+\t\t\titemsByMonth.set(monthKey, new Map<string, HistoryItem>())\n+\t\t}\n+\t\titemsByMonth.get(monthKey)!.set(item.id, item)\n+\t}\n+\n+\t// Use a single set to track all pending promises with a maximum of BATCH_SIZE in flight\n+\tconst pendingPromises = new Set<Promise<any>>()\n+\tconst workspaceUpdates: Record<string, number> = {}\n+\n+\t// Second pass: save individual item files\n+\tfor (const [monthKey, itemsInMonth] of itemsByMonth.entries()) {\n+\t\tconst count = itemsInMonth.size\n+\t\tif (count > 1) {\n+\t\t\tconsole.debug(`[setHistoryItems] Processing ${itemsInMonth.size} items for month ${monthKey}`)\n+\t\t}\n+\n+\t\t// Process all items in the month\n+\t\tfor (const [itemId, item] of itemsInMonth.entries()) {\n+\t\t\t// Collect workspace updates; item.workspace is guaranteed to be defined in the first pass:\n+\t\t\tconst workspacePathForIndex = item.workspace!\n+\n+\t\t\tif (!workspaceUpdates[workspacePathForIndex] || item.ts > workspaceUpdates[workspacePathForIndex]) {\n+\t\t\t\tworkspaceUpdates[workspacePathForIndex] = item.ts\n+\t\t\t}\n+\n+\t\t\t// Start a new operation\n+\t\t\tconst itemPath = _getHistoryItemPath(item.id)\n+\t\t\tconst promise = safeWriteJson(itemPath, item)\n+\n+\t\t\t// Add to pending set first\n+\t\t\tpendingPromises.add(promise)\n+\n+\t\t\t// Then attach the cleanup handlers to prevent any possible races\n+\t\t\tpromise\n+\t\t\t\t.then(() => {\n+\t\t\t\t\t// Cache the item after successful save\n+\t\t\t\t\titemObjectCache.set(item.id, item)\n+\t\t\t\t\t// Remove this promise from the pending set\n+\t\t\t\t\tpendingPromises.delete(promise)\n+\t\t\t\t\treturn item.id\n+\t\t\t\t})\n+\t\t\t\t.catch((error) => {\n+\t\t\t\t\tconsole.error(`[setHistoryItems] Error processing history item ${item.id}:`, error)\n+\t\t\t\t\t// Remove this promise from the pending set\n+\t\t\t\t\tpendingPromises.delete(promise)\n+\t\t\t\t\treturn undefined\n+\t\t\t\t})\n+\n+\t\t\t// Wait while we've reached the maximum in-flight operations\n+\t\t\twhile (pendingPromises.size >= BATCH_SIZE) {\n+\t\t\t\tawait Promise.race(pendingPromises)\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// Third pass: update month indexes\n+\tfor (const [monthKey, itemsInMonth] of itemsByMonth.entries()) {\n+\t\tconst [year, month] = monthKey.split(\"-\")\n+\t\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\n+\t\t// Create a promise for this month's update\n+\t\tconst monthUpdatePromise = safeWriteJson(indexPath, {}, async (currentMonthData) => {\n+\t\t\t// Update each item in this month\n+\t\t\tfor (const [itemId, item] of itemsInMonth.entries()) {\n+\t\t\t\t// Use \"unknown\" as the index key if item.workspace is undefined or empty\n+\t\t\t\tlet workspacePathForIndex\n+\t\t\t\tif (item.workspace === undefined || item.workspace === \"\") {\n+\t\t\t\t\tworkspacePathForIndex = \"unknown\"\n+\t\t\t\t} else {\n+\t\t\t\t\tworkspacePathForIndex = item.workspace\n+\t\t\t\t}\n+\n+\t\t\t\t// Initialize workspace if needed - TypeScript requires explicit initialization\n+\t\t\t\tif (!currentMonthData[workspacePathForIndex]) {\n+\t\t\t\t\tcurrentMonthData[workspacePathForIndex] = {}\n+\t\t\t\t}\n+\n+\t\t\t\t// Update the item reference\n+\t\t\t\tcurrentMonthData[workspacePathForIndex][itemId] = item.ts\n+\t\t\t}\n+\n+\t\t\treturn true // Return true to write\n+\t\t})\n+\n+\t\t// Add to the collection of promises first\n+\t\tpendingPromises.add(monthUpdatePromise)\n+\n+\t\t// Then attach the cleanup handlers to prevent any possible races\n+\t\tmonthUpdatePromise\n+\t\t\t.then(() => {\n+\t\t\t\tpendingPromises.delete(monthUpdatePromise)\n+\t\t\t})\n+\t\t\t.catch((error) => {\n+\t\t\t\tconsole.error(`[setHistoryItems] Error updating month index for ${monthKey}:`, error)\n+\t\t\t\tpendingPromises.delete(monthUpdatePromise)\n+\t\t\t})\n+\t}\n+\n+\t// Add workspaces index update\n+\tconst workspacesIndexPath = _getWorkspacesIndexFilePath()\n+\tconst workspacesUpdatePromise = safeWriteJson(workspacesIndexPath, {}, async (currentWorkspacesData) => {\n+\t\t// Update each workspace timestamp from the collected data\n+\t\tfor (const [workspacePath, timestamp] of Object.entries(workspaceUpdates)) {\n+\t\t\t// Update the workspace timestamp if it's newer\n+\t\t\tif (!currentWorkspacesData[workspacePath] || timestamp > currentWorkspacesData[workspacePath]) {\n+\t\t\t\tcurrentWorkspacesData[workspacePath] = timestamp\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn true // Return true to write\n+\t})\n+\n+\t// Add to the collection of promises first\n+\tpendingPromises.add(workspacesUpdatePromise)\n+\n+\t// Then attach the cleanup handlers to prevent any possible races\n+\tworkspacesUpdatePromise\n+\t\t.then(() => {\n+\t\t\tpendingPromises.delete(workspacesUpdatePromise)\n+\t\t})\n+\t\t.catch((error) => {\n+\t\t\tconsole.error(`[setHistoryItems] Error updating workspaces index:`, error)\n+\t\t\tpendingPromises.delete(workspacesUpdatePromise)\n+\t\t})\n+\n+\t// Wait for all remaining operations to complete\n+\tif (pendingPromises.size > 0) {\n+\t\tawait Promise.all(pendingPromises)\n+\t}\n+}\n+\n+/**\n+ * Retrieves a specific history item by its ID.\n+ * Uses an in-memory cache first, then falls back to file storage.\n+ * @param taskId - The ID of the task to retrieve.\n+ * @returns The HistoryItem if found, otherwise undefined.\n+ */\n+export async function getHistoryItem(taskId: string, useCache: boolean = true): Promise<HistoryItem | undefined> {\n+\t// Check cache first (fast path)\n+\tif (useCache && itemObjectCache.has(taskId)) {\n+\t\treturn itemObjectCache.get(taskId)\n+\t}\n+\n+\t// Cache miss - read from file using safeReadJson\n+\tconst itemPath = _getHistoryItemPath(taskId)\n+\ttry {\n+\t\tconst historyItem = await safeReadJson(itemPath)\n+\n+\t\tif (historyItem && historyItem.id && historyItem.ts !== undefined && historyItem.ts > 0) {\n+\t\t\tif (useCache) {\n+\t\t\t\titemObjectCache.set(taskId, historyItem)\n+\t\t\t}\n+\n+\t\t\treturn historyItem\n+\t\t} else {\n+\t\t\tconsole.error(`[TaskHistory] [getHistoryItem] [${taskId}] ${itemPath} content is invalid:`, historyItem)\n+\t\t\treturn undefined\n+\t\t}\n+\t} catch (error: any) {\n+\t\t// Suppress ENOENT (file not found) errors, but log other errors\n+\t\tif (error.code !== \"ENOENT\") {\n+\t\t\tconsole.error(`[TaskHistory] [getHistoryItem] [${taskId}] error reading file ${itemPath}:`, error)\n+\t\t}\n+\t\treturn undefined\n+\t}\n+}\n+\n+/**\n+ * Deletes a history item by its ID.\n+ * This involves deleting the item's file and removing its references from ALL globalState month indexes.\n+ * @param taskId - The ID of the task to delete.\n+ */\n+export async function deleteHistoryItem(taskId: string): Promise<void> {\n+\tif (!taskId) {\n+\t\tthrow new Error(\"Invalid arguments: taskId is required.\")\n+\t}\n+\n+\tconst itemPath = _getHistoryItemPath(taskId)\n+\tconst itemDir = path.dirname(itemPath)\n+\n+\ttry {\n+\t\tawait fs.rm(itemDir, { recursive: true, force: true })\n+\t} catch (error: any) {\n+\t\tif (error.code !== \"ENOENT\") {\n+\t\t\tconsole.warn(\n+\t\t\t\t`[TaskHistory Migration] Error deleting history item directory ${itemDir} (may be benign if already deleted):`,\n+\t\t\t\terror,\n+\t\t\t)\n+\t\t}\n+\t}\n+\n+\titemObjectCache.delete(taskId)\n+\n+\t// Iterate all monthly indexes to ensure comprehensive cleanup of the taskId.\n+\t// We don't use getHistoryItem() here to get workspace/ts for a targeted update\n+\t// because historical index states is intentionally inconsistent (\"fuzzy\"), and we want to ensure\n+\t// the ID is removed wherever it might appear as the latest for any workspace in any month.\n+\t// Tasks may exist in multiple workspaces and this is a normal workflow when the user loads\n+\t// a task from one workspace and continues using it in another.\n+\tconst availableMonths = await getAvailableHistoryMonths()\n+\n+\tfor (const { year, month } of availableMonths) {\n+\t\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\n+\t\ttry {\n+\t\t\t// Atomic read-modify-write operation for each month\n+\t\t\tawait safeWriteJson(indexPath, {}, async (monthData) => {\n+\t\t\t\tlet updatedInThisMonth = false\n+\n+\t\t\t\tfor (const workspacePath in monthData) {\n+\t\t\t\t\tif (Object.prototype.hasOwnProperty.call(monthData, workspacePath)) {\n+\t\t\t\t\t\tconst tasksInWorkspace = monthData[workspacePath]\n+\n+\t\t\t\t\t\t// Ensure tasksInWorkspace exists and then check for taskId\n+\t\t\t\t\t\tif (tasksInWorkspace && tasksInWorkspace[taskId] !== undefined) {\n+\t\t\t\t\t\t\tdelete tasksInWorkspace[taskId]\n+\n+\t\t\t\t\t\t\t// If the workspacePath entry becomes empty after deleting the task,\n+\t\t\t\t\t\t\t// remove the workspacePath key itself\n+\t\t\t\t\t\t\tif (Object.keys(tasksInWorkspace).length === 0) {\n+\t\t\t\t\t\t\t\tdelete monthData[workspacePath]\n+\t\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t\tupdatedInThisMonth = true\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\t// Return true only if changes were made, false otherwise\n+\t\t\t\t// This prevents unnecessary file writes when nothing changed\n+\t\t\t\treturn updatedInThisMonth\n+\t\t\t})\n+\t\t} catch (error) {\n+\t\t\tconsole.error(\n+\t\t\t\t`[TaskHistory] Error updating month index for ${year}-${month} when deleting task ${taskId}:`,\n+\t\t\t\terror,\n+\t\t\t)\n+\t\t}\n+\t}\n+}\n+\n+/**\n+ * Generates a timestamp string in the format YYYY-MM-DD_HH-MM-SS\n+ * @returns Formatted timestamp string\n+ */\n+function _getTimestampString(): string {\n+\tconst now = new Date()\n+\treturn `${now.getFullYear()}-${(now.getMonth() + 1).toString().padStart(2, \"0\")}-${now.getDate().toString().padStart(2, \"0\")}_${now.getHours().toString().padStart(2, \"0\")}-${now.getMinutes().toString().padStart(2, \"0\")}-${now.getSeconds().toString().padStart(2, \"0\")}`\n+}\n+\n+/**\n+ * Helper function to log a message both to console and to an array\n+ * @param logs Array to accumulate logs\n+ * @param message The message to log\n+ * @returns The message (for convenience)\n+ */\n+/**\n+ * Logs a message to both console and an array of logs.\n+ * Tags in square brackets at the beginning of the message are shown\n+ * in the console but omitted from the logs array.\n+ */\n+function logMessage(logs: string[], message: string): string {\n+\t// Display full message including tags in console\n+\tconsole.log(message)\n+\n+\t// Extract tags and strip them from the message stored in logs array\n+\t// Using a more specific regex pattern to avoid potential ReDoS vulnerability\n+\t// Original: /^\\[(.*?)\\]\\s*(.*)$/\n+\tconst tagMatch = message.match(/^\\[([^\\]]*)\\]\\s*(.*)$/)",
        "comment_created_at": "2025-06-26T22:01:21+00:00",
        "comment_author": "github-advanced-security[bot]",
        "comment_body": "## Polynomial regular expression used on uncontrolled data\n\nThis [regular expression](1) that depends on [library input](2) may run slow on strings starting with '\\[\\]' and with many repetitions of '\\t'.\n\n[Show more details](https://github.com/RooCodeInc/Roo-Code/security/code-scanning/111)",
        "pr_file_module": null
      },
      {
        "comment_id": "2170154602",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 3785,
        "pr_file": "src/core/task-persistence/taskHistory.ts",
        "discussion_id": "2170106741",
        "commented_code": "@@ -0,0 +1,1487 @@\n+import * as path from \"path\"\n+import * as fs from \"fs/promises\"\n+import getFolderSize from \"get-folder-size\"\n+import { safeWriteJson, safeReadJson } from \"../../utils/safeWriteJson\"\n+import { getWorkspacePath } from \"../../utils/path\"\n+import {\n+\tHistoryItem,\n+\tHistorySortOption,\n+\tHistorySearchOptions,\n+\tHistorySearchResults,\n+\tHistorySearchResultItem,\n+\tHistoryWorkspaceItem,\n+\tHistoryScanResults,\n+\tHistoryRebuildOptions,\n+} from \"@roo-code/types\"\n+import { getExtensionContext } from \"../../extension\"\n+import { taskHistorySearch } from \"./taskHistorySearch\"\n+\n+const TASK_HISTORY_MONTH_INDEX_PREFIX = \"task_history-\"\n+const TASK_DIR_NAME = \"tasks\"\n+const TASK_HISTORY_DIR_NAME = \"taskHistory\"\n+const TASK_HISTORY_VERSION_KEY = \"taskHistoryVersion\"\n+const CURRENT_TASK_HISTORY_VERSION = 2 // Version 1: old array, Version 2: new file-based\n+const WORKSPACES_INDEX_FILE = \"workspaces.index.json\"\n+\n+// Configuration for batch processing; empirically, a value of 16 seems to perform best:\n+const BATCH_SIZE = 16\n+\n+const itemObjectCache = new Map<string, HistoryItem>()\n+\n+/**\n+ * Gets the base path for task HistoryItem storage in tasks/<id>/history_item.json\n+ * @returns The base path string for task items.\n+ */\n+function _getTasksBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn path.join(context.globalStorageUri.fsPath, TASK_DIR_NAME)\n+}\n+\n+/**\n+ * Gets the base path for monthly index storage.\n+ * @returns The base path string for monthly indexes.\n+ */\n+function _getHistoryIndexesBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn path.join(context.globalStorageUri.fsPath, TASK_HISTORY_DIR_NAME)\n+}\n+\n+/**\n+ * Gets the base path for backup files.\n+ * @returns The base path string for backup files.\n+ */\n+function _getBackupBasePath(): string {\n+\tconst context = getExtensionContext()\n+\treturn context.globalStorageUri.fsPath\n+}\n+\n+/**\n+ * Extracts year (YYYY) and month (MM) from a timestamp.\n+ * @param timestamp - Milliseconds since epoch.\n+ * @returns Object with year and month strings.\n+ */\n+function _getYearMonthFromTs(timestamp: number): { year: string; month: string } {\n+\tconst date = new Date(timestamp)\n+\tconst year = date.getFullYear().toString()\n+\tconst month = (date.getMonth() + 1).toString().padStart(2, \"0\")\n+\treturn { year, month }\n+}\n+\n+/**\n+ * Gets the path for a month's index file.\n+ * @param year - YYYY string.\n+ * @param month - MM string.\n+ * @returns The file path string.\n+ */\n+function _getMonthIndexFilePath(year: string, month: string): string {\n+\tconst basePath = _getHistoryIndexesBasePath()\n+\treturn path.join(basePath, `${year}-${month}.index.json`)\n+}\n+\n+/**\n+ * Gets the path for the workspaces index file.\n+ * @returns The file path string.\n+ */\n+function _getWorkspacesIndexFilePath(): string {\n+\tconst basePath = _getHistoryIndexesBasePath()\n+\treturn path.join(basePath, WORKSPACES_INDEX_FILE)\n+}\n+\n+/**\n+ * Constructs the full file path for a history item.\n+ * @param taskId - The ID of the task.\n+ * @returns Full path to the history item's JSON file.\n+ */\n+function _getHistoryItemPath(taskId: string): string {\n+\tconst tasksBasePath = _getTasksBasePath()\n+\treturn path.join(tasksBasePath, taskId, \"history_item.json\")\n+}\n+\n+/**\n+ * Reads the index object for a given month from a JSON file.\n+ * The object maps workspacePath to an inner object, which maps taskId to its timestamp.\n+ * e.g., { \"workspace/path\": { \"task-id-1\": 12345, \"task-id-2\": 67890 } }\n+ * @param year - YYYY string.\n+ * @param month - MM string.\n+ * @returns The Record of {workspacePath: {[taskId: string]: timestamp}}, or an empty object if not found.\n+ */\n+async function _readTaskHistoryMonthIndex(\n+\tyear: string,\n+\tmonth: string,\n+): Promise<Record<string, Record<string, number>>> {\n+\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\ttry {\n+\t\tconst data = await safeReadJson(indexPath)\n+\t\tif (data && typeof data === \"object\" && !Array.isArray(data)) {\n+\t\t\treturn data\n+\t\t}\n+\t} catch (error) {\n+\t\tconsole.error(`[TaskHistory] Error reading month index file for ${year}-${month}:`, error)\n+\t}\n+\treturn {}\n+}\n+\n+/**\n+ * Extracts task references from month data, optionally filtering by workspace.\n+ * @param monthDataByWorkspace - The month data indexed by workspace.\n+ * @param workspacePath - Optional workspace path to filter by.\n+ * @returns Array of task references with id and timestamp.\n+ */\n+function _getTasksByWorkspace(\n+\tmonthDataByWorkspace: Record<string, Record<string, number>>,\n+\tworkspacePath?: string,\n+): Array<{ id: string; ts: number }> {\n+\tconst tasksToFetch: Array<{ id: string; ts: number }> = []\n+\n+\t// Handle special paths\n+\tlet effectiveWorkspacePath = workspacePath\n+\n+\tif (workspacePath === \"all\") {\n+\t\teffectiveWorkspacePath = \"all\"\n+\t} else if (workspacePath === \"current\" || workspacePath === undefined || workspacePath === \"\") {\n+\t\t// Get the current workspace path from VSCode\n+\t\teffectiveWorkspacePath = getWorkspacePath()\n+\t}\n+\n+\t// If effectiveWorkspacePath is undefined, show all workspaces\n+\tif (effectiveWorkspacePath === \"all\") {\n+\t\t// All workspaces for the month\n+\t\tfor (const wsPathKey in monthDataByWorkspace) {\n+\t\t\tconst tasksInCurrentWorkspace = monthDataByWorkspace[wsPathKey]\n+\t\t\tif (tasksInCurrentWorkspace) {\n+\t\t\t\tfor (const id in tasksInCurrentWorkspace) {\n+\t\t\t\t\tif (Object.prototype.hasOwnProperty.call(tasksInCurrentWorkspace, id)) {\n+\t\t\t\t\t\ttasksToFetch.push({ id, ts: tasksInCurrentWorkspace[id] })\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t} else if (effectiveWorkspacePath !== undefined) {\n+\t\t// Filter by single workspace\n+\t\tconst tasksInWorkspace = monthDataByWorkspace[effectiveWorkspacePath]\n+\t\tif (tasksInWorkspace) {\n+\t\t\tfor (const id in tasksInWorkspace) {\n+\t\t\t\tif (Object.prototype.hasOwnProperty.call(tasksInWorkspace, id)) {\n+\t\t\t\t\ttasksToFetch.push({ id, ts: tasksInWorkspace[id] })\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\treturn tasksToFetch\n+}\n+\n+/**\n+ * Prepares task references for processing by filtering by date range and sorting.\n+ * We consider this \"fast\" because it does not read the history item from disk,\n+ * so it is a preliminary sort-filter.\n+ *\n+ * @param tasks - Array of task references with id and timestamp.\n+ * @param dateRange - Optional date range to filter by.\n+ * @param sortOption - Optional sort option (defaults to \"newest\").\n+ * @returns Filtered and sorted array of task references.\n+ */\n+function _fastSortFilterTasks(\n+\ttasks: Array<{ id: string; ts: number }>,\n+\tdateRange?: { fromTs?: number; toTs?: number },\n+\tsortOption: HistorySortOption = \"newest\",\n+): Array<{ id: string; ts: number }> {\n+\tconst fromTsNum = dateRange?.fromTs\n+\tconst toTsNum = dateRange?.toTs\n+\n+\t// Filter by date range\n+\tlet filteredTasks = tasks\n+\tif (fromTsNum || toTsNum) {\n+\t\tfilteredTasks = tasks.filter((taskRef) => {\n+\t\t\tif (fromTsNum && taskRef.ts < fromTsNum) {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t\tif (toTsNum && taskRef.ts > toTsNum) {\n+\t\t\t\treturn false\n+\t\t\t}\n+\t\t\treturn true\n+\t\t})\n+\t}\n+\n+\t// Sort by timestamp based on sortOption\n+\tif (sortOption === \"oldest\") {\n+\t\treturn filteredTasks.sort((a, b) => a.ts - b.ts)\n+\t} else {\n+\t\t// Default to \"newest\" for all other sort options at this stage\n+\t\t// Other sort options (mostExpensive, mostTokens, mostRelevant) require the full HistoryItem\n+\t\t// and will be handled by _sortHistoryItems after fetching the items\n+\t\treturn filteredTasks.sort((a, b) => b.ts - a.ts)\n+\t}\n+}\n+\n+// Public API Functions\n+\n+/**\n+ * Adds or updates multiple history items.\n+ * This is the primary method for saving items.\n+ * @param items - An array of HistoryItem objects to set.\n+ */\n+export async function setHistoryItems(items: HistoryItem[]): Promise<void> {\n+\tif (!Array.isArray(items)) {\n+\t\tthrow new Error(\"Invalid argument: items must be an array.\")\n+\t}\n+\n+\t// Return early if there's nothing to set\n+\tif (items.length === 0) {\n+\t\treturn\n+\t}\n+\n+\t// Group items by month for efficient processing\n+\tconst itemsByMonth = new Map<string, Map<string, HistoryItem>>()\n+\n+\t// First pass: group items by month\n+\tfor (const item of items) {\n+\t\tif (!item || !item.id || typeof item.ts !== \"number\" || typeof item.task !== \"string\") {\n+\t\t\t// Use console.warn for this since it's not part of the normal operation logs\n+\t\t\tconsole.warn(\n+\t\t\t\t`[setHistoryItems] Invalid HistoryItem skipped (missing id, ts, or task): ${JSON.stringify(item)}`,\n+\t\t\t)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\t// workspace updates - use \"unknown\" instead of empty string\n+\t\tif (item.workspace === undefined || item.workspace === \"\") {\n+\t\t\titem.workspace = \"unknown\"\n+\t\t}\n+\n+\t\t// Group by month for index updates\n+\t\tconst { year, month } = _getYearMonthFromTs(item.ts)\n+\t\tconst monthKey = `${year}-${month}`\n+\n+\t\tif (!itemsByMonth.has(monthKey)) {\n+\t\t\titemsByMonth.set(monthKey, new Map<string, HistoryItem>())\n+\t\t}\n+\t\titemsByMonth.get(monthKey)!.set(item.id, item)\n+\t}\n+\n+\t// Use a single set to track all pending promises with a maximum of BATCH_SIZE in flight\n+\tconst pendingPromises = new Set<Promise<any>>()\n+\tconst workspaceUpdates: Record<string, number> = {}\n+\n+\t// Second pass: save individual item files\n+\tfor (const [monthKey, itemsInMonth] of itemsByMonth.entries()) {\n+\t\tconst count = itemsInMonth.size\n+\t\tif (count > 1) {\n+\t\t\tconsole.debug(`[setHistoryItems] Processing ${itemsInMonth.size} items for month ${monthKey}`)\n+\t\t}\n+\n+\t\t// Process all items in the month\n+\t\tfor (const [itemId, item] of itemsInMonth.entries()) {\n+\t\t\t// Collect workspace updates; item.workspace is guaranteed to be defined in the first pass:\n+\t\t\tconst workspacePathForIndex = item.workspace!\n+\n+\t\t\tif (!workspaceUpdates[workspacePathForIndex] || item.ts > workspaceUpdates[workspacePathForIndex]) {\n+\t\t\t\tworkspaceUpdates[workspacePathForIndex] = item.ts\n+\t\t\t}\n+\n+\t\t\t// Start a new operation\n+\t\t\tconst itemPath = _getHistoryItemPath(item.id)\n+\t\t\tconst promise = safeWriteJson(itemPath, item)\n+\n+\t\t\t// Add to pending set first\n+\t\t\tpendingPromises.add(promise)\n+\n+\t\t\t// Then attach the cleanup handlers to prevent any possible races\n+\t\t\tpromise\n+\t\t\t\t.then(() => {\n+\t\t\t\t\t// Cache the item after successful save\n+\t\t\t\t\titemObjectCache.set(item.id, item)\n+\t\t\t\t\t// Remove this promise from the pending set\n+\t\t\t\t\tpendingPromises.delete(promise)\n+\t\t\t\t\treturn item.id\n+\t\t\t\t})\n+\t\t\t\t.catch((error) => {\n+\t\t\t\t\tconsole.error(`[setHistoryItems] Error processing history item ${item.id}:`, error)\n+\t\t\t\t\t// Remove this promise from the pending set\n+\t\t\t\t\tpendingPromises.delete(promise)\n+\t\t\t\t\treturn undefined\n+\t\t\t\t})\n+\n+\t\t\t// Wait while we've reached the maximum in-flight operations\n+\t\t\twhile (pendingPromises.size >= BATCH_SIZE) {\n+\t\t\t\tawait Promise.race(pendingPromises)\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\t// Third pass: update month indexes\n+\tfor (const [monthKey, itemsInMonth] of itemsByMonth.entries()) {\n+\t\tconst [year, month] = monthKey.split(\"-\")\n+\t\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\n+\t\t// Create a promise for this month's update\n+\t\tconst monthUpdatePromise = safeWriteJson(indexPath, {}, async (currentMonthData) => {\n+\t\t\t// Update each item in this month\n+\t\t\tfor (const [itemId, item] of itemsInMonth.entries()) {\n+\t\t\t\t// Use \"unknown\" as the index key if item.workspace is undefined or empty\n+\t\t\t\tlet workspacePathForIndex\n+\t\t\t\tif (item.workspace === undefined || item.workspace === \"\") {\n+\t\t\t\t\tworkspacePathForIndex = \"unknown\"\n+\t\t\t\t} else {\n+\t\t\t\t\tworkspacePathForIndex = item.workspace\n+\t\t\t\t}\n+\n+\t\t\t\t// Initialize workspace if needed - TypeScript requires explicit initialization\n+\t\t\t\tif (!currentMonthData[workspacePathForIndex]) {\n+\t\t\t\t\tcurrentMonthData[workspacePathForIndex] = {}\n+\t\t\t\t}\n+\n+\t\t\t\t// Update the item reference\n+\t\t\t\tcurrentMonthData[workspacePathForIndex][itemId] = item.ts\n+\t\t\t}\n+\n+\t\t\treturn true // Return true to write\n+\t\t})\n+\n+\t\t// Add to the collection of promises first\n+\t\tpendingPromises.add(monthUpdatePromise)\n+\n+\t\t// Then attach the cleanup handlers to prevent any possible races\n+\t\tmonthUpdatePromise\n+\t\t\t.then(() => {\n+\t\t\t\tpendingPromises.delete(monthUpdatePromise)\n+\t\t\t})\n+\t\t\t.catch((error) => {\n+\t\t\t\tconsole.error(`[setHistoryItems] Error updating month index for ${monthKey}:`, error)\n+\t\t\t\tpendingPromises.delete(monthUpdatePromise)\n+\t\t\t})\n+\t}\n+\n+\t// Add workspaces index update\n+\tconst workspacesIndexPath = _getWorkspacesIndexFilePath()\n+\tconst workspacesUpdatePromise = safeWriteJson(workspacesIndexPath, {}, async (currentWorkspacesData) => {\n+\t\t// Update each workspace timestamp from the collected data\n+\t\tfor (const [workspacePath, timestamp] of Object.entries(workspaceUpdates)) {\n+\t\t\t// Update the workspace timestamp if it's newer\n+\t\t\tif (!currentWorkspacesData[workspacePath] || timestamp > currentWorkspacesData[workspacePath]) {\n+\t\t\t\tcurrentWorkspacesData[workspacePath] = timestamp\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn true // Return true to write\n+\t})\n+\n+\t// Add to the collection of promises first\n+\tpendingPromises.add(workspacesUpdatePromise)\n+\n+\t// Then attach the cleanup handlers to prevent any possible races\n+\tworkspacesUpdatePromise\n+\t\t.then(() => {\n+\t\t\tpendingPromises.delete(workspacesUpdatePromise)\n+\t\t})\n+\t\t.catch((error) => {\n+\t\t\tconsole.error(`[setHistoryItems] Error updating workspaces index:`, error)\n+\t\t\tpendingPromises.delete(workspacesUpdatePromise)\n+\t\t})\n+\n+\t// Wait for all remaining operations to complete\n+\tif (pendingPromises.size > 0) {\n+\t\tawait Promise.all(pendingPromises)\n+\t}\n+}\n+\n+/**\n+ * Retrieves a specific history item by its ID.\n+ * Uses an in-memory cache first, then falls back to file storage.\n+ * @param taskId - The ID of the task to retrieve.\n+ * @returns The HistoryItem if found, otherwise undefined.\n+ */\n+export async function getHistoryItem(taskId: string, useCache: boolean = true): Promise<HistoryItem | undefined> {\n+\t// Check cache first (fast path)\n+\tif (useCache && itemObjectCache.has(taskId)) {\n+\t\treturn itemObjectCache.get(taskId)\n+\t}\n+\n+\t// Cache miss - read from file using safeReadJson\n+\tconst itemPath = _getHistoryItemPath(taskId)\n+\ttry {\n+\t\tconst historyItem = await safeReadJson(itemPath)\n+\n+\t\tif (historyItem && historyItem.id && historyItem.ts !== undefined && historyItem.ts > 0) {\n+\t\t\tif (useCache) {\n+\t\t\t\titemObjectCache.set(taskId, historyItem)\n+\t\t\t}\n+\n+\t\t\treturn historyItem\n+\t\t} else {\n+\t\t\tconsole.error(`[TaskHistory] [getHistoryItem] [${taskId}] ${itemPath} content is invalid:`, historyItem)\n+\t\t\treturn undefined\n+\t\t}\n+\t} catch (error: any) {\n+\t\t// Suppress ENOENT (file not found) errors, but log other errors\n+\t\tif (error.code !== \"ENOENT\") {\n+\t\t\tconsole.error(`[TaskHistory] [getHistoryItem] [${taskId}] error reading file ${itemPath}:`, error)\n+\t\t}\n+\t\treturn undefined\n+\t}\n+}\n+\n+/**\n+ * Deletes a history item by its ID.\n+ * This involves deleting the item's file and removing its references from ALL globalState month indexes.\n+ * @param taskId - The ID of the task to delete.\n+ */\n+export async function deleteHistoryItem(taskId: string): Promise<void> {\n+\tif (!taskId) {\n+\t\tthrow new Error(\"Invalid arguments: taskId is required.\")\n+\t}\n+\n+\tconst itemPath = _getHistoryItemPath(taskId)\n+\tconst itemDir = path.dirname(itemPath)\n+\n+\ttry {\n+\t\tawait fs.rm(itemDir, { recursive: true, force: true })\n+\t} catch (error: any) {\n+\t\tif (error.code !== \"ENOENT\") {\n+\t\t\tconsole.warn(\n+\t\t\t\t`[TaskHistory Migration] Error deleting history item directory ${itemDir} (may be benign if already deleted):`,\n+\t\t\t\terror,\n+\t\t\t)\n+\t\t}\n+\t}\n+\n+\titemObjectCache.delete(taskId)\n+\n+\t// Iterate all monthly indexes to ensure comprehensive cleanup of the taskId.\n+\t// We don't use getHistoryItem() here to get workspace/ts for a targeted update\n+\t// because historical index states is intentionally inconsistent (\"fuzzy\"), and we want to ensure\n+\t// the ID is removed wherever it might appear as the latest for any workspace in any month.\n+\t// Tasks may exist in multiple workspaces and this is a normal workflow when the user loads\n+\t// a task from one workspace and continues using it in another.\n+\tconst availableMonths = await getAvailableHistoryMonths()\n+\n+\tfor (const { year, month } of availableMonths) {\n+\t\tconst indexPath = _getMonthIndexFilePath(year, month)\n+\n+\t\ttry {\n+\t\t\t// Atomic read-modify-write operation for each month\n+\t\t\tawait safeWriteJson(indexPath, {}, async (monthData) => {\n+\t\t\t\tlet updatedInThisMonth = false\n+\n+\t\t\t\tfor (const workspacePath in monthData) {\n+\t\t\t\t\tif (Object.prototype.hasOwnProperty.call(monthData, workspacePath)) {\n+\t\t\t\t\t\tconst tasksInWorkspace = monthData[workspacePath]\n+\n+\t\t\t\t\t\t// Ensure tasksInWorkspace exists and then check for taskId\n+\t\t\t\t\t\tif (tasksInWorkspace && tasksInWorkspace[taskId] !== undefined) {\n+\t\t\t\t\t\t\tdelete tasksInWorkspace[taskId]\n+\n+\t\t\t\t\t\t\t// If the workspacePath entry becomes empty after deleting the task,\n+\t\t\t\t\t\t\t// remove the workspacePath key itself\n+\t\t\t\t\t\t\tif (Object.keys(tasksInWorkspace).length === 0) {\n+\t\t\t\t\t\t\t\tdelete monthData[workspacePath]\n+\t\t\t\t\t\t\t}\n+\n+\t\t\t\t\t\t\tupdatedInThisMonth = true\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\n+\t\t\t\t// Return true only if changes were made, false otherwise\n+\t\t\t\t// This prevents unnecessary file writes when nothing changed\n+\t\t\t\treturn updatedInThisMonth\n+\t\t\t})\n+\t\t} catch (error) {\n+\t\t\tconsole.error(\n+\t\t\t\t`[TaskHistory] Error updating month index for ${year}-${month} when deleting task ${taskId}:`,\n+\t\t\t\terror,\n+\t\t\t)\n+\t\t}\n+\t}\n+}\n+\n+/**\n+ * Generates a timestamp string in the format YYYY-MM-DD_HH-MM-SS\n+ * @returns Formatted timestamp string\n+ */\n+function _getTimestampString(): string {\n+\tconst now = new Date()\n+\treturn `${now.getFullYear()}-${(now.getMonth() + 1).toString().padStart(2, \"0\")}-${now.getDate().toString().padStart(2, \"0\")}_${now.getHours().toString().padStart(2, \"0\")}-${now.getMinutes().toString().padStart(2, \"0\")}-${now.getSeconds().toString().padStart(2, \"0\")}`\n+}\n+\n+/**\n+ * Helper function to log a message both to console and to an array\n+ * @param logs Array to accumulate logs\n+ * @param message The message to log\n+ * @returns The message (for convenience)\n+ */\n+/**\n+ * Logs a message to both console and an array of logs.\n+ * Tags in square brackets at the beginning of the message are shown\n+ * in the console but omitted from the logs array.\n+ */\n+function logMessage(logs: string[], message: string): string {\n+\t// Display full message including tags in console\n+\tconsole.log(message)\n+\n+\t// Extract tags and strip them from the message stored in logs array\n+\t// Using a more specific regex pattern to avoid potential ReDoS vulnerability\n+\t// Original: /^\\[(.*?)\\]\\s*(.*)$/\n+\tconst tagMatch = message.match(/^\\[([^\\]]*)\\]\\s*(.*)$/)",
        "comment_created_at": "2025-06-26T22:34:18+00:00",
        "comment_author": "KJ7LNW",
        "comment_body": "fixed as much as we can while still maintaining purpose ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2205982544",
    "pr_number": 5503,
    "pr_file": "src/core/tools/ToolRepetitionDetector.ts",
    "created_at": "2025-07-14T23:24:36+00:00",
    "commented_code": "return { allowExecution: true }\n \t}\n \n+\t/**\n+\t * Updates the tool call history with the latest call\n+\t * @param toolCallJson The serialized tool call to add to history\n+\t */\n+\tprivate updateHistory(toolCallJson: string): void {\n+\t\tthis.toolCallHistory.push(toolCallJson)\n+\n+\t\t// Keep history within maximum length\n+\t\tif (this.toolCallHistory.length > this.historyMaxLength) {\n+\t\t\tthis.toolCallHistory.shift() // Remove oldest entry\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Detects repeating patterns in the tool call history using KMP algorithm\n+\t * @returns true if a pattern repetition is detected beyond the allowed limit\n+\t */\n+\tprivate detectPatternRepetition(): boolean {\n+\t\tconst history = this.toolCallHistory\n+\t\tif (history.length < 4) {\n+\t\t\t// Need at least 4 elements for meaningful pattern\n+\t\t\treturn false\n+\t\t}\n+\n+\t\t// Create a simplified representation of the history\n+\t\t// Use the actual tool calls (not indices) to ensure accurate pattern detection\n+\t\tconst historyArray = [...history]\n+\t\t\n+\t\t// Check patterns of various lengths\n+\t\t// Start with longer patterns to avoid false positives with short patterns\n+\t\tconst maxPatternLength = Math.floor(history.length / 2)\n+\t\t\n+\t\tfor (let patternLength = 1; patternLength <= maxPatternLength; patternLength++) {",
    "repo_full_name": "RooCodeInc/Roo-Code",
    "discussion_comments": [
      {
        "comment_id": "2205982544",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5503,
        "pr_file": "src/core/tools/ToolRepetitionDetector.ts",
        "discussion_id": "2205982544",
        "commented_code": "@@ -63,6 +79,104 @@ export class ToolRepetitionDetector {\n \t\treturn { allowExecution: true }\n \t}\n \n+\t/**\n+\t * Updates the tool call history with the latest call\n+\t * @param toolCallJson The serialized tool call to add to history\n+\t */\n+\tprivate updateHistory(toolCallJson: string): void {\n+\t\tthis.toolCallHistory.push(toolCallJson)\n+\n+\t\t// Keep history within maximum length\n+\t\tif (this.toolCallHistory.length > this.historyMaxLength) {\n+\t\t\tthis.toolCallHistory.shift() // Remove oldest entry\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Detects repeating patterns in the tool call history using KMP algorithm\n+\t * @returns true if a pattern repetition is detected beyond the allowed limit\n+\t */\n+\tprivate detectPatternRepetition(): boolean {\n+\t\tconst history = this.toolCallHistory\n+\t\tif (history.length < 4) {\n+\t\t\t// Need at least 4 elements for meaningful pattern\n+\t\t\treturn false\n+\t\t}\n+\n+\t\t// Create a simplified representation of the history\n+\t\t// Use the actual tool calls (not indices) to ensure accurate pattern detection\n+\t\tconst historyArray = [...history]\n+\t\t\n+\t\t// Check patterns of various lengths\n+\t\t// Start with longer patterns to avoid false positives with short patterns\n+\t\tconst maxPatternLength = Math.floor(history.length / 2)\n+\t\t\n+\t\tfor (let patternLength = 1; patternLength <= maxPatternLength; patternLength++) {",
        "comment_created_at": "2025-07-14T23:24:36+00:00",
        "comment_author": "daniel-lxs",
        "comment_body": "**Important**: Starting pattern detection from length 1 could cause false positives. For example, \"AAAA\" would be detected as pattern \"A\" repeated 4 times, which overlaps with consecutive repetition detection.\n\nConsider starting from length 2 to avoid this overlap:\n```typescript\nfor (let patternLength = 2; patternLength <= maxPatternLength; patternLength++) {\n```\n\nThis ensures pattern detection only catches actual patterns like \"AB\", \"ABC\", etc., not single repeated elements.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2193035270",
    "pr_number": 5471,
    "pr_file": "src/core/task/TaskComplexityAnalyzer.ts",
    "created_at": "2025-07-08T17:08:04+00:00",
    "commented_code": "+import { TodoItem } from \"@roo-code/types\"\n+import { addTodoToTask } from \"../tools/updateTodoListTool\"\n+import { Task } from \"./Task\"\n+\n+/**\n+ * Configuration for automatic TODO list creation\n+ */\n+export interface AutoTodoConfig {\n+\tenabled: boolean\n+\tcomplexityThreshold: number\n+\tminTaskLength: number\n+\tmaxInitialTodos: number\n+}\n+\n+/**\n+ * Default configuration for automatic TODO list creation\n+ */\n+export const DEFAULT_AUTO_TODO_CONFIG: AutoTodoConfig = {\n+\tenabled: true,\n+\tcomplexityThreshold: 3, // Minimum complexity score to trigger auto TODO\n+\tminTaskLength: 50, // Minimum task description length\n+\tmaxInitialTodos: 8, // Maximum number of initial TODOs to create\n+}\n+\n+/**\n+ * Keywords that indicate task complexity and suggest multiple steps\n+ */\n+const COMPLEXITY_KEYWORDS = {\n+\t// High complexity indicators (weight: 3)\n+\thigh: [\n+\t\t\"create\",\n+\t\t\"build\",\n+\t\t\"implement\",\n+\t\t\"develop\",\n+\t\t\"design\",\n+\t\t\"architect\",\n+\t\t\"full-stack\",\n+\t\t\"end-to-end\",\n+\t\t\"complete\",\n+\t\t\"entire\",\n+\t\t\"comprehensive\",\n+\t\t\"system\",\n+\t\t\"application\",\n+\t\t\"project\",\n+\t\t\"framework\",\n+\t\t\"platform\",\n+\t\t\"integrate\",\n+\t\t\"configure\",\n+\t\t\"setup\",\n+\t\t\"install\",\n+\t\t\"deploy\",\n+\t],\n+\t// Medium complexity indicators (weight: 2)\n+\tmedium: [\n+\t\t\"add\",\n+\t\t\"update\",\n+\t\t\"modify\",\n+\t\t\"refactor\",\n+\t\t\"optimize\",\n+\t\t\"improve\",\n+\t\t\"enhance\",\n+\t\t\"extend\",\n+\t\t\"migrate\",\n+\t\t\"convert\",\n+\t\t\"transform\",\n+\t\t\"test\",\n+\t\t\"debug\",\n+\t\t\"fix\",\n+\t\t\"resolve\",\n+\t\t\"handle\",\n+\t\t\"manage\",\n+\t],\n+\t// Step indicators (weight: 2)\n+\tsteps: [\n+\t\t\"step\",\n+\t\t\"steps\",\n+\t\t\"phase\",\n+\t\t\"phases\",\n+\t\t\"stage\",\n+\t\t\"stages\",\n+\t\t\"first\",\n+\t\t\"then\",\n+\t\t\"next\",\n+\t\t\"after\",\n+\t\t\"before\",\n+\t\t\"finally\",\n+\t\t\"initially\",\n+\t\t\"subsequently\",\n+\t\t\"process\",\n+\t\t\"workflow\",\n+\t],\n+\t// Multiple item indicators (weight: 1)\n+\tmultiple: [\n+\t\t\"multiple\",\n+\t\t\"several\",\n+\t\t\"various\",\n+\t\t\"different\",\n+\t\t\"many\",\n+\t\t\"all\",\n+\t\t\"each\",\n+\t\t\"every\",\n+\t\t\"both\",\n+\t\t\"and\",\n+\t\t\"also\",\n+\t\t\"plus\",\n+\t],\n+}\n+\n+/**\n+ * Patterns that suggest multiple steps or complex workflows\n+ */\n+const COMPLEXITY_PATTERNS = [\n+\t// Lists or enumerations\n+\t/\\d+\\.\\s+/g, // \"1. \", \"2. \", etc.\n+\t/[-*]\\s+/g, // \"- \" or \"* \" bullet points\n+\t/\\b(first|second|third|fourth|fifth|then|next|after|finally)\\b/gi,\n+\t// Conditional or branching logic\n+\t/\\b(if|when|unless|depending|based on|according to)\\b/gi,\n+\t// Multiple technologies or components\n+\t/\\b(with|using|and|plus|\\+|&)\\s+\\w+/gi,\n+\t// Authentication, database, API patterns\n+\t/\\b(auth|database|api|frontend|backend|server|client)\\b/gi,\n+]\n+\n+/**\n+ * Analyzes task description to determine complexity and suggest initial TODOs\n+ */\n+export class TaskComplexityAnalyzer {\n+\tprivate config: AutoTodoConfig\n+\n+\tconstructor(config: Partial<AutoTodoConfig> = {}) {\n+\t\tthis.config = { ...DEFAULT_AUTO_TODO_CONFIG, ...config }\n+\t}\n+\n+\t/**\n+\t * Analyzes a task description and returns complexity score and suggested TODOs\n+\t */\n+\tanalyzeTask(taskDescription: string): {\n+\t\tcomplexityScore: number\n+\t\tshouldCreateTodos: boolean\n+\t\tsuggestedTodos: string[]\n+\t\treasoning: string[]\n+\t} {\n+\t\tif (!taskDescription || taskDescription.length < this.config.minTaskLength) {\n+\t\t\treturn {\n+\t\t\t\tcomplexityScore: 0,\n+\t\t\t\tshouldCreateTodos: false,\n+\t\t\t\tsuggestedTodos: [],\n+\t\t\t\treasoning: [\"Task description too short for complexity analysis\"],\n+\t\t\t}\n+\t\t}\n+\n+\t\tconst reasoning: string[] = []\n+\t\tlet complexityScore = 0\n+\n+\t\t// Analyze keyword complexity\n+\t\tconst keywordScore = this.analyzeKeywords(taskDescription, reasoning)\n+\t\tcomplexityScore += keywordScore\n+\n+\t\t// Analyze pattern complexity\n+\t\tconst patternScore = this.analyzePatterns(taskDescription, reasoning)\n+\t\tcomplexityScore += patternScore\n+\n+\t\t// Analyze length and structure\n+\t\tconst structureScore = this.analyzeStructure(taskDescription, reasoning)\n+\t\tcomplexityScore += structureScore\n+\n+\t\t// Generate suggested TODOs based on the task\n+\t\tconst suggestedTodos = this.generateSuggestedTodos(taskDescription, complexityScore)\n+\n+\t\tconst shouldCreateTodos =\n+\t\t\tthis.config.enabled && complexityScore >= this.config.complexityThreshold && suggestedTodos.length > 0\n+\n+\t\treasoning.push(`Total complexity score: ${complexityScore}`)\n+\t\treasoning.push(`Threshold: ${this.config.complexityThreshold}`)\n+\t\treasoning.push(`Should create TODOs: ${shouldCreateTodos}`)\n+\n+\t\treturn {\n+\t\t\tcomplexityScore,\n+\t\t\tshouldCreateTodos,\n+\t\t\tsuggestedTodos,\n+\t\t\treasoning,\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Analyzes keywords in the task description\n+\t */\n+\tprivate analyzeKeywords(task: string, reasoning: string[]): number {\n+\t\tconst lowerTask = task.toLowerCase()\n+\t\tlet score = 0\n+\n+\t\t// Check high complexity keywords\n+\t\tconst highMatches = COMPLEXITY_KEYWORDS.high.filter((keyword) => lowerTask.includes(keyword))\n+\t\tif (highMatches.length > 0) {\n+\t\t\tscore += highMatches.length * 3\n+\t\t\treasoning.push(`High complexity keywords found: ${highMatches.join(\", \")} (+${highMatches.length * 3})`)\n+\t\t}\n+\n+\t\t// Check medium complexity keywords\n+\t\tconst mediumMatches = COMPLEXITY_KEYWORDS.medium.filter((keyword) => lowerTask.includes(keyword))\n+\t\tif (mediumMatches.length > 0) {\n+\t\t\tscore += mediumMatches.length * 2\n+\t\t\treasoning.push(\n+\t\t\t\t`Medium complexity keywords found: ${mediumMatches.join(\", \")} (+${mediumMatches.length * 2})`,\n+\t\t\t)\n+\t\t}\n+\n+\t\t// Check step indicators\n+\t\tconst stepMatches = COMPLEXITY_KEYWORDS.steps.filter((keyword) => lowerTask.includes(keyword))\n+\t\tif (stepMatches.length > 0) {\n+\t\t\tscore += stepMatches.length * 2\n+\t\t\treasoning.push(`Step indicators found: ${stepMatches.join(\", \")} (+${stepMatches.length * 2})`)\n+\t\t}\n+\n+\t\t// Check multiple item indicators\n+\t\tconst multipleMatches = COMPLEXITY_KEYWORDS.multiple.filter((keyword) => lowerTask.includes(keyword))\n+\t\tif (multipleMatches.length > 0) {\n+\t\t\tscore += multipleMatches.length * 1\n+\t\t\treasoning.push(`Multiple item indicators found: ${multipleMatches.join(\", \")} (+${multipleMatches.length})`)\n+\t\t}\n+\n+\t\treturn score\n+\t}\n+\n+\t/**\n+\t * Analyzes patterns that suggest complexity\n+\t */\n+\tprivate analyzePatterns(task: string, reasoning: string[]): number {\n+\t\tlet score = 0\n+\n+\t\tfor (const pattern of COMPLEXITY_PATTERNS) {\n+\t\t\tconst matches = task.match(pattern)\n+\t\t\tif (matches && matches.length > 0) {\n+\t\t\t\tscore += matches.length\n+\t\t\t\treasoning.push(`Pattern matches for ${pattern.source}: ${matches.length} (+${matches.length})`)\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn Math.min(score, 10) // Cap pattern score at 10\n+\t}\n+\n+\t/**\n+\t * Analyzes task structure and length\n+\t */\n+\tprivate analyzeStructure(task: string, reasoning: string[]): number {\n+\t\tlet score = 0\n+\n+\t\t// Length-based scoring\n+\t\tif (task.length > 200) {\n+\t\t\tscore += 2\n+\t\t\treasoning.push(\"Long task description (+2)\")\n+\t\t} else if (task.length > 100) {\n+\t\t\tscore += 1\n+\t\t\treasoning.push(\"Medium task description (+1)\")\n+\t\t}\n+\n+\t\t// Sentence count\n+\t\tconst sentences = task.split(/[.!?]+/).filter((s) => s.trim().length > 0)\n+\t\tif (sentences.length > 3) {\n+\t\t\tscore += 2\n+\t\t\treasoning.push(`Multiple sentences: ${sentences.length} (+2)`)\n+\t\t}\n+\n+\t\t// Line breaks suggest structured content\n+\t\tconst lines = task.split(/\n/).filter((l) => l.trim().length > 0)\n+\t\tif (lines.length > 2) {\n+\t\t\tscore += 1\n+\t\t\treasoning.push(`Multiple lines: ${lines.length} (+1)`)\n+\t\t}\n+\n+\t\treturn score\n+\t}\n+\n+\t/**\n+\t * Generates suggested TODO items based on task analysis\n+\t */\n+\tprivate generateSuggestedTodos(task: string, complexityScore: number): string[] {\n+\t\tconst todos: string[] = []\n+\t\tconst lowerTask = task.toLowerCase()\n+\n+\t\t// Common patterns for different types of tasks\n+\t\tif (this.containsAny(lowerTask, [\"create\", \"build\", \"develop\", \"implement\"])) {\n+\t\t\tif (this.containsAny(lowerTask, [\"app\", \"application\", \"website\", \"system\"])) {\n+\t\t\t\ttodos.push(\"Analyze requirements and define scope\")\n+\t\t\t\ttodos.push(\"Design system architecture\")\n+\t\t\t\ttodos.push(\"Set up project structure\")\n+\t\t\t\ttodos.push(\"Implement core functionality\")\n+\t\t\t\ttodos.push(\"Add error handling and validation\")\n+\t\t\t\ttodos.push(\"Write tests\")\n+\t\t\t\ttodos.push(\"Update documentation\")\n+\t\t\t} else if (this.containsAny(lowerTask, [\"api\", \"endpoint\", \"service\"])) {\n+\t\t\t\ttodos.push(\"Define API specification\")\n+\t\t\t\ttodos.push(\"Set up routing and middleware\")\n+\t\t\t\ttodos.push(\"Implement endpoint logic\")\n+\t\t\t\ttodos.push(\"Add authentication and authorization\")\n+\t\t\t\ttodos.push(\"Write API tests\")\n+\t\t\t\ttodos.push(\"Update API documentation\")\n+\t\t\t} else if (this.containsAny(lowerTask, [\"component\", \"ui\", \"interface\"])) {\n+\t\t\t\ttodos.push(\"Design component interface\")\n+\t\t\t\ttodos.push(\"Implement component logic\")\n+\t\t\t\ttodos.push(\"Add styling and responsive design\")\n+\t\t\t\ttodos.push(\"Handle user interactions\")\n+\t\t\t\ttodos.push(\"Write component tests\")\n+\t\t\t\ttodos.push(\"Update component documentation\")\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (this.containsAny(lowerTask, [\"fix\", \"debug\", \"resolve\", \"issue\"])) {\n+\t\t\ttodos.push(\"Reproduce the issue\")\n+\t\t\ttodos.push(\"Identify root cause\")\n+\t\t\ttodos.push(\"Implement fix\")\n+\t\t\ttodos.push(\"Test the solution\")\n+\t\t\ttodos.push(\"Verify no regression\")\n+\t\t}\n+\n+\t\tif (this.containsAny(lowerTask, [\"refactor\", \"optimize\", \"improve\"])) {\n+\t\t\ttodos.push(\"Analyze current implementation\")\n+\t\t\ttodos.push(\"Identify improvement opportunities\")\n+\t\t\ttodos.push(\"Plan refactoring approach\")\n+\t\t\ttodos.push(\"Implement improvements\")\n+\t\t\ttodos.push(\"Test refactored code\")\n+\t\t\ttodos.push(\"Update related documentation\")\n+\t\t}\n+\n+\t\tif (this.containsAny(lowerTask, [\"setup\", \"configure\", \"install\"])) {\n+\t\t\ttodos.push(\"Review setup requirements\")\n+\t\t\ttodos.push(\"Install dependencies\")\n+\t\t\ttodos.push(\"Configure environment\")\n+\t\t\ttodos.push(\"Test configuration\")\n+\t\t\ttodos.push(\"Document setup process\")\n+\t\t}\n+\n+\t\t// If no specific patterns matched, create generic todos based on complexity\n+\t\tif (todos.length === 0 && complexityScore >= this.config.complexityThreshold) {\n+\t\t\ttodos.push(\"Break down the task into smaller steps\")\n+\t\t\ttodos.push(\"Analyze requirements and constraints\")\n+\t\t\ttodos.push(\"Plan implementation approach\")\n+\t\t\ttodos.push(\"Execute the main task\")\n+\t\t\ttodos.push(\"Test and verify results\")\n+\t\t}\n+\n+\t\t// Limit the number of initial todos\n+\t\treturn todos.slice(0, this.config.maxInitialTodos)\n+\t}\n+\n+\t/**\n+\t * Helper method to check if text contains any of the given keywords\n+\t */\n+\tprivate containsAny(text: string, keywords: string[]): boolean {\n+\t\treturn keywords.some((keyword) => text.includes(keyword))",
    "repo_full_name": "RooCodeInc/Roo-Code",
    "discussion_comments": [
      {
        "comment_id": "2193035270",
        "repo_full_name": "RooCodeInc/Roo-Code",
        "pr_number": 5471,
        "pr_file": "src/core/task/TaskComplexityAnalyzer.ts",
        "discussion_id": "2193035270",
        "commented_code": "@@ -0,0 +1,391 @@\n+import { TodoItem } from \"@roo-code/types\"\n+import { addTodoToTask } from \"../tools/updateTodoListTool\"\n+import { Task } from \"./Task\"\n+\n+/**\n+ * Configuration for automatic TODO list creation\n+ */\n+export interface AutoTodoConfig {\n+\tenabled: boolean\n+\tcomplexityThreshold: number\n+\tminTaskLength: number\n+\tmaxInitialTodos: number\n+}\n+\n+/**\n+ * Default configuration for automatic TODO list creation\n+ */\n+export const DEFAULT_AUTO_TODO_CONFIG: AutoTodoConfig = {\n+\tenabled: true,\n+\tcomplexityThreshold: 3, // Minimum complexity score to trigger auto TODO\n+\tminTaskLength: 50, // Minimum task description length\n+\tmaxInitialTodos: 8, // Maximum number of initial TODOs to create\n+}\n+\n+/**\n+ * Keywords that indicate task complexity and suggest multiple steps\n+ */\n+const COMPLEXITY_KEYWORDS = {\n+\t// High complexity indicators (weight: 3)\n+\thigh: [\n+\t\t\"create\",\n+\t\t\"build\",\n+\t\t\"implement\",\n+\t\t\"develop\",\n+\t\t\"design\",\n+\t\t\"architect\",\n+\t\t\"full-stack\",\n+\t\t\"end-to-end\",\n+\t\t\"complete\",\n+\t\t\"entire\",\n+\t\t\"comprehensive\",\n+\t\t\"system\",\n+\t\t\"application\",\n+\t\t\"project\",\n+\t\t\"framework\",\n+\t\t\"platform\",\n+\t\t\"integrate\",\n+\t\t\"configure\",\n+\t\t\"setup\",\n+\t\t\"install\",\n+\t\t\"deploy\",\n+\t],\n+\t// Medium complexity indicators (weight: 2)\n+\tmedium: [\n+\t\t\"add\",\n+\t\t\"update\",\n+\t\t\"modify\",\n+\t\t\"refactor\",\n+\t\t\"optimize\",\n+\t\t\"improve\",\n+\t\t\"enhance\",\n+\t\t\"extend\",\n+\t\t\"migrate\",\n+\t\t\"convert\",\n+\t\t\"transform\",\n+\t\t\"test\",\n+\t\t\"debug\",\n+\t\t\"fix\",\n+\t\t\"resolve\",\n+\t\t\"handle\",\n+\t\t\"manage\",\n+\t],\n+\t// Step indicators (weight: 2)\n+\tsteps: [\n+\t\t\"step\",\n+\t\t\"steps\",\n+\t\t\"phase\",\n+\t\t\"phases\",\n+\t\t\"stage\",\n+\t\t\"stages\",\n+\t\t\"first\",\n+\t\t\"then\",\n+\t\t\"next\",\n+\t\t\"after\",\n+\t\t\"before\",\n+\t\t\"finally\",\n+\t\t\"initially\",\n+\t\t\"subsequently\",\n+\t\t\"process\",\n+\t\t\"workflow\",\n+\t],\n+\t// Multiple item indicators (weight: 1)\n+\tmultiple: [\n+\t\t\"multiple\",\n+\t\t\"several\",\n+\t\t\"various\",\n+\t\t\"different\",\n+\t\t\"many\",\n+\t\t\"all\",\n+\t\t\"each\",\n+\t\t\"every\",\n+\t\t\"both\",\n+\t\t\"and\",\n+\t\t\"also\",\n+\t\t\"plus\",\n+\t],\n+}\n+\n+/**\n+ * Patterns that suggest multiple steps or complex workflows\n+ */\n+const COMPLEXITY_PATTERNS = [\n+\t// Lists or enumerations\n+\t/\\d+\\.\\s+/g, // \"1. \", \"2. \", etc.\n+\t/[-*]\\s+/g, // \"- \" or \"* \" bullet points\n+\t/\\b(first|second|third|fourth|fifth|then|next|after|finally)\\b/gi,\n+\t// Conditional or branching logic\n+\t/\\b(if|when|unless|depending|based on|according to)\\b/gi,\n+\t// Multiple technologies or components\n+\t/\\b(with|using|and|plus|\\+|&)\\s+\\w+/gi,\n+\t// Authentication, database, API patterns\n+\t/\\b(auth|database|api|frontend|backend|server|client)\\b/gi,\n+]\n+\n+/**\n+ * Analyzes task description to determine complexity and suggest initial TODOs\n+ */\n+export class TaskComplexityAnalyzer {\n+\tprivate config: AutoTodoConfig\n+\n+\tconstructor(config: Partial<AutoTodoConfig> = {}) {\n+\t\tthis.config = { ...DEFAULT_AUTO_TODO_CONFIG, ...config }\n+\t}\n+\n+\t/**\n+\t * Analyzes a task description and returns complexity score and suggested TODOs\n+\t */\n+\tanalyzeTask(taskDescription: string): {\n+\t\tcomplexityScore: number\n+\t\tshouldCreateTodos: boolean\n+\t\tsuggestedTodos: string[]\n+\t\treasoning: string[]\n+\t} {\n+\t\tif (!taskDescription || taskDescription.length < this.config.minTaskLength) {\n+\t\t\treturn {\n+\t\t\t\tcomplexityScore: 0,\n+\t\t\t\tshouldCreateTodos: false,\n+\t\t\t\tsuggestedTodos: [],\n+\t\t\t\treasoning: [\"Task description too short for complexity analysis\"],\n+\t\t\t}\n+\t\t}\n+\n+\t\tconst reasoning: string[] = []\n+\t\tlet complexityScore = 0\n+\n+\t\t// Analyze keyword complexity\n+\t\tconst keywordScore = this.analyzeKeywords(taskDescription, reasoning)\n+\t\tcomplexityScore += keywordScore\n+\n+\t\t// Analyze pattern complexity\n+\t\tconst patternScore = this.analyzePatterns(taskDescription, reasoning)\n+\t\tcomplexityScore += patternScore\n+\n+\t\t// Analyze length and structure\n+\t\tconst structureScore = this.analyzeStructure(taskDescription, reasoning)\n+\t\tcomplexityScore += structureScore\n+\n+\t\t// Generate suggested TODOs based on the task\n+\t\tconst suggestedTodos = this.generateSuggestedTodos(taskDescription, complexityScore)\n+\n+\t\tconst shouldCreateTodos =\n+\t\t\tthis.config.enabled && complexityScore >= this.config.complexityThreshold && suggestedTodos.length > 0\n+\n+\t\treasoning.push(`Total complexity score: ${complexityScore}`)\n+\t\treasoning.push(`Threshold: ${this.config.complexityThreshold}`)\n+\t\treasoning.push(`Should create TODOs: ${shouldCreateTodos}`)\n+\n+\t\treturn {\n+\t\t\tcomplexityScore,\n+\t\t\tshouldCreateTodos,\n+\t\t\tsuggestedTodos,\n+\t\t\treasoning,\n+\t\t}\n+\t}\n+\n+\t/**\n+\t * Analyzes keywords in the task description\n+\t */\n+\tprivate analyzeKeywords(task: string, reasoning: string[]): number {\n+\t\tconst lowerTask = task.toLowerCase()\n+\t\tlet score = 0\n+\n+\t\t// Check high complexity keywords\n+\t\tconst highMatches = COMPLEXITY_KEYWORDS.high.filter((keyword) => lowerTask.includes(keyword))\n+\t\tif (highMatches.length > 0) {\n+\t\t\tscore += highMatches.length * 3\n+\t\t\treasoning.push(`High complexity keywords found: ${highMatches.join(\", \")} (+${highMatches.length * 3})`)\n+\t\t}\n+\n+\t\t// Check medium complexity keywords\n+\t\tconst mediumMatches = COMPLEXITY_KEYWORDS.medium.filter((keyword) => lowerTask.includes(keyword))\n+\t\tif (mediumMatches.length > 0) {\n+\t\t\tscore += mediumMatches.length * 2\n+\t\t\treasoning.push(\n+\t\t\t\t`Medium complexity keywords found: ${mediumMatches.join(\", \")} (+${mediumMatches.length * 2})`,\n+\t\t\t)\n+\t\t}\n+\n+\t\t// Check step indicators\n+\t\tconst stepMatches = COMPLEXITY_KEYWORDS.steps.filter((keyword) => lowerTask.includes(keyword))\n+\t\tif (stepMatches.length > 0) {\n+\t\t\tscore += stepMatches.length * 2\n+\t\t\treasoning.push(`Step indicators found: ${stepMatches.join(\", \")} (+${stepMatches.length * 2})`)\n+\t\t}\n+\n+\t\t// Check multiple item indicators\n+\t\tconst multipleMatches = COMPLEXITY_KEYWORDS.multiple.filter((keyword) => lowerTask.includes(keyword))\n+\t\tif (multipleMatches.length > 0) {\n+\t\t\tscore += multipleMatches.length * 1\n+\t\t\treasoning.push(`Multiple item indicators found: ${multipleMatches.join(\", \")} (+${multipleMatches.length})`)\n+\t\t}\n+\n+\t\treturn score\n+\t}\n+\n+\t/**\n+\t * Analyzes patterns that suggest complexity\n+\t */\n+\tprivate analyzePatterns(task: string, reasoning: string[]): number {\n+\t\tlet score = 0\n+\n+\t\tfor (const pattern of COMPLEXITY_PATTERNS) {\n+\t\t\tconst matches = task.match(pattern)\n+\t\t\tif (matches && matches.length > 0) {\n+\t\t\t\tscore += matches.length\n+\t\t\t\treasoning.push(`Pattern matches for ${pattern.source}: ${matches.length} (+${matches.length})`)\n+\t\t\t}\n+\t\t}\n+\n+\t\treturn Math.min(score, 10) // Cap pattern score at 10\n+\t}\n+\n+\t/**\n+\t * Analyzes task structure and length\n+\t */\n+\tprivate analyzeStructure(task: string, reasoning: string[]): number {\n+\t\tlet score = 0\n+\n+\t\t// Length-based scoring\n+\t\tif (task.length > 200) {\n+\t\t\tscore += 2\n+\t\t\treasoning.push(\"Long task description (+2)\")\n+\t\t} else if (task.length > 100) {\n+\t\t\tscore += 1\n+\t\t\treasoning.push(\"Medium task description (+1)\")\n+\t\t}\n+\n+\t\t// Sentence count\n+\t\tconst sentences = task.split(/[.!?]+/).filter((s) => s.trim().length > 0)\n+\t\tif (sentences.length > 3) {\n+\t\t\tscore += 2\n+\t\t\treasoning.push(`Multiple sentences: ${sentences.length} (+2)`)\n+\t\t}\n+\n+\t\t// Line breaks suggest structured content\n+\t\tconst lines = task.split(/\\n/).filter((l) => l.trim().length > 0)\n+\t\tif (lines.length > 2) {\n+\t\t\tscore += 1\n+\t\t\treasoning.push(`Multiple lines: ${lines.length} (+1)`)\n+\t\t}\n+\n+\t\treturn score\n+\t}\n+\n+\t/**\n+\t * Generates suggested TODO items based on task analysis\n+\t */\n+\tprivate generateSuggestedTodos(task: string, complexityScore: number): string[] {\n+\t\tconst todos: string[] = []\n+\t\tconst lowerTask = task.toLowerCase()\n+\n+\t\t// Common patterns for different types of tasks\n+\t\tif (this.containsAny(lowerTask, [\"create\", \"build\", \"develop\", \"implement\"])) {\n+\t\t\tif (this.containsAny(lowerTask, [\"app\", \"application\", \"website\", \"system\"])) {\n+\t\t\t\ttodos.push(\"Analyze requirements and define scope\")\n+\t\t\t\ttodos.push(\"Design system architecture\")\n+\t\t\t\ttodos.push(\"Set up project structure\")\n+\t\t\t\ttodos.push(\"Implement core functionality\")\n+\t\t\t\ttodos.push(\"Add error handling and validation\")\n+\t\t\t\ttodos.push(\"Write tests\")\n+\t\t\t\ttodos.push(\"Update documentation\")\n+\t\t\t} else if (this.containsAny(lowerTask, [\"api\", \"endpoint\", \"service\"])) {\n+\t\t\t\ttodos.push(\"Define API specification\")\n+\t\t\t\ttodos.push(\"Set up routing and middleware\")\n+\t\t\t\ttodos.push(\"Implement endpoint logic\")\n+\t\t\t\ttodos.push(\"Add authentication and authorization\")\n+\t\t\t\ttodos.push(\"Write API tests\")\n+\t\t\t\ttodos.push(\"Update API documentation\")\n+\t\t\t} else if (this.containsAny(lowerTask, [\"component\", \"ui\", \"interface\"])) {\n+\t\t\t\ttodos.push(\"Design component interface\")\n+\t\t\t\ttodos.push(\"Implement component logic\")\n+\t\t\t\ttodos.push(\"Add styling and responsive design\")\n+\t\t\t\ttodos.push(\"Handle user interactions\")\n+\t\t\t\ttodos.push(\"Write component tests\")\n+\t\t\t\ttodos.push(\"Update component documentation\")\n+\t\t\t}\n+\t\t}\n+\n+\t\tif (this.containsAny(lowerTask, [\"fix\", \"debug\", \"resolve\", \"issue\"])) {\n+\t\t\ttodos.push(\"Reproduce the issue\")\n+\t\t\ttodos.push(\"Identify root cause\")\n+\t\t\ttodos.push(\"Implement fix\")\n+\t\t\ttodos.push(\"Test the solution\")\n+\t\t\ttodos.push(\"Verify no regression\")\n+\t\t}\n+\n+\t\tif (this.containsAny(lowerTask, [\"refactor\", \"optimize\", \"improve\"])) {\n+\t\t\ttodos.push(\"Analyze current implementation\")\n+\t\t\ttodos.push(\"Identify improvement opportunities\")\n+\t\t\ttodos.push(\"Plan refactoring approach\")\n+\t\t\ttodos.push(\"Implement improvements\")\n+\t\t\ttodos.push(\"Test refactored code\")\n+\t\t\ttodos.push(\"Update related documentation\")\n+\t\t}\n+\n+\t\tif (this.containsAny(lowerTask, [\"setup\", \"configure\", \"install\"])) {\n+\t\t\ttodos.push(\"Review setup requirements\")\n+\t\t\ttodos.push(\"Install dependencies\")\n+\t\t\ttodos.push(\"Configure environment\")\n+\t\t\ttodos.push(\"Test configuration\")\n+\t\t\ttodos.push(\"Document setup process\")\n+\t\t}\n+\n+\t\t// If no specific patterns matched, create generic todos based on complexity\n+\t\tif (todos.length === 0 && complexityScore >= this.config.complexityThreshold) {\n+\t\t\ttodos.push(\"Break down the task into smaller steps\")\n+\t\t\ttodos.push(\"Analyze requirements and constraints\")\n+\t\t\ttodos.push(\"Plan implementation approach\")\n+\t\t\ttodos.push(\"Execute the main task\")\n+\t\t\ttodos.push(\"Test and verify results\")\n+\t\t}\n+\n+\t\t// Limit the number of initial todos\n+\t\treturn todos.slice(0, this.config.maxInitialTodos)\n+\t}\n+\n+\t/**\n+\t * Helper method to check if text contains any of the given keywords\n+\t */\n+\tprivate containsAny(text: string, keywords: string[]): boolean {\n+\t\treturn keywords.some((keyword) => text.includes(keyword))",
        "comment_created_at": "2025-07-08T17:08:04+00:00",
        "comment_author": "ellipsis-dev[bot]",
        "comment_body": "The helper 'containsAny' uses simple substring matching which can yield false positives. Consider using word-boundary checks if more precise keyword matching is needed.\n```suggestion\n\t\treturn keywords.some((keyword) => new RegExp(`\\\\b${keyword}\\\\b`).test(text))\n```\n",
        "pr_file_module": null
      }
    ]
  }
]