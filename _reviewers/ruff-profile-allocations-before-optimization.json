[
  {
    "discussion_id": "2181931301",
    "pr_number": 19108,
    "pr_file": "crates/ty_ide/src/semantic_tokens.rs",
    "created_at": "2025-07-03T06:05:52+00:00",
    "commented_code": "+use crate::Db;\n+use ruff_db::files::File;\n+use ruff_db::parsed::parsed_module;\n+use ruff_python_ast as ast;\n+use ruff_python_ast::visitor::source_order::{SourceOrderVisitor, walk_expr, walk_stmt};\n+use ruff_python_ast::{Expr, Stmt, TypeParam, TypeParams};\n+use ruff_text_size::{Ranged, TextRange};\n+use ty_python_semantic::{HasType, SemanticModel, types::Type};\n+\n+// This module walks the AST and collects a set of \"semantic tokens\" for a file\n+// or a range within a file. Each semantic token provides a \"token type\" and zero\n+// or more \"modifiers\". This information can be used by an editor to provide\n+// color coding based on semantic meaning.\n+\n+// Current limitations and areas for future improvement:\n+\n+// TODO: Need to handle semantic tokens within quoted annotations.\n+\n+// TODO: Need to properly handle Annotated expressions. All type arguments other\n+// than the first should be treated as value expressions, not as type expressions.\n+\n+// TODO: An identifier that resolves to a parameter when used within a function\n+// should be classified as a parameter, selfParameter, or clsParameter token.\n+\n+// TODO: Properties (or perhaps more generally, descriptor objects?) should be\n+// classified as property tokens rather than just variables.\n+\n+// TODO: Special forms like Protocol and TypedDict should probably be classified\n+// as class tokens, but they are currently classified as variables.\n+\n+// TODO: Type aliases (including those defined with the Python 3.12 \"type\" statement)\n+// do not currently have a dedicated semantic token type, but they maybe should.\n+\n+// TODO: Additional token modifiers might be added (e.g. for static methods,\n+// abstract methods and classes).\n+\n+/// Semantic token types supported by the language server.\n+#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\n+#[repr(u32)]\n+pub enum SemanticTokenType {\n+    Namespace = 0,\n+    Class = 1,\n+    Parameter = 2,\n+    SelfParameter = 3,\n+    ClsParameter = 4,\n+    Variable = 5,\n+    Property = 6,\n+    Function = 7,\n+    Method = 8,\n+    Keyword = 9,\n+    String = 10,\n+    Number = 11,\n+    Decorator = 12,\n+    BuiltinConstant = 13,\n+    TypeParameter = 14,\n+}\n+\n+impl SemanticTokenType {\n+    /// Returns all supported token types for LSP capabilities.\n+    pub fn all() -> Vec<&'static str> {\n+        vec![",
    "repo_full_name": "astral-sh/ruff",
    "discussion_comments": [
      {
        "comment_id": "2181931301",
        "repo_full_name": "astral-sh/ruff",
        "pr_number": 19108,
        "pr_file": "crates/ty_ide/src/semantic_tokens.rs",
        "discussion_id": "2181931301",
        "commented_code": "@@ -0,0 +1,2531 @@\n+use crate::Db;\n+use ruff_db::files::File;\n+use ruff_db::parsed::parsed_module;\n+use ruff_python_ast as ast;\n+use ruff_python_ast::visitor::source_order::{SourceOrderVisitor, walk_expr, walk_stmt};\n+use ruff_python_ast::{Expr, Stmt, TypeParam, TypeParams};\n+use ruff_text_size::{Ranged, TextRange};\n+use ty_python_semantic::{HasType, SemanticModel, types::Type};\n+\n+// This module walks the AST and collects a set of \"semantic tokens\" for a file\n+// or a range within a file. Each semantic token provides a \"token type\" and zero\n+// or more \"modifiers\". This information can be used by an editor to provide\n+// color coding based on semantic meaning.\n+\n+// Current limitations and areas for future improvement:\n+\n+// TODO: Need to handle semantic tokens within quoted annotations.\n+\n+// TODO: Need to properly handle Annotated expressions. All type arguments other\n+// than the first should be treated as value expressions, not as type expressions.\n+\n+// TODO: An identifier that resolves to a parameter when used within a function\n+// should be classified as a parameter, selfParameter, or clsParameter token.\n+\n+// TODO: Properties (or perhaps more generally, descriptor objects?) should be\n+// classified as property tokens rather than just variables.\n+\n+// TODO: Special forms like Protocol and TypedDict should probably be classified\n+// as class tokens, but they are currently classified as variables.\n+\n+// TODO: Type aliases (including those defined with the Python 3.12 \"type\" statement)\n+// do not currently have a dedicated semantic token type, but they maybe should.\n+\n+// TODO: Additional token modifiers might be added (e.g. for static methods,\n+// abstract methods and classes).\n+\n+/// Semantic token types supported by the language server.\n+#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]\n+#[repr(u32)]\n+pub enum SemanticTokenType {\n+    Namespace = 0,\n+    Class = 1,\n+    Parameter = 2,\n+    SelfParameter = 3,\n+    ClsParameter = 4,\n+    Variable = 5,\n+    Property = 6,\n+    Function = 7,\n+    Method = 8,\n+    Keyword = 9,\n+    String = 10,\n+    Number = 11,\n+    Decorator = 12,\n+    BuiltinConstant = 13,\n+    TypeParameter = 14,\n+}\n+\n+impl SemanticTokenType {\n+    /// Returns all supported token types for LSP capabilities.\n+    pub fn all() -> Vec<&'static str> {\n+        vec![",
        "comment_created_at": "2025-07-03T06:05:52+00:00",
        "comment_author": "dhruvmanila",
        "comment_body": "We can use a `[&'static str; 15]` as the return type to avoid allocating here. The caller can then do the allocation if it's required. This will also allow us to make this function a `const`.\n\n```suggestion\n    pub const fn all() -> [&'static str; 15] {\n        [\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2168338888",
    "pr_number": 18946,
    "pr_file": "crates/ruff/src/diagnostics.rs",
    "created_at": "2025-06-26T07:10:38+00:00",
    "commented_code": "let fixed_in_file = self.0.entry(filename).or_default();\n             for (rule, name, count) in fixed.iter() {\n                 if count > 0 {\n-                    *fixed_in_file.entry(rule).or_default(name) += count;\n+                    *fixed_in_file.entry(rule.to_string()).or_default(name) += count;",
    "repo_full_name": "astral-sh/ruff",
    "discussion_comments": [
      {
        "comment_id": "2168338888",
        "repo_full_name": "astral-sh/ruff",
        "pr_number": 18946,
        "pr_file": "crates/ruff/src/diagnostics.rs",
        "discussion_id": "2168338888",
        "commented_code": "@@ -167,7 +167,7 @@ impl AddAssign for FixMap {\n             let fixed_in_file = self.0.entry(filename).or_default();\n             for (rule, name, count) in fixed.iter() {\n                 if count > 0 {\n-                    *fixed_in_file.entry(rule).or_default(name) += count;\n+                    *fixed_in_file.entry(rule.to_string()).or_default(name) += count;",
        "comment_created_at": "2025-06-26T07:10:38+00:00",
        "comment_author": "MichaReiser",
        "comment_body": "We could use hashbrown with `entry_ref` here to avoid allocating a new string only to increment the counter\r\n\r\n<details><summary>Patch<summary>\r\n<p>\r\n\r\n```patch\r\nIndex: Cargo.lock\r\nIDEA additional info:\r\nSubsystem: com.intellij.openapi.diff.impl.patch.CharsetEP\r\n<+>UTF-8\r\n===================================================================\r\ndiff --git a/Cargo.lock b/Cargo.lock\r\n--- a/Cargo.lock\t(revision 44c13a29c5f24064c446277cfdfd9fdba6c163f6)\r\n+++ b/Cargo.lock\t(date 1750921570209)\r\n@@ -2812,6 +2812,7 @@\r\n  \"fern\",\r\n  \"glob\",\r\n  \"globset\",\r\n+ \"hashbrown 0.15.4\",\r\n  \"imperative\",\r\n  \"insta\",\r\n  \"is-macro\",\r\nIndex: crates/ruff_linter/src/linter.rs\r\nIDEA additional info:\r\nSubsystem: com.intellij.openapi.diff.impl.patch.CharsetEP\r\n<+>UTF-8\r\n===================================================================\r\ndiff --git a/crates/ruff_linter/src/linter.rs b/crates/ruff_linter/src/linter.rs\r\n--- a/crates/ruff_linter/src/linter.rs\t(revision 44c13a29c5f24064c446277cfdfd9fdba6c163f6)\r\n+++ b/crates/ruff_linter/src/linter.rs\t(date 1750921780496)\r\n@@ -1,12 +1,11 @@\r\n use std::borrow::Cow;\r\n-use std::collections::hash_map::Entry;\r\n use std::path::Path;\r\n \r\n use anyhow::{Result, anyhow};\r\n use colored::Colorize;\r\n use itertools::Itertools;\r\n use ruff_python_parser::semantic_errors::SemanticSyntaxError;\r\n-use rustc_hash::FxHashMap;\r\n+use rustc_hash::FxBuildHasher;\r\n \r\n use ruff_notebook::Notebook;\r\n use ruff_python_ast::{ModModule, PySourceType, PythonVersion};\r\n@@ -94,15 +93,15 @@\r\n \r\n /// A mapping from a noqa code to the corresponding lint name and a count of applied fixes.\r\n #[derive(Debug, Default, PartialEq)]\r\n-pub struct FixTable(FxHashMap<String, FixCount>);\r\n+pub struct FixTable(hashbrown::HashMap<String, FixCount, rustc_hash::FxBuildHasher>);\r\n \r\n impl FixTable {\r\n     pub fn counts(&self) -> impl Iterator<Item = usize> {\r\n         self.0.values().map(|fc| fc.count)\r\n     }\r\n \r\n-    pub fn entry(&mut self, code: String) -> FixTableEntry {\r\n-        FixTableEntry(self.0.entry(code))\r\n+    pub fn entry<'a>(&'a mut self, code: &'a str) -> FixTableEntry<'a> {\r\n+        FixTableEntry(self.0.entry_ref(code))\r\n     }\r\n \r\n     pub fn iter(&self) -> impl Iterator<Item = (&str, &'static str, usize)> {\r\n@@ -120,7 +119,9 @@\r\n     }\r\n }\r\n \r\n-pub struct FixTableEntry<'a>(Entry<'a, String, FixCount>);\r\n+pub struct FixTableEntry<'a>(\r\n+    hashbrown::hash_map::EntryRef<'a, 'a, String, str, FixCount, FxBuildHasher>,\r\n+);\r\n \r\n impl<'a> FixTableEntry<'a> {\r\n     pub fn or_default(self, rule_name: &'static str) -> &'a mut usize {\r\n@@ -650,7 +651,7 @@\r\n             if iterations < MAX_ITERATIONS {\r\n                 // Count the number of fixed errors.\r\n                 for (rule, name, count) in applied.iter() {\r\n-                    *fixed.entry(rule.to_string()).or_default(name) += count;\r\n+                    *fixed.entry(rule).or_default(name) += count;\r\n                 }\r\n \r\n                 transformed = Cow::Owned(transformed.updated(fixed_contents, &source_map));\r\nIndex: crates/ruff/src/diagnostics.rs\r\nIDEA additional info:\r\nSubsystem: com.intellij.openapi.diff.impl.patch.CharsetEP\r\n<+>UTF-8\r\n===================================================================\r\ndiff --git a/crates/ruff/src/diagnostics.rs b/crates/ruff/src/diagnostics.rs\r\n--- a/crates/ruff/src/diagnostics.rs\t(revision 44c13a29c5f24064c446277cfdfd9fdba6c163f6)\r\n+++ b/crates/ruff/src/diagnostics.rs\t(date 1750921482563)\r\n@@ -167,7 +167,7 @@\r\n             let fixed_in_file = self.0.entry(filename).or_default();\r\n             for (rule, name, count) in fixed.iter() {\r\n                 if count > 0 {\r\n-                    *fixed_in_file.entry(rule.to_string()).or_default(name) += count;\r\n+                    *fixed_in_file.entry(rule).or_default(name) += count;\r\n                 }\r\n             }\r\n         }\r\nIndex: crates/ruff_linter/Cargo.toml\r\nIDEA additional info:\r\nSubsystem: com.intellij.openapi.diff.impl.patch.CharsetEP\r\n<+>UTF-8\r\n===================================================================\r\ndiff --git a/crates/ruff_linter/Cargo.toml b/crates/ruff_linter/Cargo.toml\r\n--- a/crates/ruff_linter/Cargo.toml\t(revision 44c13a29c5f24064c446277cfdfd9fdba6c163f6)\r\n+++ b/crates/ruff_linter/Cargo.toml\t(date 1750921569921)\r\n@@ -38,6 +38,7 @@\r\n fern = { workspace = true }\r\n glob = { workspace = true }\r\n globset = { workspace = true }\r\n+hashbrown = { workspace = true }\r\n imperative = { workspace = true }\r\n is-macro = { workspace = true }\r\n is-wsl = { workspace = true }\r\nIndex: crates/ruff_linter/src/fix/mod.rs\r\nIDEA additional info:\r\nSubsystem: com.intellij.openapi.diff.impl.patch.CharsetEP\r\n<+>UTF-8\r\n===================================================================\r\ndiff --git a/crates/ruff_linter/src/fix/mod.rs b/crates/ruff_linter/src/fix/mod.rs\r\n--- a/crates/ruff_linter/src/fix/mod.rs\t(revision 44c13a29c5f24064c446277cfdfd9fdba6c163f6)\r\n+++ b/crates/ruff_linter/src/fix/mod.rs\t(date 1750921753842)\r\n@@ -110,7 +110,7 @@\r\n         }\r\n \r\n         applied.extend(applied_edits.drain(..));\r\n-        *fixed.entry(code.to_string()).or_default(name) += 1;\r\n+        *fixed.entry(code).or_default(name) += 1;\r\n     }\r\n \r\n     // Add the remaining content.\r\n\r\n```\r\n\r\n</p>\r\n</details> ",
        "pr_file_module": null
      },
      {
        "comment_id": "2169024126",
        "repo_full_name": "astral-sh/ruff",
        "pr_number": 18946,
        "pr_file": "crates/ruff/src/diagnostics.rs",
        "discussion_id": "2168338888",
        "commented_code": "@@ -167,7 +167,7 @@ impl AddAssign for FixMap {\n             let fixed_in_file = self.0.entry(filename).or_default();\n             for (rule, name, count) in fixed.iter() {\n                 if count > 0 {\n-                    *fixed_in_file.entry(rule).or_default(name) += count;\n+                    *fixed_in_file.entry(rule.to_string()).or_default(name) += count;",
        "comment_created_at": "2025-06-26T13:03:54+00:00",
        "comment_author": "ntBre",
        "comment_body": "Nice, thanks for the patch! It was annoying that I couldn't do this with a regular `Entry`.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2158768540",
    "pr_number": 18600,
    "pr_file": "crates/ty_python_semantic/src/types/tuple.rs",
    "created_at": "2025-06-20T11:45:33+00:00",
    "commented_code": "+//! Defines types for describing fixed- and variable-length tuples.\n+//!\n+//! At runtime, a Python tuple is a fixed-length immutable list of values. There is no restriction\n+//! on the types of the elements of a tuple value. In the type system, we want to model both\n+//! \"heterogeneous\" tuples that have elements of a fixed sequence of specific types, and\n+//! \"homogenous\" tuples that have an unknown number of elements of the same single type. And in\n+//! fact, we want to model tuples that are a combination of the two, with a heterogeneous prefix\n+//! and/or suffix, and a homogeneous portion of unknown length in between those.\n+\n+use itertools::Either;\n+\n+use crate::types::class::{ClassType, KnownClass};\n+use crate::types::{Type, TypeMapping, TypeRelation, TypeVarInstance, TypeVarVariance, UnionType};\n+use crate::util::subscript::{Nth, OutOfBoundsError, PyIndex, PySlice, StepSizeZeroError};\n+use crate::{Db, FxOrderSet};\n+\n+/// # Ordering\n+/// Ordering is based on the tuple's salsa-assigned id and not on its elements.\n+/// The id may change between runs, or when the tuple was garbage collected and recreated.\n+#[salsa::interned(debug)]\n+#[derive(PartialOrd, Ord)]\n+pub struct TupleType<'db> {\n+    #[returns(ref)]\n+    pub(crate) tuple: Tuple<'db>,\n+}\n+\n+impl<'db> Type<'db> {\n+    pub(crate) fn tuple(db: &'db dyn Db, tuple: TupleType<'db>) -> Self {\n+        // If a fixed-length (i.e., mandatory) element of the tuple is `Never`, then it's not\n+        // possible to instantiate the tuple as a whole. (This is not true of the variable-length\n+        // portion of the tuple, since it can contain no elements.)\n+        if tuple.tuple(db).fixed_elements().any(|ty| ty.is_never()) {\n+            return Type::Never;\n+        }\n+        Self::Tuple(tuple)\n+    }\n+}\n+\n+impl<'db> TupleType<'db> {\n+    pub(crate) fn empty(db: &'db dyn Db) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(db, Tuple::from(FixedLengthTuple::empty())),\n+        )\n+    }\n+\n+    pub(crate) fn from_elements(\n+        db: &'db dyn Db,\n+        types: impl IntoIterator<Item = impl Into<Type<'db>>>,\n+    ) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(db, Tuple::from(FixedLengthTuple::from_elements(types))),\n+        )\n+    }\n+\n+    #[cfg(test)]\n+    pub(crate) fn mixed(\n+        db: &'db dyn Db,\n+        prefix: impl IntoIterator<Item = impl Into<Type<'db>>>,\n+        variable: Type<'db>,\n+        suffix: impl IntoIterator<Item = impl Into<Type<'db>>>,\n+    ) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(\n+                db,\n+                Tuple::from(VariableLengthTuple::mixed(prefix, variable, suffix)),\n+            ),\n+        )\n+    }\n+\n+    pub(crate) fn homogeneous(db: &'db dyn Db, element: Type<'db>) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(db, Tuple::from(VariableLengthTuple::homogeneous(element))),\n+        )\n+    }\n+\n+    pub(crate) fn to_class_type(self, db: &'db dyn Db) -> Option<ClassType<'db>> {\n+        KnownClass::Tuple\n+            .try_to_class_literal(db)\n+            .and_then(|class_literal| match class_literal.generic_context(db) {\n+                None => Some(ClassType::NonGeneric(class_literal)),\n+                Some(generic_context) if generic_context.variables(db).len() != 1 => None,\n+                Some(generic_context) => Some(\n+                    class_literal\n+                        .apply_specialization(db, |_| generic_context.specialize_tuple(db, self)),\n+                ),\n+            })\n+    }\n+\n+    /// Return a normalized version of `self`.\n+    ///\n+    /// See [`Type::normalized`] for more details.\n+    #[must_use]\n+    pub(crate) fn normalized(self, db: &'db dyn Db) -> Self {\n+        TupleType::new(db, self.tuple(db).normalized(db))\n+    }\n+\n+    pub(crate) fn materialize(self, db: &'db dyn Db, variance: TypeVarVariance) -> Self {\n+        TupleType::new(db, self.tuple(db).materialize(db, variance))\n+    }\n+\n+    pub(crate) fn apply_type_mapping<'a>(\n+        self,\n+        db: &'db dyn Db,\n+        type_mapping: &TypeMapping<'a, 'db>,\n+    ) -> Self {\n+        TupleType::new(db, self.tuple(db).apply_type_mapping(db, type_mapping))\n+    }\n+\n+    pub(crate) fn find_legacy_typevars(\n+        self,\n+        db: &'db dyn Db,\n+        typevars: &mut FxOrderSet<TypeVarInstance<'db>>,\n+    ) {\n+        self.tuple(db).find_legacy_typevars(db, typevars);\n+    }\n+\n+    pub(crate) fn has_relation_to(\n+        self,\n+        db: &'db dyn Db,\n+        other: Self,\n+        relation: TypeRelation,\n+    ) -> bool {\n+        self.tuple(db)\n+            .has_relation_to(db, other.tuple(db), relation)\n+    }\n+\n+    pub(crate) fn is_equivalent_to(self, db: &'db dyn Db, other: Self) -> bool {\n+        self.tuple(db).is_equivalent_to(db, other.tuple(db))\n+    }\n+\n+    pub(crate) fn is_gradual_equivalent_to(self, db: &'db dyn Db, other: Self) -> bool {\n+        self.tuple(db).is_gradual_equivalent_to(db, other.tuple(db))\n+    }\n+\n+    pub(crate) fn is_disjoint_from(self, db: &'db dyn Db, other: Self) -> bool {\n+        self.tuple(db).is_disjoint_from(db, other.tuple(db))\n+    }\n+\n+    pub(crate) fn is_fully_static(self, db: &'db dyn Db) -> bool {\n+        self.tuple(db).is_fully_static(db)\n+    }\n+\n+    pub(crate) fn is_single_valued(self, db: &'db dyn Db) -> bool {\n+        self.tuple(db).is_single_valued(db)\n+    }\n+}\n+\n+/// A fixed-length tuple.\n+#[derive(Clone, Debug, Default, Eq, Hash, PartialEq, salsa::Update)]\n+pub struct FixedLengthTuple<'db>(Vec<Type<'db>>);\n+\n+impl<'db> FixedLengthTuple<'db> {\n+    pub(crate) fn empty() -> Self {\n+        Self::default()\n+    }\n+\n+    pub(crate) fn with_capacity(capacity: usize) -> Self {\n+        Self(Vec::with_capacity(capacity))\n+    }\n+\n+    pub(crate) fn from_elements(elements: impl IntoIterator<Item = impl Into<Type<'db>>>) -> Self {\n+        Self(elements.into_iter().map(Into::into).collect())\n+    }\n+\n+    pub(crate) fn as_slice(&self) -> &[Type<'db>] {\n+        &self.0\n+    }\n+\n+    pub(crate) fn fixed_elements(&self) -> impl Iterator<Item = Type<'db>> + '_ {\n+        self.0.iter().copied()\n+    }\n+\n+    pub(crate) fn all_elements(&self) -> impl Iterator<Item = Type<'db>> + '_ {\n+        self.0.iter().copied()\n+    }\n+\n+    /// Returns the length of this tuple.\n+    pub(crate) fn len(&self) -> usize {\n+        self.0.len()\n+    }\n+\n+    fn is_empty(&self) -> bool {\n+        self.0.is_empty()\n+    }\n+\n+    fn concat(&self, other: &Tuple<'db>) -> Tuple<'db> {\n+        match other {\n+            Tuple::Fixed(other) => {\n+                let mut elements = Vec::with_capacity(self.0.len() + other.0.len());\n+                elements.extend_from_slice(&self.0);\n+                elements.extend_from_slice(&other.0);\n+                Tuple::Fixed(FixedLengthTuple(elements))\n+            }\n+\n+            Tuple::Variable(other) => {\n+                let mut prefix = Vec::with_capacity(self.0.len() + other.prefix.len());\n+                prefix.extend_from_slice(&self.0);\n+                prefix.extend_from_slice(&other.prefix);\n+                Tuple::Variable(VariableLengthTuple {\n+                    prefix,\n+                    variable: other.variable,\n+                    suffix: other.suffix.clone(),\n+                })\n+            }\n+        }\n+    }\n+\n+    pub(crate) fn push(&mut self, element: Type<'db>) {\n+        self.0.push(element);\n+    }\n+\n+    pub(crate) fn extend_from_slice(&mut self, elements: &[Type<'db>]) {\n+        self.0.extend_from_slice(elements);\n+    }\n+\n+    #[must_use]\n+    fn normalized(&self, db: &'db dyn Db) -> Self {\n+        Self(self.0.iter().map(|ty| ty.normalized(db)).collect())\n+    }\n+\n+    fn materialize(&self, db: &'db dyn Db, variance: TypeVarVariance) -> Self {\n+        Self(\n+            self.0\n+                .iter()\n+                .map(|ty| ty.materialize(db, variance))\n+                .collect(),\n+        )\n+    }\n+\n+    fn apply_type_mapping<'a>(&self, db: &'db dyn Db, type_mapping: &TypeMapping<'a, 'db>) -> Self {\n+        Self(\n+            self.0\n+                .iter()\n+                .map(|ty| ty.apply_type_mapping(db, type_mapping))\n+                .collect(),\n+        )\n+    }\n+\n+    fn find_legacy_typevars(\n+        &self,\n+        db: &'db dyn Db,\n+        typevars: &mut FxOrderSet<TypeVarInstance<'db>>,\n+    ) {\n+        for ty in &self.0 {\n+            ty.find_legacy_typevars(db, typevars);\n+        }\n+    }\n+\n+    fn has_relation_to(&self, db: &'db dyn Db, other: &Tuple<'db>, relation: TypeRelation) -> bool {\n+        match other {\n+            Tuple::Fixed(other) => {\n+                self.0.len() == other.0.len()\n+                    && (self.0.iter())\n+                        .zip(&other.0)\n+                        .all(|(self_ty, other_ty)| self_ty.has_relation_to(db, *other_ty, relation))\n+            }\n+\n+            Tuple::Variable(other) => {\n+                // This tuple must have enough elements to match up with the other tuple's prefix\n+                // and suffix, and each of those elements must pairwise satisfy the relation.\n+                let mut self_iter = self.0.iter();\n+                for other_ty in &other.prefix {\n+                    let Some(self_ty) = self_iter.next() else {\n+                        return false;\n+                    };\n+                    if !self_ty.has_relation_to(db, *other_ty, relation) {\n+                        return false;\n+                    }\n+                }\n+                for other_ty in other.suffix.iter().rev() {\n+                    let Some(self_ty) = self_iter.next_back() else {\n+                        return false;\n+                    };\n+                    if !self_ty.has_relation_to(db, *other_ty, relation) {\n+                        return false;\n+                    }\n+                }\n+\n+                // In addition, any remaining elements in this tuple must satisfy the\n+                // variable-length portion of the other tuple.\n+                self_iter.all(|self_ty| self_ty.has_relation_to(db, other.variable, relation))\n+            }\n+        }\n+    }\n+\n+    fn is_equivalent_to(&self, db: &'db dyn Db, other: &Self) -> bool {\n+        self.0.len() == other.0.len()\n+            && (self.0.iter())\n+                .zip(&other.0)\n+                .all(|(self_ty, other_ty)| self_ty.is_equivalent_to(db, *other_ty))\n+    }\n+\n+    fn is_gradual_equivalent_to(&self, db: &'db dyn Db, other: &Self) -> bool {\n+        self.0.len() == other.0.len()\n+            && (self.0.iter())\n+                .zip(&other.0)\n+                .all(|(self_ty, other_ty)| self_ty.is_gradual_equivalent_to(db, *other_ty))\n+    }\n+\n+    fn is_disjoint_from(&self, db: &'db dyn Db, other: &Self) -> bool {\n+        self.0.len() != other.0.len()\n+            || (self.0.iter())\n+                .zip(&other.0)\n+                .any(|(self_ty, other_ty)| self_ty.is_disjoint_from(db, *other_ty))\n+    }\n+\n+    fn is_fully_static(&self, db: &'db dyn Db) -> bool {\n+        self.0.iter().all(|ty| ty.is_fully_static(db))\n+    }\n+\n+    fn is_single_valued(&self, db: &'db dyn Db) -> bool {\n+        self.0.iter().all(|ty| ty.is_single_valued(db))\n+    }\n+}\n+\n+impl<'db> PyIndex<'db> for &FixedLengthTuple<'db> {\n+    type Item = Type<'db>;\n+\n+    fn py_index(self, db: &'db dyn Db, index: i32) -> Result<Self::Item, OutOfBoundsError> {\n+        self.0.as_slice().py_index(db, index).copied()\n+    }\n+}\n+\n+impl<'db> PySlice<'db> for FixedLengthTuple<'db> {\n+    type Item = Type<'db>;\n+\n+    fn py_slice(\n+        &'db self,\n+        db: &'db dyn Db,\n+        start: Option<i32>,\n+        stop: Option<i32>,\n+        step: Option<i32>,\n+    ) -> Result<impl Iterator<Item = &'db Self::Item>, StepSizeZeroError> {\n+        self.0.py_slice(db, start, stop, step)\n+    }\n+}\n+\n+/// A variable-length tuple.\n+///\n+/// The tuple can contain a fixed-length heterogeneous prefix and/or suffix. All of the elements of\n+/// the variable-length portion must be of the same type.\n+#[derive(Clone, Debug, Eq, Hash, PartialEq, salsa::Update)]\n+pub struct VariableLengthTuple<'db> {\n+    pub(crate) prefix: Vec<Type<'db>>,\n+    pub(crate) variable: Type<'db>,\n+    pub(crate) suffix: Vec<Type<'db>>,",
    "repo_full_name": "astral-sh/ruff",
    "discussion_comments": [
      {
        "comment_id": "2158768540",
        "repo_full_name": "astral-sh/ruff",
        "pr_number": 18600,
        "pr_file": "crates/ty_python_semantic/src/types/tuple.rs",
        "discussion_id": "2158768540",
        "commented_code": "@@ -0,0 +1,819 @@\n+//! Defines types for describing fixed- and variable-length tuples.\n+//!\n+//! At runtime, a Python tuple is a fixed-length immutable list of values. There is no restriction\n+//! on the types of the elements of a tuple value. In the type system, we want to model both\n+//! \"heterogeneous\" tuples that have elements of a fixed sequence of specific types, and\n+//! \"homogenous\" tuples that have an unknown number of elements of the same single type. And in\n+//! fact, we want to model tuples that are a combination of the two, with a heterogeneous prefix\n+//! and/or suffix, and a homogeneous portion of unknown length in between those.\n+\n+use itertools::Either;\n+\n+use crate::types::class::{ClassType, KnownClass};\n+use crate::types::{Type, TypeMapping, TypeRelation, TypeVarInstance, TypeVarVariance, UnionType};\n+use crate::util::subscript::{Nth, OutOfBoundsError, PyIndex, PySlice, StepSizeZeroError};\n+use crate::{Db, FxOrderSet};\n+\n+/// # Ordering\n+/// Ordering is based on the tuple's salsa-assigned id and not on its elements.\n+/// The id may change between runs, or when the tuple was garbage collected and recreated.\n+#[salsa::interned(debug)]\n+#[derive(PartialOrd, Ord)]\n+pub struct TupleType<'db> {\n+    #[returns(ref)]\n+    pub(crate) tuple: Tuple<'db>,\n+}\n+\n+impl<'db> Type<'db> {\n+    pub(crate) fn tuple(db: &'db dyn Db, tuple: TupleType<'db>) -> Self {\n+        // If a fixed-length (i.e., mandatory) element of the tuple is `Never`, then it's not\n+        // possible to instantiate the tuple as a whole. (This is not true of the variable-length\n+        // portion of the tuple, since it can contain no elements.)\n+        if tuple.tuple(db).fixed_elements().any(|ty| ty.is_never()) {\n+            return Type::Never;\n+        }\n+        Self::Tuple(tuple)\n+    }\n+}\n+\n+impl<'db> TupleType<'db> {\n+    pub(crate) fn empty(db: &'db dyn Db) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(db, Tuple::from(FixedLengthTuple::empty())),\n+        )\n+    }\n+\n+    pub(crate) fn from_elements(\n+        db: &'db dyn Db,\n+        types: impl IntoIterator<Item = impl Into<Type<'db>>>,\n+    ) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(db, Tuple::from(FixedLengthTuple::from_elements(types))),\n+        )\n+    }\n+\n+    #[cfg(test)]\n+    pub(crate) fn mixed(\n+        db: &'db dyn Db,\n+        prefix: impl IntoIterator<Item = impl Into<Type<'db>>>,\n+        variable: Type<'db>,\n+        suffix: impl IntoIterator<Item = impl Into<Type<'db>>>,\n+    ) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(\n+                db,\n+                Tuple::from(VariableLengthTuple::mixed(prefix, variable, suffix)),\n+            ),\n+        )\n+    }\n+\n+    pub(crate) fn homogeneous(db: &'db dyn Db, element: Type<'db>) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(db, Tuple::from(VariableLengthTuple::homogeneous(element))),\n+        )\n+    }\n+\n+    pub(crate) fn to_class_type(self, db: &'db dyn Db) -> Option<ClassType<'db>> {\n+        KnownClass::Tuple\n+            .try_to_class_literal(db)\n+            .and_then(|class_literal| match class_literal.generic_context(db) {\n+                None => Some(ClassType::NonGeneric(class_literal)),\n+                Some(generic_context) if generic_context.variables(db).len() != 1 => None,\n+                Some(generic_context) => Some(\n+                    class_literal\n+                        .apply_specialization(db, |_| generic_context.specialize_tuple(db, self)),\n+                ),\n+            })\n+    }\n+\n+    /// Return a normalized version of `self`.\n+    ///\n+    /// See [`Type::normalized`] for more details.\n+    #[must_use]\n+    pub(crate) fn normalized(self, db: &'db dyn Db) -> Self {\n+        TupleType::new(db, self.tuple(db).normalized(db))\n+    }\n+\n+    pub(crate) fn materialize(self, db: &'db dyn Db, variance: TypeVarVariance) -> Self {\n+        TupleType::new(db, self.tuple(db).materialize(db, variance))\n+    }\n+\n+    pub(crate) fn apply_type_mapping<'a>(\n+        self,\n+        db: &'db dyn Db,\n+        type_mapping: &TypeMapping<'a, 'db>,\n+    ) -> Self {\n+        TupleType::new(db, self.tuple(db).apply_type_mapping(db, type_mapping))\n+    }\n+\n+    pub(crate) fn find_legacy_typevars(\n+        self,\n+        db: &'db dyn Db,\n+        typevars: &mut FxOrderSet<TypeVarInstance<'db>>,\n+    ) {\n+        self.tuple(db).find_legacy_typevars(db, typevars);\n+    }\n+\n+    pub(crate) fn has_relation_to(\n+        self,\n+        db: &'db dyn Db,\n+        other: Self,\n+        relation: TypeRelation,\n+    ) -> bool {\n+        self.tuple(db)\n+            .has_relation_to(db, other.tuple(db), relation)\n+    }\n+\n+    pub(crate) fn is_equivalent_to(self, db: &'db dyn Db, other: Self) -> bool {\n+        self.tuple(db).is_equivalent_to(db, other.tuple(db))\n+    }\n+\n+    pub(crate) fn is_gradual_equivalent_to(self, db: &'db dyn Db, other: Self) -> bool {\n+        self.tuple(db).is_gradual_equivalent_to(db, other.tuple(db))\n+    }\n+\n+    pub(crate) fn is_disjoint_from(self, db: &'db dyn Db, other: Self) -> bool {\n+        self.tuple(db).is_disjoint_from(db, other.tuple(db))\n+    }\n+\n+    pub(crate) fn is_fully_static(self, db: &'db dyn Db) -> bool {\n+        self.tuple(db).is_fully_static(db)\n+    }\n+\n+    pub(crate) fn is_single_valued(self, db: &'db dyn Db) -> bool {\n+        self.tuple(db).is_single_valued(db)\n+    }\n+}\n+\n+/// A fixed-length tuple.\n+#[derive(Clone, Debug, Default, Eq, Hash, PartialEq, salsa::Update)]\n+pub struct FixedLengthTuple<'db>(Vec<Type<'db>>);\n+\n+impl<'db> FixedLengthTuple<'db> {\n+    pub(crate) fn empty() -> Self {\n+        Self::default()\n+    }\n+\n+    pub(crate) fn with_capacity(capacity: usize) -> Self {\n+        Self(Vec::with_capacity(capacity))\n+    }\n+\n+    pub(crate) fn from_elements(elements: impl IntoIterator<Item = impl Into<Type<'db>>>) -> Self {\n+        Self(elements.into_iter().map(Into::into).collect())\n+    }\n+\n+    pub(crate) fn as_slice(&self) -> &[Type<'db>] {\n+        &self.0\n+    }\n+\n+    pub(crate) fn fixed_elements(&self) -> impl Iterator<Item = Type<'db>> + '_ {\n+        self.0.iter().copied()\n+    }\n+\n+    pub(crate) fn all_elements(&self) -> impl Iterator<Item = Type<'db>> + '_ {\n+        self.0.iter().copied()\n+    }\n+\n+    /// Returns the length of this tuple.\n+    pub(crate) fn len(&self) -> usize {\n+        self.0.len()\n+    }\n+\n+    fn is_empty(&self) -> bool {\n+        self.0.is_empty()\n+    }\n+\n+    fn concat(&self, other: &Tuple<'db>) -> Tuple<'db> {\n+        match other {\n+            Tuple::Fixed(other) => {\n+                let mut elements = Vec::with_capacity(self.0.len() + other.0.len());\n+                elements.extend_from_slice(&self.0);\n+                elements.extend_from_slice(&other.0);\n+                Tuple::Fixed(FixedLengthTuple(elements))\n+            }\n+\n+            Tuple::Variable(other) => {\n+                let mut prefix = Vec::with_capacity(self.0.len() + other.prefix.len());\n+                prefix.extend_from_slice(&self.0);\n+                prefix.extend_from_slice(&other.prefix);\n+                Tuple::Variable(VariableLengthTuple {\n+                    prefix,\n+                    variable: other.variable,\n+                    suffix: other.suffix.clone(),\n+                })\n+            }\n+        }\n+    }\n+\n+    pub(crate) fn push(&mut self, element: Type<'db>) {\n+        self.0.push(element);\n+    }\n+\n+    pub(crate) fn extend_from_slice(&mut self, elements: &[Type<'db>]) {\n+        self.0.extend_from_slice(elements);\n+    }\n+\n+    #[must_use]\n+    fn normalized(&self, db: &'db dyn Db) -> Self {\n+        Self(self.0.iter().map(|ty| ty.normalized(db)).collect())\n+    }\n+\n+    fn materialize(&self, db: &'db dyn Db, variance: TypeVarVariance) -> Self {\n+        Self(\n+            self.0\n+                .iter()\n+                .map(|ty| ty.materialize(db, variance))\n+                .collect(),\n+        )\n+    }\n+\n+    fn apply_type_mapping<'a>(&self, db: &'db dyn Db, type_mapping: &TypeMapping<'a, 'db>) -> Self {\n+        Self(\n+            self.0\n+                .iter()\n+                .map(|ty| ty.apply_type_mapping(db, type_mapping))\n+                .collect(),\n+        )\n+    }\n+\n+    fn find_legacy_typevars(\n+        &self,\n+        db: &'db dyn Db,\n+        typevars: &mut FxOrderSet<TypeVarInstance<'db>>,\n+    ) {\n+        for ty in &self.0 {\n+            ty.find_legacy_typevars(db, typevars);\n+        }\n+    }\n+\n+    fn has_relation_to(&self, db: &'db dyn Db, other: &Tuple<'db>, relation: TypeRelation) -> bool {\n+        match other {\n+            Tuple::Fixed(other) => {\n+                self.0.len() == other.0.len()\n+                    && (self.0.iter())\n+                        .zip(&other.0)\n+                        .all(|(self_ty, other_ty)| self_ty.has_relation_to(db, *other_ty, relation))\n+            }\n+\n+            Tuple::Variable(other) => {\n+                // This tuple must have enough elements to match up with the other tuple's prefix\n+                // and suffix, and each of those elements must pairwise satisfy the relation.\n+                let mut self_iter = self.0.iter();\n+                for other_ty in &other.prefix {\n+                    let Some(self_ty) = self_iter.next() else {\n+                        return false;\n+                    };\n+                    if !self_ty.has_relation_to(db, *other_ty, relation) {\n+                        return false;\n+                    }\n+                }\n+                for other_ty in other.suffix.iter().rev() {\n+                    let Some(self_ty) = self_iter.next_back() else {\n+                        return false;\n+                    };\n+                    if !self_ty.has_relation_to(db, *other_ty, relation) {\n+                        return false;\n+                    }\n+                }\n+\n+                // In addition, any remaining elements in this tuple must satisfy the\n+                // variable-length portion of the other tuple.\n+                self_iter.all(|self_ty| self_ty.has_relation_to(db, other.variable, relation))\n+            }\n+        }\n+    }\n+\n+    fn is_equivalent_to(&self, db: &'db dyn Db, other: &Self) -> bool {\n+        self.0.len() == other.0.len()\n+            && (self.0.iter())\n+                .zip(&other.0)\n+                .all(|(self_ty, other_ty)| self_ty.is_equivalent_to(db, *other_ty))\n+    }\n+\n+    fn is_gradual_equivalent_to(&self, db: &'db dyn Db, other: &Self) -> bool {\n+        self.0.len() == other.0.len()\n+            && (self.0.iter())\n+                .zip(&other.0)\n+                .all(|(self_ty, other_ty)| self_ty.is_gradual_equivalent_to(db, *other_ty))\n+    }\n+\n+    fn is_disjoint_from(&self, db: &'db dyn Db, other: &Self) -> bool {\n+        self.0.len() != other.0.len()\n+            || (self.0.iter())\n+                .zip(&other.0)\n+                .any(|(self_ty, other_ty)| self_ty.is_disjoint_from(db, *other_ty))\n+    }\n+\n+    fn is_fully_static(&self, db: &'db dyn Db) -> bool {\n+        self.0.iter().all(|ty| ty.is_fully_static(db))\n+    }\n+\n+    fn is_single_valued(&self, db: &'db dyn Db) -> bool {\n+        self.0.iter().all(|ty| ty.is_single_valued(db))\n+    }\n+}\n+\n+impl<'db> PyIndex<'db> for &FixedLengthTuple<'db> {\n+    type Item = Type<'db>;\n+\n+    fn py_index(self, db: &'db dyn Db, index: i32) -> Result<Self::Item, OutOfBoundsError> {\n+        self.0.as_slice().py_index(db, index).copied()\n+    }\n+}\n+\n+impl<'db> PySlice<'db> for FixedLengthTuple<'db> {\n+    type Item = Type<'db>;\n+\n+    fn py_slice(\n+        &'db self,\n+        db: &'db dyn Db,\n+        start: Option<i32>,\n+        stop: Option<i32>,\n+        step: Option<i32>,\n+    ) -> Result<impl Iterator<Item = &'db Self::Item>, StepSizeZeroError> {\n+        self.0.py_slice(db, start, stop, step)\n+    }\n+}\n+\n+/// A variable-length tuple.\n+///\n+/// The tuple can contain a fixed-length heterogeneous prefix and/or suffix. All of the elements of\n+/// the variable-length portion must be of the same type.\n+#[derive(Clone, Debug, Eq, Hash, PartialEq, salsa::Update)]\n+pub struct VariableLengthTuple<'db> {\n+    pub(crate) prefix: Vec<Type<'db>>,\n+    pub(crate) variable: Type<'db>,\n+    pub(crate) suffix: Vec<Type<'db>>,",
        "comment_created_at": "2025-06-20T11:45:33+00:00",
        "comment_author": "AlexWaygood",
        "comment_body": "is it worth it/possible to use a smallvec for `prefix`/`suffix`? They're unlikely to be very large usually.",
        "pr_file_module": null
      },
      {
        "comment_id": "2158962839",
        "repo_full_name": "astral-sh/ruff",
        "pr_number": 18600,
        "pr_file": "crates/ty_python_semantic/src/types/tuple.rs",
        "discussion_id": "2158768540",
        "commented_code": "@@ -0,0 +1,819 @@\n+//! Defines types for describing fixed- and variable-length tuples.\n+//!\n+//! At runtime, a Python tuple is a fixed-length immutable list of values. There is no restriction\n+//! on the types of the elements of a tuple value. In the type system, we want to model both\n+//! \"heterogeneous\" tuples that have elements of a fixed sequence of specific types, and\n+//! \"homogenous\" tuples that have an unknown number of elements of the same single type. And in\n+//! fact, we want to model tuples that are a combination of the two, with a heterogeneous prefix\n+//! and/or suffix, and a homogeneous portion of unknown length in between those.\n+\n+use itertools::Either;\n+\n+use crate::types::class::{ClassType, KnownClass};\n+use crate::types::{Type, TypeMapping, TypeRelation, TypeVarInstance, TypeVarVariance, UnionType};\n+use crate::util::subscript::{Nth, OutOfBoundsError, PyIndex, PySlice, StepSizeZeroError};\n+use crate::{Db, FxOrderSet};\n+\n+/// # Ordering\n+/// Ordering is based on the tuple's salsa-assigned id and not on its elements.\n+/// The id may change between runs, or when the tuple was garbage collected and recreated.\n+#[salsa::interned(debug)]\n+#[derive(PartialOrd, Ord)]\n+pub struct TupleType<'db> {\n+    #[returns(ref)]\n+    pub(crate) tuple: Tuple<'db>,\n+}\n+\n+impl<'db> Type<'db> {\n+    pub(crate) fn tuple(db: &'db dyn Db, tuple: TupleType<'db>) -> Self {\n+        // If a fixed-length (i.e., mandatory) element of the tuple is `Never`, then it's not\n+        // possible to instantiate the tuple as a whole. (This is not true of the variable-length\n+        // portion of the tuple, since it can contain no elements.)\n+        if tuple.tuple(db).fixed_elements().any(|ty| ty.is_never()) {\n+            return Type::Never;\n+        }\n+        Self::Tuple(tuple)\n+    }\n+}\n+\n+impl<'db> TupleType<'db> {\n+    pub(crate) fn empty(db: &'db dyn Db) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(db, Tuple::from(FixedLengthTuple::empty())),\n+        )\n+    }\n+\n+    pub(crate) fn from_elements(\n+        db: &'db dyn Db,\n+        types: impl IntoIterator<Item = impl Into<Type<'db>>>,\n+    ) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(db, Tuple::from(FixedLengthTuple::from_elements(types))),\n+        )\n+    }\n+\n+    #[cfg(test)]\n+    pub(crate) fn mixed(\n+        db: &'db dyn Db,\n+        prefix: impl IntoIterator<Item = impl Into<Type<'db>>>,\n+        variable: Type<'db>,\n+        suffix: impl IntoIterator<Item = impl Into<Type<'db>>>,\n+    ) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(\n+                db,\n+                Tuple::from(VariableLengthTuple::mixed(prefix, variable, suffix)),\n+            ),\n+        )\n+    }\n+\n+    pub(crate) fn homogeneous(db: &'db dyn Db, element: Type<'db>) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(db, Tuple::from(VariableLengthTuple::homogeneous(element))),\n+        )\n+    }\n+\n+    pub(crate) fn to_class_type(self, db: &'db dyn Db) -> Option<ClassType<'db>> {\n+        KnownClass::Tuple\n+            .try_to_class_literal(db)\n+            .and_then(|class_literal| match class_literal.generic_context(db) {\n+                None => Some(ClassType::NonGeneric(class_literal)),\n+                Some(generic_context) if generic_context.variables(db).len() != 1 => None,\n+                Some(generic_context) => Some(\n+                    class_literal\n+                        .apply_specialization(db, |_| generic_context.specialize_tuple(db, self)),\n+                ),\n+            })\n+    }\n+\n+    /// Return a normalized version of `self`.\n+    ///\n+    /// See [`Type::normalized`] for more details.\n+    #[must_use]\n+    pub(crate) fn normalized(self, db: &'db dyn Db) -> Self {\n+        TupleType::new(db, self.tuple(db).normalized(db))\n+    }\n+\n+    pub(crate) fn materialize(self, db: &'db dyn Db, variance: TypeVarVariance) -> Self {\n+        TupleType::new(db, self.tuple(db).materialize(db, variance))\n+    }\n+\n+    pub(crate) fn apply_type_mapping<'a>(\n+        self,\n+        db: &'db dyn Db,\n+        type_mapping: &TypeMapping<'a, 'db>,\n+    ) -> Self {\n+        TupleType::new(db, self.tuple(db).apply_type_mapping(db, type_mapping))\n+    }\n+\n+    pub(crate) fn find_legacy_typevars(\n+        self,\n+        db: &'db dyn Db,\n+        typevars: &mut FxOrderSet<TypeVarInstance<'db>>,\n+    ) {\n+        self.tuple(db).find_legacy_typevars(db, typevars);\n+    }\n+\n+    pub(crate) fn has_relation_to(\n+        self,\n+        db: &'db dyn Db,\n+        other: Self,\n+        relation: TypeRelation,\n+    ) -> bool {\n+        self.tuple(db)\n+            .has_relation_to(db, other.tuple(db), relation)\n+    }\n+\n+    pub(crate) fn is_equivalent_to(self, db: &'db dyn Db, other: Self) -> bool {\n+        self.tuple(db).is_equivalent_to(db, other.tuple(db))\n+    }\n+\n+    pub(crate) fn is_gradual_equivalent_to(self, db: &'db dyn Db, other: Self) -> bool {\n+        self.tuple(db).is_gradual_equivalent_to(db, other.tuple(db))\n+    }\n+\n+    pub(crate) fn is_disjoint_from(self, db: &'db dyn Db, other: Self) -> bool {\n+        self.tuple(db).is_disjoint_from(db, other.tuple(db))\n+    }\n+\n+    pub(crate) fn is_fully_static(self, db: &'db dyn Db) -> bool {\n+        self.tuple(db).is_fully_static(db)\n+    }\n+\n+    pub(crate) fn is_single_valued(self, db: &'db dyn Db) -> bool {\n+        self.tuple(db).is_single_valued(db)\n+    }\n+}\n+\n+/// A fixed-length tuple.\n+#[derive(Clone, Debug, Default, Eq, Hash, PartialEq, salsa::Update)]\n+pub struct FixedLengthTuple<'db>(Vec<Type<'db>>);\n+\n+impl<'db> FixedLengthTuple<'db> {\n+    pub(crate) fn empty() -> Self {\n+        Self::default()\n+    }\n+\n+    pub(crate) fn with_capacity(capacity: usize) -> Self {\n+        Self(Vec::with_capacity(capacity))\n+    }\n+\n+    pub(crate) fn from_elements(elements: impl IntoIterator<Item = impl Into<Type<'db>>>) -> Self {\n+        Self(elements.into_iter().map(Into::into).collect())\n+    }\n+\n+    pub(crate) fn as_slice(&self) -> &[Type<'db>] {\n+        &self.0\n+    }\n+\n+    pub(crate) fn fixed_elements(&self) -> impl Iterator<Item = Type<'db>> + '_ {\n+        self.0.iter().copied()\n+    }\n+\n+    pub(crate) fn all_elements(&self) -> impl Iterator<Item = Type<'db>> + '_ {\n+        self.0.iter().copied()\n+    }\n+\n+    /// Returns the length of this tuple.\n+    pub(crate) fn len(&self) -> usize {\n+        self.0.len()\n+    }\n+\n+    fn is_empty(&self) -> bool {\n+        self.0.is_empty()\n+    }\n+\n+    fn concat(&self, other: &Tuple<'db>) -> Tuple<'db> {\n+        match other {\n+            Tuple::Fixed(other) => {\n+                let mut elements = Vec::with_capacity(self.0.len() + other.0.len());\n+                elements.extend_from_slice(&self.0);\n+                elements.extend_from_slice(&other.0);\n+                Tuple::Fixed(FixedLengthTuple(elements))\n+            }\n+\n+            Tuple::Variable(other) => {\n+                let mut prefix = Vec::with_capacity(self.0.len() + other.prefix.len());\n+                prefix.extend_from_slice(&self.0);\n+                prefix.extend_from_slice(&other.prefix);\n+                Tuple::Variable(VariableLengthTuple {\n+                    prefix,\n+                    variable: other.variable,\n+                    suffix: other.suffix.clone(),\n+                })\n+            }\n+        }\n+    }\n+\n+    pub(crate) fn push(&mut self, element: Type<'db>) {\n+        self.0.push(element);\n+    }\n+\n+    pub(crate) fn extend_from_slice(&mut self, elements: &[Type<'db>]) {\n+        self.0.extend_from_slice(elements);\n+    }\n+\n+    #[must_use]\n+    fn normalized(&self, db: &'db dyn Db) -> Self {\n+        Self(self.0.iter().map(|ty| ty.normalized(db)).collect())\n+    }\n+\n+    fn materialize(&self, db: &'db dyn Db, variance: TypeVarVariance) -> Self {\n+        Self(\n+            self.0\n+                .iter()\n+                .map(|ty| ty.materialize(db, variance))\n+                .collect(),\n+        )\n+    }\n+\n+    fn apply_type_mapping<'a>(&self, db: &'db dyn Db, type_mapping: &TypeMapping<'a, 'db>) -> Self {\n+        Self(\n+            self.0\n+                .iter()\n+                .map(|ty| ty.apply_type_mapping(db, type_mapping))\n+                .collect(),\n+        )\n+    }\n+\n+    fn find_legacy_typevars(\n+        &self,\n+        db: &'db dyn Db,\n+        typevars: &mut FxOrderSet<TypeVarInstance<'db>>,\n+    ) {\n+        for ty in &self.0 {\n+            ty.find_legacy_typevars(db, typevars);\n+        }\n+    }\n+\n+    fn has_relation_to(&self, db: &'db dyn Db, other: &Tuple<'db>, relation: TypeRelation) -> bool {\n+        match other {\n+            Tuple::Fixed(other) => {\n+                self.0.len() == other.0.len()\n+                    && (self.0.iter())\n+                        .zip(&other.0)\n+                        .all(|(self_ty, other_ty)| self_ty.has_relation_to(db, *other_ty, relation))\n+            }\n+\n+            Tuple::Variable(other) => {\n+                // This tuple must have enough elements to match up with the other tuple's prefix\n+                // and suffix, and each of those elements must pairwise satisfy the relation.\n+                let mut self_iter = self.0.iter();\n+                for other_ty in &other.prefix {\n+                    let Some(self_ty) = self_iter.next() else {\n+                        return false;\n+                    };\n+                    if !self_ty.has_relation_to(db, *other_ty, relation) {\n+                        return false;\n+                    }\n+                }\n+                for other_ty in other.suffix.iter().rev() {\n+                    let Some(self_ty) = self_iter.next_back() else {\n+                        return false;\n+                    };\n+                    if !self_ty.has_relation_to(db, *other_ty, relation) {\n+                        return false;\n+                    }\n+                }\n+\n+                // In addition, any remaining elements in this tuple must satisfy the\n+                // variable-length portion of the other tuple.\n+                self_iter.all(|self_ty| self_ty.has_relation_to(db, other.variable, relation))\n+            }\n+        }\n+    }\n+\n+    fn is_equivalent_to(&self, db: &'db dyn Db, other: &Self) -> bool {\n+        self.0.len() == other.0.len()\n+            && (self.0.iter())\n+                .zip(&other.0)\n+                .all(|(self_ty, other_ty)| self_ty.is_equivalent_to(db, *other_ty))\n+    }\n+\n+    fn is_gradual_equivalent_to(&self, db: &'db dyn Db, other: &Self) -> bool {\n+        self.0.len() == other.0.len()\n+            && (self.0.iter())\n+                .zip(&other.0)\n+                .all(|(self_ty, other_ty)| self_ty.is_gradual_equivalent_to(db, *other_ty))\n+    }\n+\n+    fn is_disjoint_from(&self, db: &'db dyn Db, other: &Self) -> bool {\n+        self.0.len() != other.0.len()\n+            || (self.0.iter())\n+                .zip(&other.0)\n+                .any(|(self_ty, other_ty)| self_ty.is_disjoint_from(db, *other_ty))\n+    }\n+\n+    fn is_fully_static(&self, db: &'db dyn Db) -> bool {\n+        self.0.iter().all(|ty| ty.is_fully_static(db))\n+    }\n+\n+    fn is_single_valued(&self, db: &'db dyn Db) -> bool {\n+        self.0.iter().all(|ty| ty.is_single_valued(db))\n+    }\n+}\n+\n+impl<'db> PyIndex<'db> for &FixedLengthTuple<'db> {\n+    type Item = Type<'db>;\n+\n+    fn py_index(self, db: &'db dyn Db, index: i32) -> Result<Self::Item, OutOfBoundsError> {\n+        self.0.as_slice().py_index(db, index).copied()\n+    }\n+}\n+\n+impl<'db> PySlice<'db> for FixedLengthTuple<'db> {\n+    type Item = Type<'db>;\n+\n+    fn py_slice(\n+        &'db self,\n+        db: &'db dyn Db,\n+        start: Option<i32>,\n+        stop: Option<i32>,\n+        step: Option<i32>,\n+    ) -> Result<impl Iterator<Item = &'db Self::Item>, StepSizeZeroError> {\n+        self.0.py_slice(db, start, stop, step)\n+    }\n+}\n+\n+/// A variable-length tuple.\n+///\n+/// The tuple can contain a fixed-length heterogeneous prefix and/or suffix. All of the elements of\n+/// the variable-length portion must be of the same type.\n+#[derive(Clone, Debug, Eq, Hash, PartialEq, salsa::Update)]\n+pub struct VariableLengthTuple<'db> {\n+    pub(crate) prefix: Vec<Type<'db>>,\n+    pub(crate) variable: Type<'db>,\n+    pub(crate) suffix: Vec<Type<'db>>,",
        "comment_created_at": "2025-06-20T13:16:38+00:00",
        "comment_author": "dcreager",
        "comment_body": "I had thought that wouldn't be important to optimize, since this will typically be hidden behind a salsa-interned `TupleType` anyway, so an extra heap allocation won't be that bad.",
        "pr_file_module": null
      },
      {
        "comment_id": "2159394229",
        "repo_full_name": "astral-sh/ruff",
        "pr_number": 18600,
        "pr_file": "crates/ty_python_semantic/src/types/tuple.rs",
        "discussion_id": "2158768540",
        "commented_code": "@@ -0,0 +1,819 @@\n+//! Defines types for describing fixed- and variable-length tuples.\n+//!\n+//! At runtime, a Python tuple is a fixed-length immutable list of values. There is no restriction\n+//! on the types of the elements of a tuple value. In the type system, we want to model both\n+//! \"heterogeneous\" tuples that have elements of a fixed sequence of specific types, and\n+//! \"homogenous\" tuples that have an unknown number of elements of the same single type. And in\n+//! fact, we want to model tuples that are a combination of the two, with a heterogeneous prefix\n+//! and/or suffix, and a homogeneous portion of unknown length in between those.\n+\n+use itertools::Either;\n+\n+use crate::types::class::{ClassType, KnownClass};\n+use crate::types::{Type, TypeMapping, TypeRelation, TypeVarInstance, TypeVarVariance, UnionType};\n+use crate::util::subscript::{Nth, OutOfBoundsError, PyIndex, PySlice, StepSizeZeroError};\n+use crate::{Db, FxOrderSet};\n+\n+/// # Ordering\n+/// Ordering is based on the tuple's salsa-assigned id and not on its elements.\n+/// The id may change between runs, or when the tuple was garbage collected and recreated.\n+#[salsa::interned(debug)]\n+#[derive(PartialOrd, Ord)]\n+pub struct TupleType<'db> {\n+    #[returns(ref)]\n+    pub(crate) tuple: Tuple<'db>,\n+}\n+\n+impl<'db> Type<'db> {\n+    pub(crate) fn tuple(db: &'db dyn Db, tuple: TupleType<'db>) -> Self {\n+        // If a fixed-length (i.e., mandatory) element of the tuple is `Never`, then it's not\n+        // possible to instantiate the tuple as a whole. (This is not true of the variable-length\n+        // portion of the tuple, since it can contain no elements.)\n+        if tuple.tuple(db).fixed_elements().any(|ty| ty.is_never()) {\n+            return Type::Never;\n+        }\n+        Self::Tuple(tuple)\n+    }\n+}\n+\n+impl<'db> TupleType<'db> {\n+    pub(crate) fn empty(db: &'db dyn Db) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(db, Tuple::from(FixedLengthTuple::empty())),\n+        )\n+    }\n+\n+    pub(crate) fn from_elements(\n+        db: &'db dyn Db,\n+        types: impl IntoIterator<Item = impl Into<Type<'db>>>,\n+    ) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(db, Tuple::from(FixedLengthTuple::from_elements(types))),\n+        )\n+    }\n+\n+    #[cfg(test)]\n+    pub(crate) fn mixed(\n+        db: &'db dyn Db,\n+        prefix: impl IntoIterator<Item = impl Into<Type<'db>>>,\n+        variable: Type<'db>,\n+        suffix: impl IntoIterator<Item = impl Into<Type<'db>>>,\n+    ) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(\n+                db,\n+                Tuple::from(VariableLengthTuple::mixed(prefix, variable, suffix)),\n+            ),\n+        )\n+    }\n+\n+    pub(crate) fn homogeneous(db: &'db dyn Db, element: Type<'db>) -> Type<'db> {\n+        Type::tuple(\n+            db,\n+            TupleType::new(db, Tuple::from(VariableLengthTuple::homogeneous(element))),\n+        )\n+    }\n+\n+    pub(crate) fn to_class_type(self, db: &'db dyn Db) -> Option<ClassType<'db>> {\n+        KnownClass::Tuple\n+            .try_to_class_literal(db)\n+            .and_then(|class_literal| match class_literal.generic_context(db) {\n+                None => Some(ClassType::NonGeneric(class_literal)),\n+                Some(generic_context) if generic_context.variables(db).len() != 1 => None,\n+                Some(generic_context) => Some(\n+                    class_literal\n+                        .apply_specialization(db, |_| generic_context.specialize_tuple(db, self)),\n+                ),\n+            })\n+    }\n+\n+    /// Return a normalized version of `self`.\n+    ///\n+    /// See [`Type::normalized`] for more details.\n+    #[must_use]\n+    pub(crate) fn normalized(self, db: &'db dyn Db) -> Self {\n+        TupleType::new(db, self.tuple(db).normalized(db))\n+    }\n+\n+    pub(crate) fn materialize(self, db: &'db dyn Db, variance: TypeVarVariance) -> Self {\n+        TupleType::new(db, self.tuple(db).materialize(db, variance))\n+    }\n+\n+    pub(crate) fn apply_type_mapping<'a>(\n+        self,\n+        db: &'db dyn Db,\n+        type_mapping: &TypeMapping<'a, 'db>,\n+    ) -> Self {\n+        TupleType::new(db, self.tuple(db).apply_type_mapping(db, type_mapping))\n+    }\n+\n+    pub(crate) fn find_legacy_typevars(\n+        self,\n+        db: &'db dyn Db,\n+        typevars: &mut FxOrderSet<TypeVarInstance<'db>>,\n+    ) {\n+        self.tuple(db).find_legacy_typevars(db, typevars);\n+    }\n+\n+    pub(crate) fn has_relation_to(\n+        self,\n+        db: &'db dyn Db,\n+        other: Self,\n+        relation: TypeRelation,\n+    ) -> bool {\n+        self.tuple(db)\n+            .has_relation_to(db, other.tuple(db), relation)\n+    }\n+\n+    pub(crate) fn is_equivalent_to(self, db: &'db dyn Db, other: Self) -> bool {\n+        self.tuple(db).is_equivalent_to(db, other.tuple(db))\n+    }\n+\n+    pub(crate) fn is_gradual_equivalent_to(self, db: &'db dyn Db, other: Self) -> bool {\n+        self.tuple(db).is_gradual_equivalent_to(db, other.tuple(db))\n+    }\n+\n+    pub(crate) fn is_disjoint_from(self, db: &'db dyn Db, other: Self) -> bool {\n+        self.tuple(db).is_disjoint_from(db, other.tuple(db))\n+    }\n+\n+    pub(crate) fn is_fully_static(self, db: &'db dyn Db) -> bool {\n+        self.tuple(db).is_fully_static(db)\n+    }\n+\n+    pub(crate) fn is_single_valued(self, db: &'db dyn Db) -> bool {\n+        self.tuple(db).is_single_valued(db)\n+    }\n+}\n+\n+/// A fixed-length tuple.\n+#[derive(Clone, Debug, Default, Eq, Hash, PartialEq, salsa::Update)]\n+pub struct FixedLengthTuple<'db>(Vec<Type<'db>>);\n+\n+impl<'db> FixedLengthTuple<'db> {\n+    pub(crate) fn empty() -> Self {\n+        Self::default()\n+    }\n+\n+    pub(crate) fn with_capacity(capacity: usize) -> Self {\n+        Self(Vec::with_capacity(capacity))\n+    }\n+\n+    pub(crate) fn from_elements(elements: impl IntoIterator<Item = impl Into<Type<'db>>>) -> Self {\n+        Self(elements.into_iter().map(Into::into).collect())\n+    }\n+\n+    pub(crate) fn as_slice(&self) -> &[Type<'db>] {\n+        &self.0\n+    }\n+\n+    pub(crate) fn fixed_elements(&self) -> impl Iterator<Item = Type<'db>> + '_ {\n+        self.0.iter().copied()\n+    }\n+\n+    pub(crate) fn all_elements(&self) -> impl Iterator<Item = Type<'db>> + '_ {\n+        self.0.iter().copied()\n+    }\n+\n+    /// Returns the length of this tuple.\n+    pub(crate) fn len(&self) -> usize {\n+        self.0.len()\n+    }\n+\n+    fn is_empty(&self) -> bool {\n+        self.0.is_empty()\n+    }\n+\n+    fn concat(&self, other: &Tuple<'db>) -> Tuple<'db> {\n+        match other {\n+            Tuple::Fixed(other) => {\n+                let mut elements = Vec::with_capacity(self.0.len() + other.0.len());\n+                elements.extend_from_slice(&self.0);\n+                elements.extend_from_slice(&other.0);\n+                Tuple::Fixed(FixedLengthTuple(elements))\n+            }\n+\n+            Tuple::Variable(other) => {\n+                let mut prefix = Vec::with_capacity(self.0.len() + other.prefix.len());\n+                prefix.extend_from_slice(&self.0);\n+                prefix.extend_from_slice(&other.prefix);\n+                Tuple::Variable(VariableLengthTuple {\n+                    prefix,\n+                    variable: other.variable,\n+                    suffix: other.suffix.clone(),\n+                })\n+            }\n+        }\n+    }\n+\n+    pub(crate) fn push(&mut self, element: Type<'db>) {\n+        self.0.push(element);\n+    }\n+\n+    pub(crate) fn extend_from_slice(&mut self, elements: &[Type<'db>]) {\n+        self.0.extend_from_slice(elements);\n+    }\n+\n+    #[must_use]\n+    fn normalized(&self, db: &'db dyn Db) -> Self {\n+        Self(self.0.iter().map(|ty| ty.normalized(db)).collect())\n+    }\n+\n+    fn materialize(&self, db: &'db dyn Db, variance: TypeVarVariance) -> Self {\n+        Self(\n+            self.0\n+                .iter()\n+                .map(|ty| ty.materialize(db, variance))\n+                .collect(),\n+        )\n+    }\n+\n+    fn apply_type_mapping<'a>(&self, db: &'db dyn Db, type_mapping: &TypeMapping<'a, 'db>) -> Self {\n+        Self(\n+            self.0\n+                .iter()\n+                .map(|ty| ty.apply_type_mapping(db, type_mapping))\n+                .collect(),\n+        )\n+    }\n+\n+    fn find_legacy_typevars(\n+        &self,\n+        db: &'db dyn Db,\n+        typevars: &mut FxOrderSet<TypeVarInstance<'db>>,\n+    ) {\n+        for ty in &self.0 {\n+            ty.find_legacy_typevars(db, typevars);\n+        }\n+    }\n+\n+    fn has_relation_to(&self, db: &'db dyn Db, other: &Tuple<'db>, relation: TypeRelation) -> bool {\n+        match other {\n+            Tuple::Fixed(other) => {\n+                self.0.len() == other.0.len()\n+                    && (self.0.iter())\n+                        .zip(&other.0)\n+                        .all(|(self_ty, other_ty)| self_ty.has_relation_to(db, *other_ty, relation))\n+            }\n+\n+            Tuple::Variable(other) => {\n+                // This tuple must have enough elements to match up with the other tuple's prefix\n+                // and suffix, and each of those elements must pairwise satisfy the relation.\n+                let mut self_iter = self.0.iter();\n+                for other_ty in &other.prefix {\n+                    let Some(self_ty) = self_iter.next() else {\n+                        return false;\n+                    };\n+                    if !self_ty.has_relation_to(db, *other_ty, relation) {\n+                        return false;\n+                    }\n+                }\n+                for other_ty in other.suffix.iter().rev() {\n+                    let Some(self_ty) = self_iter.next_back() else {\n+                        return false;\n+                    };\n+                    if !self_ty.has_relation_to(db, *other_ty, relation) {\n+                        return false;\n+                    }\n+                }\n+\n+                // In addition, any remaining elements in this tuple must satisfy the\n+                // variable-length portion of the other tuple.\n+                self_iter.all(|self_ty| self_ty.has_relation_to(db, other.variable, relation))\n+            }\n+        }\n+    }\n+\n+    fn is_equivalent_to(&self, db: &'db dyn Db, other: &Self) -> bool {\n+        self.0.len() == other.0.len()\n+            && (self.0.iter())\n+                .zip(&other.0)\n+                .all(|(self_ty, other_ty)| self_ty.is_equivalent_to(db, *other_ty))\n+    }\n+\n+    fn is_gradual_equivalent_to(&self, db: &'db dyn Db, other: &Self) -> bool {\n+        self.0.len() == other.0.len()\n+            && (self.0.iter())\n+                .zip(&other.0)\n+                .all(|(self_ty, other_ty)| self_ty.is_gradual_equivalent_to(db, *other_ty))\n+    }\n+\n+    fn is_disjoint_from(&self, db: &'db dyn Db, other: &Self) -> bool {\n+        self.0.len() != other.0.len()\n+            || (self.0.iter())\n+                .zip(&other.0)\n+                .any(|(self_ty, other_ty)| self_ty.is_disjoint_from(db, *other_ty))\n+    }\n+\n+    fn is_fully_static(&self, db: &'db dyn Db) -> bool {\n+        self.0.iter().all(|ty| ty.is_fully_static(db))\n+    }\n+\n+    fn is_single_valued(&self, db: &'db dyn Db) -> bool {\n+        self.0.iter().all(|ty| ty.is_single_valued(db))\n+    }\n+}\n+\n+impl<'db> PyIndex<'db> for &FixedLengthTuple<'db> {\n+    type Item = Type<'db>;\n+\n+    fn py_index(self, db: &'db dyn Db, index: i32) -> Result<Self::Item, OutOfBoundsError> {\n+        self.0.as_slice().py_index(db, index).copied()\n+    }\n+}\n+\n+impl<'db> PySlice<'db> for FixedLengthTuple<'db> {\n+    type Item = Type<'db>;\n+\n+    fn py_slice(\n+        &'db self,\n+        db: &'db dyn Db,\n+        start: Option<i32>,\n+        stop: Option<i32>,\n+        step: Option<i32>,\n+    ) -> Result<impl Iterator<Item = &'db Self::Item>, StepSizeZeroError> {\n+        self.0.py_slice(db, start, stop, step)\n+    }\n+}\n+\n+/// A variable-length tuple.\n+///\n+/// The tuple can contain a fixed-length heterogeneous prefix and/or suffix. All of the elements of\n+/// the variable-length portion must be of the same type.\n+#[derive(Clone, Debug, Eq, Hash, PartialEq, salsa::Update)]\n+pub struct VariableLengthTuple<'db> {\n+    pub(crate) prefix: Vec<Type<'db>>,\n+    pub(crate) variable: Type<'db>,\n+    pub(crate) suffix: Vec<Type<'db>>,",
        "comment_created_at": "2025-06-20T17:07:43+00:00",
        "comment_author": "AlexWaygood",
        "comment_body": "SG, we can leave this unless it shows up in profiles later",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2157595077",
    "pr_number": 18801,
    "pr_file": "crates/ruff_linter/src/checkers/ast/mod.rs",
    "created_at": "2025-06-19T20:01:44+00:00",
    "commented_code": "/// Returns whether the given rule should be checked.\n     #[inline]\n-    pub(crate) const fn enabled(&self, rule: Rule) -> bool {\n-        self.settings.rules.enabled(rule)\n+    pub(crate) fn enabled(&self, rule: Rule) -> bool {",
    "repo_full_name": "astral-sh/ruff",
    "discussion_comments": [
      {
        "comment_id": "2157595077",
        "repo_full_name": "astral-sh/ruff",
        "pr_number": 18801,
        "pr_file": "crates/ruff_linter/src/checkers/ast/mod.rs",
        "discussion_id": "2157595077",
        "commented_code": "@@ -473,14 +475,14 @@ impl<'a> Checker<'a> {\n \n     /// Returns whether the given rule should be checked.\n     #[inline]\n-    pub(crate) const fn enabled(&self, rule: Rule) -> bool {\n-        self.settings.rules.enabled(rule)\n+    pub(crate) fn enabled(&self, rule: Rule) -> bool {",
        "comment_created_at": "2025-06-19T20:01:44+00:00",
        "comment_author": "MichaReiser",
        "comment_body": "Oh, removing the const here could be problematic because the `RuleTable` lookup requires some bit operations and I assume that they might no longer happen at comp time",
        "pr_file_module": null
      },
      {
        "comment_id": "2157597048",
        "repo_full_name": "astral-sh/ruff",
        "pr_number": 18801,
        "pr_file": "crates/ruff_linter/src/checkers/ast/mod.rs",
        "discussion_id": "2157595077",
        "commented_code": "@@ -473,14 +475,14 @@ impl<'a> Checker<'a> {\n \n     /// Returns whether the given rule should be checked.\n     #[inline]\n-    pub(crate) const fn enabled(&self, rule: Rule) -> bool {\n-        self.settings.rules.enabled(rule)\n+    pub(crate) fn enabled(&self, rule: Rule) -> bool {",
        "comment_created_at": "2025-06-19T20:03:59+00:00",
        "comment_author": "ntBre",
        "comment_body": "Ahhh, hopefully that's it. I'll try just always cloning, the `Cow` is the reason I removed these consts.",
        "pr_file_module": null
      },
      {
        "comment_id": "2157635468",
        "repo_full_name": "astral-sh/ruff",
        "pr_number": 18801,
        "pr_file": "crates/ruff_linter/src/checkers/ast/mod.rs",
        "discussion_id": "2157595077",
        "commented_code": "@@ -473,14 +475,14 @@ impl<'a> Checker<'a> {\n \n     /// Returns whether the given rule should be checked.\n     #[inline]\n-    pub(crate) const fn enabled(&self, rule: Rule) -> bool {\n-        self.settings.rules.enabled(rule)\n+    pub(crate) fn enabled(&self, rule: Rule) -> bool {",
        "comment_created_at": "2025-06-19T20:35:03+00:00",
        "comment_author": "ntBre",
        "comment_body": "I guess that was it, thank you! Now there's a very slight speedup.",
        "pr_file_module": null
      },
      {
        "comment_id": "2157638896",
        "repo_full_name": "astral-sh/ruff",
        "pr_number": 18801,
        "pr_file": "crates/ruff_linter/src/checkers/ast/mod.rs",
        "discussion_id": "2157595077",
        "commented_code": "@@ -473,14 +475,14 @@ impl<'a> Checker<'a> {\n \n     /// Returns whether the given rule should be checked.\n     #[inline]\n-    pub(crate) const fn enabled(&self, rule: Rule) -> bool {\n-        self.settings.rules.enabled(rule)\n+    pub(crate) fn enabled(&self, rule: Rule) -> bool {",
        "comment_created_at": "2025-06-19T20:38:50+00:00",
        "comment_author": "MichaReiser",
        "comment_body": "Yeah, the rule checks are in a very hot path. Still surprising that it would regress by that much",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2139670185",
    "pr_number": 18623,
    "pr_file": "crates/ruff_server/src/session/index.rs",
    "created_at": "2025-06-11T09:34:15+00:00",
    "commented_code": "\"No settings available for {} - falling back to default settings\",\n                     url\n                 );\n-                let resolved_global = ResolvedClientSettings::global(global_settings);",
    "repo_full_name": "astral-sh/ruff",
    "discussion_comments": [
      {
        "comment_id": "2139670185",
        "repo_full_name": "astral-sh/ruff",
        "pr_number": 18623,
        "pr_file": "crates/ruff_server/src/session/index.rs",
        "discussion_id": "2139670185",
        "commented_code": "@@ -230,13 +229,12 @@ impl Index {\n                     \"No settings available for {} - falling back to default settings\",\n                     url\n                 );\n-                let resolved_global = ResolvedClientSettings::global(global_settings);",
        "comment_created_at": "2025-06-11T09:34:15+00:00",
        "comment_author": "MichaReiser",
        "comment_body": "This resulted in constructing and validating the global settings on every keystroke (worst case) which then could result in Ruff spamming the user with errors. We can now simply cache settings.",
        "pr_file_module": null
      },
      {
        "comment_id": "2142046343",
        "repo_full_name": "astral-sh/ruff",
        "pr_number": 18623,
        "pr_file": "crates/ruff_server/src/session/index.rs",
        "discussion_id": "2139670185",
        "commented_code": "@@ -230,13 +229,12 @@ impl Index {\n                     \"No settings available for {} - falling back to default settings\",\n                     url\n                 );\n-                let resolved_global = ResolvedClientSettings::global(global_settings);",
        "comment_created_at": "2025-06-12T08:25:45+00:00",
        "comment_author": "dhruvmanila",
        "comment_body": "Thanks! This makes sense, I have a half baked branch doing something similar locally ;)",
        "pr_file_module": null
      }
    ]
  }
]