[
  {
    "discussion_id": "2224954875",
    "pr_number": 143730,
    "pr_file": "library/coretests/benches/fmt.rs",
    "created_at": "2025-07-23T09:24:24+00:00",
    "commented_code": "black_box(format!(\"{}\", black_box(u8::MIN)));\n     });\n }\n+\n+#[bench]\n+fn write_12ints_bin(bh: &mut Bencher) {\n+    bh.iter(|| {\n+        black_box(format!(\"{:b}\", black_box(0_u8)));\n+        black_box(format!(\"{:b}\", black_box(100_i8)));\n+        black_box(format!(\"{:b}\", black_box(-100_i8)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u32)));\n+        black_box(format!(\"{:b}\", black_box(1000_i32)));\n+        black_box(format!(\"{:b}\", black_box(-1000_i32)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u64)));\n+        black_box(format!(\"{:b}\", black_box(10000_i64)));\n+        black_box(format!(\"{:b}\", black_box(-10000_i64)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u128)));\n+        black_box(format!(\"{:b}\", black_box(100000_i128)));\n+        black_box(format!(\"{:b}\", black_box(-100000_i128)));\n+    });\n+}",
    "repo_full_name": "rust-lang/rust",
    "discussion_comments": [
      {
        "comment_id": "2224954875",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 143730,
        "pr_file": "library/coretests/benches/fmt.rs",
        "discussion_id": "2224954875",
        "commented_code": "@@ -162,3 +162,66 @@ fn write_u8_min(bh: &mut Bencher) {\n         black_box(format!(\"{}\", black_box(u8::MIN)));\n     });\n }\n+\n+#[bench]\n+fn write_12ints_bin(bh: &mut Bencher) {\n+    bh.iter(|| {\n+        black_box(format!(\"{:b}\", black_box(0_u8)));\n+        black_box(format!(\"{:b}\", black_box(100_i8)));\n+        black_box(format!(\"{:b}\", black_box(-100_i8)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u32)));\n+        black_box(format!(\"{:b}\", black_box(1000_i32)));\n+        black_box(format!(\"{:b}\", black_box(-1000_i32)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u64)));\n+        black_box(format!(\"{:b}\", black_box(10000_i64)));\n+        black_box(format!(\"{:b}\", black_box(-10000_i64)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u128)));\n+        black_box(format!(\"{:b}\", black_box(100000_i128)));\n+        black_box(format!(\"{:b}\", black_box(-100000_i128)));\n+    });\n+}",
        "comment_created_at": "2025-07-23T09:24:24+00:00",
        "comment_author": "tgross35",
        "comment_body": "I think it would be good to break up benchmarks by integer size because that can be pretty platform-dependent, e.g. u64 might be about the same as u32 on 64-bit platforms, but significantly slower on 32-bit.\r\n\r\nTesting a few assorted values seems good though. To get an even balance it may also be good to check:\r\n\r\n* `1 << n` for n `0..U::BITS`, both signed and unsigned\r\n* `10.pow(n)` for `n = 0` up to the max that fits\r\n* `I::MIN`, `I::MAX`, `U::MAX`\r\n\r\nThese can be collected outside of `bb.iter` so the cost of computing values isn't included in the benchmarks",
        "pr_file_module": null
      },
      {
        "comment_id": "2224963177",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 143730,
        "pr_file": "library/coretests/benches/fmt.rs",
        "discussion_id": "2224954875",
        "commented_code": "@@ -162,3 +162,66 @@ fn write_u8_min(bh: &mut Bencher) {\n         black_box(format!(\"{}\", black_box(u8::MIN)));\n     });\n }\n+\n+#[bench]\n+fn write_12ints_bin(bh: &mut Bencher) {\n+    bh.iter(|| {\n+        black_box(format!(\"{:b}\", black_box(0_u8)));\n+        black_box(format!(\"{:b}\", black_box(100_i8)));\n+        black_box(format!(\"{:b}\", black_box(-100_i8)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u32)));\n+        black_box(format!(\"{:b}\", black_box(1000_i32)));\n+        black_box(format!(\"{:b}\", black_box(-1000_i32)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u64)));\n+        black_box(format!(\"{:b}\", black_box(10000_i64)));\n+        black_box(format!(\"{:b}\", black_box(-10000_i64)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u128)));\n+        black_box(format!(\"{:b}\", black_box(100000_i128)));\n+        black_box(format!(\"{:b}\", black_box(-100000_i128)));\n+    });\n+}",
        "comment_created_at": "2025-07-23T09:27:54+00:00",
        "comment_author": "tgross35",
        "comment_body": "This is preexisting but it would also be better to create a `String::with_capacity(enough_for_u128)`, within `bb.iter` just `.clear()` and `write!` into it. Keeps time to alloc/free from skewing benchmark results.",
        "pr_file_module": null
      },
      {
        "comment_id": "2225601753",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 143730,
        "pr_file": "library/coretests/benches/fmt.rs",
        "discussion_id": "2224954875",
        "commented_code": "@@ -162,3 +162,66 @@ fn write_u8_min(bh: &mut Bencher) {\n         black_box(format!(\"{}\", black_box(u8::MIN)));\n     });\n }\n+\n+#[bench]\n+fn write_12ints_bin(bh: &mut Bencher) {\n+    bh.iter(|| {\n+        black_box(format!(\"{:b}\", black_box(0_u8)));\n+        black_box(format!(\"{:b}\", black_box(100_i8)));\n+        black_box(format!(\"{:b}\", black_box(-100_i8)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u32)));\n+        black_box(format!(\"{:b}\", black_box(1000_i32)));\n+        black_box(format!(\"{:b}\", black_box(-1000_i32)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u64)));\n+        black_box(format!(\"{:b}\", black_box(10000_i64)));\n+        black_box(format!(\"{:b}\", black_box(-10000_i64)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u128)));\n+        black_box(format!(\"{:b}\", black_box(100000_i128)));\n+        black_box(format!(\"{:b}\", black_box(-100000_i128)));\n+    });\n+}",
        "comment_created_at": "2025-07-23T13:22:34+00:00",
        "comment_author": "pascaldekloe",
        "comment_body": "Good point on comparison between hardware platforms.\r\n\r\nInteger values in practice don't spread evenly across the available range. Zero is by far the most common value, and values up to 1000 cover the vast majority according to internal research from Google when developing ProtoBuf. The zero, plus a medium-sized count, plus the maximum number of digits with a negative count might give a better indication than such rich mix of scenario. Do you agree @tgross35?",
        "pr_file_module": null
      },
      {
        "comment_id": "2225711489",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 143730,
        "pr_file": "library/coretests/benches/fmt.rs",
        "discussion_id": "2224954875",
        "commented_code": "@@ -162,3 +162,66 @@ fn write_u8_min(bh: &mut Bencher) {\n         black_box(format!(\"{}\", black_box(u8::MIN)));\n     });\n }\n+\n+#[bench]\n+fn write_12ints_bin(bh: &mut Bencher) {\n+    bh.iter(|| {\n+        black_box(format!(\"{:b}\", black_box(0_u8)));\n+        black_box(format!(\"{:b}\", black_box(100_i8)));\n+        black_box(format!(\"{:b}\", black_box(-100_i8)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u32)));\n+        black_box(format!(\"{:b}\", black_box(1000_i32)));\n+        black_box(format!(\"{:b}\", black_box(-1000_i32)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u64)));\n+        black_box(format!(\"{:b}\", black_box(10000_i64)));\n+        black_box(format!(\"{:b}\", black_box(-10000_i64)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u128)));\n+        black_box(format!(\"{:b}\", black_box(100000_i128)));\n+        black_box(format!(\"{:b}\", black_box(-100000_i128)));\n+    });\n+}",
        "comment_created_at": "2025-07-23T13:59:18+00:00",
        "comment_author": "pascaldekloe",
        "comment_body": "A sink might be better than buffering with String?\r\n\r\n```rust\r\n#[bench]\r\nfn write_64bit_hex(bh: &mut Bencher) {\r\n    let discard = io::sink();\r\n    bh.iter(|| {\r\n        write!(black_box(discard), \"{:x}\", black_box(0_u64)).unwrap();\r\n        write!(black_box(discard), \"{:x}\", black_box(10000_i64)).unwrap();\r\n        write!(black_box(discard), \"{:x}\", black_box(-10000_i64)).unwrap();\r\n    });\r\n}\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2226415599",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 143730,
        "pr_file": "library/coretests/benches/fmt.rs",
        "discussion_id": "2224954875",
        "commented_code": "@@ -162,3 +162,66 @@ fn write_u8_min(bh: &mut Bencher) {\n         black_box(format!(\"{}\", black_box(u8::MIN)));\n     });\n }\n+\n+#[bench]\n+fn write_12ints_bin(bh: &mut Bencher) {\n+    bh.iter(|| {\n+        black_box(format!(\"{:b}\", black_box(0_u8)));\n+        black_box(format!(\"{:b}\", black_box(100_i8)));\n+        black_box(format!(\"{:b}\", black_box(-100_i8)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u32)));\n+        black_box(format!(\"{:b}\", black_box(1000_i32)));\n+        black_box(format!(\"{:b}\", black_box(-1000_i32)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u64)));\n+        black_box(format!(\"{:b}\", black_box(10000_i64)));\n+        black_box(format!(\"{:b}\", black_box(-10000_i64)));\n+\n+        black_box(format!(\"{:b}\", black_box(0_u128)));\n+        black_box(format!(\"{:b}\", black_box(100000_i128)));\n+        black_box(format!(\"{:b}\", black_box(-100000_i128)));\n+    });\n+}",
        "comment_created_at": "2025-07-23T19:05:17+00:00",
        "comment_author": "tgross35",
        "comment_body": "I think there is some advantage to having a bit of a wider range to attempt to reflect something for cases where e.g. formatting slows down for values above a specific count. But it doesn't need to be as extensive as I suggested.\r\n\r\n> A sink might be better than buffering with String?\r\n\r\nI think the formatter might not actually get called with `Sink` https://github.com/rust-lang/rust/blob/4ff3fa01cbdd468851b1b859541ee1c648cde7de/library/std/src/io/util.rs#L400-L403. Writing to a `String` is a pretty common usecase so I think that is fine.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2223684059",
    "pr_number": 144308,
    "pr_file": "src/librustdoc/doctest.rs",
    "created_at": "2025-07-22T19:44:35+00:00",
    "commented_code": "no_run: scraped_test.no_run(&rustdoc_options),\n         merged_test_code: None,\n     };\n-    let res =\n+    let (_, res) =",
    "repo_full_name": "rust-lang/rust",
    "discussion_comments": [
      {
        "comment_id": "2223684059",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 144308,
        "pr_file": "src/librustdoc/doctest.rs",
        "discussion_id": "2223684059",
        "commented_code": "@@ -1071,7 +1120,7 @@ fn doctest_run_fn(\n         no_run: scraped_test.no_run(&rustdoc_options),\n         merged_test_code: None,\n     };\n-    let res =\n+    let (_, res) =",
        "comment_created_at": "2025-07-22T19:44:35+00:00",
        "comment_author": "lolbinarycat",
        "comment_body": "Is there a reason we're not also tracking this, so we can report `(time compiling standalone tests, time compiling merged tests)`?\r\n\r\nI believe doctests are run with some level of parallelism, so currently we would be reporting the total absolute wall clock time for the total compilation time, but for merged doctests, we're reporting the sum of the amount of time each thread spent compiling.  This inconsistency could over-report the impact of merged doctests.\r\n\r\nAlso, if parallelism is involved, then I think perhaps a more useful metric for minimizing compilation time would be how long the *longest* test took.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2220755998",
    "pr_number": 143511,
    "pr_file": "library/std/src/sys/thread_local/native/eager.rs",
    "created_at": "2025-07-22T01:36:48+00:00",
    "commented_code": "/// The `self` reference must remain valid until the TLS destructor is run.\n     #[inline]\n     pub unsafe fn get(&self) -> *const T {\n-        match self.state.get() {\n-            State::Alive => self.val.get(),\n-            State::Destroyed => ptr::null(),\n-            State::Initial => unsafe { self.initialize() },\n+        if let State::Alive = self.state.get() {\n+            self.val.get()\n+        } else {\n+            unsafe { self.get_or_init_slow() }\n         }\n     }\n \n     #[cold]\n-    unsafe fn initialize(&self) -> *const T {",
    "repo_full_name": "rust-lang/rust",
    "discussion_comments": [
      {
        "comment_id": "2220755998",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 143511,
        "pr_file": "library/std/src/sys/thread_local/native/eager.rs",
        "discussion_id": "2220755998",
        "commented_code": "@@ -30,16 +30,22 @@ impl<T> Storage<T> {\n     /// The `self` reference must remain valid until the TLS destructor is run.\n     #[inline]\n     pub unsafe fn get(&self) -> *const T {\n-        match self.state.get() {\n-            State::Alive => self.val.get(),\n-            State::Destroyed => ptr::null(),\n-            State::Initial => unsafe { self.initialize() },\n+        if let State::Alive = self.state.get() {\n+            self.val.get()\n+        } else {\n+            unsafe { self.get_or_init_slow() }\n         }\n     }\n \n     #[cold]\n-    unsafe fn initialize(&self) -> *const T {",
        "comment_created_at": "2025-07-22T01:36:48+00:00",
        "comment_author": "ibraheemdev",
        "comment_body": "Should this be marked as `#[inline(never)]`? I've noticed `destructors::register` calls in the hot-path before, for `const` thread-locals with destructors.",
        "pr_file_module": null
      },
      {
        "comment_id": "2221494138",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 143511,
        "pr_file": "library/std/src/sys/thread_local/native/eager.rs",
        "discussion_id": "2220755998",
        "commented_code": "@@ -30,16 +30,22 @@ impl<T> Storage<T> {\n     /// The `self` reference must remain valid until the TLS destructor is run.\n     #[inline]\n     pub unsafe fn get(&self) -> *const T {\n-        match self.state.get() {\n-            State::Alive => self.val.get(),\n-            State::Destroyed => ptr::null(),\n-            State::Initial => unsafe { self.initialize() },\n+        if let State::Alive = self.state.get() {\n+            self.val.get()\n+        } else {\n+            unsafe { self.get_or_init_slow() }\n         }\n     }\n \n     #[cold]\n-    unsafe fn initialize(&self) -> *const T {",
        "comment_created_at": "2025-07-22T07:30:54+00:00",
        "comment_author": "orlp",
        "comment_body": "I had that in an earlier PR, see https://github.com/rust-lang/rust/pull/143511#issuecomment-3041600308.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2202413857",
    "pr_number": 143636,
    "pr_file": "library/core/src/fmt/num.rs",
    "created_at": "2025-07-12T07:30:06+00:00",
    "commented_code": "/// use core::fmt::NumBuffer;\n             ///\n             #[doc = concat!(\"let n = 0\", stringify!($signed), \";\")]\n-            /// let mut buf = NumBuffer::new();\n+            #[doc = concat!(\"let mut buf = NumBuffer::<\", stringify!($signed), \">::new();\")]",
    "repo_full_name": "rust-lang/rust",
    "discussion_comments": [
      {
        "comment_id": "2202413857",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 143636,
        "pr_file": "library/core/src/fmt/num.rs",
        "discussion_id": "2202413857",
        "commented_code": "@@ -338,7 +338,7 @@ macro_rules! impl_Display {\n             /// use core::fmt::NumBuffer;\n             ///\n             #[doc = concat!(\"let n = 0\", stringify!($signed), \";\")]\n-            /// let mut buf = NumBuffer::new();\n+            #[doc = concat!(\"let mut buf = NumBuffer::<\", stringify!($signed), \">::new();\")]",
        "comment_created_at": "2025-07-12T07:30:06+00:00",
        "comment_author": "hanna-kruppe",
        "comment_body": "Needing to specify/repeat the type when creating the buffer seems like a non-trivial downside. I'm not sure if the added flexibility is worth it. Can you give a semi-realistic example of where you'd want the flexibility of formatting one of several integer types into the same buffer?",
        "pr_file_module": null
      },
      {
        "comment_id": "2217317505",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 143636,
        "pr_file": "library/core/src/fmt/num.rs",
        "discussion_id": "2202413857",
        "commented_code": "@@ -338,7 +338,7 @@ macro_rules! impl_Display {\n             /// use core::fmt::NumBuffer;\n             ///\n             #[doc = concat!(\"let n = 0\", stringify!($signed), \";\")]\n-            /// let mut buf = NumBuffer::new();\n+            #[doc = concat!(\"let mut buf = NumBuffer::<\", stringify!($signed), \">::new();\")]",
        "comment_created_at": "2025-07-19T13:21:49+00:00",
        "comment_author": "GuillaumeGomez",
        "comment_body": "If you want to have only one buffer across your program life to fit all your integers that have different sizes, it's quite convenient.",
        "pr_file_module": null
      },
      {
        "comment_id": "2217320192",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 143636,
        "pr_file": "library/core/src/fmt/num.rs",
        "discussion_id": "2202413857",
        "commented_code": "@@ -338,7 +338,7 @@ macro_rules! impl_Display {\n             /// use core::fmt::NumBuffer;\n             ///\n             #[doc = concat!(\"let n = 0\", stringify!($signed), \";\")]\n-            /// let mut buf = NumBuffer::new();\n+            #[doc = concat!(\"let mut buf = NumBuffer::<\", stringify!($signed), \">::new();\")]",
        "comment_created_at": "2025-07-19T13:32:28+00:00",
        "comment_author": "hanna-kruppe",
        "comment_body": "When would I want such a long-lived buffer? Every usage of `itoa` I've seen while researching for the ACP just creates a new temporary buffer on the spot whenever it needs to format an integer. I don't think I've even seen a single buffer used twice for the same integer type. Setting up a buffer doesn't have any cost that needs to be amortized, allocating some extra uninitialized space in your stack frame is as close to free as it gets. If anything, putting the buffer somewhere else has a higher risk that it's moved around, which generally implies copying the whole buffer!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "973599732",
    "pr_number": 101551,
    "pr_file": "library/alloc/src/boxed.rs",
    "created_at": "2022-09-17T15:47:08+00:00",
    "commented_code": "#[cfg(not(no_global_oom_handling))]\n #[stable(feature = \"box_slice_clone\", since = \"1.3.0\")]\n-impl Clone for Box<str> {\n+impl<A: Allocator + Clone> Clone for Box<str, A> {\n     fn clone(&self) -> Self {\n+        let alloc = Box::allocator(self).clone();\n         // this makes a copy of the data\n-        let buf: Box<[u8]> = self.as_bytes().into();\n+        let buf: Box<[u8], A> = self.as_bytes().to_vec_in(alloc).into_boxed_slice();",
    "repo_full_name": "rust-lang/rust",
    "discussion_comments": [
      {
        "comment_id": "973599732",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 101551,
        "pr_file": "library/alloc/src/boxed.rs",
        "discussion_id": "973599732",
        "commented_code": "@@ -1325,10 +1325,11 @@ impl<T: Clone, A: Allocator + Clone> Clone for Box<T, A> {\n \n #[cfg(not(no_global_oom_handling))]\n #[stable(feature = \"box_slice_clone\", since = \"1.3.0\")]\n-impl Clone for Box<str> {\n+impl<A: Allocator + Clone> Clone for Box<str, A> {\n     fn clone(&self) -> Self {\n+        let alloc = Box::allocator(self).clone();\n         // this makes a copy of the data\n-        let buf: Box<[u8]> = self.as_bytes().into();\n+        let buf: Box<[u8], A> = self.as_bytes().to_vec_in(alloc).into_boxed_slice();",
        "comment_created_at": "2022-09-17T15:47:08+00:00",
        "comment_author": "Mark-Simulacrum",
        "comment_body": "This is probably introducing extra checks that weren't here before since it uses into_boxed_slice which calls shrink_to_fit, whereas before we directly reused the buffer via the unsafe `into_box` I think. IMO we should keep that prior property, perhaps by allocating the Vec ourselves and copying bytes into it, then using into_box.",
        "pr_file_module": null
      },
      {
        "comment_id": "974859143",
        "repo_full_name": "rust-lang/rust",
        "pr_number": 101551,
        "pr_file": "library/alloc/src/boxed.rs",
        "discussion_id": "973599732",
        "commented_code": "@@ -1325,10 +1325,11 @@ impl<T: Clone, A: Allocator + Clone> Clone for Box<T, A> {\n \n #[cfg(not(no_global_oom_handling))]\n #[stable(feature = \"box_slice_clone\", since = \"1.3.0\")]\n-impl Clone for Box<str> {\n+impl<A: Allocator + Clone> Clone for Box<str, A> {\n     fn clone(&self) -> Self {\n+        let alloc = Box::allocator(self).clone();\n         // this makes a copy of the data\n-        let buf: Box<[u8]> = self.as_bytes().into();\n+        let buf: Box<[u8], A> = self.as_bytes().to_vec_in(alloc).into_boxed_slice();",
        "comment_created_at": "2022-09-20T03:47:36+00:00",
        "comment_author": "zachs18",
        "comment_body": "Okay, I have rewritten it to use `RawVec::with_capacity_in` and `into_box`. I also implemented `clone_from` to re-use the allocation in the case that `self` and `other` are the same length, like `Clone for Box<[T], A>` does.",
        "pr_file_module": null
      }
    ]
  }
]