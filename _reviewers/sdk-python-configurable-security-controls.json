[
  {
    "discussion_id": "2475095898",
    "pr_number": 1080,
    "pr_file": "src/strands/models/bedrock.py",
    "created_at": "2025-10-29T19:36:38+00:00",
    "commented_code": "input_assessment = guardrail_data.get(\"inputAssessment\", {})\n         output_assessments = guardrail_data.get(\"outputAssessments\", {})\n \n+        blocked_input, blocked_output = False, False\n+\n         # Check input assessments\n         if any(self._find_detected_and_blocked_policy(assessment) for assessment in input_assessment.values()):\n-            return True\n+            blocked_input = True\n \n         # Check output assessments\n         if any(self._find_detected_and_blocked_policy(assessment) for assessment in output_assessments.values()):\n-            return True\n+            blocked_output = True\n \n-        return False\n+        return blocked_input, blocked_output",
    "repo_full_name": "strands-agents/sdk-python",
    "discussion_comments": [
      {
        "comment_id": "2475095898",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 1080,
        "pr_file": "src/strands/models/bedrock.py",
        "discussion_id": "2475095898",
        "commented_code": "@@ -530,25 +530,27 @@ def _has_blocked_guardrail(self, guardrail_data: dict[str, Any]) -> bool:\n         input_assessment = guardrail_data.get(\"inputAssessment\", {})\n         output_assessments = guardrail_data.get(\"outputAssessments\", {})\n \n+        blocked_input, blocked_output = False, False\n+\n         # Check input assessments\n         if any(self._find_detected_and_blocked_policy(assessment) for assessment in input_assessment.values()):\n-            return True\n+            blocked_input = True\n \n         # Check output assessments\n         if any(self._find_detected_and_blocked_policy(assessment) for assessment in output_assessments.values()):\n-            return True\n+            blocked_output = True\n \n-        return False\n+        return blocked_input, blocked_output",
        "comment_created_at": "2025-10-29T19:36:38+00:00",
        "comment_author": "Unshure",
        "comment_body": "This redaction logic was intentional, sometimes you want to redact both the input and output if just an input guardrail triggers. The reason for this is sometimes people setup their guardrail to contain the very phrase that triggers the guardrail. For example, imagine a guardrail that tirggers on the word cactus\r\n\r\n```\r\nuser: cactus\r\nassistant: You cant say the word cactus!\r\n//can no longer continue since assistant responded with the trigger word\r\n\r\n```\r\n\r\n\r\nYou can configure if inputs or outputs are redacted with the `guardrail_redact_input` or `guardrail_redact_output` configs",
        "pr_file_module": null
      },
      {
        "comment_id": "2475300157",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 1080,
        "pr_file": "src/strands/models/bedrock.py",
        "discussion_id": "2475095898",
        "commented_code": "@@ -530,25 +530,27 @@ def _has_blocked_guardrail(self, guardrail_data: dict[str, Any]) -> bool:\n         input_assessment = guardrail_data.get(\"inputAssessment\", {})\n         output_assessments = guardrail_data.get(\"outputAssessments\", {})\n \n+        blocked_input, blocked_output = False, False\n+\n         # Check input assessments\n         if any(self._find_detected_and_blocked_policy(assessment) for assessment in input_assessment.values()):\n-            return True\n+            blocked_input = True\n \n         # Check output assessments\n         if any(self._find_detected_and_blocked_policy(assessment) for assessment in output_assessments.values()):\n-            return True\n+            blocked_output = True\n \n-        return False\n+        return blocked_input, blocked_output",
        "comment_created_at": "2025-10-29T20:26:46+00:00",
        "comment_author": "leotac",
        "comment_body": "In your example the input would be blocked too, as it contains the word cactus and that would trigger the input guardrail :-)\r\n\r\nBut I do see your point about the behavior being intentional. You might indeed want to be 100% sure you redact input that led the assistant to generate a forbidden output.\r\n(Although arguably one would expect the _input_ guardrails to detect that. For example, input guardrails always block an input such as \"how to make a bomb?\" even if the \"dangerous\" content is the assistant response).\r\n\r\nI'll modify the PR to only ensure the tool result is not broken.",
        "pr_file_module": null
      },
      {
        "comment_id": "2478933957",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 1080,
        "pr_file": "src/strands/models/bedrock.py",
        "discussion_id": "2475095898",
        "commented_code": "@@ -530,25 +530,27 @@ def _has_blocked_guardrail(self, guardrail_data: dict[str, Any]) -> bool:\n         input_assessment = guardrail_data.get(\"inputAssessment\", {})\n         output_assessments = guardrail_data.get(\"outputAssessments\", {})\n \n+        blocked_input, blocked_output = False, False\n+\n         # Check input assessments\n         if any(self._find_detected_and_blocked_policy(assessment) for assessment in input_assessment.values()):\n-            return True\n+            blocked_input = True\n \n         # Check output assessments\n         if any(self._find_detected_and_blocked_policy(assessment) for assessment in output_assessments.values()):\n-            return True\n+            blocked_output = True\n \n-        return False\n+        return blocked_input, blocked_output",
        "comment_created_at": "2025-10-30T17:24:21+00:00",
        "comment_author": "Unshure",
        "comment_body": "Gotcha, that makes a lot of sense. Lets separate that out to another issue to figure out the implementation. I see both cases as valid, so we should be able to configure between all of them (redact user/assistant just based on corresponding triggered guardrail, or be able to redact both based on either triggered guardrail).",
        "pr_file_module": null
      }
    ]
  }
]