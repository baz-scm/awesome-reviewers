[
  {
    "discussion_id": "2445860691",
    "pr_number": 900,
    "pr_file": "src/strands/multiagent/graph.py",
    "created_at": "2025-10-20T19:02:48+00:00",
    "commented_code": "self.reset_on_revisit = reset_on_revisit\n         self.state = GraphState()\n         self.tracer = get_tracer()\n+        self.session_manager = session_manager\n+        self.hooks = HookRegistry()\n+        if self.session_manager is not None:\n+            self.hooks.add_hook(self.session_manager)\n+        if hooks:\n+            for hook in hooks:",
    "repo_full_name": "strands-agents/sdk-python",
    "discussion_comments": [
      {
        "comment_id": "2445860691",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 900,
        "pr_file": "src/strands/multiagent/graph.py",
        "discussion_id": "2445860691",
        "commented_code": "@@ -384,6 +420,18 @@ def __init__(\n         self.reset_on_revisit = reset_on_revisit\n         self.state = GraphState()\n         self.tracer = get_tracer()\n+        self.session_manager = session_manager\n+        self.hooks = HookRegistry()\n+        if self.session_manager is not None:\n+            self.hooks.add_hook(self.session_manager)\n+        if hooks:\n+            for hook in hooks:",
        "comment_created_at": "2025-10-20T19:02:48+00:00",
        "comment_author": "dbschmigelski",
        "comment_body": "nit could simplify to some `for hook in (hooks or [])`",
        "pr_file_module": null
      },
      {
        "comment_id": "2445889665",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 900,
        "pr_file": "src/strands/multiagent/graph.py",
        "discussion_id": "2445860691",
        "commented_code": "@@ -384,6 +420,18 @@ def __init__(\n         self.reset_on_revisit = reset_on_revisit\n         self.state = GraphState()\n         self.tracer = get_tracer()\n+        self.session_manager = session_manager\n+        self.hooks = HookRegistry()\n+        if self.session_manager is not None:\n+            self.hooks.add_hook(self.session_manager)\n+        if hooks:\n+            for hook in hooks:",
        "comment_created_at": "2025-10-20T19:19:18+00:00",
        "comment_author": "JackYPCOnline",
        "comment_body": "keep consitency with `agent.py`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2407690508",
    "pr_number": 961,
    "pr_file": "src/strands/multiagent/graph.py",
    "created_at": "2025-10-06T17:50:53+00:00",
    "commented_code": ")\n         return False\n \n-    async def _execute_node(self, node: GraphNode, invocation_state: dict[str, Any]) -> None:\n-        \"\"\"Execute a single node with error handling and timeout protection.\"\"\"\n+    async def _execute_node(self, node: GraphNode, invocation_state: dict[str, Any]) -> AsyncIterator[dict[str, Any]]:\n+        \"\"\"Execute a single node.\"\"\"\n         # Reset the node's state if reset_on_revisit is enabled and it's being revisited\n         if self.reset_on_revisit and node in self.state.completed_nodes:\n             logger.debug(\"node_id=<%s> | resetting node state for revisit\", node.node_id)\n             node.reset_executor_state()\n-            # Remove from completed nodes since we're re-executing it\n             self.state.completed_nodes.remove(node)\n \n         node.execution_status = Status.EXECUTING\n         logger.debug(\"node_id=<%s> | executing node\", node.node_id)\n \n+        # Emit node start event\n+        start_event = MultiAgentNodeStartEvent(\n+            node_id=node.node_id, node_type=\"agent\" if isinstance(node.executor, Agent) else \"multiagent\"\n+        )\n+        yield start_event.as_dict()\n+\n         start_time = time.time()\n         try:\n             # Build node input from satisfied dependencies\n             node_input = self._build_node_input(node)\n \n-            # Execute with timeout protection (only if node_timeout is set)\n+            # Execute with timeout protection and stream events\n             try:\n-                # Execute based on node type and create unified NodeResult\n                 if isinstance(node.executor, MultiAgentBase):\n+                    # For nested multi-agent systems, stream their events and collect result\n+                    multi_agent_result = None\n                     if self.node_timeout is not None:",
    "repo_full_name": "strands-agents/sdk-python",
    "discussion_comments": [
      {
        "comment_id": "2407690508",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 961,
        "pr_file": "src/strands/multiagent/graph.py",
        "discussion_id": "2407690508",
        "commented_code": "@@ -530,38 +637,61 @@ def _is_node_ready_with_conditions(self, node: GraphNode, completed_batch: list[\n                     )\n         return False\n \n-    async def _execute_node(self, node: GraphNode, invocation_state: dict[str, Any]) -> None:\n-        \"\"\"Execute a single node with error handling and timeout protection.\"\"\"\n+    async def _execute_node(self, node: GraphNode, invocation_state: dict[str, Any]) -> AsyncIterator[dict[str, Any]]:\n+        \"\"\"Execute a single node.\"\"\"\n         # Reset the node's state if reset_on_revisit is enabled and it's being revisited\n         if self.reset_on_revisit and node in self.state.completed_nodes:\n             logger.debug(\"node_id=<%s> | resetting node state for revisit\", node.node_id)\n             node.reset_executor_state()\n-            # Remove from completed nodes since we're re-executing it\n             self.state.completed_nodes.remove(node)\n \n         node.execution_status = Status.EXECUTING\n         logger.debug(\"node_id=<%s> | executing node\", node.node_id)\n \n+        # Emit node start event\n+        start_event = MultiAgentNodeStartEvent(\n+            node_id=node.node_id, node_type=\"agent\" if isinstance(node.executor, Agent) else \"multiagent\"\n+        )\n+        yield start_event.as_dict()\n+\n         start_time = time.time()\n         try:\n             # Build node input from satisfied dependencies\n             node_input = self._build_node_input(node)\n \n-            # Execute with timeout protection (only if node_timeout is set)\n+            # Execute with timeout protection and stream events\n             try:\n-                # Execute based on node type and create unified NodeResult\n                 if isinstance(node.executor, MultiAgentBase):\n+                    # For nested multi-agent systems, stream their events and collect result\n+                    multi_agent_result = None\n                     if self.node_timeout is not None:",
        "comment_created_at": "2025-10-06T17:50:53+00:00",
        "comment_author": "zastrowm",
        "comment_body": "Rather than having two code paths, can `_stream_with_timeout` special_case no timeout to infinite?  \n\nIf not, perhaps a conditional like so:\n\n```\nevents = self._stream_with_timeout(...) if timeout else self.stream_async()\n```\n\nSo that the if blocks are unified",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2407695426",
    "pr_number": 961,
    "pr_file": "src/strands/multiagent/graph.py",
    "created_at": "2025-10-06T17:51:50+00:00",
    "commented_code": ")\n \n                 elif isinstance(node.executor, Agent):\n+                    # For agents, stream their events and collect result\n+                    agent_response = None\n                     if self.node_timeout is not None:",
    "repo_full_name": "strands-agents/sdk-python",
    "discussion_comments": [
      {
        "comment_id": "2407695426",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 961,
        "pr_file": "src/strands/multiagent/graph.py",
        "discussion_id": "2407695426",
        "commented_code": "@@ -570,15 +700,34 @@ async def _execute_node(self, node: GraphNode, invocation_state: dict[str, Any])\n                     )\n \n                 elif isinstance(node.executor, Agent):\n+                    # For agents, stream their events and collect result\n+                    agent_response = None\n                     if self.node_timeout is not None:",
        "comment_created_at": "2025-10-06T17:51:50+00:00",
        "comment_author": "zastrowm",
        "comment_body": "Same comments as above - these if blocks have the same content, so let's find a way to unify them",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2402818365",
    "pr_number": 964,
    "pr_file": "src/strands/tools/executors/_executor.py",
    "created_at": "2025-10-03T17:50:46+00:00",
    "commented_code": ")\n         )\n \n+        if before_event.cancel_tool:\n+            after_event = agent.hooks.invoke_callbacks(\n+                AfterToolCallEvent(\n+                    agent=agent,\n+                    tool_use=tool_use,\n+                    invocation_state=invocation_state,\n+                    result={",
    "repo_full_name": "strands-agents/sdk-python",
    "discussion_comments": [
      {
        "comment_id": "2402818365",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 964,
        "pr_file": "src/strands/tools/executors/_executor.py",
        "discussion_id": "2402818365",
        "commented_code": "@@ -81,6 +81,32 @@ async def _stream(\n             )\n         )\n \n+        if before_event.cancel_tool:\n+            after_event = agent.hooks.invoke_callbacks(\n+                AfterToolCallEvent(\n+                    agent=agent,\n+                    tool_use=tool_use,\n+                    invocation_state=invocation_state,\n+                    result={",
        "comment_created_at": "2025-10-03T17:50:46+00:00",
        "comment_author": "zastrowm",
        "comment_body": "nit - for readability, can extract this result construction from the AfterToolCallEvent; it's harder to read as-is IMHO",
        "pr_file_module": null
      },
      {
        "comment_id": "2402923900",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 964,
        "pr_file": "src/strands/tools/executors/_executor.py",
        "discussion_id": "2402818365",
        "commented_code": "@@ -81,6 +81,32 @@ async def _stream(\n             )\n         )\n \n+        if before_event.cancel_tool:\n+            after_event = agent.hooks.invoke_callbacks(\n+                AfterToolCallEvent(\n+                    agent=agent,\n+                    tool_use=tool_use,\n+                    invocation_state=invocation_state,\n+                    result={",
        "comment_created_at": "2025-10-03T18:24:13+00:00",
        "comment_author": "pgrayy",
        "comment_body": "Can do",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2392181241",
    "pr_number": 924,
    "pr_file": "src/strands/experimental/bidirectional_streaming/event_loop/bidirectional_event_loop.py",
    "created_at": "2025-09-30T16:24:13+00:00",
    "commented_code": "+\"\"\"Bidirectional session management for concurrent streaming conversations.\n+\n+Manages bidirectional communication sessions with concurrent processing of model events,\n+tool execution, and audio processing. Provides coordination between background tasks\n+while maintaining a simple interface for agent interaction.\n+\n+Features:\n+- Concurrent task management for model events and tool execution\n+- Interruption handling with audio buffer clearing\n+- Tool execution with cancellation support\n+- Session lifecycle management\n+\"\"\"\n+\n+import asyncio\n+import json\n+import logging\n+import traceback\n+import uuid\n+from typing import Any, Dict\n+\n+from strands.tools._validator import validate_and_prepare_tools\n+from strands.types.content import Message\n+from strands.types.tools import ToolResult, ToolUse\n+\n+from ..models.bidirectional_model import BidirectionalModelSession\n+from ..utils.debug import log_event, log_flow\n+\n+logger = logging.getLogger(__name__)\n+\n+# Session constants\n+TOOL_QUEUE_TIMEOUT = 0.5\n+SUPERVISION_INTERVAL = 0.1\n+\n+\n+class BidirectionalConnection:\n+    \"\"\"Session wrapper for bidirectional communication with concurrent task management.\n+    \n+    Coordinates background tasks for model event processing, tool execution, and audio\n+    handling while providing a simple interface for agent interactions.\n+    \"\"\"\n+    \n+    def __init__(self, model_session: BidirectionalModelSession, agent):\n+        \"\"\"Initialize session with model session and agent reference.\n+        \n+        Args:\n+            model_session: Provider-specific bidirectional model session.\n+            agent: BidirectionalAgent instance for tool registry access.\n+        \"\"\"\n+        self.model_session = model_session\n+        self.agent = agent\n+        self.active = True\n+        \n+        # Background processing coordination\n+        self.background_tasks = []\n+        self.tool_queue = asyncio.Queue()\n+        self.audio_output_queue = asyncio.Queue()\n+        \n+        # Task management for cleanup\n+        self.pending_tool_tasks: Dict[str, asyncio.Task] = {}\n+        \n+        # Interruption handling (model-agnostic)\n+        self.interrupted = False\n+\n+async def start_bidirectional_connection(agent) -> BidirectionalConnection:\n+    \"\"\"Initialize bidirectional session with concurrent background tasks.\n+    \n+    Creates a model-specific session and starts background tasks for processing\n+    model events, executing tools, and managing the session lifecycle.\n+    \n+    Args:\n+        agent: BidirectionalAgent instance.\n+        \n+    Returns:\n+        BidirectionalConnection: Active session with background tasks running.\n+    \"\"\"    \n+    log_flow(\"session_start\", \"initializing model session\")\n+    \n+    # Create provider-specific session\n+    model_session = await agent.model.create_bidirectional_connection(\n+        system_prompt=agent.system_prompt,\n+        tools=agent.tool_registry.get_all_tool_specs(),\n+        messages=agent.messages\n+    )\n+    \n+    # Create session wrapper for background processing\n+    session = BidirectionalConnection(model_session=model_session, agent=agent)\n+    \n+    # Start concurrent background processors IMMEDIATELY after session creation\n+    # This is critical - Nova Sonic needs response processing during initialization\n+    log_flow(\"background_tasks\", \"starting processors\")\n+    session.background_tasks = [\n+        asyncio.create_task(_process_model_events(session)),    # Handle model responses\n+        asyncio.create_task(_process_tool_execution(session))   # Execute tools concurrently\n+    ]\n+    \n+    # Start main coordination cycle\n+    session.main_cycle_task = asyncio.create_task(\n+        bidirectional_event_loop_cycle(session)\n+    )\n+    \n+    # Give background tasks a moment to start\n+    await asyncio.sleep(0.1)\n+    log_event(\"session_ready\", tasks=len(session.background_tasks))\n+    \n+    return session\n+\n+\n+async def stop_bidirectional_connection(session: BidirectionalConnection) -> None:\n+    \"\"\"End session and cleanup resources including background tasks.\n+    \n+    Args:\n+        session: BidirectionalConnection to cleanup.\n+    \"\"\"\n+    if not session.active:\n+        return\n+    \n+    log_flow(\"session_cleanup\", \"starting\")\n+    session.active = False\n+    \n+    # Cancel pending tool tasks\n+    for _, task in session.pending_tool_tasks.items():\n+        if not task.done():\n+            task.cancel()\n+    \n+    # Cancel background tasks\n+    for task in session.background_tasks:\n+        if not task.done():\n+            task.cancel()\n+    \n+    # Cancel main cycle task\n+    if hasattr(session, 'main_cycle_task') and not session.main_cycle_task.done():\n+        session.main_cycle_task.cancel()\n+    \n+    # Wait for tasks to complete\n+    all_tasks = session.background_tasks + list(session.pending_tool_tasks.values())\n+    if hasattr(session, 'main_cycle_task'):\n+        all_tasks.append(session.main_cycle_task)\n+    \n+    if all_tasks:\n+        await asyncio.gather(*all_tasks, return_exceptions=True)\n+    \n+    # Close model session\n+    await session.model_session.close()\n+    log_event(\"session_closed\")\n+\n+\n+async def bidirectional_event_loop_cycle(session: BidirectionalConnection) -> None:\n+    \"\"\"Main event loop coordinator that runs continuously during the session.\n+    \n+    Monitors background tasks, manages session state, and handles session lifecycle.\n+    Provides supervision for concurrent model event processing and tool execution.\n+    \n+    Args:\n+        session: BidirectionalConnection to coordinate.\n+    \"\"\"\n+    while session.active:\n+        try:\n+            # Check if background processors are still running\n+            if all(task.done() for task in session.background_tasks):\n+                log_event(\"session_end\", reason=\"all_processors_completed\")\n+                session.active = False\n+                break\n+            \n+            # Check for failed background tasks\n+            for i, task in enumerate(session.background_tasks):\n+                if task.done() and not task.cancelled():\n+                    exception = task.exception()\n+                    if exception:\n+                        log_event(\"session_error\", processor=i, error=str(exception))\n+                        session.active = False\n+                        raise exception\n+            \n+            # Brief pause before next supervision check\n+            await asyncio.sleep(SUPERVISION_INTERVAL)\n+            \n+        except asyncio.CancelledError:\n+            break\n+        except Exception as e:\n+            log_event(\"event_loop_error\", error=str(e))\n+            session.active = False\n+            raise\n+\n+\n+async def _handle_interruption(session: BidirectionalConnection) -> None:\n+    \"\"\"Handle interruption detection with task cancellation and audio buffer clearing.\n+    \n+    Cancels pending tool tasks and clears audio output queues to ensure responsive\n+    interruption handling during conversations.\n+    \n+    Args:\n+        session: BidirectionalConnection to handle interruption for.\n+    \"\"\"\n+    log_event(\"interruption_detected\")\n+    session.interrupted = True\n+    \n+    # \ud83d\udd25 CANCEL ALL PENDING TOOL TASKS (Nova Sonic pattern)\n+    cancelled_tools = 0\n+    for task_id, task in list(session.pending_tool_tasks.items()):\n+        if not task.done():\n+            task.cancel()\n+            cancelled_tools += 1\n+            log_event(\"tool_task_cancelled\", task_id=task_id)\n+    \n+    if cancelled_tools > 0:\n+        log_event(\"tool_tasks_cancelled\", count=cancelled_tools)\n+    \n+    # \ud83d\udd25 AGGRESSIVELY CLEAR AUDIO OUTPUT QUEUE (Nova Sonic pattern)\n+    cleared_count = 0\n+    while True:\n+        try:\n+            session.audio_output_queue.get_nowait()\n+            cleared_count += 1\n+        except asyncio.QueueEmpty:\n+            break\n+    \n+    # Also clear the agent's audio output queue if it exists\n+    if hasattr(session.agent, '_output_queue'):\n+        audio_cleared = 0\n+        # Create a temporary list to hold non-audio events\n+        temp_events = []\n+        try:\n+            while True:\n+                event = session.agent._output_queue.get_nowait()\n+                if event.get(\"audioOutput\"):\n+                    audio_cleared += 1\n+                else:\n+                    # Keep non-audio events\n+                    temp_events.append(event)\n+        except asyncio.QueueEmpty:\n+            pass\n+        \n+        # Put back non-audio events\n+        for event in temp_events:\n+            session.agent._output_queue.put_nowait(event)\n+        \n+        if audio_cleared > 0:\n+            log_event(\"agent_audio_queue_cleared\", count=audio_cleared)\n+    \n+    if cleared_count > 0:\n+        log_event(\"session_audio_queue_cleared\", count=cleared_count)\n+    \n+    # Brief sleep to allow audio system to settle (matches Nova Sonic timing)\n+    await asyncio.sleep(0.05)\n+    \n+    # Reset interruption flag after clearing (automatic recovery)\n+    session.interrupted = False\n+    log_event(\"interruption_handled\", tools_cancelled=cancelled_tools, audio_cleared=cleared_count)\n+\n+\n+async def _process_model_events(session: BidirectionalConnection) -> None:\n+    \"\"\"Process model events and convert them to Strands format.\n+    \n+    Background task that handles all model responses, converts provider-specific\n+    events to standardized formats, and manages interruption detection.\n+    \n+    Args:\n+        session: BidirectionalConnection containing model session.\n+    \"\"\"\n+    log_flow(\"model_events\", \"processor started\")\n+    try:\n+        async for provider_event in session.model_session.receive_events():\n+            if not session.active:\n+                break\n+            \n+            # Convert provider events to Strands format\n+            strands_event = _convert_to_strands_event(provider_event)\n+            \n+            # Handle interruption detection (multiple patterns)\n+            if strands_event.get(\"interruptionDetected\"):\n+                log_event(\"interruption_forwarded\")\n+                await _handle_interruption(session)\n+                # Forward interruption event to agent for application-level handling\n+                await session.agent._output_queue.put(strands_event)\n+                continue\n+            \n+            # Check for text-based interruption (Nova Sonic pattern)\n+            if strands_event.get(\"textOutput\"):\n+                text_content = strands_event[\"textOutput\"].get(\"content\", \"\")\n+                if '{ \"interrupted\" : true }' in text_content:\n+                    log_event(\"text_interruption_detected\")\n+                    await _handle_interruption(session)\n+                    # Still forward the text event\n+                    await session.agent._output_queue.put(strands_event)\n+                    continue\n+            \n+            # Queue tool requests for concurrent execution\n+            if strands_event.get(\"toolUse\"):\n+                log_event(\"tool_queued\", name=strands_event[\"toolUse\"].get(\"name\"))\n+                await session.tool_queue.put(strands_event[\"toolUse\"])\n+                continue\n+            \n+            # Send output events to Agent for receive() method\n+            if strands_event.get(\"audioOutput\") or strands_event.get(\"textOutput\"):\n+                await session.agent._output_queue.put(strands_event)\n+            \n+            # Update Agent conversation history using existing patterns\n+            if strands_event.get(\"messageStop\"):\n+                log_event(\"message_added_to_history\")\n+                session.agent.messages.append(strands_event[\"messageStop\"][\"message\"])\n+                \n+    except Exception as e:\n+        log_event(\"model_events_error\", error=str(e))\n+        traceback.print_exc()\n+    finally:\n+        log_flow(\"model_events\", \"processor stopped\")\n+\n+\n+async def _process_tool_execution(session: BidirectionalConnection) -> None:\n+    \"\"\"Execute tools concurrently with interruption support.\n+    \n+    Background task that manages tool execution without blocking model event\n+    processing or user interaction. Includes proper task cleanup and cancellation\n+    handling for interruptions.\n+    \n+    Args:\n+        session: BidirectionalConnection containing tool queue.\n+    \"\"\"\n+    log_flow(\"tool_execution\", \"processor started\")\n+    while session.active:\n+        try:\n+            tool_use = await asyncio.wait_for(session.tool_queue.get(), timeout=TOOL_QUEUE_TIMEOUT)\n+            log_event(\"tool_execution_started\", name=tool_use.get(\"name\"), id=tool_use.get(\"toolUseId\"))\n+            \n+            if not session.active:\n+                break\n+            \n+            task_id = str(uuid.uuid4())\n+            task = asyncio.create_task(_execute_tool_with_strands(session, tool_use))\n+            session.pending_tool_tasks[task_id] = task\n+            \n+            # \ud83d\udd25 ADD CLEANUP CALLBACK (Nova Sonic pattern)\n+            def cleanup_task(completed_task):\n+                try:\n+                    # Remove from pending tasks\n+                    if task_id in session.pending_tool_tasks:\n+                        del session.pending_tool_tasks[task_id]\n+                    \n+                    # Log completion status\n+                    if completed_task.cancelled():\n+                        log_event(\"tool_task_cleanup_cancelled\", task_id=task_id)\n+                    elif completed_task.exception():\n+                        log_event(\"tool_task_cleanup_error\", task_id=task_id, \n+                                error=str(completed_task.exception()))\n+                    else:\n+                        log_event(\"tool_task_cleanup_success\", task_id=task_id)\n+                except Exception as e:\n+                    log_event(\"tool_task_cleanup_failed\", task_id=task_id, error=str(e))\n+            \n+            task.add_done_callback(cleanup_task)\n+            \n+        except asyncio.TimeoutError:\n+            if not session.active:\n+                break\n+            # \ud83d\udd25 PERIODIC CLEANUP OF COMPLETED TASKS\n+            completed_tasks = [\n+                task_id for task_id, task in session.pending_tool_tasks.items() \n+                if task.done()\n+            ]\n+            for task_id in completed_tasks:\n+                if task_id in session.pending_tool_tasks:\n+                    del session.pending_tool_tasks[task_id]\n+            \n+            if completed_tasks:\n+                log_event(\"periodic_task_cleanup\", count=len(completed_tasks))\n+            \n+            continue\n+        except Exception as e:\n+            log_event(\"tool_execution_error\", error=str(e))\n+            if not session.active:\n+                break\n+    \n+    log_flow(\"tool_execution\", \"processor stopped\")\n+\n+\n+def _convert_to_strands_event(provider_event: Dict) -> Dict:\n+    \"\"\"Pass-through for events already normalized by provider sessions.\n+    \n+    Providers convert their raw events to standard format before reaching here.\n+    This just validates and passes through the normalized events.\n+    \n+    Args:\n+        provider_event: Already normalized event from provider session.\n+        \n+    Returns:\n+        Dict: The same event, validated and passed through.\n+    \"\"\"\n+    # Basic validation - ensure we have a dict\n+    if not isinstance(provider_event, dict):\n+        return {}\n+    \n+    # Pass through - conversion already done by provider session\n+    return provider_event\n+\n+\n+async def _execute_tool_with_strands(session: BidirectionalConnection, tool_use: Dict) -> None:\n+    \"\"\"Execute tool using Strands infrastructure with interruption support.\n+    \n+    Executes tools using the existing Strands tool system, handles interruption\n+    during execution, and sends results back to the model provider.\n+    \n+    Args:\n+        session: BidirectionalConnection for context.\n+        tool_use: Tool use event to execute.\n+    \"\"\"\n+    tool_name = tool_use.get('name')\n+    tool_id = tool_use.get('toolUseId')\n+    \n+    try:\n+        # \ud83d\udd25 CHECK FOR INTERRUPTION BEFORE STARTING (Nova Sonic pattern)\n+        if session.interrupted or not session.active:\n+            log_event(\"tool_execution_cancelled_before_start\", name=tool_name, id=tool_id)\n+            return\n+        \n+        # Create message structure for existing tool system\n+        tool_message: Message = {\n+            \"role\": \"assistant\", \n+            \"content\": [{\"toolUse\": tool_use}]\n+        }\n+        \n+        tool_uses: list[ToolUse] = []\n+        tool_results: list[ToolResult] = []\n+        invalid_tool_use_ids: list[str] = []\n+        \n+        # Validate using existing Strands validation\n+        validate_and_prepare_tools(tool_message, tool_uses, tool_results, invalid_tool_use_ids)\n+        \n+        # Filter valid tool uses\n+        valid_tool_uses = [tu for tu in tool_uses if tu.get(\"toolUseId\") not in invalid_tool_use_ids]\n+        \n+        if not valid_tool_uses:\n+            log_event(\"tool_validation_failed\", name=tool_name, id=tool_id)\n+            return\n+        \n+        # Execute tools directly (simpler approach for bidirectional)\n+        for tool_use in valid_tool_uses:\n+            # \ud83d\udd25 CHECK FOR INTERRUPTION DURING EXECUTION\n+            if session.interrupted or not session.active:\n+                log_event(\"tool_execution_cancelled_during\", name=tool_name, id=tool_id)\n+                return\n+            \n+            tool_func = session.agent.tool_registry.registry.get(tool_use[\"name\"])\n+            \n+            if tool_func:\n+                try:\n+                    actual_func = _extract_callable_function(tool_func)\n+                    \n+                    # \ud83d\udd25 WRAP TOOL EXECUTION IN CANCELLATION CHECK\n+                    # For async tools, we could wrap with asyncio.wait_for with cancellation\n+                    # For sync tools, we execute directly but check interruption after\n+                    result = actual_func(**tool_use.get(\"input\", {}))\n+                    \n+                    # \ud83d\udd25 CHECK FOR INTERRUPTION AFTER TOOL EXECUTION\n+                    if session.interrupted or not session.active:\n+                        log_event(\"tool_result_discarded_interruption\", name=tool_name, id=tool_id)\n+                        return\n+                    \n+                    tool_result = _create_success_result(tool_use[\"toolUseId\"], result)\n+                    tool_results.append(tool_result)\n+                    \n+                except asyncio.CancelledError:\n+                    # Tool was cancelled due to interruption\n+                    log_event(\"tool_execution_cancelled\", name=tool_name, id=tool_id)\n+                    return\n+                except Exception as e:\n+                    # \ud83d\udd25 CHECK FOR INTERRUPTION EVEN ON ERROR\n+                    if session.interrupted or not session.active:\n+                        log_event(\"tool_error_discarded_interruption\", name=tool_name, id=tool_id)\n+                        return\n+",
    "repo_full_name": "strands-agents/sdk-python",
    "discussion_comments": [
      {
        "comment_id": "2392181241",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 924,
        "pr_file": "src/strands/experimental/bidirectional_streaming/event_loop/bidirectional_event_loop.py",
        "discussion_id": "2392181241",
        "commented_code": "@@ -0,0 +1,535 @@\n+\"\"\"Bidirectional session management for concurrent streaming conversations.\n+\n+Manages bidirectional communication sessions with concurrent processing of model events,\n+tool execution, and audio processing. Provides coordination between background tasks\n+while maintaining a simple interface for agent interaction.\n+\n+Features:\n+- Concurrent task management for model events and tool execution\n+- Interruption handling with audio buffer clearing\n+- Tool execution with cancellation support\n+- Session lifecycle management\n+\"\"\"\n+\n+import asyncio\n+import json\n+import logging\n+import traceback\n+import uuid\n+from typing import Any, Dict\n+\n+from strands.tools._validator import validate_and_prepare_tools\n+from strands.types.content import Message\n+from strands.types.tools import ToolResult, ToolUse\n+\n+from ..models.bidirectional_model import BidirectionalModelSession\n+from ..utils.debug import log_event, log_flow\n+\n+logger = logging.getLogger(__name__)\n+\n+# Session constants\n+TOOL_QUEUE_TIMEOUT = 0.5\n+SUPERVISION_INTERVAL = 0.1\n+\n+\n+class BidirectionalConnection:\n+    \"\"\"Session wrapper for bidirectional communication with concurrent task management.\n+    \n+    Coordinates background tasks for model event processing, tool execution, and audio\n+    handling while providing a simple interface for agent interactions.\n+    \"\"\"\n+    \n+    def __init__(self, model_session: BidirectionalModelSession, agent):\n+        \"\"\"Initialize session with model session and agent reference.\n+        \n+        Args:\n+            model_session: Provider-specific bidirectional model session.\n+            agent: BidirectionalAgent instance for tool registry access.\n+        \"\"\"\n+        self.model_session = model_session\n+        self.agent = agent\n+        self.active = True\n+        \n+        # Background processing coordination\n+        self.background_tasks = []\n+        self.tool_queue = asyncio.Queue()\n+        self.audio_output_queue = asyncio.Queue()\n+        \n+        # Task management for cleanup\n+        self.pending_tool_tasks: Dict[str, asyncio.Task] = {}\n+        \n+        # Interruption handling (model-agnostic)\n+        self.interrupted = False\n+\n+async def start_bidirectional_connection(agent) -> BidirectionalConnection:\n+    \"\"\"Initialize bidirectional session with concurrent background tasks.\n+    \n+    Creates a model-specific session and starts background tasks for processing\n+    model events, executing tools, and managing the session lifecycle.\n+    \n+    Args:\n+        agent: BidirectionalAgent instance.\n+        \n+    Returns:\n+        BidirectionalConnection: Active session with background tasks running.\n+    \"\"\"    \n+    log_flow(\"session_start\", \"initializing model session\")\n+    \n+    # Create provider-specific session\n+    model_session = await agent.model.create_bidirectional_connection(\n+        system_prompt=agent.system_prompt,\n+        tools=agent.tool_registry.get_all_tool_specs(),\n+        messages=agent.messages\n+    )\n+    \n+    # Create session wrapper for background processing\n+    session = BidirectionalConnection(model_session=model_session, agent=agent)\n+    \n+    # Start concurrent background processors IMMEDIATELY after session creation\n+    # This is critical - Nova Sonic needs response processing during initialization\n+    log_flow(\"background_tasks\", \"starting processors\")\n+    session.background_tasks = [\n+        asyncio.create_task(_process_model_events(session)),    # Handle model responses\n+        asyncio.create_task(_process_tool_execution(session))   # Execute tools concurrently\n+    ]\n+    \n+    # Start main coordination cycle\n+    session.main_cycle_task = asyncio.create_task(\n+        bidirectional_event_loop_cycle(session)\n+    )\n+    \n+    # Give background tasks a moment to start\n+    await asyncio.sleep(0.1)\n+    log_event(\"session_ready\", tasks=len(session.background_tasks))\n+    \n+    return session\n+\n+\n+async def stop_bidirectional_connection(session: BidirectionalConnection) -> None:\n+    \"\"\"End session and cleanup resources including background tasks.\n+    \n+    Args:\n+        session: BidirectionalConnection to cleanup.\n+    \"\"\"\n+    if not session.active:\n+        return\n+    \n+    log_flow(\"session_cleanup\", \"starting\")\n+    session.active = False\n+    \n+    # Cancel pending tool tasks\n+    for _, task in session.pending_tool_tasks.items():\n+        if not task.done():\n+            task.cancel()\n+    \n+    # Cancel background tasks\n+    for task in session.background_tasks:\n+        if not task.done():\n+            task.cancel()\n+    \n+    # Cancel main cycle task\n+    if hasattr(session, 'main_cycle_task') and not session.main_cycle_task.done():\n+        session.main_cycle_task.cancel()\n+    \n+    # Wait for tasks to complete\n+    all_tasks = session.background_tasks + list(session.pending_tool_tasks.values())\n+    if hasattr(session, 'main_cycle_task'):\n+        all_tasks.append(session.main_cycle_task)\n+    \n+    if all_tasks:\n+        await asyncio.gather(*all_tasks, return_exceptions=True)\n+    \n+    # Close model session\n+    await session.model_session.close()\n+    log_event(\"session_closed\")\n+\n+\n+async def bidirectional_event_loop_cycle(session: BidirectionalConnection) -> None:\n+    \"\"\"Main event loop coordinator that runs continuously during the session.\n+    \n+    Monitors background tasks, manages session state, and handles session lifecycle.\n+    Provides supervision for concurrent model event processing and tool execution.\n+    \n+    Args:\n+        session: BidirectionalConnection to coordinate.\n+    \"\"\"\n+    while session.active:\n+        try:\n+            # Check if background processors are still running\n+            if all(task.done() for task in session.background_tasks):\n+                log_event(\"session_end\", reason=\"all_processors_completed\")\n+                session.active = False\n+                break\n+            \n+            # Check for failed background tasks\n+            for i, task in enumerate(session.background_tasks):\n+                if task.done() and not task.cancelled():\n+                    exception = task.exception()\n+                    if exception:\n+                        log_event(\"session_error\", processor=i, error=str(exception))\n+                        session.active = False\n+                        raise exception\n+            \n+            # Brief pause before next supervision check\n+            await asyncio.sleep(SUPERVISION_INTERVAL)\n+            \n+        except asyncio.CancelledError:\n+            break\n+        except Exception as e:\n+            log_event(\"event_loop_error\", error=str(e))\n+            session.active = False\n+            raise\n+\n+\n+async def _handle_interruption(session: BidirectionalConnection) -> None:\n+    \"\"\"Handle interruption detection with task cancellation and audio buffer clearing.\n+    \n+    Cancels pending tool tasks and clears audio output queues to ensure responsive\n+    interruption handling during conversations.\n+    \n+    Args:\n+        session: BidirectionalConnection to handle interruption for.\n+    \"\"\"\n+    log_event(\"interruption_detected\")\n+    session.interrupted = True\n+    \n+    # \ud83d\udd25 CANCEL ALL PENDING TOOL TASKS (Nova Sonic pattern)\n+    cancelled_tools = 0\n+    for task_id, task in list(session.pending_tool_tasks.items()):\n+        if not task.done():\n+            task.cancel()\n+            cancelled_tools += 1\n+            log_event(\"tool_task_cancelled\", task_id=task_id)\n+    \n+    if cancelled_tools > 0:\n+        log_event(\"tool_tasks_cancelled\", count=cancelled_tools)\n+    \n+    # \ud83d\udd25 AGGRESSIVELY CLEAR AUDIO OUTPUT QUEUE (Nova Sonic pattern)\n+    cleared_count = 0\n+    while True:\n+        try:\n+            session.audio_output_queue.get_nowait()\n+            cleared_count += 1\n+        except asyncio.QueueEmpty:\n+            break\n+    \n+    # Also clear the agent's audio output queue if it exists\n+    if hasattr(session.agent, '_output_queue'):\n+        audio_cleared = 0\n+        # Create a temporary list to hold non-audio events\n+        temp_events = []\n+        try:\n+            while True:\n+                event = session.agent._output_queue.get_nowait()\n+                if event.get(\"audioOutput\"):\n+                    audio_cleared += 1\n+                else:\n+                    # Keep non-audio events\n+                    temp_events.append(event)\n+        except asyncio.QueueEmpty:\n+            pass\n+        \n+        # Put back non-audio events\n+        for event in temp_events:\n+            session.agent._output_queue.put_nowait(event)\n+        \n+        if audio_cleared > 0:\n+            log_event(\"agent_audio_queue_cleared\", count=audio_cleared)\n+    \n+    if cleared_count > 0:\n+        log_event(\"session_audio_queue_cleared\", count=cleared_count)\n+    \n+    # Brief sleep to allow audio system to settle (matches Nova Sonic timing)\n+    await asyncio.sleep(0.05)\n+    \n+    # Reset interruption flag after clearing (automatic recovery)\n+    session.interrupted = False\n+    log_event(\"interruption_handled\", tools_cancelled=cancelled_tools, audio_cleared=cleared_count)\n+\n+\n+async def _process_model_events(session: BidirectionalConnection) -> None:\n+    \"\"\"Process model events and convert them to Strands format.\n+    \n+    Background task that handles all model responses, converts provider-specific\n+    events to standardized formats, and manages interruption detection.\n+    \n+    Args:\n+        session: BidirectionalConnection containing model session.\n+    \"\"\"\n+    log_flow(\"model_events\", \"processor started\")\n+    try:\n+        async for provider_event in session.model_session.receive_events():\n+            if not session.active:\n+                break\n+            \n+            # Convert provider events to Strands format\n+            strands_event = _convert_to_strands_event(provider_event)\n+            \n+            # Handle interruption detection (multiple patterns)\n+            if strands_event.get(\"interruptionDetected\"):\n+                log_event(\"interruption_forwarded\")\n+                await _handle_interruption(session)\n+                # Forward interruption event to agent for application-level handling\n+                await session.agent._output_queue.put(strands_event)\n+                continue\n+            \n+            # Check for text-based interruption (Nova Sonic pattern)\n+            if strands_event.get(\"textOutput\"):\n+                text_content = strands_event[\"textOutput\"].get(\"content\", \"\")\n+                if '{ \"interrupted\" : true }' in text_content:\n+                    log_event(\"text_interruption_detected\")\n+                    await _handle_interruption(session)\n+                    # Still forward the text event\n+                    await session.agent._output_queue.put(strands_event)\n+                    continue\n+            \n+            # Queue tool requests for concurrent execution\n+            if strands_event.get(\"toolUse\"):\n+                log_event(\"tool_queued\", name=strands_event[\"toolUse\"].get(\"name\"))\n+                await session.tool_queue.put(strands_event[\"toolUse\"])\n+                continue\n+            \n+            # Send output events to Agent for receive() method\n+            if strands_event.get(\"audioOutput\") or strands_event.get(\"textOutput\"):\n+                await session.agent._output_queue.put(strands_event)\n+            \n+            # Update Agent conversation history using existing patterns\n+            if strands_event.get(\"messageStop\"):\n+                log_event(\"message_added_to_history\")\n+                session.agent.messages.append(strands_event[\"messageStop\"][\"message\"])\n+                \n+    except Exception as e:\n+        log_event(\"model_events_error\", error=str(e))\n+        traceback.print_exc()\n+    finally:\n+        log_flow(\"model_events\", \"processor stopped\")\n+\n+\n+async def _process_tool_execution(session: BidirectionalConnection) -> None:\n+    \"\"\"Execute tools concurrently with interruption support.\n+    \n+    Background task that manages tool execution without blocking model event\n+    processing or user interaction. Includes proper task cleanup and cancellation\n+    handling for interruptions.\n+    \n+    Args:\n+        session: BidirectionalConnection containing tool queue.\n+    \"\"\"\n+    log_flow(\"tool_execution\", \"processor started\")\n+    while session.active:\n+        try:\n+            tool_use = await asyncio.wait_for(session.tool_queue.get(), timeout=TOOL_QUEUE_TIMEOUT)\n+            log_event(\"tool_execution_started\", name=tool_use.get(\"name\"), id=tool_use.get(\"toolUseId\"))\n+            \n+            if not session.active:\n+                break\n+            \n+            task_id = str(uuid.uuid4())\n+            task = asyncio.create_task(_execute_tool_with_strands(session, tool_use))\n+            session.pending_tool_tasks[task_id] = task\n+            \n+            # \ud83d\udd25 ADD CLEANUP CALLBACK (Nova Sonic pattern)\n+            def cleanup_task(completed_task):\n+                try:\n+                    # Remove from pending tasks\n+                    if task_id in session.pending_tool_tasks:\n+                        del session.pending_tool_tasks[task_id]\n+                    \n+                    # Log completion status\n+                    if completed_task.cancelled():\n+                        log_event(\"tool_task_cleanup_cancelled\", task_id=task_id)\n+                    elif completed_task.exception():\n+                        log_event(\"tool_task_cleanup_error\", task_id=task_id, \n+                                error=str(completed_task.exception()))\n+                    else:\n+                        log_event(\"tool_task_cleanup_success\", task_id=task_id)\n+                except Exception as e:\n+                    log_event(\"tool_task_cleanup_failed\", task_id=task_id, error=str(e))\n+            \n+            task.add_done_callback(cleanup_task)\n+            \n+        except asyncio.TimeoutError:\n+            if not session.active:\n+                break\n+            # \ud83d\udd25 PERIODIC CLEANUP OF COMPLETED TASKS\n+            completed_tasks = [\n+                task_id for task_id, task in session.pending_tool_tasks.items() \n+                if task.done()\n+            ]\n+            for task_id in completed_tasks:\n+                if task_id in session.pending_tool_tasks:\n+                    del session.pending_tool_tasks[task_id]\n+            \n+            if completed_tasks:\n+                log_event(\"periodic_task_cleanup\", count=len(completed_tasks))\n+            \n+            continue\n+        except Exception as e:\n+            log_event(\"tool_execution_error\", error=str(e))\n+            if not session.active:\n+                break\n+    \n+    log_flow(\"tool_execution\", \"processor stopped\")\n+\n+\n+def _convert_to_strands_event(provider_event: Dict) -> Dict:\n+    \"\"\"Pass-through for events already normalized by provider sessions.\n+    \n+    Providers convert their raw events to standard format before reaching here.\n+    This just validates and passes through the normalized events.\n+    \n+    Args:\n+        provider_event: Already normalized event from provider session.\n+        \n+    Returns:\n+        Dict: The same event, validated and passed through.\n+    \"\"\"\n+    # Basic validation - ensure we have a dict\n+    if not isinstance(provider_event, dict):\n+        return {}\n+    \n+    # Pass through - conversion already done by provider session\n+    return provider_event\n+\n+\n+async def _execute_tool_with_strands(session: BidirectionalConnection, tool_use: Dict) -> None:\n+    \"\"\"Execute tool using Strands infrastructure with interruption support.\n+    \n+    Executes tools using the existing Strands tool system, handles interruption\n+    during execution, and sends results back to the model provider.\n+    \n+    Args:\n+        session: BidirectionalConnection for context.\n+        tool_use: Tool use event to execute.\n+    \"\"\"\n+    tool_name = tool_use.get('name')\n+    tool_id = tool_use.get('toolUseId')\n+    \n+    try:\n+        # \ud83d\udd25 CHECK FOR INTERRUPTION BEFORE STARTING (Nova Sonic pattern)\n+        if session.interrupted or not session.active:\n+            log_event(\"tool_execution_cancelled_before_start\", name=tool_name, id=tool_id)\n+            return\n+        \n+        # Create message structure for existing tool system\n+        tool_message: Message = {\n+            \"role\": \"assistant\", \n+            \"content\": [{\"toolUse\": tool_use}]\n+        }\n+        \n+        tool_uses: list[ToolUse] = []\n+        tool_results: list[ToolResult] = []\n+        invalid_tool_use_ids: list[str] = []\n+        \n+        # Validate using existing Strands validation\n+        validate_and_prepare_tools(tool_message, tool_uses, tool_results, invalid_tool_use_ids)\n+        \n+        # Filter valid tool uses\n+        valid_tool_uses = [tu for tu in tool_uses if tu.get(\"toolUseId\") not in invalid_tool_use_ids]\n+        \n+        if not valid_tool_uses:\n+            log_event(\"tool_validation_failed\", name=tool_name, id=tool_id)\n+            return\n+        \n+        # Execute tools directly (simpler approach for bidirectional)\n+        for tool_use in valid_tool_uses:\n+            # \ud83d\udd25 CHECK FOR INTERRUPTION DURING EXECUTION\n+            if session.interrupted or not session.active:\n+                log_event(\"tool_execution_cancelled_during\", name=tool_name, id=tool_id)\n+                return\n+            \n+            tool_func = session.agent.tool_registry.registry.get(tool_use[\"name\"])\n+            \n+            if tool_func:\n+                try:\n+                    actual_func = _extract_callable_function(tool_func)\n+                    \n+                    # \ud83d\udd25 WRAP TOOL EXECUTION IN CANCELLATION CHECK\n+                    # For async tools, we could wrap with asyncio.wait_for with cancellation\n+                    # For sync tools, we execute directly but check interruption after\n+                    result = actual_func(**tool_use.get(\"input\", {}))\n+                    \n+                    # \ud83d\udd25 CHECK FOR INTERRUPTION AFTER TOOL EXECUTION\n+                    if session.interrupted or not session.active:\n+                        log_event(\"tool_result_discarded_interruption\", name=tool_name, id=tool_id)\n+                        return\n+                    \n+                    tool_result = _create_success_result(tool_use[\"toolUseId\"], result)\n+                    tool_results.append(tool_result)\n+                    \n+                except asyncio.CancelledError:\n+                    # Tool was cancelled due to interruption\n+                    log_event(\"tool_execution_cancelled\", name=tool_name, id=tool_id)\n+                    return\n+                except Exception as e:\n+                    # \ud83d\udd25 CHECK FOR INTERRUPTION EVEN ON ERROR\n+                    if session.interrupted or not session.active:\n+                        log_event(\"tool_error_discarded_interruption\", name=tool_name, id=tool_id)\n+                        return\n+                    ",
        "comment_created_at": "2025-09-30T16:24:13+00:00",
        "comment_author": "Unshure",
        "comment_body": "We do this check multiple times in this method. Any reason why we need to check this so often?",
        "pr_file_module": null
      },
      {
        "comment_id": "2399741253",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 924,
        "pr_file": "src/strands/experimental/bidirectional_streaming/event_loop/bidirectional_event_loop.py",
        "discussion_id": "2392181241",
        "commented_code": "@@ -0,0 +1,535 @@\n+\"\"\"Bidirectional session management for concurrent streaming conversations.\n+\n+Manages bidirectional communication sessions with concurrent processing of model events,\n+tool execution, and audio processing. Provides coordination between background tasks\n+while maintaining a simple interface for agent interaction.\n+\n+Features:\n+- Concurrent task management for model events and tool execution\n+- Interruption handling with audio buffer clearing\n+- Tool execution with cancellation support\n+- Session lifecycle management\n+\"\"\"\n+\n+import asyncio\n+import json\n+import logging\n+import traceback\n+import uuid\n+from typing import Any, Dict\n+\n+from strands.tools._validator import validate_and_prepare_tools\n+from strands.types.content import Message\n+from strands.types.tools import ToolResult, ToolUse\n+\n+from ..models.bidirectional_model import BidirectionalModelSession\n+from ..utils.debug import log_event, log_flow\n+\n+logger = logging.getLogger(__name__)\n+\n+# Session constants\n+TOOL_QUEUE_TIMEOUT = 0.5\n+SUPERVISION_INTERVAL = 0.1\n+\n+\n+class BidirectionalConnection:\n+    \"\"\"Session wrapper for bidirectional communication with concurrent task management.\n+    \n+    Coordinates background tasks for model event processing, tool execution, and audio\n+    handling while providing a simple interface for agent interactions.\n+    \"\"\"\n+    \n+    def __init__(self, model_session: BidirectionalModelSession, agent):\n+        \"\"\"Initialize session with model session and agent reference.\n+        \n+        Args:\n+            model_session: Provider-specific bidirectional model session.\n+            agent: BidirectionalAgent instance for tool registry access.\n+        \"\"\"\n+        self.model_session = model_session\n+        self.agent = agent\n+        self.active = True\n+        \n+        # Background processing coordination\n+        self.background_tasks = []\n+        self.tool_queue = asyncio.Queue()\n+        self.audio_output_queue = asyncio.Queue()\n+        \n+        # Task management for cleanup\n+        self.pending_tool_tasks: Dict[str, asyncio.Task] = {}\n+        \n+        # Interruption handling (model-agnostic)\n+        self.interrupted = False\n+\n+async def start_bidirectional_connection(agent) -> BidirectionalConnection:\n+    \"\"\"Initialize bidirectional session with concurrent background tasks.\n+    \n+    Creates a model-specific session and starts background tasks for processing\n+    model events, executing tools, and managing the session lifecycle.\n+    \n+    Args:\n+        agent: BidirectionalAgent instance.\n+        \n+    Returns:\n+        BidirectionalConnection: Active session with background tasks running.\n+    \"\"\"    \n+    log_flow(\"session_start\", \"initializing model session\")\n+    \n+    # Create provider-specific session\n+    model_session = await agent.model.create_bidirectional_connection(\n+        system_prompt=agent.system_prompt,\n+        tools=agent.tool_registry.get_all_tool_specs(),\n+        messages=agent.messages\n+    )\n+    \n+    # Create session wrapper for background processing\n+    session = BidirectionalConnection(model_session=model_session, agent=agent)\n+    \n+    # Start concurrent background processors IMMEDIATELY after session creation\n+    # This is critical - Nova Sonic needs response processing during initialization\n+    log_flow(\"background_tasks\", \"starting processors\")\n+    session.background_tasks = [\n+        asyncio.create_task(_process_model_events(session)),    # Handle model responses\n+        asyncio.create_task(_process_tool_execution(session))   # Execute tools concurrently\n+    ]\n+    \n+    # Start main coordination cycle\n+    session.main_cycle_task = asyncio.create_task(\n+        bidirectional_event_loop_cycle(session)\n+    )\n+    \n+    # Give background tasks a moment to start\n+    await asyncio.sleep(0.1)\n+    log_event(\"session_ready\", tasks=len(session.background_tasks))\n+    \n+    return session\n+\n+\n+async def stop_bidirectional_connection(session: BidirectionalConnection) -> None:\n+    \"\"\"End session and cleanup resources including background tasks.\n+    \n+    Args:\n+        session: BidirectionalConnection to cleanup.\n+    \"\"\"\n+    if not session.active:\n+        return\n+    \n+    log_flow(\"session_cleanup\", \"starting\")\n+    session.active = False\n+    \n+    # Cancel pending tool tasks\n+    for _, task in session.pending_tool_tasks.items():\n+        if not task.done():\n+            task.cancel()\n+    \n+    # Cancel background tasks\n+    for task in session.background_tasks:\n+        if not task.done():\n+            task.cancel()\n+    \n+    # Cancel main cycle task\n+    if hasattr(session, 'main_cycle_task') and not session.main_cycle_task.done():\n+        session.main_cycle_task.cancel()\n+    \n+    # Wait for tasks to complete\n+    all_tasks = session.background_tasks + list(session.pending_tool_tasks.values())\n+    if hasattr(session, 'main_cycle_task'):\n+        all_tasks.append(session.main_cycle_task)\n+    \n+    if all_tasks:\n+        await asyncio.gather(*all_tasks, return_exceptions=True)\n+    \n+    # Close model session\n+    await session.model_session.close()\n+    log_event(\"session_closed\")\n+\n+\n+async def bidirectional_event_loop_cycle(session: BidirectionalConnection) -> None:\n+    \"\"\"Main event loop coordinator that runs continuously during the session.\n+    \n+    Monitors background tasks, manages session state, and handles session lifecycle.\n+    Provides supervision for concurrent model event processing and tool execution.\n+    \n+    Args:\n+        session: BidirectionalConnection to coordinate.\n+    \"\"\"\n+    while session.active:\n+        try:\n+            # Check if background processors are still running\n+            if all(task.done() for task in session.background_tasks):\n+                log_event(\"session_end\", reason=\"all_processors_completed\")\n+                session.active = False\n+                break\n+            \n+            # Check for failed background tasks\n+            for i, task in enumerate(session.background_tasks):\n+                if task.done() and not task.cancelled():\n+                    exception = task.exception()\n+                    if exception:\n+                        log_event(\"session_error\", processor=i, error=str(exception))\n+                        session.active = False\n+                        raise exception\n+            \n+            # Brief pause before next supervision check\n+            await asyncio.sleep(SUPERVISION_INTERVAL)\n+            \n+        except asyncio.CancelledError:\n+            break\n+        except Exception as e:\n+            log_event(\"event_loop_error\", error=str(e))\n+            session.active = False\n+            raise\n+\n+\n+async def _handle_interruption(session: BidirectionalConnection) -> None:\n+    \"\"\"Handle interruption detection with task cancellation and audio buffer clearing.\n+    \n+    Cancels pending tool tasks and clears audio output queues to ensure responsive\n+    interruption handling during conversations.\n+    \n+    Args:\n+        session: BidirectionalConnection to handle interruption for.\n+    \"\"\"\n+    log_event(\"interruption_detected\")\n+    session.interrupted = True\n+    \n+    # \ud83d\udd25 CANCEL ALL PENDING TOOL TASKS (Nova Sonic pattern)\n+    cancelled_tools = 0\n+    for task_id, task in list(session.pending_tool_tasks.items()):\n+        if not task.done():\n+            task.cancel()\n+            cancelled_tools += 1\n+            log_event(\"tool_task_cancelled\", task_id=task_id)\n+    \n+    if cancelled_tools > 0:\n+        log_event(\"tool_tasks_cancelled\", count=cancelled_tools)\n+    \n+    # \ud83d\udd25 AGGRESSIVELY CLEAR AUDIO OUTPUT QUEUE (Nova Sonic pattern)\n+    cleared_count = 0\n+    while True:\n+        try:\n+            session.audio_output_queue.get_nowait()\n+            cleared_count += 1\n+        except asyncio.QueueEmpty:\n+            break\n+    \n+    # Also clear the agent's audio output queue if it exists\n+    if hasattr(session.agent, '_output_queue'):\n+        audio_cleared = 0\n+        # Create a temporary list to hold non-audio events\n+        temp_events = []\n+        try:\n+            while True:\n+                event = session.agent._output_queue.get_nowait()\n+                if event.get(\"audioOutput\"):\n+                    audio_cleared += 1\n+                else:\n+                    # Keep non-audio events\n+                    temp_events.append(event)\n+        except asyncio.QueueEmpty:\n+            pass\n+        \n+        # Put back non-audio events\n+        for event in temp_events:\n+            session.agent._output_queue.put_nowait(event)\n+        \n+        if audio_cleared > 0:\n+            log_event(\"agent_audio_queue_cleared\", count=audio_cleared)\n+    \n+    if cleared_count > 0:\n+        log_event(\"session_audio_queue_cleared\", count=cleared_count)\n+    \n+    # Brief sleep to allow audio system to settle (matches Nova Sonic timing)\n+    await asyncio.sleep(0.05)\n+    \n+    # Reset interruption flag after clearing (automatic recovery)\n+    session.interrupted = False\n+    log_event(\"interruption_handled\", tools_cancelled=cancelled_tools, audio_cleared=cleared_count)\n+\n+\n+async def _process_model_events(session: BidirectionalConnection) -> None:\n+    \"\"\"Process model events and convert them to Strands format.\n+    \n+    Background task that handles all model responses, converts provider-specific\n+    events to standardized formats, and manages interruption detection.\n+    \n+    Args:\n+        session: BidirectionalConnection containing model session.\n+    \"\"\"\n+    log_flow(\"model_events\", \"processor started\")\n+    try:\n+        async for provider_event in session.model_session.receive_events():\n+            if not session.active:\n+                break\n+            \n+            # Convert provider events to Strands format\n+            strands_event = _convert_to_strands_event(provider_event)\n+            \n+            # Handle interruption detection (multiple patterns)\n+            if strands_event.get(\"interruptionDetected\"):\n+                log_event(\"interruption_forwarded\")\n+                await _handle_interruption(session)\n+                # Forward interruption event to agent for application-level handling\n+                await session.agent._output_queue.put(strands_event)\n+                continue\n+            \n+            # Check for text-based interruption (Nova Sonic pattern)\n+            if strands_event.get(\"textOutput\"):\n+                text_content = strands_event[\"textOutput\"].get(\"content\", \"\")\n+                if '{ \"interrupted\" : true }' in text_content:\n+                    log_event(\"text_interruption_detected\")\n+                    await _handle_interruption(session)\n+                    # Still forward the text event\n+                    await session.agent._output_queue.put(strands_event)\n+                    continue\n+            \n+            # Queue tool requests for concurrent execution\n+            if strands_event.get(\"toolUse\"):\n+                log_event(\"tool_queued\", name=strands_event[\"toolUse\"].get(\"name\"))\n+                await session.tool_queue.put(strands_event[\"toolUse\"])\n+                continue\n+            \n+            # Send output events to Agent for receive() method\n+            if strands_event.get(\"audioOutput\") or strands_event.get(\"textOutput\"):\n+                await session.agent._output_queue.put(strands_event)\n+            \n+            # Update Agent conversation history using existing patterns\n+            if strands_event.get(\"messageStop\"):\n+                log_event(\"message_added_to_history\")\n+                session.agent.messages.append(strands_event[\"messageStop\"][\"message\"])\n+                \n+    except Exception as e:\n+        log_event(\"model_events_error\", error=str(e))\n+        traceback.print_exc()\n+    finally:\n+        log_flow(\"model_events\", \"processor stopped\")\n+\n+\n+async def _process_tool_execution(session: BidirectionalConnection) -> None:\n+    \"\"\"Execute tools concurrently with interruption support.\n+    \n+    Background task that manages tool execution without blocking model event\n+    processing or user interaction. Includes proper task cleanup and cancellation\n+    handling for interruptions.\n+    \n+    Args:\n+        session: BidirectionalConnection containing tool queue.\n+    \"\"\"\n+    log_flow(\"tool_execution\", \"processor started\")\n+    while session.active:\n+        try:\n+            tool_use = await asyncio.wait_for(session.tool_queue.get(), timeout=TOOL_QUEUE_TIMEOUT)\n+            log_event(\"tool_execution_started\", name=tool_use.get(\"name\"), id=tool_use.get(\"toolUseId\"))\n+            \n+            if not session.active:\n+                break\n+            \n+            task_id = str(uuid.uuid4())\n+            task = asyncio.create_task(_execute_tool_with_strands(session, tool_use))\n+            session.pending_tool_tasks[task_id] = task\n+            \n+            # \ud83d\udd25 ADD CLEANUP CALLBACK (Nova Sonic pattern)\n+            def cleanup_task(completed_task):\n+                try:\n+                    # Remove from pending tasks\n+                    if task_id in session.pending_tool_tasks:\n+                        del session.pending_tool_tasks[task_id]\n+                    \n+                    # Log completion status\n+                    if completed_task.cancelled():\n+                        log_event(\"tool_task_cleanup_cancelled\", task_id=task_id)\n+                    elif completed_task.exception():\n+                        log_event(\"tool_task_cleanup_error\", task_id=task_id, \n+                                error=str(completed_task.exception()))\n+                    else:\n+                        log_event(\"tool_task_cleanup_success\", task_id=task_id)\n+                except Exception as e:\n+                    log_event(\"tool_task_cleanup_failed\", task_id=task_id, error=str(e))\n+            \n+            task.add_done_callback(cleanup_task)\n+            \n+        except asyncio.TimeoutError:\n+            if not session.active:\n+                break\n+            # \ud83d\udd25 PERIODIC CLEANUP OF COMPLETED TASKS\n+            completed_tasks = [\n+                task_id for task_id, task in session.pending_tool_tasks.items() \n+                if task.done()\n+            ]\n+            for task_id in completed_tasks:\n+                if task_id in session.pending_tool_tasks:\n+                    del session.pending_tool_tasks[task_id]\n+            \n+            if completed_tasks:\n+                log_event(\"periodic_task_cleanup\", count=len(completed_tasks))\n+            \n+            continue\n+        except Exception as e:\n+            log_event(\"tool_execution_error\", error=str(e))\n+            if not session.active:\n+                break\n+    \n+    log_flow(\"tool_execution\", \"processor stopped\")\n+\n+\n+def _convert_to_strands_event(provider_event: Dict) -> Dict:\n+    \"\"\"Pass-through for events already normalized by provider sessions.\n+    \n+    Providers convert their raw events to standard format before reaching here.\n+    This just validates and passes through the normalized events.\n+    \n+    Args:\n+        provider_event: Already normalized event from provider session.\n+        \n+    Returns:\n+        Dict: The same event, validated and passed through.\n+    \"\"\"\n+    # Basic validation - ensure we have a dict\n+    if not isinstance(provider_event, dict):\n+        return {}\n+    \n+    # Pass through - conversion already done by provider session\n+    return provider_event\n+\n+\n+async def _execute_tool_with_strands(session: BidirectionalConnection, tool_use: Dict) -> None:\n+    \"\"\"Execute tool using Strands infrastructure with interruption support.\n+    \n+    Executes tools using the existing Strands tool system, handles interruption\n+    during execution, and sends results back to the model provider.\n+    \n+    Args:\n+        session: BidirectionalConnection for context.\n+        tool_use: Tool use event to execute.\n+    \"\"\"\n+    tool_name = tool_use.get('name')\n+    tool_id = tool_use.get('toolUseId')\n+    \n+    try:\n+        # \ud83d\udd25 CHECK FOR INTERRUPTION BEFORE STARTING (Nova Sonic pattern)\n+        if session.interrupted or not session.active:\n+            log_event(\"tool_execution_cancelled_before_start\", name=tool_name, id=tool_id)\n+            return\n+        \n+        # Create message structure for existing tool system\n+        tool_message: Message = {\n+            \"role\": \"assistant\", \n+            \"content\": [{\"toolUse\": tool_use}]\n+        }\n+        \n+        tool_uses: list[ToolUse] = []\n+        tool_results: list[ToolResult] = []\n+        invalid_tool_use_ids: list[str] = []\n+        \n+        # Validate using existing Strands validation\n+        validate_and_prepare_tools(tool_message, tool_uses, tool_results, invalid_tool_use_ids)\n+        \n+        # Filter valid tool uses\n+        valid_tool_uses = [tu for tu in tool_uses if tu.get(\"toolUseId\") not in invalid_tool_use_ids]\n+        \n+        if not valid_tool_uses:\n+            log_event(\"tool_validation_failed\", name=tool_name, id=tool_id)\n+            return\n+        \n+        # Execute tools directly (simpler approach for bidirectional)\n+        for tool_use in valid_tool_uses:\n+            # \ud83d\udd25 CHECK FOR INTERRUPTION DURING EXECUTION\n+            if session.interrupted or not session.active:\n+                log_event(\"tool_execution_cancelled_during\", name=tool_name, id=tool_id)\n+                return\n+            \n+            tool_func = session.agent.tool_registry.registry.get(tool_use[\"name\"])\n+            \n+            if tool_func:\n+                try:\n+                    actual_func = _extract_callable_function(tool_func)\n+                    \n+                    # \ud83d\udd25 WRAP TOOL EXECUTION IN CANCELLATION CHECK\n+                    # For async tools, we could wrap with asyncio.wait_for with cancellation\n+                    # For sync tools, we execute directly but check interruption after\n+                    result = actual_func(**tool_use.get(\"input\", {}))\n+                    \n+                    # \ud83d\udd25 CHECK FOR INTERRUPTION AFTER TOOL EXECUTION\n+                    if session.interrupted or not session.active:\n+                        log_event(\"tool_result_discarded_interruption\", name=tool_name, id=tool_id)\n+                        return\n+                    \n+                    tool_result = _create_success_result(tool_use[\"toolUseId\"], result)\n+                    tool_results.append(tool_result)\n+                    \n+                except asyncio.CancelledError:\n+                    # Tool was cancelled due to interruption\n+                    log_event(\"tool_execution_cancelled\", name=tool_name, id=tool_id)\n+                    return\n+                except Exception as e:\n+                    # \ud83d\udd25 CHECK FOR INTERRUPTION EVEN ON ERROR\n+                    if session.interrupted or not session.active:\n+                        log_event(\"tool_error_discarded_interruption\", name=tool_name, id=tool_id)\n+                        return\n+                    ",
        "comment_created_at": "2025-10-02T18:38:49+00:00",
        "comment_author": "mehtarac",
        "comment_body": "Upon closer look, it was redundant logic. We don't need that many interruption checks. Removed in the newest commit",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2402895921",
    "pr_number": 966,
    "pr_file": "src/strands/agent/agent.py",
    "created_at": "2025-10-03T18:15:03+00:00",
    "commented_code": "yield event[\"data\"]\n             ```\n         \"\"\"\n-        callback_handler = kwargs.get(\"callback_handler\", self.callback_handler)\n+        merged_state = {}",
    "repo_full_name": "strands-agents/sdk-python",
    "discussion_comments": [
      {
        "comment_id": "2402895921",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 966,
        "pr_file": "src/strands/agent/agent.py",
        "discussion_id": "2402895921",
        "commented_code": "@@ -567,7 +572,21 @@ async def stream_async(\n                     yield event[\"data\"]\n             ```\n         \"\"\"\n-        callback_handler = kwargs.get(\"callback_handler\", self.callback_handler)\n+        merged_state = {}",
        "comment_created_at": "2025-10-03T18:15:03+00:00",
        "comment_author": "afarntrog",
        "comment_body": "I think this code can be cleaned up a bit as it looks like we're setting `merged_state[\"invocation_state\"] = invocation_state` regardless. Therefore, we should consider:\r\n```python\r\nmerged_state = {}\r\n\r\nif kwargs:\r\n    logger.warning(\"`**kwargs` parameter is deprecated, use `invocation_state` instead.\")\r\n    merged_state.update(kwargs)\r\n\r\nif invocation_state is not None:\r\n    merged_state[\"invocation_state\"] = invocation_state\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2403008768",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 966,
        "pr_file": "src/strands/agent/agent.py",
        "discussion_id": "2402895921",
        "commented_code": "@@ -567,7 +572,21 @@ async def stream_async(\n                     yield event[\"data\"]\n             ```\n         \"\"\"\n-        callback_handler = kwargs.get(\"callback_handler\", self.callback_handler)\n+        merged_state = {}",
        "comment_created_at": "2025-10-03T18:48:34+00:00",
        "comment_author": "JackYPCOnline",
        "comment_body": "I put it seprate because we are accepting both `invocation_sate` & `kwargs`, first, we want to check if user pass in `kwarg`, then check if they also pass in `invocation_state`. \r\nIf no `kwargs` we update `invocation_state`, although result might be same, current approach is more readable and maintainable after we remove `kwargs`.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2410684133",
    "pr_number": 994,
    "pr_file": "src/strands/models/litellm.py",
    "created_at": "2025-10-07T13:41:12+00:00",
    "commented_code": "logger.debug(\"request=<%s>\", request)\n \n         logger.debug(\"invoking model\")\n-        response = await litellm.acompletion(**self.client_args, **request)\n+        try:\n+            response = await litellm.acompletion(**self.client_args, **request)\n+        except Exception as e:\n+            # Prefer litellm-specific typed exception if exposed\n+            litellm_exc_type = getattr(litellm, \"ContextWindowExceededError\", None) or getattr(\n+                litellm, \"ContextWindowExceeded\", None\n+            )\n+            if litellm_exc_type and isinstance(e, litellm_exc_type):\n+                logger.warning(\"litellm client raised context window overflow\")\n+                raise ContextWindowOverflowException(e) from e\n+\n+            # Fallback to substring checks similar to Bedrock handling\n+            error_message = str(e)\n+            if any(substr in error_message for substr in LITELLM_CONTEXT_WINDOW_OVERFLOW_MESSAGES):\n+                logger.warning(\"litellm threw context window overflow error\")\n+                raise ContextWindowOverflowException(e) from e\n+\n+            # Not a context-window error \u2014 re-raise original",
    "repo_full_name": "strands-agents/sdk-python",
    "discussion_comments": [
      {
        "comment_id": "2410684133",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 994,
        "pr_file": "src/strands/models/litellm.py",
        "discussion_id": "2410684133",
        "commented_code": "@@ -135,7 +145,25 @@ async def stream(\n         logger.debug(\"request=<%s>\", request)\n \n         logger.debug(\"invoking model\")\n-        response = await litellm.acompletion(**self.client_args, **request)\n+        try:\n+            response = await litellm.acompletion(**self.client_args, **request)\n+        except Exception as e:\n+            # Prefer litellm-specific typed exception if exposed\n+            litellm_exc_type = getattr(litellm, \"ContextWindowExceededError\", None) or getattr(\n+                litellm, \"ContextWindowExceeded\", None\n+            )\n+            if litellm_exc_type and isinstance(e, litellm_exc_type):\n+                logger.warning(\"litellm client raised context window overflow\")\n+                raise ContextWindowOverflowException(e) from e\n+\n+            # Fallback to substring checks similar to Bedrock handling\n+            error_message = str(e)\n+            if any(substr in error_message for substr in LITELLM_CONTEXT_WINDOW_OVERFLOW_MESSAGES):\n+                logger.warning(\"litellm threw context window overflow error\")\n+                raise ContextWindowOverflowException(e) from e\n+\n+            # Not a context-window error \u2014 re-raise original",
        "comment_created_at": "2025-10-07T13:41:12+00:00",
        "comment_author": "Unshure",
        "comment_body": "nit: Can we move this logic to a common function called `handle_context_window_overflow_exception` or something?",
        "pr_file_module": null
      },
      {
        "comment_id": "2411121986",
        "repo_full_name": "strands-agents/sdk-python",
        "pr_number": 994,
        "pr_file": "src/strands/models/litellm.py",
        "discussion_id": "2410684133",
        "commented_code": "@@ -135,7 +145,25 @@ async def stream(\n         logger.debug(\"request=<%s>\", request)\n \n         logger.debug(\"invoking model\")\n-        response = await litellm.acompletion(**self.client_args, **request)\n+        try:\n+            response = await litellm.acompletion(**self.client_args, **request)\n+        except Exception as e:\n+            # Prefer litellm-specific typed exception if exposed\n+            litellm_exc_type = getattr(litellm, \"ContextWindowExceededError\", None) or getattr(\n+                litellm, \"ContextWindowExceeded\", None\n+            )\n+            if litellm_exc_type and isinstance(e, litellm_exc_type):\n+                logger.warning(\"litellm client raised context window overflow\")\n+                raise ContextWindowOverflowException(e) from e\n+\n+            # Fallback to substring checks similar to Bedrock handling\n+            error_message = str(e)\n+            if any(substr in error_message for substr in LITELLM_CONTEXT_WINDOW_OVERFLOW_MESSAGES):\n+                logger.warning(\"litellm threw context window overflow error\")\n+                raise ContextWindowOverflowException(e) from e\n+\n+            # Not a context-window error \u2014 re-raise original",
        "comment_created_at": "2025-10-07T15:56:55+00:00",
        "comment_author": "Ratish1",
        "comment_body": "Done!.",
        "pr_file_module": null
      }
    ]
  }
]