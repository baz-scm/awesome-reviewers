[
  {
    "discussion_id": "1397743749",
    "pr_number": 9284,
    "pr_file": "src/osemgrep/reporting/Summary_report.ml",
    "created_at": "2023-11-17T18:54:27+00:00",
    "commented_code": "(* Entry point *)\n (*****************************************************************************)\n \n+exception FoundGitDir of Fpath.t\n+\n+let find_git_dir lst =\n+  try\n+    let _ =\n+      List.fold_left\n+        (fun _ x ->\n+          let dir =\n+            if Common2.dir_exists (Fpath.to_string x) then x else Fpath.parent x\n+          in\n+          if Git_wrapper.is_git_repo dir then raise (FoundGitDir dir))\n+        () lst\n+    in\n+    None\n+  with\n+  | FoundGitDir x -> Some x",
    "repo_full_name": "semgrep/semgrep",
    "discussion_comments": [
      {
        "comment_id": "1397743749",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9284,
        "pr_file": "src/osemgrep/reporting/Summary_report.ml",
        "discussion_id": "1397743749",
        "commented_code": "@@ -15,8 +15,29 @@ module Out = Semgrep_output_v1_t\n (* Entry point *)\n (*****************************************************************************)\n \n+exception FoundGitDir of Fpath.t\n+\n+let find_git_dir lst =\n+  try\n+    let _ =\n+      List.fold_left\n+        (fun _ x ->\n+          let dir =\n+            if Common2.dir_exists (Fpath.to_string x) then x else Fpath.parent x\n+          in\n+          if Git_wrapper.is_git_repo dir then raise (FoundGitDir dir))\n+        () lst\n+    in\n+    None\n+  with\n+  | FoundGitDir x -> Some x",
        "comment_created_at": "2023-11-17T18:54:27+00:00",
        "comment_author": "emjin",
        "comment_body": "We don't usually use exception handling style for things like this. Maybe if there was a very significant performance cost to traversing the list, but even with long lists I find that OCaml does it quickly enough. It's not worth the more complicated code. (Also, if I were to use exception handling style, I would put it in a `List.iter`.)\r\n\r\nFor your function here, you can just do `List.find_opt (fun x -> <your check>) lst`.\r\n\r\nAnd in case you weren't sure, here's how you would write the equivalent code using a fold:\r\n\r\n```\r\nlet find_git_dir xs =\r\n   List.fold_left (fun acc x -> \r\n       match acc with\r\n       | Some x -> Some x\r\n       | None -> if is_git_repo(x) then Some x else None) \r\n    None xs\r\n```\r\n(where `is_git_repo` doesn't have to be a separate function)",
        "pr_file_module": null
      },
      {
        "comment_id": "1397796424",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9284,
        "pr_file": "src/osemgrep/reporting/Summary_report.ml",
        "discussion_id": "1397743749",
        "commented_code": "@@ -15,8 +15,29 @@ module Out = Semgrep_output_v1_t\n (* Entry point *)\n (*****************************************************************************)\n \n+exception FoundGitDir of Fpath.t\n+\n+let find_git_dir lst =\n+  try\n+    let _ =\n+      List.fold_left\n+        (fun _ x ->\n+          let dir =\n+            if Common2.dir_exists (Fpath.to_string x) then x else Fpath.parent x\n+          in\n+          if Git_wrapper.is_git_repo dir then raise (FoundGitDir dir))\n+        () lst\n+    in\n+    None\n+  with\n+  | FoundGitDir x -> Some x",
        "comment_created_at": "2023-11-17T19:44:29+00:00",
        "comment_author": "zzeleznick",
        "comment_body": "Initially I did just use `List.iter` but I had a shower thought concern that `is_git_repo` could take quite a bit of time if we have a large list of targets. \r\n\r\nI'm not very familiar with the expected (or extreme cases of) lengths of inputs, and I thought exiting early was desirable. Also, I thought about a parallel map reduce but that's out of my current ocaml knowledge scope \ud83d\ude05 ",
        "pr_file_module": null
      },
      {
        "comment_id": "1397893175",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9284,
        "pr_file": "src/osemgrep/reporting/Summary_report.ml",
        "discussion_id": "1397743749",
        "commented_code": "@@ -15,8 +15,29 @@ module Out = Semgrep_output_v1_t\n (* Entry point *)\n (*****************************************************************************)\n \n+exception FoundGitDir of Fpath.t\n+\n+let find_git_dir lst =\n+  try\n+    let _ =\n+      List.fold_left\n+        (fun _ x ->\n+          let dir =\n+            if Common2.dir_exists (Fpath.to_string x) then x else Fpath.parent x\n+          in\n+          if Git_wrapper.is_git_repo dir then raise (FoundGitDir dir))\n+        () lst\n+    in\n+    None\n+  with\n+  | FoundGitDir x -> Some x",
        "comment_created_at": "2023-11-17T21:12:49+00:00",
        "comment_author": "emjin",
        "comment_body": "`List.find_opt` and `List.exists` will both only go up to the first occurrence! Depending on implementation, they may still traverse the rest of the list, but they won't run `is_git_repo` on the rest.\r\n\r\nSimilarly, with the fold I wrote, since it checks the accumulator first, it won't run `is_git_repo` more than it needs to.",
        "pr_file_module": null
      },
      {
        "comment_id": "1397894258",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9284,
        "pr_file": "src/osemgrep/reporting/Summary_report.ml",
        "discussion_id": "1397743749",
        "commented_code": "@@ -15,8 +15,29 @@ module Out = Semgrep_output_v1_t\n (* Entry point *)\n (*****************************************************************************)\n \n+exception FoundGitDir of Fpath.t\n+\n+let find_git_dir lst =\n+  try\n+    let _ =\n+      List.fold_left\n+        (fun _ x ->\n+          let dir =\n+            if Common2.dir_exists (Fpath.to_string x) then x else Fpath.parent x\n+          in\n+          if Git_wrapper.is_git_repo dir then raise (FoundGitDir dir))\n+        () lst\n+    in\n+    None\n+  with\n+  | FoundGitDir x -> Some x",
        "comment_created_at": "2023-11-17T21:14:22+00:00",
        "comment_author": "emjin",
        "comment_body": "I think with your approach `List.iter` would be equivalent to `List.fold`! Since you exit early through the exception either way",
        "pr_file_module": null
      },
      {
        "comment_id": "1397937699",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9284,
        "pr_file": "src/osemgrep/reporting/Summary_report.ml",
        "discussion_id": "1397743749",
        "commented_code": "@@ -15,8 +15,29 @@ module Out = Semgrep_output_v1_t\n (* Entry point *)\n (*****************************************************************************)\n \n+exception FoundGitDir of Fpath.t\n+\n+let find_git_dir lst =\n+  try\n+    let _ =\n+      List.fold_left\n+        (fun _ x ->\n+          let dir =\n+            if Common2.dir_exists (Fpath.to_string x) then x else Fpath.parent x\n+          in\n+          if Git_wrapper.is_git_repo dir then raise (FoundGitDir dir))\n+        () lst\n+    in\n+    None\n+  with\n+  | FoundGitDir x -> Some x",
        "comment_created_at": "2023-11-17T22:08:23+00:00",
        "comment_author": "zzeleznick",
        "comment_body": "Nice! Glad we can simplify the code here \ud83d\ude4c \r\n\r\nExiting early via an exception is definitely a new pattern for me coming from `js` and `python` world ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1515769630",
    "pr_number": 9894,
    "pr_file": "src/osemgrep/reporting/Output.ml",
    "created_at": "2024-03-07T08:48:43+00:00",
    "commented_code": "Gitlab_output.secrets_output cli_output.results\n       in\n       Out.put (Yojson.Basic.to_string gitlab_secrets_json)\n+  | Files_only ->\n+      let files =\n+        List.fold_left\n+          (fun acc (m : OutJ.cli_match) ->\n+            Common2.StringSet.add (Fpath.to_string m.path) acc)\n+          Common2.StringSet.empty cli_output.results\n+      in\n+      Out.put (files |> Common2.StringSet.to_list |> String.concat \"\n\")",
    "repo_full_name": "semgrep/semgrep",
    "discussion_comments": [
      {
        "comment_id": "1515769630",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9894,
        "pr_file": "src/osemgrep/reporting/Output.ml",
        "discussion_id": "1515769630",
        "commented_code": "@@ -150,6 +150,14 @@ let dispatch_output_format (output_format : Output_format.t) (conf : conf)\n         Gitlab_output.secrets_output cli_output.results\n       in\n       Out.put (Yojson.Basic.to_string gitlab_secrets_json)\n+  | Files_only ->\n+      let files =\n+        List.fold_left\n+          (fun acc (m : OutJ.cli_match) ->\n+            Common2.StringSet.add (Fpath.to_string m.path) acc)\n+          Common2.StringSet.empty cli_output.results\n+      in\n+      Out.put (files |> Common2.StringSet.to_list |> String.concat \"\\n\")",
        "comment_created_at": "2024-03-07T08:48:43+00:00",
        "comment_author": "aryx",
        "comment_body": "simpler as cli_output.results |> List.map (fun x -> !!x.path) |> Set_.of_list |> Set_.elements |> List_.sort |>  String.concat \"\\n\") ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1509630545",
    "pr_number": 9868,
    "pr_file": "libs/commons/Textedit.ml",
    "created_at": "2024-03-01T22:17:12+00:00",
    "commented_code": "conflicting_edits : t list;\n     }\n \n+let overlaps (e1 : t) (e2 : t) =\n+  (* overlap <=> not (no overlap)\n+             <=> not (e1 ends before e2 or e2 ends before e1) *)\n+  not (e1.end_ <= e2.start || e2.end_ <= e1.start)\n+\n+let overlaps_with_an_interval (intervals : t list) (e1 : t) =\n+  List.exists (fun e2 -> overlaps e1 e2) intervals\n+\n+(*\n+   Remove overlapping edits by proceeding from left to right in the order\n+   the edits are given to us.\n+\n+   This is an O(N^2) algorithm where N is the number of edits. It should be\n+   small enough in practice since N is the number of edits to make in one\n+   file. If it turns out this isn't good enough, we'll have to use a more\n+   elaborate algorithm. The problem is that we have to apply the fixes\n+   in the order in which they're discovered by semgrep rules rather than\n+   than in the order in which they appear in the file.\n+*)\n let remove_overlapping_edits edits =\n-  let rec f edits conflicting_edits = function\n-    | e1 :: e2 :: tl ->\n-        if e1.end_ > e2.start then\n-          let conflicting_edits =\n-            (* If the edits are identical, they are not conflicting. We can\n-             * apply just one. *)\n-            if e1 = e2 then conflicting_edits else e2 :: conflicting_edits\n-          in\n-          f edits conflicting_edits (e1 :: tl)\n-        else\n-          let edits = e1 :: edits in\n-          f edits conflicting_edits (e2 :: tl)\n-    | [ edit ] ->\n-        let edits = edit :: edits in\n-        (List.rev edits, List.rev conflicting_edits)\n-    | [] -> (List.rev edits, List.rev conflicting_edits)\n+  let accepted_edits, conflicting_edits =\n+    List.fold_left\n+      (fun (accepted_edits, conflicting_edits) edit ->\n+        if overlaps_with_an_interval accepted_edits edit then\n+          (accepted_edits, edit :: conflicting_edits)\n+        else (edit :: accepted_edits, conflicting_edits))\n+      ([], []) edits\n   in\n-  f [] [] edits\n+  (List.rev accepted_edits, List.rev conflicting_edits)\n \n-let apply_edit_to_text text { start; end_; replacement_text; _ } =\n+let apply_edit_to_text text ({ start; end_; replacement_text; _ } as edit) =\n+  Logs.debug (fun m -> m ~tags \"Apply edit %s\" (show edit));\n   let before = Str.string_before text start in\n   let after = Str.string_after text end_ in\n   before ^ replacement_text ^ after\n \n-let apply_edits_to_text text edits =\n-  let edits = List.sort (fun e1 e2 -> e1.start - e2.start) edits in\n+let apply_edits_to_text path text edits =\n+  (*\n+     Don't sort the edits. They must be applied in the order in which they\n+     were detected. If two rules report a problem at the same location,\n+     the first rule that reports the problem has precedence.\n+  *)",
    "repo_full_name": "semgrep/semgrep",
    "discussion_comments": [
      {
        "comment_id": "1509630545",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9868,
        "pr_file": "libs/commons/Textedit.ml",
        "discussion_id": "1509630545",
        "commented_code": "@@ -33,33 +37,50 @@ type edit_application_result =\n       conflicting_edits : t list;\n     }\n \n+let overlaps (e1 : t) (e2 : t) =\n+  (* overlap <=> not (no overlap)\n+             <=> not (e1 ends before e2 or e2 ends before e1) *)\n+  not (e1.end_ <= e2.start || e2.end_ <= e1.start)\n+\n+let overlaps_with_an_interval (intervals : t list) (e1 : t) =\n+  List.exists (fun e2 -> overlaps e1 e2) intervals\n+\n+(*\n+   Remove overlapping edits by proceeding from left to right in the order\n+   the edits are given to us.\n+\n+   This is an O(N^2) algorithm where N is the number of edits. It should be\n+   small enough in practice since N is the number of edits to make in one\n+   file. If it turns out this isn't good enough, we'll have to use a more\n+   elaborate algorithm. The problem is that we have to apply the fixes\n+   in the order in which they're discovered by semgrep rules rather than\n+   than in the order in which they appear in the file.\n+*)\n let remove_overlapping_edits edits =\n-  let rec f edits conflicting_edits = function\n-    | e1 :: e2 :: tl ->\n-        if e1.end_ > e2.start then\n-          let conflicting_edits =\n-            (* If the edits are identical, they are not conflicting. We can\n-             * apply just one. *)\n-            if e1 = e2 then conflicting_edits else e2 :: conflicting_edits\n-          in\n-          f edits conflicting_edits (e1 :: tl)\n-        else\n-          let edits = e1 :: edits in\n-          f edits conflicting_edits (e2 :: tl)\n-    | [ edit ] ->\n-        let edits = edit :: edits in\n-        (List.rev edits, List.rev conflicting_edits)\n-    | [] -> (List.rev edits, List.rev conflicting_edits)\n+  let accepted_edits, conflicting_edits =\n+    List.fold_left\n+      (fun (accepted_edits, conflicting_edits) edit ->\n+        if overlaps_with_an_interval accepted_edits edit then\n+          (accepted_edits, edit :: conflicting_edits)\n+        else (edit :: accepted_edits, conflicting_edits))\n+      ([], []) edits\n   in\n-  f [] [] edits\n+  (List.rev accepted_edits, List.rev conflicting_edits)\n \n-let apply_edit_to_text text { start; end_; replacement_text; _ } =\n+let apply_edit_to_text text ({ start; end_; replacement_text; _ } as edit) =\n+  Logs.debug (fun m -> m ~tags \"Apply edit %s\" (show edit));\n   let before = Str.string_before text start in\n   let after = Str.string_after text end_ in\n   before ^ replacement_text ^ after\n \n-let apply_edits_to_text text edits =\n-  let edits = List.sort (fun e1 e2 -> e1.start - e2.start) edits in\n+let apply_edits_to_text path text edits =\n+  (*\n+     Don't sort the edits. They must be applied in the order in which they\n+     were detected. If two rules report a problem at the same location,\n+     the first rule that reports the problem has precedence.\n+  *)",
        "comment_created_at": "2024-03-01T22:17:12+00:00",
        "comment_author": "nmote",
        "comment_body": "It's fine to deduplicate before applying, but after that we do need to sort them and then apply them in reverse order. Otherwise, edits applied earlier in the file will shift the text later in the file, and subsequent edits will be applied in the wrong place. I suspect this is why the tests are failing.",
        "pr_file_module": null
      },
      {
        "comment_id": "1509641295",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9868,
        "pr_file": "libs/commons/Textedit.ml",
        "discussion_id": "1509630545",
        "commented_code": "@@ -33,33 +37,50 @@ type edit_application_result =\n       conflicting_edits : t list;\n     }\n \n+let overlaps (e1 : t) (e2 : t) =\n+  (* overlap <=> not (no overlap)\n+             <=> not (e1 ends before e2 or e2 ends before e1) *)\n+  not (e1.end_ <= e2.start || e2.end_ <= e1.start)\n+\n+let overlaps_with_an_interval (intervals : t list) (e1 : t) =\n+  List.exists (fun e2 -> overlaps e1 e2) intervals\n+\n+(*\n+   Remove overlapping edits by proceeding from left to right in the order\n+   the edits are given to us.\n+\n+   This is an O(N^2) algorithm where N is the number of edits. It should be\n+   small enough in practice since N is the number of edits to make in one\n+   file. If it turns out this isn't good enough, we'll have to use a more\n+   elaborate algorithm. The problem is that we have to apply the fixes\n+   in the order in which they're discovered by semgrep rules rather than\n+   than in the order in which they appear in the file.\n+*)\n let remove_overlapping_edits edits =\n-  let rec f edits conflicting_edits = function\n-    | e1 :: e2 :: tl ->\n-        if e1.end_ > e2.start then\n-          let conflicting_edits =\n-            (* If the edits are identical, they are not conflicting. We can\n-             * apply just one. *)\n-            if e1 = e2 then conflicting_edits else e2 :: conflicting_edits\n-          in\n-          f edits conflicting_edits (e1 :: tl)\n-        else\n-          let edits = e1 :: edits in\n-          f edits conflicting_edits (e2 :: tl)\n-    | [ edit ] ->\n-        let edits = edit :: edits in\n-        (List.rev edits, List.rev conflicting_edits)\n-    | [] -> (List.rev edits, List.rev conflicting_edits)\n+  let accepted_edits, conflicting_edits =\n+    List.fold_left\n+      (fun (accepted_edits, conflicting_edits) edit ->\n+        if overlaps_with_an_interval accepted_edits edit then\n+          (accepted_edits, edit :: conflicting_edits)\n+        else (edit :: accepted_edits, conflicting_edits))\n+      ([], []) edits\n   in\n-  f [] [] edits\n+  (List.rev accepted_edits, List.rev conflicting_edits)\n \n-let apply_edit_to_text text { start; end_; replacement_text; _ } =\n+let apply_edit_to_text text ({ start; end_; replacement_text; _ } as edit) =\n+  Logs.debug (fun m -> m ~tags \"Apply edit %s\" (show edit));\n   let before = Str.string_before text start in\n   let after = Str.string_after text end_ in\n   before ^ replacement_text ^ after\n \n-let apply_edits_to_text text edits =\n-  let edits = List.sort (fun e1 e2 -> e1.start - e2.start) edits in\n+let apply_edits_to_text path text edits =\n+  (*\n+     Don't sort the edits. They must be applied in the order in which they\n+     were detected. If two rules report a problem at the same location,\n+     the first rule that reports the problem has precedence.\n+  *)",
        "comment_created_at": "2024-03-01T22:36:18+00:00",
        "comment_author": "mjambon",
        "comment_body": "Yes, I found out about it the hard way but the existing comment explaining this was helpful.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1476632923",
    "pr_number": 9708,
    "pr_file": "src/engine/Match_tainting_mode.ml",
    "created_at": "2024-02-02T20:02:27+00:00",
    "commented_code": "})\n          else None)\n \n+(* Builds a table to quickly look up for propagator matches, taking advantage of\n+ * the requirement that propagators must be exact matches.\n+ *\n+ * OBS: Previously we allowed these matches if they had an overlap of >0.99, but\n+ *   to be honest that was arbitrary and fragile (the overlap largely depends on\n+ *   the amount of text being matched). Typically propagators from/to match\n+ *   l-values and those typically we can count as being 100% perfect matches.\n+ *   If this causes problems we can always roll back, but all tests still work.\n+ *)\n+let propagators_table_of_matches rule matches =\n+  let mk_match prop var kind r =\n+    let spec_pm = RM.range_to_pattern_match_adjusted rule prop.rwm in\n+    let spec : D.a_propagator = { kind; prop = prop.spec; var } in\n+    {\n+      Taint_smatch.spec;\n+      spec_id = prop.spec.propagator_id;\n+      spec_pm;\n+      range = r;\n+      overlap = 1.0;\n+    }\n+  in\n+  let tbl = Hashtbl.create 100 in",
    "repo_full_name": "semgrep/semgrep",
    "discussion_comments": [
      {
        "comment_id": "1476632923",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9708,
        "pr_file": "src/engine/Match_tainting_mode.ml",
        "discussion_id": "1476632923",
        "commented_code": "@@ -383,33 +373,46 @@ let any_is_in_sources_matches rule any matches =\n               })\n          else None)\n \n+(* Builds a table to quickly look up for propagator matches, taking advantage of\n+ * the requirement that propagators must be exact matches.\n+ *\n+ * OBS: Previously we allowed these matches if they had an overlap of >0.99, but\n+ *   to be honest that was arbitrary and fragile (the overlap largely depends on\n+ *   the amount of text being matched). Typically propagators from/to match\n+ *   l-values and those typically we can count as being 100% perfect matches.\n+ *   If this causes problems we can always roll back, but all tests still work.\n+ *)\n+let propagators_table_of_matches rule matches =\n+  let mk_match prop var kind r =\n+    let spec_pm = RM.range_to_pattern_match_adjusted rule prop.rwm in\n+    let spec : D.a_propagator = { kind; prop = prop.spec; var } in\n+    {\n+      Taint_smatch.spec;\n+      spec_id = prop.spec.propagator_id;\n+      spec_pm;\n+      range = r;\n+      overlap = 1.0;\n+    }\n+  in\n+  let tbl = Hashtbl.create 100 in",
        "comment_created_at": "2024-02-02T20:02:27+00:00",
        "comment_author": "emjin",
        "comment_body": "How large does this table get on larger repos?",
        "pr_file_module": null
      },
      {
        "comment_id": "1476639289",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9708,
        "pr_file": "src/engine/Match_tainting_mode.ml",
        "discussion_id": "1476632923",
        "commented_code": "@@ -383,33 +373,46 @@ let any_is_in_sources_matches rule any matches =\n               })\n          else None)\n \n+(* Builds a table to quickly look up for propagator matches, taking advantage of\n+ * the requirement that propagators must be exact matches.\n+ *\n+ * OBS: Previously we allowed these matches if they had an overlap of >0.99, but\n+ *   to be honest that was arbitrary and fragile (the overlap largely depends on\n+ *   the amount of text being matched). Typically propagators from/to match\n+ *   l-values and those typically we can count as being 100% perfect matches.\n+ *   If this causes problems we can always roll back, but all tests still work.\n+ *)\n+let propagators_table_of_matches rule matches =\n+  let mk_match prop var kind r =\n+    let spec_pm = RM.range_to_pattern_match_adjusted rule prop.rwm in\n+    let spec : D.a_propagator = { kind; prop = prop.spec; var } in\n+    {\n+      Taint_smatch.spec;\n+      spec_id = prop.spec.propagator_id;\n+      spec_pm;\n+      range = r;\n+      overlap = 1.0;\n+    }\n+  in\n+  let tbl = Hashtbl.create 100 in",
        "comment_created_at": "2024-02-02T20:05:22+00:00",
        "comment_author": "emjin",
        "comment_body": "Also, how does the compare for this work? Is it using polymorphic compare?",
        "pr_file_module": null
      },
      {
        "comment_id": "1481559749",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9708,
        "pr_file": "src/engine/Match_tainting_mode.ml",
        "discussion_id": "1476632923",
        "commented_code": "@@ -383,33 +373,46 @@ let any_is_in_sources_matches rule any matches =\n               })\n          else None)\n \n+(* Builds a table to quickly look up for propagator matches, taking advantage of\n+ * the requirement that propagators must be exact matches.\n+ *\n+ * OBS: Previously we allowed these matches if they had an overlap of >0.99, but\n+ *   to be honest that was arbitrary and fragile (the overlap largely depends on\n+ *   the amount of text being matched). Typically propagators from/to match\n+ *   l-values and those typically we can count as being 100% perfect matches.\n+ *   If this causes problems we can always roll back, but all tests still work.\n+ *)\n+let propagators_table_of_matches rule matches =\n+  let mk_match prop var kind r =\n+    let spec_pm = RM.range_to_pattern_match_adjusted rule prop.rwm in\n+    let spec : D.a_propagator = { kind; prop = prop.spec; var } in\n+    {\n+      Taint_smatch.spec;\n+      spec_id = prop.spec.propagator_id;\n+      spec_pm;\n+      range = r;\n+      overlap = 1.0;\n+    }\n+  in\n+  let tbl = Hashtbl.create 100 in",
        "comment_created_at": "2024-02-07T14:27:58+00:00",
        "comment_author": "IagoAbal",
        "comment_body": "I'd say it doesn't cause memory problems but can actually help there. Before we were allocating a list and now we're allocating a hash table. But I'll do some runs to give you concrete numbers.\r\n\r\nRe `compare`, it uses polymorphic compare on `Range.t` which should be fine (it's just a pair of `int`s). But I'm fine creating a dedicated hash-table module for `Range` if you insist.",
        "pr_file_module": null
      },
      {
        "comment_id": "1482015223",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9708,
        "pr_file": "src/engine/Match_tainting_mode.ml",
        "discussion_id": "1476632923",
        "commented_code": "@@ -383,33 +373,46 @@ let any_is_in_sources_matches rule any matches =\n               })\n          else None)\n \n+(* Builds a table to quickly look up for propagator matches, taking advantage of\n+ * the requirement that propagators must be exact matches.\n+ *\n+ * OBS: Previously we allowed these matches if they had an overlap of >0.99, but\n+ *   to be honest that was arbitrary and fragile (the overlap largely depends on\n+ *   the amount of text being matched). Typically propagators from/to match\n+ *   l-values and those typically we can count as being 100% perfect matches.\n+ *   If this causes problems we can always roll back, but all tests still work.\n+ *)\n+let propagators_table_of_matches rule matches =\n+  let mk_match prop var kind r =\n+    let spec_pm = RM.range_to_pattern_match_adjusted rule prop.rwm in\n+    let spec : D.a_propagator = { kind; prop = prop.spec; var } in\n+    {\n+      Taint_smatch.spec;\n+      spec_id = prop.spec.propagator_id;\n+      spec_pm;\n+      range = r;\n+      overlap = 1.0;\n+    }\n+  in\n+  let tbl = Hashtbl.create 100 in",
        "comment_created_at": "2024-02-07T20:00:49+00:00",
        "comment_author": "emjin",
        "comment_body": "We've been burned before by polymorphic compare so I'd appreciate the dedicated hash table :D If we were previously allocating a list every time I'm fine with you skipping the concrete numbers, that reasoning convinces me.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1397923124",
    "pr_number": 9288,
    "pr_file": "src/osemgrep/language_server/scan_helpers/Diagnostics.ml",
    "created_at": "2023-11-17T21:51:52+00:00",
    "commented_code": "List.filter (fun (m : Out.cli_match) -> m.path = file) matches\n   in\n   let diagnostics = Common.map (diagnostic_of_match is_intellij) matches in\n-  let ranges_overlap (a : Diagnostic.t) (b : Diagnostic.t) =\n-    if a.range.start.line = b.range.start.line then\n-      a.range.start.character <= b.range.start.character\n-    else\n-      a.range.start.line <= b.range.start.line\n-      && a.range.end_.line >= b.range.end_.line\n-  in\n   let diagnostics =\n     Common.uniq_by\n       (fun (a : Diagnostic.t) (b : Diagnostic.t) ->\n-        a.code = b.code && ranges_overlap a b)\n+        let a_json = a |> Diagnostic.yojson_of_t |> Yojson.Safe.to_string in\n+        let b_json = b |> Diagnostic.yojson_of_t |> Yojson.Safe.to_string in\n+        String.equal a_json b_json)",
    "repo_full_name": "semgrep/semgrep",
    "discussion_comments": [
      {
        "comment_id": "1397923124",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9288,
        "pr_file": "src/osemgrep/language_server/scan_helpers/Diagnostics.ml",
        "discussion_id": "1397923124",
        "commented_code": "@@ -48,17 +48,12 @@ let diagnostics_of_file is_intellij matches file =\n     List.filter (fun (m : Out.cli_match) -> m.path = file) matches\n   in\n   let diagnostics = Common.map (diagnostic_of_match is_intellij) matches in\n-  let ranges_overlap (a : Diagnostic.t) (b : Diagnostic.t) =\n-    if a.range.start.line = b.range.start.line then\n-      a.range.start.character <= b.range.start.character\n-    else\n-      a.range.start.line <= b.range.start.line\n-      && a.range.end_.line >= b.range.end_.line\n-  in\n   let diagnostics =\n     Common.uniq_by\n       (fun (a : Diagnostic.t) (b : Diagnostic.t) ->\n-        a.code = b.code && ranges_overlap a b)\n+        let a_json = a |> Diagnostic.yojson_of_t |> Yojson.Safe.to_string in\n+        let b_json = b |> Diagnostic.yojson_of_t |> Yojson.Safe.to_string in\n+        String.equal a_json b_json)",
        "comment_created_at": "2023-11-17T21:51:52+00:00",
        "comment_author": "kopecs",
        "comment_body": "Can be `Common2.on String.equal (fun x ->  x |> Diagnostic.yojson_of_t |> Yojson.Safe.to_string) a b`",
        "pr_file_module": null
      },
      {
        "comment_id": "1397976439",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9288,
        "pr_file": "src/osemgrep/language_server/scan_helpers/Diagnostics.ml",
        "discussion_id": "1397923124",
        "commented_code": "@@ -48,17 +48,12 @@ let diagnostics_of_file is_intellij matches file =\n     List.filter (fun (m : Out.cli_match) -> m.path = file) matches\n   in\n   let diagnostics = Common.map (diagnostic_of_match is_intellij) matches in\n-  let ranges_overlap (a : Diagnostic.t) (b : Diagnostic.t) =\n-    if a.range.start.line = b.range.start.line then\n-      a.range.start.character <= b.range.start.character\n-    else\n-      a.range.start.line <= b.range.start.line\n-      && a.range.end_.line >= b.range.end_.line\n-  in\n   let diagnostics =\n     Common.uniq_by\n       (fun (a : Diagnostic.t) (b : Diagnostic.t) ->\n-        a.code = b.code && ranges_overlap a b)\n+        let a_json = a |> Diagnostic.yojson_of_t |> Yojson.Safe.to_string in\n+        let b_json = b |> Diagnostic.yojson_of_t |> Yojson.Safe.to_string in\n+        String.equal a_json b_json)",
        "comment_created_at": "2023-11-17T23:05:47+00:00",
        "comment_author": "ajbt200128",
        "comment_body": "Sure",
        "pr_file_module": null
      }
    ]
  }
]