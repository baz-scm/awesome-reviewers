[
  {
    "discussion_id": "1568075904",
    "pr_number": 10112,
    "pr_file": "cli/src/semgrep/output.py",
    "created_at": "2024-04-17T00:41:46+00:00",
    "commented_code": "except requests.exceptions.Timeout:\n             raise SemgrepError(f\"posting output to {output_url} timed out\")\n \n-    def _build_output(self) -> str:\n-        # CliOutputExtra members\n-        cli_paths = out.ScannedAndSkipped(\n-            # This is incorrect when some rules are skipped by semgrep-core\n-            # e.g. proprietary rules.\n-            # TODO: Use what semgrep-core returns for 'scanned' and 'skipped'.\n-            scanned=[out.Fpath(str(path)) for path in sorted(self.all_targets)],\n-            skipped=None,\n-        )\n-        cli_timing: Optional[out.Profile] = None\n-\n-        explanations: Optional[List[out.MatchingExplanation]] = self.explanations\n-\n-        # Extra, extra! This just in! \ud83d\uddde\ufe0f\n-        # The extra dict is for blatantly skipping type checking and function signatures.\n-        # - The text formatter uses it to store settings\n-        # You should use CliOutputExtra for better type checking\n-        extra: Dict[str, Any] = {}\n-        if self.settings.output_time and self.extra and self.extra.core.time:\n-            cli_timing = _build_time_json(\n-                self.filtered_rules,\n-                self.all_targets,\n-                self.extra.core.time,\n-                self.profiler,\n-            )\n-        if self.settings.verbose_errors:\n-            # TODO: use SkippedTarget directly in ignore_log or in yield_json_objects at least\n-            skipped = sorted(\n-                self.ignore_log.yield_json_objects(), key=lambda x: Path(x[\"path\"])\n+    def _build_output(self) -> Iterator[Tuple[Optional[str], str]]:",
    "repo_full_name": "semgrep/semgrep",
    "discussion_comments": [
      {
        "comment_id": "1568075904",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 10112,
        "pr_file": "cli/src/semgrep/output.py",
        "discussion_id": "1568075904",
        "commented_code": "@@ -450,85 +511,81 @@ def _post_output(self, output_url: str, output: str) -> None:\n         except requests.exceptions.Timeout:\n             raise SemgrepError(f\"posting output to {output_url} timed out\")\n \n-    def _build_output(self) -> str:\n-        # CliOutputExtra members\n-        cli_paths = out.ScannedAndSkipped(\n-            # This is incorrect when some rules are skipped by semgrep-core\n-            # e.g. proprietary rules.\n-            # TODO: Use what semgrep-core returns for 'scanned' and 'skipped'.\n-            scanned=[out.Fpath(str(path)) for path in sorted(self.all_targets)],\n-            skipped=None,\n-        )\n-        cli_timing: Optional[out.Profile] = None\n-\n-        explanations: Optional[List[out.MatchingExplanation]] = self.explanations\n-\n-        # Extra, extra! This just in! \ud83d\uddde\ufe0f\n-        # The extra dict is for blatantly skipping type checking and function signatures.\n-        # - The text formatter uses it to store settings\n-        # You should use CliOutputExtra for better type checking\n-        extra: Dict[str, Any] = {}\n-        if self.settings.output_time and self.extra and self.extra.core.time:\n-            cli_timing = _build_time_json(\n-                self.filtered_rules,\n-                self.all_targets,\n-                self.extra.core.time,\n-                self.profiler,\n-            )\n-        if self.settings.verbose_errors:\n-            # TODO: use SkippedTarget directly in ignore_log or in yield_json_objects at least\n-            skipped = sorted(\n-                self.ignore_log.yield_json_objects(), key=lambda x: Path(x[\"path\"])\n+    def _build_output(self) -> Iterator[Tuple[Optional[str], str]]:",
        "comment_created_at": "2024-04-17T00:41:46+00:00",
        "comment_author": "amchiclet",
        "comment_body": "Optional: this is probably more about the limitations on how github diffs the changes. Once things got indented, now it looks like a big change, when I think it's just a couple of small tweaks.\r\n\r\nI think the changes would be easier to read if you have `_build_outputs` do the for loop and yielding, and `_build_output` just return the pair (output_destination, output_format).\r\n\r\nIn general, I like it more when indented blocks aren't too long. :)\r\n\r\nYour call.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1479048998",
    "pr_number": 9717,
    "pr_file": "cli/src/semgrep/rule.py",
    "created_at": "2024-02-05T23:28:31+00:00",
    "commented_code": "\"\"\"\n         Returns if this rule indicates matches should block CI\n         \"\"\"\n+\n+        validation_state_metadata = self.metadata.get(\n+            \"dev.semgrep.validation_state.actions\"\n+        )\n+        if validation_state_metadata:\n+            for value in validation_state_metadata.values():\n+                if value == \"block\":\n+                    return True\n+            return False",
    "repo_full_name": "semgrep/semgrep",
    "discussion_comments": [
      {
        "comment_id": "1479048998",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9717,
        "pr_file": "cli/src/semgrep/rule.py",
        "discussion_id": "1479048998",
        "commented_code": "@@ -150,6 +150,16 @@ def is_blocking(self) -> bool:\n         \"\"\"\n         Returns if this rule indicates matches should block CI\n         \"\"\"\n+\n+        validation_state_metadata = self.metadata.get(\n+            \"dev.semgrep.validation_state.actions\"\n+        )\n+        if validation_state_metadata:\n+            for value in validation_state_metadata.values():\n+                if value == \"block\":\n+                    return True\n+            return False",
        "comment_created_at": "2024-02-05T23:28:31+00:00",
        "comment_author": "kopecs",
        "comment_body": "```suggestion\r\n            return \"block\" in validation_state_metadata.values()\r\n```\r\nThis instead?\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "1479060707",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9717,
        "pr_file": "cli/src/semgrep/rule.py",
        "discussion_id": "1479048998",
        "commented_code": "@@ -150,6 +150,16 @@ def is_blocking(self) -> bool:\n         \"\"\"\n         Returns if this rule indicates matches should block CI\n         \"\"\"\n+\n+        validation_state_metadata = self.metadata.get(\n+            \"dev.semgrep.validation_state.actions\"\n+        )\n+        if validation_state_metadata:\n+            for value in validation_state_metadata.values():\n+                if value == \"block\":\n+                    return True\n+            return False",
        "comment_created_at": "2024-02-05T23:47:36+00:00",
        "comment_author": "salolivares",
        "comment_body": "good catch, much cleaner.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1464177061",
    "pr_number": 9610,
    "pr_file": "cli/src/semgrep/rule_match.py",
    "created_at": "2024-01-24T01:04:33+00:00",
    "commented_code": "# current scan results if an issue arises.\n             self.annotated_rule_name if self.from_transient_scan else self.rule_id,\n             str(self.path),\n-            self.start.offset,\n-            self.end.offset,\n+            # Lockfile-only supply chain findings don't have offsets (not for any technical reason, the parsers just aren't set up to output them, though of course they could be)\n+            # So just use line numbers instead\n+            # TODO: remove this when the switch to ocaml is done\n+            *(\n+                (self.start.offset, self.end.offset)\n+                if not (\n+                    self.extra.get(\"sca_info\") and not self.extra[\"sca_info\"].reachable\n+                )\n+                else (self.start.line, self.end.line)\n+            ),",
    "repo_full_name": "semgrep/semgrep",
    "discussion_comments": [
      {
        "comment_id": "1464177061",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9610,
        "pr_file": "cli/src/semgrep/rule_match.py",
        "discussion_id": "1464177061",
        "commented_code": "@@ -221,8 +221,16 @@ def get_cli_unique_key(self) -> CliUniqueKey:\n             # current scan results if an issue arises.\n             self.annotated_rule_name if self.from_transient_scan else self.rule_id,\n             str(self.path),\n-            self.start.offset,\n-            self.end.offset,\n+            # Lockfile-only supply chain findings don't have offsets (not for any technical reason, the parsers just aren't set up to output them, though of course they could be)\n+            # So just use line numbers instead\n+            # TODO: remove this when the switch to ocaml is done\n+            *(\n+                (self.start.offset, self.end.offset)\n+                if not (\n+                    self.extra.get(\"sca_info\") and not self.extra[\"sca_info\"].reachable\n+                )\n+                else (self.start.line, self.end.line)\n+            ),",
        "comment_created_at": "2024-01-24T01:04:33+00:00",
        "comment_author": "chmccreery",
        "comment_body": "The reliance on self.extra.get(\"sca_info\") here scares me a little bit, because it feels like an implementation detail that should be abstracted. Can you use self.product == SCA here in case how we implement that later changes?\r\n\r\nAlso, the double negative here is messing with my head. Is this the same thing and maybe easier to read?\r\n\r\n```suggestion\r\n                (self.start.line, self.end.line)\r\n                if (\r\n                    self.extra.get(\"sca_info\") and not self.extra[\"sca_info\"].reachable\r\n                )\r\n                else (self.start.offset, self.end.offset)\r\n            ),\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1465433675",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9610,
        "pr_file": "cli/src/semgrep/rule_match.py",
        "discussion_id": "1464177061",
        "commented_code": "@@ -221,8 +221,16 @@ def get_cli_unique_key(self) -> CliUniqueKey:\n             # current scan results if an issue arises.\n             self.annotated_rule_name if self.from_transient_scan else self.rule_id,\n             str(self.path),\n-            self.start.offset,\n-            self.end.offset,\n+            # Lockfile-only supply chain findings don't have offsets (not for any technical reason, the parsers just aren't set up to output them, though of course they could be)\n+            # So just use line numbers instead\n+            # TODO: remove this when the switch to ocaml is done\n+            *(\n+                (self.start.offset, self.end.offset)\n+                if not (\n+                    self.extra.get(\"sca_info\") and not self.extra[\"sca_info\"].reachable\n+                )\n+                else (self.start.line, self.end.line)\n+            ),",
        "comment_created_at": "2024-01-24T19:21:21+00:00",
        "comment_author": "mmcqd",
        "comment_body": "I did it in that order because I wanted the \"default\" case to be textually first, but I agree the logic is a bit confusing, I'll go with your suggestion",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1419046264",
    "pr_number": 9396,
    "pr_file": "cli/src/semgrep/settings.py",
    "created_at": "2023-12-07T14:25:05+00:00",
    "commented_code": "class SettingsSchema(TypedDict, total=False):\n     has_shown_metrics_notification: bool\n-    api_token: str\n+    api_token: Optional[str]\n     anonymous_user_id: str\n \n \n SettingsKeys = Literal[\n     \"has_shown_metrics_notification\", \"api_token\", \"anonymous_user_id\"\n ]\n \n-DEFAULT_SETTINGS: SettingsSchema = {\"anonymous_user_id\": str(uuid.uuid4())}\n+\n+def generate_anonymous_user_id(api_token: Optional[str]) -> str:\n+    return (\n+        str(uuid.uuid4())\n+        if api_token is None\n+        else str(\n+            uuid.uuid5(\n+                uuid.UUID(\"0\" * 32), hashlib.sha256(api_token.encode()).hexdigest()\n+            )\n+        )\n+    )\n+\n+\n+def generate_default_settings(api_token: Optional[str] = None) -> SettingsSchema:\n+    anonymous_user_id = generate_anonymous_user_id(api_token)\n+    return (\n+        {\n+            \"has_shown_metrics_notification\": False,\n+            \"api_token\": api_token,\n+            \"anonymous_user_id\": anonymous_user_id,\n+        }\n+        if api_token is not None\n+        else {\n+            \"has_shown_metrics_notification\": False,\n+            \"anonymous_user_id\": anonymous_user_id,\n+        }\n+    )",
    "repo_full_name": "semgrep/semgrep",
    "discussion_comments": [
      {
        "comment_id": "1419046264",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9396,
        "pr_file": "cli/src/semgrep/settings.py",
        "discussion_id": "1419046264",
        "commented_code": "@@ -34,15 +36,41 @@\n \n class SettingsSchema(TypedDict, total=False):\n     has_shown_metrics_notification: bool\n-    api_token: str\n+    api_token: Optional[str]\n     anonymous_user_id: str\n \n \n SettingsKeys = Literal[\n     \"has_shown_metrics_notification\", \"api_token\", \"anonymous_user_id\"\n ]\n \n-DEFAULT_SETTINGS: SettingsSchema = {\"anonymous_user_id\": str(uuid.uuid4())}\n+\n+def generate_anonymous_user_id(api_token: Optional[str]) -> str:\n+    return (\n+        str(uuid.uuid4())\n+        if api_token is None\n+        else str(\n+            uuid.uuid5(\n+                uuid.UUID(\"0\" * 32), hashlib.sha256(api_token.encode()).hexdigest()\n+            )\n+        )\n+    )\n+\n+\n+def generate_default_settings(api_token: Optional[str] = None) -> SettingsSchema:\n+    anonymous_user_id = generate_anonymous_user_id(api_token)\n+    return (\n+        {\n+            \"has_shown_metrics_notification\": False,\n+            \"api_token\": api_token,\n+            \"anonymous_user_id\": anonymous_user_id,\n+        }\n+        if api_token is not None\n+        else {\n+            \"has_shown_metrics_notification\": False,\n+            \"anonymous_user_id\": anonymous_user_id,\n+        }\n+    )",
        "comment_created_at": "2023-12-07T14:25:05+00:00",
        "comment_author": "jbergler",
        "comment_body": "this might be a little less repetitive if you do something like this\r\n\r\n```suggestion\r\n    settings = {\r\n        \"has_shown_metrics_notification\": False,\r\n        \"anonymous_user_id\": anonymous_user_id,\r\n    }\r\n    if api_token is not None:\r\n        settings[\"api_token\"] api_token\r\n    return settings\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1419518229",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9396,
        "pr_file": "cli/src/semgrep/settings.py",
        "discussion_id": "1419046264",
        "commented_code": "@@ -34,15 +36,41 @@\n \n class SettingsSchema(TypedDict, total=False):\n     has_shown_metrics_notification: bool\n-    api_token: str\n+    api_token: Optional[str]\n     anonymous_user_id: str\n \n \n SettingsKeys = Literal[\n     \"has_shown_metrics_notification\", \"api_token\", \"anonymous_user_id\"\n ]\n \n-DEFAULT_SETTINGS: SettingsSchema = {\"anonymous_user_id\": str(uuid.uuid4())}\n+\n+def generate_anonymous_user_id(api_token: Optional[str]) -> str:\n+    return (\n+        str(uuid.uuid4())\n+        if api_token is None\n+        else str(\n+            uuid.uuid5(\n+                uuid.UUID(\"0\" * 32), hashlib.sha256(api_token.encode()).hexdigest()\n+            )\n+        )\n+    )\n+\n+\n+def generate_default_settings(api_token: Optional[str] = None) -> SettingsSchema:\n+    anonymous_user_id = generate_anonymous_user_id(api_token)\n+    return (\n+        {\n+            \"has_shown_metrics_notification\": False,\n+            \"api_token\": api_token,\n+            \"anonymous_user_id\": anonymous_user_id,\n+        }\n+        if api_token is not None\n+        else {\n+            \"has_shown_metrics_notification\": False,\n+            \"anonymous_user_id\": anonymous_user_id,\n+        }\n+    )",
        "comment_created_at": "2023-12-07T19:35:46+00:00",
        "comment_author": "zzeleznick",
        "comment_body": "Yep, I debated whether I wanted to go with the natural, pythonic inclination use a mutation (gasp) to reduce the LOC here \u2013 and went with the more \"pure\" approach.",
        "pr_file_module": null
      },
      {
        "comment_id": "1419713876",
        "repo_full_name": "semgrep/semgrep",
        "pr_number": 9396,
        "pr_file": "cli/src/semgrep/settings.py",
        "discussion_id": "1419046264",
        "commented_code": "@@ -34,15 +36,41 @@\n \n class SettingsSchema(TypedDict, total=False):\n     has_shown_metrics_notification: bool\n-    api_token: str\n+    api_token: Optional[str]\n     anonymous_user_id: str\n \n \n SettingsKeys = Literal[\n     \"has_shown_metrics_notification\", \"api_token\", \"anonymous_user_id\"\n ]\n \n-DEFAULT_SETTINGS: SettingsSchema = {\"anonymous_user_id\": str(uuid.uuid4())}\n+\n+def generate_anonymous_user_id(api_token: Optional[str]) -> str:\n+    return (\n+        str(uuid.uuid4())\n+        if api_token is None\n+        else str(\n+            uuid.uuid5(\n+                uuid.UUID(\"0\" * 32), hashlib.sha256(api_token.encode()).hexdigest()\n+            )\n+        )\n+    )\n+\n+\n+def generate_default_settings(api_token: Optional[str] = None) -> SettingsSchema:\n+    anonymous_user_id = generate_anonymous_user_id(api_token)\n+    return (\n+        {\n+            \"has_shown_metrics_notification\": False,\n+            \"api_token\": api_token,\n+            \"anonymous_user_id\": anonymous_user_id,\n+        }\n+        if api_token is not None\n+        else {\n+            \"has_shown_metrics_notification\": False,\n+            \"anonymous_user_id\": anonymous_user_id,\n+        }\n+    )",
        "comment_created_at": "2023-12-07T22:10:17+00:00",
        "comment_author": "zzeleznick",
        "comment_body": "found a better signature \u2013 will commit and push!",
        "pr_file_module": null
      }
    ]
  }
]