[
  {
    "discussion_id": "2159464343",
    "pr_number": 93963,
    "pr_file": "src/sentry/replays/usecases/ingest/event_parser.py",
    "created_at": "2025-06-20T18:03:29+00:00",
    "commented_code": "duration = payload[\"endTimestamp\"] - payload[\"startTimestamp\"]\n             method = payload[\"data\"][\"method\"]\n \n+            # if status code is successful, ignore it",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2159464343",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 93963,
        "pr_file": "src/sentry/replays/usecases/ingest/event_parser.py",
        "discussion_id": "2159464343",
        "commented_code": "@@ -214,6 +214,10 @@ def as_log_message(event: dict[str, Any]) -> str | None:\n             duration = payload[\"endTimestamp\"] - payload[\"startTimestamp\"]\n             method = payload[\"data\"][\"method\"]\n \n+            # if status code is successful, ignore it",
        "comment_created_at": "2025-06-20T18:03:29+00:00",
        "comment_author": "michellewzhang",
        "comment_body": "one thought i had was if this `as_log_message` function were to be reused somewhere else in the future, this might not be very flexible",
        "pr_file_module": null
      },
      {
        "comment_id": "2159466004",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 93963,
        "pr_file": "src/sentry/replays/usecases/ingest/event_parser.py",
        "discussion_id": "2159464343",
        "commented_code": "@@ -214,6 +214,10 @@ def as_log_message(event: dict[str, Any]) -> str | None:\n             duration = payload[\"endTimestamp\"] - payload[\"startTimestamp\"]\n             method = payload[\"data\"][\"method\"]\n \n+            # if status code is successful, ignore it",
        "comment_created_at": "2025-06-20T18:05:07+00:00",
        "comment_author": "cmanallen",
        "comment_body": "It might be better to move this function to the AI endpoint module to make this connection more apparent.  This is not a generic function.  It has a specific use case.",
        "pr_file_module": null
      },
      {
        "comment_id": "2159469138",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 93963,
        "pr_file": "src/sentry/replays/usecases/ingest/event_parser.py",
        "discussion_id": "2159464343",
        "commented_code": "@@ -214,6 +214,10 @@ def as_log_message(event: dict[str, Any]) -> str | None:\n             duration = payload[\"endTimestamp\"] - payload[\"startTimestamp\"]\n             method = payload[\"data\"][\"method\"]\n \n+            # if status code is successful, ignore it",
        "comment_created_at": "2025-06-20T18:07:56+00:00",
        "comment_author": "michellewzhang",
        "comment_body": "makes sense üëç ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2140416267",
    "pr_number": 93134,
    "pr_file": "src/sentry/feedback/usecases/feedback_summaries.py",
    "created_at": "2025-06-11T14:54:21+00:00",
    "commented_code": "+import logging\n+import re\n+\n+from sentry.llm.usecases import LLMUseCase, complete_prompt\n+from sentry.utils import metrics\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+def make_input_prompt(\n+    feedbacks,\n+):\n+    feedbacks_string = \"\n\".join(f\"- {msg}\" for msg in feedbacks)\n+    return f\"\"\"Task:\n+Instructions: You are an AI assistant that analyzes customer feedback.\n+Create a summary based on the user feedbacks that is at most three sentences, and complete the sentence \"Users say...\". Be concise, but specific in the summary.\n+\n+User Feedbacks:\n+\n+{feedbacks_string}\n+\n+Output Format:\n+\n+Summary: <1-3 sentence summary>\n+\"\"\"",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2140416267",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 93134,
        "pr_file": "src/sentry/feedback/usecases/feedback_summaries.py",
        "discussion_id": "2140416267",
        "commented_code": "@@ -0,0 +1,59 @@\n+import logging\n+import re\n+\n+from sentry.llm.usecases import LLMUseCase, complete_prompt\n+from sentry.utils import metrics\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+def make_input_prompt(\n+    feedbacks,\n+):\n+    feedbacks_string = \"\\n\".join(f\"- {msg}\" for msg in feedbacks)\n+    return f\"\"\"Task:\n+Instructions: You are an AI assistant that analyzes customer feedback.\n+Create a summary based on the user feedbacks that is at most three sentences, and complete the sentence \"Users say...\". Be concise, but specific in the summary.\n+\n+User Feedbacks:\n+\n+{feedbacks_string}\n+\n+Output Format:\n+\n+Summary: <1-3 sentence summary>\n+\"\"\"",
        "comment_created_at": "2025-06-11T14:54:21+00:00",
        "comment_author": "cmanallen",
        "comment_body": "Be aware.  The AI team wants everything prompt related in Seer.  I think its low risk to leave this here for now.  But a future refactor should be considered where you proxy Seer.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2140420859",
    "pr_number": 93134,
    "pr_file": "src/sentry/feedback/usecases/feedback_summaries.py",
    "created_at": "2025-06-11T14:56:15+00:00",
    "commented_code": "+import logging\n+import re\n+\n+from sentry.llm.usecases import LLMUseCase, complete_prompt\n+from sentry.utils import metrics\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+def make_input_prompt(\n+    feedbacks,\n+):\n+    feedbacks_string = \"\n\".join(f\"- {msg}\" for msg in feedbacks)\n+    return f\"\"\"Task:\n+Instructions: You are an AI assistant that analyzes customer feedback.\n+Create a summary based on the user feedbacks that is at most three sentences, and complete the sentence \"Users say...\". Be concise, but specific in the summary.\n+\n+User Feedbacks:\n+\n+{feedbacks_string}\n+\n+Output Format:\n+\n+Summary: <1-3 sentence summary>\n+\"\"\"\n+\n+\n+SUMMARY_REGEX = re.compile(r\"Summary:\\s*(.*)\", re.DOTALL)",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2140420859",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 93134,
        "pr_file": "src/sentry/feedback/usecases/feedback_summaries.py",
        "discussion_id": "2140420859",
        "commented_code": "@@ -0,0 +1,59 @@\n+import logging\n+import re\n+\n+from sentry.llm.usecases import LLMUseCase, complete_prompt\n+from sentry.utils import metrics\n+\n+logger = logging.getLogger(__name__)\n+\n+\n+def make_input_prompt(\n+    feedbacks,\n+):\n+    feedbacks_string = \"\\n\".join(f\"- {msg}\" for msg in feedbacks)\n+    return f\"\"\"Task:\n+Instructions: You are an AI assistant that analyzes customer feedback.\n+Create a summary based on the user feedbacks that is at most three sentences, and complete the sentence \"Users say...\". Be concise, but specific in the summary.\n+\n+User Feedbacks:\n+\n+{feedbacks_string}\n+\n+Output Format:\n+\n+Summary: <1-3 sentence summary>\n+\"\"\"\n+\n+\n+SUMMARY_REGEX = re.compile(r\"Summary:\\s*(.*)\", re.DOTALL)",
        "comment_created_at": "2025-06-11T14:56:15+00:00",
        "comment_author": "cmanallen",
        "comment_body": "This is fine for now.  But we can get structured output.  There's many examples in Seer.  Here's one I recently wrote: https://github.com/getsentry/seer/pull/2741/files#diff-798e03ed205a63e1198b21d0837bef5af0862f83704afafb084d68cff456ee4eR220-R251",
        "pr_file_module": null
      }
    ]
  }
]