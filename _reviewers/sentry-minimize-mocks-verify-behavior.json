[
  {
    "discussion_id": "2157582140",
    "pr_number": 93914,
    "pr_file": "tests/sentry/api/endpoints/test_seer_rpc.py",
    "created_at": "2025-06-19T19:47:56+00:00",
    "commented_code": "path, data=data, HTTP_AUTHORIZATION=self.auth_header(path, data)\n         )\n         assert response.status_code == 404\n+\n+\n+class TestSeerRpcMethods(APITestCase):\n+    \"\"\"Test individual RPC methods\"\"\"\n+\n+    def setUp(self):\n+        super().setUp()\n+        self.organization = self.create_organization()\n+\n+    @patch(\"sentry.api.endpoints.seer_rpc.integration_service.get_organization_integrations\")",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2157582140",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 93914,
        "pr_file": "tests/sentry/api/endpoints/test_seer_rpc.py",
        "discussion_id": "2157582140",
        "commented_code": "@@ -36,3 +40,189 @@ def test_404(self):\n             path, data=data, HTTP_AUTHORIZATION=self.auth_header(path, data)\n         )\n         assert response.status_code == 404\n+\n+\n+class TestSeerRpcMethods(APITestCase):\n+    \"\"\"Test individual RPC methods\"\"\"\n+\n+    def setUp(self):\n+        super().setUp()\n+        self.organization = self.create_organization()\n+\n+    @patch(\"sentry.api.endpoints.seer_rpc.integration_service.get_organization_integrations\")",
        "comment_created_at": "2025-06-19T19:47:56+00:00",
        "comment_author": "markstory",
        "comment_body": "Why mock? You could setup an integration + org_integration and have higher confidence that your logic works.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2157584105",
    "pr_number": 93914,
    "pr_file": "tests/sentry/api/endpoints/test_seer_rpc.py",
    "created_at": "2025-06-19T19:50:18+00:00",
    "commented_code": "path, data=data, HTTP_AUTHORIZATION=self.auth_header(path, data)\n         )\n         assert response.status_code == 404\n+\n+\n+class TestSeerRpcMethods(APITestCase):\n+    \"\"\"Test individual RPC methods\"\"\"\n+\n+    def setUp(self):\n+        super().setUp()\n+        self.organization = self.create_organization()\n+\n+    @patch(\"sentry.api.endpoints.seer_rpc.integration_service.get_organization_integrations\")\n+    def test_get_organization_seer_consent_by_org_name_no_integrations(self, mock_get_integrations):\n+        \"\"\"Test when no organization integrations are found\"\"\"\n+        mock_get_integrations.return_value = []\n+\n+        result = get_organization_seer_consent_by_org_name(org_name=\"test-org\")\n+\n+        assert result == {\"consent\": False}\n+        mock_get_integrations.assert_called_once_with(provider=\"github\", name=\"test-org\")\n+\n+    @patch(\"sentry.api.endpoints.seer_rpc.options.get\")\n+    @patch(\"sentry.api.endpoints.seer_rpc.get_seer_org_acknowledgement\")\n+    @patch(\"sentry.api.endpoints.seer_rpc.integration_service.get_organization_integrations\")\n+    def test_get_organization_seer_consent_by_org_name_no_consent(\n+        self, mock_get_integrations, mock_get_acknowledgement, mock_options_get\n+    ):\n+        \"\"\"Test when organization exists but has no consent\"\"\"\n+        from unittest.mock import Mock\n+\n+        mock_integration = Mock()\n+        mock_integration.organization_id = self.organization.id\n+        mock_get_integrations.return_value = [mock_integration]\n+        mock_get_acknowledgement.return_value = False\n+        mock_options_get.return_value = []  # No orgs in github-extension.enabled-orgs",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2157584105",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 93914,
        "pr_file": "tests/sentry/api/endpoints/test_seer_rpc.py",
        "discussion_id": "2157584105",
        "commented_code": "@@ -36,3 +40,189 @@ def test_404(self):\n             path, data=data, HTTP_AUTHORIZATION=self.auth_header(path, data)\n         )\n         assert response.status_code == 404\n+\n+\n+class TestSeerRpcMethods(APITestCase):\n+    \"\"\"Test individual RPC methods\"\"\"\n+\n+    def setUp(self):\n+        super().setUp()\n+        self.organization = self.create_organization()\n+\n+    @patch(\"sentry.api.endpoints.seer_rpc.integration_service.get_organization_integrations\")\n+    def test_get_organization_seer_consent_by_org_name_no_integrations(self, mock_get_integrations):\n+        \"\"\"Test when no organization integrations are found\"\"\"\n+        mock_get_integrations.return_value = []\n+\n+        result = get_organization_seer_consent_by_org_name(org_name=\"test-org\")\n+\n+        assert result == {\"consent\": False}\n+        mock_get_integrations.assert_called_once_with(provider=\"github\", name=\"test-org\")\n+\n+    @patch(\"sentry.api.endpoints.seer_rpc.options.get\")\n+    @patch(\"sentry.api.endpoints.seer_rpc.get_seer_org_acknowledgement\")\n+    @patch(\"sentry.api.endpoints.seer_rpc.integration_service.get_organization_integrations\")\n+    def test_get_organization_seer_consent_by_org_name_no_consent(\n+        self, mock_get_integrations, mock_get_acknowledgement, mock_options_get\n+    ):\n+        \"\"\"Test when organization exists but has no consent\"\"\"\n+        from unittest.mock import Mock\n+\n+        mock_integration = Mock()\n+        mock_integration.organization_id = self.organization.id\n+        mock_get_integrations.return_value = [mock_integration]\n+        mock_get_acknowledgement.return_value = False\n+        mock_options_get.return_value = []  # No orgs in github-extension.enabled-orgs",
        "comment_created_at": "2025-06-19T19:50:18+00:00",
        "comment_author": "markstory",
        "comment_body": "Tests with this many mocks can end up passing even when the actual logic is broken. Personally, I would use fewer mocks.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2159117141",
    "pr_number": 93914,
    "pr_file": "tests/sentry/api/endpoints/test_seer_rpc.py",
    "created_at": "2025-06-20T14:27:25+00:00",
    "commented_code": "path, data=data, HTTP_AUTHORIZATION=self.auth_header(path, data)\n         )\n         assert response.status_code == 404\n+\n+\n+class TestSeerRpcMethods(APITestCase):\n+    \"\"\"Test individual RPC methods\"\"\"\n+\n+    def setUp(self):\n+        super().setUp()\n+        self.organization = self.create_organization(owner=self.user)\n+\n+    def _create_options_get_side_effect(self, enabled_orgs=None):\n+        \"\"\"Helper to create a side effect function for options.get mock\"\"\"\n+\n+        def side_effect(key):\n+            if key == \"github-extension.enabled-orgs\":\n+                return enabled_orgs or []\n+            return []\n+\n+        return side_effect\n+\n+    def test_get_organization_seer_consent_by_org_name_no_integrations(self):\n+        \"\"\"Test when no organization integrations are found\"\"\"\n+        # Test with a non-existent organization name\n+        result = get_organization_seer_consent_by_org_name(org_name=\"non-existent-org\")\n+        assert result == {\"consent\": False}\n+\n+    @patch(\"sentry.api.endpoints.seer_rpc.options.get\")",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2159117141",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 93914,
        "pr_file": "tests/sentry/api/endpoints/test_seer_rpc.py",
        "discussion_id": "2159117141",
        "commented_code": "@@ -36,3 +40,188 @@ def test_404(self):\n             path, data=data, HTTP_AUTHORIZATION=self.auth_header(path, data)\n         )\n         assert response.status_code == 404\n+\n+\n+class TestSeerRpcMethods(APITestCase):\n+    \"\"\"Test individual RPC methods\"\"\"\n+\n+    def setUp(self):\n+        super().setUp()\n+        self.organization = self.create_organization(owner=self.user)\n+\n+    def _create_options_get_side_effect(self, enabled_orgs=None):\n+        \"\"\"Helper to create a side effect function for options.get mock\"\"\"\n+\n+        def side_effect(key):\n+            if key == \"github-extension.enabled-orgs\":\n+                return enabled_orgs or []\n+            return []\n+\n+        return side_effect\n+\n+    def test_get_organization_seer_consent_by_org_name_no_integrations(self):\n+        \"\"\"Test when no organization integrations are found\"\"\"\n+        # Test with a non-existent organization name\n+        result = get_organization_seer_consent_by_org_name(org_name=\"non-existent-org\")\n+        assert result == {\"consent\": False}\n+\n+    @patch(\"sentry.api.endpoints.seer_rpc.options.get\")",
        "comment_created_at": "2025-06-20T14:27:25+00:00",
        "comment_author": "markstory",
        "comment_body": "Instead of mocking `options.get()` use `@override_options`. Mocking all option gets will make this test brittle in the future.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2190759765",
    "pr_number": 94500,
    "pr_file": "tests/sentry/api/endpoints/test_seer_rpc.py",
    "created_at": "2025-07-07T18:14:27+00:00",
    "commented_code": "assert result == {\"consent\": True}\n         # Should be called twice (checks both existing orgs)\n         assert mock_get_acknowledgement.call_count == 2\n+\n+    @responses.activate\n+    @override_settings(SEER_API_SHARED_SECRET=TEST_FERNET_KEY)\n+    @assume_test_silo_mode(SiloMode.CONTROL)\n+    @patch(\"sentry.integrations.github_enterprise.client.get_jwt\", return_value=\"jwt_token_1\")\n+    def test_get_github_enterprise_integration_config(self, mock_get_jwt):\n+        \"\"\"Test when organization has github enterprise integration\"\"\"\n+\n+        installation_id = 1234\n+        private_key = \"private_key_1\"\n+        access_token = \"access_token_1\"\n+        responses.add(\n+            responses.POST,\n+            f\"https://github.example.org/api/v3/app/installations/{installation_id}/access_tokens\",\n+            json={\"token\": access_token, \"expires_at\": \"3000-01-01T00:00:00Z\"},\n+        )\n+\n+        # Create a GitHub Enterprise integration\n+        integration = self.create_integration(\n+            organization=self.organization,\n+            provider=\"github_enterprise\",\n+            external_id=\"github_external_id\",\n+            metadata={\n+                \"domain_name\": \"github.example.org\",\n+                \"installation\": {\n+                    \"private_key\": private_key,\n+                    \"id\": 1,\n+                    \"verify_ssl\": True,\n+                },\n+                \"installation_id\": installation_id,\n+            },\n+        )\n+\n+        result = get_github_enterprise_integration_config(\n+            organization_id=self.organization.id,\n+            integration_id=integration.id,\n+        )\n+        assert result[\"base_url\"] == \"https://github.example.org/api/v3\"\n+        assert result[\"verify_ssl\"]\n+        assert result[\"encrypted_access_token\"]\n+\n+        # Test that the access token is encrypted correctly\n+        fernet = Fernet(base64.urlsafe_b64encode(TEST_FERNET_KEY.encode(\"utf-8\")))\n+        decrypted_access_token = fernet.decrypt(\n+            result[\"encrypted_access_token\"].encode(\"utf-8\")\n+        ).decode(\"utf-8\")\n+\n+        assert decrypted_access_token == access_token\n+\n+        mock_get_jwt.assert_called_once_with(github_id=1, github_private_key=private_key)\n+\n+        # Test with invalid integration_id\n+        with pytest.raises(Integration.DoesNotExist):\n+            get_github_enterprise_integration_config(\n+                organization_id=self.organization.id,\n+                integration_id=-1,\n+            )\n+\n+        # Test with invalid organization_id\n+        with pytest.raises(Integration.DoesNotExist):\n+            get_github_enterprise_integration_config(\n+                organization_id=-1,\n+                integration_id=integration.id,\n+            )\n+\n+        # Test with disabled integration\n+        integration.status = ObjectStatus.DISABLED\n+        integration.save()\n+\n+        with pytest.raises(Integration.DoesNotExist):\n+            get_github_enterprise_integration_config(\n+                organization_id=self.organization.id,\n+                integration_id=integration.id,\n+            )",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2190759765",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 94500,
        "pr_file": "tests/sentry/api/endpoints/test_seer_rpc.py",
        "discussion_id": "2190759765",
        "commented_code": "@@ -198,3 +210,77 @@ def test_get_organization_seer_consent_by_org_name_mixed_scenarios(\n         assert result == {\"consent\": True}\n         # Should be called twice (checks both existing orgs)\n         assert mock_get_acknowledgement.call_count == 2\n+\n+    @responses.activate\n+    @override_settings(SEER_API_SHARED_SECRET=TEST_FERNET_KEY)\n+    @assume_test_silo_mode(SiloMode.CONTROL)\n+    @patch(\"sentry.integrations.github_enterprise.client.get_jwt\", return_value=\"jwt_token_1\")\n+    def test_get_github_enterprise_integration_config(self, mock_get_jwt):\n+        \"\"\"Test when organization has github enterprise integration\"\"\"\n+\n+        installation_id = 1234\n+        private_key = \"private_key_1\"\n+        access_token = \"access_token_1\"\n+        responses.add(\n+            responses.POST,\n+            f\"https://github.example.org/api/v3/app/installations/{installation_id}/access_tokens\",\n+            json={\"token\": access_token, \"expires_at\": \"3000-01-01T00:00:00Z\"},\n+        )\n+\n+        # Create a GitHub Enterprise integration\n+        integration = self.create_integration(\n+            organization=self.organization,\n+            provider=\"github_enterprise\",\n+            external_id=\"github_external_id\",\n+            metadata={\n+                \"domain_name\": \"github.example.org\",\n+                \"installation\": {\n+                    \"private_key\": private_key,\n+                    \"id\": 1,\n+                    \"verify_ssl\": True,\n+                },\n+                \"installation_id\": installation_id,\n+            },\n+        )\n+\n+        result = get_github_enterprise_integration_config(\n+            organization_id=self.organization.id,\n+            integration_id=integration.id,\n+        )\n+        assert result[\"base_url\"] == \"https://github.example.org/api/v3\"\n+        assert result[\"verify_ssl\"]\n+        assert result[\"encrypted_access_token\"]\n+\n+        # Test that the access token is encrypted correctly\n+        fernet = Fernet(base64.urlsafe_b64encode(TEST_FERNET_KEY.encode(\"utf-8\")))\n+        decrypted_access_token = fernet.decrypt(\n+            result[\"encrypted_access_token\"].encode(\"utf-8\")\n+        ).decode(\"utf-8\")\n+\n+        assert decrypted_access_token == access_token\n+\n+        mock_get_jwt.assert_called_once_with(github_id=1, github_private_key=private_key)\n+\n+        # Test with invalid integration_id\n+        with pytest.raises(Integration.DoesNotExist):\n+            get_github_enterprise_integration_config(\n+                organization_id=self.organization.id,\n+                integration_id=-1,\n+            )\n+\n+        # Test with invalid organization_id\n+        with pytest.raises(Integration.DoesNotExist):\n+            get_github_enterprise_integration_config(\n+                organization_id=-1,\n+                integration_id=integration.id,\n+            )\n+\n+        # Test with disabled integration\n+        integration.status = ObjectStatus.DISABLED\n+        integration.save()\n+\n+        with pytest.raises(Integration.DoesNotExist):\n+            get_github_enterprise_integration_config(\n+                organization_id=self.organization.id,\n+                integration_id=integration.id,\n+            )",
        "comment_created_at": "2025-07-07T18:14:27+00:00",
        "comment_author": "mdtro",
        "comment_body": "These should be broken out into separate tests. It'll make it easier to identify the issue if one of these breaks.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2180899456",
    "pr_number": 94818,
    "pr_file": "tests/sentry/tasks/test_delete_seer_grouping_records.py",
    "created_at": "2025-07-02T20:16:53+00:00",
    "commented_code": "\"args\": [project_id, hashes, 100]\n         }\n \n-    @patch(\"sentry.tasks.delete_seer_grouping_records.logger\")\n-    def test_call_delete_seer_grouping_records_by_hash_simple(self, mock_logger):\n+    @patch(\n+        \"sentry.tasks.delete_seer_grouping_records.delete_seer_grouping_records_by_hash.apply_async\"\n+    )\n+    def test_call_delete_seer_grouping_records_by_hash_simple(\n+        self, mock_apply_async: MagicMock\n+    ) -> None:\n+        \"\"\"\n+        Test that call_delete_seer_grouping_records_by_hash correctly collects hashes\n+        and calls the deletion task with the expected parameters.\n+        \"\"\"\n         self.project.update_option(\"sentry:similarity_backfill_completed\", int(time()))\n \n-        group_ids, hashes = [], []\n+        group_ids, expected_hashes = [], []\n         for i in range(5):\n             group = self.create_group(project=self.project)\n             group_ids.append(group.id)\n             group_hash = GroupHash.objects.create(\n                 project=self.project, hash=str(i) * 32, group_id=group.id\n             )\n-            hashes.append(group_hash.hash)\n+            expected_hashes.append(group_hash.hash)\n+\n         call_delete_seer_grouping_records_by_hash(group_ids)\n-        mock_logger.info.assert_called_with(\n-            \"calling seer record deletion by hash\",\n-            extra={\"project_id\": self.project.id, \"hashes\": hashes},\n-        )\n+\n+        # Verify that the task was called with the correct parameters",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2180899456",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 94818,
        "pr_file": "tests/sentry/tasks/test_delete_seer_grouping_records.py",
        "discussion_id": "2180899456",
        "commented_code": "@@ -33,50 +32,41 @@ def test_delete_seer_grouping_records_by_hash_batches(\n             \"args\": [project_id, hashes, 100]\n         }\n \n-    @patch(\"sentry.tasks.delete_seer_grouping_records.logger\")\n-    def test_call_delete_seer_grouping_records_by_hash_simple(self, mock_logger):\n+    @patch(\n+        \"sentry.tasks.delete_seer_grouping_records.delete_seer_grouping_records_by_hash.apply_async\"\n+    )\n+    def test_call_delete_seer_grouping_records_by_hash_simple(\n+        self, mock_apply_async: MagicMock\n+    ) -> None:\n+        \"\"\"\n+        Test that call_delete_seer_grouping_records_by_hash correctly collects hashes\n+        and calls the deletion task with the expected parameters.\n+        \"\"\"\n         self.project.update_option(\"sentry:similarity_backfill_completed\", int(time()))\n \n-        group_ids, hashes = [], []\n+        group_ids, expected_hashes = [], []\n         for i in range(5):\n             group = self.create_group(project=self.project)\n             group_ids.append(group.id)\n             group_hash = GroupHash.objects.create(\n                 project=self.project, hash=str(i) * 32, group_id=group.id\n             )\n-            hashes.append(group_hash.hash)\n+            expected_hashes.append(group_hash.hash)\n+\n         call_delete_seer_grouping_records_by_hash(group_ids)\n-        mock_logger.info.assert_called_with(\n-            \"calling seer record deletion by hash\",\n-            extra={\"project_id\": self.project.id, \"hashes\": hashes},\n-        )\n+\n+        # Verify that the task was called with the correct parameters",
        "comment_created_at": "2025-07-02T20:16:53+00:00",
        "comment_author": "seer-by-sentry[bot]",
        "comment_body": "The test method has been significantly improved. The new implementation properly verifies the actual behavior (task scheduling) rather than just logging. However, consider testing both the happy path and edge cases more thoroughly.\n```suggestion\n# Consider adding additional assertions:\n# 1. Verify mock_apply_async was called exactly once\n# 2. Check that the hashes list contains expected values\n# 3. Test with different numbers of groups (0, 1, many)\nassert mock_apply_async.call_count == 1\nassert len(expected_hashes) == 5\nassert all(isinstance(h, str) and len(h) == 32 for h in expected_hashes)\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2180910124",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 94818,
        "pr_file": "tests/sentry/tasks/test_delete_seer_grouping_records.py",
        "discussion_id": "2180899456",
        "commented_code": "@@ -33,50 +32,41 @@ def test_delete_seer_grouping_records_by_hash_batches(\n             \"args\": [project_id, hashes, 100]\n         }\n \n-    @patch(\"sentry.tasks.delete_seer_grouping_records.logger\")\n-    def test_call_delete_seer_grouping_records_by_hash_simple(self, mock_logger):\n+    @patch(\n+        \"sentry.tasks.delete_seer_grouping_records.delete_seer_grouping_records_by_hash.apply_async\"\n+    )\n+    def test_call_delete_seer_grouping_records_by_hash_simple(\n+        self, mock_apply_async: MagicMock\n+    ) -> None:\n+        \"\"\"\n+        Test that call_delete_seer_grouping_records_by_hash correctly collects hashes\n+        and calls the deletion task with the expected parameters.\n+        \"\"\"\n         self.project.update_option(\"sentry:similarity_backfill_completed\", int(time()))\n \n-        group_ids, hashes = [], []\n+        group_ids, expected_hashes = [], []\n         for i in range(5):\n             group = self.create_group(project=self.project)\n             group_ids.append(group.id)\n             group_hash = GroupHash.objects.create(\n                 project=self.project, hash=str(i) * 32, group_id=group.id\n             )\n-            hashes.append(group_hash.hash)\n+            expected_hashes.append(group_hash.hash)\n+\n         call_delete_seer_grouping_records_by_hash(group_ids)\n-        mock_logger.info.assert_called_with(\n-            \"calling seer record deletion by hash\",\n-            extra={\"project_id\": self.project.id, \"hashes\": hashes},\n-        )\n+\n+        # Verify that the task was called with the correct parameters",
        "comment_created_at": "2025-07-02T20:23:57+00:00",
        "comment_author": "armenzg",
        "comment_body": "`assert_called_once_with()` does what you suggest.",
        "pr_file_module": null
      },
      {
        "comment_id": "2183410906",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 94818,
        "pr_file": "tests/sentry/tasks/test_delete_seer_grouping_records.py",
        "discussion_id": "2180899456",
        "commented_code": "@@ -33,50 +32,41 @@ def test_delete_seer_grouping_records_by_hash_batches(\n             \"args\": [project_id, hashes, 100]\n         }\n \n-    @patch(\"sentry.tasks.delete_seer_grouping_records.logger\")\n-    def test_call_delete_seer_grouping_records_by_hash_simple(self, mock_logger):\n+    @patch(\n+        \"sentry.tasks.delete_seer_grouping_records.delete_seer_grouping_records_by_hash.apply_async\"\n+    )\n+    def test_call_delete_seer_grouping_records_by_hash_simple(\n+        self, mock_apply_async: MagicMock\n+    ) -> None:\n+        \"\"\"\n+        Test that call_delete_seer_grouping_records_by_hash correctly collects hashes\n+        and calls the deletion task with the expected parameters.\n+        \"\"\"\n         self.project.update_option(\"sentry:similarity_backfill_completed\", int(time()))\n \n-        group_ids, hashes = [], []\n+        group_ids, expected_hashes = [], []\n         for i in range(5):\n             group = self.create_group(project=self.project)\n             group_ids.append(group.id)\n             group_hash = GroupHash.objects.create(\n                 project=self.project, hash=str(i) * 32, group_id=group.id\n             )\n-            hashes.append(group_hash.hash)\n+            expected_hashes.append(group_hash.hash)\n+\n         call_delete_seer_grouping_records_by_hash(group_ids)\n-        mock_logger.info.assert_called_with(\n-            \"calling seer record deletion by hash\",\n-            extra={\"project_id\": self.project.id, \"hashes\": hashes},\n-        )\n+\n+        # Verify that the task was called with the correct parameters",
        "comment_created_at": "2025-07-03T17:56:34+00:00",
        "comment_author": "armenzg",
        "comment_body": "Also the suggested fix is not respecting Python indentation.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2180899506",
    "pr_number": 94818,
    "pr_file": "tests/sentry/tasks/test_delete_seer_grouping_records.py",
    "created_at": "2025-07-02T20:16:55+00:00",
    "commented_code": "\"args\": [project_id, hashes, 100]\n         }\n \n-    @patch(\"sentry.tasks.delete_seer_grouping_records.logger\")\n-    def test_call_delete_seer_grouping_records_by_hash_simple(self, mock_logger):\n+    @patch(\n+        \"sentry.tasks.delete_seer_grouping_records.delete_seer_grouping_records_by_hash.apply_async\"\n+    )\n+    def test_call_delete_seer_grouping_records_by_hash_simple(\n+        self, mock_apply_async: MagicMock\n+    ) -> None:\n+        \"\"\"\n+        Test that call_delete_seer_grouping_records_by_hash correctly collects hashes\n+        and calls the deletion task with the expected parameters.\n+        \"\"\"\n         self.project.update_option(\"sentry:similarity_backfill_completed\", int(time()))\n \n-        group_ids, hashes = [], []\n+        group_ids, expected_hashes = [], []\n         for i in range(5):\n             group = self.create_group(project=self.project)\n             group_ids.append(group.id)\n             group_hash = GroupHash.objects.create(\n                 project=self.project, hash=str(i) * 32, group_id=group.id\n             )\n-            hashes.append(group_hash.hash)\n+            expected_hashes.append(group_hash.hash)\n+\n         call_delete_seer_grouping_records_by_hash(group_ids)\n-        mock_logger.info.assert_called_with(\n-            \"calling seer record deletion by hash\",\n-            extra={\"project_id\": self.project.id, \"hashes\": hashes},\n-        )\n+\n+        # Verify that the task was called with the correct parameters\n+        mock_apply_async.assert_called_once_with(args=[self.project.id, expected_hashes, 0])\n \n     @patch(\"sentry.tasks.delete_seer_grouping_records.delete_seer_grouping_records_by_hash\")\n-    @patch(\"sentry.tasks.delete_seer_grouping_records.logger\")\n     def test_call_delete_seer_grouping_records_by_hash_no_hashes(\n-        self, mock_logger, mock_delete_seer_grouping_records_by_hash\n-    ):\n+        self, mock_delete_seer_grouping_records_by_hash: MagicMock\n+    ) -> None:\n         self.project.update_option(\"sentry:similarity_backfill_completed\", int(time()))\n \n         group_ids = []\n         for _ in range(5):\n             group = self.create_group(project=self.project)\n             group_ids.append(group.id)\n         call_delete_seer_grouping_records_by_hash(group_ids)\n-        mock_logger.info.assert_called_with(\n-            \"calling seer record deletion by hash\",\n-            extra={\"project_id\": self.project.id, \"hashes\": []},\n-        )\n         mock_delete_seer_grouping_records_by_hash.assert_not_called()",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2180899506",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 94818,
        "pr_file": "tests/sentry/tasks/test_delete_seer_grouping_records.py",
        "discussion_id": "2180899506",
        "commented_code": "@@ -33,50 +32,41 @@ def test_delete_seer_grouping_records_by_hash_batches(\n             \"args\": [project_id, hashes, 100]\n         }\n \n-    @patch(\"sentry.tasks.delete_seer_grouping_records.logger\")\n-    def test_call_delete_seer_grouping_records_by_hash_simple(self, mock_logger):\n+    @patch(\n+        \"sentry.tasks.delete_seer_grouping_records.delete_seer_grouping_records_by_hash.apply_async\"\n+    )\n+    def test_call_delete_seer_grouping_records_by_hash_simple(\n+        self, mock_apply_async: MagicMock\n+    ) -> None:\n+        \"\"\"\n+        Test that call_delete_seer_grouping_records_by_hash correctly collects hashes\n+        and calls the deletion task with the expected parameters.\n+        \"\"\"\n         self.project.update_option(\"sentry:similarity_backfill_completed\", int(time()))\n \n-        group_ids, hashes = [], []\n+        group_ids, expected_hashes = [], []\n         for i in range(5):\n             group = self.create_group(project=self.project)\n             group_ids.append(group.id)\n             group_hash = GroupHash.objects.create(\n                 project=self.project, hash=str(i) * 32, group_id=group.id\n             )\n-            hashes.append(group_hash.hash)\n+            expected_hashes.append(group_hash.hash)\n+\n         call_delete_seer_grouping_records_by_hash(group_ids)\n-        mock_logger.info.assert_called_with(\n-            \"calling seer record deletion by hash\",\n-            extra={\"project_id\": self.project.id, \"hashes\": hashes},\n-        )\n+\n+        # Verify that the task was called with the correct parameters\n+        mock_apply_async.assert_called_once_with(args=[self.project.id, expected_hashes, 0])\n \n     @patch(\"sentry.tasks.delete_seer_grouping_records.delete_seer_grouping_records_by_hash\")\n-    @patch(\"sentry.tasks.delete_seer_grouping_records.logger\")\n     def test_call_delete_seer_grouping_records_by_hash_no_hashes(\n-        self, mock_logger, mock_delete_seer_grouping_records_by_hash\n-    ):\n+        self, mock_delete_seer_grouping_records_by_hash: MagicMock\n+    ) -> None:\n         self.project.update_option(\"sentry:similarity_backfill_completed\", int(time()))\n \n         group_ids = []\n         for _ in range(5):\n             group = self.create_group(project=self.project)\n             group_ids.append(group.id)\n         call_delete_seer_grouping_records_by_hash(group_ids)\n-        mock_logger.info.assert_called_with(\n-            \"calling seer record deletion by hash\",\n-            extra={\"project_id\": self.project.id, \"hashes\": []},\n-        )\n         mock_delete_seer_grouping_records_by_hash.assert_not_called()",
        "comment_created_at": "2025-07-02T20:16:55+00:00",
        "comment_author": "seer-by-sentry[bot]",
        "comment_body": "The updated test method removes the logger assertion, which aligns with the code changes. However, consider verifying that the task is NOT called when there are no hashes, which is the actual important behavior.\n```suggestion\n@patch(\n    \"sentry.tasks.delete_seer_grouping_records.delete_seer_grouping_records_by_hash.apply_async\"\n)\ndef test_call_delete_seer_grouping_records_by_hash_no_hashes(\n    self, mock_apply_async: MagicMock\n) -> None:\n    self.project.update_option(\"sentry:similarity_backfill_completed\", int(time()))\n\n    group_ids = []\n    for _ in range(5):\n        group = self.create_group(project=self.project)\n        group_ids.append(group.id)\n    call_delete_seer_grouping_records_by_hash(group_ids)\n    # Verify the task is not called when no hashes exist\n    mock_apply_async.assert_not_called()\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2183446653",
    "pr_number": 94818,
    "pr_file": "tests/sentry/tasks/test_delete_seer_grouping_records.py",
    "created_at": "2025-07-03T18:08:02+00:00",
    "commented_code": "\"args\": [project_id, hashes, 100]\n         }\n \n-    @patch(\"sentry.tasks.delete_seer_grouping_records.logger\")",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2183446653",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 94818,
        "pr_file": "tests/sentry/tasks/test_delete_seer_grouping_records.py",
        "discussion_id": "2183446653",
        "commented_code": "@@ -33,50 +32,43 @@ def test_delete_seer_grouping_records_by_hash_batches(\n             \"args\": [project_id, hashes, 100]\n         }\n \n-    @patch(\"sentry.tasks.delete_seer_grouping_records.logger\")",
        "comment_created_at": "2025-07-03T18:08:02+00:00",
        "comment_author": "armenzg",
        "comment_body": "Testing the logger does not make sense. We need to test that the task got scheduled.\n\nSee this block:\nhttps://github.com/getsentry/sentry/blob/282f05a21d591bcc4478f94dc20d4c3eb967a98b/src/sentry/tasks/delete_seer_grouping_records.py#L74-L79",
        "pr_file_module": null
      }
    ]
  }
]