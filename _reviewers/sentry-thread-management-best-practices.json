[
  {
    "discussion_id": "2190599993",
    "pr_number": 94722,
    "pr_file": "tools/flake8_plugin.py",
    "created_at": "2025-07-07T16:37:32+00:00",
    "commented_code": "if keyword.arg == \"SENTRY_OPTIONS\":\n                     self.errors.append((keyword.lineno, keyword.col_offset, S011_msg))\n \n+        elif (\n+            (\n+                (\n+                    # ThreadPoolExecutor(...)\n+                    isinstance(node.func, ast.Name)\n+                    and node.func.id == \"ThreadPoolExecutor\"\n+                )\n+                or (\n+                    # concurrent.futures.ThreadPoolExecutor(...)\n+                    isinstance(node.func, ast.Attribute)\n+                    and node.func.attr == \"ThreadPoolExecutor\"\n+                )\n+            )\n+            # it's okay to not name \"immediate\" threadpools\n+            and not self._in_with_item\n+        ):\n+            if \"thread_name_prefix\" not in (kw.arg for kw in node.keywords):\n+                self.errors.append((node.lineno, node.col_offset, S014_msg))",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2190599993",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 94722,
        "pr_file": "tools/flake8_plugin.py",
        "discussion_id": "2190599993",
        "commented_code": "@@ -150,6 +158,25 @@ def visit_Call(self, node: ast.Call) -> None:\n                 if keyword.arg == \"SENTRY_OPTIONS\":\n                     self.errors.append((keyword.lineno, keyword.col_offset, S011_msg))\n \n+        elif (\n+            (\n+                (\n+                    # ThreadPoolExecutor(...)\n+                    isinstance(node.func, ast.Name)\n+                    and node.func.id == \"ThreadPoolExecutor\"\n+                )\n+                or (\n+                    # concurrent.futures.ThreadPoolExecutor(...)\n+                    isinstance(node.func, ast.Attribute)\n+                    and node.func.attr == \"ThreadPoolExecutor\"\n+                )\n+            )\n+            # it's okay to not name \"immediate\" threadpools\n+            and not self._in_with_item\n+        ):\n+            if \"thread_name_prefix\" not in (kw.arg for kw in node.keywords):\n+                self.errors.append((node.lineno, node.col_offset, S014_msg))",
        "comment_created_at": "2025-07-07T16:37:32+00:00",
        "comment_author": "asottile-sentry",
        "comment_body": "```suggestion\r\n            and \"thread_name_prefix\" not in (kw.arg for kw in node.keywords)\r\n        ):\r\n            self.errors.append((node.lineno, node.col_offset, S014_msg))\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2193100882",
    "pr_number": 95013,
    "pr_file": "src/sentry/api/endpoints/seer_rpc.py",
    "created_at": "2025-07-08T17:42:18+00:00",
    "commented_code": ")\n \n             values_response = snuba_rpc.attribute_values_rpc(req)\n-            if field in values:\n-                values[field].update({value for value in values_response.values if value})\n-            else:\n-                values[field] = {value for value in values_response.values if value}\n+            return field, {value for value in values_response.values if value}\n+        return None\n+\n+    timeout_seconds = 1.0\n+    with ThreadPoolExecutor(max_workers=min(len(fields_with_substrings), 10)) as executor:\n+        future_to_field = {\n+            executor.submit(\n+                process_field_with_substring, field_with_substring\n+            ): field_with_substring\n+            for field_with_substring in fields_with_substrings\n+        }\n+\n+        try:\n+            for future in as_completed(future_to_field, timeout=timeout_seconds):\n+                field_with_substring = future_to_field[future]\n+\n+                try:\n+                    result = future.result(timeout=timeout_seconds)",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2193100882",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 95013,
        "pr_file": "src/sentry/api/endpoints/seer_rpc.py",
        "discussion_id": "2193100882",
        "commented_code": "@@ -409,10 +353,46 @@ def get_attribute_values_with_substring(\n             )\n \n             values_response = snuba_rpc.attribute_values_rpc(req)\n-            if field in values:\n-                values[field].update({value for value in values_response.values if value})\n-            else:\n-                values[field] = {value for value in values_response.values if value}\n+            return field, {value for value in values_response.values if value}\n+        return None\n+\n+    timeout_seconds = 1.0\n+    with ThreadPoolExecutor(max_workers=min(len(fields_with_substrings), 10)) as executor:\n+        future_to_field = {\n+            executor.submit(\n+                process_field_with_substring, field_with_substring\n+            ): field_with_substring\n+            for field_with_substring in fields_with_substrings\n+        }\n+\n+        try:\n+            for future in as_completed(future_to_field, timeout=timeout_seconds):\n+                field_with_substring = future_to_field[future]\n+\n+                try:\n+                    result = future.result(timeout=timeout_seconds)",
        "comment_created_at": "2025-07-08T17:42:18+00:00",
        "comment_author": "ram-senth",
        "comment_body": "Minor one - I do not think timeout param is meaningful here when you use `as_completed`.",
        "pr_file_module": null
      },
      {
        "comment_id": "2193113855",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 95013,
        "pr_file": "src/sentry/api/endpoints/seer_rpc.py",
        "discussion_id": "2193100882",
        "commented_code": "@@ -409,10 +353,46 @@ def get_attribute_values_with_substring(\n             )\n \n             values_response = snuba_rpc.attribute_values_rpc(req)\n-            if field in values:\n-                values[field].update({value for value in values_response.values if value})\n-            else:\n-                values[field] = {value for value in values_response.values if value}\n+            return field, {value for value in values_response.values if value}\n+        return None\n+\n+    timeout_seconds = 1.0\n+    with ThreadPoolExecutor(max_workers=min(len(fields_with_substrings), 10)) as executor:\n+        future_to_field = {\n+            executor.submit(\n+                process_field_with_substring, field_with_substring\n+            ): field_with_substring\n+            for field_with_substring in fields_with_substrings\n+        }\n+\n+        try:\n+            for future in as_completed(future_to_field, timeout=timeout_seconds):\n+                field_with_substring = future_to_field[future]\n+\n+                try:\n+                    result = future.result(timeout=timeout_seconds)",
        "comment_created_at": "2025-07-08T17:49:52+00:00",
        "comment_author": "aayush-se",
        "comment_body": "I see, I assume this means that the timeout in `as_completed` takes priority over this one right?\n\nShould I even be using `as_completed` here then in this case? ",
        "pr_file_module": null
      },
      {
        "comment_id": "2195685552",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 95013,
        "pr_file": "src/sentry/api/endpoints/seer_rpc.py",
        "discussion_id": "2193100882",
        "commented_code": "@@ -409,10 +353,46 @@ def get_attribute_values_with_substring(\n             )\n \n             values_response = snuba_rpc.attribute_values_rpc(req)\n-            if field in values:\n-                values[field].update({value for value in values_response.values if value})\n-            else:\n-                values[field] = {value for value in values_response.values if value}\n+            return field, {value for value in values_response.values if value}\n+        return None\n+\n+    timeout_seconds = 1.0\n+    with ThreadPoolExecutor(max_workers=min(len(fields_with_substrings), 10)) as executor:\n+        future_to_field = {\n+            executor.submit(\n+                process_field_with_substring, field_with_substring\n+            ): field_with_substring\n+            for field_with_substring in fields_with_substrings\n+        }\n+\n+        try:\n+            for future in as_completed(future_to_field, timeout=timeout_seconds):\n+                field_with_substring = future_to_field[future]\n+\n+                try:\n+                    result = future.result(timeout=timeout_seconds)",
        "comment_created_at": "2025-07-09T18:08:47+00:00",
        "comment_author": "ram-senth",
        "comment_body": "So the as_completed sets up a listener for each Future that is called when the future has result or timedout. So by the time we get to this result the future is already complete and so timeout is meaningless. Using as_completed is fine as you wont be hung up on the longest call.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2183633547",
    "pr_number": 94885,
    "pr_file": "src/sentry/taskworker/worker.py",
    "created_at": "2025-07-03T19:43:05+00:00",
    "commented_code": "Shutdown cleanly\n         Activate the shutdown event and drain results before terminating children.\n         \"\"\"\n-        if self._shutdown_event.is_set():\n-            return\n-\n-        logger.info(\"taskworker.worker.shutdown\")\n+        logger.info(\"taskworker.worker.shutdown.start\")\n         self._shutdown_event.set()\n \n         for child in self._children:\n             child.terminate()\n-            child.join()\n+\n+        for child in self._children:\n+            child.join(timeout=1.0)\n \n         if self._result_thread:\n-            self._result_thread.join()\n+            self._result_thread.join(timeout=1.0)",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2183633547",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 94885,
        "pr_file": "src/sentry/taskworker/worker.py",
        "discussion_id": "2183633547",
        "commented_code": "@@ -113,30 +120,32 @@ def shutdown(self) -> None:\n         Shutdown cleanly\n         Activate the shutdown event and drain results before terminating children.\n         \"\"\"\n-        if self._shutdown_event.is_set():\n-            return\n-\n-        logger.info(\"taskworker.worker.shutdown\")\n+        logger.info(\"taskworker.worker.shutdown.start\")\n         self._shutdown_event.set()\n \n         for child in self._children:\n             child.terminate()\n-            child.join()\n+\n+        for child in self._children:\n+            child.join(timeout=1.0)\n \n         if self._result_thread:\n-            self._result_thread.join()\n+            self._result_thread.join(timeout=1.0)",
        "comment_created_at": "2025-07-03T19:43:05+00:00",
        "comment_author": "markstory",
        "comment_body": "I added these timeouts to prevent blocking indefinitely.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2183634299",
    "pr_number": 94885,
    "pr_file": "src/sentry/taskworker/worker.py",
    "created_at": "2025-07-03T19:43:43+00:00",
    "commented_code": ")\n                         continue\n \n-        self._result_thread = threading.Thread(target=result_thread)\n+        self._result_thread = threading.Thread(\n+            name=\"send-result\", target=result_thread, daemon=True",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2183634299",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 94885,
        "pr_file": "src/sentry/taskworker/worker.py",
        "discussion_id": "2183634299",
        "commented_code": "@@ -193,7 +202,9 @@ def result_thread() -> None:\n                         )\n                         continue\n \n-        self._result_thread = threading.Thread(target=result_thread)\n+        self._result_thread = threading.Thread(\n+            name=\"send-result\", target=result_thread, daemon=True",
        "comment_created_at": "2025-07-03T19:43:43+00:00",
        "comment_author": "markstory",
        "comment_body": "The threads have daemon=true now as we don't need/want to block the worker shutdown on them.",
        "pr_file_module": null
      }
    ]
  }
]