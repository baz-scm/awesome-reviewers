[
  {
    "discussion_id": "2197662842",
    "pr_number": 95101,
    "pr_file": "src/sentry/api/endpoints/organization_trace.py",
    "created_at": "2025-07-10T12:56:30+00:00",
    "commented_code": "raise Exception(f\"Unknown event encountered in trace: {event.get('event_type')}\")\n \n     def serialize_rpc_event(\n-        self, event: dict[str, Any], group_cache: dict[int, Group]\n+        self, event: dict[str, Any], group_cache: dict[int, Group], additional_attributes: list[str]\n     ) -> SerializedEvent | SerializedIssue:\n         if event.get(\"event_type\") == \"span\":\n+            attributeDict = {\n+                attribute: event[attribute]\n+                for attribute in additional_attributes\n+                if attribute in event\n+            }",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2197662842",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 95101,
        "pr_file": "src/sentry/api/endpoints/organization_trace.py",
        "discussion_id": "2197662842",
        "commented_code": "@@ -165,12 +166,18 @@ def _qualify_short_id(project: str, short_id: int | None) -> str | None:\n             raise Exception(f\"Unknown event encountered in trace: {event.get('event_type')}\")\n \n     def serialize_rpc_event(\n-        self, event: dict[str, Any], group_cache: dict[int, Group]\n+        self, event: dict[str, Any], group_cache: dict[int, Group], additional_attributes: list[str]\n     ) -> SerializedEvent | SerializedIssue:\n         if event.get(\"event_type\") == \"span\":\n+            attributeDict = {\n+                attribute: event[attribute]\n+                for attribute in additional_attributes\n+                if attribute in event\n+            }",
        "comment_created_at": "2025-07-10T12:56:30+00:00",
        "comment_author": "shellmayr",
        "comment_body": "nit: always snake_case in python :) \r\n```suggestion\r\n            attribute_dict = {\r\n                attribute: event[attribute]\r\n                for attribute in additional_attributes\r\n                if attribute in event\r\n            }\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2155697046",
    "pr_number": 93882,
    "pr_file": "src/sentry/workflow_engine/processors/workflow.py",
    "created_at": "2025-06-18T23:10:14+00:00",
    "commented_code": "delayed_conditions: list[DataCondition]\n     event: GroupEvent\n     source: WorkflowDataConditionGroupType\n+    timestamp: datetime",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2155697046",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 93882,
        "pr_file": "src/sentry/workflow_engine/processors/workflow.py",
        "discussion_id": "2155697046",
        "commented_code": "@@ -75,6 +77,7 @@ class DelayedWorkflowItem:\n     delayed_conditions: list[DataCondition]\n     event: GroupEvent\n     source: WorkflowDataConditionGroupType\n+    timestamp: datetime",
        "comment_created_at": "2025-06-18T23:10:14+00:00",
        "comment_author": "kcons",
        "comment_body": "worth explaining what this timestamp is and what it should correspond to. Or, rename the field to make the comment pointless.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2180730169",
    "pr_number": 94604,
    "pr_file": "src/sentry/spans/consumers/process/flusher.py",
    "created_at": "2025-07-02T18:29:57+00:00",
    "commented_code": "logger = logging.getLogger(__name__)\n \n \n+class MultiProducerManager:",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2180730169",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 94604,
        "pr_file": "src/sentry/spans/consumers/process/flusher.py",
        "discussion_id": "2180730169",
        "commented_code": "@@ -26,6 +27,74 @@\n logger = logging.getLogger(__name__)\n \n \n+class MultiProducerManager:",
        "comment_created_at": "2025-07-02T18:29:57+00:00",
        "comment_author": "fpacifici",
        "comment_body": "Hint, Since this is used as a producer (it has a `produce` method) and not only as a manager, why not calling it `MultiProducer` ?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2151172501",
    "pr_number": 93676,
    "pr_file": "src/sentry/workflow_engine/handlers/detector/stateful.py",
    "created_at": "2025-06-17T01:57:32+00:00",
    "commented_code": "**detector_occurrence.evidence_data,\n             \"detector_id\": self.detector.id,\n             \"value\": new_priority,\n+            \"data_source_id\": data_packet.source_id,",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2151172501",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 93676,
        "pr_file": "src/sentry/workflow_engine/handlers/detector/stateful.py",
        "discussion_id": "2151172501",
        "commented_code": "@@ -486,6 +487,7 @@ def _create_decorated_issue_occurrence(\n             **detector_occurrence.evidence_data,\n             \"detector_id\": self.detector.id,\n             \"value\": new_priority,\n+            \"data_source_id\": data_packet.source_id,",
        "comment_created_at": "2025-06-17T01:57:32+00:00",
        "comment_author": "saponifi3d",
        "comment_body": "ðŸ¤” we should probably come up with a different name for this, `data_packet_source_id`? i fear `data_source_id` will be confused with `DataSource.id` -- if we include `packet` it will also be clear that this is coming from the evaluation of a single data packet.",
        "pr_file_module": null
      },
      {
        "comment_id": "2151175105",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 93676,
        "pr_file": "src/sentry/workflow_engine/handlers/detector/stateful.py",
        "discussion_id": "2151172501",
        "commented_code": "@@ -486,6 +487,7 @@ def _create_decorated_issue_occurrence(\n             **detector_occurrence.evidence_data,\n             \"detector_id\": self.detector.id,\n             \"value\": new_priority,\n+            \"data_source_id\": data_packet.source_id,",
        "comment_created_at": "2025-06-17T02:00:38+00:00",
        "comment_author": "iamrajjoshi",
        "comment_body": "good point, i think `data_packet_source_id` is good",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2180818520",
    "pr_number": 94783,
    "pr_file": "src/sentry/preprod/tasks.py",
    "created_at": "2025-07-02T19:24:43+00:00",
    "commented_code": "set_assemble_status(AssembleTask.PREPROD_ARTIFACT, project_id, checksum, ChunkFileState.OK)\n \n \n-@instrumented_task(\n-    name=\"sentry.preprod.tasks.assemble_preprod_artifact_size_analysis\",\n-    queue=\"assemble\",\n-    silo_mode=SiloMode.REGION,\n-    taskworker_config=TaskworkerConfig(\n-        namespace=attachments_tasks,\n-        processing_deadline_duration=30,\n-    ),\n-)\n-def assemble_preprod_artifact_size_analysis(\n-    org_id,\n-    project_id,\n-    checksum,\n-    chunks,\n-    artifact_id=None,\n-    **kwargs,\n-) -> None:\n-    \"\"\"\n-    Creates a size analysis file for a preprod artifact from uploaded chunks.\n-    \"\"\"\n-    from sentry.preprod.models import PreprodArtifact, PreprodArtifactSizeMetrics\n-\n+def _assemble_preprod_artifact(\n+    assemble_task: str,\n+    project_id: int,\n+    org_id: int,\n+    checksum: str,\n+    chunks: Any,\n+    func: Callable[[AssembleResult, Any], None],",
    "repo_full_name": "getsentry/sentry",
    "discussion_comments": [
      {
        "comment_id": "2180818520",
        "repo_full_name": "getsentry/sentry",
        "pr_number": 94783,
        "pr_file": "src/sentry/preprod/tasks.py",
        "discussion_id": "2180818520",
        "commented_code": "@@ -162,140 +170,150 @@ def assemble_preprod_artifact(\n         set_assemble_status(AssembleTask.PREPROD_ARTIFACT, project_id, checksum, ChunkFileState.OK)\n \n \n-@instrumented_task(\n-    name=\"sentry.preprod.tasks.assemble_preprod_artifact_size_analysis\",\n-    queue=\"assemble\",\n-    silo_mode=SiloMode.REGION,\n-    taskworker_config=TaskworkerConfig(\n-        namespace=attachments_tasks,\n-        processing_deadline_duration=30,\n-    ),\n-)\n-def assemble_preprod_artifact_size_analysis(\n-    org_id,\n-    project_id,\n-    checksum,\n-    chunks,\n-    artifact_id=None,\n-    **kwargs,\n-) -> None:\n-    \"\"\"\n-    Creates a size analysis file for a preprod artifact from uploaded chunks.\n-    \"\"\"\n-    from sentry.preprod.models import PreprodArtifact, PreprodArtifactSizeMetrics\n-\n+def _assemble_preprod_artifact(\n+    assemble_task: str,\n+    project_id: int,\n+    org_id: int,\n+    checksum: str,\n+    chunks: Any,\n+    func: Callable[[AssembleResult, Any], None],",
        "comment_created_at": "2025-07-02T19:24:43+00:00",
        "comment_author": "NicoHinderling",
        "comment_body": "can we rename this to `callback` or `next_step`? id much rather those than \"func\"",
        "pr_file_module": null
      }
    ]
  }
]