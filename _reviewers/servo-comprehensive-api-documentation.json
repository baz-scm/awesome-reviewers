[
  {
    "discussion_id": "2443893538",
    "pr_number": 39072,
    "pr_file": "components/compositing/refresh_driver.rs",
    "created_at": "2025-10-20T06:11:52+00:00",
    "commented_code": "* License, v. 2.0. If a copy of the MPL was not distributed with this\n  * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n \n-use std::cell::Cell;\n-use std::collections::hash_map::Values;\n+use std::cell::{Cell, RefCell};\n+use std::rc::Rc;\n use std::sync::Arc;\n use std::sync::atomic::{AtomicBool, Ordering};\n use std::thread::{self, JoinHandle};\n use std::time::Duration;\n \n-use base::id::WebViewId;\n use constellation_traits::EmbedderToConstellationMessage;\n use crossbeam_channel::{Sender, select};\n-use embedder_traits::EventLoopWaker;\n+use embedder_traits::{EventLoopWaker, RefreshDriver};\n use log::warn;\n use timers::{BoxedTimerCallback, TimerEventRequest, TimerScheduler};\n \n+use crate::IOCompositor;\n use crate::compositor::RepaintReason;\n use crate::webview_renderer::WebViewRenderer;\n \n-const FRAME_DURATION: Duration = Duration::from_millis(1000 / 120);\n-\n-/// The [`RefreshDriver`] is responsible for controlling updates to aall `WebView`s\n-/// onscreen presentation. Currently, it only manages controlling animation update\n-/// requests.\n-///\n-/// The implementation is very basic at the moment, only requesting new animation\n-/// frames at a constant time after a repaint.\n-pub(crate) struct RefreshDriver {\n-    /// The channel on which messages can be sent to the Constellation.\n-    pub(crate) constellation_sender: Sender<EmbedderToConstellationMessage>,\n-\n-    /// Whether or not we are currently animating via a timer.\n-    pub(crate) animating: Cell<bool>,\n-\n-    /// Whether or not we are waiting for our frame timeout to trigger\n-    pub(crate) waiting_for_frame_timeout: Arc<AtomicBool>,\n-\n-    /// A [`TimerThread`] which is used to schedule frame timeouts in the future.\n-    timer_thread: TimerThread,\n-\n-    /// An [`EventLoopWaker`] to be used to wake up the embedder when it is\n-    /// time to paint a frame.\n+/// The [`BaseRefreshDriver`] is a \"base class\" for [`RefreshDriver`] trait\n+/// implementations. It encapsulates shared behavior so that it does not have to be\n+/// implemented by all trait implementations. It is responsible for providing\n+/// [`RefreshDriver`] implementations with a callback that is used to wake up the event\n+/// loop and trigger frame readiness.\n+pub(crate) struct BaseRefreshDriver {\n+    waiting_for_frame: Arc<AtomicBool>,",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2443893538",
        "repo_full_name": "servo/servo",
        "pr_number": 39072,
        "pr_file": "components/compositing/refresh_driver.rs",
        "discussion_id": "2443893538",
        "commented_code": "@@ -2,129 +2,141 @@\n  * License, v. 2.0. If a copy of the MPL was not distributed with this\n  * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n \n-use std::cell::Cell;\n-use std::collections::hash_map::Values;\n+use std::cell::{Cell, RefCell};\n+use std::rc::Rc;\n use std::sync::Arc;\n use std::sync::atomic::{AtomicBool, Ordering};\n use std::thread::{self, JoinHandle};\n use std::time::Duration;\n \n-use base::id::WebViewId;\n use constellation_traits::EmbedderToConstellationMessage;\n use crossbeam_channel::{Sender, select};\n-use embedder_traits::EventLoopWaker;\n+use embedder_traits::{EventLoopWaker, RefreshDriver};\n use log::warn;\n use timers::{BoxedTimerCallback, TimerEventRequest, TimerScheduler};\n \n+use crate::IOCompositor;\n use crate::compositor::RepaintReason;\n use crate::webview_renderer::WebViewRenderer;\n \n-const FRAME_DURATION: Duration = Duration::from_millis(1000 / 120);\n-\n-/// The [`RefreshDriver`] is responsible for controlling updates to aall `WebView`s\n-/// onscreen presentation. Currently, it only manages controlling animation update\n-/// requests.\n-///\n-/// The implementation is very basic at the moment, only requesting new animation\n-/// frames at a constant time after a repaint.\n-pub(crate) struct RefreshDriver {\n-    /// The channel on which messages can be sent to the Constellation.\n-    pub(crate) constellation_sender: Sender<EmbedderToConstellationMessage>,\n-\n-    /// Whether or not we are currently animating via a timer.\n-    pub(crate) animating: Cell<bool>,\n-\n-    /// Whether or not we are waiting for our frame timeout to trigger\n-    pub(crate) waiting_for_frame_timeout: Arc<AtomicBool>,\n-\n-    /// A [`TimerThread`] which is used to schedule frame timeouts in the future.\n-    timer_thread: TimerThread,\n-\n-    /// An [`EventLoopWaker`] to be used to wake up the embedder when it is\n-    /// time to paint a frame.\n+/// The [`BaseRefreshDriver`] is a \"base class\" for [`RefreshDriver`] trait\n+/// implementations. It encapsulates shared behavior so that it does not have to be\n+/// implemented by all trait implementations. It is responsible for providing\n+/// [`RefreshDriver`] implementations with a callback that is used to wake up the event\n+/// loop and trigger frame readiness.\n+pub(crate) struct BaseRefreshDriver {\n+    waiting_for_frame: Arc<AtomicBool>,",
        "comment_created_at": "2025-10-20T06:11:52+00:00",
        "comment_author": "mukilan",
        "comment_body": "Could we add doc comments for these fields?",
        "pr_file_module": null
      },
      {
        "comment_id": "2444302679",
        "repo_full_name": "servo/servo",
        "pr_number": 39072,
        "pr_file": "components/compositing/refresh_driver.rs",
        "discussion_id": "2443893538",
        "commented_code": "@@ -2,129 +2,141 @@\n  * License, v. 2.0. If a copy of the MPL was not distributed with this\n  * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n \n-use std::cell::Cell;\n-use std::collections::hash_map::Values;\n+use std::cell::{Cell, RefCell};\n+use std::rc::Rc;\n use std::sync::Arc;\n use std::sync::atomic::{AtomicBool, Ordering};\n use std::thread::{self, JoinHandle};\n use std::time::Duration;\n \n-use base::id::WebViewId;\n use constellation_traits::EmbedderToConstellationMessage;\n use crossbeam_channel::{Sender, select};\n-use embedder_traits::EventLoopWaker;\n+use embedder_traits::{EventLoopWaker, RefreshDriver};\n use log::warn;\n use timers::{BoxedTimerCallback, TimerEventRequest, TimerScheduler};\n \n+use crate::IOCompositor;\n use crate::compositor::RepaintReason;\n use crate::webview_renderer::WebViewRenderer;\n \n-const FRAME_DURATION: Duration = Duration::from_millis(1000 / 120);\n-\n-/// The [`RefreshDriver`] is responsible for controlling updates to aall `WebView`s\n-/// onscreen presentation. Currently, it only manages controlling animation update\n-/// requests.\n-///\n-/// The implementation is very basic at the moment, only requesting new animation\n-/// frames at a constant time after a repaint.\n-pub(crate) struct RefreshDriver {\n-    /// The channel on which messages can be sent to the Constellation.\n-    pub(crate) constellation_sender: Sender<EmbedderToConstellationMessage>,\n-\n-    /// Whether or not we are currently animating via a timer.\n-    pub(crate) animating: Cell<bool>,\n-\n-    /// Whether or not we are waiting for our frame timeout to trigger\n-    pub(crate) waiting_for_frame_timeout: Arc<AtomicBool>,\n-\n-    /// A [`TimerThread`] which is used to schedule frame timeouts in the future.\n-    timer_thread: TimerThread,\n-\n-    /// An [`EventLoopWaker`] to be used to wake up the embedder when it is\n-    /// time to paint a frame.\n+/// The [`BaseRefreshDriver`] is a \"base class\" for [`RefreshDriver`] trait\n+/// implementations. It encapsulates shared behavior so that it does not have to be\n+/// implemented by all trait implementations. It is responsible for providing\n+/// [`RefreshDriver`] implementations with a callback that is used to wake up the event\n+/// loop and trigger frame readiness.\n+pub(crate) struct BaseRefreshDriver {\n+    waiting_for_frame: Arc<AtomicBool>,",
        "comment_created_at": "2025-10-20T09:10:42+00:00",
        "comment_author": "mrobinson",
        "comment_body": "Sure. Done.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2443925586",
    "pr_number": 39072,
    "pr_file": "components/compositing/refresh_driver.rs",
    "created_at": "2025-10-20T06:34:48+00:00",
    "commented_code": "* License, v. 2.0. If a copy of the MPL was not distributed with this\n  * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n \n-use std::cell::Cell;\n-use std::collections::hash_map::Values;\n+use std::cell::{Cell, RefCell};\n+use std::rc::Rc;\n use std::sync::Arc;\n use std::sync::atomic::{AtomicBool, Ordering};\n use std::thread::{self, JoinHandle};\n use std::time::Duration;\n \n-use base::id::WebViewId;\n use constellation_traits::EmbedderToConstellationMessage;\n use crossbeam_channel::{Sender, select};\n-use embedder_traits::EventLoopWaker;\n+use embedder_traits::{EventLoopWaker, RefreshDriver};\n use log::warn;\n use timers::{BoxedTimerCallback, TimerEventRequest, TimerScheduler};\n \n+use crate::IOCompositor;\n use crate::compositor::RepaintReason;\n use crate::webview_renderer::WebViewRenderer;\n \n-const FRAME_DURATION: Duration = Duration::from_millis(1000 / 120);\n-\n-/// The [`RefreshDriver`] is responsible for controlling updates to aall `WebView`s\n-/// onscreen presentation. Currently, it only manages controlling animation update\n-/// requests.\n-///\n-/// The implementation is very basic at the moment, only requesting new animation\n-/// frames at a constant time after a repaint.\n-pub(crate) struct RefreshDriver {\n-    /// The channel on which messages can be sent to the Constellation.\n-    pub(crate) constellation_sender: Sender<EmbedderToConstellationMessage>,\n-\n-    /// Whether or not we are currently animating via a timer.\n-    pub(crate) animating: Cell<bool>,\n-\n-    /// Whether or not we are waiting for our frame timeout to trigger\n-    pub(crate) waiting_for_frame_timeout: Arc<AtomicBool>,\n-\n-    /// A [`TimerThread`] which is used to schedule frame timeouts in the future.\n-    timer_thread: TimerThread,\n-\n-    /// An [`EventLoopWaker`] to be used to wake up the embedder when it is\n-    /// time to paint a frame.\n+/// The [`BaseRefreshDriver`] is a \"base class\" for [`RefreshDriver`] trait\n+/// implementations. It encapsulates shared behavior so that it does not have to be\n+/// implemented by all trait implementations. It is responsible for providing\n+/// [`RefreshDriver`] implementations with a callback that is used to wake up the event\n+/// loop and trigger frame readiness.\n+pub(crate) struct BaseRefreshDriver {\n+    waiting_for_frame: Arc<AtomicBool>,\n     event_loop_waker: Box<dyn EventLoopWaker>,\n+    observers: RefCell<Vec<Rc<dyn RefreshDriverObserver>>>,\n+    refresh_driver: Rc<dyn RefreshDriver>,\n }\n \n-impl RefreshDriver {\n+impl BaseRefreshDriver {\n     pub(crate) fn new(\n-        constellation_sender: Sender<EmbedderToConstellationMessage>,\n         event_loop_waker: Box<dyn EventLoopWaker>,\n+        refresh_driver: Option<Rc<dyn RefreshDriver>>,\n     ) -> Self {\n+        let refresh_driver =\n+            refresh_driver.unwrap_or_else(|| Rc::new(TimerRefreshDriver::default()));\n         Self {\n-            constellation_sender,\n-            animating: Default::default(),\n-            waiting_for_frame_timeout: Default::default(),\n-            timer_thread: Default::default(),\n+            waiting_for_frame: Arc::new(AtomicBool::new(false)),\n             event_loop_waker,\n+            observers: Default::default(),\n+            refresh_driver,\n         }\n     }\n \n-    fn timer_callback(&self) -> BoxedTimerCallback {\n-        let waiting_for_frame_timeout = self.waiting_for_frame_timeout.clone();\n-        let event_loop_waker = self.event_loop_waker.clone_box();\n-        Box::new(move || {\n-            waiting_for_frame_timeout.store(false, Ordering::Relaxed);\n-            event_loop_waker.wake();\n-        })\n+    pub(crate) fn add_observer(&self, observer: Rc<dyn RefreshDriverObserver>) {\n+        let mut observers = self.observers.borrow_mut();\n+        observers.push(observer);\n+\n+        // If this is the first observer, make sure to observe the next frame.\n+        if observers.len() == 1 {\n+            self.observe_next_frame();\n+        }\n     }\n \n-    /// Notify the [`RefreshDriver`] that a paint is about to happen. This will trigger\n-    /// new animation frames for all active `WebView`s and schedule a new frame deadline.\n-    pub(crate) fn notify_will_paint(\n-        &self,\n-        webview_renderers: Values<'_, WebViewId, WebViewRenderer>,\n-    ) {\n+    pub(crate) fn notify_will_paint(&self, compositor: &mut IOCompositor) {\n         // If we are still waiting for the frame to timeout this paint was caused for some\n         // non-animation related reason and we should wait until the frame timeout to trigger\n         // the next one.\n-        if self.waiting_for_frame_timeout.load(Ordering::Relaxed) {\n+        if self.waiting_for_frame.load(Ordering::Relaxed) {\n             return;\n         }\n \n-        // If any WebViews are animating ask them to paint again for another animation tick.\n-        let animating_webviews: Vec<_> = webview_renderers\n-            .filter_map(|webview_renderer| {\n-                if webview_renderer.animating() {\n-                    Some(webview_renderer.id)\n-                } else {\n-                    None\n-                }\n-            })\n-            .collect();\n+        // Limit the borrow of `self.observers` to the minimum here.\n+        let still_has_observers = {\n+            let mut observers = self.observers.borrow_mut();\n+            observers.retain(|observer| observer.frame_started(compositor));\n+            !observers.is_empty()\n+        };\n \n-        // If nothing is animating any longer, update our state and exit early without requesting\n-        // any noew frames nor triggering a new animation deadline.\n-        if animating_webviews.is_empty() {\n-            self.animating.set(false);\n-            return;\n+        if still_has_observers {\n+            self.observe_next_frame();\n         }\n+    }\n \n-        if let Err(error) =\n-            self.constellation_sender\n-                .send(EmbedderToConstellationMessage::TickAnimation(\n-                    animating_webviews,\n-                ))\n+    fn observe_next_frame(&self) {\n+        self.waiting_for_frame.store(true, Ordering::Relaxed);\n+\n+        let waiting_for_frame = self.waiting_for_frame.clone();\n+        let event_loop_waker = self.event_loop_waker.clone_box();\n+        self.refresh_driver.observe_next_frame(Box::new(move || {\n+            waiting_for_frame.store(false, Ordering::Relaxed);\n+            event_loop_waker.wake();\n+        }));\n+    }\n+\n+    /// Whether or not the renderer should trigger a message to the embedder to request a\n+    /// repaint. This might be false if: we are animating and the repaint reason is just\n+    /// for a new frame. In that case, the renderer should wait until the frame timeout to\n+    /// ask the embedder to repaint.\n+    pub(crate) fn wait_to_paint(&self, repaint_reason: RepaintReason) -> bool {\n+        if self.observers.borrow().is_empty() || repaint_reason != RepaintReason::NewWebRenderFrame\n         {\n-            warn!(\"Sending tick to constellation failed ({error:?}).\");\n+            return false;\n         }\n \n-        // Queue the next frame deadline.\n-        self.animating.set(true);\n-        self.waiting_for_frame_timeout\n-            .store(true, Ordering::Relaxed);\n-        self.timer_thread\n-            .queue_timer(FRAME_DURATION, self.timer_callback());\n+        self.waiting_for_frame.load(Ordering::Relaxed)\n     }\n+}\n+\n+/// A [`RefreshDriverObserver`] is an internal subscriber to frame start signals from the\n+/// [`RefreshDriver`]. Examples of these kind of observers would be one that triggers new\n+/// animation frames right after vsync signals or one that handles touch interactions once\n+/// per frame.\n+pub(crate) trait RefreshDriverObserver {\n+    fn frame_started(&self, compositor: &mut IOCompositor) -> bool;",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2443925586",
        "repo_full_name": "servo/servo",
        "pr_number": 39072,
        "pr_file": "components/compositing/refresh_driver.rs",
        "discussion_id": "2443925586",
        "commented_code": "@@ -2,129 +2,141 @@\n  * License, v. 2.0. If a copy of the MPL was not distributed with this\n  * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n \n-use std::cell::Cell;\n-use std::collections::hash_map::Values;\n+use std::cell::{Cell, RefCell};\n+use std::rc::Rc;\n use std::sync::Arc;\n use std::sync::atomic::{AtomicBool, Ordering};\n use std::thread::{self, JoinHandle};\n use std::time::Duration;\n \n-use base::id::WebViewId;\n use constellation_traits::EmbedderToConstellationMessage;\n use crossbeam_channel::{Sender, select};\n-use embedder_traits::EventLoopWaker;\n+use embedder_traits::{EventLoopWaker, RefreshDriver};\n use log::warn;\n use timers::{BoxedTimerCallback, TimerEventRequest, TimerScheduler};\n \n+use crate::IOCompositor;\n use crate::compositor::RepaintReason;\n use crate::webview_renderer::WebViewRenderer;\n \n-const FRAME_DURATION: Duration = Duration::from_millis(1000 / 120);\n-\n-/// The [`RefreshDriver`] is responsible for controlling updates to aall `WebView`s\n-/// onscreen presentation. Currently, it only manages controlling animation update\n-/// requests.\n-///\n-/// The implementation is very basic at the moment, only requesting new animation\n-/// frames at a constant time after a repaint.\n-pub(crate) struct RefreshDriver {\n-    /// The channel on which messages can be sent to the Constellation.\n-    pub(crate) constellation_sender: Sender<EmbedderToConstellationMessage>,\n-\n-    /// Whether or not we are currently animating via a timer.\n-    pub(crate) animating: Cell<bool>,\n-\n-    /// Whether or not we are waiting for our frame timeout to trigger\n-    pub(crate) waiting_for_frame_timeout: Arc<AtomicBool>,\n-\n-    /// A [`TimerThread`] which is used to schedule frame timeouts in the future.\n-    timer_thread: TimerThread,\n-\n-    /// An [`EventLoopWaker`] to be used to wake up the embedder when it is\n-    /// time to paint a frame.\n+/// The [`BaseRefreshDriver`] is a \"base class\" for [`RefreshDriver`] trait\n+/// implementations. It encapsulates shared behavior so that it does not have to be\n+/// implemented by all trait implementations. It is responsible for providing\n+/// [`RefreshDriver`] implementations with a callback that is used to wake up the event\n+/// loop and trigger frame readiness.\n+pub(crate) struct BaseRefreshDriver {\n+    waiting_for_frame: Arc<AtomicBool>,\n     event_loop_waker: Box<dyn EventLoopWaker>,\n+    observers: RefCell<Vec<Rc<dyn RefreshDriverObserver>>>,\n+    refresh_driver: Rc<dyn RefreshDriver>,\n }\n \n-impl RefreshDriver {\n+impl BaseRefreshDriver {\n     pub(crate) fn new(\n-        constellation_sender: Sender<EmbedderToConstellationMessage>,\n         event_loop_waker: Box<dyn EventLoopWaker>,\n+        refresh_driver: Option<Rc<dyn RefreshDriver>>,\n     ) -> Self {\n+        let refresh_driver =\n+            refresh_driver.unwrap_or_else(|| Rc::new(TimerRefreshDriver::default()));\n         Self {\n-            constellation_sender,\n-            animating: Default::default(),\n-            waiting_for_frame_timeout: Default::default(),\n-            timer_thread: Default::default(),\n+            waiting_for_frame: Arc::new(AtomicBool::new(false)),\n             event_loop_waker,\n+            observers: Default::default(),\n+            refresh_driver,\n         }\n     }\n \n-    fn timer_callback(&self) -> BoxedTimerCallback {\n-        let waiting_for_frame_timeout = self.waiting_for_frame_timeout.clone();\n-        let event_loop_waker = self.event_loop_waker.clone_box();\n-        Box::new(move || {\n-            waiting_for_frame_timeout.store(false, Ordering::Relaxed);\n-            event_loop_waker.wake();\n-        })\n+    pub(crate) fn add_observer(&self, observer: Rc<dyn RefreshDriverObserver>) {\n+        let mut observers = self.observers.borrow_mut();\n+        observers.push(observer);\n+\n+        // If this is the first observer, make sure to observe the next frame.\n+        if observers.len() == 1 {\n+            self.observe_next_frame();\n+        }\n     }\n \n-    /// Notify the [`RefreshDriver`] that a paint is about to happen. This will trigger\n-    /// new animation frames for all active `WebView`s and schedule a new frame deadline.\n-    pub(crate) fn notify_will_paint(\n-        &self,\n-        webview_renderers: Values<'_, WebViewId, WebViewRenderer>,\n-    ) {\n+    pub(crate) fn notify_will_paint(&self, compositor: &mut IOCompositor) {\n         // If we are still waiting for the frame to timeout this paint was caused for some\n         // non-animation related reason and we should wait until the frame timeout to trigger\n         // the next one.\n-        if self.waiting_for_frame_timeout.load(Ordering::Relaxed) {\n+        if self.waiting_for_frame.load(Ordering::Relaxed) {\n             return;\n         }\n \n-        // If any WebViews are animating ask them to paint again for another animation tick.\n-        let animating_webviews: Vec<_> = webview_renderers\n-            .filter_map(|webview_renderer| {\n-                if webview_renderer.animating() {\n-                    Some(webview_renderer.id)\n-                } else {\n-                    None\n-                }\n-            })\n-            .collect();\n+        // Limit the borrow of `self.observers` to the minimum here.\n+        let still_has_observers = {\n+            let mut observers = self.observers.borrow_mut();\n+            observers.retain(|observer| observer.frame_started(compositor));\n+            !observers.is_empty()\n+        };\n \n-        // If nothing is animating any longer, update our state and exit early without requesting\n-        // any noew frames nor triggering a new animation deadline.\n-        if animating_webviews.is_empty() {\n-            self.animating.set(false);\n-            return;\n+        if still_has_observers {\n+            self.observe_next_frame();\n         }\n+    }\n \n-        if let Err(error) =\n-            self.constellation_sender\n-                .send(EmbedderToConstellationMessage::TickAnimation(\n-                    animating_webviews,\n-                ))\n+    fn observe_next_frame(&self) {\n+        self.waiting_for_frame.store(true, Ordering::Relaxed);\n+\n+        let waiting_for_frame = self.waiting_for_frame.clone();\n+        let event_loop_waker = self.event_loop_waker.clone_box();\n+        self.refresh_driver.observe_next_frame(Box::new(move || {\n+            waiting_for_frame.store(false, Ordering::Relaxed);\n+            event_loop_waker.wake();\n+        }));\n+    }\n+\n+    /// Whether or not the renderer should trigger a message to the embedder to request a\n+    /// repaint. This might be false if: we are animating and the repaint reason is just\n+    /// for a new frame. In that case, the renderer should wait until the frame timeout to\n+    /// ask the embedder to repaint.\n+    pub(crate) fn wait_to_paint(&self, repaint_reason: RepaintReason) -> bool {\n+        if self.observers.borrow().is_empty() || repaint_reason != RepaintReason::NewWebRenderFrame\n         {\n-            warn!(\"Sending tick to constellation failed ({error:?}).\");\n+            return false;\n         }\n \n-        // Queue the next frame deadline.\n-        self.animating.set(true);\n-        self.waiting_for_frame_timeout\n-            .store(true, Ordering::Relaxed);\n-        self.timer_thread\n-            .queue_timer(FRAME_DURATION, self.timer_callback());\n+        self.waiting_for_frame.load(Ordering::Relaxed)\n     }\n+}\n+\n+/// A [`RefreshDriverObserver`] is an internal subscriber to frame start signals from the\n+/// [`RefreshDriver`]. Examples of these kind of observers would be one that triggers new\n+/// animation frames right after vsync signals or one that handles touch interactions once\n+/// per frame.\n+pub(crate) trait RefreshDriverObserver {\n+    fn frame_started(&self, compositor: &mut IOCompositor) -> bool;",
        "comment_created_at": "2025-10-20T06:34:48+00:00",
        "comment_author": "mukilan",
        "comment_body": "Could we add doc comment to this method to describe what the returned bool represents?",
        "pr_file_module": null
      },
      {
        "comment_id": "2444316952",
        "repo_full_name": "servo/servo",
        "pr_number": 39072,
        "pr_file": "components/compositing/refresh_driver.rs",
        "discussion_id": "2443925586",
        "commented_code": "@@ -2,129 +2,141 @@\n  * License, v. 2.0. If a copy of the MPL was not distributed with this\n  * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n \n-use std::cell::Cell;\n-use std::collections::hash_map::Values;\n+use std::cell::{Cell, RefCell};\n+use std::rc::Rc;\n use std::sync::Arc;\n use std::sync::atomic::{AtomicBool, Ordering};\n use std::thread::{self, JoinHandle};\n use std::time::Duration;\n \n-use base::id::WebViewId;\n use constellation_traits::EmbedderToConstellationMessage;\n use crossbeam_channel::{Sender, select};\n-use embedder_traits::EventLoopWaker;\n+use embedder_traits::{EventLoopWaker, RefreshDriver};\n use log::warn;\n use timers::{BoxedTimerCallback, TimerEventRequest, TimerScheduler};\n \n+use crate::IOCompositor;\n use crate::compositor::RepaintReason;\n use crate::webview_renderer::WebViewRenderer;\n \n-const FRAME_DURATION: Duration = Duration::from_millis(1000 / 120);\n-\n-/// The [`RefreshDriver`] is responsible for controlling updates to aall `WebView`s\n-/// onscreen presentation. Currently, it only manages controlling animation update\n-/// requests.\n-///\n-/// The implementation is very basic at the moment, only requesting new animation\n-/// frames at a constant time after a repaint.\n-pub(crate) struct RefreshDriver {\n-    /// The channel on which messages can be sent to the Constellation.\n-    pub(crate) constellation_sender: Sender<EmbedderToConstellationMessage>,\n-\n-    /// Whether or not we are currently animating via a timer.\n-    pub(crate) animating: Cell<bool>,\n-\n-    /// Whether or not we are waiting for our frame timeout to trigger\n-    pub(crate) waiting_for_frame_timeout: Arc<AtomicBool>,\n-\n-    /// A [`TimerThread`] which is used to schedule frame timeouts in the future.\n-    timer_thread: TimerThread,\n-\n-    /// An [`EventLoopWaker`] to be used to wake up the embedder when it is\n-    /// time to paint a frame.\n+/// The [`BaseRefreshDriver`] is a \"base class\" for [`RefreshDriver`] trait\n+/// implementations. It encapsulates shared behavior so that it does not have to be\n+/// implemented by all trait implementations. It is responsible for providing\n+/// [`RefreshDriver`] implementations with a callback that is used to wake up the event\n+/// loop and trigger frame readiness.\n+pub(crate) struct BaseRefreshDriver {\n+    waiting_for_frame: Arc<AtomicBool>,\n     event_loop_waker: Box<dyn EventLoopWaker>,\n+    observers: RefCell<Vec<Rc<dyn RefreshDriverObserver>>>,\n+    refresh_driver: Rc<dyn RefreshDriver>,\n }\n \n-impl RefreshDriver {\n+impl BaseRefreshDriver {\n     pub(crate) fn new(\n-        constellation_sender: Sender<EmbedderToConstellationMessage>,\n         event_loop_waker: Box<dyn EventLoopWaker>,\n+        refresh_driver: Option<Rc<dyn RefreshDriver>>,\n     ) -> Self {\n+        let refresh_driver =\n+            refresh_driver.unwrap_or_else(|| Rc::new(TimerRefreshDriver::default()));\n         Self {\n-            constellation_sender,\n-            animating: Default::default(),\n-            waiting_for_frame_timeout: Default::default(),\n-            timer_thread: Default::default(),\n+            waiting_for_frame: Arc::new(AtomicBool::new(false)),\n             event_loop_waker,\n+            observers: Default::default(),\n+            refresh_driver,\n         }\n     }\n \n-    fn timer_callback(&self) -> BoxedTimerCallback {\n-        let waiting_for_frame_timeout = self.waiting_for_frame_timeout.clone();\n-        let event_loop_waker = self.event_loop_waker.clone_box();\n-        Box::new(move || {\n-            waiting_for_frame_timeout.store(false, Ordering::Relaxed);\n-            event_loop_waker.wake();\n-        })\n+    pub(crate) fn add_observer(&self, observer: Rc<dyn RefreshDriverObserver>) {\n+        let mut observers = self.observers.borrow_mut();\n+        observers.push(observer);\n+\n+        // If this is the first observer, make sure to observe the next frame.\n+        if observers.len() == 1 {\n+            self.observe_next_frame();\n+        }\n     }\n \n-    /// Notify the [`RefreshDriver`] that a paint is about to happen. This will trigger\n-    /// new animation frames for all active `WebView`s and schedule a new frame deadline.\n-    pub(crate) fn notify_will_paint(\n-        &self,\n-        webview_renderers: Values<'_, WebViewId, WebViewRenderer>,\n-    ) {\n+    pub(crate) fn notify_will_paint(&self, compositor: &mut IOCompositor) {\n         // If we are still waiting for the frame to timeout this paint was caused for some\n         // non-animation related reason and we should wait until the frame timeout to trigger\n         // the next one.\n-        if self.waiting_for_frame_timeout.load(Ordering::Relaxed) {\n+        if self.waiting_for_frame.load(Ordering::Relaxed) {\n             return;\n         }\n \n-        // If any WebViews are animating ask them to paint again for another animation tick.\n-        let animating_webviews: Vec<_> = webview_renderers\n-            .filter_map(|webview_renderer| {\n-                if webview_renderer.animating() {\n-                    Some(webview_renderer.id)\n-                } else {\n-                    None\n-                }\n-            })\n-            .collect();\n+        // Limit the borrow of `self.observers` to the minimum here.\n+        let still_has_observers = {\n+            let mut observers = self.observers.borrow_mut();\n+            observers.retain(|observer| observer.frame_started(compositor));\n+            !observers.is_empty()\n+        };\n \n-        // If nothing is animating any longer, update our state and exit early without requesting\n-        // any noew frames nor triggering a new animation deadline.\n-        if animating_webviews.is_empty() {\n-            self.animating.set(false);\n-            return;\n+        if still_has_observers {\n+            self.observe_next_frame();\n         }\n+    }\n \n-        if let Err(error) =\n-            self.constellation_sender\n-                .send(EmbedderToConstellationMessage::TickAnimation(\n-                    animating_webviews,\n-                ))\n+    fn observe_next_frame(&self) {\n+        self.waiting_for_frame.store(true, Ordering::Relaxed);\n+\n+        let waiting_for_frame = self.waiting_for_frame.clone();\n+        let event_loop_waker = self.event_loop_waker.clone_box();\n+        self.refresh_driver.observe_next_frame(Box::new(move || {\n+            waiting_for_frame.store(false, Ordering::Relaxed);\n+            event_loop_waker.wake();\n+        }));\n+    }\n+\n+    /// Whether or not the renderer should trigger a message to the embedder to request a\n+    /// repaint. This might be false if: we are animating and the repaint reason is just\n+    /// for a new frame. In that case, the renderer should wait until the frame timeout to\n+    /// ask the embedder to repaint.\n+    pub(crate) fn wait_to_paint(&self, repaint_reason: RepaintReason) -> bool {\n+        if self.observers.borrow().is_empty() || repaint_reason != RepaintReason::NewWebRenderFrame\n         {\n-            warn!(\"Sending tick to constellation failed ({error:?}).\");\n+            return false;\n         }\n \n-        // Queue the next frame deadline.\n-        self.animating.set(true);\n-        self.waiting_for_frame_timeout\n-            .store(true, Ordering::Relaxed);\n-        self.timer_thread\n-            .queue_timer(FRAME_DURATION, self.timer_callback());\n+        self.waiting_for_frame.load(Ordering::Relaxed)\n     }\n+}\n+\n+/// A [`RefreshDriverObserver`] is an internal subscriber to frame start signals from the\n+/// [`RefreshDriver`]. Examples of these kind of observers would be one that triggers new\n+/// animation frames right after vsync signals or one that handles touch interactions once\n+/// per frame.\n+pub(crate) trait RefreshDriverObserver {\n+    fn frame_started(&self, compositor: &mut IOCompositor) -> bool;",
        "comment_created_at": "2025-10-20T09:14:31+00:00",
        "comment_author": "mrobinson",
        "comment_body": "I've added a doc comment here:\r\n\r\n```\r\n    /// Informs the observer that a new frame has started. The observer should return\r\n    /// `true` to keep observing or `false` if wants to stop observing and should be\r\n    /// removed by the [`BaseRefreshDriver`].\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2119117972",
    "pr_number": 37021,
    "pr_file": "components/fonts/font_context.rs",
    "created_at": "2025-06-01T12:43:47+00:00",
    "commented_code": "have_removed_web_fonts: AtomicBool,\n }\n \n+#[derive(Clone, Debug)]\n+pub struct WebFontDocumentContext {",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2119117972",
        "repo_full_name": "servo/servo",
        "pr_number": 37021,
        "pr_file": "components/fonts/font_context.rs",
        "discussion_id": "2119117972",
        "commented_code": "@@ -83,6 +87,14 @@ pub struct FontContext {\n     have_removed_web_fonts: AtomicBool,\n }\n \n+#[derive(Clone, Debug)]\n+pub struct WebFontDocumentContext {",
        "comment_created_at": "2025-06-01T12:43:47+00:00",
        "comment_author": "jdm",
        "comment_body": "```suggestion\r\n/// Document-specific data required to fetch a web font.\r\n#[derive(Clone, Debug)]\r\npub struct WebFontDocumentContext {\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2438530426",
    "pr_number": 39940,
    "pr_file": "components/script/dom/document.rs",
    "created_at": "2025-10-17T06:23:55+00:00",
    "commented_code": "}\n         }\n \n-        let global_scope = self.window.as_global_scope();\n-        // Step 10, 14\n-        // https://html.spec.whatwg.org/multipage/#unloading-document-cleanup-steps\n-        if !self.salvageable.get() {\n-            // Step 1 of clean-up steps.\n-            global_scope.close_event_sources();\n-            let msg = ScriptToConstellationMessage::DiscardDocument;\n-            let _ = global_scope.script_to_constellation_chan().send(msg);\n-        }\n+        self.unloading_cleanup_steps();",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2438530426",
        "repo_full_name": "servo/servo",
        "pr_number": 39940,
        "pr_file": "components/script/dom/document.rs",
        "discussion_id": "2438530426",
        "commented_code": "@@ -2097,17 +2144,10 @@ impl Document {\n             }\n         }\n \n-        let global_scope = self.window.as_global_scope();\n-        // Step 10, 14\n-        // https://html.spec.whatwg.org/multipage/#unloading-document-cleanup-steps\n-        if !self.salvageable.get() {\n-            // Step 1 of clean-up steps.\n-            global_scope.close_event_sources();\n-            let msg = ScriptToConstellationMessage::DiscardDocument;\n-            let _ = global_scope.script_to_constellation_chan().send(msg);\n-        }\n+        self.unloading_cleanup_steps();",
        "comment_created_at": "2025-10-17T06:23:55+00:00",
        "comment_author": "TimvdLippe",
        "comment_body": "Nit: add the following spec comment:\n\n```\nStep 18. Run any unloading document cleanup steps for oldDocument that are defined by this specification and other applicable specifications.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2432156137",
    "pr_number": 39885,
    "pr_file": "components/webdriver_server/script_argument_extraction.rs",
    "created_at": "2025-10-15T11:08:39+00:00",
    "commented_code": "}\n     }\n \n+    /// <https://w3c.github.io/webdriver/#dfn-deserialize-a-web-window>\n+    fn deserialize_web_window(&self, window: &Value) -> WebDriverResult<String> {\n+        // Step 2. Let reference be the result of getting the web window identifier property from object.\n+        let window_ref = match window {\n+            Value::String(s) => s.clone(),\n+            _ => return Err(WebDriverError::new(ErrorStatus::InvalidArgument, \"\")),\n+        };\n+\n+        // Step 3 - 5.",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2432156137",
        "repo_full_name": "servo/servo",
        "pr_number": 39885,
        "pr_file": "components/webdriver_server/script_argument_extraction.rs",
        "discussion_id": "2432156137",
        "commented_code": "@@ -90,6 +90,27 @@ impl Handler {\n         }\n     }\n \n+    /// <https://w3c.github.io/webdriver/#dfn-deserialize-a-web-window>\n+    fn deserialize_web_window(&self, window: &Value) -> WebDriverResult<String> {\n+        // Step 2. Let reference be the result of getting the web window identifier property from object.\n+        let window_ref = match window {\n+            Value::String(s) => s.clone(),\n+            _ => return Err(WebDriverError::new(ErrorStatus::InvalidArgument, \"\")),\n+        };\n+\n+        // Step 3 - 5.",
        "comment_created_at": "2025-10-15T11:08:39+00:00",
        "comment_author": "mrobinson",
        "comment_body": "We typically include spec text as the specifications tend to change over time:\r\n\r\n```suggestion\r\n    // Step 3: Let browsing context be the browsing context whose window handle is\r\n    // reference, or null if no such browsing context exists.\r\n    // Step 4: If browsing context is null or not a top-level browsing context,\r\n    // return error with error code no such window.\r\n    // Step 5: Return success with data browsing context's associated window. \r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2434336268",
        "repo_full_name": "servo/servo",
        "pr_number": 39885,
        "pr_file": "components/webdriver_server/script_argument_extraction.rs",
        "discussion_id": "2432156137",
        "commented_code": "@@ -90,6 +90,27 @@ impl Handler {\n         }\n     }\n \n+    /// <https://w3c.github.io/webdriver/#dfn-deserialize-a-web-window>\n+    fn deserialize_web_window(&self, window: &Value) -> WebDriverResult<String> {\n+        // Step 2. Let reference be the result of getting the web window identifier property from object.\n+        let window_ref = match window {\n+            Value::String(s) => s.clone(),\n+            _ => return Err(WebDriverError::new(ErrorStatus::InvalidArgument, \"\")),\n+        };\n+\n+        // Step 3 - 5.",
        "comment_created_at": "2025-10-16T01:36:40+00:00",
        "comment_author": "yezhizhen",
        "comment_body": "Thanks!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2210806777",
    "pr_number": 38112,
    "pr_file": "components/script/dom/textdecoderstream.rs",
    "created_at": "2025-07-16T15:41:00+00:00",
    "commented_code": "+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use std::rc::Rc;\n+\n+use dom_struct::dom_struct;\n+use encoding_rs::Encoding;\n+use js::conversions::{FromJSValConvertible, ToJSValConvertible};\n+use js::jsval::UndefinedValue;\n+use js::rust::{HandleObject as SafeHandleObject, HandleValue as SafeHandleValue};\n+\n+use crate::DomTypes;\n+use crate::dom::bindings::codegen::Bindings::TextDecoderBinding;\n+use crate::dom::bindings::codegen::Bindings::TextDecoderStreamBinding::TextDecoderStreamMethods;\n+use crate::dom::bindings::codegen::UnionTypes::ArrayBufferViewOrArrayBuffer;\n+use crate::dom::bindings::error::{Error, Fallible};\n+use crate::dom::bindings::reflector::{Reflector, reflect_dom_object_with_proto};\n+use crate::dom::bindings::root::{Dom, DomRoot};\n+use crate::dom::bindings::str::DOMString;\n+use crate::dom::globalscope::GlobalScope;\n+use crate::dom::textdecodercommon::TextDecoderCommon;\n+use crate::dom::transformstreamdefaultcontroller::{\n+    TransformerFlushAlgorithm, TransformerFlushAlgorithmType, TransformerTransformAlgorithm,\n+    TransformerTransformAlgorithmType,\n+};\n+use crate::dom::types::{Promise, TransformStream, TransformStreamDefaultController};\n+use crate::script_runtime::{CanGc, JSContext as SafeJSContext};\n+\n+// https://encoding.spec.whatwg.org/#decode-and-enqueue-a-chunk\n+#[allow(unsafe_code)]\n+fn decode_and_enqueue_a_chunk(\n+    cx: SafeJSContext,\n+    global: &GlobalScope,\n+    chunk: SafeHandleValue,\n+    decoder: &TextDecoderCommon,\n+    controller: &TransformStreamDefaultController,\n+    can_gc: CanGc,\n+) -> Fallible<()> {\n+    // Step 1. Let bufferSource be the result of converting chunk to an AllowSharedBufferSource.\n+    let conversion_result = unsafe {\n+        ArrayBufferViewOrArrayBuffer::from_jsval(*cx, chunk, ()).map_err(|_| {\n+            Error::Type(\"Unable to convert chunk into ArrayBuffer or ArrayBufferView\".to_string())\n+        })?\n+    };\n+    let buffer_source = conversion_result.get_success_value().ok_or(Error::Type(\n+        \"Unable to convert chunk into ArrayBuffer or ArrayBufferView\".to_string(),\n+    ))?;\n+\n+    // Step 2. Push a copy of bufferSource to decoder\u2019s I/O queue.\n+    // Step 3. Let output be the I/O queue of scalar values \u00ab end-of-queue \u00bb.\n+    // Step 4. Implemented by `TextDecoderCommon::decode`, which uses the same process as\n+    //      `TextDecoder`\n+    let output_chunk = decoder.decode(Some(buffer_source), true)?;\n+\n+    // Step 4.2.2 If outputChunk is not the empty string, then enqueue\n+    //      outputChunk in decoder\u2019s transform.\n+    if output_chunk.is_empty() {\n+        return Ok(());\n+    }\n+    rooted!(in(*cx) let mut rval = UndefinedValue());\n+    unsafe { output_chunk.to_jsval(*cx, rval.handle_mut()) };\n+    controller.enqueue(cx, global, rval.handle(), can_gc)\n+}\n+\n+#[derive(JSTraceable, MallocSizeOf)]\n+struct TextDecoderStreamTransformAlgorithm {\n+    #[ignore_malloc_size_of = \"Rc is hard\"]\n+    decoder: Rc<TextDecoderCommon>,\n+}\n+\n+impl TransformerTransformAlgorithm for TextDecoderStreamTransformAlgorithm {\n+    fn run(\n+        &self,\n+        cx: SafeJSContext,\n+        global: &GlobalScope,\n+        chunk: SafeHandleValue,\n+        controller: &TransformStreamDefaultController,\n+        can_gc: CanGc,\n+    ) -> Fallible<std::rc::Rc<super::types::Promise>> {\n+        // Step 7. Let transformAlgorithm be an algorithm which takes a chunk argument",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2210806777",
        "repo_full_name": "servo/servo",
        "pr_number": 38112,
        "pr_file": "components/script/dom/textdecoderstream.rs",
        "discussion_id": "2210806777",
        "commented_code": "@@ -0,0 +1,248 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use std::rc::Rc;\n+\n+use dom_struct::dom_struct;\n+use encoding_rs::Encoding;\n+use js::conversions::{FromJSValConvertible, ToJSValConvertible};\n+use js::jsval::UndefinedValue;\n+use js::rust::{HandleObject as SafeHandleObject, HandleValue as SafeHandleValue};\n+\n+use crate::DomTypes;\n+use crate::dom::bindings::codegen::Bindings::TextDecoderBinding;\n+use crate::dom::bindings::codegen::Bindings::TextDecoderStreamBinding::TextDecoderStreamMethods;\n+use crate::dom::bindings::codegen::UnionTypes::ArrayBufferViewOrArrayBuffer;\n+use crate::dom::bindings::error::{Error, Fallible};\n+use crate::dom::bindings::reflector::{Reflector, reflect_dom_object_with_proto};\n+use crate::dom::bindings::root::{Dom, DomRoot};\n+use crate::dom::bindings::str::DOMString;\n+use crate::dom::globalscope::GlobalScope;\n+use crate::dom::textdecodercommon::TextDecoderCommon;\n+use crate::dom::transformstreamdefaultcontroller::{\n+    TransformerFlushAlgorithm, TransformerFlushAlgorithmType, TransformerTransformAlgorithm,\n+    TransformerTransformAlgorithmType,\n+};\n+use crate::dom::types::{Promise, TransformStream, TransformStreamDefaultController};\n+use crate::script_runtime::{CanGc, JSContext as SafeJSContext};\n+\n+// https://encoding.spec.whatwg.org/#decode-and-enqueue-a-chunk\n+#[allow(unsafe_code)]\n+fn decode_and_enqueue_a_chunk(\n+    cx: SafeJSContext,\n+    global: &GlobalScope,\n+    chunk: SafeHandleValue,\n+    decoder: &TextDecoderCommon,\n+    controller: &TransformStreamDefaultController,\n+    can_gc: CanGc,\n+) -> Fallible<()> {\n+    // Step 1. Let bufferSource be the result of converting chunk to an AllowSharedBufferSource.\n+    let conversion_result = unsafe {\n+        ArrayBufferViewOrArrayBuffer::from_jsval(*cx, chunk, ()).map_err(|_| {\n+            Error::Type(\"Unable to convert chunk into ArrayBuffer or ArrayBufferView\".to_string())\n+        })?\n+    };\n+    let buffer_source = conversion_result.get_success_value().ok_or(Error::Type(\n+        \"Unable to convert chunk into ArrayBuffer or ArrayBufferView\".to_string(),\n+    ))?;\n+\n+    // Step 2. Push a copy of bufferSource to decoder\u2019s I/O queue.\n+    // Step 3. Let output be the I/O queue of scalar values \u00ab end-of-queue \u00bb.\n+    // Step 4. Implemented by `TextDecoderCommon::decode`, which uses the same process as\n+    //      `TextDecoder`\n+    let output_chunk = decoder.decode(Some(buffer_source), true)?;\n+\n+    // Step 4.2.2 If outputChunk is not the empty string, then enqueue\n+    //      outputChunk in decoder\u2019s transform.\n+    if output_chunk.is_empty() {\n+        return Ok(());\n+    }\n+    rooted!(in(*cx) let mut rval = UndefinedValue());\n+    unsafe { output_chunk.to_jsval(*cx, rval.handle_mut()) };\n+    controller.enqueue(cx, global, rval.handle(), can_gc)\n+}\n+\n+#[derive(JSTraceable, MallocSizeOf)]\n+struct TextDecoderStreamTransformAlgorithm {\n+    #[ignore_malloc_size_of = \"Rc is hard\"]\n+    decoder: Rc<TextDecoderCommon>,\n+}\n+\n+impl TransformerTransformAlgorithm for TextDecoderStreamTransformAlgorithm {\n+    fn run(\n+        &self,\n+        cx: SafeJSContext,\n+        global: &GlobalScope,\n+        chunk: SafeHandleValue,\n+        controller: &TransformStreamDefaultController,\n+        can_gc: CanGc,\n+    ) -> Fallible<std::rc::Rc<super::types::Promise>> {\n+        // Step 7. Let transformAlgorithm be an algorithm which takes a chunk argument",
        "comment_created_at": "2025-07-16T15:41:00+00:00",
        "comment_author": "gterzian",
        "comment_body": "Please link to a spec for the method, otherwise we don't know where this step is coming from. ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2210814836",
    "pr_number": 38112,
    "pr_file": "components/script/dom/textdecoderstream.rs",
    "created_at": "2025-07-16T15:44:42+00:00",
    "commented_code": "+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use std::rc::Rc;\n+\n+use dom_struct::dom_struct;\n+use encoding_rs::Encoding;\n+use js::conversions::{FromJSValConvertible, ToJSValConvertible};\n+use js::jsval::UndefinedValue;\n+use js::rust::{HandleObject as SafeHandleObject, HandleValue as SafeHandleValue};\n+\n+use crate::DomTypes;\n+use crate::dom::bindings::codegen::Bindings::TextDecoderBinding;\n+use crate::dom::bindings::codegen::Bindings::TextDecoderStreamBinding::TextDecoderStreamMethods;\n+use crate::dom::bindings::codegen::UnionTypes::ArrayBufferViewOrArrayBuffer;\n+use crate::dom::bindings::error::{Error, Fallible};\n+use crate::dom::bindings::reflector::{Reflector, reflect_dom_object_with_proto};\n+use crate::dom::bindings::root::{Dom, DomRoot};\n+use crate::dom::bindings::str::DOMString;\n+use crate::dom::globalscope::GlobalScope;\n+use crate::dom::textdecodercommon::TextDecoderCommon;\n+use crate::dom::transformstreamdefaultcontroller::{\n+    TransformerFlushAlgorithm, TransformerFlushAlgorithmType, TransformerTransformAlgorithm,\n+    TransformerTransformAlgorithmType,\n+};\n+use crate::dom::types::{Promise, TransformStream, TransformStreamDefaultController};\n+use crate::script_runtime::{CanGc, JSContext as SafeJSContext};\n+\n+// https://encoding.spec.whatwg.org/#decode-and-enqueue-a-chunk\n+#[allow(unsafe_code)]\n+fn decode_and_enqueue_a_chunk(\n+    cx: SafeJSContext,\n+    global: &GlobalScope,\n+    chunk: SafeHandleValue,\n+    decoder: &TextDecoderCommon,\n+    controller: &TransformStreamDefaultController,\n+    can_gc: CanGc,\n+) -> Fallible<()> {\n+    // Step 1. Let bufferSource be the result of converting chunk to an AllowSharedBufferSource.\n+    let conversion_result = unsafe {\n+        ArrayBufferViewOrArrayBuffer::from_jsval(*cx, chunk, ()).map_err(|_| {\n+            Error::Type(\"Unable to convert chunk into ArrayBuffer or ArrayBufferView\".to_string())\n+        })?\n+    };\n+    let buffer_source = conversion_result.get_success_value().ok_or(Error::Type(\n+        \"Unable to convert chunk into ArrayBuffer or ArrayBufferView\".to_string(),\n+    ))?;\n+\n+    // Step 2. Push a copy of bufferSource to decoder\u2019s I/O queue.\n+    // Step 3. Let output be the I/O queue of scalar values \u00ab end-of-queue \u00bb.\n+    // Step 4. Implemented by `TextDecoderCommon::decode`, which uses the same process as\n+    //      `TextDecoder`\n+    let output_chunk = decoder.decode(Some(buffer_source), true)?;\n+\n+    // Step 4.2.2 If outputChunk is not the empty string, then enqueue\n+    //      outputChunk in decoder\u2019s transform.\n+    if output_chunk.is_empty() {\n+        return Ok(());\n+    }\n+    rooted!(in(*cx) let mut rval = UndefinedValue());\n+    unsafe { output_chunk.to_jsval(*cx, rval.handle_mut()) };\n+    controller.enqueue(cx, global, rval.handle(), can_gc)\n+}\n+\n+#[derive(JSTraceable, MallocSizeOf)]\n+struct TextDecoderStreamTransformAlgorithm {\n+    #[ignore_malloc_size_of = \"Rc is hard\"]\n+    decoder: Rc<TextDecoderCommon>,\n+}\n+\n+impl TransformerTransformAlgorithm for TextDecoderStreamTransformAlgorithm {\n+    fn run(\n+        &self,\n+        cx: SafeJSContext,\n+        global: &GlobalScope,\n+        chunk: SafeHandleValue,\n+        controller: &TransformStreamDefaultController,\n+        can_gc: CanGc,\n+    ) -> Fallible<std::rc::Rc<super::types::Promise>> {\n+        // Step 7. Let transformAlgorithm be an algorithm which takes a chunk argument\n+        //      and runs the decode and enqueue a chunk algorithm with this and chunk.\n+        decode_and_enqueue_a_chunk(cx, global, chunk, &self.decoder, controller, can_gc)\n+            .map(|_| Promise::new_resolved(global, cx, (), can_gc))\n+    }\n+}\n+\n+// https://encoding.spec.whatwg.org/#flush-and-enqueue\n+#[allow(unsafe_code)]\n+fn flush_and_enqueue(\n+    cx: SafeJSContext,\n+    global: &GlobalScope,\n+    decoder: &TextDecoderCommon,\n+    controller: &TransformStreamDefaultController,\n+    can_gc: CanGc,\n+) -> Fallible<()> {\n+    // Step 1. Implemented by `TextDecoderCommon::decode` which uses a similar process\n+    //      as `TextDecoder::Decode`.\n+    let output_chunk = decoder.decode(None, false)?;\n+\n+    // Step 2.3.2 If outputChunk is not the empty string, then enqueue\n+    //      outputChunk in decoder\u2019s transform.\n+    if output_chunk.is_empty() {\n+        return Ok(());\n+    }\n+    rooted!(in(*cx) let mut rval = UndefinedValue());\n+    unsafe { output_chunk.to_jsval(*cx, rval.handle_mut()) };\n+    controller.enqueue(cx, global, rval.handle(), can_gc)\n+}\n+\n+#[derive(JSTraceable, MallocSizeOf)]\n+struct TextDecoderStreamFlushAlgorithm {\n+    #[ignore_malloc_size_of = \"Rc is hard\"]\n+    decoder: Rc<TextDecoderCommon>,\n+}\n+\n+impl TransformerFlushAlgorithm for TextDecoderStreamFlushAlgorithm {\n+    fn run(\n+        &self,\n+        cx: SafeJSContext,\n+        global: &GlobalScope,\n+        controller: &TransformStreamDefaultController,\n+        can_gc: CanGc,\n+    ) -> Fallible<Rc<Promise>> {\n+        // Step 8. Let flushAlgorithm be an algorithm which takes no arguments\n+        //      and runs the flush and enqueue algorithm with this.\n+        flush_and_enqueue(cx, global, &self.decoder, controller, can_gc)\n+            .map(|_| Promise::new_resolved(global, cx, (), can_gc))\n+    }\n+}\n+\n+#[dom_struct]\n+#[allow(non_snake_case)]\n+pub(crate) struct TextDecoderStream {\n+    reflector_: Reflector,\n+    #[ignore_malloc_size_of = \"Rc is hard\"]\n+    decoder: Rc<TextDecoderCommon>,\n+    transform: Dom<TransformStream>,",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2210814836",
        "repo_full_name": "servo/servo",
        "pr_number": 38112,
        "pr_file": "components/script/dom/textdecoderstream.rs",
        "discussion_id": "2210814836",
        "commented_code": "@@ -0,0 +1,248 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use std::rc::Rc;\n+\n+use dom_struct::dom_struct;\n+use encoding_rs::Encoding;\n+use js::conversions::{FromJSValConvertible, ToJSValConvertible};\n+use js::jsval::UndefinedValue;\n+use js::rust::{HandleObject as SafeHandleObject, HandleValue as SafeHandleValue};\n+\n+use crate::DomTypes;\n+use crate::dom::bindings::codegen::Bindings::TextDecoderBinding;\n+use crate::dom::bindings::codegen::Bindings::TextDecoderStreamBinding::TextDecoderStreamMethods;\n+use crate::dom::bindings::codegen::UnionTypes::ArrayBufferViewOrArrayBuffer;\n+use crate::dom::bindings::error::{Error, Fallible};\n+use crate::dom::bindings::reflector::{Reflector, reflect_dom_object_with_proto};\n+use crate::dom::bindings::root::{Dom, DomRoot};\n+use crate::dom::bindings::str::DOMString;\n+use crate::dom::globalscope::GlobalScope;\n+use crate::dom::textdecodercommon::TextDecoderCommon;\n+use crate::dom::transformstreamdefaultcontroller::{\n+    TransformerFlushAlgorithm, TransformerFlushAlgorithmType, TransformerTransformAlgorithm,\n+    TransformerTransformAlgorithmType,\n+};\n+use crate::dom::types::{Promise, TransformStream, TransformStreamDefaultController};\n+use crate::script_runtime::{CanGc, JSContext as SafeJSContext};\n+\n+// https://encoding.spec.whatwg.org/#decode-and-enqueue-a-chunk\n+#[allow(unsafe_code)]\n+fn decode_and_enqueue_a_chunk(\n+    cx: SafeJSContext,\n+    global: &GlobalScope,\n+    chunk: SafeHandleValue,\n+    decoder: &TextDecoderCommon,\n+    controller: &TransformStreamDefaultController,\n+    can_gc: CanGc,\n+) -> Fallible<()> {\n+    // Step 1. Let bufferSource be the result of converting chunk to an AllowSharedBufferSource.\n+    let conversion_result = unsafe {\n+        ArrayBufferViewOrArrayBuffer::from_jsval(*cx, chunk, ()).map_err(|_| {\n+            Error::Type(\"Unable to convert chunk into ArrayBuffer or ArrayBufferView\".to_string())\n+        })?\n+    };\n+    let buffer_source = conversion_result.get_success_value().ok_or(Error::Type(\n+        \"Unable to convert chunk into ArrayBuffer or ArrayBufferView\".to_string(),\n+    ))?;\n+\n+    // Step 2. Push a copy of bufferSource to decoder\u2019s I/O queue.\n+    // Step 3. Let output be the I/O queue of scalar values \u00ab end-of-queue \u00bb.\n+    // Step 4. Implemented by `TextDecoderCommon::decode`, which uses the same process as\n+    //      `TextDecoder`\n+    let output_chunk = decoder.decode(Some(buffer_source), true)?;\n+\n+    // Step 4.2.2 If outputChunk is not the empty string, then enqueue\n+    //      outputChunk in decoder\u2019s transform.\n+    if output_chunk.is_empty() {\n+        return Ok(());\n+    }\n+    rooted!(in(*cx) let mut rval = UndefinedValue());\n+    unsafe { output_chunk.to_jsval(*cx, rval.handle_mut()) };\n+    controller.enqueue(cx, global, rval.handle(), can_gc)\n+}\n+\n+#[derive(JSTraceable, MallocSizeOf)]\n+struct TextDecoderStreamTransformAlgorithm {\n+    #[ignore_malloc_size_of = \"Rc is hard\"]\n+    decoder: Rc<TextDecoderCommon>,\n+}\n+\n+impl TransformerTransformAlgorithm for TextDecoderStreamTransformAlgorithm {\n+    fn run(\n+        &self,\n+        cx: SafeJSContext,\n+        global: &GlobalScope,\n+        chunk: SafeHandleValue,\n+        controller: &TransformStreamDefaultController,\n+        can_gc: CanGc,\n+    ) -> Fallible<std::rc::Rc<super::types::Promise>> {\n+        // Step 7. Let transformAlgorithm be an algorithm which takes a chunk argument\n+        //      and runs the decode and enqueue a chunk algorithm with this and chunk.\n+        decode_and_enqueue_a_chunk(cx, global, chunk, &self.decoder, controller, can_gc)\n+            .map(|_| Promise::new_resolved(global, cx, (), can_gc))\n+    }\n+}\n+\n+// https://encoding.spec.whatwg.org/#flush-and-enqueue\n+#[allow(unsafe_code)]\n+fn flush_and_enqueue(\n+    cx: SafeJSContext,\n+    global: &GlobalScope,\n+    decoder: &TextDecoderCommon,\n+    controller: &TransformStreamDefaultController,\n+    can_gc: CanGc,\n+) -> Fallible<()> {\n+    // Step 1. Implemented by `TextDecoderCommon::decode` which uses a similar process\n+    //      as `TextDecoder::Decode`.\n+    let output_chunk = decoder.decode(None, false)?;\n+\n+    // Step 2.3.2 If outputChunk is not the empty string, then enqueue\n+    //      outputChunk in decoder\u2019s transform.\n+    if output_chunk.is_empty() {\n+        return Ok(());\n+    }\n+    rooted!(in(*cx) let mut rval = UndefinedValue());\n+    unsafe { output_chunk.to_jsval(*cx, rval.handle_mut()) };\n+    controller.enqueue(cx, global, rval.handle(), can_gc)\n+}\n+\n+#[derive(JSTraceable, MallocSizeOf)]\n+struct TextDecoderStreamFlushAlgorithm {\n+    #[ignore_malloc_size_of = \"Rc is hard\"]\n+    decoder: Rc<TextDecoderCommon>,\n+}\n+\n+impl TransformerFlushAlgorithm for TextDecoderStreamFlushAlgorithm {\n+    fn run(\n+        &self,\n+        cx: SafeJSContext,\n+        global: &GlobalScope,\n+        controller: &TransformStreamDefaultController,\n+        can_gc: CanGc,\n+    ) -> Fallible<Rc<Promise>> {\n+        // Step 8. Let flushAlgorithm be an algorithm which takes no arguments\n+        //      and runs the flush and enqueue algorithm with this.\n+        flush_and_enqueue(cx, global, &self.decoder, controller, can_gc)\n+            .map(|_| Promise::new_resolved(global, cx, (), can_gc))\n+    }\n+}\n+\n+#[dom_struct]\n+#[allow(non_snake_case)]\n+pub(crate) struct TextDecoderStream {\n+    reflector_: Reflector,\n+    #[ignore_malloc_size_of = \"Rc is hard\"]\n+    decoder: Rc<TextDecoderCommon>,\n+    transform: Dom<TransformStream>,",
        "comment_created_at": "2025-07-16T15:44:42+00:00",
        "comment_author": "gterzian",
        "comment_body": "You should try to document each field with a link, and/or a note. For example: \r\n\r\n```\r\n/// The associated transform, as per\r\n/// <https://streams.spec.whatwg.org/#generictransformstream>\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2398069908",
    "pr_number": 36730,
    "pr_file": "components/script/textinput.rs",
    "created_at": "2025-10-02T09:48:36+00:00",
    "commented_code": "///\n /// If the string has fewer than n characters, returns the length of the whole string.\n /// If n is 0, returns 0\n-fn len_of_first_n_chars(text: &str, n: usize) -> UTF8Bytes {\n+fn len_of_first_n_chars(text: &Utf16Str, n: usize) -> usize {\n     match text.char_indices().take(n).last() {\n-        Some((index, ch)) => UTF8Bytes(index + ch.len_utf8()),\n-        None => UTF8Bytes::zero(),\n+        Some((index, ch)) => index + ch.map(|c| c.len_utf16()).unwrap_or(1),\n+        None => 0,\n     }\n }\n \n /// The length in bytes of the first n code units in a string when encoded in UTF-16.\n ///\n /// If the string is fewer than n code units, returns the length of the whole string.\n-fn len_of_first_n_code_units(text: &str, n: UTF16CodeUnits) -> UTF8Bytes {\n-    let mut utf8_len = UTF8Bytes::zero();\n-    let mut utf16_len = UTF16CodeUnits::zero();\n-    for c in text.chars() {\n-        utf16_len += UTF16CodeUnits(c.len_utf16());\n-        if utf16_len > n {\n-            break;\n-        }\n-        utf8_len += UTF8Bytes(c.len_utf8());\n-    }\n-    utf8_len\n+fn len_of_first_n_code_units(text: &Utf16Str, n: usize) -> usize {",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2398069908",
        "repo_full_name": "servo/servo",
        "pr_number": 36730,
        "pr_file": "components/script/textinput.rs",
        "discussion_id": "2398069908",
        "commented_code": "@@ -246,37 +195,31 @@ pub(crate) const CMD_OR_CONTROL: Modifiers = Modifiers::CONTROL;\n ///\n /// If the string has fewer than n characters, returns the length of the whole string.\n /// If n is 0, returns 0\n-fn len_of_first_n_chars(text: &str, n: usize) -> UTF8Bytes {\n+fn len_of_first_n_chars(text: &Utf16Str, n: usize) -> usize {\n     match text.char_indices().take(n).last() {\n-        Some((index, ch)) => UTF8Bytes(index + ch.len_utf8()),\n-        None => UTF8Bytes::zero(),\n+        Some((index, ch)) => index + ch.map(|c| c.len_utf16()).unwrap_or(1),\n+        None => 0,\n     }\n }\n \n /// The length in bytes of the first n code units in a string when encoded in UTF-16.\n ///\n /// If the string is fewer than n code units, returns the length of the whole string.\n-fn len_of_first_n_code_units(text: &str, n: UTF16CodeUnits) -> UTF8Bytes {\n-    let mut utf8_len = UTF8Bytes::zero();\n-    let mut utf16_len = UTF16CodeUnits::zero();\n-    for c in text.chars() {\n-        utf16_len += UTF16CodeUnits(c.len_utf16());\n-        if utf16_len > n {\n-            break;\n-        }\n-        utf8_len += UTF8Bytes(c.len_utf8());\n-    }\n-    utf8_len\n+fn len_of_first_n_code_units(text: &Utf16Str, n: usize) -> usize {",
        "comment_created_at": "2025-10-02T09:48:36+00:00",
        "comment_author": "xiaochengh",
        "comment_body": "Could you revise the documentation? I can't follow what this function does after the change.\r\n\r\nThe function currently returns some number based on code units, but the documentation says bytes.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2384095527",
    "pr_number": 39418,
    "pr_file": "components/script/dom/globalscope.rs",
    "created_at": "2025-09-27T11:42:01+00:00",
    "commented_code": "self.resource_threads().sender()\n     }\n \n+    /// Get the `&StorageThreads` for this global scope.",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2384095527",
        "repo_full_name": "servo/servo",
        "pr_number": 39418,
        "pr_file": "components/script/dom/globalscope.rs",
        "discussion_id": "2384095527",
        "commented_code": "@@ -2761,6 +2769,11 @@ impl GlobalScope {\n         self.resource_threads().sender()\n     }\n \n+    /// Get the `&StorageThreads` for this global scope.",
        "comment_created_at": "2025-09-27T11:42:01+00:00",
        "comment_author": "mrobinson",
        "comment_body": "```suggestion\r\n    /// Get a reference to the [`StorageThreads`] for this [`GlobalScope`].\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2330576086",
    "pr_number": 38717,
    "pr_file": "components/webgpu/canvas_context.rs",
    "created_at": "2025-09-08T15:19:01+00:00",
    "commented_code": "+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use webgpu_traits::{\n+    ContextConfiguration, PRESENTATION_BUFFER_COUNT, PendingTexture, WebGPUContextId, WebGPUMsg,\n+};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == config.buffer_size()\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer can be shared between safely (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+\n+    pub fn stride(&self) -> u32 {\n+        (self.image_size.width * self.image_format.bytes_per_pixel() as u32)\n+            .next_multiple_of(wgt::COPY_BYTES_PER_ROW_ALIGNMENT)\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+// [`StagingBuffer`] only used for reading (never for writing)\n+// so it is safe to share between threads.\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = config.buffer_size();\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            if let Some(error) = error {\n+                return Err(error);\n+            };\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!(\"Should be made available by `ensure_available`\")\n+        };\n+        let device_id = buffer.device_id;\n+        let command_descriptor = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) = self.global.device_create_command_encoder(\n+            device_id,\n+            &command_descriptor,\n+            Some(encoder_id),\n+        );\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        let buffer_info = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(config.stride()),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_info = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_info,\n+            &buffer_info,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        let StagingBufferState::Mapped(mapped) = &self.state else {\n+            return None;\n+        };\n+        let format = match mapped.image_format {\n+            ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+            ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+            _ => unimplemented!(),\n+        };\n+        let alpha_mode = if mapped.is_opaque {\n+            SnapshotAlphaMode::AsOpaque {\n+                premultiplied: false,\n+            }\n+        } else {\n+            SnapshotAlphaMode::Transparent {\n+                premultiplied: true,\n+            }\n+        };\n+        let padded_byte_width = mapped.stride();\n+        let data = mapped.slice();\n+        let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+        let mut result_unpadded =\n+            Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+        for row in 0..mapped.image_size.height {\n+            let start = (row * padded_byte_width).try_into().ok()?;\n+            result_unpadded\n+                .extend(&data[start..start + mapped.image_size.width as usize * bytes_per_pixel]);\n+        }\n+        let mut snapshot =\n+            Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+        if mapped.is_opaque {\n+            snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+        }\n+        Some(snapshot)\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!(\"Presentation staging buffer should be mapped\")\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// If the internal staging buffer is not shared,\n+    /// unmap it and call [`ContextData::return_staging_buffer`] with it.\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2330576086",
        "repo_full_name": "servo/servo",
        "pr_number": 38717,
        "pr_file": "components/webgpu/canvas_context.rs",
        "discussion_id": "2330576086",
        "commented_code": "@@ -0,0 +1,771 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use webgpu_traits::{\n+    ContextConfiguration, PRESENTATION_BUFFER_COUNT, PendingTexture, WebGPUContextId, WebGPUMsg,\n+};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == config.buffer_size()\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer can be shared between safely (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+\n+    pub fn stride(&self) -> u32 {\n+        (self.image_size.width * self.image_format.bytes_per_pixel() as u32)\n+            .next_multiple_of(wgt::COPY_BYTES_PER_ROW_ALIGNMENT)\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+// [`StagingBuffer`] only used for reading (never for writing)\n+// so it is safe to share between threads.\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = config.buffer_size();\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            if let Some(error) = error {\n+                return Err(error);\n+            };\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!(\"Should be made available by `ensure_available`\")\n+        };\n+        let device_id = buffer.device_id;\n+        let command_descriptor = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) = self.global.device_create_command_encoder(\n+            device_id,\n+            &command_descriptor,\n+            Some(encoder_id),\n+        );\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        let buffer_info = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(config.stride()),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_info = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_info,\n+            &buffer_info,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        let StagingBufferState::Mapped(mapped) = &self.state else {\n+            return None;\n+        };\n+        let format = match mapped.image_format {\n+            ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+            ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+            _ => unimplemented!(),\n+        };\n+        let alpha_mode = if mapped.is_opaque {\n+            SnapshotAlphaMode::AsOpaque {\n+                premultiplied: false,\n+            }\n+        } else {\n+            SnapshotAlphaMode::Transparent {\n+                premultiplied: true,\n+            }\n+        };\n+        let padded_byte_width = mapped.stride();\n+        let data = mapped.slice();\n+        let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+        let mut result_unpadded =\n+            Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+        for row in 0..mapped.image_size.height {\n+            let start = (row * padded_byte_width).try_into().ok()?;\n+            result_unpadded\n+                .extend(&data[start..start + mapped.image_size.width as usize * bytes_per_pixel]);\n+        }\n+        let mut snapshot =\n+            Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+        if mapped.is_opaque {\n+            snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+        }\n+        Some(snapshot)\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!(\"Presentation staging buffer should be mapped\")\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// If the internal staging buffer is not shared,\n+    /// unmap it and call [`ContextData::return_staging_buffer`] with it.\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext",
        "comment_created_at": "2025-09-08T15:19:01+00:00",
        "comment_author": "mrobinson",
        "comment_body": "```suggestion\r\n/// The main state structure of GPUCanvasContext.\r\n```\r\n\r\nNot sure what \"process\" is supposed to mean here.",
        "pr_file_module": null
      },
      {
        "comment_id": "2330770983",
        "repo_full_name": "servo/servo",
        "pr_number": 38717,
        "pr_file": "components/webgpu/canvas_context.rs",
        "discussion_id": "2330576086",
        "commented_code": "@@ -0,0 +1,771 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use webgpu_traits::{\n+    ContextConfiguration, PRESENTATION_BUFFER_COUNT, PendingTexture, WebGPUContextId, WebGPUMsg,\n+};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == config.buffer_size()\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer can be shared between safely (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+\n+    pub fn stride(&self) -> u32 {\n+        (self.image_size.width * self.image_format.bytes_per_pixel() as u32)\n+            .next_multiple_of(wgt::COPY_BYTES_PER_ROW_ALIGNMENT)\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+// [`StagingBuffer`] only used for reading (never for writing)\n+// so it is safe to share between threads.\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = config.buffer_size();\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            if let Some(error) = error {\n+                return Err(error);\n+            };\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!(\"Should be made available by `ensure_available`\")\n+        };\n+        let device_id = buffer.device_id;\n+        let command_descriptor = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) = self.global.device_create_command_encoder(\n+            device_id,\n+            &command_descriptor,\n+            Some(encoder_id),\n+        );\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        let buffer_info = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(config.stride()),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_info = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_info,\n+            &buffer_info,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        let StagingBufferState::Mapped(mapped) = &self.state else {\n+            return None;\n+        };\n+        let format = match mapped.image_format {\n+            ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+            ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+            _ => unimplemented!(),\n+        };\n+        let alpha_mode = if mapped.is_opaque {\n+            SnapshotAlphaMode::AsOpaque {\n+                premultiplied: false,\n+            }\n+        } else {\n+            SnapshotAlphaMode::Transparent {\n+                premultiplied: true,\n+            }\n+        };\n+        let padded_byte_width = mapped.stride();\n+        let data = mapped.slice();\n+        let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+        let mut result_unpadded =\n+            Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+        for row in 0..mapped.image_size.height {\n+            let start = (row * padded_byte_width).try_into().ok()?;\n+            result_unpadded\n+                .extend(&data[start..start + mapped.image_size.width as usize * bytes_per_pixel]);\n+        }\n+        let mut snapshot =\n+            Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+        if mapped.is_opaque {\n+            snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+        }\n+        Some(snapshot)\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!(\"Presentation staging buffer should be mapped\")\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// If the internal staging buffer is not shared,\n+    /// unmap it and call [`ContextData::return_staging_buffer`] with it.\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext",
        "comment_created_at": "2025-09-08T16:31:27+00:00",
        "comment_author": "sagudev",
        "comment_body": "That it lives in main process.",
        "pr_file_module": null
      },
      {
        "comment_id": "2330800584",
        "repo_full_name": "servo/servo",
        "pr_number": 38717,
        "pr_file": "components/webgpu/canvas_context.rs",
        "discussion_id": "2330576086",
        "commented_code": "@@ -0,0 +1,771 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use webgpu_traits::{\n+    ContextConfiguration, PRESENTATION_BUFFER_COUNT, PendingTexture, WebGPUContextId, WebGPUMsg,\n+};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == config.buffer_size()\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer can be shared between safely (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+\n+    pub fn stride(&self) -> u32 {\n+        (self.image_size.width * self.image_format.bytes_per_pixel() as u32)\n+            .next_multiple_of(wgt::COPY_BYTES_PER_ROW_ALIGNMENT)\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+// [`StagingBuffer`] only used for reading (never for writing)\n+// so it is safe to share between threads.\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = config.buffer_size();\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            if let Some(error) = error {\n+                return Err(error);\n+            };\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!(\"Should be made available by `ensure_available`\")\n+        };\n+        let device_id = buffer.device_id;\n+        let command_descriptor = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) = self.global.device_create_command_encoder(\n+            device_id,\n+            &command_descriptor,\n+            Some(encoder_id),\n+        );\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        let buffer_info = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(config.stride()),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_info = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_info,\n+            &buffer_info,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        let StagingBufferState::Mapped(mapped) = &self.state else {\n+            return None;\n+        };\n+        let format = match mapped.image_format {\n+            ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+            ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+            _ => unimplemented!(),\n+        };\n+        let alpha_mode = if mapped.is_opaque {\n+            SnapshotAlphaMode::AsOpaque {\n+                premultiplied: false,\n+            }\n+        } else {\n+            SnapshotAlphaMode::Transparent {\n+                premultiplied: true,\n+            }\n+        };\n+        let padded_byte_width = mapped.stride();\n+        let data = mapped.slice();\n+        let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+        let mut result_unpadded =\n+            Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+        for row in 0..mapped.image_size.height {\n+            let start = (row * padded_byte_width).try_into().ok()?;\n+            result_unpadded\n+                .extend(&data[start..start + mapped.image_size.width as usize * bytes_per_pixel]);\n+        }\n+        let mut snapshot =\n+            Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+        if mapped.is_opaque {\n+            snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+        }\n+        Some(snapshot)\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!(\"Presentation staging buffer should be mapped\")\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// If the internal staging buffer is not shared,\n+    /// unmap it and call [`ContextData::return_staging_buffer`] with it.\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext",
        "comment_created_at": "2025-09-08T16:45:58+00:00",
        "comment_author": "mrobinson",
        "comment_body": "Ah, how about this:\r\n\r\n```\r\n/// The embedder process-side representation of what is the `GPUCanvasContext` in the `ScriptThread.\r\n```\r\n\r\nThanks for the clarification.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2330577382",
    "pr_number": 38717,
    "pr_file": "components/webgpu/canvas_context.rs",
    "created_at": "2025-09-08T15:19:25+00:00",
    "commented_code": "+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use webgpu_traits::{\n+    ContextConfiguration, PRESENTATION_BUFFER_COUNT, PendingTexture, WebGPUContextId, WebGPUMsg,\n+};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == config.buffer_size()\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer can be shared between safely (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+\n+    pub fn stride(&self) -> u32 {\n+        (self.image_size.width * self.image_format.bytes_per_pixel() as u32)\n+            .next_multiple_of(wgt::COPY_BYTES_PER_ROW_ALIGNMENT)\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+// [`StagingBuffer`] only used for reading (never for writing)\n+// so it is safe to share between threads.\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = config.buffer_size();\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            if let Some(error) = error {\n+                return Err(error);\n+            };\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!(\"Should be made available by `ensure_available`\")\n+        };\n+        let device_id = buffer.device_id;\n+        let command_descriptor = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) = self.global.device_create_command_encoder(\n+            device_id,\n+            &command_descriptor,\n+            Some(encoder_id),\n+        );\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        let buffer_info = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(config.stride()),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_info = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_info,\n+            &buffer_info,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        let StagingBufferState::Mapped(mapped) = &self.state else {\n+            return None;\n+        };\n+        let format = match mapped.image_format {\n+            ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+            ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+            _ => unimplemented!(),\n+        };\n+        let alpha_mode = if mapped.is_opaque {\n+            SnapshotAlphaMode::AsOpaque {\n+                premultiplied: false,\n+            }\n+        } else {\n+            SnapshotAlphaMode::Transparent {\n+                premultiplied: true,\n+            }\n+        };\n+        let padded_byte_width = mapped.stride();\n+        let data = mapped.slice();\n+        let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+        let mut result_unpadded =\n+            Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+        for row in 0..mapped.image_size.height {\n+            let start = (row * padded_byte_width).try_into().ok()?;\n+            result_unpadded\n+                .extend(&data[start..start + mapped.image_size.width as usize * bytes_per_pixel]);\n+        }\n+        let mut snapshot =\n+            Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+        if mapped.is_opaque {\n+            snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+        }\n+        Some(snapshot)\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!(\"Presentation staging buffer should be mapped\")\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// If the internal staging buffer is not shared,\n+    /// unmap it and call [`ContextData::return_staging_buffer`] with it.\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext\n+pub struct ContextData {\n+    /// Associated WebRender image",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2330577382",
        "repo_full_name": "servo/servo",
        "pr_number": 38717,
        "pr_file": "components/webgpu/canvas_context.rs",
        "discussion_id": "2330577382",
        "commented_code": "@@ -0,0 +1,771 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use webgpu_traits::{\n+    ContextConfiguration, PRESENTATION_BUFFER_COUNT, PendingTexture, WebGPUContextId, WebGPUMsg,\n+};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == config.buffer_size()\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer can be shared between safely (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+\n+    pub fn stride(&self) -> u32 {\n+        (self.image_size.width * self.image_format.bytes_per_pixel() as u32)\n+            .next_multiple_of(wgt::COPY_BYTES_PER_ROW_ALIGNMENT)\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+// [`StagingBuffer`] only used for reading (never for writing)\n+// so it is safe to share between threads.\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = config.buffer_size();\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            if let Some(error) = error {\n+                return Err(error);\n+            };\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!(\"Should be made available by `ensure_available`\")\n+        };\n+        let device_id = buffer.device_id;\n+        let command_descriptor = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) = self.global.device_create_command_encoder(\n+            device_id,\n+            &command_descriptor,\n+            Some(encoder_id),\n+        );\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        let buffer_info = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(config.stride()),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_info = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_info,\n+            &buffer_info,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        let StagingBufferState::Mapped(mapped) = &self.state else {\n+            return None;\n+        };\n+        let format = match mapped.image_format {\n+            ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+            ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+            _ => unimplemented!(),\n+        };\n+        let alpha_mode = if mapped.is_opaque {\n+            SnapshotAlphaMode::AsOpaque {\n+                premultiplied: false,\n+            }\n+        } else {\n+            SnapshotAlphaMode::Transparent {\n+                premultiplied: true,\n+            }\n+        };\n+        let padded_byte_width = mapped.stride();\n+        let data = mapped.slice();\n+        let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+        let mut result_unpadded =\n+            Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+        for row in 0..mapped.image_size.height {\n+            let start = (row * padded_byte_width).try_into().ok()?;\n+            result_unpadded\n+                .extend(&data[start..start + mapped.image_size.width as usize * bytes_per_pixel]);\n+        }\n+        let mut snapshot =\n+            Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+        if mapped.is_opaque {\n+            snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+        }\n+        Some(snapshot)\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!(\"Presentation staging buffer should be mapped\")\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// If the internal staging buffer is not shared,\n+    /// unmap it and call [`ContextData::return_staging_buffer`] with it.\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext\n+pub struct ContextData {\n+    /// Associated WebRender image",
        "comment_created_at": "2025-09-08T15:19:25+00:00",
        "comment_author": "mrobinson",
        "comment_body": "```suggestion\r\n    /// The [`ImageKey`] of the WebRender image associated with this context.\r\n```",
        "pr_file_module": null
      }
    ]
  }
]