[
  {
    "discussion_id": "2432913131",
    "pr_number": 39900,
    "pr_file": ".github/actions/runner-select/action.yml",
    "created_at": "2025-10-15T14:58:42+00:00",
    "commented_code": "echo\n         echo 'No self-hosted runners available!'\n         fall_back_to_github_hosted\n+\n+    - name: Publish artifact marking this job as done\n+      uses: actions/upload-artifact@v4\n+      with:",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2432913131",
        "repo_full_name": "servo/servo",
        "pr_number": 39900,
        "pr_file": ".github/actions/runner-select/action.yml",
        "discussion_id": "2432913131",
        "commented_code": "@@ -104,3 +130,9 @@ runs:\n         echo\n         echo 'No self-hosted runners available!'\n         fall_back_to_github_hosted\n+\n+    - name: Publish artifact marking this job as done\n+      uses: actions/upload-artifact@v4\n+      with:",
        "comment_created_at": "2025-10-15T14:58:42+00:00",
        "comment_author": "jschwe",
        "comment_body": "this should probably have an `if: ${{ always() }}`, so that this step also runs even if a previous step failed, or the job was cancelled. Is there any additinal safe-guard like a timeout on the monitor side?",
        "pr_file_module": null
      },
      {
        "comment_id": "2434328766",
        "repo_full_name": "servo/servo",
        "pr_number": 39900,
        "pr_file": ".github/actions/runner-select/action.yml",
        "discussion_id": "2432913131",
        "commented_code": "@@ -104,3 +130,9 @@ runs:\n         echo\n         echo 'No self-hosted runners available!'\n         fall_back_to_github_hosted\n+\n+    - name: Publish artifact marking this job as done\n+      uses: actions/upload-artifact@v4\n+      with:",
        "comment_created_at": "2025-10-16T01:29:06+00:00",
        "comment_author": "delan",
        "comment_body": "there wasn\u2019t a timeout yet, but i could add one. do you mean something like rejecting if the workflow run started too long ago? in the meantime, added if always in 7a0a1d87b864de7c71a8d9b80bbd999daf047d9a",
        "pr_file_module": null
      },
      {
        "comment_id": "2443902154",
        "repo_full_name": "servo/servo",
        "pr_number": 39900,
        "pr_file": ".github/actions/runner-select/action.yml",
        "discussion_id": "2432913131",
        "commented_code": "@@ -104,3 +130,9 @@ runs:\n         echo\n         echo 'No self-hosted runners available!'\n         fall_back_to_github_hosted\n+\n+    - name: Publish artifact marking this job as done\n+      uses: actions/upload-artifact@v4\n+      with:",
        "comment_created_at": "2025-10-20T06:18:39+00:00",
        "comment_author": "jschwe",
        "comment_body": "> do you mean something like rejecting if the workflow run started too long ago.\r\n\r\nYes, basically an additional safe-guard on the monitor side, to prevent abuse if thee \"done\" artifact is never published. I guess deciding on what a reasonable timeout would be is also not easy, but I guess this job should only take a couple of minutes at most?",
        "pr_file_module": null
      },
      {
        "comment_id": "2444154111",
        "repo_full_name": "servo/servo",
        "pr_number": 39900,
        "pr_file": ".github/actions/runner-select/action.yml",
        "discussion_id": "2432913131",
        "commented_code": "@@ -104,3 +130,9 @@ runs:\n         echo\n         echo 'No self-hosted runners available!'\n         fall_back_to_github_hosted\n+\n+    - name: Publish artifact marking this job as done\n+      uses: actions/upload-artifact@v4\n+      with:",
        "comment_created_at": "2025-10-20T08:23:10+00:00",
        "comment_author": "sagudev",
        "comment_body": "Maybe even better idea: do not allow too old artifacts (max oldness being 5min or less). This way we can avoid another artifact. I would prefer if we could also remove the artifacts (I think this should happen from monitor), but I do not think we can relay on this to happen for security.",
        "pr_file_module": null
      },
      {
        "comment_id": "2444166792",
        "repo_full_name": "servo/servo",
        "pr_number": 39900,
        "pr_file": ".github/actions/runner-select/action.yml",
        "discussion_id": "2432913131",
        "commented_code": "@@ -104,3 +130,9 @@ runs:\n         echo\n         echo 'No self-hosted runners available!'\n         fall_back_to_github_hosted\n+\n+    - name: Publish artifact marking this job as done\n+      uses: actions/upload-artifact@v4\n+      with:",
        "comment_created_at": "2025-10-20T08:27:43+00:00",
        "comment_author": "sagudev",
        "comment_body": "Also one can always remove artifacts (not sure how many permissions is needed for this), so this could bypass the existing checks.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2354088591",
    "pr_number": 39272,
    "pr_file": ".github/workflows/bencher.yml",
    "created_at": "2025-09-17T02:24:27+00:00",
    "commented_code": "BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2354088591",
        "repo_full_name": "servo/servo",
        "pr_number": 39272,
        "pr_file": ".github/workflows/bencher.yml",
        "discussion_id": "2354088591",
        "commented_code": "@@ -42,22 +46,76 @@ env:\n   BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
        "comment_created_at": "2025-09-17T02:24:27+00:00",
        "comment_author": "jschwe",
        "comment_body": "Is there a usecase for falling back to github hosted runners for benchmarks? ",
        "pr_file_module": null
      },
      {
        "comment_id": "2367840426",
        "repo_full_name": "servo/servo",
        "pr_number": 39272,
        "pr_file": ".github/workflows/bencher.yml",
        "discussion_id": "2354088591",
        "commented_code": "@@ -42,22 +46,76 @@ env:\n   BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
        "comment_created_at": "2025-09-22T11:34:41+00:00",
        "comment_author": "delan",
        "comment_body": "in general, we try to make our usage of self-hosted runners gracefully degrade to github-hosted runners, because self-hosted runners are provided on a best-effort basis. and for bencher jobs, there are cases where we only measure binary size, so we use `force-github-hosted-runner` to force those cases to use github-hosted runners.",
        "pr_file_module": null
      },
      {
        "comment_id": "2370800128",
        "repo_full_name": "servo/servo",
        "pr_number": 39272,
        "pr_file": ".github/workflows/bencher.yml",
        "discussion_id": "2354088591",
        "commented_code": "@@ -42,22 +46,76 @@ env:\n   BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
        "comment_created_at": "2025-09-23T01:49:20+00:00",
        "comment_author": "jschwe",
        "comment_body": "> there are cases where we only measure binary size, so we use force-github-hosted-runner to force those cases to use github-hosted runners.\r\n\r\nI already lost context here (and am a bit time constrained now, so can't look at the code again), but do non-perf related metrics like binary size need to be handled by the bencher workflow? I would imagine that the metric could be a regular output of the build workflow (and either directly uploaded, or if tokens are a problem, eventually uploaded by the bencher perf job). \r\n\r\n> In general, we try to make our usage of self-hosted runners gracefully degrade to github-hosted runners,\r\n\r\nI think that is great, but at least for perf jobs it doesn't really make sense to me, since the perf measurements on github-hosted runners are not useful in practice due to the high volatility (counting instructions might work there, but that metric is also not incredibly useful). \r\n\r\nI'm mainly wondering if the added complexity (to handle github-hosted runners) here is really needed or not.",
        "pr_file_module": null
      },
      {
        "comment_id": "2371093189",
        "repo_full_name": "servo/servo",
        "pr_number": 39272,
        "pr_file": ".github/workflows/bencher.yml",
        "discussion_id": "2354088591",
        "commented_code": "@@ -42,22 +46,76 @@ env:\n   BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
        "comment_created_at": "2025-09-23T04:25:34+00:00",
        "comment_author": "delan",
        "comment_body": "> I already lost context here (and am a bit time constrained now, so can't look at the code again), but do non-perf related metrics like binary size need to be handled by the bencher workflow? I would imagine that the metric could be a regular output of the build workflow (and either directly uploaded, or if tokens are a problem, eventually uploaded by the bencher perf job).\r\n\r\ni agree. i think this would be a good rework to do in a separate patch.\r\n\r\n> I think that is great, but at least for perf jobs it doesn't really make sense to me, since the perf measurements on github-hosted runners are not useful in practice due to the high volatility (counting instructions might work there, but that metric is also not incredibly useful).\r\n\r\nthat\u2019s fair, yea, do you think we should skip running speedometer and dromaeo if no self-hosted runners are available?\r\n\r\n> I'm mainly wondering if the added complexity (to handle github-hosted runners) here is really needed or not.\r\n\r\ni think this is the approach with the least added complexity overall, because it takes the existing bencher job and self-hosts it using the same pattern for selecting a runner as most of our other self-hosted jobs.\r\n\r\nwithout fallback (even to a github-hosted no-op job), any downtime in the self-hosted runners would break everyone\u2019s builds, which is currently a non-starter imo. i\u2019m working towards a world where we don\u2019t rely on github-hosted runners and our self-hosted runners are zero maintenance, but we\u2019re not quite there yet.",
        "pr_file_module": null
      },
      {
        "comment_id": "2371130310",
        "repo_full_name": "servo/servo",
        "pr_number": 39272,
        "pr_file": ".github/workflows/bencher.yml",
        "discussion_id": "2354088591",
        "commented_code": "@@ -42,22 +46,76 @@ env:\n   BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
        "comment_created_at": "2025-09-23T04:50:57+00:00",
        "comment_author": "jschwe",
        "comment_body": "> that\u2019s fair, yea, do you think we should skip running speedometer and dromaeo if no self-hosted runners are available?\r\n\r\nProbably we should avoid uploading metrics we aren't going to use (since there presumably is a cost, and bencher.dev is a single-person project as far as I understand). I think bencher also recently introduced rate limiting (for non paying orgs).\r\n\r\n> i think this is the approach with the least added complexity overall, because it takes the existing bencher job and self-hosts it using the same pattern for selecting a runner as most of our other self-hosted jobs.\r\n\r\nThat's fair. \r\n\r\n> without fallback (even to a github-hosted no-op job), any downtime in the self-hosted runners would break everyone\u2019s builds, which is currently a non-starter imo. \r\n\r\nI'm not sure I agree here. I think we do need to transition towards a model where performance benchmarking is mandatory for pull requests to be merged. Performance regressions are just as serious as test regressions, so if we can't measure, then the MQ being broken is a feature in my opinion. The main problem here in my opinion is that we don't really have redundancy in terms of infrastructure maintainers. But I guess this discussion might be better had on zulip in the TSC channel to have a bit more visibility.\r\n\r\nIf we could trigger the performance testing workflow manually, and **backfill performance data** after a self-hosted runner downtime, so we can easily identify regressions merged to main (and revert), that could also be a viable short-term - medium-term bandaid. I'm not sure how feasible that would be though.",
        "pr_file_module": null
      },
      {
        "comment_id": "2371221770",
        "repo_full_name": "servo/servo",
        "pr_number": 39272,
        "pr_file": ".github/workflows/bencher.yml",
        "discussion_id": "2354088591",
        "commented_code": "@@ -42,22 +46,76 @@ env:\n   BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
        "comment_created_at": "2025-09-23T05:45:09+00:00",
        "comment_author": "delan",
        "comment_body": "> I think we do need to transition towards a model where performance benchmarking is mandatory for pull requests to be merged. Performance regressions are just as serious as test regressions, so if we can't measure, then the MQ being broken is a feature in my opinion.\r\n\r\ni think that\u2019s a good goal, and i would like to explore what we need to get there, but i think it\u2019s a more complex problem than we can solve in this patch. why not start with this and iterate?",
        "pr_file_module": null
      },
      {
        "comment_id": "2405690364",
        "repo_full_name": "servo/servo",
        "pr_number": 39272,
        "pr_file": ".github/workflows/bencher.yml",
        "discussion_id": "2354088591",
        "commented_code": "@@ -42,22 +46,76 @@ env:\n   BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
        "comment_created_at": "2025-10-06T10:52:09+00:00",
        "comment_author": "delan",
        "comment_body": "> > > I think that is great, but at least for perf jobs it doesn't really make sense to me, since the perf measurements on github-hosted runners are not useful in practice due to the high volatility (counting instructions might work there, but that metric is also not incredibly useful).\r\n> >\r\n> > that\u2019s fair, yea, do you think we should skip running speedometer and dromaeo if no self-hosted runners are available?\r\n>\r\n> Probably we should avoid uploading metrics we aren't going to use (since there presumably is a cost, and bencher.dev is a single-person project as far as I understand). I think bencher also recently introduced rate limiting (for non paying orgs).\r\n\r\ni was inclined to agree with you that github-hosted benchmark results are not useful, but issues like #39641 show that even our existing github-hosted benchmarking can be very useful. i do expect that self-hosted benchmark results will be *more* useful though.",
        "pr_file_module": null
      },
      {
        "comment_id": "2405904580",
        "repo_full_name": "servo/servo",
        "pr_number": 39272,
        "pr_file": ".github/workflows/bencher.yml",
        "discussion_id": "2354088591",
        "commented_code": "@@ -42,22 +46,76 @@ env:\n   BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
        "comment_created_at": "2025-10-06T11:50:17+00:00",
        "comment_author": "sagudev",
        "comment_body": "> I already lost context here (and am a bit time constrained now, so can't look at the code again), but do non-perf related metrics like binary size need to be handled by the bencher workflow? I would imagine that the metric could be a regular output of the build workflow (and either directly uploaded, or if tokens are a problem, eventually uploaded by the bencher perf job).\r\n\r\nThis was done because bencher requires to send all data for single point (if we would send binary size from build workflow it would show as separate point).",
        "pr_file_module": null
      },
      {
        "comment_id": "2416407629",
        "repo_full_name": "servo/servo",
        "pr_number": 39272,
        "pr_file": ".github/workflows/bencher.yml",
        "discussion_id": "2354088591",
        "commented_code": "@@ -42,22 +46,76 @@ env:\n   BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
        "comment_created_at": "2025-10-09T11:05:14+00:00",
        "comment_author": "jschwe",
        "comment_body": "> i was inclined to agree with you that github-hosted benchmark results are not useful, but issues like https://github.com/servo/servo/issues/39641 show that even our existing github-hosted benchmarking can be very useful. i do expect that self-hosted benchmark results will be more useful though.\r\n\r\nMy assumption is that we would want to prevent PRs that regress performance from getting merged eventually (but rather sooner than later). We definitely need selfhosted runners to be able to measure accurately enough to be able to add thresholds that are low enough to be generally useful. GitHub hosted runners could be used to prevent major regressions, but anything smaller than lets say 10-20% would easily fall through the cracks given the volatility we see. I agree that it is better than nothing, but we would also need to measure with github-hosted runners on every commit to establish a baseline - Since our utilization is high, and we often use 100% of our github-hosted runners, I'm not sure if this is worth it over just accepting that the merge queue would be broken if our self-hosted benchmark runners are down. ",
        "pr_file_module": null
      },
      {
        "comment_id": "2419608767",
        "repo_full_name": "servo/servo",
        "pr_number": 39272,
        "pr_file": ".github/workflows/bencher.yml",
        "discussion_id": "2354088591",
        "commented_code": "@@ -42,22 +46,76 @@ env:\n   BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
        "comment_created_at": "2025-10-10T11:34:51+00:00",
        "comment_author": "delan",
        "comment_body": "the current relationship we have with the self-hosted runners is that they\u2019re provided on a best-effort basis, because no one is on call for outages. if you\u2019re interested in changing that, we should discuss how to get there with the broader servo community. i don\u2019t think this patch is the right place to unilaterally change that relationship and decide it\u2019s acceptable for the merge queue to be broken for hours or days at a time.",
        "pr_file_module": null
      },
      {
        "comment_id": "2420519836",
        "repo_full_name": "servo/servo",
        "pr_number": 39272,
        "pr_file": ".github/workflows/bencher.yml",
        "discussion_id": "2354088591",
        "commented_code": "@@ -42,22 +46,76 @@ env:\n   BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
        "comment_created_at": "2025-10-10T14:26:07+00:00",
        "comment_author": "mrego",
        "comment_body": "I think moving to self-hosted runners is independent of this discussion, so I'd propose we move to the self-hosted runners first and then we discuss in Zulip about how strict we want to be.\r\n\r\nBTW, in other projects like Chromium you don't get blocked due to performance regressions, the patch lands and then you get notified afterwards about the regressions, sometimes the patch has to be reverted, other times a fix can get merged and solve the regression. Just to show how other projects do this. The good part in Chromium is that the notifications are automatic opening a bug and tagging the person that landed the original patch, if we could do something like that in Bencher would be quite usefull. ",
        "pr_file_module": null
      },
      {
        "comment_id": "2420710939",
        "repo_full_name": "servo/servo",
        "pr_number": 39272,
        "pr_file": ".github/workflows/bencher.yml",
        "discussion_id": "2354088591",
        "commented_code": "@@ -42,22 +46,76 @@ env:\n   BENCHER_PROJECT: ${{ vars.BENCHER_PROJECT || 'servo' }}\n \n jobs:\n-  bencher:\n-    name: Bencher (${{ inputs.target }})\n-    # This needs to be kept in sync with the `--testbed` argument sent to bencher.\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n     runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      selected-runner-host: ${{ steps.select.outputs.selected-runner-host }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n     steps:\n-      - uses: actions/checkout@v4\n-        if: github.event_name != 'pull_request_target'\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          github-hosted-runner-label: ubuntu-22.04",
        "comment_created_at": "2025-10-10T15:02:24+00:00",
        "comment_author": "jschwe",
        "comment_body": "> i don\u2019t think this patch is the right place to unilaterally change that relationship and decide it\u2019s acceptable for the merge queue to be broken for hours or days at a time.\r\n\r\nMy intention was not to suggest that we do this now as part of this patch. I mainly meant to state that I believe long-term we want something like that (and yes that would discussions on how to practically implement it). I was mainly wondering if we could just not require the bencher workflows for the MQ (instead of falling back), and make it a requirement once self-hosted is stable enough, and we have relevant procedures inplace. But this PR has been cooking for long enough, so I'd be fine with merging as is and picking up the discussion another time. \r\n\r\n>BTW, in other projects like Chromium you don't get blocked due to performance regressions, the patch lands and then you get notified afterwards about the regressions, sometimes the patch has to be reverted, other times a fix can get merged and solve the regression.\r\n\r\nI only have second-hand knowledge about this, but my understanding was that chromium CI does have multiple layers, and there are performance tests run before merging (although the number of test-configurations run only after merging is considerably larger).\r\n\r\n> The good part in Chromium is that the notifications are automatic opening a bug and tagging the person that landed the original patch, if we could do something like that in Bencher would be quite usefull.\r\n\r\nWe can setup thresholds in bencher, which would trigger a warning on bencher (as a comment in the PR if run before merging), but the usefulness of thresholds correlates strongly with the stability of the results. ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2328677724",
    "pr_number": 39190,
    "pr_file": ".github/workflows/linux.yml",
    "created_at": "2025-09-07T13:06:28+00:00",
    "commented_code": "- name: Setup Python\n         if: ${{ runner.environment != 'self-hosted' }}\n         uses: ./.github/actions/setup-python\n+      - name: Change Mirror Priorities\n+        if: ${{ runner.environment != 'self-hosted' }}",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2328677724",
        "repo_full_name": "servo/servo",
        "pr_number": 39190,
        "pr_file": ".github/workflows/linux.yml",
        "discussion_id": "2328677724",
        "commented_code": "@@ -163,8 +163,12 @@ jobs:\n       - name: Setup Python\n         if: ${{ runner.environment != 'self-hosted' }}\n         uses: ./.github/actions/setup-python\n+      - name: Change Mirror Priorities\n+        if: ${{ runner.environment != 'self-hosted' }}",
        "comment_created_at": "2025-09-07T13:06:28+00:00",
        "comment_author": "yezhizhen",
        "comment_body": "Why we only need the condition here but not for `linux-wpt.yml`?",
        "pr_file_module": null
      },
      {
        "comment_id": "2328678442",
        "repo_full_name": "servo/servo",
        "pr_number": 39190,
        "pr_file": ".github/workflows/linux.yml",
        "discussion_id": "2328677724",
        "commented_code": "@@ -163,8 +163,12 @@ jobs:\n       - name: Setup Python\n         if: ${{ runner.environment != 'self-hosted' }}\n         uses: ./.github/actions/setup-python\n+      - name: Change Mirror Priorities\n+        if: ${{ runner.environment != 'self-hosted' }}",
        "comment_created_at": "2025-09-07T13:08:19+00:00",
        "comment_author": "sagudev",
        "comment_body": "wpt is never run on self-hosted runners. Self hosted runners already have bootstrap done and they do not use azure mirrors.",
        "pr_file_module": null
      },
      {
        "comment_id": "2328681629",
        "repo_full_name": "servo/servo",
        "pr_number": 39190,
        "pr_file": ".github/workflows/linux.yml",
        "discussion_id": "2328677724",
        "commented_code": "@@ -163,8 +163,12 @@ jobs:\n       - name: Setup Python\n         if: ${{ runner.environment != 'self-hosted' }}\n         uses: ./.github/actions/setup-python\n+      - name: Change Mirror Priorities\n+        if: ${{ runner.environment != 'self-hosted' }}",
        "comment_created_at": "2025-09-07T13:16:57+00:00",
        "comment_author": "yezhizhen",
        "comment_body": "So the linux workflow can be run on either self-hosted or github runner? How do I know which one am I using?",
        "pr_file_module": null
      },
      {
        "comment_id": "2328683156",
        "repo_full_name": "servo/servo",
        "pr_number": 39190,
        "pr_file": ".github/workflows/linux.yml",
        "discussion_id": "2328677724",
        "commented_code": "@@ -163,8 +163,12 @@ jobs:\n       - name: Setup Python\n         if: ${{ runner.environment != 'self-hosted' }}\n         uses: ./.github/actions/setup-python\n+      - name: Change Mirror Priorities\n+        if: ${{ runner.environment != 'self-hosted' }}",
        "comment_created_at": "2025-09-07T13:20:55+00:00",
        "comment_author": "sagudev",
        "comment_body": "If you run in you personal fork it's always github hosted runner, in servo/servo repo you can check runner name: https://github.com/servo/servo/actions/runs/17529042601/job/49783448664#step:1:2. github hosted runners have simple runner names (labels): https://github.com/actions/runner-images?tab=readme-ov-file#available-images",
        "pr_file_module": null
      },
      {
        "comment_id": "2328687866",
        "repo_full_name": "servo/servo",
        "pr_number": 39190,
        "pr_file": ".github/workflows/linux.yml",
        "discussion_id": "2328677724",
        "commented_code": "@@ -163,8 +163,12 @@ jobs:\n       - name: Setup Python\n         if: ${{ runner.environment != 'self-hosted' }}\n         uses: ./.github/actions/setup-python\n+      - name: Change Mirror Priorities\n+        if: ${{ runner.environment != 'self-hosted' }}",
        "comment_created_at": "2025-09-07T13:33:43+00:00",
        "comment_author": "yezhizhen",
        "comment_body": "Ah. Is it random?",
        "pr_file_module": null
      },
      {
        "comment_id": "2328689473",
        "repo_full_name": "servo/servo",
        "pr_number": 39190,
        "pr_file": ".github/workflows/linux.yml",
        "discussion_id": "2328677724",
        "commented_code": "@@ -163,8 +163,12 @@ jobs:\n       - name: Setup Python\n         if: ${{ runner.environment != 'self-hosted' }}\n         uses: ./.github/actions/setup-python\n+      - name: Change Mirror Priorities\n+        if: ${{ runner.environment != 'self-hosted' }}",
        "comment_created_at": "2025-09-07T13:38:13+00:00",
        "comment_author": "sagudev",
        "comment_body": "I think it's generated somewhere in this repo: https://github.com/servo/ci-runners",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2425271719",
    "pr_number": 39789,
    "pr_file": ".github/workflows/coverage.yml",
    "created_at": "2025-10-13T05:48:47+00:00",
    "commented_code": "+name: Code Coverage\n+on:\n+  workflow_call:\n+    inputs:\n+      force-github-hosted-runner:\n+        required: false\n+        type: boolean\n+        default: false\n+  workflow_dispatch:\n+    inputs:\n+      force-github-hosted-runner:\n+        description: \"Force using github hosted runners\"\n+        required: false\n+        type: boolean\n+        default: false\n+\n+env:\n+  RUST_BACKTRACE: 1\n+  SHELL: /bin/bash\n+\n+jobs:\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n+    runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n+    steps:\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          # Before updating the GH action runner image for the nightly job, ensure\n+          # that the system has a glibc version that is compatible with the one\n+          # used by the wpt.fyi runners.\n+          github-hosted-runner-label: ubuntu-22.04\n+          self-hosted-image-name: servo-ubuntu2204\n+          # You can disable self-hosted runners globally by creating a repository variable named\n+          # NO_SELF_HOSTED_RUNNERS with any non-empty value.\n+          # <https://github.com/servo/servo/settings/variables/actions>\n+          NO_SELF_HOSTED_RUNNERS: ${{ vars.NO_SELF_HOSTED_RUNNERS }}\n+          # Any other boolean conditions that disable self-hosted runners go here.\n+          force-github-hosted-runner: ${{ inputs.force-github-hosted-runner }}\n+  runner-timeout:\n+    needs:\n+      - runner-select\n+    if: ${{ fromJSON(needs.runner-select.outputs.is-self-hosted) }}\n+    runs-on: ubuntu-22.04\n+    steps:\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner timeout\n+        uses: ./.github/actions/runner-timeout\n+        with:\n+          github_token: '${{ secrets.GITHUB_TOKEN }}'\n+          unique-id: '${{ needs.runner-select.outputs.unique-id }}'\n+\n+  unit-test-coverage:\n+    needs: runner-select\n+    name: Unit Test Coverage [${{ needs.runner-select.outputs.unique-id }}]\n+    runs-on: ${{ needs.runner-select.outputs.selected-runner-label }}\n+    continue-on-error: true\n+    steps:\n+      - uses: actions/checkout@v4\n+        if: ${{ runner.environment != 'self-hosted' && github.event_name != 'pull_request_target' }}\n+      # This is necessary to checkout the pull request if this run was triggered via a\n+      # `pull_request_target` event.\n+      - uses: actions/checkout@v4\n+        if: ${{ runner.environment != 'self-hosted' && github.event_name == 'pull_request_target' }}\n+        with:\n+          ref: ${{ github.event.pull_request.head.sha }}\n+      # Faster checkout for self-hosted runner that uses prebaked repo.\n+      - if: ${{ runner.environment == 'self-hosted' && github.event_name != 'pull_request_target' }}\n+        run: git fetch --depth=1 origin $GITHUB_SHA\n+      - if: ${{ runner.environment == 'self-hosted' && github.event_name == 'pull_request_target' }}\n+        run: git fetch --depth=1 origin ${{ github.event.pull_request.head.sha }}\n+      - if: ${{ runner.environment == 'self-hosted' }}\n+        # Same as `git switch --detach FETCH_HEAD`, but fixes up dirty working\n+        # trees, in case the runner image was baked with a dirty working tree.\n+        run: |\n+          git switch --detach\n+          git reset --hard FETCH_HEAD\n+      - name: Free Disk Space (Ubuntu)\n+        uses: jlumbroso/free-disk-space@main\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        with:\n+          tool-cache: false\n+          large-packages: false\n+          swap-storage: false\n+      - name: Set LIBCLANG_PATH env # needed for bindgen in mozangle\n+        shell: bash\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        run: echo \"LIBCLANG_PATH=/usr/lib/llvm-14/lib\" >> $GITHUB_ENV\n+      - name: Setup Python\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        uses: ./.github/actions/setup-python\n+      - name: Change Mirror Priorities\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        uses: ./.github/actions/apt-mirrors\n+      - name: Install cargo-llvm-cov\n+        uses: taiki-e/install-action@v2\n+        with:\n+          tool: cargo-llvm-cov\n+      - name: Bootstrap dependencies\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        shell: bash\n+        run: |\n+          sudo apt update\n+          ./mach bootstrap --skip-lints\n+      # We need to reduce the concurrency to prevent OOM errors (when building / linking servo).\n+      # Adding the coverage instrumentation seems to increase the memory usage when building / linking.\n+      - name: Determine options\n+        id: options\n+        run: | \n+          echo \"nproc: $(nproc)\"\n+          NUM_JOBS=$(nproc)\n+          # Todo: a more sophisticated implementation would take into account available memory.\n+          if [[ ${{ runner.environment }} == 'self-hosted' ]];\n+          then\n+            NUM_JOBS=3\n+            CARGO_PROFILE=dev\n+          else\n+            NUM_JOBS=1\n+            # github hosted runners don't have enough diskspace for the dev profile.\n+            CARGO_PROFILE=coverage\n+          fi \n+          echo \"num_jobs=${NUM_JOBS}\" | tee $GITHUB_OUTPUT\n+          echo \"cargo_profile=${CARGO_PROFILE}\" | tee $GITHUB_OUTPUT\n+      - name: Run unit-tests with coverage\n+        shell: bash\n+        run: | \n+          ./mach test-unit --code-coverage \\\n+              --profile=${{ steps.options.outputs.cargo_profile }} \\\n+              --llvm-cov-option=--codecov \\\n+              --llvm-cov-option=--output-path=codecov.json \\\n+              --llvm-cov-option=--jobs=${{ steps.options.outputs.num_jobs}}\n+      - name: Upload coverage to Codecov\n+        uses: codecov/codecov-action@v5\n+        with:\n+          token: ${{ secrets.CODECOV_TOKEN }}\n+          files: codecov.json,support/crown/codecov.json\n+          fail_ci_if_error: true\n+          flags: unittests",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2425271719",
        "repo_full_name": "servo/servo",
        "pr_number": 39789,
        "pr_file": ".github/workflows/coverage.yml",
        "discussion_id": "2425271719",
        "commented_code": "@@ -0,0 +1,152 @@\n+name: Code Coverage\n+on:\n+  workflow_call:\n+    inputs:\n+      force-github-hosted-runner:\n+        required: false\n+        type: boolean\n+        default: false\n+  workflow_dispatch:\n+    inputs:\n+      force-github-hosted-runner:\n+        description: \"Force using github hosted runners\"\n+        required: false\n+        type: boolean\n+        default: false\n+\n+env:\n+  RUST_BACKTRACE: 1\n+  SHELL: /bin/bash\n+\n+jobs:\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n+    runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n+    steps:\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          # Before updating the GH action runner image for the nightly job, ensure\n+          # that the system has a glibc version that is compatible with the one\n+          # used by the wpt.fyi runners.\n+          github-hosted-runner-label: ubuntu-22.04\n+          self-hosted-image-name: servo-ubuntu2204\n+          # You can disable self-hosted runners globally by creating a repository variable named\n+          # NO_SELF_HOSTED_RUNNERS with any non-empty value.\n+          # <https://github.com/servo/servo/settings/variables/actions>\n+          NO_SELF_HOSTED_RUNNERS: ${{ vars.NO_SELF_HOSTED_RUNNERS }}\n+          # Any other boolean conditions that disable self-hosted runners go here.\n+          force-github-hosted-runner: ${{ inputs.force-github-hosted-runner }}\n+  runner-timeout:\n+    needs:\n+      - runner-select\n+    if: ${{ fromJSON(needs.runner-select.outputs.is-self-hosted) }}\n+    runs-on: ubuntu-22.04\n+    steps:\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner timeout\n+        uses: ./.github/actions/runner-timeout\n+        with:\n+          github_token: '${{ secrets.GITHUB_TOKEN }}'\n+          unique-id: '${{ needs.runner-select.outputs.unique-id }}'\n+\n+  unit-test-coverage:\n+    needs: runner-select\n+    name: Unit Test Coverage [${{ needs.runner-select.outputs.unique-id }}]\n+    runs-on: ${{ needs.runner-select.outputs.selected-runner-label }}\n+    continue-on-error: true\n+    steps:\n+      - uses: actions/checkout@v4\n+        if: ${{ runner.environment != 'self-hosted' && github.event_name != 'pull_request_target' }}\n+      # This is necessary to checkout the pull request if this run was triggered via a\n+      # `pull_request_target` event.\n+      - uses: actions/checkout@v4\n+        if: ${{ runner.environment != 'self-hosted' && github.event_name == 'pull_request_target' }}\n+        with:\n+          ref: ${{ github.event.pull_request.head.sha }}\n+      # Faster checkout for self-hosted runner that uses prebaked repo.\n+      - if: ${{ runner.environment == 'self-hosted' && github.event_name != 'pull_request_target' }}\n+        run: git fetch --depth=1 origin $GITHUB_SHA\n+      - if: ${{ runner.environment == 'self-hosted' && github.event_name == 'pull_request_target' }}\n+        run: git fetch --depth=1 origin ${{ github.event.pull_request.head.sha }}\n+      - if: ${{ runner.environment == 'self-hosted' }}\n+        # Same as `git switch --detach FETCH_HEAD`, but fixes up dirty working\n+        # trees, in case the runner image was baked with a dirty working tree.\n+        run: |\n+          git switch --detach\n+          git reset --hard FETCH_HEAD\n+      - name: Free Disk Space (Ubuntu)\n+        uses: jlumbroso/free-disk-space@main\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        with:\n+          tool-cache: false\n+          large-packages: false\n+          swap-storage: false\n+      - name: Set LIBCLANG_PATH env # needed for bindgen in mozangle\n+        shell: bash\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        run: echo \"LIBCLANG_PATH=/usr/lib/llvm-14/lib\" >> $GITHUB_ENV\n+      - name: Setup Python\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        uses: ./.github/actions/setup-python\n+      - name: Change Mirror Priorities\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        uses: ./.github/actions/apt-mirrors\n+      - name: Install cargo-llvm-cov\n+        uses: taiki-e/install-action@v2\n+        with:\n+          tool: cargo-llvm-cov\n+      - name: Bootstrap dependencies\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        shell: bash\n+        run: |\n+          sudo apt update\n+          ./mach bootstrap --skip-lints\n+      # We need to reduce the concurrency to prevent OOM errors (when building / linking servo).\n+      # Adding the coverage instrumentation seems to increase the memory usage when building / linking.\n+      - name: Determine options\n+        id: options\n+        run: | \n+          echo \"nproc: $(nproc)\"\n+          NUM_JOBS=$(nproc)\n+          # Todo: a more sophisticated implementation would take into account available memory.\n+          if [[ ${{ runner.environment }} == 'self-hosted' ]];\n+          then\n+            NUM_JOBS=3\n+            CARGO_PROFILE=dev\n+          else\n+            NUM_JOBS=1\n+            # github hosted runners don't have enough diskspace for the dev profile.\n+            CARGO_PROFILE=coverage\n+          fi \n+          echo \"num_jobs=${NUM_JOBS}\" | tee $GITHUB_OUTPUT\n+          echo \"cargo_profile=${CARGO_PROFILE}\" | tee $GITHUB_OUTPUT\n+      - name: Run unit-tests with coverage\n+        shell: bash\n+        run: | \n+          ./mach test-unit --code-coverage \\\n+              --profile=${{ steps.options.outputs.cargo_profile }} \\\n+              --llvm-cov-option=--codecov \\\n+              --llvm-cov-option=--output-path=codecov.json \\\n+              --llvm-cov-option=--jobs=${{ steps.options.outputs.num_jobs}}\n+      - name: Upload coverage to Codecov\n+        uses: codecov/codecov-action@v5\n+        with:\n+          token: ${{ secrets.CODECOV_TOKEN }}\n+          files: codecov.json,support/crown/codecov.json\n+          fail_ci_if_error: true\n+          flags: unittests",
        "comment_created_at": "2025-10-13T05:48:47+00:00",
        "comment_author": "sagudev",
        "comment_body": "Will this command properly account for try runs (they are happening on push)? I know we have some special code in bencher workflows to set base commit for all workflow cases.",
        "pr_file_module": null
      },
      {
        "comment_id": "2425382842",
        "repo_full_name": "servo/servo",
        "pr_number": 39789,
        "pr_file": ".github/workflows/coverage.yml",
        "discussion_id": "2425271719",
        "commented_code": "@@ -0,0 +1,152 @@\n+name: Code Coverage\n+on:\n+  workflow_call:\n+    inputs:\n+      force-github-hosted-runner:\n+        required: false\n+        type: boolean\n+        default: false\n+  workflow_dispatch:\n+    inputs:\n+      force-github-hosted-runner:\n+        description: \"Force using github hosted runners\"\n+        required: false\n+        type: boolean\n+        default: false\n+\n+env:\n+  RUST_BACKTRACE: 1\n+  SHELL: /bin/bash\n+\n+jobs:\n+  # Runs the underlying job (\u201cworkload\u201d) on a self-hosted runner if available,\n+  # with the help of a `runner-select` job and a `runner-timeout` job.\n+  runner-select:\n+    runs-on: ubuntu-22.04\n+    outputs:\n+      unique-id: ${{ steps.select.outputs.unique-id }}\n+      selected-runner-label: ${{ steps.select.outputs.selected-runner-label }}\n+      is-self-hosted: ${{ steps.select.outputs.is-self-hosted }}\n+    steps:\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner select\n+        id: select\n+        uses: ./.github/actions/runner-select\n+        with:\n+          monitor-api-token: ${{ secrets.SERVO_CI_MONITOR_API_TOKEN }}\n+          # Before updating the GH action runner image for the nightly job, ensure\n+          # that the system has a glibc version that is compatible with the one\n+          # used by the wpt.fyi runners.\n+          github-hosted-runner-label: ubuntu-22.04\n+          self-hosted-image-name: servo-ubuntu2204\n+          # You can disable self-hosted runners globally by creating a repository variable named\n+          # NO_SELF_HOSTED_RUNNERS with any non-empty value.\n+          # <https://github.com/servo/servo/settings/variables/actions>\n+          NO_SELF_HOSTED_RUNNERS: ${{ vars.NO_SELF_HOSTED_RUNNERS }}\n+          # Any other boolean conditions that disable self-hosted runners go here.\n+          force-github-hosted-runner: ${{ inputs.force-github-hosted-runner }}\n+  runner-timeout:\n+    needs:\n+      - runner-select\n+    if: ${{ fromJSON(needs.runner-select.outputs.is-self-hosted) }}\n+    runs-on: ubuntu-22.04\n+    steps:\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+        with:\n+          sparse-checkout: '.github'\n+      - name: Runner timeout\n+        uses: ./.github/actions/runner-timeout\n+        with:\n+          github_token: '${{ secrets.GITHUB_TOKEN }}'\n+          unique-id: '${{ needs.runner-select.outputs.unique-id }}'\n+\n+  unit-test-coverage:\n+    needs: runner-select\n+    name: Unit Test Coverage [${{ needs.runner-select.outputs.unique-id }}]\n+    runs-on: ${{ needs.runner-select.outputs.selected-runner-label }}\n+    continue-on-error: true\n+    steps:\n+      - uses: actions/checkout@v4\n+        if: ${{ runner.environment != 'self-hosted' && github.event_name != 'pull_request_target' }}\n+      # This is necessary to checkout the pull request if this run was triggered via a\n+      # `pull_request_target` event.\n+      - uses: actions/checkout@v4\n+        if: ${{ runner.environment != 'self-hosted' && github.event_name == 'pull_request_target' }}\n+        with:\n+          ref: ${{ github.event.pull_request.head.sha }}\n+      # Faster checkout for self-hosted runner that uses prebaked repo.\n+      - if: ${{ runner.environment == 'self-hosted' && github.event_name != 'pull_request_target' }}\n+        run: git fetch --depth=1 origin $GITHUB_SHA\n+      - if: ${{ runner.environment == 'self-hosted' && github.event_name == 'pull_request_target' }}\n+        run: git fetch --depth=1 origin ${{ github.event.pull_request.head.sha }}\n+      - if: ${{ runner.environment == 'self-hosted' }}\n+        # Same as `git switch --detach FETCH_HEAD`, but fixes up dirty working\n+        # trees, in case the runner image was baked with a dirty working tree.\n+        run: |\n+          git switch --detach\n+          git reset --hard FETCH_HEAD\n+      - name: Free Disk Space (Ubuntu)\n+        uses: jlumbroso/free-disk-space@main\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        with:\n+          tool-cache: false\n+          large-packages: false\n+          swap-storage: false\n+      - name: Set LIBCLANG_PATH env # needed for bindgen in mozangle\n+        shell: bash\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        run: echo \"LIBCLANG_PATH=/usr/lib/llvm-14/lib\" >> $GITHUB_ENV\n+      - name: Setup Python\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        uses: ./.github/actions/setup-python\n+      - name: Change Mirror Priorities\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        uses: ./.github/actions/apt-mirrors\n+      - name: Install cargo-llvm-cov\n+        uses: taiki-e/install-action@v2\n+        with:\n+          tool: cargo-llvm-cov\n+      - name: Bootstrap dependencies\n+        if: ${{ runner.environment != 'self-hosted' }}\n+        shell: bash\n+        run: |\n+          sudo apt update\n+          ./mach bootstrap --skip-lints\n+      # We need to reduce the concurrency to prevent OOM errors (when building / linking servo).\n+      # Adding the coverage instrumentation seems to increase the memory usage when building / linking.\n+      - name: Determine options\n+        id: options\n+        run: | \n+          echo \"nproc: $(nproc)\"\n+          NUM_JOBS=$(nproc)\n+          # Todo: a more sophisticated implementation would take into account available memory.\n+          if [[ ${{ runner.environment }} == 'self-hosted' ]];\n+          then\n+            NUM_JOBS=3\n+            CARGO_PROFILE=dev\n+          else\n+            NUM_JOBS=1\n+            # github hosted runners don't have enough diskspace for the dev profile.\n+            CARGO_PROFILE=coverage\n+          fi \n+          echo \"num_jobs=${NUM_JOBS}\" | tee $GITHUB_OUTPUT\n+          echo \"cargo_profile=${CARGO_PROFILE}\" | tee $GITHUB_OUTPUT\n+      - name: Run unit-tests with coverage\n+        shell: bash\n+        run: | \n+          ./mach test-unit --code-coverage \\\n+              --profile=${{ steps.options.outputs.cargo_profile }} \\\n+              --llvm-cov-option=--codecov \\\n+              --llvm-cov-option=--output-path=codecov.json \\\n+              --llvm-cov-option=--jobs=${{ steps.options.outputs.num_jobs}}\n+      - name: Upload coverage to Codecov\n+        uses: codecov/codecov-action@v5\n+        with:\n+          token: ${{ secrets.CODECOV_TOKEN }}\n+          files: codecov.json,support/crown/codecov.json\n+          fail_ci_if_error: true\n+          flags: unittests",
        "comment_created_at": "2025-10-13T07:07:46+00:00",
        "comment_author": "jschwe",
        "comment_body": "No, it won't. The action has input variables which allow us to override settings like PR number, base commit etc., so we should be able to do something similar to the bencher workflow. I'm just thinking it might be easier to add that after we merged the baseline.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2427879570",
    "pr_number": 39789,
    "pr_file": ".github/workflows/dispatch-workflow.yml",
    "created_at": "2025-10-14T04:29:34+00:00",
    "commented_code": "bencher:\n         required: true\n         type: boolean\n+      coverage:\n+        required: true",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2427879570",
        "repo_full_name": "servo/servo",
        "pr_number": 39789,
        "pr_file": ".github/workflows/dispatch-workflow.yml",
        "discussion_id": "2427879570",
        "commented_code": "@@ -29,6 +29,9 @@ on:\n       bencher:\n         required: true\n         type: boolean\n+      coverage:\n+        required: true",
        "comment_created_at": "2025-10-14T04:29:34+00:00",
        "comment_author": "sagudev",
        "comment_body": "Because this is required, we need to provide it in all workflow entrypoints, but this pr is missing it in try-label.yml",
        "pr_file_module": null
      }
    ]
  }
]