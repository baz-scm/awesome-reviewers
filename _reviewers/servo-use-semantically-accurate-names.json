[
  {
    "discussion_id": "2454844625",
    "pr_number": 40014,
    "pr_file": "ports/servoshell/desktop/app_state.rs",
    "created_at": "2025-10-23T11:44:57+00:00",
    "commented_code": "/// to inform the WebDriver server when the event has been fully handled. This map is used\n     /// to report back to WebDriver when that happens.\n     pending_webdriver_events: HashMap<InputEventId, Sender<()>>,\n+\n+    /// A list of showing [`InputMethod`] interfaces.\n+    visible_input_method: Vec<EmbedderControlId>,",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2454844625",
        "repo_full_name": "servo/servo",
        "pr_number": 40014,
        "pr_file": "ports/servoshell/desktop/app_state.rs",
        "discussion_id": "2454844625",
        "commented_code": "@@ -97,6 +97,9 @@ pub struct RunningAppStateInner {\n     /// to inform the WebDriver server when the event has been fully handled. This map is used\n     /// to report back to WebDriver when that happens.\n     pending_webdriver_events: HashMap<InputEventId, Sender<()>>,\n+\n+    /// A list of showing [`InputMethod`] interfaces.\n+    visible_input_method: Vec<EmbedderControlId>,",
        "comment_created_at": "2025-10-23T11:44:57+00:00",
        "comment_author": "mukilan",
        "comment_body": "Should this use a plural name?\r\n\r\n```suggestion\r\n    visible_input_methods: Vec<EmbedderControlId>,\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1805116114",
    "pr_number": 31746,
    "pr_file": "components/layout_2020/replaced.rs",
    "created_at": "2024-10-17T16:56:00+00:00",
    "commented_code": "ratio: None,\n         }\n     }\n+\n+    pub(crate) fn with_fallback(self, ratio: Option<f32>) -> Self {",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "1805116114",
        "repo_full_name": "servo/servo",
        "pr_number": 31746,
        "pr_file": "components/layout_2020/replaced.rs",
        "discussion_id": "1805116114",
        "commented_code": "@@ -89,6 +89,14 @@ impl NaturalSizes {\n             ratio: None,\n         }\n     }\n+\n+    pub(crate) fn with_fallback(self, ratio: Option<f32>) -> Self {",
        "comment_created_at": "2024-10-17T16:56:00+00:00",
        "comment_author": "Loirooriol",
        "comment_body": "Name it `with_ratio` instead? Or there is a single caller, doing `NaturalSizes::empty().with_fallback`, so maybe\r\n\r\n```rs\r\n    pub(crate) fn from_ratio(ratio: Option<f32>) -> Self {\r\n        Self {\r\n            width: None,\r\n            height: None,\r\n            ratio,\r\n        }\r\n    }\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2390531562",
    "pr_number": 39585,
    "pr_file": "components/script/dom/mod.rs",
    "created_at": "2025-09-30T09:24:53+00:00",
    "commented_code": "pub(crate) mod svgimageelement;\n pub(crate) mod svgsvgelement;\n #[cfg(feature = \"testbinding\")]\n-pub(crate) mod testbinding;\n+mod test;",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2390531562",
        "repo_full_name": "servo/servo",
        "pr_number": 39585,
        "pr_file": "components/script/dom/mod.rs",
        "discussion_id": "2390531562",
        "commented_code": "@@ -455,29 +455,9 @@ pub(crate) mod svggraphicselement;\n pub(crate) mod svgimageelement;\n pub(crate) mod svgsvgelement;\n #[cfg(feature = \"testbinding\")]\n-pub(crate) mod testbinding;\n+mod test;",
        "comment_created_at": "2025-09-30T09:24:53+00:00",
        "comment_author": "mrobinson",
        "comment_body": "Nit: Can you call this `testing` instead to refer to the general concept of testing rather than a single test?",
        "pr_file_module": null
      },
      {
        "comment_id": "2390570163",
        "repo_full_name": "servo/servo",
        "pr_number": 39585,
        "pr_file": "components/script/dom/mod.rs",
        "discussion_id": "2390531562",
        "commented_code": "@@ -455,29 +455,9 @@ pub(crate) mod svggraphicselement;\n pub(crate) mod svgimageelement;\n pub(crate) mod svgsvgelement;\n #[cfg(feature = \"testbinding\")]\n-pub(crate) mod testbinding;\n+mod test;",
        "comment_created_at": "2025-09-30T09:34:12+00:00",
        "comment_author": "Gae24",
        "comment_body": "Done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2404521909",
    "pr_number": 39658,
    "pr_file": "components/script/dom/decompressionstream.rs",
    "created_at": "2025-10-05T14:55:28+00:00",
    "commented_code": "+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at http://mozilla.org/MPL/2.0/. */\n+\n+use std::cell::RefCell;\n+use std::io::{self, Write};\n+use std::ptr;\n+\n+use dom_struct::dom_struct;\n+use flate2::write::{DeflateDecoder, GzDecoder, ZlibDecoder};\n+use js::jsapi::JSObject;\n+use js::jsval::UndefinedValue;\n+use js::rust::{HandleObject as SafeHandleObject, HandleValue as SafeHandleValue};\n+use js::typedarray::Uint8Array;\n+\n+use crate::dom::bindings::buffer_source::create_buffer_source;\n+use crate::dom::bindings::codegen::Bindings::CompressionStreamBinding::CompressionFormat;\n+use crate::dom::bindings::codegen::Bindings::DecompressionStreamBinding::DecompressionStreamMethods;\n+use crate::dom::bindings::codegen::UnionTypes::ArrayBufferViewOrArrayBuffer;\n+use crate::dom::bindings::conversions::{SafeFromJSValConvertible, SafeToJSValConvertible};\n+use crate::dom::bindings::error::{Error, Fallible};\n+use crate::dom::bindings::reflector::{Reflector, reflect_dom_object_with_proto};\n+use crate::dom::bindings::root::{Dom, DomRoot};\n+use crate::dom::transformstreamdefaultcontroller::TransformerType;\n+use crate::dom::types::{\n+    GlobalScope, ReadableStream, TransformStream, TransformStreamDefaultController, WritableStream,\n+};\n+use crate::script_runtime::{CanGc, JSContext as SafeJSContext};\n+\n+/// A wrapper to blend ZlibDecoder<Vec<u8>>, DeflateDecoder<Vec<u8>> and GzDecoder<Vec<u8>>\n+/// together as a single type.\n+enum Decompressor {\n+    Deflate(ZlibDecoder<Vec<u8>>),\n+    DeflateRaw(DeflateDecoder<Vec<u8>>),\n+    Gzip(GzDecoder<Vec<u8>>),\n+}\n+\n+/// Expose methods of the inner decoder.\n+impl Decompressor {\n+    fn new(format: CompressionFormat) -> Decompressor {\n+        match format {\n+            CompressionFormat::Deflate => Decompressor::Deflate(ZlibDecoder::new(Vec::new())),\n+            CompressionFormat::Deflate_raw => {\n+                Decompressor::DeflateRaw(DeflateDecoder::new(Vec::new()))\n+            },\n+            CompressionFormat::Gzip => Decompressor::Gzip(GzDecoder::new(Vec::new())),\n+        }\n+    }\n+\n+    fn get_ref(&self) -> &Vec<u8> {\n+        match self {\n+            Decompressor::Deflate(zlib_decoder) => zlib_decoder.get_ref(),\n+            Decompressor::DeflateRaw(deflate_decoder) => deflate_decoder.get_ref(),\n+            Decompressor::Gzip(gz_decoder) => gz_decoder.get_ref(),\n+        }\n+    }\n+\n+    fn get_mut(&mut self) -> &mut Vec<u8> {\n+        match self {\n+            Decompressor::Deflate(zlib_decoder) => zlib_decoder.get_mut(),\n+            Decompressor::DeflateRaw(deflate_decoder) => deflate_decoder.get_mut(),\n+            Decompressor::Gzip(gz_decoder) => gz_decoder.get_mut(),\n+        }\n+    }\n+\n+    fn write(&mut self, buf: &[u8]) -> Result<usize, io::Error> {\n+        match self {\n+            Decompressor::Deflate(zlib_decoder) => zlib_decoder.write(buf),\n+            Decompressor::DeflateRaw(deflate_decoder) => deflate_decoder.write(buf),\n+            Decompressor::Gzip(gz_decoder) => gz_decoder.write(buf),\n+        }\n+    }\n+\n+    fn write_all(&mut self, buf: &[u8]) -> Result<(), io::Error> {\n+        match self {\n+            Decompressor::Deflate(zlib_decoder) => zlib_decoder.write_all(buf),\n+            Decompressor::DeflateRaw(deflate_decoder) => deflate_decoder.write_all(buf),\n+            Decompressor::Gzip(gz_decoder) => gz_decoder.write_all(buf),\n+        }\n+    }\n+\n+    fn flush(&mut self) -> io::Result<()> {\n+        match self {\n+            Decompressor::Deflate(zlib_decoder) => zlib_decoder.flush(),\n+            Decompressor::DeflateRaw(deflate_decoder) => deflate_decoder.flush(),\n+            Decompressor::Gzip(gz_decoder) => gz_decoder.flush(),\n+        }\n+    }\n+\n+    fn try_finish(&mut self) -> io::Result<()> {\n+        match self {\n+            Decompressor::Deflate(zlib_decoder) => zlib_decoder.try_finish(),\n+            Decompressor::DeflateRaw(deflate_decoder) => deflate_decoder.try_finish(),\n+            Decompressor::Gzip(gz_decoder) => gz_decoder.try_finish(),\n+        }\n+    }\n+}\n+\n+/// <https://compression.spec.whatwg.org/#decompressionstream>\n+#[dom_struct]\n+pub(crate) struct DecompressionStream {\n+    reflector_: Reflector,\n+\n+    /// <https://streams.spec.whatwg.org/#generictransformstream>\n+    transform: Dom<TransformStream>,\n+\n+    /// <https://compression.spec.whatwg.org/#decompressionstream-format>\n+    format: CompressionFormat,\n+\n+    // <https://compression.spec.whatwg.org/#decompressionstream-context>\n+    #[ignore_malloc_size_of = \"defined in flate2\"]\n+    #[no_trace]\n+    context: RefCell<Decompressor>,\n+}\n+\n+impl DecompressionStream {\n+    fn new_inherited(\n+        transform: &TransformStream,\n+        format: CompressionFormat,\n+    ) -> DecompressionStream {\n+        DecompressionStream {\n+            reflector_: Reflector::new(),\n+            transform: Dom::from_ref(transform),\n+            format,\n+            context: RefCell::new(Decompressor::new(format)),\n+        }\n+    }\n+\n+    fn new_with_proto(\n+        global: &GlobalScope,\n+        proto: Option<SafeHandleObject>,\n+        transform: &TransformStream,\n+        format: CompressionFormat,\n+        can_gc: CanGc,\n+    ) -> DomRoot<DecompressionStream> {\n+        reflect_dom_object_with_proto(\n+            Box::new(DecompressionStream::new_inherited(transform, format)),\n+            global,\n+            proto,\n+            can_gc,\n+        )\n+    }\n+}\n+\n+impl DecompressionStreamMethods<crate::DomTypeHolder> for DecompressionStream {\n+    /// <https://compression.spec.whatwg.org/#dom-decompressionstream-decompressionstream>\n+    fn Constructor(\n+        global: &GlobalScope,\n+        proto: Option<SafeHandleObject>,\n+        can_gc: CanGc,\n+        format: CompressionFormat,\n+    ) -> Fallible<DomRoot<DecompressionStream>> {\n+        // Step 1. If format is unsupported in DecompressionStream, then throw a TypeError.\n+        // NOTE: All of \"deflate\", \"deflate_raw\" and \"gzip\" are supported.\n+\n+        // Step 2. Set this\u2019s format to format.\n+        // Step 5. Set this\u2019s transform to a new TransformStream.\n+        let transform = TransformStream::new_with_proto(global, None, can_gc);\n+        let this = DecompressionStream::new_with_proto(global, proto, &transform, format, can_gc);",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2404521909",
        "repo_full_name": "servo/servo",
        "pr_number": 39658,
        "pr_file": "components/script/dom/decompressionstream.rs",
        "discussion_id": "2404521909",
        "commented_code": "@@ -0,0 +1,303 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at http://mozilla.org/MPL/2.0/. */\n+\n+use std::cell::RefCell;\n+use std::io::{self, Write};\n+use std::ptr;\n+\n+use dom_struct::dom_struct;\n+use flate2::write::{DeflateDecoder, GzDecoder, ZlibDecoder};\n+use js::jsapi::JSObject;\n+use js::jsval::UndefinedValue;\n+use js::rust::{HandleObject as SafeHandleObject, HandleValue as SafeHandleValue};\n+use js::typedarray::Uint8Array;\n+\n+use crate::dom::bindings::buffer_source::create_buffer_source;\n+use crate::dom::bindings::codegen::Bindings::CompressionStreamBinding::CompressionFormat;\n+use crate::dom::bindings::codegen::Bindings::DecompressionStreamBinding::DecompressionStreamMethods;\n+use crate::dom::bindings::codegen::UnionTypes::ArrayBufferViewOrArrayBuffer;\n+use crate::dom::bindings::conversions::{SafeFromJSValConvertible, SafeToJSValConvertible};\n+use crate::dom::bindings::error::{Error, Fallible};\n+use crate::dom::bindings::reflector::{Reflector, reflect_dom_object_with_proto};\n+use crate::dom::bindings::root::{Dom, DomRoot};\n+use crate::dom::transformstreamdefaultcontroller::TransformerType;\n+use crate::dom::types::{\n+    GlobalScope, ReadableStream, TransformStream, TransformStreamDefaultController, WritableStream,\n+};\n+use crate::script_runtime::{CanGc, JSContext as SafeJSContext};\n+\n+/// A wrapper to blend ZlibDecoder<Vec<u8>>, DeflateDecoder<Vec<u8>> and GzDecoder<Vec<u8>>\n+/// together as a single type.\n+enum Decompressor {\n+    Deflate(ZlibDecoder<Vec<u8>>),\n+    DeflateRaw(DeflateDecoder<Vec<u8>>),\n+    Gzip(GzDecoder<Vec<u8>>),\n+}\n+\n+/// Expose methods of the inner decoder.\n+impl Decompressor {\n+    fn new(format: CompressionFormat) -> Decompressor {\n+        match format {\n+            CompressionFormat::Deflate => Decompressor::Deflate(ZlibDecoder::new(Vec::new())),\n+            CompressionFormat::Deflate_raw => {\n+                Decompressor::DeflateRaw(DeflateDecoder::new(Vec::new()))\n+            },\n+            CompressionFormat::Gzip => Decompressor::Gzip(GzDecoder::new(Vec::new())),\n+        }\n+    }\n+\n+    fn get_ref(&self) -> &Vec<u8> {\n+        match self {\n+            Decompressor::Deflate(zlib_decoder) => zlib_decoder.get_ref(),\n+            Decompressor::DeflateRaw(deflate_decoder) => deflate_decoder.get_ref(),\n+            Decompressor::Gzip(gz_decoder) => gz_decoder.get_ref(),\n+        }\n+    }\n+\n+    fn get_mut(&mut self) -> &mut Vec<u8> {\n+        match self {\n+            Decompressor::Deflate(zlib_decoder) => zlib_decoder.get_mut(),\n+            Decompressor::DeflateRaw(deflate_decoder) => deflate_decoder.get_mut(),\n+            Decompressor::Gzip(gz_decoder) => gz_decoder.get_mut(),\n+        }\n+    }\n+\n+    fn write(&mut self, buf: &[u8]) -> Result<usize, io::Error> {\n+        match self {\n+            Decompressor::Deflate(zlib_decoder) => zlib_decoder.write(buf),\n+            Decompressor::DeflateRaw(deflate_decoder) => deflate_decoder.write(buf),\n+            Decompressor::Gzip(gz_decoder) => gz_decoder.write(buf),\n+        }\n+    }\n+\n+    fn write_all(&mut self, buf: &[u8]) -> Result<(), io::Error> {\n+        match self {\n+            Decompressor::Deflate(zlib_decoder) => zlib_decoder.write_all(buf),\n+            Decompressor::DeflateRaw(deflate_decoder) => deflate_decoder.write_all(buf),\n+            Decompressor::Gzip(gz_decoder) => gz_decoder.write_all(buf),\n+        }\n+    }\n+\n+    fn flush(&mut self) -> io::Result<()> {\n+        match self {\n+            Decompressor::Deflate(zlib_decoder) => zlib_decoder.flush(),\n+            Decompressor::DeflateRaw(deflate_decoder) => deflate_decoder.flush(),\n+            Decompressor::Gzip(gz_decoder) => gz_decoder.flush(),\n+        }\n+    }\n+\n+    fn try_finish(&mut self) -> io::Result<()> {\n+        match self {\n+            Decompressor::Deflate(zlib_decoder) => zlib_decoder.try_finish(),\n+            Decompressor::DeflateRaw(deflate_decoder) => deflate_decoder.try_finish(),\n+            Decompressor::Gzip(gz_decoder) => gz_decoder.try_finish(),\n+        }\n+    }\n+}\n+\n+/// <https://compression.spec.whatwg.org/#decompressionstream>\n+#[dom_struct]\n+pub(crate) struct DecompressionStream {\n+    reflector_: Reflector,\n+\n+    /// <https://streams.spec.whatwg.org/#generictransformstream>\n+    transform: Dom<TransformStream>,\n+\n+    /// <https://compression.spec.whatwg.org/#decompressionstream-format>\n+    format: CompressionFormat,\n+\n+    // <https://compression.spec.whatwg.org/#decompressionstream-context>\n+    #[ignore_malloc_size_of = \"defined in flate2\"]\n+    #[no_trace]\n+    context: RefCell<Decompressor>,\n+}\n+\n+impl DecompressionStream {\n+    fn new_inherited(\n+        transform: &TransformStream,\n+        format: CompressionFormat,\n+    ) -> DecompressionStream {\n+        DecompressionStream {\n+            reflector_: Reflector::new(),\n+            transform: Dom::from_ref(transform),\n+            format,\n+            context: RefCell::new(Decompressor::new(format)),\n+        }\n+    }\n+\n+    fn new_with_proto(\n+        global: &GlobalScope,\n+        proto: Option<SafeHandleObject>,\n+        transform: &TransformStream,\n+        format: CompressionFormat,\n+        can_gc: CanGc,\n+    ) -> DomRoot<DecompressionStream> {\n+        reflect_dom_object_with_proto(\n+            Box::new(DecompressionStream::new_inherited(transform, format)),\n+            global,\n+            proto,\n+            can_gc,\n+        )\n+    }\n+}\n+\n+impl DecompressionStreamMethods<crate::DomTypeHolder> for DecompressionStream {\n+    /// <https://compression.spec.whatwg.org/#dom-decompressionstream-decompressionstream>\n+    fn Constructor(\n+        global: &GlobalScope,\n+        proto: Option<SafeHandleObject>,\n+        can_gc: CanGc,\n+        format: CompressionFormat,\n+    ) -> Fallible<DomRoot<DecompressionStream>> {\n+        // Step 1. If format is unsupported in DecompressionStream, then throw a TypeError.\n+        // NOTE: All of \"deflate\", \"deflate_raw\" and \"gzip\" are supported.\n+\n+        // Step 2. Set this\u2019s format to format.\n+        // Step 5. Set this\u2019s transform to a new TransformStream.\n+        let transform = TransformStream::new_with_proto(global, None, can_gc);\n+        let this = DecompressionStream::new_with_proto(global, proto, &transform, format, can_gc);",
        "comment_created_at": "2025-10-05T14:55:28+00:00",
        "comment_author": "Taym95",
        "comment_body": "I would avoid using `this` and `that` in naming, `Set this\u2019s` means to set current DecompressionStream's format ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2438525859",
    "pr_number": 39940,
    "pr_file": "components/script/dom/document.rs",
    "created_at": "2025-10-17T06:21:23+00:00",
    "commented_code": "#[no_trace]\n     #[ignore_malloc_size_of = \"TODO: unimplemented on Image\"]\n     favicon: RefCell<Option<Image>>,\n+\n+    /// All websockets created that are associated with this document.\n+    websockets: DOMTracker<WebSocket>,\n }\n \n #[allow(non_snake_case)]\n impl Document {\n+    /// <https://html.spec.whatwg.org/multipage/#unloading-document-cleanup-steps>\n+    fn unloading_cleanup_steps(&self) {\n+        // Step 1. Let window be document's relevant global object.\n+        // Step 2. For each WebSocket object webSocket whose relevant global object is window, make disappear webSocket.\n+        if self.close_outstanding_websockets() {\n+            // If this affected any WebSocket objects, then make document unsalvageable given document and \"websocket\".\n+            self.salvageable.set(false);\n+        }\n+\n+        // Step 3. For each WebTransport object transport whose relevant global object is window, run the context cleanup steps given transport.\n+        // TODO\n+\n+        // Step 4. If document's salvageable state is false, then:\n+        if !self.salvageable.get() {\n+            let global_scope = self.window.as_global_scope();\n+\n+            // Step 4.1. For each EventSource object eventSource whose relevant global object is equal to window, forcibly close eventSource.\n+            global_scope.close_event_sources();\n+\n+            // Step 4.2. Clear window's map of active timers.\n+            // TODO\n+\n+            // Ensure the constellation discards all bfcache information for this document.\n+            let msg = ScriptToConstellationMessage::DiscardDocument;\n+            let _ = global_scope.script_to_constellation_chan().send(msg);\n+        }\n+    }\n+\n+    pub(crate) fn track_websocket(&self, websocket: &WebSocket) {\n+        self.websockets.track(websocket);\n+    }\n+\n+    fn close_outstanding_websockets(&self) -> bool {\n+        let mut canceled_any_fetch = false;",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2438525859",
        "repo_full_name": "servo/servo",
        "pr_number": 39940,
        "pr_file": "components/script/dom/document.rs",
        "discussion_id": "2438525859",
        "commented_code": "@@ -594,10 +596,55 @@ pub(crate) struct Document {\n     #[no_trace]\n     #[ignore_malloc_size_of = \"TODO: unimplemented on Image\"]\n     favicon: RefCell<Option<Image>>,\n+\n+    /// All websockets created that are associated with this document.\n+    websockets: DOMTracker<WebSocket>,\n }\n \n #[allow(non_snake_case)]\n impl Document {\n+    /// <https://html.spec.whatwg.org/multipage/#unloading-document-cleanup-steps>\n+    fn unloading_cleanup_steps(&self) {\n+        // Step 1. Let window be document's relevant global object.\n+        // Step 2. For each WebSocket object webSocket whose relevant global object is window, make disappear webSocket.\n+        if self.close_outstanding_websockets() {\n+            // If this affected any WebSocket objects, then make document unsalvageable given document and \"websocket\".\n+            self.salvageable.set(false);\n+        }\n+\n+        // Step 3. For each WebTransport object transport whose relevant global object is window, run the context cleanup steps given transport.\n+        // TODO\n+\n+        // Step 4. If document's salvageable state is false, then:\n+        if !self.salvageable.get() {\n+            let global_scope = self.window.as_global_scope();\n+\n+            // Step 4.1. For each EventSource object eventSource whose relevant global object is equal to window, forcibly close eventSource.\n+            global_scope.close_event_sources();\n+\n+            // Step 4.2. Clear window's map of active timers.\n+            // TODO\n+\n+            // Ensure the constellation discards all bfcache information for this document.\n+            let msg = ScriptToConstellationMessage::DiscardDocument;\n+            let _ = global_scope.script_to_constellation_chan().send(msg);\n+        }\n+    }\n+\n+    pub(crate) fn track_websocket(&self, websocket: &WebSocket) {\n+        self.websockets.track(websocket);\n+    }\n+\n+    fn close_outstanding_websockets(&self) -> bool {\n+        let mut canceled_any_fetch = false;",
        "comment_created_at": "2025-10-17T06:21:23+00:00",
        "comment_author": "TimvdLippe",
        "comment_body": "Nit: call this `closed_any_websocket`. I am not sure why this relates to fetch and when I read `make_disappear` I don't see Fetch mentioned either",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2432179023",
    "pr_number": 39891,
    "pr_file": "components/compositing/webview_renderer.rs",
    "created_at": "2025-10-15T11:17:31+00:00",
    "commented_code": "let cached_hit_test_result = match event.event {",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2432179023",
        "repo_full_name": "servo/servo",
        "pr_number": 39891,
        "pr_file": "components/compositing/webview_renderer.rs",
        "discussion_id": "2432179023",
        "commented_code": "@@ -290,14 +290,19 @@ impl WebViewRenderer {\n                 let cached_hit_test_result = match event.event {",
        "comment_created_at": "2025-10-15T11:17:31+00:00",
        "comment_author": "mrobinson",
        "comment_body": "Please call this `hit_test_result` as it isn't always the cached hit test any longer.\r\n```suggestion\r\n                let hit_test_result = match event.event {\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2418344526",
    "pr_number": 39647,
    "pr_file": "components/shared/embedder/lib.rs",
    "created_at": "2025-10-10T02:15:12+00:00",
    "commented_code": "}\n \n #[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]\n+pub struct JavaScriptErrorInfo {\n+    pub message: String,\n+    pub filename: String,\n+    pub stack: Option<String>,\n+    pub line_number: u64,\n+    pub column: u64,\n+}\n+\n+#[derive(Clone, Debug, Deserialize, EnumMessage, PartialEq, Serialize)]\n+pub enum JavaScriptSerializationError {\n+    Generic,",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2418344526",
        "repo_full_name": "servo/servo",
        "pr_number": 39647,
        "pr_file": "components/shared/embedder/lib.rs",
        "discussion_id": "2418344526",
        "commented_code": "@@ -1057,11 +1057,30 @@ pub enum JSValue {\n }\n \n #[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]\n+pub struct JavaScriptErrorInfo {\n+    pub message: String,\n+    pub filename: String,\n+    pub stack: Option<String>,\n+    pub line_number: u64,\n+    pub column: u64,\n+}\n+\n+#[derive(Clone, Debug, Deserialize, EnumMessage, PartialEq, Serialize)]\n+pub enum JavaScriptSerializationError {\n+    Generic,",
        "comment_created_at": "2025-10-10T02:15:12+00:00",
        "comment_author": "jdm",
        "comment_body": "I think my only real quibble is about this variant. I think I would be happier if there was either documentation about what it meant, or if it was named in a less... generic? way.",
        "pr_file_module": null
      },
      {
        "comment_id": "2418956029",
        "repo_full_name": "servo/servo",
        "pr_number": 39647,
        "pr_file": "components/shared/embedder/lib.rs",
        "discussion_id": "2418344526",
        "commented_code": "@@ -1057,11 +1057,30 @@ pub enum JSValue {\n }\n \n #[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]\n+pub struct JavaScriptErrorInfo {\n+    pub message: String,\n+    pub filename: String,\n+    pub stack: Option<String>,\n+    pub line_number: u64,\n+    pub column: u64,\n+}\n+\n+#[derive(Clone, Debug, Deserialize, EnumMessage, PartialEq, Serialize)]\n+pub enum JavaScriptSerializationError {\n+    Generic,",
        "comment_created_at": "2025-10-10T08:42:29+00:00",
        "comment_author": "mrobinson",
        "comment_body": "I've renamed this to `JavaScriptEvaluationResultSerializationError`, but I'm open to other suggestions as well.",
        "pr_file_module": null
      },
      {
        "comment_id": "2420088517",
        "repo_full_name": "servo/servo",
        "pr_number": 39647,
        "pr_file": "components/shared/embedder/lib.rs",
        "discussion_id": "2418344526",
        "commented_code": "@@ -1057,11 +1057,30 @@ pub enum JSValue {\n }\n \n #[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]\n+pub struct JavaScriptErrorInfo {\n+    pub message: String,\n+    pub filename: String,\n+    pub stack: Option<String>,\n+    pub line_number: u64,\n+    pub column: u64,\n+}\n+\n+#[derive(Clone, Debug, Deserialize, EnumMessage, PartialEq, Serialize)]\n+pub enum JavaScriptSerializationError {\n+    Generic,",
        "comment_created_at": "2025-10-10T13:08:19+00:00",
        "comment_author": "jdm",
        "comment_body": "I was actually referring to the variant named Generic :)",
        "pr_file_module": null
      },
      {
        "comment_id": "2420181818",
        "repo_full_name": "servo/servo",
        "pr_number": 39647,
        "pr_file": "components/shared/embedder/lib.rs",
        "discussion_id": "2418344526",
        "commented_code": "@@ -1057,11 +1057,30 @@ pub enum JSValue {\n }\n \n #[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]\n+pub struct JavaScriptErrorInfo {\n+    pub message: String,\n+    pub filename: String,\n+    pub stack: Option<String>,\n+    pub line_number: u64,\n+    pub column: u64,\n+}\n+\n+#[derive(Clone, Debug, Deserialize, EnumMessage, PartialEq, Serialize)]\n+pub enum JavaScriptSerializationError {\n+    Generic,",
        "comment_created_at": "2025-10-10T13:25:22+00:00",
        "comment_author": "mrobinson",
        "comment_body": "Apologies! :facepalm: I'll fix this in a followup.",
        "pr_file_module": null
      },
      {
        "comment_id": "2420521542",
        "repo_full_name": "servo/servo",
        "pr_number": 39647,
        "pr_file": "components/shared/embedder/lib.rs",
        "discussion_id": "2418344526",
        "commented_code": "@@ -1057,11 +1057,30 @@ pub enum JSValue {\n }\n \n #[derive(Clone, Debug, Deserialize, PartialEq, Serialize)]\n+pub struct JavaScriptErrorInfo {\n+    pub message: String,\n+    pub filename: String,\n+    pub stack: Option<String>,\n+    pub line_number: u64,\n+    pub column: u64,\n+}\n+\n+#[derive(Clone, Debug, Deserialize, EnumMessage, PartialEq, Serialize)]\n+pub enum JavaScriptSerializationError {\n+    Generic,",
        "comment_created_at": "2025-10-10T14:26:26+00:00",
        "comment_author": "mrobinson",
        "comment_body": "Addressed in #39770.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2400851036",
    "pr_number": 39627,
    "pr_file": "components/script/dom/document.rs",
    "created_at": "2025-10-03T05:41:16+00:00",
    "commented_code": "self.has_pending_animated_image_update.set(false);\n         }\n \n+        self.current_layout_epoch",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2400851036",
        "repo_full_name": "servo/servo",
        "pr_number": 39627,
        "pr_file": "components/script/dom/document.rs",
        "discussion_id": "2400851036",
        "commented_code": "@@ -2739,26 +2748,26 @@ impl Document {\n             self.has_pending_animated_image_update.set(false);\n         }\n \n+        self.current_layout_epoch",
        "comment_created_at": "2025-10-03T05:41:16+00:00",
        "comment_author": "sagudev",
        "comment_body": "nit(non-blocking): I am not sure about the naming here, as we still bump the epoch even if we skip layout (well at least we will be when https://github.com/servo/servo/pull/38991 lands). Maybe we should name it \"rendering epoch\" (because of update the rendering)?",
        "pr_file_module": null
      },
      {
        "comment_id": "2400952487",
        "repo_full_name": "servo/servo",
        "pr_number": 39627,
        "pr_file": "components/script/dom/document.rs",
        "discussion_id": "2400851036",
        "commented_code": "@@ -2739,26 +2748,26 @@ impl Document {\n             self.has_pending_animated_image_update.set(false);\n         }\n \n+        self.current_layout_epoch",
        "comment_created_at": "2025-10-03T06:40:55+00:00",
        "comment_author": "mrobinson",
        "comment_body": "That makes sense. I've done this.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2218078579",
    "pr_number": 38041,
    "pr_file": "components/compositing/largest_contentful_paint.rs",
    "created_at": "2025-07-21T02:19:27+00:00",
    "commented_code": "+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use std::collections::HashMap;\n+\n+use base::cross_process_instant::CrossProcessInstant;\n+use compositing_traits::largest_contentful_paint_candidate::{\n+    ImageCandidate, LCPCandidates, LargestContentfulPaint,\n+};\n+use webrender_api::{Epoch, PipelineId};\n+\n+#[derive(Default)]\n+pub struct LargestContentfulPaintDetector {\n+    lcp_calculators: HashMap<PipelineId, LargestContentfulPaintCalculator>,\n+}\n+\n+impl LargestContentfulPaintDetector {\n+    pub fn new() -> Self {\n+        Self {\n+            lcp_calculators: HashMap::new(),\n+        }\n+    }\n+\n+    fn ensure_lcp_calculator(\n+        &mut self,\n+        pipeline_id: PipelineId,\n+    ) -> &mut LargestContentfulPaintCalculator {\n+        self.lcp_calculators\n+            .entry(pipeline_id)\n+            .or_insert(LargestContentfulPaintCalculator {\n+                image_calculator: Default::default(),\n+                lcp: None,\n+            })\n+    }\n+\n+    pub fn append_lcp_candidates(&mut self, pipeline_id: PipelineId, candidates: LCPCandidates) {\n+        if let Some(image_candiadate) = candidates.image_candidate {\n+            self.ensure_lcp_calculator(pipeline_id)\n+                .image_calculator\n+                .candidates\n+                .push(image_candiadate);\n+        }\n+    }\n+\n+    pub fn calculate_largest_contentful_paint(\n+        &mut self,\n+        paint_time: CrossProcessInstant,\n+        epoch: Epoch,\n+        pipeline_id: PipelineId,\n+    ) -> Option<LargestContentfulPaint> {\n+        let lcp_calculator = self.ensure_lcp_calculator(pipeline_id);\n+        let image_candidate = lcp_calculator\n+            .image_calculator\n+            .calculate_largest_contentful_paint(paint_time, epoch);\n+\n+        let candidate = Self::pick_largest_contentful_paint(image_candidate, lcp_calculator.lcp);\n+        if candidate == lcp_calculator.lcp {\n+            return None;\n+        }\n+\n+        lcp_calculator.lcp = candidate;\n+        lcp_calculator.lcp\n+    }\n+\n+    fn pick_largest_contentful_paint(\n+        candidate1: Option<LargestContentfulPaint>,\n+        candidate2: Option<LargestContentfulPaint>,\n+    ) -> Option<LargestContentfulPaint> {\n+        match (candidate1, candidate2) {\n+            (_, None) => candidate1,\n+            (None, _) => candidate2,\n+            (Some(c1), Some(c2)) => {\n+                if (c1.size > c2.size) || (c1.size == c2.size && c1.paint_time <= c2.paint_time) {\n+                    Some(c1)\n+                } else {\n+                    Some(c2)\n+                }\n+            },\n+        }\n+    }\n+}\n+\n+struct LargestContentfulPaintCalculator {\n+    image_calculator: ImageLargestContentfulPaintCalculator,",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2218078579",
        "repo_full_name": "servo/servo",
        "pr_number": 38041,
        "pr_file": "components/compositing/largest_contentful_paint.rs",
        "discussion_id": "2218078579",
        "commented_code": "@@ -0,0 +1,133 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use std::collections::HashMap;\n+\n+use base::cross_process_instant::CrossProcessInstant;\n+use compositing_traits::largest_contentful_paint_candidate::{\n+    ImageCandidate, LCPCandidates, LargestContentfulPaint,\n+};\n+use webrender_api::{Epoch, PipelineId};\n+\n+#[derive(Default)]\n+pub struct LargestContentfulPaintDetector {\n+    lcp_calculators: HashMap<PipelineId, LargestContentfulPaintCalculator>,\n+}\n+\n+impl LargestContentfulPaintDetector {\n+    pub fn new() -> Self {\n+        Self {\n+            lcp_calculators: HashMap::new(),\n+        }\n+    }\n+\n+    fn ensure_lcp_calculator(\n+        &mut self,\n+        pipeline_id: PipelineId,\n+    ) -> &mut LargestContentfulPaintCalculator {\n+        self.lcp_calculators\n+            .entry(pipeline_id)\n+            .or_insert(LargestContentfulPaintCalculator {\n+                image_calculator: Default::default(),\n+                lcp: None,\n+            })\n+    }\n+\n+    pub fn append_lcp_candidates(&mut self, pipeline_id: PipelineId, candidates: LCPCandidates) {\n+        if let Some(image_candiadate) = candidates.image_candidate {\n+            self.ensure_lcp_calculator(pipeline_id)\n+                .image_calculator\n+                .candidates\n+                .push(image_candiadate);\n+        }\n+    }\n+\n+    pub fn calculate_largest_contentful_paint(\n+        &mut self,\n+        paint_time: CrossProcessInstant,\n+        epoch: Epoch,\n+        pipeline_id: PipelineId,\n+    ) -> Option<LargestContentfulPaint> {\n+        let lcp_calculator = self.ensure_lcp_calculator(pipeline_id);\n+        let image_candidate = lcp_calculator\n+            .image_calculator\n+            .calculate_largest_contentful_paint(paint_time, epoch);\n+\n+        let candidate = Self::pick_largest_contentful_paint(image_candidate, lcp_calculator.lcp);\n+        if candidate == lcp_calculator.lcp {\n+            return None;\n+        }\n+\n+        lcp_calculator.lcp = candidate;\n+        lcp_calculator.lcp\n+    }\n+\n+    fn pick_largest_contentful_paint(\n+        candidate1: Option<LargestContentfulPaint>,\n+        candidate2: Option<LargestContentfulPaint>,\n+    ) -> Option<LargestContentfulPaint> {\n+        match (candidate1, candidate2) {\n+            (_, None) => candidate1,\n+            (None, _) => candidate2,\n+            (Some(c1), Some(c2)) => {\n+                if (c1.size > c2.size) || (c1.size == c2.size && c1.paint_time <= c2.paint_time) {\n+                    Some(c1)\n+                } else {\n+                    Some(c2)\n+                }\n+            },\n+        }\n+    }\n+}\n+\n+struct LargestContentfulPaintCalculator {\n+    image_calculator: ImageLargestContentfulPaintCalculator,",
        "comment_created_at": "2025-07-21T02:19:27+00:00",
        "comment_author": "coding-joedow",
        "comment_body": "change `image_calculator` -> `image_lcp_calculator`",
        "pr_file_module": null
      },
      {
        "comment_id": "2224669514",
        "repo_full_name": "servo/servo",
        "pr_number": 38041,
        "pr_file": "components/compositing/largest_contentful_paint.rs",
        "discussion_id": "2218078579",
        "commented_code": "@@ -0,0 +1,133 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use std::collections::HashMap;\n+\n+use base::cross_process_instant::CrossProcessInstant;\n+use compositing_traits::largest_contentful_paint_candidate::{\n+    ImageCandidate, LCPCandidates, LargestContentfulPaint,\n+};\n+use webrender_api::{Epoch, PipelineId};\n+\n+#[derive(Default)]\n+pub struct LargestContentfulPaintDetector {\n+    lcp_calculators: HashMap<PipelineId, LargestContentfulPaintCalculator>,\n+}\n+\n+impl LargestContentfulPaintDetector {\n+    pub fn new() -> Self {\n+        Self {\n+            lcp_calculators: HashMap::new(),\n+        }\n+    }\n+\n+    fn ensure_lcp_calculator(\n+        &mut self,\n+        pipeline_id: PipelineId,\n+    ) -> &mut LargestContentfulPaintCalculator {\n+        self.lcp_calculators\n+            .entry(pipeline_id)\n+            .or_insert(LargestContentfulPaintCalculator {\n+                image_calculator: Default::default(),\n+                lcp: None,\n+            })\n+    }\n+\n+    pub fn append_lcp_candidates(&mut self, pipeline_id: PipelineId, candidates: LCPCandidates) {\n+        if let Some(image_candiadate) = candidates.image_candidate {\n+            self.ensure_lcp_calculator(pipeline_id)\n+                .image_calculator\n+                .candidates\n+                .push(image_candiadate);\n+        }\n+    }\n+\n+    pub fn calculate_largest_contentful_paint(\n+        &mut self,\n+        paint_time: CrossProcessInstant,\n+        epoch: Epoch,\n+        pipeline_id: PipelineId,\n+    ) -> Option<LargestContentfulPaint> {\n+        let lcp_calculator = self.ensure_lcp_calculator(pipeline_id);\n+        let image_candidate = lcp_calculator\n+            .image_calculator\n+            .calculate_largest_contentful_paint(paint_time, epoch);\n+\n+        let candidate = Self::pick_largest_contentful_paint(image_candidate, lcp_calculator.lcp);\n+        if candidate == lcp_calculator.lcp {\n+            return None;\n+        }\n+\n+        lcp_calculator.lcp = candidate;\n+        lcp_calculator.lcp\n+    }\n+\n+    fn pick_largest_contentful_paint(\n+        candidate1: Option<LargestContentfulPaint>,\n+        candidate2: Option<LargestContentfulPaint>,\n+    ) -> Option<LargestContentfulPaint> {\n+        match (candidate1, candidate2) {\n+            (_, None) => candidate1,\n+            (None, _) => candidate2,\n+            (Some(c1), Some(c2)) => {\n+                if (c1.size > c2.size) || (c1.size == c2.size && c1.paint_time <= c2.paint_time) {\n+                    Some(c1)\n+                } else {\n+                    Some(c2)\n+                }\n+            },\n+        }\n+    }\n+}\n+\n+struct LargestContentfulPaintCalculator {\n+    image_calculator: ImageLargestContentfulPaintCalculator,",
        "comment_created_at": "2025-07-23T07:30:29+00:00",
        "comment_author": "boluochoufeng",
        "comment_body": "changed.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2218086328",
    "pr_number": 38041,
    "pr_file": "components/layout/display_list/largest_contenful_paint_collector.rs",
    "created_at": "2025-07-21T02:34:15+00:00",
    "commented_code": "+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use base::id::ScrollTreeNodeId;\n+use compositing_traits::display_list::{ScrollTree, SpatialTreeNodeInfo};\n+use compositing_traits::largest_contentful_paint_candidate::{ImageCandidate, LCPCandidates};\n+use log::debug;\n+use webrender_api::Epoch;\n+use webrender_api::units::{LayoutRect, LayoutSize};\n+\n+use crate::display_list::clip::{Clip, ClipId, StackingContextTreeClipStore};\n+\n+pub(crate) struct LargestContentfulPaintCollector<'a> {\n+    pub clip_tree: &'a StackingContextTreeClipStore,\n+\n+    pub current_scroll_node_id: ScrollTreeNodeId,\n+\n+    pub current_clip_id: ClipId,\n+\n+    pub largerst_image: Option<ImageCandidate>,\n+\n+    pub lcp_candidates: &'a mut LCPCandidates,\n+}\n+\n+impl LargestContentfulPaintCollector<'_> {\n+    pub fn update_current_node_id(\n+        &mut self,\n+        next_scroll_node_id: ScrollTreeNodeId,\n+        next_clip_id: ClipId,\n+    ) {\n+        self.current_scroll_node_id = next_scroll_node_id;\n+        self.current_clip_id = next_clip_id;\n+    }\n+\n+    pub fn record_image_candidate(\n+        &mut self,\n+        tag: usize,\n+        rect: LayoutRect,\n+        viewport_size: LayoutSize,\n+        scroll_tree: &ScrollTree,\n+        epoch: Epoch,\n+    ) {\n+        let visual_rect = self.compute_visual_rect(rect, scroll_tree, viewport_size);\n+        let size = visual_rect.area() as usize;",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2218086328",
        "repo_full_name": "servo/servo",
        "pr_number": 38041,
        "pr_file": "components/layout/display_list/largest_contenful_paint_collector.rs",
        "discussion_id": "2218086328",
        "commented_code": "@@ -0,0 +1,174 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use base::id::ScrollTreeNodeId;\n+use compositing_traits::display_list::{ScrollTree, SpatialTreeNodeInfo};\n+use compositing_traits::largest_contentful_paint_candidate::{ImageCandidate, LCPCandidates};\n+use log::debug;\n+use webrender_api::Epoch;\n+use webrender_api::units::{LayoutRect, LayoutSize};\n+\n+use crate::display_list::clip::{Clip, ClipId, StackingContextTreeClipStore};\n+\n+pub(crate) struct LargestContentfulPaintCollector<'a> {\n+    pub clip_tree: &'a StackingContextTreeClipStore,\n+\n+    pub current_scroll_node_id: ScrollTreeNodeId,\n+\n+    pub current_clip_id: ClipId,\n+\n+    pub largerst_image: Option<ImageCandidate>,\n+\n+    pub lcp_candidates: &'a mut LCPCandidates,\n+}\n+\n+impl LargestContentfulPaintCollector<'_> {\n+    pub fn update_current_node_id(\n+        &mut self,\n+        next_scroll_node_id: ScrollTreeNodeId,\n+        next_clip_id: ClipId,\n+    ) {\n+        self.current_scroll_node_id = next_scroll_node_id;\n+        self.current_clip_id = next_clip_id;\n+    }\n+\n+    pub fn record_image_candidate(\n+        &mut self,\n+        tag: usize,\n+        rect: LayoutRect,\n+        viewport_size: LayoutSize,\n+        scroll_tree: &ScrollTree,\n+        epoch: Epoch,\n+    ) {\n+        let visual_rect = self.compute_visual_rect(rect, scroll_tree, viewport_size);\n+        let size = visual_rect.area() as usize;",
        "comment_created_at": "2025-07-21T02:34:15+00:00",
        "comment_author": "jschwe",
        "comment_body": "I would recommend renaming `size` to area, as that makes it more clear what we are measuring. \r\nThat includes the name in `ImageCandidate`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2218087740",
    "pr_number": 38041,
    "pr_file": "components/shared/compositing/largest_contentful_paint_candidate.rs",
    "created_at": "2025-07-21T02:37:17+00:00",
    "commented_code": "+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use base::cross_process_instant::CrossProcessInstant;\n+use serde::{Deserialize, Serialize};\n+use webrender_api::Epoch;\n+\n+#[derive(Default, Deserialize, Serialize)]\n+pub struct LCPCandidates {\n+    pub image_candidate: Option<ImageCandidate>,\n+}",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2218087740",
        "repo_full_name": "servo/servo",
        "pr_number": 38041,
        "pr_file": "components/shared/compositing/largest_contentful_paint_candidate.rs",
        "discussion_id": "2218087740",
        "commented_code": "@@ -0,0 +1,85 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use base::cross_process_instant::CrossProcessInstant;\n+use serde::{Deserialize, Serialize};\n+use webrender_api::Epoch;\n+\n+#[derive(Default, Deserialize, Serialize)]\n+pub struct LCPCandidates {\n+    pub image_candidate: Option<ImageCandidate>,\n+}",
        "comment_created_at": "2025-07-21T02:37:17+00:00",
        "comment_author": "coding-joedow",
        "comment_body": "```suggestion\r\npub struct LCPCandidates {\r\n    pub image_candidate: Option<ImageCandidate>,\r\n    pub epoch: Epoch,\r\n}\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2218095730",
        "repo_full_name": "servo/servo",
        "pr_number": 38041,
        "pr_file": "components/shared/compositing/largest_contentful_paint_candidate.rs",
        "discussion_id": "2218087740",
        "commented_code": "@@ -0,0 +1,85 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use base::cross_process_instant::CrossProcessInstant;\n+use serde::{Deserialize, Serialize};\n+use webrender_api::Epoch;\n+\n+#[derive(Default, Deserialize, Serialize)]\n+pub struct LCPCandidates {\n+    pub image_candidate: Option<ImageCandidate>,\n+}",
        "comment_created_at": "2025-07-21T02:50:59+00:00",
        "comment_author": "coding-joedow",
        "comment_body": "Add the `epoch` at here to avoid repeatedly storing it for each candidate.",
        "pr_file_module": null
      },
      {
        "comment_id": "2218110377",
        "repo_full_name": "servo/servo",
        "pr_number": 38041,
        "pr_file": "components/shared/compositing/largest_contentful_paint_candidate.rs",
        "discussion_id": "2218087740",
        "commented_code": "@@ -0,0 +1,85 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use base::cross_process_instant::CrossProcessInstant;\n+use serde::{Deserialize, Serialize};\n+use webrender_api::Epoch;\n+\n+#[derive(Default, Deserialize, Serialize)]\n+pub struct LCPCandidates {\n+    pub image_candidate: Option<ImageCandidate>,\n+}",
        "comment_created_at": "2025-07-21T03:16:23+00:00",
        "comment_author": "coding-joedow",
        "comment_body": "By the way, there should be only one candidate for one epoch,  `LCPCandidates` should be changed to `LCPCandidate`. It maybe better to replace the `struct` with `enum`.",
        "pr_file_module": null
      },
      {
        "comment_id": "2219054797",
        "repo_full_name": "servo/servo",
        "pr_number": 38041,
        "pr_file": "components/shared/compositing/largest_contentful_paint_candidate.rs",
        "discussion_id": "2218087740",
        "commented_code": "@@ -0,0 +1,85 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+use base::cross_process_instant::CrossProcessInstant;\n+use serde::{Deserialize, Serialize};\n+use webrender_api::Epoch;\n+\n+#[derive(Default, Deserialize, Serialize)]\n+pub struct LCPCandidates {\n+    pub image_candidate: Option<ImageCandidate>,\n+}",
        "comment_created_at": "2025-07-21T12:27:03+00:00",
        "comment_author": "boluochoufeng",
        "comment_body": "> By the way, there should be only one candidate for one epoch, `LCPCandidates` should be changed to `LCPCandidate`. It maybe better to replace the `struct` with `enum`.\r\n\r\nYes. But both images and text can be candidates. I am considering that there may be needing to know whether the LCP is an image or text in the future, so I used LCPCandidates. The LCP for text nodes will be submitted in the next PR. However, you're right\u2014an `enum` can be used instead of a `struct.`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2310689308",
    "pr_number": 38717,
    "pr_file": "components/webgpu/canvas_context.rs",
    "created_at": "2025-08-29T17:09:49+00:00",
    "commented_code": "+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use serde::{Deserialize, Serialize};\n+use webgpu_traits::{ContextConfiguration, PRESENTATION_BUFFER_COUNT, WebGPUContextId, WebGPUMsg};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+use wgpu_types::COPY_BYTES_PER_ROW_ALIGNMENT;\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+fn stride(size: Size2D<u32>, format: ImageFormat) -> u32 {\n+    (size.width * format.bytes_per_pixel() as u32).next_multiple_of(COPY_BYTES_PER_ROW_ALIGNMENT)\n+}\n+\n+fn buffer_size(size: Size2D<u32>, format: ImageFormat) -> u64 {\n+    stride(size, format) as u64 * size.height as u64\n+}\n+\n+fn image_desc(config: &ContextConfiguration) -> ImageDescriptor {\n+    ImageDescriptor {\n+        format: config.format,\n+        size: config.size.cast().cast_unit(),\n+        stride: Some(stride(config.size, config.format) as i32),\n+        offset: 0,\n+        flags: if config.is_opaque {\n+            ImageDescriptorFlags::IS_OPAQUE\n+        } else {\n+            ImageDescriptorFlags::empty()\n+        },\n+    }\n+}\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+fn err<T: std::error::Error + 'static>(e: Option<T>) -> Result<(), T> {\n+    if let Some(error) = e {\n+        Err(error)\n+    } else {\n+        Ok(())\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == buffer_size(config.size, config.format)\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer ptr can be shared between threads (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = buffer_size(config.size, config.format);\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            err(error)?;\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!()\n+        };\n+        let device_id = buffer.device_id;\n+        let comm_desc = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) =\n+            self.global\n+                .device_create_command_encoder(device_id, &comm_desc, Some(encoder_id));\n+        err(error)?;\n+        let buffer_cv = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(stride(config.size, config.format)),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_cv = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_cv,\n+            &buffer_cv,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        err(error)?;\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        if let StagingBufferState::Mapped(mapped) = &self.state {\n+            let format = match mapped.image_format {\n+                ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+                ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+                _ => unimplemented!(),\n+            };\n+            let alpha_mode = if mapped.is_opaque {\n+                SnapshotAlphaMode::AsOpaque {\n+                    premultiplied: false,\n+                }\n+            } else {\n+                SnapshotAlphaMode::Transparent {\n+                    premultiplied: true,\n+                }\n+            };\n+            let padded_byte_width = stride(mapped.image_size, mapped.image_format);\n+            let data = mapped.slice();\n+            let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+            let mut result_unpadded =\n+                Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+            for row in 0..mapped.image_size.height {\n+                let start = (row * padded_byte_width).try_into().unwrap();\n+                result_unpadded.extend(\n+                    &data[start..start + mapped.image_size.width as usize * bytes_per_pixel],\n+                );\n+            }\n+            let mut snapshot =\n+                Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+            if mapped.is_opaque {\n+                snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+            }\n+            Some(snapshot)\n+        } else {\n+            None\n+        }\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+/// Presentation id encodes current configuration and current image\n+/// so that async presentation does not update context with older data\n+#[derive(Clone, Copy, Debug, Deserialize, Eq, Hash, Ord, PartialEq, PartialOrd, Serialize)]\n+struct PresentationId(u64);\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!()\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+// Only reading staging buffer\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// Unmap this presentation and return if last user\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext\n+pub struct ContextData {\n+    /// Webrender ImageKey\n+    image_key: ImageKey,\n+    /// Unused staging buffers\n+    staging_buffers: ArrayVec<StagingBuffer, PRESENTATION_BUFFER_COUNT>,\n+    /// Last presentation\n+    ///\n+    /// This is `None` only on init\n+    /// as clearing is done only in script\n+    presentation: Option<PresentationStagingBuffer>,\n+    /// Next epoch to be used\n+    next_epoch: Epoch,\n+}\n+\n+impl ContextData {\n+    fn new(\n+        image_key: ImageKey,\n+        global: &Arc<Global>,\n+        buffer_ids: ArrayVec<id::BufferId, PRESENTATION_BUFFER_COUNT>,\n+    ) -> Self {\n+        Self {\n+            image_key,\n+            staging_buffers: buffer_ids\n+                .iter()\n+                .map(|buffer_id| StagingBuffer::new(global.clone(), *buffer_id))\n+                .collect(),\n+            presentation: None,\n+            next_epoch: Epoch(1),\n+        }\n+    }\n+\n+    /// Returns `None` if no staging buffer is unused or failure when making it available\n+    fn get_available_buffer(&'_ mut self, config: &ContextConfiguration) -> Option<StagingBuffer> {",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2310689308",
        "repo_full_name": "servo/servo",
        "pr_number": 38717,
        "pr_file": "components/webgpu/canvas_context.rs",
        "discussion_id": "2310689308",
        "commented_code": "@@ -0,0 +1,747 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use serde::{Deserialize, Serialize};\n+use webgpu_traits::{ContextConfiguration, PRESENTATION_BUFFER_COUNT, WebGPUContextId, WebGPUMsg};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+use wgpu_types::COPY_BYTES_PER_ROW_ALIGNMENT;\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+fn stride(size: Size2D<u32>, format: ImageFormat) -> u32 {\n+    (size.width * format.bytes_per_pixel() as u32).next_multiple_of(COPY_BYTES_PER_ROW_ALIGNMENT)\n+}\n+\n+fn buffer_size(size: Size2D<u32>, format: ImageFormat) -> u64 {\n+    stride(size, format) as u64 * size.height as u64\n+}\n+\n+fn image_desc(config: &ContextConfiguration) -> ImageDescriptor {\n+    ImageDescriptor {\n+        format: config.format,\n+        size: config.size.cast().cast_unit(),\n+        stride: Some(stride(config.size, config.format) as i32),\n+        offset: 0,\n+        flags: if config.is_opaque {\n+            ImageDescriptorFlags::IS_OPAQUE\n+        } else {\n+            ImageDescriptorFlags::empty()\n+        },\n+    }\n+}\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+fn err<T: std::error::Error + 'static>(e: Option<T>) -> Result<(), T> {\n+    if let Some(error) = e {\n+        Err(error)\n+    } else {\n+        Ok(())\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == buffer_size(config.size, config.format)\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer ptr can be shared between threads (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = buffer_size(config.size, config.format);\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            err(error)?;\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!()\n+        };\n+        let device_id = buffer.device_id;\n+        let comm_desc = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) =\n+            self.global\n+                .device_create_command_encoder(device_id, &comm_desc, Some(encoder_id));\n+        err(error)?;\n+        let buffer_cv = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(stride(config.size, config.format)),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_cv = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_cv,\n+            &buffer_cv,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        err(error)?;\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        if let StagingBufferState::Mapped(mapped) = &self.state {\n+            let format = match mapped.image_format {\n+                ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+                ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+                _ => unimplemented!(),\n+            };\n+            let alpha_mode = if mapped.is_opaque {\n+                SnapshotAlphaMode::AsOpaque {\n+                    premultiplied: false,\n+                }\n+            } else {\n+                SnapshotAlphaMode::Transparent {\n+                    premultiplied: true,\n+                }\n+            };\n+            let padded_byte_width = stride(mapped.image_size, mapped.image_format);\n+            let data = mapped.slice();\n+            let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+            let mut result_unpadded =\n+                Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+            for row in 0..mapped.image_size.height {\n+                let start = (row * padded_byte_width).try_into().unwrap();\n+                result_unpadded.extend(\n+                    &data[start..start + mapped.image_size.width as usize * bytes_per_pixel],\n+                );\n+            }\n+            let mut snapshot =\n+                Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+            if mapped.is_opaque {\n+                snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+            }\n+            Some(snapshot)\n+        } else {\n+            None\n+        }\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+/// Presentation id encodes current configuration and current image\n+/// so that async presentation does not update context with older data\n+#[derive(Clone, Copy, Debug, Deserialize, Eq, Hash, Ord, PartialEq, PartialOrd, Serialize)]\n+struct PresentationId(u64);\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!()\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+// Only reading staging buffer\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// Unmap this presentation and return if last user\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext\n+pub struct ContextData {\n+    /// Webrender ImageKey\n+    image_key: ImageKey,\n+    /// Unused staging buffers\n+    staging_buffers: ArrayVec<StagingBuffer, PRESENTATION_BUFFER_COUNT>,\n+    /// Last presentation\n+    ///\n+    /// This is `None` only on init\n+    /// as clearing is done only in script\n+    presentation: Option<PresentationStagingBuffer>,\n+    /// Next epoch to be used\n+    next_epoch: Epoch,\n+}\n+\n+impl ContextData {\n+    fn new(\n+        image_key: ImageKey,\n+        global: &Arc<Global>,\n+        buffer_ids: ArrayVec<id::BufferId, PRESENTATION_BUFFER_COUNT>,\n+    ) -> Self {\n+        Self {\n+            image_key,\n+            staging_buffers: buffer_ids\n+                .iter()\n+                .map(|buffer_id| StagingBuffer::new(global.clone(), *buffer_id))\n+                .collect(),\n+            presentation: None,\n+            next_epoch: Epoch(1),\n+        }\n+    }\n+\n+    /// Returns `None` if no staging buffer is unused or failure when making it available\n+    fn get_available_buffer(&'_ mut self, config: &ContextConfiguration) -> Option<StagingBuffer> {",
        "comment_created_at": "2025-08-29T17:09:49+00:00",
        "comment_author": "mrobinson",
        "comment_body": "```suggestion\r\n    fn available_buffer(&'_ mut self, config: &ContextConfiguration) -> Option<StagingBuffer> {\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2311786918",
        "repo_full_name": "servo/servo",
        "pr_number": 38717,
        "pr_file": "components/webgpu/canvas_context.rs",
        "discussion_id": "2310689308",
        "commented_code": "@@ -0,0 +1,747 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use serde::{Deserialize, Serialize};\n+use webgpu_traits::{ContextConfiguration, PRESENTATION_BUFFER_COUNT, WebGPUContextId, WebGPUMsg};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+use wgpu_types::COPY_BYTES_PER_ROW_ALIGNMENT;\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+fn stride(size: Size2D<u32>, format: ImageFormat) -> u32 {\n+    (size.width * format.bytes_per_pixel() as u32).next_multiple_of(COPY_BYTES_PER_ROW_ALIGNMENT)\n+}\n+\n+fn buffer_size(size: Size2D<u32>, format: ImageFormat) -> u64 {\n+    stride(size, format) as u64 * size.height as u64\n+}\n+\n+fn image_desc(config: &ContextConfiguration) -> ImageDescriptor {\n+    ImageDescriptor {\n+        format: config.format,\n+        size: config.size.cast().cast_unit(),\n+        stride: Some(stride(config.size, config.format) as i32),\n+        offset: 0,\n+        flags: if config.is_opaque {\n+            ImageDescriptorFlags::IS_OPAQUE\n+        } else {\n+            ImageDescriptorFlags::empty()\n+        },\n+    }\n+}\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+fn err<T: std::error::Error + 'static>(e: Option<T>) -> Result<(), T> {\n+    if let Some(error) = e {\n+        Err(error)\n+    } else {\n+        Ok(())\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == buffer_size(config.size, config.format)\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer ptr can be shared between threads (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = buffer_size(config.size, config.format);\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            err(error)?;\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!()\n+        };\n+        let device_id = buffer.device_id;\n+        let comm_desc = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) =\n+            self.global\n+                .device_create_command_encoder(device_id, &comm_desc, Some(encoder_id));\n+        err(error)?;\n+        let buffer_cv = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(stride(config.size, config.format)),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_cv = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_cv,\n+            &buffer_cv,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        err(error)?;\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        if let StagingBufferState::Mapped(mapped) = &self.state {\n+            let format = match mapped.image_format {\n+                ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+                ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+                _ => unimplemented!(),\n+            };\n+            let alpha_mode = if mapped.is_opaque {\n+                SnapshotAlphaMode::AsOpaque {\n+                    premultiplied: false,\n+                }\n+            } else {\n+                SnapshotAlphaMode::Transparent {\n+                    premultiplied: true,\n+                }\n+            };\n+            let padded_byte_width = stride(mapped.image_size, mapped.image_format);\n+            let data = mapped.slice();\n+            let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+            let mut result_unpadded =\n+                Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+            for row in 0..mapped.image_size.height {\n+                let start = (row * padded_byte_width).try_into().unwrap();\n+                result_unpadded.extend(\n+                    &data[start..start + mapped.image_size.width as usize * bytes_per_pixel],\n+                );\n+            }\n+            let mut snapshot =\n+                Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+            if mapped.is_opaque {\n+                snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+            }\n+            Some(snapshot)\n+        } else {\n+            None\n+        }\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+/// Presentation id encodes current configuration and current image\n+/// so that async presentation does not update context with older data\n+#[derive(Clone, Copy, Debug, Deserialize, Eq, Hash, Ord, PartialEq, PartialOrd, Serialize)]\n+struct PresentationId(u64);\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!()\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+// Only reading staging buffer\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// Unmap this presentation and return if last user\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext\n+pub struct ContextData {\n+    /// Webrender ImageKey\n+    image_key: ImageKey,\n+    /// Unused staging buffers\n+    staging_buffers: ArrayVec<StagingBuffer, PRESENTATION_BUFFER_COUNT>,\n+    /// Last presentation\n+    ///\n+    /// This is `None` only on init\n+    /// as clearing is done only in script\n+    presentation: Option<PresentationStagingBuffer>,\n+    /// Next epoch to be used\n+    next_epoch: Epoch,\n+}\n+\n+impl ContextData {\n+    fn new(\n+        image_key: ImageKey,\n+        global: &Arc<Global>,\n+        buffer_ids: ArrayVec<id::BufferId, PRESENTATION_BUFFER_COUNT>,\n+    ) -> Self {\n+        Self {\n+            image_key,\n+            staging_buffers: buffer_ids\n+                .iter()\n+                .map(|buffer_id| StagingBuffer::new(global.clone(), *buffer_id))\n+                .collect(),\n+            presentation: None,\n+            next_epoch: Epoch(1),\n+        }\n+    }\n+\n+    /// Returns `None` if no staging buffer is unused or failure when making it available\n+    fn get_available_buffer(&'_ mut self, config: &ContextConfiguration) -> Option<StagingBuffer> {",
        "comment_created_at": "2025-08-30T05:05:28+00:00",
        "comment_author": "sagudev",
        "comment_body": "Actually given the amount of work this method does and they type it returns (Option, like https://doc.rust-lang.org/std/vec/struct.Vec.html#method.get) I will change the name to `get_or_make_available_buffer`.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2330597449",
    "pr_number": 38717,
    "pr_file": "components/webgpu/canvas_context.rs",
    "created_at": "2025-09-08T15:26:39+00:00",
    "commented_code": "+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use webgpu_traits::{\n+    ContextConfiguration, PRESENTATION_BUFFER_COUNT, PendingTexture, WebGPUContextId, WebGPUMsg,\n+};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == config.buffer_size()\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer can be shared between safely (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+\n+    pub fn stride(&self) -> u32 {\n+        (self.image_size.width * self.image_format.bytes_per_pixel() as u32)\n+            .next_multiple_of(wgt::COPY_BYTES_PER_ROW_ALIGNMENT)\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+// [`StagingBuffer`] only used for reading (never for writing)\n+// so it is safe to share between threads.\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = config.buffer_size();\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            if let Some(error) = error {\n+                return Err(error);\n+            };\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!(\"Should be made available by `ensure_available`\")\n+        };\n+        let device_id = buffer.device_id;\n+        let command_descriptor = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) = self.global.device_create_command_encoder(\n+            device_id,\n+            &command_descriptor,\n+            Some(encoder_id),\n+        );\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        let buffer_info = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(config.stride()),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_info = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_info,\n+            &buffer_info,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        let StagingBufferState::Mapped(mapped) = &self.state else {\n+            return None;\n+        };\n+        let format = match mapped.image_format {\n+            ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+            ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+            _ => unimplemented!(),\n+        };\n+        let alpha_mode = if mapped.is_opaque {\n+            SnapshotAlphaMode::AsOpaque {\n+                premultiplied: false,\n+            }\n+        } else {\n+            SnapshotAlphaMode::Transparent {\n+                premultiplied: true,\n+            }\n+        };\n+        let padded_byte_width = mapped.stride();\n+        let data = mapped.slice();\n+        let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+        let mut result_unpadded =\n+            Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+        for row in 0..mapped.image_size.height {\n+            let start = (row * padded_byte_width).try_into().ok()?;\n+            result_unpadded\n+                .extend(&data[start..start + mapped.image_size.width as usize * bytes_per_pixel]);\n+        }\n+        let mut snapshot =\n+            Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+        if mapped.is_opaque {\n+            snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+        }\n+        Some(snapshot)\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!(\"Presentation staging buffer should be mapped\")\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// If the internal staging buffer is not shared,\n+    /// unmap it and call [`ContextData::return_staging_buffer`] with it.\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext\n+pub struct ContextData {\n+    /// Associated WebRender image\n+    image_key: ImageKey,\n+    /// Staging buffers that are not actively used.\n+    ///\n+    /// Staging buffer here are either [`StagingBufferState::Unassigned`] or [`StagingBufferState::Available`].\n+    /// They are removed from here when they are in process of mapping or mapped.\n+    inactive_staging_buffers: ArrayVec<StagingBuffer, PRESENTATION_BUFFER_COUNT>,\n+    /// The [`PresentationStagingBuffer`] of the most recent presentation. This will\n+    /// be `None` directly after initialization, as clearing is handled completely in\n+    /// the `ScriptThread`.\n+    presentation: Option<PresentationStagingBuffer>,\n+    /// Next epoch to be used\n+    next_epoch: Epoch,\n+}\n+\n+impl ContextData {\n+    fn new(\n+        image_key: ImageKey,\n+        global: &Arc<Global>,\n+        buffer_ids: ArrayVec<id::BufferId, PRESENTATION_BUFFER_COUNT>,\n+    ) -> Self {\n+        Self {\n+            image_key,\n+            inactive_staging_buffers: buffer_ids\n+                .iter()\n+                .map(|buffer_id| StagingBuffer::new(global.clone(), *buffer_id))\n+                .collect(),\n+            presentation: None,\n+            next_epoch: Epoch(1),\n+        }\n+    }\n+\n+    /// Returns `None` if no staging buffer is unused or failure when making it available\n+    fn get_or_make_available_buffer(\n+        &'_ mut self,\n+        config: &ContextConfiguration,\n+    ) -> Option<StagingBuffer> {\n+        self.inactive_staging_buffers\n+            .iter()\n+            // try to get first preallocated GPUBuffer\n+            .position(|staging_buffer| staging_buffer.is_available_with_config(config))\n+            // fallback to first unallocated\n+            .or_else(|| {\n+                self.inactive_staging_buffers\n+                    .iter()\n+                    .position(|staging_buffer| staging_buffer.needs_assign())\n+            })\n+            // or use first one\n+            .or_else(|| {\n+                if self.inactive_staging_buffers.is_empty() {\n+                    None\n+                } else {\n+                    Some(0)\n+                }\n+            })\n+            .and_then(|pos| {\n+                let mut staging_buffer = self.inactive_staging_buffers.remove(pos);\n+                if staging_buffer.ensure_available(config).is_ok() {\n+                    Some(staging_buffer)\n+                } else {\n+                    // if we fail to make it available, return it\n+                    self.inactive_staging_buffers.push(staging_buffer);\n+                    None\n+                }\n+            })\n+    }\n+\n+    /// Destroy the context that this [`ContextData`] represents,\n+    /// freeing all of its buffers,\n+    /// and deleting the associated WebRender image.\n+    fn destroy(\n+        self,\n+        script_sender: &IpcSender<WebGPUMsg>,\n+        compositor_api: &CrossProcessCompositorApi,\n+    ) {\n+        // free ids on script\n+        for staging_buffer in self.inactive_staging_buffers {\n+            if let Err(e) = script_sender.send(WebGPUMsg::FreeBuffer(staging_buffer.buffer_id)) {\n+                warn!(\n+                    \"Unable to send FreeBuffer({:?}) ({:?})\",\n+                    staging_buffer.buffer_id, e\n+                );\n+            };\n+        }\n+        compositor_api.delete_image(self.image_key);\n+    }\n+\n+    /// Returns new epoch\n+    fn next_epoch(&mut self) -> Epoch {\n+        let epoch = self.next_epoch;\n+        self.next_epoch.next();\n+        epoch\n+    }\n+\n+    /// If the given [`PresentationStagingBuffer`] is for a newer presentation, replace the existing\n+    /// one. Deallocate the older one and call by calling [`Self::return_staging_buffer`] on it.\n+    fn replace_presentation(&mut self, presentation: PresentationStagingBuffer) {\n+        let stale_presentation = if presentation.epoch >=\n+            self.presentation\n+                .as_ref()\n+                .map(|p| p.epoch)\n+                .unwrap_or(Epoch(0))\n+        {\n+            self.presentation.replace(presentation)\n+        } else {\n+            Some(presentation)\n+        };\n+        if let Some(stale_presentation) = stale_presentation {\n+            stale_presentation.maybe_destroy(self);\n+        }\n+    }\n+\n+    fn clear_presentation(&mut self) {\n+        if let Some(stale_presentation) = self.presentation.take() {\n+            stale_presentation.maybe_destroy(self);\n+        }\n+    }\n+\n+    fn return_staging_buffer(&mut self, staging_buffer: StagingBuffer) {\n+        self.inactive_staging_buffers.push(staging_buffer)\n+    }\n+}\n+\n+impl crate::WGPU {\n+    pub(crate) fn create_context(\n+        &self,\n+        context_id: WebGPUContextId,\n+        image_key: ImageKey,\n+        size: DeviceIntSize,\n+        buffer_ids: ArrayVec<id::BufferId, PRESENTATION_BUFFER_COUNT>,\n+    ) {\n+        let context_data = ContextData::new(image_key, &self.global, buffer_ids);\n+        self.compositor_api.add_image(\n+            image_key,\n+            ImageDescriptor {\n+                format: ImageFormat::BGRA8,\n+                size,\n+                stride: None,\n+                offset: 0,\n+                flags: ImageDescriptorFlags::empty(),\n+            },\n+            SerializableImageData::External(image_data(context_id)),\n+        );\n+        assert!(\n+            self.wgpu_image_map\n+                .lock()\n+                .unwrap()\n+                .insert(context_id, context_data)\n+                .is_none(),\n+            \"Context should be created only once!\"\n+        );\n+    }\n+\n+    pub(crate) fn get_image(\n+        &self,\n+        context_id: WebGPUContextId,\n+        pending_texture: Option<PendingTexture>,\n+        sender: IpcSender<IpcSnapshot>,\n+    ) {\n+        let mut webgpu_contexts = self.wgpu_image_map.lock().unwrap();\n+        let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+        if let Some(PendingTexture {\n+            texture_id,\n+            encoder_id,\n+            configuration,\n+        }) = pending_texture\n+        {\n+            let Some(staging_buffer) = context_data.get_or_make_available_buffer(&configuration)\n+            else {\n+                warn!(\"Failure obtaining available staging buffer\");\n+                sender\n+                    .send(Snapshot::cleared(configuration.size).as_ipc())\n+                    .unwrap();\n+                return;\n+            };\n+\n+            let epoch = context_data.next_epoch();\n+            let wgpu_image_map = self.wgpu_image_map.clone();\n+            let sender = sender.clone();\n+            drop(webgpu_contexts);\n+            self.texture_download(\n+                texture_id,\n+                encoder_id,\n+                staging_buffer,\n+                configuration,\n+                move |staging_buffer| {\n+                    let mut webgpu_contexts = wgpu_image_map.lock().unwrap();\n+                    let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+                    sender\n+                        .send(\n+                            staging_buffer\n+                                .snapshot()\n+                                .unwrap_or_else(|| Snapshot::cleared(configuration.size))\n+                                .as_ipc(),\n+                        )\n+                        .unwrap();\n+                    if staging_buffer.is_mapped() {\n+                        context_data.replace_presentation(PresentationStagingBuffer::new(\n+                            epoch,\n+                            staging_buffer,\n+                        ));\n+                    } else {\n+                        // failure\n+                        context_data.return_staging_buffer(staging_buffer);\n+                    }\n+                },\n+            );\n+        } else {\n+            sender\n+                .send(\n+                    context_data\n+                        .presentation\n+                        .as_ref()\n+                        .and_then(|presentation_staging_buffer| {\n+                            presentation_staging_buffer.staging_buffer.snapshot()\n+                        })\n+                        .unwrap_or_else(Snapshot::empty)\n+                        .as_ipc(),\n+                )\n+                .unwrap();\n+        }\n+    }\n+\n+    /// Reads texture to staging buffer maps it to CPU\n+    /// and updates image in WR when done\n+    pub(crate) fn present(\n+        &self,\n+        context_id: WebGPUContextId,\n+        pending_texture: Option<PendingTexture>,\n+        size: Size2D<u32>,\n+        canvas_epoch: Epoch,\n+    ) {\n+        let mut webgpu_contexts = self.wgpu_image_map.lock().unwrap();\n+        let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+        let image_key = context_data.image_key;\n+        let Some(PendingTexture {\n+            texture_id,\n+            encoder_id,\n+            configuration,\n+        }) = pending_texture\n+        else {\n+            context_data.clear_presentation();\n+            self.compositor_api.update_image(\n+                image_key,\n+                ImageDescriptor {\n+                    format: ImageFormat::BGRA8,\n+                    size: size.cast_unit().cast(),\n+                    stride: None,\n+                    offset: 0,\n+                    flags: ImageDescriptorFlags::empty(),\n+                },\n+                SerializableImageData::External(image_data(context_id)),\n+                Some(canvas_epoch),\n+            );\n+            return;\n+        };\n+        let Some(staging_buffer) = context_data.get_or_make_available_buffer(&configuration) else {\n+            warn!(\"Failure obtaining available staging buffer\");\n+            context_data.clear_presentation();\n+            self.compositor_api.update_image(\n+                image_key,\n+                configuration.into(),\n+                SerializableImageData::External(image_data(context_id)),\n+                Some(canvas_epoch),\n+            );\n+            return;\n+        };\n+        let epoch = context_data.next_epoch();\n+        let wgpu_image_map = self.wgpu_image_map.clone();\n+        let compositor_api = self.compositor_api.clone();\n+        drop(webgpu_contexts);\n+        self.texture_download(\n+            texture_id,\n+            encoder_id,\n+            staging_buffer,\n+            configuration,\n+            move |staging_buffer| {\n+                let mut webgpu_contexts = wgpu_image_map.lock().unwrap();\n+                let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+                if staging_buffer.is_mapped() {\n+                    context_data.replace_presentation(PresentationStagingBuffer::new(\n+                        epoch,\n+                        staging_buffer,\n+                    ));\n+                } else {\n+                    context_data.return_staging_buffer(staging_buffer);\n+                    context_data.clear_presentation();\n+                }\n+                // update image in WR\n+                compositor_api.update_image(\n+                    image_key,\n+                    configuration.into(),\n+                    SerializableImageData::External(image_data(context_id)),\n+                    Some(canvas_epoch),\n+                );\n+            },\n+        );\n+    }\n+\n+    /// Copies data from provided texture using encoder_id to provided staging buffer.\n+    ///\n+    /// Callback is guaranteed to be called.\n+    /// Returns [`StagingBuffer`] with [`StagingBufferState::Mapped`] state on success\n+    /// or [`StagingBufferState::Available`] on failure.\n+    fn texture_download(\n+        &self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        mut staging_buffer: StagingBuffer,\n+        config: ContextConfiguration,\n+        callback: impl FnOnce(StagingBuffer) + Send + 'static,",
    "repo_full_name": "servo/servo",
    "discussion_comments": [
      {
        "comment_id": "2330597449",
        "repo_full_name": "servo/servo",
        "pr_number": 38717,
        "pr_file": "components/webgpu/canvas_context.rs",
        "discussion_id": "2330597449",
        "commented_code": "@@ -0,0 +1,771 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use webgpu_traits::{\n+    ContextConfiguration, PRESENTATION_BUFFER_COUNT, PendingTexture, WebGPUContextId, WebGPUMsg,\n+};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == config.buffer_size()\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer can be shared between safely (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+\n+    pub fn stride(&self) -> u32 {\n+        (self.image_size.width * self.image_format.bytes_per_pixel() as u32)\n+            .next_multiple_of(wgt::COPY_BYTES_PER_ROW_ALIGNMENT)\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+// [`StagingBuffer`] only used for reading (never for writing)\n+// so it is safe to share between threads.\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = config.buffer_size();\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            if let Some(error) = error {\n+                return Err(error);\n+            };\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!(\"Should be made available by `ensure_available`\")\n+        };\n+        let device_id = buffer.device_id;\n+        let command_descriptor = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) = self.global.device_create_command_encoder(\n+            device_id,\n+            &command_descriptor,\n+            Some(encoder_id),\n+        );\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        let buffer_info = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(config.stride()),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_info = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_info,\n+            &buffer_info,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        let StagingBufferState::Mapped(mapped) = &self.state else {\n+            return None;\n+        };\n+        let format = match mapped.image_format {\n+            ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+            ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+            _ => unimplemented!(),\n+        };\n+        let alpha_mode = if mapped.is_opaque {\n+            SnapshotAlphaMode::AsOpaque {\n+                premultiplied: false,\n+            }\n+        } else {\n+            SnapshotAlphaMode::Transparent {\n+                premultiplied: true,\n+            }\n+        };\n+        let padded_byte_width = mapped.stride();\n+        let data = mapped.slice();\n+        let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+        let mut result_unpadded =\n+            Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+        for row in 0..mapped.image_size.height {\n+            let start = (row * padded_byte_width).try_into().ok()?;\n+            result_unpadded\n+                .extend(&data[start..start + mapped.image_size.width as usize * bytes_per_pixel]);\n+        }\n+        let mut snapshot =\n+            Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+        if mapped.is_opaque {\n+            snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+        }\n+        Some(snapshot)\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!(\"Presentation staging buffer should be mapped\")\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// If the internal staging buffer is not shared,\n+    /// unmap it and call [`ContextData::return_staging_buffer`] with it.\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext\n+pub struct ContextData {\n+    /// Associated WebRender image\n+    image_key: ImageKey,\n+    /// Staging buffers that are not actively used.\n+    ///\n+    /// Staging buffer here are either [`StagingBufferState::Unassigned`] or [`StagingBufferState::Available`].\n+    /// They are removed from here when they are in process of mapping or mapped.\n+    inactive_staging_buffers: ArrayVec<StagingBuffer, PRESENTATION_BUFFER_COUNT>,\n+    /// The [`PresentationStagingBuffer`] of the most recent presentation. This will\n+    /// be `None` directly after initialization, as clearing is handled completely in\n+    /// the `ScriptThread`.\n+    presentation: Option<PresentationStagingBuffer>,\n+    /// Next epoch to be used\n+    next_epoch: Epoch,\n+}\n+\n+impl ContextData {\n+    fn new(\n+        image_key: ImageKey,\n+        global: &Arc<Global>,\n+        buffer_ids: ArrayVec<id::BufferId, PRESENTATION_BUFFER_COUNT>,\n+    ) -> Self {\n+        Self {\n+            image_key,\n+            inactive_staging_buffers: buffer_ids\n+                .iter()\n+                .map(|buffer_id| StagingBuffer::new(global.clone(), *buffer_id))\n+                .collect(),\n+            presentation: None,\n+            next_epoch: Epoch(1),\n+        }\n+    }\n+\n+    /// Returns `None` if no staging buffer is unused or failure when making it available\n+    fn get_or_make_available_buffer(\n+        &'_ mut self,\n+        config: &ContextConfiguration,\n+    ) -> Option<StagingBuffer> {\n+        self.inactive_staging_buffers\n+            .iter()\n+            // try to get first preallocated GPUBuffer\n+            .position(|staging_buffer| staging_buffer.is_available_with_config(config))\n+            // fallback to first unallocated\n+            .or_else(|| {\n+                self.inactive_staging_buffers\n+                    .iter()\n+                    .position(|staging_buffer| staging_buffer.needs_assign())\n+            })\n+            // or use first one\n+            .or_else(|| {\n+                if self.inactive_staging_buffers.is_empty() {\n+                    None\n+                } else {\n+                    Some(0)\n+                }\n+            })\n+            .and_then(|pos| {\n+                let mut staging_buffer = self.inactive_staging_buffers.remove(pos);\n+                if staging_buffer.ensure_available(config).is_ok() {\n+                    Some(staging_buffer)\n+                } else {\n+                    // if we fail to make it available, return it\n+                    self.inactive_staging_buffers.push(staging_buffer);\n+                    None\n+                }\n+            })\n+    }\n+\n+    /// Destroy the context that this [`ContextData`] represents,\n+    /// freeing all of its buffers,\n+    /// and deleting the associated WebRender image.\n+    fn destroy(\n+        self,\n+        script_sender: &IpcSender<WebGPUMsg>,\n+        compositor_api: &CrossProcessCompositorApi,\n+    ) {\n+        // free ids on script\n+        for staging_buffer in self.inactive_staging_buffers {\n+            if let Err(e) = script_sender.send(WebGPUMsg::FreeBuffer(staging_buffer.buffer_id)) {\n+                warn!(\n+                    \"Unable to send FreeBuffer({:?}) ({:?})\",\n+                    staging_buffer.buffer_id, e\n+                );\n+            };\n+        }\n+        compositor_api.delete_image(self.image_key);\n+    }\n+\n+    /// Returns new epoch\n+    fn next_epoch(&mut self) -> Epoch {\n+        let epoch = self.next_epoch;\n+        self.next_epoch.next();\n+        epoch\n+    }\n+\n+    /// If the given [`PresentationStagingBuffer`] is for a newer presentation, replace the existing\n+    /// one. Deallocate the older one and call by calling [`Self::return_staging_buffer`] on it.\n+    fn replace_presentation(&mut self, presentation: PresentationStagingBuffer) {\n+        let stale_presentation = if presentation.epoch >=\n+            self.presentation\n+                .as_ref()\n+                .map(|p| p.epoch)\n+                .unwrap_or(Epoch(0))\n+        {\n+            self.presentation.replace(presentation)\n+        } else {\n+            Some(presentation)\n+        };\n+        if let Some(stale_presentation) = stale_presentation {\n+            stale_presentation.maybe_destroy(self);\n+        }\n+    }\n+\n+    fn clear_presentation(&mut self) {\n+        if let Some(stale_presentation) = self.presentation.take() {\n+            stale_presentation.maybe_destroy(self);\n+        }\n+    }\n+\n+    fn return_staging_buffer(&mut self, staging_buffer: StagingBuffer) {\n+        self.inactive_staging_buffers.push(staging_buffer)\n+    }\n+}\n+\n+impl crate::WGPU {\n+    pub(crate) fn create_context(\n+        &self,\n+        context_id: WebGPUContextId,\n+        image_key: ImageKey,\n+        size: DeviceIntSize,\n+        buffer_ids: ArrayVec<id::BufferId, PRESENTATION_BUFFER_COUNT>,\n+    ) {\n+        let context_data = ContextData::new(image_key, &self.global, buffer_ids);\n+        self.compositor_api.add_image(\n+            image_key,\n+            ImageDescriptor {\n+                format: ImageFormat::BGRA8,\n+                size,\n+                stride: None,\n+                offset: 0,\n+                flags: ImageDescriptorFlags::empty(),\n+            },\n+            SerializableImageData::External(image_data(context_id)),\n+        );\n+        assert!(\n+            self.wgpu_image_map\n+                .lock()\n+                .unwrap()\n+                .insert(context_id, context_data)\n+                .is_none(),\n+            \"Context should be created only once!\"\n+        );\n+    }\n+\n+    pub(crate) fn get_image(\n+        &self,\n+        context_id: WebGPUContextId,\n+        pending_texture: Option<PendingTexture>,\n+        sender: IpcSender<IpcSnapshot>,\n+    ) {\n+        let mut webgpu_contexts = self.wgpu_image_map.lock().unwrap();\n+        let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+        if let Some(PendingTexture {\n+            texture_id,\n+            encoder_id,\n+            configuration,\n+        }) = pending_texture\n+        {\n+            let Some(staging_buffer) = context_data.get_or_make_available_buffer(&configuration)\n+            else {\n+                warn!(\"Failure obtaining available staging buffer\");\n+                sender\n+                    .send(Snapshot::cleared(configuration.size).as_ipc())\n+                    .unwrap();\n+                return;\n+            };\n+\n+            let epoch = context_data.next_epoch();\n+            let wgpu_image_map = self.wgpu_image_map.clone();\n+            let sender = sender.clone();\n+            drop(webgpu_contexts);\n+            self.texture_download(\n+                texture_id,\n+                encoder_id,\n+                staging_buffer,\n+                configuration,\n+                move |staging_buffer| {\n+                    let mut webgpu_contexts = wgpu_image_map.lock().unwrap();\n+                    let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+                    sender\n+                        .send(\n+                            staging_buffer\n+                                .snapshot()\n+                                .unwrap_or_else(|| Snapshot::cleared(configuration.size))\n+                                .as_ipc(),\n+                        )\n+                        .unwrap();\n+                    if staging_buffer.is_mapped() {\n+                        context_data.replace_presentation(PresentationStagingBuffer::new(\n+                            epoch,\n+                            staging_buffer,\n+                        ));\n+                    } else {\n+                        // failure\n+                        context_data.return_staging_buffer(staging_buffer);\n+                    }\n+                },\n+            );\n+        } else {\n+            sender\n+                .send(\n+                    context_data\n+                        .presentation\n+                        .as_ref()\n+                        .and_then(|presentation_staging_buffer| {\n+                            presentation_staging_buffer.staging_buffer.snapshot()\n+                        })\n+                        .unwrap_or_else(Snapshot::empty)\n+                        .as_ipc(),\n+                )\n+                .unwrap();\n+        }\n+    }\n+\n+    /// Reads texture to staging buffer maps it to CPU\n+    /// and updates image in WR when done\n+    pub(crate) fn present(\n+        &self,\n+        context_id: WebGPUContextId,\n+        pending_texture: Option<PendingTexture>,\n+        size: Size2D<u32>,\n+        canvas_epoch: Epoch,\n+    ) {\n+        let mut webgpu_contexts = self.wgpu_image_map.lock().unwrap();\n+        let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+        let image_key = context_data.image_key;\n+        let Some(PendingTexture {\n+            texture_id,\n+            encoder_id,\n+            configuration,\n+        }) = pending_texture\n+        else {\n+            context_data.clear_presentation();\n+            self.compositor_api.update_image(\n+                image_key,\n+                ImageDescriptor {\n+                    format: ImageFormat::BGRA8,\n+                    size: size.cast_unit().cast(),\n+                    stride: None,\n+                    offset: 0,\n+                    flags: ImageDescriptorFlags::empty(),\n+                },\n+                SerializableImageData::External(image_data(context_id)),\n+                Some(canvas_epoch),\n+            );\n+            return;\n+        };\n+        let Some(staging_buffer) = context_data.get_or_make_available_buffer(&configuration) else {\n+            warn!(\"Failure obtaining available staging buffer\");\n+            context_data.clear_presentation();\n+            self.compositor_api.update_image(\n+                image_key,\n+                configuration.into(),\n+                SerializableImageData::External(image_data(context_id)),\n+                Some(canvas_epoch),\n+            );\n+            return;\n+        };\n+        let epoch = context_data.next_epoch();\n+        let wgpu_image_map = self.wgpu_image_map.clone();\n+        let compositor_api = self.compositor_api.clone();\n+        drop(webgpu_contexts);\n+        self.texture_download(\n+            texture_id,\n+            encoder_id,\n+            staging_buffer,\n+            configuration,\n+            move |staging_buffer| {\n+                let mut webgpu_contexts = wgpu_image_map.lock().unwrap();\n+                let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+                if staging_buffer.is_mapped() {\n+                    context_data.replace_presentation(PresentationStagingBuffer::new(\n+                        epoch,\n+                        staging_buffer,\n+                    ));\n+                } else {\n+                    context_data.return_staging_buffer(staging_buffer);\n+                    context_data.clear_presentation();\n+                }\n+                // update image in WR\n+                compositor_api.update_image(\n+                    image_key,\n+                    configuration.into(),\n+                    SerializableImageData::External(image_data(context_id)),\n+                    Some(canvas_epoch),\n+                );\n+            },\n+        );\n+    }\n+\n+    /// Copies data from provided texture using encoder_id to provided staging buffer.\n+    ///\n+    /// Callback is guaranteed to be called.\n+    /// Returns [`StagingBuffer`] with [`StagingBufferState::Mapped`] state on success\n+    /// or [`StagingBufferState::Available`] on failure.\n+    fn texture_download(\n+        &self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        mut staging_buffer: StagingBuffer,\n+        config: ContextConfiguration,\n+        callback: impl FnOnce(StagingBuffer) + Send + 'static,",
        "comment_created_at": "2025-09-08T15:26:39+00:00",
        "comment_author": "mrobinson",
        "comment_body": "```suggestion\r\n        completion_callback: impl FnOnce(StagingBuffer) + Send + 'static,\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2330788420",
        "repo_full_name": "servo/servo",
        "pr_number": 38717,
        "pr_file": "components/webgpu/canvas_context.rs",
        "discussion_id": "2330597449",
        "commented_code": "@@ -0,0 +1,771 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use webgpu_traits::{\n+    ContextConfiguration, PRESENTATION_BUFFER_COUNT, PendingTexture, WebGPUContextId, WebGPUMsg,\n+};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == config.buffer_size()\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer can be shared between safely (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+\n+    pub fn stride(&self) -> u32 {\n+        (self.image_size.width * self.image_format.bytes_per_pixel() as u32)\n+            .next_multiple_of(wgt::COPY_BYTES_PER_ROW_ALIGNMENT)\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+// [`StagingBuffer`] only used for reading (never for writing)\n+// so it is safe to share between threads.\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = config.buffer_size();\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            if let Some(error) = error {\n+                return Err(error);\n+            };\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!(\"Should be made available by `ensure_available`\")\n+        };\n+        let device_id = buffer.device_id;\n+        let command_descriptor = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) = self.global.device_create_command_encoder(\n+            device_id,\n+            &command_descriptor,\n+            Some(encoder_id),\n+        );\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        let buffer_info = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(config.stride()),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_info = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_info,\n+            &buffer_info,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        let StagingBufferState::Mapped(mapped) = &self.state else {\n+            return None;\n+        };\n+        let format = match mapped.image_format {\n+            ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+            ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+            _ => unimplemented!(),\n+        };\n+        let alpha_mode = if mapped.is_opaque {\n+            SnapshotAlphaMode::AsOpaque {\n+                premultiplied: false,\n+            }\n+        } else {\n+            SnapshotAlphaMode::Transparent {\n+                premultiplied: true,\n+            }\n+        };\n+        let padded_byte_width = mapped.stride();\n+        let data = mapped.slice();\n+        let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+        let mut result_unpadded =\n+            Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+        for row in 0..mapped.image_size.height {\n+            let start = (row * padded_byte_width).try_into().ok()?;\n+            result_unpadded\n+                .extend(&data[start..start + mapped.image_size.width as usize * bytes_per_pixel]);\n+        }\n+        let mut snapshot =\n+            Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+        if mapped.is_opaque {\n+            snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+        }\n+        Some(snapshot)\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!(\"Presentation staging buffer should be mapped\")\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// If the internal staging buffer is not shared,\n+    /// unmap it and call [`ContextData::return_staging_buffer`] with it.\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext\n+pub struct ContextData {\n+    /// Associated WebRender image\n+    image_key: ImageKey,\n+    /// Staging buffers that are not actively used.\n+    ///\n+    /// Staging buffer here are either [`StagingBufferState::Unassigned`] or [`StagingBufferState::Available`].\n+    /// They are removed from here when they are in process of mapping or mapped.\n+    inactive_staging_buffers: ArrayVec<StagingBuffer, PRESENTATION_BUFFER_COUNT>,\n+    /// The [`PresentationStagingBuffer`] of the most recent presentation. This will\n+    /// be `None` directly after initialization, as clearing is handled completely in\n+    /// the `ScriptThread`.\n+    presentation: Option<PresentationStagingBuffer>,\n+    /// Next epoch to be used\n+    next_epoch: Epoch,\n+}\n+\n+impl ContextData {\n+    fn new(\n+        image_key: ImageKey,\n+        global: &Arc<Global>,\n+        buffer_ids: ArrayVec<id::BufferId, PRESENTATION_BUFFER_COUNT>,\n+    ) -> Self {\n+        Self {\n+            image_key,\n+            inactive_staging_buffers: buffer_ids\n+                .iter()\n+                .map(|buffer_id| StagingBuffer::new(global.clone(), *buffer_id))\n+                .collect(),\n+            presentation: None,\n+            next_epoch: Epoch(1),\n+        }\n+    }\n+\n+    /// Returns `None` if no staging buffer is unused or failure when making it available\n+    fn get_or_make_available_buffer(\n+        &'_ mut self,\n+        config: &ContextConfiguration,\n+    ) -> Option<StagingBuffer> {\n+        self.inactive_staging_buffers\n+            .iter()\n+            // try to get first preallocated GPUBuffer\n+            .position(|staging_buffer| staging_buffer.is_available_with_config(config))\n+            // fallback to first unallocated\n+            .or_else(|| {\n+                self.inactive_staging_buffers\n+                    .iter()\n+                    .position(|staging_buffer| staging_buffer.needs_assign())\n+            })\n+            // or use first one\n+            .or_else(|| {\n+                if self.inactive_staging_buffers.is_empty() {\n+                    None\n+                } else {\n+                    Some(0)\n+                }\n+            })\n+            .and_then(|pos| {\n+                let mut staging_buffer = self.inactive_staging_buffers.remove(pos);\n+                if staging_buffer.ensure_available(config).is_ok() {\n+                    Some(staging_buffer)\n+                } else {\n+                    // if we fail to make it available, return it\n+                    self.inactive_staging_buffers.push(staging_buffer);\n+                    None\n+                }\n+            })\n+    }\n+\n+    /// Destroy the context that this [`ContextData`] represents,\n+    /// freeing all of its buffers,\n+    /// and deleting the associated WebRender image.\n+    fn destroy(\n+        self,\n+        script_sender: &IpcSender<WebGPUMsg>,\n+        compositor_api: &CrossProcessCompositorApi,\n+    ) {\n+        // free ids on script\n+        for staging_buffer in self.inactive_staging_buffers {\n+            if let Err(e) = script_sender.send(WebGPUMsg::FreeBuffer(staging_buffer.buffer_id)) {\n+                warn!(\n+                    \"Unable to send FreeBuffer({:?}) ({:?})\",\n+                    staging_buffer.buffer_id, e\n+                );\n+            };\n+        }\n+        compositor_api.delete_image(self.image_key);\n+    }\n+\n+    /// Returns new epoch\n+    fn next_epoch(&mut self) -> Epoch {\n+        let epoch = self.next_epoch;\n+        self.next_epoch.next();\n+        epoch\n+    }\n+\n+    /// If the given [`PresentationStagingBuffer`] is for a newer presentation, replace the existing\n+    /// one. Deallocate the older one and call by calling [`Self::return_staging_buffer`] on it.\n+    fn replace_presentation(&mut self, presentation: PresentationStagingBuffer) {\n+        let stale_presentation = if presentation.epoch >=\n+            self.presentation\n+                .as_ref()\n+                .map(|p| p.epoch)\n+                .unwrap_or(Epoch(0))\n+        {\n+            self.presentation.replace(presentation)\n+        } else {\n+            Some(presentation)\n+        };\n+        if let Some(stale_presentation) = stale_presentation {\n+            stale_presentation.maybe_destroy(self);\n+        }\n+    }\n+\n+    fn clear_presentation(&mut self) {\n+        if let Some(stale_presentation) = self.presentation.take() {\n+            stale_presentation.maybe_destroy(self);\n+        }\n+    }\n+\n+    fn return_staging_buffer(&mut self, staging_buffer: StagingBuffer) {\n+        self.inactive_staging_buffers.push(staging_buffer)\n+    }\n+}\n+\n+impl crate::WGPU {\n+    pub(crate) fn create_context(\n+        &self,\n+        context_id: WebGPUContextId,\n+        image_key: ImageKey,\n+        size: DeviceIntSize,\n+        buffer_ids: ArrayVec<id::BufferId, PRESENTATION_BUFFER_COUNT>,\n+    ) {\n+        let context_data = ContextData::new(image_key, &self.global, buffer_ids);\n+        self.compositor_api.add_image(\n+            image_key,\n+            ImageDescriptor {\n+                format: ImageFormat::BGRA8,\n+                size,\n+                stride: None,\n+                offset: 0,\n+                flags: ImageDescriptorFlags::empty(),\n+            },\n+            SerializableImageData::External(image_data(context_id)),\n+        );\n+        assert!(\n+            self.wgpu_image_map\n+                .lock()\n+                .unwrap()\n+                .insert(context_id, context_data)\n+                .is_none(),\n+            \"Context should be created only once!\"\n+        );\n+    }\n+\n+    pub(crate) fn get_image(\n+        &self,\n+        context_id: WebGPUContextId,\n+        pending_texture: Option<PendingTexture>,\n+        sender: IpcSender<IpcSnapshot>,\n+    ) {\n+        let mut webgpu_contexts = self.wgpu_image_map.lock().unwrap();\n+        let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+        if let Some(PendingTexture {\n+            texture_id,\n+            encoder_id,\n+            configuration,\n+        }) = pending_texture\n+        {\n+            let Some(staging_buffer) = context_data.get_or_make_available_buffer(&configuration)\n+            else {\n+                warn!(\"Failure obtaining available staging buffer\");\n+                sender\n+                    .send(Snapshot::cleared(configuration.size).as_ipc())\n+                    .unwrap();\n+                return;\n+            };\n+\n+            let epoch = context_data.next_epoch();\n+            let wgpu_image_map = self.wgpu_image_map.clone();\n+            let sender = sender.clone();\n+            drop(webgpu_contexts);\n+            self.texture_download(\n+                texture_id,\n+                encoder_id,\n+                staging_buffer,\n+                configuration,\n+                move |staging_buffer| {\n+                    let mut webgpu_contexts = wgpu_image_map.lock().unwrap();\n+                    let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+                    sender\n+                        .send(\n+                            staging_buffer\n+                                .snapshot()\n+                                .unwrap_or_else(|| Snapshot::cleared(configuration.size))\n+                                .as_ipc(),\n+                        )\n+                        .unwrap();\n+                    if staging_buffer.is_mapped() {\n+                        context_data.replace_presentation(PresentationStagingBuffer::new(\n+                            epoch,\n+                            staging_buffer,\n+                        ));\n+                    } else {\n+                        // failure\n+                        context_data.return_staging_buffer(staging_buffer);\n+                    }\n+                },\n+            );\n+        } else {\n+            sender\n+                .send(\n+                    context_data\n+                        .presentation\n+                        .as_ref()\n+                        .and_then(|presentation_staging_buffer| {\n+                            presentation_staging_buffer.staging_buffer.snapshot()\n+                        })\n+                        .unwrap_or_else(Snapshot::empty)\n+                        .as_ipc(),\n+                )\n+                .unwrap();\n+        }\n+    }\n+\n+    /// Reads texture to staging buffer maps it to CPU\n+    /// and updates image in WR when done\n+    pub(crate) fn present(\n+        &self,\n+        context_id: WebGPUContextId,\n+        pending_texture: Option<PendingTexture>,\n+        size: Size2D<u32>,\n+        canvas_epoch: Epoch,\n+    ) {\n+        let mut webgpu_contexts = self.wgpu_image_map.lock().unwrap();\n+        let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+        let image_key = context_data.image_key;\n+        let Some(PendingTexture {\n+            texture_id,\n+            encoder_id,\n+            configuration,\n+        }) = pending_texture\n+        else {\n+            context_data.clear_presentation();\n+            self.compositor_api.update_image(\n+                image_key,\n+                ImageDescriptor {\n+                    format: ImageFormat::BGRA8,\n+                    size: size.cast_unit().cast(),\n+                    stride: None,\n+                    offset: 0,\n+                    flags: ImageDescriptorFlags::empty(),\n+                },\n+                SerializableImageData::External(image_data(context_id)),\n+                Some(canvas_epoch),\n+            );\n+            return;\n+        };\n+        let Some(staging_buffer) = context_data.get_or_make_available_buffer(&configuration) else {\n+            warn!(\"Failure obtaining available staging buffer\");\n+            context_data.clear_presentation();\n+            self.compositor_api.update_image(\n+                image_key,\n+                configuration.into(),\n+                SerializableImageData::External(image_data(context_id)),\n+                Some(canvas_epoch),\n+            );\n+            return;\n+        };\n+        let epoch = context_data.next_epoch();\n+        let wgpu_image_map = self.wgpu_image_map.clone();\n+        let compositor_api = self.compositor_api.clone();\n+        drop(webgpu_contexts);\n+        self.texture_download(\n+            texture_id,\n+            encoder_id,\n+            staging_buffer,\n+            configuration,\n+            move |staging_buffer| {\n+                let mut webgpu_contexts = wgpu_image_map.lock().unwrap();\n+                let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+                if staging_buffer.is_mapped() {\n+                    context_data.replace_presentation(PresentationStagingBuffer::new(\n+                        epoch,\n+                        staging_buffer,\n+                    ));\n+                } else {\n+                    context_data.return_staging_buffer(staging_buffer);\n+                    context_data.clear_presentation();\n+                }\n+                // update image in WR\n+                compositor_api.update_image(\n+                    image_key,\n+                    configuration.into(),\n+                    SerializableImageData::External(image_data(context_id)),\n+                    Some(canvas_epoch),\n+                );\n+            },\n+        );\n+    }\n+\n+    /// Copies data from provided texture using encoder_id to provided staging buffer.\n+    ///\n+    /// Callback is guaranteed to be called.\n+    /// Returns [`StagingBuffer`] with [`StagingBufferState::Mapped`] state on success\n+    /// or [`StagingBufferState::Available`] on failure.\n+    fn texture_download(\n+        &self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        mut staging_buffer: StagingBuffer,\n+        config: ContextConfiguration,\n+        callback: impl FnOnce(StagingBuffer) + Send + 'static,",
        "comment_created_at": "2025-09-08T16:40:16+00:00",
        "comment_author": "sagudev",
        "comment_body": "Not sure about the naming here, because we also call the callback on failure before running actual download (so nothing actually completed). We just need this to return staging buffer (on error or succes).",
        "pr_file_module": null
      },
      {
        "comment_id": "2330802338",
        "repo_full_name": "servo/servo",
        "pr_number": 38717,
        "pr_file": "components/webgpu/canvas_context.rs",
        "discussion_id": "2330597449",
        "commented_code": "@@ -0,0 +1,771 @@\n+/* This Source Code Form is subject to the terms of the Mozilla Public\n+ * License, v. 2.0. If a copy of the MPL was not distributed with this\n+ * file, You can obtain one at https://mozilla.org/MPL/2.0/. */\n+\n+//! Main process implementation of [GPUCanvasContext](https://www.w3.org/TR/webgpu/#canvas-context)\n+\n+use std::collections::HashMap;\n+use std::ptr::NonNull;\n+use std::sync::{Arc, Mutex};\n+\n+use arrayvec::ArrayVec;\n+use base::Epoch;\n+use compositing_traits::{\n+    CrossProcessCompositorApi, ExternalImageSource, SerializableImageData,\n+    WebrenderExternalImageApi,\n+};\n+use euclid::default::Size2D;\n+use ipc_channel::ipc::IpcSender;\n+use log::warn;\n+use pixels::{IpcSnapshot, Snapshot, SnapshotAlphaMode, SnapshotPixelFormat};\n+use webgpu_traits::{\n+    ContextConfiguration, PRESENTATION_BUFFER_COUNT, PendingTexture, WebGPUContextId, WebGPUMsg,\n+};\n+use webrender_api::units::DeviceIntSize;\n+use webrender_api::{\n+    ExternalImageData, ExternalImageId, ExternalImageType, ImageDescriptor, ImageDescriptorFlags,\n+    ImageFormat, ImageKey,\n+};\n+use wgpu_core::device::HostMap;\n+use wgpu_core::global::Global;\n+use wgpu_core::id::{\n+    self, BufferId, CommandBufferId, CommandEncoderId, DeviceId, QueueId, TextureId,\n+};\n+use wgpu_core::resource::{\n+    BufferAccessError, BufferDescriptor, BufferMapOperation, CreateBufferError,\n+};\n+\n+use crate::wgt;\n+\n+pub type WGPUImageMap = Arc<Mutex<HashMap<WebGPUContextId, ContextData>>>;\n+\n+const fn image_data(context_id: WebGPUContextId) -> ExternalImageData {\n+    ExternalImageData {\n+        id: ExternalImageId(context_id.0),\n+        channel_index: 0,\n+        image_type: ExternalImageType::Buffer,\n+        normalized_uvs: false,\n+    }\n+}\n+\n+/// Allocated buffer on GPU device\n+#[derive(Clone, Copy, Debug)]\n+struct Buffer {\n+    device_id: DeviceId,\n+    queue_id: QueueId,\n+    size: u64,\n+}\n+\n+impl Buffer {\n+    /// Returns true if buffer is compatible with provided configuration\n+    fn has_config(&self, config: &ContextConfiguration) -> bool {\n+        config.device_id == self.device_id && self.size == config.buffer_size()\n+    }\n+}\n+\n+/// Mapped GPUBuffer\n+#[derive(Debug)]\n+struct MappedBuffer {\n+    buffer: Buffer,\n+    data: NonNull<u8>,\n+    len: u64,\n+    image_size: Size2D<u32>,\n+    image_format: ImageFormat,\n+    is_opaque: bool,\n+}\n+\n+// Mapped buffer can be shared between safely (it's read-only)\n+unsafe impl Send for MappedBuffer {}\n+\n+impl MappedBuffer {\n+    const fn slice(&'_ self) -> &'_ [u8] {\n+        // Safety: Pointer is from wgpu, and we only use it here\n+        unsafe { std::slice::from_raw_parts(self.data.as_ptr(), self.len as usize) }\n+    }\n+\n+    pub fn stride(&self) -> u32 {\n+        (self.image_size.width * self.image_format.bytes_per_pixel() as u32)\n+            .next_multiple_of(wgt::COPY_BYTES_PER_ROW_ALIGNMENT)\n+    }\n+}\n+\n+/// State of staging buffer\n+#[derive(Debug)]\n+enum StagingBufferState {\n+    /// Initial state, buffer has yet to be created,\n+    /// only it's id is reserved\n+    Unassigned,\n+    /// Buffer is allocated on GPUDevice and ready to be used immediately\n+    Available(Buffer),\n+    /// Buffer is running mapAsync\n+    Mapping(Buffer),\n+    /// Buffer is currently actively mapped\n+    Mapped(MappedBuffer),\n+}\n+\n+/// Staging buffer used for\n+/// Texture to Buffer to CPU copying\n+#[derive(Debug)]\n+struct StagingBuffer {\n+    global: Arc<Global>,\n+    buffer_id: BufferId,\n+    state: StagingBufferState,\n+}\n+\n+// [`StagingBuffer`] only used for reading (never for writing)\n+// so it is safe to share between threads.\n+unsafe impl Sync for StagingBuffer {}\n+\n+impl StagingBuffer {\n+    fn new(global: Arc<Global>, buffer_id: BufferId) -> Self {\n+        Self {\n+            global,\n+            buffer_id,\n+            state: StagingBufferState::Unassigned,\n+        }\n+    }\n+\n+    const fn is_mapped(&self) -> bool {\n+        matches!(self.state, StagingBufferState::Mapped(..))\n+    }\n+\n+    /// Return true if buffer can be used directly with provided config\n+    /// without any additional work\n+    fn is_available_with_config(&self, config: &ContextConfiguration) -> bool {\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            return false;\n+        };\n+        buffer.has_config(config)\n+    }\n+\n+    /// Return true if buffer is not mapping or being mapped\n+    const fn needs_assign(&self) -> bool {\n+        matches!(\n+            self.state,\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_)\n+        )\n+    }\n+\n+    /// Make buffer available by unmap/destroy and recreating it if needed\n+    fn ensure_available(&mut self, config: &ContextConfiguration) -> Result<(), CreateBufferError> {\n+        let recreate = match &self.state {\n+            StagingBufferState::Unassigned => true,\n+            StagingBufferState::Available(buffer) |\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                if buffer.has_config(config) {\n+                    let _ = self.global.buffer_unmap(self.buffer_id);\n+                    false\n+                } else {\n+                    self.global.buffer_drop(self.buffer_id);\n+                    true\n+                }\n+            },\n+        };\n+        if recreate {\n+            let buffer_size = config.buffer_size();\n+            let (_, error) = self.global.device_create_buffer(\n+                config.device_id,\n+                &BufferDescriptor {\n+                    label: None,\n+                    size: buffer_size,\n+                    usage: wgt::BufferUsages::MAP_READ | wgt::BufferUsages::COPY_DST,\n+                    mapped_at_creation: false,\n+                },\n+                Some(self.buffer_id),\n+            );\n+            if let Some(error) = error {\n+                return Err(error);\n+            };\n+            self.state = StagingBufferState::Available(Buffer {\n+                device_id: config.device_id,\n+                queue_id: config.queue_id,\n+                size: buffer_size,\n+            });\n+        }\n+        Ok(())\n+    }\n+\n+    /// Makes buffer available and prepares command encoder\n+    /// that will copy texture to this staging buffer.\n+    ///\n+    /// Caller must submit command buffer to queue.\n+    fn prepare_load_texture_command_buffer(\n+        &mut self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        config: &ContextConfiguration,\n+    ) -> Result<CommandBufferId, Box<dyn std::error::Error>> {\n+        self.ensure_available(config)?;\n+        let StagingBufferState::Available(buffer) = &self.state else {\n+            unreachable!(\"Should be made available by `ensure_available`\")\n+        };\n+        let device_id = buffer.device_id;\n+        let command_descriptor = wgt::CommandEncoderDescriptor { label: None };\n+        let (encoder_id, error) = self.global.device_create_command_encoder(\n+            device_id,\n+            &command_descriptor,\n+            Some(encoder_id),\n+        );\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        let buffer_info = wgt::TexelCopyBufferInfo {\n+            buffer: self.buffer_id,\n+            layout: wgt::TexelCopyBufferLayout {\n+                offset: 0,\n+                bytes_per_row: Some(config.stride()),\n+                rows_per_image: None,\n+            },\n+        };\n+        let texture_info = wgt::TexelCopyTextureInfo {\n+            texture: texture_id,\n+            mip_level: 0,\n+            origin: wgt::Origin3d::ZERO,\n+            aspect: wgt::TextureAspect::All,\n+        };\n+        let copy_size = wgt::Extent3d {\n+            width: config.size.width,\n+            height: config.size.height,\n+            depth_or_array_layers: 1,\n+        };\n+        self.global.command_encoder_copy_texture_to_buffer(\n+            encoder_id,\n+            &texture_info,\n+            &buffer_info,\n+            &copy_size,\n+        )?;\n+        let (command_buffer_id, error) = self\n+            .global\n+            .command_encoder_finish(encoder_id, &wgt::CommandBufferDescriptor::default());\n+        if let Some(error) = error {\n+            return Err(error.into());\n+        };\n+        Ok(command_buffer_id)\n+    }\n+\n+    /// Unmaps buffer or cancel mapping if in progress\n+    fn unmap(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned | StagingBufferState::Available(_) => {},\n+            StagingBufferState::Mapping(buffer) |\n+            StagingBufferState::Mapped(MappedBuffer { buffer, .. }) => {\n+                let _ = self.global.buffer_unmap(self.buffer_id);\n+                self.state = StagingBufferState::Available(buffer)\n+            },\n+        }\n+    }\n+\n+    /// Obtains snapshot from mapped buffer\n+    fn snapshot(&self) -> Option<Snapshot> {\n+        let StagingBufferState::Mapped(mapped) = &self.state else {\n+            return None;\n+        };\n+        let format = match mapped.image_format {\n+            ImageFormat::RGBA8 => SnapshotPixelFormat::RGBA,\n+            ImageFormat::BGRA8 => SnapshotPixelFormat::BGRA,\n+            _ => unimplemented!(),\n+        };\n+        let alpha_mode = if mapped.is_opaque {\n+            SnapshotAlphaMode::AsOpaque {\n+                premultiplied: false,\n+            }\n+        } else {\n+            SnapshotAlphaMode::Transparent {\n+                premultiplied: true,\n+            }\n+        };\n+        let padded_byte_width = mapped.stride();\n+        let data = mapped.slice();\n+        let bytes_per_pixel = mapped.image_format.bytes_per_pixel() as usize;\n+        let mut result_unpadded =\n+            Vec::<u8>::with_capacity(mapped.image_size.area() as usize * bytes_per_pixel);\n+        for row in 0..mapped.image_size.height {\n+            let start = (row * padded_byte_width).try_into().ok()?;\n+            result_unpadded\n+                .extend(&data[start..start + mapped.image_size.width as usize * bytes_per_pixel]);\n+        }\n+        let mut snapshot =\n+            Snapshot::from_vec(mapped.image_size, format, alpha_mode, result_unpadded);\n+        if mapped.is_opaque {\n+            snapshot.transform(SnapshotAlphaMode::Opaque, snapshot.format())\n+        }\n+        Some(snapshot)\n+    }\n+}\n+\n+impl Drop for StagingBuffer {\n+    fn drop(&mut self) {\n+        match self.state {\n+            StagingBufferState::Unassigned => {},\n+            StagingBufferState::Available(_) |\n+            StagingBufferState::Mapping(_) |\n+            StagingBufferState::Mapped(_) => {\n+                self.global.buffer_drop(self.buffer_id);\n+            },\n+        }\n+    }\n+}\n+\n+#[derive(Default)]\n+pub struct WGPUExternalImages {\n+    pub images: WGPUImageMap,\n+    pub locked_ids: HashMap<WebGPUContextId, PresentationStagingBuffer>,\n+}\n+\n+impl WebrenderExternalImageApi for WGPUExternalImages {\n+    fn lock(&mut self, id: u64) -> (ExternalImageSource<'_>, Size2D<i32>) {\n+        let id = WebGPUContextId(id);\n+        let presentation = {\n+            let mut webgpu_contexts = self.images.lock().unwrap();\n+            webgpu_contexts\n+                .get_mut(&id)\n+                .and_then(|context_data| context_data.presentation.clone())\n+        };\n+        let Some(presentation) = presentation else {\n+            return (ExternalImageSource::Invalid, Size2D::zero());\n+        };\n+        self.locked_ids.insert(id, presentation);\n+        let presentation = self.locked_ids.get(&id).unwrap();\n+        let StagingBufferState::Mapped(mapped_buffer) = &presentation.staging_buffer.state else {\n+            unreachable!(\"Presentation staging buffer should be mapped\")\n+        };\n+        let size = mapped_buffer.image_size;\n+        (\n+            ExternalImageSource::RawData(mapped_buffer.slice()),\n+            size.cast().cast_unit(),\n+        )\n+    }\n+\n+    fn unlock(&mut self, id: u64) {\n+        let id = WebGPUContextId(id);\n+        let Some(presentation) = self.locked_ids.remove(&id) else {\n+            return;\n+        };\n+        let mut webgpu_contexts = self.images.lock().unwrap();\n+        if let Some(context_data) = webgpu_contexts.get_mut(&id) {\n+            // we use this to return staging buffer if newer exists\n+            presentation.maybe_destroy(context_data);\n+        } else {\n+            // this will not free this adapter id in script, but that's okay\n+            drop(presentation);\n+        }\n+    }\n+}\n+\n+/// Staging buffer currently used for presenting the epoch.\n+///\n+/// Users should `put_presentation` to destroy\n+#[derive(Clone)]\n+pub struct PresentationStagingBuffer {\n+    epoch: Epoch,\n+    staging_buffer: Arc<StagingBuffer>,\n+}\n+\n+impl PresentationStagingBuffer {\n+    fn new(epoch: Epoch, staging_buffer: StagingBuffer) -> Self {\n+        Self {\n+            epoch,\n+            staging_buffer: Arc::new(staging_buffer),\n+        }\n+    }\n+\n+    /// If the internal staging buffer is not shared,\n+    /// unmap it and call [`ContextData::return_staging_buffer`] with it.\n+    fn maybe_destroy(self, context_data: &mut ContextData) {\n+        if let Some(mut staging_buffer) = Arc::into_inner(self.staging_buffer) {\n+            staging_buffer.unmap();\n+            context_data.return_staging_buffer(staging_buffer);\n+        }\n+    }\n+}\n+\n+/// Main process structure of GPUCanvasContext\n+pub struct ContextData {\n+    /// Associated WebRender image\n+    image_key: ImageKey,\n+    /// Staging buffers that are not actively used.\n+    ///\n+    /// Staging buffer here are either [`StagingBufferState::Unassigned`] or [`StagingBufferState::Available`].\n+    /// They are removed from here when they are in process of mapping or mapped.\n+    inactive_staging_buffers: ArrayVec<StagingBuffer, PRESENTATION_BUFFER_COUNT>,\n+    /// The [`PresentationStagingBuffer`] of the most recent presentation. This will\n+    /// be `None` directly after initialization, as clearing is handled completely in\n+    /// the `ScriptThread`.\n+    presentation: Option<PresentationStagingBuffer>,\n+    /// Next epoch to be used\n+    next_epoch: Epoch,\n+}\n+\n+impl ContextData {\n+    fn new(\n+        image_key: ImageKey,\n+        global: &Arc<Global>,\n+        buffer_ids: ArrayVec<id::BufferId, PRESENTATION_BUFFER_COUNT>,\n+    ) -> Self {\n+        Self {\n+            image_key,\n+            inactive_staging_buffers: buffer_ids\n+                .iter()\n+                .map(|buffer_id| StagingBuffer::new(global.clone(), *buffer_id))\n+                .collect(),\n+            presentation: None,\n+            next_epoch: Epoch(1),\n+        }\n+    }\n+\n+    /// Returns `None` if no staging buffer is unused or failure when making it available\n+    fn get_or_make_available_buffer(\n+        &'_ mut self,\n+        config: &ContextConfiguration,\n+    ) -> Option<StagingBuffer> {\n+        self.inactive_staging_buffers\n+            .iter()\n+            // try to get first preallocated GPUBuffer\n+            .position(|staging_buffer| staging_buffer.is_available_with_config(config))\n+            // fallback to first unallocated\n+            .or_else(|| {\n+                self.inactive_staging_buffers\n+                    .iter()\n+                    .position(|staging_buffer| staging_buffer.needs_assign())\n+            })\n+            // or use first one\n+            .or_else(|| {\n+                if self.inactive_staging_buffers.is_empty() {\n+                    None\n+                } else {\n+                    Some(0)\n+                }\n+            })\n+            .and_then(|pos| {\n+                let mut staging_buffer = self.inactive_staging_buffers.remove(pos);\n+                if staging_buffer.ensure_available(config).is_ok() {\n+                    Some(staging_buffer)\n+                } else {\n+                    // if we fail to make it available, return it\n+                    self.inactive_staging_buffers.push(staging_buffer);\n+                    None\n+                }\n+            })\n+    }\n+\n+    /// Destroy the context that this [`ContextData`] represents,\n+    /// freeing all of its buffers,\n+    /// and deleting the associated WebRender image.\n+    fn destroy(\n+        self,\n+        script_sender: &IpcSender<WebGPUMsg>,\n+        compositor_api: &CrossProcessCompositorApi,\n+    ) {\n+        // free ids on script\n+        for staging_buffer in self.inactive_staging_buffers {\n+            if let Err(e) = script_sender.send(WebGPUMsg::FreeBuffer(staging_buffer.buffer_id)) {\n+                warn!(\n+                    \"Unable to send FreeBuffer({:?}) ({:?})\",\n+                    staging_buffer.buffer_id, e\n+                );\n+            };\n+        }\n+        compositor_api.delete_image(self.image_key);\n+    }\n+\n+    /// Returns new epoch\n+    fn next_epoch(&mut self) -> Epoch {\n+        let epoch = self.next_epoch;\n+        self.next_epoch.next();\n+        epoch\n+    }\n+\n+    /// If the given [`PresentationStagingBuffer`] is for a newer presentation, replace the existing\n+    /// one. Deallocate the older one and call by calling [`Self::return_staging_buffer`] on it.\n+    fn replace_presentation(&mut self, presentation: PresentationStagingBuffer) {\n+        let stale_presentation = if presentation.epoch >=\n+            self.presentation\n+                .as_ref()\n+                .map(|p| p.epoch)\n+                .unwrap_or(Epoch(0))\n+        {\n+            self.presentation.replace(presentation)\n+        } else {\n+            Some(presentation)\n+        };\n+        if let Some(stale_presentation) = stale_presentation {\n+            stale_presentation.maybe_destroy(self);\n+        }\n+    }\n+\n+    fn clear_presentation(&mut self) {\n+        if let Some(stale_presentation) = self.presentation.take() {\n+            stale_presentation.maybe_destroy(self);\n+        }\n+    }\n+\n+    fn return_staging_buffer(&mut self, staging_buffer: StagingBuffer) {\n+        self.inactive_staging_buffers.push(staging_buffer)\n+    }\n+}\n+\n+impl crate::WGPU {\n+    pub(crate) fn create_context(\n+        &self,\n+        context_id: WebGPUContextId,\n+        image_key: ImageKey,\n+        size: DeviceIntSize,\n+        buffer_ids: ArrayVec<id::BufferId, PRESENTATION_BUFFER_COUNT>,\n+    ) {\n+        let context_data = ContextData::new(image_key, &self.global, buffer_ids);\n+        self.compositor_api.add_image(\n+            image_key,\n+            ImageDescriptor {\n+                format: ImageFormat::BGRA8,\n+                size,\n+                stride: None,\n+                offset: 0,\n+                flags: ImageDescriptorFlags::empty(),\n+            },\n+            SerializableImageData::External(image_data(context_id)),\n+        );\n+        assert!(\n+            self.wgpu_image_map\n+                .lock()\n+                .unwrap()\n+                .insert(context_id, context_data)\n+                .is_none(),\n+            \"Context should be created only once!\"\n+        );\n+    }\n+\n+    pub(crate) fn get_image(\n+        &self,\n+        context_id: WebGPUContextId,\n+        pending_texture: Option<PendingTexture>,\n+        sender: IpcSender<IpcSnapshot>,\n+    ) {\n+        let mut webgpu_contexts = self.wgpu_image_map.lock().unwrap();\n+        let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+        if let Some(PendingTexture {\n+            texture_id,\n+            encoder_id,\n+            configuration,\n+        }) = pending_texture\n+        {\n+            let Some(staging_buffer) = context_data.get_or_make_available_buffer(&configuration)\n+            else {\n+                warn!(\"Failure obtaining available staging buffer\");\n+                sender\n+                    .send(Snapshot::cleared(configuration.size).as_ipc())\n+                    .unwrap();\n+                return;\n+            };\n+\n+            let epoch = context_data.next_epoch();\n+            let wgpu_image_map = self.wgpu_image_map.clone();\n+            let sender = sender.clone();\n+            drop(webgpu_contexts);\n+            self.texture_download(\n+                texture_id,\n+                encoder_id,\n+                staging_buffer,\n+                configuration,\n+                move |staging_buffer| {\n+                    let mut webgpu_contexts = wgpu_image_map.lock().unwrap();\n+                    let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+                    sender\n+                        .send(\n+                            staging_buffer\n+                                .snapshot()\n+                                .unwrap_or_else(|| Snapshot::cleared(configuration.size))\n+                                .as_ipc(),\n+                        )\n+                        .unwrap();\n+                    if staging_buffer.is_mapped() {\n+                        context_data.replace_presentation(PresentationStagingBuffer::new(\n+                            epoch,\n+                            staging_buffer,\n+                        ));\n+                    } else {\n+                        // failure\n+                        context_data.return_staging_buffer(staging_buffer);\n+                    }\n+                },\n+            );\n+        } else {\n+            sender\n+                .send(\n+                    context_data\n+                        .presentation\n+                        .as_ref()\n+                        .and_then(|presentation_staging_buffer| {\n+                            presentation_staging_buffer.staging_buffer.snapshot()\n+                        })\n+                        .unwrap_or_else(Snapshot::empty)\n+                        .as_ipc(),\n+                )\n+                .unwrap();\n+        }\n+    }\n+\n+    /// Reads texture to staging buffer maps it to CPU\n+    /// and updates image in WR when done\n+    pub(crate) fn present(\n+        &self,\n+        context_id: WebGPUContextId,\n+        pending_texture: Option<PendingTexture>,\n+        size: Size2D<u32>,\n+        canvas_epoch: Epoch,\n+    ) {\n+        let mut webgpu_contexts = self.wgpu_image_map.lock().unwrap();\n+        let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+        let image_key = context_data.image_key;\n+        let Some(PendingTexture {\n+            texture_id,\n+            encoder_id,\n+            configuration,\n+        }) = pending_texture\n+        else {\n+            context_data.clear_presentation();\n+            self.compositor_api.update_image(\n+                image_key,\n+                ImageDescriptor {\n+                    format: ImageFormat::BGRA8,\n+                    size: size.cast_unit().cast(),\n+                    stride: None,\n+                    offset: 0,\n+                    flags: ImageDescriptorFlags::empty(),\n+                },\n+                SerializableImageData::External(image_data(context_id)),\n+                Some(canvas_epoch),\n+            );\n+            return;\n+        };\n+        let Some(staging_buffer) = context_data.get_or_make_available_buffer(&configuration) else {\n+            warn!(\"Failure obtaining available staging buffer\");\n+            context_data.clear_presentation();\n+            self.compositor_api.update_image(\n+                image_key,\n+                configuration.into(),\n+                SerializableImageData::External(image_data(context_id)),\n+                Some(canvas_epoch),\n+            );\n+            return;\n+        };\n+        let epoch = context_data.next_epoch();\n+        let wgpu_image_map = self.wgpu_image_map.clone();\n+        let compositor_api = self.compositor_api.clone();\n+        drop(webgpu_contexts);\n+        self.texture_download(\n+            texture_id,\n+            encoder_id,\n+            staging_buffer,\n+            configuration,\n+            move |staging_buffer| {\n+                let mut webgpu_contexts = wgpu_image_map.lock().unwrap();\n+                let context_data = webgpu_contexts.get_mut(&context_id).unwrap();\n+                if staging_buffer.is_mapped() {\n+                    context_data.replace_presentation(PresentationStagingBuffer::new(\n+                        epoch,\n+                        staging_buffer,\n+                    ));\n+                } else {\n+                    context_data.return_staging_buffer(staging_buffer);\n+                    context_data.clear_presentation();\n+                }\n+                // update image in WR\n+                compositor_api.update_image(\n+                    image_key,\n+                    configuration.into(),\n+                    SerializableImageData::External(image_data(context_id)),\n+                    Some(canvas_epoch),\n+                );\n+            },\n+        );\n+    }\n+\n+    /// Copies data from provided texture using encoder_id to provided staging buffer.\n+    ///\n+    /// Callback is guaranteed to be called.\n+    /// Returns [`StagingBuffer`] with [`StagingBufferState::Mapped`] state on success\n+    /// or [`StagingBufferState::Available`] on failure.\n+    fn texture_download(\n+        &self,\n+        texture_id: TextureId,\n+        encoder_id: CommandEncoderId,\n+        mut staging_buffer: StagingBuffer,\n+        config: ContextConfiguration,\n+        callback: impl FnOnce(StagingBuffer) + Send + 'static,",
        "comment_created_at": "2025-09-08T16:46:53+00:00",
        "comment_author": "mrobinson",
        "comment_body": "Hrm. I think that I would consider a failure as a kind of \"completion,\" but in the end this is a small nit, so do what you feel here.",
        "pr_file_module": null
      }
    ]
  }
]