[
  {
    "discussion_id": "2239587888",
    "pr_number": 8328,
    "pr_file": "python/sglang/srt/mem_cache/memory_pool.py",
    "created_at": "2025-07-29T12:05:56+00:00",
    "commented_code": ")\n \n \n+def set_mla_kv_buffer_npu(",
    "repo_full_name": "sgl-project/sglang",
    "discussion_comments": [
      {
        "comment_id": "2239587888",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 8328,
        "pr_file": "python/sglang/srt/mem_cache/memory_pool.py",
        "discussion_id": "2239587888",
        "commented_code": "@@ -766,6 +766,16 @@ def set_mla_kv_buffer_triton(\n     )\n \n \n+def set_mla_kv_buffer_npu(",
        "comment_created_at": "2025-07-29T12:05:56+00:00",
        "comment_author": "Alcanderian",
        "comment_body": "We have AscendTokenToKVPool",
        "pr_file_module": null
      },
      {
        "comment_id": "2243634893",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 8328,
        "pr_file": "python/sglang/srt/mem_cache/memory_pool.py",
        "discussion_id": "2239587888",
        "commented_code": "@@ -766,6 +766,16 @@ def set_mla_kv_buffer_triton(\n     )\n \n \n+def set_mla_kv_buffer_npu(",
        "comment_created_at": "2025-07-30T19:10:54+00:00",
        "comment_author": "ZhengdQin",
        "comment_body": "Thanks for the comment, for the _npumla_ backend, using AscendTokenToKVPool is not very convenient. This is because in MLATokenToKVPool, the allocation and usage of KV caches are independent across layers. If a use a contiguous buffer of KV cache, additional slice operations may be required.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2283864902",
    "pr_number": 8901,
    "pr_file": "python/sglang/srt/managers/cache_controller.py",
    "created_at": "2025-08-19T01:51:56+00:00",
    "commented_code": "self.backup_queue.put(operation)\n         return operation.id\n \n+    # Backup batch by batch\n     def generic_page_backup(self, operation, batch_size=8):\n         for i in range(0, len(operation.hash_value), batch_size):\n-            page_hashes = operation.hash_value[i : i + batch_size]\n-            page_data = [\n-                self.mem_pool_host.get_flat_data_page(\n-                    operation.host_indices[j * self.page_size]\n-                )\n-                for j in range(i, i + len(page_hashes))\n-            ]\n-            success = self.storage_backend.batch_set(page_hashes, page_data)\n-            if not success:\n-                logger.warning(f\"Failed to write page {page_hashes} to storage.\")\n-                break\n-            operation.completed_tokens += self.page_size * len(page_hashes)\n-\n-    def mooncake_page_backup(self, operation):\n-        if len(operation.hash_value):\n-            exist_hashvalues = self.storage_backend.exists(operation.hash_value)\n-            indices = operation.host_indices.tolist()\n-            non_exist_keys = []\n-            non_exist_indices = []\n-            for i in range(len(operation.hash_value)):\n-                if not exist_hashvalues[operation.hash_value[i]]:\n-                    non_exist_keys.append(operation.hash_value[i])\n-                    non_exist_indices.extend(\n-                        indices[i * self.page_size : (i + 1) * self.page_size]\n-                    )\n-            if len(non_exist_keys) > 0:\n+            batch_hashes = operation.hash_value[i : i + batch_size]\n+            # Set one batch token, and record if success\n+            if self.is_mooncake_backend():\n+                # zero copy",
    "repo_full_name": "sgl-project/sglang",
    "discussion_comments": [
      {
        "comment_id": "2283864902",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 8901,
        "pr_file": "python/sglang/srt/managers/cache_controller.py",
        "discussion_id": "2283864902",
        "commented_code": "@@ -713,46 +739,43 @@ def write_storage(\n         self.backup_queue.put(operation)\n         return operation.id\n \n+    # Backup batch by batch\n     def generic_page_backup(self, operation, batch_size=8):\n         for i in range(0, len(operation.hash_value), batch_size):\n-            page_hashes = operation.hash_value[i : i + batch_size]\n-            page_data = [\n-                self.mem_pool_host.get_flat_data_page(\n-                    operation.host_indices[j * self.page_size]\n-                )\n-                for j in range(i, i + len(page_hashes))\n-            ]\n-            success = self.storage_backend.batch_set(page_hashes, page_data)\n-            if not success:\n-                logger.warning(f\"Failed to write page {page_hashes} to storage.\")\n-                break\n-            operation.completed_tokens += self.page_size * len(page_hashes)\n-\n-    def mooncake_page_backup(self, operation):\n-        if len(operation.hash_value):\n-            exist_hashvalues = self.storage_backend.exists(operation.hash_value)\n-            indices = operation.host_indices.tolist()\n-            non_exist_keys = []\n-            non_exist_indices = []\n-            for i in range(len(operation.hash_value)):\n-                if not exist_hashvalues[operation.hash_value[i]]:\n-                    non_exist_keys.append(operation.hash_value[i])\n-                    non_exist_indices.extend(\n-                        indices[i * self.page_size : (i + 1) * self.page_size]\n-                    )\n-            if len(non_exist_keys) > 0:\n+            batch_hashes = operation.hash_value[i : i + batch_size]\n+            # Set one batch token, and record if success\n+            if self.is_mooncake_backend():\n+                # zero copy",
        "comment_created_at": "2025-08-19T01:51:56+00:00",
        "comment_author": "xiezhq-hermann",
        "comment_body": "same here, we can use zerocopy_page_backup from https://github.com/sgl-project/sglang/pull/9109 and leave the generic page backup for layer first layout.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2284162899",
    "pr_number": 8742,
    "pr_file": "python/sglang/srt/multimodal/processors/base_processor.py",
    "created_at": "2025-08-19T06:05:59+00:00",
    "commented_code": "import numpy as np\n import torch\n+import transformers\n from PIL import Image\n from transformers import BaseImageProcessorFast\n \n from sglang.srt.managers.schedule_batch import Modality, MultimodalDataItem\n-from sglang.srt.utils import load_audio, load_image, load_video, logger\n+from sglang.srt.utils import (\n+    get_bool_env_var,\n+    load_audio,\n+    load_image,\n+    load_video,\n+    logger,\n+)\n+\n+CACHED_IMAGE_MAX_NUM = 64\n+QWEN2_VL_PATCH_SIZE = 196.0\n+QWEN2_PER_TOKEN_PATCH_NUM = 4\n+QWEN2_PATCH_SIZE = 14\n+\n+VISION_START_TOKEN = 151652\n+IMG_PAD_TOKEN = 151655\n+VISION_END_TOKEN = 151653\n+\n+\n+def fast_image_hash(img: Image.Image, hash_type: str = \"int\") -> int | str:\n+    small_img = img.resize((8, 8), Image.Resampling.BILINEAR).convert(\"L\")\n+    pixel_data = small_img.tobytes()\n+    hash_obj = hashlib.md5(pixel_data)\n+\n+    if hash_type == \"int\":\n+        return int.from_bytes(hash_obj.digest(), byteorder=\"little\", signed=False)\n+    else:\n+        return hash_obj.hexdigest()\n+\n+\n+def image_to_int(img: Image.Image) -> int:\n+    img_bytes = img.tobytes()\n+    hash_obj = hashlib.md5(img_bytes)\n+    hash_bytes = hash_obj.digest()\n+    return int.from_bytes(hash_bytes, byteorder=\"big\")\n+\n+\n+class FIFOHashTable:",
    "repo_full_name": "sgl-project/sglang",
    "discussion_comments": [
      {
        "comment_id": "2284162899",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 8742,
        "pr_file": "python/sglang/srt/multimodal/processors/base_processor.py",
        "discussion_id": "2284162899",
        "commented_code": "@@ -9,11 +10,137 @@\n \n import numpy as np\n import torch\n+import transformers\n from PIL import Image\n from transformers import BaseImageProcessorFast\n \n from sglang.srt.managers.schedule_batch import Modality, MultimodalDataItem\n-from sglang.srt.utils import load_audio, load_image, load_video, logger\n+from sglang.srt.utils import (\n+    get_bool_env_var,\n+    load_audio,\n+    load_image,\n+    load_video,\n+    logger,\n+)\n+\n+CACHED_IMAGE_MAX_NUM = 64\n+QWEN2_VL_PATCH_SIZE = 196.0\n+QWEN2_PER_TOKEN_PATCH_NUM = 4\n+QWEN2_PATCH_SIZE = 14\n+\n+VISION_START_TOKEN = 151652\n+IMG_PAD_TOKEN = 151655\n+VISION_END_TOKEN = 151653\n+\n+\n+def fast_image_hash(img: Image.Image, hash_type: str = \"int\") -> int | str:\n+    small_img = img.resize((8, 8), Image.Resampling.BILINEAR).convert(\"L\")\n+    pixel_data = small_img.tobytes()\n+    hash_obj = hashlib.md5(pixel_data)\n+\n+    if hash_type == \"int\":\n+        return int.from_bytes(hash_obj.digest(), byteorder=\"little\", signed=False)\n+    else:\n+        return hash_obj.hexdigest()\n+\n+\n+def image_to_int(img: Image.Image) -> int:\n+    img_bytes = img.tobytes()\n+    hash_obj = hashlib.md5(img_bytes)\n+    hash_bytes = hash_obj.digest()\n+    return int.from_bytes(hash_bytes, byteorder=\"big\")\n+\n+\n+class FIFOHashTable:",
        "comment_created_at": "2025-08-19T06:05:59+00:00",
        "comment_author": "byjiang1996",
        "comment_body": "Similar comments as https://github.com/sgl-project/sglang/pull/8742/files#r2284122880\r\n\r\nIf we can use cache more than once, we should consider `@lru_cache` i think",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2278451543",
    "pr_number": 7667,
    "pr_file": "python/sglang/srt/layers/moe/utils.py",
    "created_at": "2025-08-15T07:26:17+00:00",
    "commented_code": "return result\n \n \n+def should_use_flashinfer_cutlass_moe_fp4_allgather():",
    "repo_full_name": "sgl-project/sglang",
    "discussion_comments": [
      {
        "comment_id": "2278451543",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 7667,
        "pr_file": "python/sglang/srt/layers/moe/utils.py",
        "discussion_id": "2278451543",
        "commented_code": "@@ -17,6 +22,18 @@ def should_use_flashinfer_trtllm_moe():\n     return result\n \n \n+def should_use_flashinfer_cutlass_moe_fp4_allgather():",
        "comment_created_at": "2025-08-15T07:26:17+00:00",
        "comment_author": "ch-wan",
        "comment_body": "use lru_cache",
        "pr_file_module": null
      },
      {
        "comment_id": "2279717030",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 7667,
        "pr_file": "python/sglang/srt/layers/moe/utils.py",
        "discussion_id": "2278451543",
        "commented_code": "@@ -17,6 +22,18 @@ def should_use_flashinfer_trtllm_moe():\n     return result\n \n \n+def should_use_flashinfer_cutlass_moe_fp4_allgather():",
        "comment_created_at": "2025-08-15T19:13:47+00:00",
        "comment_author": "trevor-m",
        "comment_body": "Thanks, done",
        "pr_file_module": null
      }
    ]
  }
]