[
  {
    "discussion_id": "2160636779",
    "pr_number": 7379,
    "pr_file": "python/sglang/srt/managers/data_parallel_controller.py",
    "created_at": "2025-06-23T03:05:42+00:00",
    "commented_code": "def shortest_queue_scheduler(self, input_requests):\n         raise NotImplementedError()\n \n+    def minimum_tokens_scheduler(self, req):\n+        def get_next_global_balance_id() -> int:\n+            INT32_MAX = 2147483647\n+            current_id = self.global_balance_id\n+            self.global_balance_id = (self.global_balance_id + 1) % INT32_MAX\n+            return current_id\n+\n+        req.dp_balance_id = get_next_global_balance_id()\n+        with self.balance_meta.mutex:\n+            # 1. local_tokens represents the tokens currently inferring on the worker,\n+            #  while onfly refers to the requests dispatched by the dispatcher but not yet received by the scheduler.\n+            onfly_info = self.balance_meta.get_shared_onfly()",
    "repo_full_name": "sgl-project/sglang",
    "discussion_comments": [
      {
        "comment_id": "2160636779",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 7379,
        "pr_file": "python/sglang/srt/managers/data_parallel_controller.py",
        "discussion_id": "2160636779",
        "commented_code": "@@ -266,6 +283,31 @@ def round_robin_scheduler(self, req: Req):\n     def shortest_queue_scheduler(self, input_requests):\n         raise NotImplementedError()\n \n+    def minimum_tokens_scheduler(self, req):\n+        def get_next_global_balance_id() -> int:\n+            INT32_MAX = 2147483647\n+            current_id = self.global_balance_id\n+            self.global_balance_id = (self.global_balance_id + 1) % INT32_MAX\n+            return current_id\n+\n+        req.dp_balance_id = get_next_global_balance_id()\n+        with self.balance_meta.mutex:\n+            # 1. local_tokens represents the tokens currently inferring on the worker,\n+            #  while onfly refers to the requests dispatched by the dispatcher but not yet received by the scheduler.\n+            onfly_info = self.balance_meta.get_shared_onfly()",
        "comment_created_at": "2025-06-23T03:05:42+00:00",
        "comment_author": "Edenzzzz",
        "comment_body": "might be more formal to name these as \"on_the_fly\" or \"in_flight\"?",
        "pr_file_module": null
      },
      {
        "comment_id": "2160641954",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 7379,
        "pr_file": "python/sglang/srt/managers/data_parallel_controller.py",
        "discussion_id": "2160636779",
        "commented_code": "@@ -266,6 +283,31 @@ def round_robin_scheduler(self, req: Req):\n     def shortest_queue_scheduler(self, input_requests):\n         raise NotImplementedError()\n \n+    def minimum_tokens_scheduler(self, req):\n+        def get_next_global_balance_id() -> int:\n+            INT32_MAX = 2147483647\n+            current_id = self.global_balance_id\n+            self.global_balance_id = (self.global_balance_id + 1) % INT32_MAX\n+            return current_id\n+\n+        req.dp_balance_id = get_next_global_balance_id()\n+        with self.balance_meta.mutex:\n+            # 1. local_tokens represents the tokens currently inferring on the worker,\n+            #  while onfly refers to the requests dispatched by the dispatcher but not yet received by the scheduler.\n+            onfly_info = self.balance_meta.get_shared_onfly()",
        "comment_created_at": "2025-06-23T03:14:04+00:00",
        "comment_author": "WANG-GH",
        "comment_body": "Sure, we can first discuss the current implementation of the algorithm, and then I\u2019ll make a unified update accordingly.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2265878664",
    "pr_number": 7379,
    "pr_file": "python/sglang/srt/managers/scheduler.py",
    "created_at": "2025-08-11T07:18:22+00:00",
    "commented_code": "disable_overlap_schedule=self.server_args.disable_overlap_schedule,\n         )\n \n+    def handle_dp_balance_data(self, local_batch: ScheduleBatch):\n+        def gather_dp_balance_info(holding_tokens_list) -> Union[None, List[List[int]]]:\n+            \"\"\"gather recv_dp_balance_id_this_term and holding tokens per worker for dp balance\"\"\"\n+            recv_list = self.recv_dp_balance_id_this_term\n+            assert len(recv_list) <= 511, (\n+                \"The number of requests received this round is too large. \"\n+                \"Please increase gather_tensor_size and onfly_info_size.\"\n+            )\n+            # The maximum size of the tensor used for gathering data from all workers.\n+            gather_tensor_size = 512",
    "repo_full_name": "sgl-project/sglang",
    "discussion_comments": [
      {
        "comment_id": "2265878664",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 7379,
        "pr_file": "python/sglang/srt/managers/scheduler.py",
        "discussion_id": "2265878664",
        "commented_code": "@@ -1767,6 +1788,86 @@ def prepare_mlp_sync_batch(self, local_batch: ScheduleBatch):\n             disable_overlap_schedule=self.server_args.disable_overlap_schedule,\n         )\n \n+    def handle_dp_balance_data(self, local_batch: ScheduleBatch):\n+        def gather_dp_balance_info(holding_tokens_list) -> Union[None, List[List[int]]]:\n+            \"\"\"gather recv_dp_balance_id_this_term and holding tokens per worker for dp balance\"\"\"\n+            recv_list = self.recv_dp_balance_id_this_term\n+            assert len(recv_list) <= 511, (\n+                \"The number of requests received this round is too large. \"\n+                \"Please increase gather_tensor_size and onfly_info_size.\"\n+            )\n+            # The maximum size of the tensor used for gathering data from all workers.\n+            gather_tensor_size = 512",
        "comment_created_at": "2025-08-11T07:18:22+00:00",
        "comment_author": "ollybbmonster",
        "comment_body": "Should this be assert len(recv_list) < 511?\r\nOr recv_tensor could be 1 + 1 + 511 in length, which would exceed 512.\r\n\r\nAlso, as the Gemini bot mentioned, holding_tokens_list is misleading when it\u2019s actually length of tokens rather than a list \u2014 especially since it\u2019s later mixed with real list operations.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2263964485",
    "pr_number": 8593,
    "pr_file": "python/sglang/srt/layers/attention/utils.py",
    "created_at": "2025-08-08T20:48:19+00:00",
    "commented_code": "kv_start = tl.load(kv_start_idx + pid).to(tl.int32)\n         kv_end = kv_start\n     kv_end += tl.load(page_kernel_lens_ptr + pid).to(tl.int32)\n-\n-    num_loop = tl.cdiv(kv_end - kv_start, BLOCK_SIZE)\n-    for i in range(num_loop):\n-        # index into req_to_token_ptr needs to be int64\n-        offset = tl.arange(0, BLOCK_SIZE).to(tl.int64) + i * BLOCK_SIZE\n-        mask = offset < kv_end - kv_start\n-        data = tl.load(\n-            req_to_token_ptr\n-            + req_pool_index * req_to_token_ptr_stride\n-            + kv_start\n-            + offset,\n-            mask=mask,\n-        )\n-        tl.store(kv_indices_ptr + kv_indices_offset + offset, data, mask=mask)\n+    \n+    kv_range = kv_end - kv_start\n+    num_pages = tl.cdiv(kv_range, PAGE_SIZE)\n+    num_pages_loop = tl.cdiv(kv_range, BLOCK_SIZE)\n+    base_ptr = req_to_token_ptr + req_pool_index * req_to_token_ptr_stride + kv_start \n+    for i in range(num_pages_loop):\n+        page_offsets_int64 = (\n+            tl.arange(0, NUM_PAGES_PER_BLOCK).to(tl.int64) + i * NUM_PAGES_PER_BLOCK\n+            ) * PAGE_SIZE\n+        out_page_offsets = tl.arange(0, NUM_PAGES_PER_BLOCK) + i * NUM_PAGES_PER_BLOCK\n+        mask_page_range = page_offsets_int64 < (kv_range)\n+        mask_out = out_page_offsets < num_pages \n+        data = tl.load(base_ptr + page_offsets_int64, mask=mask_page_range)\n+        tl.store(kv_indices_ptr + kv_indices_offset + out_page_offsets, data // PAGE_SIZE, mask=mask_out)",
    "repo_full_name": "sgl-project/sglang",
    "discussion_comments": [
      {
        "comment_id": "2263964485",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 8593,
        "pr_file": "python/sglang/srt/layers/attention/utils.py",
        "discussion_id": "2263964485",
        "commented_code": "@@ -30,20 +101,20 @@ def create_flashinfer_kv_indices_triton(\n         kv_start = tl.load(kv_start_idx + pid).to(tl.int32)\n         kv_end = kv_start\n     kv_end += tl.load(page_kernel_lens_ptr + pid).to(tl.int32)\n-\n-    num_loop = tl.cdiv(kv_end - kv_start, BLOCK_SIZE)\n-    for i in range(num_loop):\n-        # index into req_to_token_ptr needs to be int64\n-        offset = tl.arange(0, BLOCK_SIZE).to(tl.int64) + i * BLOCK_SIZE\n-        mask = offset < kv_end - kv_start\n-        data = tl.load(\n-            req_to_token_ptr\n-            + req_pool_index * req_to_token_ptr_stride\n-            + kv_start\n-            + offset,\n-            mask=mask,\n-        )\n-        tl.store(kv_indices_ptr + kv_indices_offset + offset, data, mask=mask)\n+    \n+    kv_range = kv_end - kv_start\n+    num_pages = tl.cdiv(kv_range, PAGE_SIZE)\n+    num_pages_loop = tl.cdiv(kv_range, BLOCK_SIZE)\n+    base_ptr = req_to_token_ptr + req_pool_index * req_to_token_ptr_stride + kv_start \n+    for i in range(num_pages_loop):\n+        page_offsets_int64 = (\n+            tl.arange(0, NUM_PAGES_PER_BLOCK).to(tl.int64) + i * NUM_PAGES_PER_BLOCK\n+            ) * PAGE_SIZE\n+        out_page_offsets = tl.arange(0, NUM_PAGES_PER_BLOCK) + i * NUM_PAGES_PER_BLOCK\n+        mask_page_range = page_offsets_int64 < (kv_range)\n+        mask_out = out_page_offsets < num_pages \n+        data = tl.load(base_ptr + page_offsets_int64, mask=mask_page_range)\n+        tl.store(kv_indices_ptr + kv_indices_offset + out_page_offsets, data // PAGE_SIZE, mask=mask_out)",
        "comment_created_at": "2025-08-08T20:48:19+00:00",
        "comment_author": "kaixih",
        "comment_body": "nit: I feel we could improve the naming a bit: \n```\npage_offsets_int64 => token_offsets\nout_page_offsets => page_offsets\nmask_page_range => token_mask\nmask_out => page_mask\nnum_pages_loop => num_loops\n```\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2274888701",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 8593,
        "pr_file": "python/sglang/srt/layers/attention/utils.py",
        "discussion_id": "2263964485",
        "commented_code": "@@ -30,20 +101,20 @@ def create_flashinfer_kv_indices_triton(\n         kv_start = tl.load(kv_start_idx + pid).to(tl.int32)\n         kv_end = kv_start\n     kv_end += tl.load(page_kernel_lens_ptr + pid).to(tl.int32)\n-\n-    num_loop = tl.cdiv(kv_end - kv_start, BLOCK_SIZE)\n-    for i in range(num_loop):\n-        # index into req_to_token_ptr needs to be int64\n-        offset = tl.arange(0, BLOCK_SIZE).to(tl.int64) + i * BLOCK_SIZE\n-        mask = offset < kv_end - kv_start\n-        data = tl.load(\n-            req_to_token_ptr\n-            + req_pool_index * req_to_token_ptr_stride\n-            + kv_start\n-            + offset,\n-            mask=mask,\n-        )\n-        tl.store(kv_indices_ptr + kv_indices_offset + offset, data, mask=mask)\n+    \n+    kv_range = kv_end - kv_start\n+    num_pages = tl.cdiv(kv_range, PAGE_SIZE)\n+    num_pages_loop = tl.cdiv(kv_range, BLOCK_SIZE)\n+    base_ptr = req_to_token_ptr + req_pool_index * req_to_token_ptr_stride + kv_start \n+    for i in range(num_pages_loop):\n+        page_offsets_int64 = (\n+            tl.arange(0, NUM_PAGES_PER_BLOCK).to(tl.int64) + i * NUM_PAGES_PER_BLOCK\n+            ) * PAGE_SIZE\n+        out_page_offsets = tl.arange(0, NUM_PAGES_PER_BLOCK) + i * NUM_PAGES_PER_BLOCK\n+        mask_page_range = page_offsets_int64 < (kv_range)\n+        mask_out = out_page_offsets < num_pages \n+        data = tl.load(base_ptr + page_offsets_int64, mask=mask_page_range)\n+        tl.store(kv_indices_ptr + kv_indices_offset + out_page_offsets, data // PAGE_SIZE, mask=mask_out)",
        "comment_created_at": "2025-08-13T23:50:17+00:00",
        "comment_author": "pavanimajety",
        "comment_body": "Made the names better. \r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2238848700",
    "pr_number": 8215,
    "pr_file": "python/sglang/srt/configs/load_config.py",
    "created_at": "2025-07-29T07:43:34+00:00",
    "commented_code": "load_format: Union[str, LoadFormat] = LoadFormat.AUTO\n     download_dir: Optional[str] = None\n+    seed_instance_url: Optional[str] = None\n+    client_instance_id: Optional[str] = None",
    "repo_full_name": "sgl-project/sglang",
    "discussion_comments": [
      {
        "comment_id": "2238848700",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 8215,
        "pr_file": "python/sglang/srt/configs/load_config.py",
        "discussion_id": "2238848700",
        "commented_code": "@@ -50,6 +51,8 @@ class LoadConfig:\n \n     load_format: Union[str, LoadFormat] = LoadFormat.AUTO\n     download_dir: Optional[str] = None\n+    seed_instance_url: Optional[str] = None\n+    client_instance_id: Optional[str] = None",
        "comment_created_at": "2025-07-29T07:43:34+00:00",
        "comment_author": "zhaochenyang20",
        "comment_body": "what's the client here mean?",
        "pr_file_module": null
      },
      {
        "comment_id": "2244871490",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 8215,
        "pr_file": "python/sglang/srt/configs/load_config.py",
        "discussion_id": "2238848700",
        "commented_code": "@@ -50,6 +51,8 @@ class LoadConfig:\n \n     load_format: Union[str, LoadFormat] = LoadFormat.AUTO\n     download_dir: Optional[str] = None\n+    seed_instance_url: Optional[str] = None\n+    client_instance_id: Optional[str] = None",
        "comment_created_at": "2025-07-31T09:36:53+00:00",
        "comment_author": "amysaq2023",
        "comment_body": "client here means the new instance who wants to load weights from the target(seed) instance. Feels like it may be confusing. How about changing to dst_instance?",
        "pr_file_module": null
      },
      {
        "comment_id": "2246654491",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 8215,
        "pr_file": "python/sglang/srt/configs/load_config.py",
        "discussion_id": "2238848700",
        "commented_code": "@@ -50,6 +51,8 @@ class LoadConfig:\n \n     load_format: Union[str, LoadFormat] = LoadFormat.AUTO\n     download_dir: Optional[str] = None\n+    seed_instance_url: Optional[str] = None\n+    client_instance_id: Optional[str] = None",
        "comment_created_at": "2025-08-01T01:02:46+00:00",
        "comment_author": "zhaochenyang20",
        "comment_body": "`dst_instance` is good to go!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2250018960",
    "pr_number": 8731,
    "pr_file": "python/sglang/srt/models/deepseek_v2.py",
    "created_at": "2025-08-03T15:24:02+00:00",
    "commented_code": ")\n         self.act_fn = SiluAndMul()\n \n-    def forward(self, x, forward_batch=None, can_fuse_mlp_allreduce=False):\n+    def forward(\n+        self, x, forward_batch=None, should_fuse_allreduce_residual_rmsnorm=False\n+    ):\n         if (self.tp_size == 1) and x.shape[0] == 0:\n             return x\n \n         gate_up, _ = self.gate_up_proj(x)\n         x = self.act_fn(gate_up)\n-        x, _ = self.down_proj(x, can_fuse_mlp_allreduce=can_fuse_mlp_allreduce)\n+        x, _ = self.down_proj(\n+            x,\n+            should_fuse_allreduce_residual_rmsnorm=should_fuse_allreduce_residual_rmsnorm,",
    "repo_full_name": "sgl-project/sglang",
    "discussion_comments": [
      {
        "comment_id": "2250018960",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 8731,
        "pr_file": "python/sglang/srt/models/deepseek_v2.py",
        "discussion_id": "2250018960",
        "commented_code": "@@ -211,13 +211,18 @@ def __init__(\n             )\n         self.act_fn = SiluAndMul()\n \n-    def forward(self, x, forward_batch=None, can_fuse_mlp_allreduce=False):\n+    def forward(\n+        self, x, forward_batch=None, should_fuse_allreduce_residual_rmsnorm=False\n+    ):\n         if (self.tp_size == 1) and x.shape[0] == 0:\n             return x\n \n         gate_up, _ = self.gate_up_proj(x)\n         x = self.act_fn(gate_up)\n-        x, _ = self.down_proj(x, can_fuse_mlp_allreduce=can_fuse_mlp_allreduce)\n+        x, _ = self.down_proj(\n+            x,\n+            should_fuse_allreduce_residual_rmsnorm=should_fuse_allreduce_residual_rmsnorm,",
        "comment_created_at": "2025-08-03T15:24:02+00:00",
        "comment_author": "ispobock",
        "comment_body": "nit: the name seems too long",
        "pr_file_module": null
      },
      {
        "comment_id": "2250201962",
        "repo_full_name": "sgl-project/sglang",
        "pr_number": 8731,
        "pr_file": "python/sglang/srt/models/deepseek_v2.py",
        "discussion_id": "2250018960",
        "commented_code": "@@ -211,13 +211,18 @@ def __init__(\n             )\n         self.act_fn = SiluAndMul()\n \n-    def forward(self, x, forward_batch=None, can_fuse_mlp_allreduce=False):\n+    def forward(\n+        self, x, forward_batch=None, should_fuse_allreduce_residual_rmsnorm=False\n+    ):\n         if (self.tp_size == 1) and x.shape[0] == 0:\n             return x\n \n         gate_up, _ = self.gate_up_proj(x)\n         x = self.act_fn(gate_up)\n-        x, _ = self.down_proj(x, can_fuse_mlp_allreduce=can_fuse_mlp_allreduce)\n+        x, _ = self.down_proj(\n+            x,\n+            should_fuse_allreduce_residual_rmsnorm=should_fuse_allreduce_residual_rmsnorm,",
        "comment_created_at": "2025-08-04T00:22:46+00:00",
        "comment_author": "BBuf",
        "comment_body": "Yes, I change it to `should_allreduce_fusion` now.",
        "pr_file_module": null
      }
    ]
  }
]