[
  {
    "discussion_id": "2142059239",
    "pr_number": 8229,
    "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
    "created_at": "2025-06-12T08:32:40+00:00",
    "commented_code": "return hasLE, nil\n }\n \n-func (r *ClickHouseReader) PreloadMetricsMetadata(ctx context.Context, orgID valuer.UUID) []error {\n+func (r *ClickHouseReader) PreloadMetricsMetadata(ctx context.Context, orgID valuer.UUID) ([]string, *model.ApiError) {\n \tvar allMetricsMetadata []model.UpdateMetricsMetadata\n-\tvar errorList []error\n+\tvar errorMetricsList []string\n \t// Fetch all rows from ClickHouse\n \tquery := fmt.Sprintf(`SELECT metric_name, type, description , temporality, is_monotonic, unit\n \t\tFROM %s.%s;`, signozMetricDBName, signozUpdatedMetricsMetadataTable)\n \tvalueCtx := context.WithValue(ctx, \"clickhouse_max_threads\", constants.MetricsExplorerClickhouseThreads)\n \terr := r.db.Select(valueCtx, &allMetricsMetadata, query)\n \tif err != nil {\n-\t\terrorList = append(errorList, err)\n-\t\treturn errorList\n+\t\treturn nil, &model.ApiError{Typ: \"ClickHouseError\", Err: fmt.Errorf(\"error in getting updated metadata: %v\", err)}\n \t}\n \tfor _, m := range allMetricsMetadata {\n \t\terr := r.cache.Set(ctx, orgID, constants.UpdatedMetricsMetadataCachePrefix+m.MetricName, &m, -1)\n \t\tif err != nil {\n-\t\t\terrorList = append(errorList, err)\n+\t\t\terrorMetricsList = append(errorMetricsList, m.MetricName)\n \t\t}\n \t}\n \n-\treturn errorList\n+\treturn errorMetricsList, nil\n }\n \n func (r *ClickHouseReader) GetUpdatedMetricsMetadata(ctx context.Context, orgID valuer.UUID, metricNames ...string) (map[string]*model.UpdateMetricsMetadata, *model.ApiError) {\n \tcachedMetadata := make(map[string]*model.UpdateMetricsMetadata)\n \tvar missingMetrics []string\n \n+\tpreCacheLoaded := new(model.CacheLoaded)\n+\terr := r.cache.Get(ctx, orgID, constants.METRICS_UPDATED_METADATA_CACHE_LOADED_KEY, preCacheLoaded, false)",
    "repo_full_name": "SigNoz/signoz",
    "discussion_comments": [
      {
        "comment_id": "2142059239",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8229,
        "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
        "discussion_id": "2142059239",
        "commented_code": "@@ -6233,45 +6233,65 @@ func (r *ClickHouseReader) CheckForLabelsInMetric(ctx context.Context, metricNam\n \treturn hasLE, nil\n }\n \n-func (r *ClickHouseReader) PreloadMetricsMetadata(ctx context.Context, orgID valuer.UUID) []error {\n+func (r *ClickHouseReader) PreloadMetricsMetadata(ctx context.Context, orgID valuer.UUID) ([]string, *model.ApiError) {\n \tvar allMetricsMetadata []model.UpdateMetricsMetadata\n-\tvar errorList []error\n+\tvar errorMetricsList []string\n \t// Fetch all rows from ClickHouse\n \tquery := fmt.Sprintf(`SELECT metric_name, type, description , temporality, is_monotonic, unit\n \t\tFROM %s.%s;`, signozMetricDBName, signozUpdatedMetricsMetadataTable)\n \tvalueCtx := context.WithValue(ctx, \"clickhouse_max_threads\", constants.MetricsExplorerClickhouseThreads)\n \terr := r.db.Select(valueCtx, &allMetricsMetadata, query)\n \tif err != nil {\n-\t\terrorList = append(errorList, err)\n-\t\treturn errorList\n+\t\treturn nil, &model.ApiError{Typ: \"ClickHouseError\", Err: fmt.Errorf(\"error in getting updated metadata: %v\", err)}\n \t}\n \tfor _, m := range allMetricsMetadata {\n \t\terr := r.cache.Set(ctx, orgID, constants.UpdatedMetricsMetadataCachePrefix+m.MetricName, &m, -1)\n \t\tif err != nil {\n-\t\t\terrorList = append(errorList, err)\n+\t\t\terrorMetricsList = append(errorMetricsList, m.MetricName)\n \t\t}\n \t}\n \n-\treturn errorList\n+\treturn errorMetricsList, nil\n }\n \n func (r *ClickHouseReader) GetUpdatedMetricsMetadata(ctx context.Context, orgID valuer.UUID, metricNames ...string) (map[string]*model.UpdateMetricsMetadata, *model.ApiError) {\n \tcachedMetadata := make(map[string]*model.UpdateMetricsMetadata)\n \tvar missingMetrics []string\n \n+\tpreCacheLoaded := new(model.CacheLoaded)\n+\terr := r.cache.Get(ctx, orgID, constants.METRICS_UPDATED_METADATA_CACHE_LOADED_KEY, preCacheLoaded, false)",
        "comment_created_at": "2025-06-12T08:32:40+00:00",
        "comment_author": "vikrantgupta25",
        "comment_body": "why are we doing this ? On the call request the metric from cache based on the key and if the key isn't found then make the call and cache it . we do not need to store another key in cache to store boolean",
        "pr_file_module": null
      },
      {
        "comment_id": "2142091448",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8229,
        "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
        "discussion_id": "2142059239",
        "commented_code": "@@ -6233,45 +6233,65 @@ func (r *ClickHouseReader) CheckForLabelsInMetric(ctx context.Context, metricNam\n \treturn hasLE, nil\n }\n \n-func (r *ClickHouseReader) PreloadMetricsMetadata(ctx context.Context, orgID valuer.UUID) []error {\n+func (r *ClickHouseReader) PreloadMetricsMetadata(ctx context.Context, orgID valuer.UUID) ([]string, *model.ApiError) {\n \tvar allMetricsMetadata []model.UpdateMetricsMetadata\n-\tvar errorList []error\n+\tvar errorMetricsList []string\n \t// Fetch all rows from ClickHouse\n \tquery := fmt.Sprintf(`SELECT metric_name, type, description , temporality, is_monotonic, unit\n \t\tFROM %s.%s;`, signozMetricDBName, signozUpdatedMetricsMetadataTable)\n \tvalueCtx := context.WithValue(ctx, \"clickhouse_max_threads\", constants.MetricsExplorerClickhouseThreads)\n \terr := r.db.Select(valueCtx, &allMetricsMetadata, query)\n \tif err != nil {\n-\t\terrorList = append(errorList, err)\n-\t\treturn errorList\n+\t\treturn nil, &model.ApiError{Typ: \"ClickHouseError\", Err: fmt.Errorf(\"error in getting updated metadata: %v\", err)}\n \t}\n \tfor _, m := range allMetricsMetadata {\n \t\terr := r.cache.Set(ctx, orgID, constants.UpdatedMetricsMetadataCachePrefix+m.MetricName, &m, -1)\n \t\tif err != nil {\n-\t\t\terrorList = append(errorList, err)\n+\t\t\terrorMetricsList = append(errorMetricsList, m.MetricName)\n \t\t}\n \t}\n \n-\treturn errorList\n+\treturn errorMetricsList, nil\n }\n \n func (r *ClickHouseReader) GetUpdatedMetricsMetadata(ctx context.Context, orgID valuer.UUID, metricNames ...string) (map[string]*model.UpdateMetricsMetadata, *model.ApiError) {\n \tcachedMetadata := make(map[string]*model.UpdateMetricsMetadata)\n \tvar missingMetrics []string\n \n+\tpreCacheLoaded := new(model.CacheLoaded)\n+\terr := r.cache.Get(ctx, orgID, constants.METRICS_UPDATED_METADATA_CACHE_LOADED_KEY, preCacheLoaded, false)",
        "comment_created_at": "2025-06-12T08:50:13+00:00",
        "comment_author": "aniketio-ctrl",
        "comment_body": "To avoid unnecessary calls to ClickHouse for each metric name, we use PreloadMetricsMetadata to load all updated metrics metadata in advance. This way, we can check if a metric name exists in the preloaded metadata and only consider it \"updated\" if it's present\u2014eliminating redundant queries. Since we always cache the metadata whenever it's updated, relying on the cache ensures efficient lookups without repeatedly hitting the database.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1726978050",
    "pr_number": 5743,
    "pr_file": "pkg/web/web.go",
    "created_at": "2024-08-22T12:38:45+00:00",
    "commented_code": "+package web\n+\n+import (\n+\t\"fmt\"\n+\t\"net/http\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"time\"\n+\n+\t\"github.com/gorilla/mux\"\n+\t\"go.signoz.io/signoz/pkg/http/middleware\"\n+\t\"go.uber.org/zap\"\n+)\n+\n+var _ http.Handler = (*Web)(nil)\n+\n+const (\n+\tindexFileName string = \"index.html\"\n+)\n+\n+type Web struct {\n+\tlogger *zap.Logger\n+\tcfg    Config\n+}\n+\n+func New(logger *zap.Logger, cfg Config) (*Web, error) {\n+\tif logger == nil {\n+\t\treturn nil, fmt.Errorf(\"cannot build web, logger is required\")\n+\t}\n+\n+\tfi, err := os.Stat(cfg.Directory)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"cannot access web directory: %w\", err)\n+\t}\n+\n+\tok := fi.IsDir()\n+\tif !ok {\n+\t\treturn nil, fmt.Errorf(\"web directory is not a directory\")\n+\t}\n+\n+\tfi, err = os.Stat(filepath.Join(cfg.Directory, indexFileName))\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"cannot access %q in web directory: %w\", indexFileName, err)\n+\t}\n+\n+\tif os.IsNotExist(err) || fi.IsDir() {\n+\t\treturn nil, fmt.Errorf(\"%q does not exist\", indexFileName)\n+\t}\n+\n+\treturn &Web{\n+\t\tlogger: logger.Named(\"go.signoz.io/pkg/web\"),\n+\t\tcfg:    cfg,\n+\t}, nil\n+}\n+\n+func (web *Web) AddToRouter(router *mux.Router) error {\n+\tcache := middleware.NewCache(7 * 24 * time.Hour)",
    "repo_full_name": "SigNoz/signoz",
    "discussion_comments": [
      {
        "comment_id": "1726978050",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 5743,
        "pr_file": "pkg/web/web.go",
        "discussion_id": "1726978050",
        "commented_code": "@@ -0,0 +1,94 @@\n+package web\n+\n+import (\n+\t\"fmt\"\n+\t\"net/http\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"time\"\n+\n+\t\"github.com/gorilla/mux\"\n+\t\"go.signoz.io/signoz/pkg/http/middleware\"\n+\t\"go.uber.org/zap\"\n+)\n+\n+var _ http.Handler = (*Web)(nil)\n+\n+const (\n+\tindexFileName string = \"index.html\"\n+)\n+\n+type Web struct {\n+\tlogger *zap.Logger\n+\tcfg    Config\n+}\n+\n+func New(logger *zap.Logger, cfg Config) (*Web, error) {\n+\tif logger == nil {\n+\t\treturn nil, fmt.Errorf(\"cannot build web, logger is required\")\n+\t}\n+\n+\tfi, err := os.Stat(cfg.Directory)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"cannot access web directory: %w\", err)\n+\t}\n+\n+\tok := fi.IsDir()\n+\tif !ok {\n+\t\treturn nil, fmt.Errorf(\"web directory is not a directory\")\n+\t}\n+\n+\tfi, err = os.Stat(filepath.Join(cfg.Directory, indexFileName))\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"cannot access %q in web directory: %w\", indexFileName, err)\n+\t}\n+\n+\tif os.IsNotExist(err) || fi.IsDir() {\n+\t\treturn nil, fmt.Errorf(\"%q does not exist\", indexFileName)\n+\t}\n+\n+\treturn &Web{\n+\t\tlogger: logger.Named(\"go.signoz.io/pkg/web\"),\n+\t\tcfg:    cfg,\n+\t}, nil\n+}\n+\n+func (web *Web) AddToRouter(router *mux.Router) error {\n+\tcache := middleware.NewCache(7 * 24 * time.Hour)",
        "comment_created_at": "2024-08-22T12:38:45+00:00",
        "comment_author": "srikanthccv",
        "comment_body": "The `NewCache` reads as if we are maintaining the cache rather than the middleware that controls the cache headers. Can every web asset be cached?",
        "pr_file_module": null
      },
      {
        "comment_id": "1727182845",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 5743,
        "pr_file": "pkg/web/web.go",
        "discussion_id": "1726978050",
        "commented_code": "@@ -0,0 +1,94 @@\n+package web\n+\n+import (\n+\t\"fmt\"\n+\t\"net/http\"\n+\t\"os\"\n+\t\"path/filepath\"\n+\t\"time\"\n+\n+\t\"github.com/gorilla/mux\"\n+\t\"go.signoz.io/signoz/pkg/http/middleware\"\n+\t\"go.uber.org/zap\"\n+)\n+\n+var _ http.Handler = (*Web)(nil)\n+\n+const (\n+\tindexFileName string = \"index.html\"\n+)\n+\n+type Web struct {\n+\tlogger *zap.Logger\n+\tcfg    Config\n+}\n+\n+func New(logger *zap.Logger, cfg Config) (*Web, error) {\n+\tif logger == nil {\n+\t\treturn nil, fmt.Errorf(\"cannot build web, logger is required\")\n+\t}\n+\n+\tfi, err := os.Stat(cfg.Directory)\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"cannot access web directory: %w\", err)\n+\t}\n+\n+\tok := fi.IsDir()\n+\tif !ok {\n+\t\treturn nil, fmt.Errorf(\"web directory is not a directory\")\n+\t}\n+\n+\tfi, err = os.Stat(filepath.Join(cfg.Directory, indexFileName))\n+\tif err != nil {\n+\t\treturn nil, fmt.Errorf(\"cannot access %q in web directory: %w\", indexFileName, err)\n+\t}\n+\n+\tif os.IsNotExist(err) || fi.IsDir() {\n+\t\treturn nil, fmt.Errorf(\"%q does not exist\", indexFileName)\n+\t}\n+\n+\treturn &Web{\n+\t\tlogger: logger.Named(\"go.signoz.io/pkg/web\"),\n+\t\tcfg:    cfg,\n+\t}, nil\n+}\n+\n+func (web *Web) AddToRouter(router *mux.Router) error {\n+\tcache := middleware.NewCache(7 * 24 * time.Hour)",
        "comment_created_at": "2024-08-22T14:35:42+00:00",
        "comment_author": "grandwizard28",
        "comment_body": "Yeah every web asset can be cached. If we were doing SSR, it would not have been possible. A static build does not change once built.\n\nI hope I understood the question correctly!",
        "pr_file_module": null
      }
    ]
  }
]