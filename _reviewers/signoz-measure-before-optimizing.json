[
  {
    "discussion_id": "2307183687",
    "pr_number": 8293,
    "pr_file": "pkg/telemetrytraces/trace_operator_cte_builder.go",
    "created_at": "2025-08-28T11:58:16+00:00",
    "commented_code": "+package telemetrytraces\n+\n+import (\n+\t\"context\"\n+\t\"fmt\"\n+\t\"github.com/SigNoz/signoz/pkg/errors\"\n+\t\"github.com/SigNoz/signoz/pkg/querybuilder\"\n+\tqbtypes \"github.com/SigNoz/signoz/pkg/types/querybuildertypes/querybuildertypesv5\"\n+\t\"github.com/SigNoz/signoz/pkg/types/telemetrytypes\"\n+\t\"github.com/huandu/go-sqlbuilder\"\n+\t\"strings\"\n+)\n+\n+type cteNode struct {\n+\tname      string\n+\tsql       string\n+\targs      []any\n+\tdependsOn []string\n+}\n+\n+type traceOperatorCTEBuilder struct {\n+\tctx            context.Context\n+\tstart          uint64\n+\tend            uint64\n+\toperator       *qbtypes.QueryBuilderTraceOperator\n+\tstmtBuilder    *traceOperatorStatementBuilder\n+\tqueries        map[string]*qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]\n+\tctes           []cteNode\n+\tcteNameToIndex map[string]int\n+\tqueryToCTEName map[string]string\n+\tcompositeQuery *qbtypes.CompositeQuery\n+}\n+\n+func (b *traceOperatorCTEBuilder) collectQueries() error {\n+\treferencedQueries := b.operator.CollectReferencedQueries(b.operator.ParsedExpression)\n+\n+\tfor _, queryEnv := range b.compositeQuery.Queries {\n+\t\tif queryEnv.Type == qbtypes.QueryTypeBuilder {\n+\t\t\tif traceQuery, ok := queryEnv.Spec.(qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]); ok {\n+\t\t\t\tfor _, refName := range referencedQueries {\n+\t\t\t\t\tif traceQuery.Name == refName {\n+\t\t\t\t\t\tqueryCopy := traceQuery\n+\t\t\t\t\t\tb.queries[refName] = &queryCopy\n+\t\t\t\t\t\tbreak\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tfor _, refName := range referencedQueries {\n+\t\tif _, found := b.queries[refName]; !found {\n+\t\t\treturn errors.NewInvalidInputf(errors.CodeInvalidInput, \"referenced query '%s' not found\", refName)\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) build(requestType qbtypes.RequestType) (*qbtypes.Statement, error) {\n+\tif len(b.queries) == 0 {\n+\t\tif err := b.collectQueries(); err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t}\n+\n+\terr := b.buildBaseSpansCTE()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\trootCTEName, err := b.buildExpressionCTEs(b.operator.ParsedExpression)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tselectFromCTE := rootCTEName\n+\tif b.operator.ReturnSpansFrom != \"\" {\n+\t\tselectFromCTE = b.queryToCTEName[b.operator.ReturnSpansFrom]\n+\t\tif selectFromCTE == \"\" {\n+\t\t\treturn nil, errors.NewInvalidInputf(errors.CodeInvalidInput,\n+\t\t\t\t\"returnSpansFrom references query '%s' which has no corresponding CTE\",\n+\t\t\t\tb.operator.ReturnSpansFrom)\n+\t\t}\n+\t}\n+\n+\tfinalStmt, err := b.buildFinalQuery(selectFromCTE, requestType)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tvar cteFragments []string\n+\tvar cteArgs [][]any\n+\n+\ttimeConstantsCTE := b.buildTimeConstantsCTE()\n+\tcteFragments = append(cteFragments, timeConstantsCTE)\n+\n+\tfor _, cte := range b.ctes {\n+\t\tcteFragments = append(cteFragments, fmt.Sprintf(\"%s AS (%s)\", cte.name, cte.sql))\n+\t\tcteArgs = append(cteArgs, cte.args)\n+\t}\n+\n+\tfinalSQL := querybuilder.CombineCTEs(cteFragments) + finalStmt.Query\n+\tfinalArgs := querybuilder.PrependArgs(cteArgs, finalStmt.Args)\n+\n+\treturn &qbtypes.Statement{\n+\t\tQuery:    finalSQL,\n+\t\tArgs:     finalArgs,\n+\t\tWarnings: finalStmt.Warnings,\n+\t}, nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildTimeConstantsCTE() string {\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\n+\treturn fmt.Sprintf(`\n+\t\ttoDateTime64(%d, 9) AS t_from,\n+\t\ttoDateTime64(%d, 9) AS t_to,\n+\t\t%d AS bucket_from,\n+\t\t%d AS bucket_to`,\n+\t\tb.start, b.end, startBucket, endBucket)\n+}\n+\n+// buildBaseSpansCTE\n+func (b *traceOperatorCTEBuilder) buildBaseSpansCTE() error {\n+\tsb := sqlbuilder.NewSelectBuilder()\n+\tsb.Select(\"*\")\n+\t// add a stable alias for downstream consumers\n+\tsb.SelectMore(sqlbuilder.Escape(\"resource_string_service$$name\") + \" AS `service.name`\")\n+\n+\tsb.From(fmt.Sprintf(\"%s.%s\", DBName, SpanIndexV3TableName))\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\tsb.Where(\n+\t\tsb.GE(\"timestamp\", fmt.Sprintf(\"%d\", b.start)),\n+\t\tsb.L(\"timestamp\", fmt.Sprintf(\"%d\", b.end)),\n+\t\tsb.GE(\"ts_bucket_start\", startBucket),\n+\t\tsb.LE(\"ts_bucket_start\", endBucket),\n+\t)\n+\tsql, args := sb.BuildWithFlavor(sqlbuilder.ClickHouse)\n+\tb.addCTE(\"base_spans\", sql, args, nil)\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildExpressionCTEs(expr *qbtypes.TraceOperand) (string, error) {\n+\tif expr == nil {\n+\t\treturn \"\", errors.NewInvalidInputf(errors.CodeInvalidInput, \"expression is nil\")\n+\t}\n+\n+\tif expr.QueryRef != nil {\n+\t\treturn b.buildQueryCTE(expr.QueryRef.Name)\n+\t}\n+\n+\tvar leftCTE, rightCTE string\n+\tvar err error\n+\n+\tif expr.Left != nil {\n+\t\tleftCTE, err = b.buildExpressionCTEs(expr.Left)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\tif expr.Right != nil {\n+\t\trightCTE, err = b.buildExpressionCTEs(expr.Right)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\treturn b.buildOperatorCTE(*expr.Operator, leftCTE, rightCTE)\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildQueryCTE(queryName string) (string, error) {",
    "repo_full_name": "SigNoz/signoz",
    "discussion_comments": [
      {
        "comment_id": "2307183687",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8293,
        "pr_file": "pkg/telemetrytraces/trace_operator_cte_builder.go",
        "discussion_id": "2307183687",
        "commented_code": "@@ -0,0 +1,975 @@\n+package telemetrytraces\n+\n+import (\n+\t\"context\"\n+\t\"fmt\"\n+\t\"github.com/SigNoz/signoz/pkg/errors\"\n+\t\"github.com/SigNoz/signoz/pkg/querybuilder\"\n+\tqbtypes \"github.com/SigNoz/signoz/pkg/types/querybuildertypes/querybuildertypesv5\"\n+\t\"github.com/SigNoz/signoz/pkg/types/telemetrytypes\"\n+\t\"github.com/huandu/go-sqlbuilder\"\n+\t\"strings\"\n+)\n+\n+type cteNode struct {\n+\tname      string\n+\tsql       string\n+\targs      []any\n+\tdependsOn []string\n+}\n+\n+type traceOperatorCTEBuilder struct {\n+\tctx            context.Context\n+\tstart          uint64\n+\tend            uint64\n+\toperator       *qbtypes.QueryBuilderTraceOperator\n+\tstmtBuilder    *traceOperatorStatementBuilder\n+\tqueries        map[string]*qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]\n+\tctes           []cteNode\n+\tcteNameToIndex map[string]int\n+\tqueryToCTEName map[string]string\n+\tcompositeQuery *qbtypes.CompositeQuery\n+}\n+\n+func (b *traceOperatorCTEBuilder) collectQueries() error {\n+\treferencedQueries := b.operator.CollectReferencedQueries(b.operator.ParsedExpression)\n+\n+\tfor _, queryEnv := range b.compositeQuery.Queries {\n+\t\tif queryEnv.Type == qbtypes.QueryTypeBuilder {\n+\t\t\tif traceQuery, ok := queryEnv.Spec.(qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]); ok {\n+\t\t\t\tfor _, refName := range referencedQueries {\n+\t\t\t\t\tif traceQuery.Name == refName {\n+\t\t\t\t\t\tqueryCopy := traceQuery\n+\t\t\t\t\t\tb.queries[refName] = &queryCopy\n+\t\t\t\t\t\tbreak\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tfor _, refName := range referencedQueries {\n+\t\tif _, found := b.queries[refName]; !found {\n+\t\t\treturn errors.NewInvalidInputf(errors.CodeInvalidInput, \"referenced query '%s' not found\", refName)\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) build(requestType qbtypes.RequestType) (*qbtypes.Statement, error) {\n+\tif len(b.queries) == 0 {\n+\t\tif err := b.collectQueries(); err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t}\n+\n+\terr := b.buildBaseSpansCTE()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\trootCTEName, err := b.buildExpressionCTEs(b.operator.ParsedExpression)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tselectFromCTE := rootCTEName\n+\tif b.operator.ReturnSpansFrom != \"\" {\n+\t\tselectFromCTE = b.queryToCTEName[b.operator.ReturnSpansFrom]\n+\t\tif selectFromCTE == \"\" {\n+\t\t\treturn nil, errors.NewInvalidInputf(errors.CodeInvalidInput,\n+\t\t\t\t\"returnSpansFrom references query '%s' which has no corresponding CTE\",\n+\t\t\t\tb.operator.ReturnSpansFrom)\n+\t\t}\n+\t}\n+\n+\tfinalStmt, err := b.buildFinalQuery(selectFromCTE, requestType)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tvar cteFragments []string\n+\tvar cteArgs [][]any\n+\n+\ttimeConstantsCTE := b.buildTimeConstantsCTE()\n+\tcteFragments = append(cteFragments, timeConstantsCTE)\n+\n+\tfor _, cte := range b.ctes {\n+\t\tcteFragments = append(cteFragments, fmt.Sprintf(\"%s AS (%s)\", cte.name, cte.sql))\n+\t\tcteArgs = append(cteArgs, cte.args)\n+\t}\n+\n+\tfinalSQL := querybuilder.CombineCTEs(cteFragments) + finalStmt.Query\n+\tfinalArgs := querybuilder.PrependArgs(cteArgs, finalStmt.Args)\n+\n+\treturn &qbtypes.Statement{\n+\t\tQuery:    finalSQL,\n+\t\tArgs:     finalArgs,\n+\t\tWarnings: finalStmt.Warnings,\n+\t}, nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildTimeConstantsCTE() string {\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\n+\treturn fmt.Sprintf(`\n+\t\ttoDateTime64(%d, 9) AS t_from,\n+\t\ttoDateTime64(%d, 9) AS t_to,\n+\t\t%d AS bucket_from,\n+\t\t%d AS bucket_to`,\n+\t\tb.start, b.end, startBucket, endBucket)\n+}\n+\n+// buildBaseSpansCTE\n+func (b *traceOperatorCTEBuilder) buildBaseSpansCTE() error {\n+\tsb := sqlbuilder.NewSelectBuilder()\n+\tsb.Select(\"*\")\n+\t// add a stable alias for downstream consumers\n+\tsb.SelectMore(sqlbuilder.Escape(\"resource_string_service$$name\") + \" AS `service.name`\")\n+\n+\tsb.From(fmt.Sprintf(\"%s.%s\", DBName, SpanIndexV3TableName))\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\tsb.Where(\n+\t\tsb.GE(\"timestamp\", fmt.Sprintf(\"%d\", b.start)),\n+\t\tsb.L(\"timestamp\", fmt.Sprintf(\"%d\", b.end)),\n+\t\tsb.GE(\"ts_bucket_start\", startBucket),\n+\t\tsb.LE(\"ts_bucket_start\", endBucket),\n+\t)\n+\tsql, args := sb.BuildWithFlavor(sqlbuilder.ClickHouse)\n+\tb.addCTE(\"base_spans\", sql, args, nil)\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildExpressionCTEs(expr *qbtypes.TraceOperand) (string, error) {\n+\tif expr == nil {\n+\t\treturn \"\", errors.NewInvalidInputf(errors.CodeInvalidInput, \"expression is nil\")\n+\t}\n+\n+\tif expr.QueryRef != nil {\n+\t\treturn b.buildQueryCTE(expr.QueryRef.Name)\n+\t}\n+\n+\tvar leftCTE, rightCTE string\n+\tvar err error\n+\n+\tif expr.Left != nil {\n+\t\tleftCTE, err = b.buildExpressionCTEs(expr.Left)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\tif expr.Right != nil {\n+\t\trightCTE, err = b.buildExpressionCTEs(expr.Right)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\treturn b.buildOperatorCTE(*expr.Operator, leftCTE, rightCTE)\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildQueryCTE(queryName string) (string, error) {",
        "comment_created_at": "2025-08-28T11:58:16+00:00",
        "comment_author": "nityanandagohain",
        "comment_body": "I don't see resource filter getting used in these queries, is there a reason of not using it ?",
        "pr_file_module": null
      },
      {
        "comment_id": "2307192885",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8293,
        "pr_file": "pkg/telemetrytraces/trace_operator_cte_builder.go",
        "discussion_id": "2307183687",
        "commented_code": "@@ -0,0 +1,975 @@\n+package telemetrytraces\n+\n+import (\n+\t\"context\"\n+\t\"fmt\"\n+\t\"github.com/SigNoz/signoz/pkg/errors\"\n+\t\"github.com/SigNoz/signoz/pkg/querybuilder\"\n+\tqbtypes \"github.com/SigNoz/signoz/pkg/types/querybuildertypes/querybuildertypesv5\"\n+\t\"github.com/SigNoz/signoz/pkg/types/telemetrytypes\"\n+\t\"github.com/huandu/go-sqlbuilder\"\n+\t\"strings\"\n+)\n+\n+type cteNode struct {\n+\tname      string\n+\tsql       string\n+\targs      []any\n+\tdependsOn []string\n+}\n+\n+type traceOperatorCTEBuilder struct {\n+\tctx            context.Context\n+\tstart          uint64\n+\tend            uint64\n+\toperator       *qbtypes.QueryBuilderTraceOperator\n+\tstmtBuilder    *traceOperatorStatementBuilder\n+\tqueries        map[string]*qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]\n+\tctes           []cteNode\n+\tcteNameToIndex map[string]int\n+\tqueryToCTEName map[string]string\n+\tcompositeQuery *qbtypes.CompositeQuery\n+}\n+\n+func (b *traceOperatorCTEBuilder) collectQueries() error {\n+\treferencedQueries := b.operator.CollectReferencedQueries(b.operator.ParsedExpression)\n+\n+\tfor _, queryEnv := range b.compositeQuery.Queries {\n+\t\tif queryEnv.Type == qbtypes.QueryTypeBuilder {\n+\t\t\tif traceQuery, ok := queryEnv.Spec.(qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]); ok {\n+\t\t\t\tfor _, refName := range referencedQueries {\n+\t\t\t\t\tif traceQuery.Name == refName {\n+\t\t\t\t\t\tqueryCopy := traceQuery\n+\t\t\t\t\t\tb.queries[refName] = &queryCopy\n+\t\t\t\t\t\tbreak\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tfor _, refName := range referencedQueries {\n+\t\tif _, found := b.queries[refName]; !found {\n+\t\t\treturn errors.NewInvalidInputf(errors.CodeInvalidInput, \"referenced query '%s' not found\", refName)\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) build(requestType qbtypes.RequestType) (*qbtypes.Statement, error) {\n+\tif len(b.queries) == 0 {\n+\t\tif err := b.collectQueries(); err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t}\n+\n+\terr := b.buildBaseSpansCTE()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\trootCTEName, err := b.buildExpressionCTEs(b.operator.ParsedExpression)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tselectFromCTE := rootCTEName\n+\tif b.operator.ReturnSpansFrom != \"\" {\n+\t\tselectFromCTE = b.queryToCTEName[b.operator.ReturnSpansFrom]\n+\t\tif selectFromCTE == \"\" {\n+\t\t\treturn nil, errors.NewInvalidInputf(errors.CodeInvalidInput,\n+\t\t\t\t\"returnSpansFrom references query '%s' which has no corresponding CTE\",\n+\t\t\t\tb.operator.ReturnSpansFrom)\n+\t\t}\n+\t}\n+\n+\tfinalStmt, err := b.buildFinalQuery(selectFromCTE, requestType)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tvar cteFragments []string\n+\tvar cteArgs [][]any\n+\n+\ttimeConstantsCTE := b.buildTimeConstantsCTE()\n+\tcteFragments = append(cteFragments, timeConstantsCTE)\n+\n+\tfor _, cte := range b.ctes {\n+\t\tcteFragments = append(cteFragments, fmt.Sprintf(\"%s AS (%s)\", cte.name, cte.sql))\n+\t\tcteArgs = append(cteArgs, cte.args)\n+\t}\n+\n+\tfinalSQL := querybuilder.CombineCTEs(cteFragments) + finalStmt.Query\n+\tfinalArgs := querybuilder.PrependArgs(cteArgs, finalStmt.Args)\n+\n+\treturn &qbtypes.Statement{\n+\t\tQuery:    finalSQL,\n+\t\tArgs:     finalArgs,\n+\t\tWarnings: finalStmt.Warnings,\n+\t}, nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildTimeConstantsCTE() string {\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\n+\treturn fmt.Sprintf(`\n+\t\ttoDateTime64(%d, 9) AS t_from,\n+\t\ttoDateTime64(%d, 9) AS t_to,\n+\t\t%d AS bucket_from,\n+\t\t%d AS bucket_to`,\n+\t\tb.start, b.end, startBucket, endBucket)\n+}\n+\n+// buildBaseSpansCTE\n+func (b *traceOperatorCTEBuilder) buildBaseSpansCTE() error {\n+\tsb := sqlbuilder.NewSelectBuilder()\n+\tsb.Select(\"*\")\n+\t// add a stable alias for downstream consumers\n+\tsb.SelectMore(sqlbuilder.Escape(\"resource_string_service$$name\") + \" AS `service.name`\")\n+\n+\tsb.From(fmt.Sprintf(\"%s.%s\", DBName, SpanIndexV3TableName))\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\tsb.Where(\n+\t\tsb.GE(\"timestamp\", fmt.Sprintf(\"%d\", b.start)),\n+\t\tsb.L(\"timestamp\", fmt.Sprintf(\"%d\", b.end)),\n+\t\tsb.GE(\"ts_bucket_start\", startBucket),\n+\t\tsb.LE(\"ts_bucket_start\", endBucket),\n+\t)\n+\tsql, args := sb.BuildWithFlavor(sqlbuilder.ClickHouse)\n+\tb.addCTE(\"base_spans\", sql, args, nil)\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildExpressionCTEs(expr *qbtypes.TraceOperand) (string, error) {\n+\tif expr == nil {\n+\t\treturn \"\", errors.NewInvalidInputf(errors.CodeInvalidInput, \"expression is nil\")\n+\t}\n+\n+\tif expr.QueryRef != nil {\n+\t\treturn b.buildQueryCTE(expr.QueryRef.Name)\n+\t}\n+\n+\tvar leftCTE, rightCTE string\n+\tvar err error\n+\n+\tif expr.Left != nil {\n+\t\tleftCTE, err = b.buildExpressionCTEs(expr.Left)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\tif expr.Right != nil {\n+\t\trightCTE, err = b.buildExpressionCTEs(expr.Right)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\treturn b.buildOperatorCTE(*expr.Operator, leftCTE, rightCTE)\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildQueryCTE(queryName string) (string, error) {",
        "comment_created_at": "2025-08-28T12:02:18+00:00",
        "comment_author": "eKuG",
        "comment_body": "Ack",
        "pr_file_module": null
      },
      {
        "comment_id": "2314541314",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8293,
        "pr_file": "pkg/telemetrytraces/trace_operator_cte_builder.go",
        "discussion_id": "2307183687",
        "commented_code": "@@ -0,0 +1,975 @@\n+package telemetrytraces\n+\n+import (\n+\t\"context\"\n+\t\"fmt\"\n+\t\"github.com/SigNoz/signoz/pkg/errors\"\n+\t\"github.com/SigNoz/signoz/pkg/querybuilder\"\n+\tqbtypes \"github.com/SigNoz/signoz/pkg/types/querybuildertypes/querybuildertypesv5\"\n+\t\"github.com/SigNoz/signoz/pkg/types/telemetrytypes\"\n+\t\"github.com/huandu/go-sqlbuilder\"\n+\t\"strings\"\n+)\n+\n+type cteNode struct {\n+\tname      string\n+\tsql       string\n+\targs      []any\n+\tdependsOn []string\n+}\n+\n+type traceOperatorCTEBuilder struct {\n+\tctx            context.Context\n+\tstart          uint64\n+\tend            uint64\n+\toperator       *qbtypes.QueryBuilderTraceOperator\n+\tstmtBuilder    *traceOperatorStatementBuilder\n+\tqueries        map[string]*qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]\n+\tctes           []cteNode\n+\tcteNameToIndex map[string]int\n+\tqueryToCTEName map[string]string\n+\tcompositeQuery *qbtypes.CompositeQuery\n+}\n+\n+func (b *traceOperatorCTEBuilder) collectQueries() error {\n+\treferencedQueries := b.operator.CollectReferencedQueries(b.operator.ParsedExpression)\n+\n+\tfor _, queryEnv := range b.compositeQuery.Queries {\n+\t\tif queryEnv.Type == qbtypes.QueryTypeBuilder {\n+\t\t\tif traceQuery, ok := queryEnv.Spec.(qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]); ok {\n+\t\t\t\tfor _, refName := range referencedQueries {\n+\t\t\t\t\tif traceQuery.Name == refName {\n+\t\t\t\t\t\tqueryCopy := traceQuery\n+\t\t\t\t\t\tb.queries[refName] = &queryCopy\n+\t\t\t\t\t\tbreak\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tfor _, refName := range referencedQueries {\n+\t\tif _, found := b.queries[refName]; !found {\n+\t\t\treturn errors.NewInvalidInputf(errors.CodeInvalidInput, \"referenced query '%s' not found\", refName)\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) build(requestType qbtypes.RequestType) (*qbtypes.Statement, error) {\n+\tif len(b.queries) == 0 {\n+\t\tif err := b.collectQueries(); err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t}\n+\n+\terr := b.buildBaseSpansCTE()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\trootCTEName, err := b.buildExpressionCTEs(b.operator.ParsedExpression)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tselectFromCTE := rootCTEName\n+\tif b.operator.ReturnSpansFrom != \"\" {\n+\t\tselectFromCTE = b.queryToCTEName[b.operator.ReturnSpansFrom]\n+\t\tif selectFromCTE == \"\" {\n+\t\t\treturn nil, errors.NewInvalidInputf(errors.CodeInvalidInput,\n+\t\t\t\t\"returnSpansFrom references query '%s' which has no corresponding CTE\",\n+\t\t\t\tb.operator.ReturnSpansFrom)\n+\t\t}\n+\t}\n+\n+\tfinalStmt, err := b.buildFinalQuery(selectFromCTE, requestType)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tvar cteFragments []string\n+\tvar cteArgs [][]any\n+\n+\ttimeConstantsCTE := b.buildTimeConstantsCTE()\n+\tcteFragments = append(cteFragments, timeConstantsCTE)\n+\n+\tfor _, cte := range b.ctes {\n+\t\tcteFragments = append(cteFragments, fmt.Sprintf(\"%s AS (%s)\", cte.name, cte.sql))\n+\t\tcteArgs = append(cteArgs, cte.args)\n+\t}\n+\n+\tfinalSQL := querybuilder.CombineCTEs(cteFragments) + finalStmt.Query\n+\tfinalArgs := querybuilder.PrependArgs(cteArgs, finalStmt.Args)\n+\n+\treturn &qbtypes.Statement{\n+\t\tQuery:    finalSQL,\n+\t\tArgs:     finalArgs,\n+\t\tWarnings: finalStmt.Warnings,\n+\t}, nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildTimeConstantsCTE() string {\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\n+\treturn fmt.Sprintf(`\n+\t\ttoDateTime64(%d, 9) AS t_from,\n+\t\ttoDateTime64(%d, 9) AS t_to,\n+\t\t%d AS bucket_from,\n+\t\t%d AS bucket_to`,\n+\t\tb.start, b.end, startBucket, endBucket)\n+}\n+\n+// buildBaseSpansCTE\n+func (b *traceOperatorCTEBuilder) buildBaseSpansCTE() error {\n+\tsb := sqlbuilder.NewSelectBuilder()\n+\tsb.Select(\"*\")\n+\t// add a stable alias for downstream consumers\n+\tsb.SelectMore(sqlbuilder.Escape(\"resource_string_service$$name\") + \" AS `service.name`\")\n+\n+\tsb.From(fmt.Sprintf(\"%s.%s\", DBName, SpanIndexV3TableName))\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\tsb.Where(\n+\t\tsb.GE(\"timestamp\", fmt.Sprintf(\"%d\", b.start)),\n+\t\tsb.L(\"timestamp\", fmt.Sprintf(\"%d\", b.end)),\n+\t\tsb.GE(\"ts_bucket_start\", startBucket),\n+\t\tsb.LE(\"ts_bucket_start\", endBucket),\n+\t)\n+\tsql, args := sb.BuildWithFlavor(sqlbuilder.ClickHouse)\n+\tb.addCTE(\"base_spans\", sql, args, nil)\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildExpressionCTEs(expr *qbtypes.TraceOperand) (string, error) {\n+\tif expr == nil {\n+\t\treturn \"\", errors.NewInvalidInputf(errors.CodeInvalidInput, \"expression is nil\")\n+\t}\n+\n+\tif expr.QueryRef != nil {\n+\t\treturn b.buildQueryCTE(expr.QueryRef.Name)\n+\t}\n+\n+\tvar leftCTE, rightCTE string\n+\tvar err error\n+\n+\tif expr.Left != nil {\n+\t\tleftCTE, err = b.buildExpressionCTEs(expr.Left)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\tif expr.Right != nil {\n+\t\trightCTE, err = b.buildExpressionCTEs(expr.Right)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\treturn b.buildOperatorCTE(*expr.Operator, leftCTE, rightCTE)\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildQueryCTE(queryName string) (string, error) {",
        "comment_created_at": "2025-09-01T20:25:57+00:00",
        "comment_author": "eKuG",
        "comment_body": "We do not use resource filters in trace operators because incorporating them significantly increases query complexity when leveraging the existing statement_builder in QBV5. In the current setup, only a single query is typically executed, which keeps the query structure straightforward. However, in trace operators, multiple queries with multiple filters are involved, requiring frequent use of OR clauses in the base CTE.\r\n\r\n```\r\n WITH \r\n                toDateTime64(1756152030000000000, 9) AS t_from,\r\n                toDateTime64(1756756830000000000, 9) AS t_to,\r\n                1756150230 AS bucket_from,\r\n                1756756830 AS bucket_to, __resource_filter AS (SELECT fingerprint FROM signoz_traces.distributed_traces_v3_resource WHERE ((simpleJSONExtractString(labels, 'service.name') = ? OR simpleJSONExtractString(labels, 'service.name') = ?) AND labels LIKE ? AND (labels LIKE ? OR labels LIKE ?)) AND seen_at_ts_bucket_start >= ? AND seen_at_ts_bucket_start <= ?), base_spans AS (SELECT *, resource_string_service$$name AS `service.name` FROM signoz_traces.distributed_signoz_index_v3 WHERE resource_fingerprint GLOBAL IN (SELECT fingerprint FROM __resource_filter) AND timestamp >= ? AND timestamp < ? AND ts_bucket_start >= ? AND ts_bucket_start <= ?), A AS (SELECT *, 'A' AS level FROM base_spans AS s WHERE (parent_span_id = '')), B AS (SELECT *, 'B' AS level FROM base_spans AS s WHERE true), A_INDIR_DESC_B AS (\r\n                WITH RECURSIVE up AS (\r\n                        SELECT\r\n                                d.trace_id,\r\n                                d.span_id,\r\n                                d.parent_span_id,\r\n                                0 AS depth\r\n                        FROM B AS d\r\n                        \r\n                        UNION ALL\r\n                        \r\n                        SELECT\r\n                                p.trace_id,\r\n                                p.span_id,\r\n                                p.parent_span_id,\r\n                                up.depth + 1\r\n                        FROM base_spans AS p\r\n                        JOIN up ON p.trace_id = up.trace_id AND p.span_id = up.parent_span_id\r\n                        WHERE up.depth < 100\r\n                )\r\n                SELECT DISTINCT a.*\r\n                FROM A AS a\r\n                GLOBAL INNER JOIN (\r\n                        SELECT DISTINCT trace_id, span_id\r\n                        FROM up\r\n                        WHERE depth > 0\r\n                ) AS ancestors ON ancestors.trace_id = a.trace_id AND ancestors.span_id = a.span_id\r\n        ) SELECT timestamp, trace_id, span_id, name, duration_nano, parent_span_id FROM A_INDIR_DESC_B ORDER BY timestamp DESC LIMIT ?\r\nArgs: [frontend redis-manual %service.name% %service.name\":\"frontend% %service.name\":\"redis-manual% 1756150230 1756756830 1756152030000000000 1756756830000000000 1756150230 1756756830 10]\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2314968540",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8293,
        "pr_file": "pkg/telemetrytraces/trace_operator_cte_builder.go",
        "discussion_id": "2307183687",
        "commented_code": "@@ -0,0 +1,975 @@\n+package telemetrytraces\n+\n+import (\n+\t\"context\"\n+\t\"fmt\"\n+\t\"github.com/SigNoz/signoz/pkg/errors\"\n+\t\"github.com/SigNoz/signoz/pkg/querybuilder\"\n+\tqbtypes \"github.com/SigNoz/signoz/pkg/types/querybuildertypes/querybuildertypesv5\"\n+\t\"github.com/SigNoz/signoz/pkg/types/telemetrytypes\"\n+\t\"github.com/huandu/go-sqlbuilder\"\n+\t\"strings\"\n+)\n+\n+type cteNode struct {\n+\tname      string\n+\tsql       string\n+\targs      []any\n+\tdependsOn []string\n+}\n+\n+type traceOperatorCTEBuilder struct {\n+\tctx            context.Context\n+\tstart          uint64\n+\tend            uint64\n+\toperator       *qbtypes.QueryBuilderTraceOperator\n+\tstmtBuilder    *traceOperatorStatementBuilder\n+\tqueries        map[string]*qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]\n+\tctes           []cteNode\n+\tcteNameToIndex map[string]int\n+\tqueryToCTEName map[string]string\n+\tcompositeQuery *qbtypes.CompositeQuery\n+}\n+\n+func (b *traceOperatorCTEBuilder) collectQueries() error {\n+\treferencedQueries := b.operator.CollectReferencedQueries(b.operator.ParsedExpression)\n+\n+\tfor _, queryEnv := range b.compositeQuery.Queries {\n+\t\tif queryEnv.Type == qbtypes.QueryTypeBuilder {\n+\t\t\tif traceQuery, ok := queryEnv.Spec.(qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]); ok {\n+\t\t\t\tfor _, refName := range referencedQueries {\n+\t\t\t\t\tif traceQuery.Name == refName {\n+\t\t\t\t\t\tqueryCopy := traceQuery\n+\t\t\t\t\t\tb.queries[refName] = &queryCopy\n+\t\t\t\t\t\tbreak\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tfor _, refName := range referencedQueries {\n+\t\tif _, found := b.queries[refName]; !found {\n+\t\t\treturn errors.NewInvalidInputf(errors.CodeInvalidInput, \"referenced query '%s' not found\", refName)\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) build(requestType qbtypes.RequestType) (*qbtypes.Statement, error) {\n+\tif len(b.queries) == 0 {\n+\t\tif err := b.collectQueries(); err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t}\n+\n+\terr := b.buildBaseSpansCTE()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\trootCTEName, err := b.buildExpressionCTEs(b.operator.ParsedExpression)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tselectFromCTE := rootCTEName\n+\tif b.operator.ReturnSpansFrom != \"\" {\n+\t\tselectFromCTE = b.queryToCTEName[b.operator.ReturnSpansFrom]\n+\t\tif selectFromCTE == \"\" {\n+\t\t\treturn nil, errors.NewInvalidInputf(errors.CodeInvalidInput,\n+\t\t\t\t\"returnSpansFrom references query '%s' which has no corresponding CTE\",\n+\t\t\t\tb.operator.ReturnSpansFrom)\n+\t\t}\n+\t}\n+\n+\tfinalStmt, err := b.buildFinalQuery(selectFromCTE, requestType)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tvar cteFragments []string\n+\tvar cteArgs [][]any\n+\n+\ttimeConstantsCTE := b.buildTimeConstantsCTE()\n+\tcteFragments = append(cteFragments, timeConstantsCTE)\n+\n+\tfor _, cte := range b.ctes {\n+\t\tcteFragments = append(cteFragments, fmt.Sprintf(\"%s AS (%s)\", cte.name, cte.sql))\n+\t\tcteArgs = append(cteArgs, cte.args)\n+\t}\n+\n+\tfinalSQL := querybuilder.CombineCTEs(cteFragments) + finalStmt.Query\n+\tfinalArgs := querybuilder.PrependArgs(cteArgs, finalStmt.Args)\n+\n+\treturn &qbtypes.Statement{\n+\t\tQuery:    finalSQL,\n+\t\tArgs:     finalArgs,\n+\t\tWarnings: finalStmt.Warnings,\n+\t}, nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildTimeConstantsCTE() string {\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\n+\treturn fmt.Sprintf(`\n+\t\ttoDateTime64(%d, 9) AS t_from,\n+\t\ttoDateTime64(%d, 9) AS t_to,\n+\t\t%d AS bucket_from,\n+\t\t%d AS bucket_to`,\n+\t\tb.start, b.end, startBucket, endBucket)\n+}\n+\n+// buildBaseSpansCTE\n+func (b *traceOperatorCTEBuilder) buildBaseSpansCTE() error {\n+\tsb := sqlbuilder.NewSelectBuilder()\n+\tsb.Select(\"*\")\n+\t// add a stable alias for downstream consumers\n+\tsb.SelectMore(sqlbuilder.Escape(\"resource_string_service$$name\") + \" AS `service.name`\")\n+\n+\tsb.From(fmt.Sprintf(\"%s.%s\", DBName, SpanIndexV3TableName))\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\tsb.Where(\n+\t\tsb.GE(\"timestamp\", fmt.Sprintf(\"%d\", b.start)),\n+\t\tsb.L(\"timestamp\", fmt.Sprintf(\"%d\", b.end)),\n+\t\tsb.GE(\"ts_bucket_start\", startBucket),\n+\t\tsb.LE(\"ts_bucket_start\", endBucket),\n+\t)\n+\tsql, args := sb.BuildWithFlavor(sqlbuilder.ClickHouse)\n+\tb.addCTE(\"base_spans\", sql, args, nil)\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildExpressionCTEs(expr *qbtypes.TraceOperand) (string, error) {\n+\tif expr == nil {\n+\t\treturn \"\", errors.NewInvalidInputf(errors.CodeInvalidInput, \"expression is nil\")\n+\t}\n+\n+\tif expr.QueryRef != nil {\n+\t\treturn b.buildQueryCTE(expr.QueryRef.Name)\n+\t}\n+\n+\tvar leftCTE, rightCTE string\n+\tvar err error\n+\n+\tif expr.Left != nil {\n+\t\tleftCTE, err = b.buildExpressionCTEs(expr.Left)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\tif expr.Right != nil {\n+\t\trightCTE, err = b.buildExpressionCTEs(expr.Right)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\treturn b.buildOperatorCTE(*expr.Operator, leftCTE, rightCTE)\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildQueryCTE(queryName string) (string, error) {",
        "comment_created_at": "2025-09-02T05:44:13+00:00",
        "comment_author": "nityanandagohain",
        "comment_body": ">We do not use resource filters in trace operators because incorporating them significantly increases query complexity when leveraging the existing statement_builder in QBV5\r\n\r\nDon't think this is a valid argument, can you check what will be the perf difference if we don't use it ?",
        "pr_file_module": null
      },
      {
        "comment_id": "2314970513",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8293,
        "pr_file": "pkg/telemetrytraces/trace_operator_cte_builder.go",
        "discussion_id": "2307183687",
        "commented_code": "@@ -0,0 +1,975 @@\n+package telemetrytraces\n+\n+import (\n+\t\"context\"\n+\t\"fmt\"\n+\t\"github.com/SigNoz/signoz/pkg/errors\"\n+\t\"github.com/SigNoz/signoz/pkg/querybuilder\"\n+\tqbtypes \"github.com/SigNoz/signoz/pkg/types/querybuildertypes/querybuildertypesv5\"\n+\t\"github.com/SigNoz/signoz/pkg/types/telemetrytypes\"\n+\t\"github.com/huandu/go-sqlbuilder\"\n+\t\"strings\"\n+)\n+\n+type cteNode struct {\n+\tname      string\n+\tsql       string\n+\targs      []any\n+\tdependsOn []string\n+}\n+\n+type traceOperatorCTEBuilder struct {\n+\tctx            context.Context\n+\tstart          uint64\n+\tend            uint64\n+\toperator       *qbtypes.QueryBuilderTraceOperator\n+\tstmtBuilder    *traceOperatorStatementBuilder\n+\tqueries        map[string]*qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]\n+\tctes           []cteNode\n+\tcteNameToIndex map[string]int\n+\tqueryToCTEName map[string]string\n+\tcompositeQuery *qbtypes.CompositeQuery\n+}\n+\n+func (b *traceOperatorCTEBuilder) collectQueries() error {\n+\treferencedQueries := b.operator.CollectReferencedQueries(b.operator.ParsedExpression)\n+\n+\tfor _, queryEnv := range b.compositeQuery.Queries {\n+\t\tif queryEnv.Type == qbtypes.QueryTypeBuilder {\n+\t\t\tif traceQuery, ok := queryEnv.Spec.(qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]); ok {\n+\t\t\t\tfor _, refName := range referencedQueries {\n+\t\t\t\t\tif traceQuery.Name == refName {\n+\t\t\t\t\t\tqueryCopy := traceQuery\n+\t\t\t\t\t\tb.queries[refName] = &queryCopy\n+\t\t\t\t\t\tbreak\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tfor _, refName := range referencedQueries {\n+\t\tif _, found := b.queries[refName]; !found {\n+\t\t\treturn errors.NewInvalidInputf(errors.CodeInvalidInput, \"referenced query '%s' not found\", refName)\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) build(requestType qbtypes.RequestType) (*qbtypes.Statement, error) {\n+\tif len(b.queries) == 0 {\n+\t\tif err := b.collectQueries(); err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t}\n+\n+\terr := b.buildBaseSpansCTE()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\trootCTEName, err := b.buildExpressionCTEs(b.operator.ParsedExpression)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tselectFromCTE := rootCTEName\n+\tif b.operator.ReturnSpansFrom != \"\" {\n+\t\tselectFromCTE = b.queryToCTEName[b.operator.ReturnSpansFrom]\n+\t\tif selectFromCTE == \"\" {\n+\t\t\treturn nil, errors.NewInvalidInputf(errors.CodeInvalidInput,\n+\t\t\t\t\"returnSpansFrom references query '%s' which has no corresponding CTE\",\n+\t\t\t\tb.operator.ReturnSpansFrom)\n+\t\t}\n+\t}\n+\n+\tfinalStmt, err := b.buildFinalQuery(selectFromCTE, requestType)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tvar cteFragments []string\n+\tvar cteArgs [][]any\n+\n+\ttimeConstantsCTE := b.buildTimeConstantsCTE()\n+\tcteFragments = append(cteFragments, timeConstantsCTE)\n+\n+\tfor _, cte := range b.ctes {\n+\t\tcteFragments = append(cteFragments, fmt.Sprintf(\"%s AS (%s)\", cte.name, cte.sql))\n+\t\tcteArgs = append(cteArgs, cte.args)\n+\t}\n+\n+\tfinalSQL := querybuilder.CombineCTEs(cteFragments) + finalStmt.Query\n+\tfinalArgs := querybuilder.PrependArgs(cteArgs, finalStmt.Args)\n+\n+\treturn &qbtypes.Statement{\n+\t\tQuery:    finalSQL,\n+\t\tArgs:     finalArgs,\n+\t\tWarnings: finalStmt.Warnings,\n+\t}, nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildTimeConstantsCTE() string {\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\n+\treturn fmt.Sprintf(`\n+\t\ttoDateTime64(%d, 9) AS t_from,\n+\t\ttoDateTime64(%d, 9) AS t_to,\n+\t\t%d AS bucket_from,\n+\t\t%d AS bucket_to`,\n+\t\tb.start, b.end, startBucket, endBucket)\n+}\n+\n+// buildBaseSpansCTE\n+func (b *traceOperatorCTEBuilder) buildBaseSpansCTE() error {\n+\tsb := sqlbuilder.NewSelectBuilder()\n+\tsb.Select(\"*\")\n+\t// add a stable alias for downstream consumers\n+\tsb.SelectMore(sqlbuilder.Escape(\"resource_string_service$$name\") + \" AS `service.name`\")\n+\n+\tsb.From(fmt.Sprintf(\"%s.%s\", DBName, SpanIndexV3TableName))\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\tsb.Where(\n+\t\tsb.GE(\"timestamp\", fmt.Sprintf(\"%d\", b.start)),\n+\t\tsb.L(\"timestamp\", fmt.Sprintf(\"%d\", b.end)),\n+\t\tsb.GE(\"ts_bucket_start\", startBucket),\n+\t\tsb.LE(\"ts_bucket_start\", endBucket),\n+\t)\n+\tsql, args := sb.BuildWithFlavor(sqlbuilder.ClickHouse)\n+\tb.addCTE(\"base_spans\", sql, args, nil)\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildExpressionCTEs(expr *qbtypes.TraceOperand) (string, error) {\n+\tif expr == nil {\n+\t\treturn \"\", errors.NewInvalidInputf(errors.CodeInvalidInput, \"expression is nil\")\n+\t}\n+\n+\tif expr.QueryRef != nil {\n+\t\treturn b.buildQueryCTE(expr.QueryRef.Name)\n+\t}\n+\n+\tvar leftCTE, rightCTE string\n+\tvar err error\n+\n+\tif expr.Left != nil {\n+\t\tleftCTE, err = b.buildExpressionCTEs(expr.Left)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\tif expr.Right != nil {\n+\t\trightCTE, err = b.buildExpressionCTEs(expr.Right)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\treturn b.buildOperatorCTE(*expr.Operator, leftCTE, rightCTE)\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildQueryCTE(queryName string) (string, error) {",
        "comment_created_at": "2025-09-02T05:45:42+00:00",
        "comment_author": "eKuG",
        "comment_body": "I have checked the perf numbers between the 2 queries. I'll share the performance numbers for the same",
        "pr_file_module": null
      },
      {
        "comment_id": "2317957653",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8293,
        "pr_file": "pkg/telemetrytraces/trace_operator_cte_builder.go",
        "discussion_id": "2307183687",
        "commented_code": "@@ -0,0 +1,975 @@\n+package telemetrytraces\n+\n+import (\n+\t\"context\"\n+\t\"fmt\"\n+\t\"github.com/SigNoz/signoz/pkg/errors\"\n+\t\"github.com/SigNoz/signoz/pkg/querybuilder\"\n+\tqbtypes \"github.com/SigNoz/signoz/pkg/types/querybuildertypes/querybuildertypesv5\"\n+\t\"github.com/SigNoz/signoz/pkg/types/telemetrytypes\"\n+\t\"github.com/huandu/go-sqlbuilder\"\n+\t\"strings\"\n+)\n+\n+type cteNode struct {\n+\tname      string\n+\tsql       string\n+\targs      []any\n+\tdependsOn []string\n+}\n+\n+type traceOperatorCTEBuilder struct {\n+\tctx            context.Context\n+\tstart          uint64\n+\tend            uint64\n+\toperator       *qbtypes.QueryBuilderTraceOperator\n+\tstmtBuilder    *traceOperatorStatementBuilder\n+\tqueries        map[string]*qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]\n+\tctes           []cteNode\n+\tcteNameToIndex map[string]int\n+\tqueryToCTEName map[string]string\n+\tcompositeQuery *qbtypes.CompositeQuery\n+}\n+\n+func (b *traceOperatorCTEBuilder) collectQueries() error {\n+\treferencedQueries := b.operator.CollectReferencedQueries(b.operator.ParsedExpression)\n+\n+\tfor _, queryEnv := range b.compositeQuery.Queries {\n+\t\tif queryEnv.Type == qbtypes.QueryTypeBuilder {\n+\t\t\tif traceQuery, ok := queryEnv.Spec.(qbtypes.QueryBuilderQuery[qbtypes.TraceAggregation]); ok {\n+\t\t\t\tfor _, refName := range referencedQueries {\n+\t\t\t\t\tif traceQuery.Name == refName {\n+\t\t\t\t\t\tqueryCopy := traceQuery\n+\t\t\t\t\t\tb.queries[refName] = &queryCopy\n+\t\t\t\t\t\tbreak\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t}\n+\n+\tfor _, refName := range referencedQueries {\n+\t\tif _, found := b.queries[refName]; !found {\n+\t\t\treturn errors.NewInvalidInputf(errors.CodeInvalidInput, \"referenced query '%s' not found\", refName)\n+\t\t}\n+\t}\n+\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) build(requestType qbtypes.RequestType) (*qbtypes.Statement, error) {\n+\tif len(b.queries) == 0 {\n+\t\tif err := b.collectQueries(); err != nil {\n+\t\t\treturn nil, err\n+\t\t}\n+\t}\n+\n+\terr := b.buildBaseSpansCTE()\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\trootCTEName, err := b.buildExpressionCTEs(b.operator.ParsedExpression)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tselectFromCTE := rootCTEName\n+\tif b.operator.ReturnSpansFrom != \"\" {\n+\t\tselectFromCTE = b.queryToCTEName[b.operator.ReturnSpansFrom]\n+\t\tif selectFromCTE == \"\" {\n+\t\t\treturn nil, errors.NewInvalidInputf(errors.CodeInvalidInput,\n+\t\t\t\t\"returnSpansFrom references query '%s' which has no corresponding CTE\",\n+\t\t\t\tb.operator.ReturnSpansFrom)\n+\t\t}\n+\t}\n+\n+\tfinalStmt, err := b.buildFinalQuery(selectFromCTE, requestType)\n+\tif err != nil {\n+\t\treturn nil, err\n+\t}\n+\n+\tvar cteFragments []string\n+\tvar cteArgs [][]any\n+\n+\ttimeConstantsCTE := b.buildTimeConstantsCTE()\n+\tcteFragments = append(cteFragments, timeConstantsCTE)\n+\n+\tfor _, cte := range b.ctes {\n+\t\tcteFragments = append(cteFragments, fmt.Sprintf(\"%s AS (%s)\", cte.name, cte.sql))\n+\t\tcteArgs = append(cteArgs, cte.args)\n+\t}\n+\n+\tfinalSQL := querybuilder.CombineCTEs(cteFragments) + finalStmt.Query\n+\tfinalArgs := querybuilder.PrependArgs(cteArgs, finalStmt.Args)\n+\n+\treturn &qbtypes.Statement{\n+\t\tQuery:    finalSQL,\n+\t\tArgs:     finalArgs,\n+\t\tWarnings: finalStmt.Warnings,\n+\t}, nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildTimeConstantsCTE() string {\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\n+\treturn fmt.Sprintf(`\n+\t\ttoDateTime64(%d, 9) AS t_from,\n+\t\ttoDateTime64(%d, 9) AS t_to,\n+\t\t%d AS bucket_from,\n+\t\t%d AS bucket_to`,\n+\t\tb.start, b.end, startBucket, endBucket)\n+}\n+\n+// buildBaseSpansCTE\n+func (b *traceOperatorCTEBuilder) buildBaseSpansCTE() error {\n+\tsb := sqlbuilder.NewSelectBuilder()\n+\tsb.Select(\"*\")\n+\t// add a stable alias for downstream consumers\n+\tsb.SelectMore(sqlbuilder.Escape(\"resource_string_service$$name\") + \" AS `service.name`\")\n+\n+\tsb.From(fmt.Sprintf(\"%s.%s\", DBName, SpanIndexV3TableName))\n+\tstartBucket := b.start/querybuilder.NsToSeconds - querybuilder.BucketAdjustment\n+\tendBucket := b.end / querybuilder.NsToSeconds\n+\tsb.Where(\n+\t\tsb.GE(\"timestamp\", fmt.Sprintf(\"%d\", b.start)),\n+\t\tsb.L(\"timestamp\", fmt.Sprintf(\"%d\", b.end)),\n+\t\tsb.GE(\"ts_bucket_start\", startBucket),\n+\t\tsb.LE(\"ts_bucket_start\", endBucket),\n+\t)\n+\tsql, args := sb.BuildWithFlavor(sqlbuilder.ClickHouse)\n+\tb.addCTE(\"base_spans\", sql, args, nil)\n+\treturn nil\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildExpressionCTEs(expr *qbtypes.TraceOperand) (string, error) {\n+\tif expr == nil {\n+\t\treturn \"\", errors.NewInvalidInputf(errors.CodeInvalidInput, \"expression is nil\")\n+\t}\n+\n+\tif expr.QueryRef != nil {\n+\t\treturn b.buildQueryCTE(expr.QueryRef.Name)\n+\t}\n+\n+\tvar leftCTE, rightCTE string\n+\tvar err error\n+\n+\tif expr.Left != nil {\n+\t\tleftCTE, err = b.buildExpressionCTEs(expr.Left)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\tif expr.Right != nil {\n+\t\trightCTE, err = b.buildExpressionCTEs(expr.Right)\n+\t\tif err != nil {\n+\t\t\treturn \"\", err\n+\t\t}\n+\t}\n+\n+\treturn b.buildOperatorCTE(*expr.Operator, leftCTE, rightCTE)\n+}\n+\n+func (b *traceOperatorCTEBuilder) buildQueryCTE(queryName string) (string, error) {",
        "comment_created_at": "2025-09-03T06:57:26+00:00",
        "comment_author": "eKuG",
        "comment_body": "I have added resource filters to the CTEs",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2206806623",
    "pr_number": 8518,
    "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
    "created_at": "2025-07-15T08:19:50+00:00",
    "commented_code": "return &searchSpansResult, nil\n }\n+\n+func (r *ClickHouseReader) GetCorrespondingNormalizedMetrics(ctx context.Context, orgID valuer.UUID) (map[string]string, error) {\n+\t// sanitize removes all non-alphanumeric characters from s\n+\tsanitize := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapRegex.ReplaceAllString(s, \"\")\n+\t}\n+\n+\t// Try cache first\n+\tresultDto := new(model.NormalizedMetricsMap)\n+\tcacheKey := constants.NormalizedMetricsMapCacheKey\n+\n+\tif err := r.cache.Get(ctx, orgID, cacheKey, resultDto, true); err == nil {\n+\t\treturn resultDto.MetricsMap, nil\n+\t}\n+\n+\tvalueCtx := context.WithValue(ctx, \"clickhouse_max_threads\", constants.NormalizedMetricsMapQueryThreads)\n+\tquery := \"SELECT DISTINCT metric_name, type, toUInt8(__normalized) FROM %s.%s\"",
    "repo_full_name": "SigNoz/signoz",
    "discussion_comments": [
      {
        "comment_id": "2206806623",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8518,
        "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
        "discussion_id": "2206806623",
        "commented_code": "@@ -6046,3 +6046,86 @@ func (r *ClickHouseReader) SearchTraces(ctx context.Context, params *model.Searc\n \n \treturn &searchSpansResult, nil\n }\n+\n+func (r *ClickHouseReader) GetCorrespondingNormalizedMetrics(ctx context.Context, orgID valuer.UUID) (map[string]string, error) {\n+\t// sanitize removes all non-alphanumeric characters from s\n+\tsanitize := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapRegex.ReplaceAllString(s, \"\")\n+\t}\n+\n+\t// Try cache first\n+\tresultDto := new(model.NormalizedMetricsMap)\n+\tcacheKey := constants.NormalizedMetricsMapCacheKey\n+\n+\tif err := r.cache.Get(ctx, orgID, cacheKey, resultDto, true); err == nil {\n+\t\treturn resultDto.MetricsMap, nil\n+\t}\n+\n+\tvalueCtx := context.WithValue(ctx, \"clickhouse_max_threads\", constants.NormalizedMetricsMapQueryThreads)\n+\tquery := \"SELECT DISTINCT metric_name, type, toUInt8(__normalized) FROM %s.%s\"",
        "comment_created_at": "2025-07-15T08:19:50+00:00",
        "comment_author": "srikanthccv",
        "comment_body": "Why are we loading all the metrics into cache regardless of whether they are used or not?",
        "pr_file_module": null
      },
      {
        "comment_id": "2206859850",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8518,
        "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
        "discussion_id": "2206806623",
        "commented_code": "@@ -6046,3 +6046,86 @@ func (r *ClickHouseReader) SearchTraces(ctx context.Context, params *model.Searc\n \n \treturn &searchSpansResult, nil\n }\n+\n+func (r *ClickHouseReader) GetCorrespondingNormalizedMetrics(ctx context.Context, orgID valuer.UUID) (map[string]string, error) {\n+\t// sanitize removes all non-alphanumeric characters from s\n+\tsanitize := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapRegex.ReplaceAllString(s, \"\")\n+\t}\n+\n+\t// Try cache first\n+\tresultDto := new(model.NormalizedMetricsMap)\n+\tcacheKey := constants.NormalizedMetricsMapCacheKey\n+\n+\tif err := r.cache.Get(ctx, orgID, cacheKey, resultDto, true); err == nil {\n+\t\treturn resultDto.MetricsMap, nil\n+\t}\n+\n+\tvalueCtx := context.WithValue(ctx, \"clickhouse_max_threads\", constants.NormalizedMetricsMapQueryThreads)\n+\tquery := \"SELECT DISTINCT metric_name, type, toUInt8(__normalized) FROM %s.%s\"",
        "comment_created_at": "2025-07-15T08:42:32+00:00",
        "comment_author": "aniketio-ctrl",
        "comment_body": "to create a map instead of calling every time in query-service, we can load all at once, for a user metrics wont be more than 1000, so it would be much better to store all at once\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2206928059",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8518,
        "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
        "discussion_id": "2206806623",
        "commented_code": "@@ -6046,3 +6046,86 @@ func (r *ClickHouseReader) SearchTraces(ctx context.Context, params *model.Searc\n \n \treturn &searchSpansResult, nil\n }\n+\n+func (r *ClickHouseReader) GetCorrespondingNormalizedMetrics(ctx context.Context, orgID valuer.UUID) (map[string]string, error) {\n+\t// sanitize removes all non-alphanumeric characters from s\n+\tsanitize := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapRegex.ReplaceAllString(s, \"\")\n+\t}\n+\n+\t// Try cache first\n+\tresultDto := new(model.NormalizedMetricsMap)\n+\tcacheKey := constants.NormalizedMetricsMapCacheKey\n+\n+\tif err := r.cache.Get(ctx, orgID, cacheKey, resultDto, true); err == nil {\n+\t\treturn resultDto.MetricsMap, nil\n+\t}\n+\n+\tvalueCtx := context.WithValue(ctx, \"clickhouse_max_threads\", constants.NormalizedMetricsMapQueryThreads)\n+\tquery := \"SELECT DISTINCT metric_name, type, toUInt8(__normalized) FROM %s.%s\"",
        "comment_created_at": "2025-07-15T09:08:36+00:00",
        "comment_author": "srikanthccv",
        "comment_body": "Many users have ~5k metrics in total, and some even more. We are going to load them all into memory (because we are using memory cache, even though very few of the metrics are used.",
        "pr_file_module": null
      },
      {
        "comment_id": "2207007037",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8518,
        "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
        "discussion_id": "2206806623",
        "commented_code": "@@ -6046,3 +6046,86 @@ func (r *ClickHouseReader) SearchTraces(ctx context.Context, params *model.Searc\n \n \treturn &searchSpansResult, nil\n }\n+\n+func (r *ClickHouseReader) GetCorrespondingNormalizedMetrics(ctx context.Context, orgID valuer.UUID) (map[string]string, error) {\n+\t// sanitize removes all non-alphanumeric characters from s\n+\tsanitize := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapRegex.ReplaceAllString(s, \"\")\n+\t}\n+\n+\t// Try cache first\n+\tresultDto := new(model.NormalizedMetricsMap)\n+\tcacheKey := constants.NormalizedMetricsMapCacheKey\n+\n+\tif err := r.cache.Get(ctx, orgID, cacheKey, resultDto, true); err == nil {\n+\t\treturn resultDto.MetricsMap, nil\n+\t}\n+\n+\tvalueCtx := context.WithValue(ctx, \"clickhouse_max_threads\", constants.NormalizedMetricsMapQueryThreads)\n+\tquery := \"SELECT DISTINCT metric_name, type, toUInt8(__normalized) FROM %s.%s\"",
        "comment_created_at": "2025-07-15T09:44:20+00:00",
        "comment_author": "aniketio-ctrl",
        "comment_body": "1.)for every new query we will be adding latency in the query range, the reason i gone with loading all the metrics, is beacuse no of metrics is gonna be finite, for our current use case, it wont gonna scale, from 5k to 5m, \r\n2.) its not that very few metrics we are gonna use, its that we have to check every query of any alert and dashboard, we will consider any new metrics to be normalized then will check wether its correct or not\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2207042866",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8518,
        "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
        "discussion_id": "2206806623",
        "commented_code": "@@ -6046,3 +6046,86 @@ func (r *ClickHouseReader) SearchTraces(ctx context.Context, params *model.Searc\n \n \treturn &searchSpansResult, nil\n }\n+\n+func (r *ClickHouseReader) GetCorrespondingNormalizedMetrics(ctx context.Context, orgID valuer.UUID) (map[string]string, error) {\n+\t// sanitize removes all non-alphanumeric characters from s\n+\tsanitize := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapRegex.ReplaceAllString(s, \"\")\n+\t}\n+\n+\t// Try cache first\n+\tresultDto := new(model.NormalizedMetricsMap)\n+\tcacheKey := constants.NormalizedMetricsMapCacheKey\n+\n+\tif err := r.cache.Get(ctx, orgID, cacheKey, resultDto, true); err == nil {\n+\t\treturn resultDto.MetricsMap, nil\n+\t}\n+\n+\tvalueCtx := context.WithValue(ctx, \"clickhouse_max_threads\", constants.NormalizedMetricsMapQueryThreads)\n+\tquery := \"SELECT DISTINCT metric_name, type, toUInt8(__normalized) FROM %s.%s\"",
        "comment_created_at": "2025-07-15T10:00:55+00:00",
        "comment_author": "srikanthccv",
        "comment_body": ">1.)for every new query we will be adding latency in the query range, the reason i gone with loading all the metrics, is beacuse no of metrics is gonna be finite, for our current use case, it wont gonna scale, from 5k to 5m,\r\n\r\nEven when it's finite, when you load 5k metrics into memory for each user, it going to take up unnecessary memory when there are hundreds of users. \r\n\r\n> its not that very few metrics we are gonna use, its that we have to check every query of any alert and dashboard, we will consider any new metrics to be normalized then will check wether its correct or not\r\n\r\nWhat is the problem with checking from every metric? We already do this to `FetchTemporality` and then cache the result of just the metric in use.",
        "pr_file_module": null
      },
      {
        "comment_id": "2208238222",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8518,
        "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
        "discussion_id": "2206806623",
        "commented_code": "@@ -6046,3 +6046,86 @@ func (r *ClickHouseReader) SearchTraces(ctx context.Context, params *model.Searc\n \n \treturn &searchSpansResult, nil\n }\n+\n+func (r *ClickHouseReader) GetCorrespondingNormalizedMetrics(ctx context.Context, orgID valuer.UUID) (map[string]string, error) {\n+\t// sanitize removes all non-alphanumeric characters from s\n+\tsanitize := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapRegex.ReplaceAllString(s, \"\")\n+\t}\n+\n+\t// Try cache first\n+\tresultDto := new(model.NormalizedMetricsMap)\n+\tcacheKey := constants.NormalizedMetricsMapCacheKey\n+\n+\tif err := r.cache.Get(ctx, orgID, cacheKey, resultDto, true); err == nil {\n+\t\treturn resultDto.MetricsMap, nil\n+\t}\n+\n+\tvalueCtx := context.WithValue(ctx, \"clickhouse_max_threads\", constants.NormalizedMetricsMapQueryThreads)\n+\tquery := \"SELECT DISTINCT metric_name, type, toUInt8(__normalized) FROM %s.%s\"",
        "comment_created_at": "2025-07-15T17:58:48+00:00",
        "comment_author": "aniketio-ctrl",
        "comment_body": "added the single metrics call add updated the function",
        "pr_file_module": null
      },
      {
        "comment_id": "2208902441",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8518,
        "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
        "discussion_id": "2206806623",
        "commented_code": "@@ -6046,3 +6046,86 @@ func (r *ClickHouseReader) SearchTraces(ctx context.Context, params *model.Searc\n \n \treturn &searchSpansResult, nil\n }\n+\n+func (r *ClickHouseReader) GetCorrespondingNormalizedMetrics(ctx context.Context, orgID valuer.UUID) (map[string]string, error) {\n+\t// sanitize removes all non-alphanumeric characters from s\n+\tsanitize := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapRegex.ReplaceAllString(s, \"\")\n+\t}\n+\n+\t// Try cache first\n+\tresultDto := new(model.NormalizedMetricsMap)\n+\tcacheKey := constants.NormalizedMetricsMapCacheKey\n+\n+\tif err := r.cache.Get(ctx, orgID, cacheKey, resultDto, true); err == nil {\n+\t\treturn resultDto.MetricsMap, nil\n+\t}\n+\n+\tvalueCtx := context.WithValue(ctx, \"clickhouse_max_threads\", constants.NormalizedMetricsMapQueryThreads)\n+\tquery := \"SELECT DISTINCT metric_name, type, toUInt8(__normalized) FROM %s.%s\"",
        "comment_created_at": "2025-07-15T23:39:42+00:00",
        "comment_author": "srikanthccv",
        "comment_body": "Have you looked at the `FetchTemporality` implementation? It doesn't make a single call each metric query. It collect the list of metric names and fetch them all at once. Please reduce the DB roundtrips to one for each query range.",
        "pr_file_module": null
      },
      {
        "comment_id": "2209236995",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8518,
        "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
        "discussion_id": "2206806623",
        "commented_code": "@@ -6046,3 +6046,86 @@ func (r *ClickHouseReader) SearchTraces(ctx context.Context, params *model.Searc\n \n \treturn &searchSpansResult, nil\n }\n+\n+func (r *ClickHouseReader) GetCorrespondingNormalizedMetrics(ctx context.Context, orgID valuer.UUID) (map[string]string, error) {\n+\t// sanitize removes all non-alphanumeric characters from s\n+\tsanitize := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapRegex.ReplaceAllString(s, \"\")\n+\t}\n+\n+\t// Try cache first\n+\tresultDto := new(model.NormalizedMetricsMap)\n+\tcacheKey := constants.NormalizedMetricsMapCacheKey\n+\n+\tif err := r.cache.Get(ctx, orgID, cacheKey, resultDto, true); err == nil {\n+\t\treturn resultDto.MetricsMap, nil\n+\t}\n+\n+\tvalueCtx := context.WithValue(ctx, \"clickhouse_max_threads\", constants.NormalizedMetricsMapQueryThreads)\n+\tquery := \"SELECT DISTINCT metric_name, type, toUInt8(__normalized) FROM %s.%s\"",
        "comment_created_at": "2025-07-16T05:11:05+00:00",
        "comment_author": "aniketio-ctrl",
        "comment_body": "added the search for list, reduced the db round trips",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2217167594",
    "pr_number": 8518,
    "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
    "created_at": "2025-07-19T06:19:19+00:00",
    "commented_code": "return &searchSpansResult, nil\n }\n+\n+func (r *ClickHouseReader) GetCorrespondingNormalizedMetrics(ctx context.Context, orgID valuer.UUID, metricNames []string) (map[string]model.NormalizedMetricsMap, error) {\n+\tif len(metricNames) == 0 {\n+\t\treturn make(map[string]model.NormalizedMetricsMap), nil\n+\t}\n+\n+\tresult := make(map[string]model.NormalizedMetricsMap)\n+\n+\tsanitize := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapRegex.ReplaceAllString(s, \"\")\n+\t}\n+\tstripQuantile := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapQuantileRegex.ReplaceAllString(s, \"\")\n+\t}\n+\n+\tmetricsToRegex := func(name string) string {\n+\t\ttokens := strings.FieldsFunc(strings.ToLower(name), func(r rune) bool {\n+\t\t\treturn !unicode.IsLetter(r) && !unicode.IsDigit(r)\n+\t\t})\n+\t\tif len(tokens) == 0 {\n+\t\t\treturn \"^$\"\n+\t\t}\n+\t\treturn \"^\" + strings.Join(tokens, \"[^a-z0-9]*\")\n+\t}",
    "repo_full_name": "SigNoz/signoz",
    "discussion_comments": [
      {
        "comment_id": "2217167594",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8518,
        "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
        "discussion_id": "2217167594",
        "commented_code": "@@ -6046,3 +6047,137 @@ func (r *ClickHouseReader) SearchTraces(ctx context.Context, params *model.Searc\n \n \treturn &searchSpansResult, nil\n }\n+\n+func (r *ClickHouseReader) GetCorrespondingNormalizedMetrics(ctx context.Context, orgID valuer.UUID, metricNames []string) (map[string]model.NormalizedMetricsMap, error) {\n+\tif len(metricNames) == 0 {\n+\t\treturn make(map[string]model.NormalizedMetricsMap), nil\n+\t}\n+\n+\tresult := make(map[string]model.NormalizedMetricsMap)\n+\n+\tsanitize := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapRegex.ReplaceAllString(s, \"\")\n+\t}\n+\tstripQuantile := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapQuantileRegex.ReplaceAllString(s, \"\")\n+\t}\n+\n+\tmetricsToRegex := func(name string) string {\n+\t\ttokens := strings.FieldsFunc(strings.ToLower(name), func(r rune) bool {\n+\t\t\treturn !unicode.IsLetter(r) && !unicode.IsDigit(r)\n+\t\t})\n+\t\tif len(tokens) == 0 {\n+\t\t\treturn \"^$\"\n+\t\t}\n+\t\treturn \"^\" + strings.Join(tokens, \"[^a-z0-9]*\")\n+\t}",
        "comment_created_at": "2025-07-19T06:19:19+00:00",
        "comment_author": "srikanthccv",
        "comment_body": "Did you test the performance for this? The regex matching is 5x slower than directly using the metric and normalised metric name. For example, instead of building a regex for `process.cpu.time`, why can't we search on ['process.cpu.time', 'process_cpu_time']? We know the normalised metric name in the database, if any. ",
        "pr_file_module": null
      },
      {
        "comment_id": "2218887565",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 8518,
        "pr_file": "pkg/query-service/app/clickhouseReader/reader.go",
        "discussion_id": "2217167594",
        "commented_code": "@@ -6046,3 +6047,137 @@ func (r *ClickHouseReader) SearchTraces(ctx context.Context, params *model.Searc\n \n \treturn &searchSpansResult, nil\n }\n+\n+func (r *ClickHouseReader) GetCorrespondingNormalizedMetrics(ctx context.Context, orgID valuer.UUID, metricNames []string) (map[string]model.NormalizedMetricsMap, error) {\n+\tif len(metricNames) == 0 {\n+\t\treturn make(map[string]model.NormalizedMetricsMap), nil\n+\t}\n+\n+\tresult := make(map[string]model.NormalizedMetricsMap)\n+\n+\tsanitize := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapRegex.ReplaceAllString(s, \"\")\n+\t}\n+\tstripQuantile := func(s string) string {\n+\t\treturn constants.NormalizedMetricsMapQuantileRegex.ReplaceAllString(s, \"\")\n+\t}\n+\n+\tmetricsToRegex := func(name string) string {\n+\t\ttokens := strings.FieldsFunc(strings.ToLower(name), func(r rune) bool {\n+\t\t\treturn !unicode.IsLetter(r) && !unicode.IsDigit(r)\n+\t\t})\n+\t\tif len(tokens) == 0 {\n+\t\t\treturn \"^$\"\n+\t\t}\n+\t\treturn \"^\" + strings.Join(tokens, \"[^a-z0-9]*\")\n+\t}",
        "comment_created_at": "2025-07-21T11:20:49+00:00",
        "comment_author": "aniketio-ctrl",
        "comment_body": "removed the regex added simple in query on metirc names",
        "pr_file_module": null
      }
    ]
  }
]