[
  {
    "discussion_id": "2095519980",
    "pr_number": 7972,
    "pr_file": "pkg/querybuilder/filter_error_listener.go",
    "created_at": "2025-05-19T11:42:41+00:00",
    "commented_code": "+package querybuilder\n+\n+import (\n+\t\"fmt\"\n+\t\"slices\"\n+\t\"sort\"\n+\t\"strings\"\n+\n+\t\"github.com/antlr4-go/antlr/v4\"\n+)\n+\n+var skipTokens = []string{\"WS\", \"COMMENT\"}\n+\n+// friendly maps SYMBOLIC_NAME -> what the user should see.\n+var friendly = map[string]string{\n+\t// punctuation & operators\n+\t\"LPAREN\": \"(\", \"RPAREN\": \")\",\n+\t\"LBRACK\": \"[\", \"RBRACK\": \"]\",\n+\t\"COMMA\":      \",\",\n+\t\"EQUALS\":     \"=\",\n+\t\"NOT_EQUALS\": \"!=\",\n+\t\"NEQ\":        \"<>\",\n+\t\"LT\":         \"<\", \"LE\": \"<=\",\n+\t\"GT\": \">\", \"GE\": \">=\",\n+\n+\t// keywords / functions\n+\t\"AND\":  \"AND\",\n+\t\"OR\":   \"OR\",\n+\t\"NOT\":  \"NOT\",\n+\t\"LIKE\": \"LIKE\", \"ILIKE\": \"ILIKE\",\n+\t\"NOT_LIKE\": \"NOT LIKE\", \"NOT_ILIKE\": \"NOT ILIKE\",\n+\t\"BETWEEN\": \"BETWEEN\", \"IN\": \"IN\", \"EXISTS\": \"EXISTS\",\n+\t\"REGEXP\": \"REGEXP\", \"CONTAINS\": \"CONTAINS\",\n+\t\"HAS\": \"has()\", \"HASANY\": \"hasAny()\", \"HASALL\": \"hasAll()\",\n+\n+\t// literals / identifiers\n+\t\"NUMBER\":      \"number\",\n+\t\"BOOL\":        \"boolean\",\n+\t\"QUOTED_TEXT\": \"quoted text\",\n+\t\"KEY\":         \"field name (ex: service.name)\",\n+}\n+\n+// prettyToken returns the nicest human label for token type tType.\n+//\n+// Order of preference:\n+//  1. hard-coded friendly table\n+//  2. literal name from grammar  e.g.  \"'('\"\n+//  3. symbolic name              e.g.  AND\n+//  4. numeric fallback           e.g.  <34>\n+func prettyToken(p antlr.Parser, tType int) (string, bool) {\n+\tif slices.Contains(skipTokens, tokenName(p, tType)) {\n+\t\treturn \"\", false\n+\t}\n+\n+\t// symbolic name -> friendly ?\n+\tsyms := p.GetSymbolicNames()\n+\tif tType >= 0 && tType < len(syms) {\n+\t\tif nice, ok := friendly[syms[tType]]; ok {\n+\t\t\treturn nice, true\n+\t\t}\n+\t}\n+\n+\t// literal name (the quoted punctuation that ANTLR generates)\n+\tlits := p.GetLiteralNames()\n+\tif tType >= 0 && tType < len(lits) && lits[tType] != \"\" {\n+\t\treturn lits[tType], true\n+\t}\n+\n+\t// symbolic name as last resort (but hide WS, EOF, \u2026)\n+\tif tType >= 0 && tType < len(syms) && syms[tType] != \"\" && syms[tType] != \"WS\" {\n+\t\treturn syms[tType], true\n+\t}\n+\n+\treturn \"\", false // tell caller to skip this entry\n+}\n+\n+type SyntaxErr struct {\n+\tLine, Col int\n+\tTokenTxt  string   // offending text (or EOF)\n+\tTokenType int      // offending token type\n+\tExpected  []string // token names the parser still expected\n+\tRuleStack []string\n+\tMsg       string\n+}\n+\n+func (e *SyntaxErr) Error() string {\n+\texp := \"\"\n+\tif len(e.Expected) > 0 {\n+\t\texp = \"expecting one of {\" + strings.Join(e.Expected, \", \") + \"}\" + \" but got \" + e.TokenTxt\n+\t}\n+\treturn fmt.Sprintf(\"line %d:%d %s\", e.Line, e.Col, exp)\n+}\n+\n+type Ambiguity struct {\n+\tText   string // slice of raw input that was ambiguous\n+\tAlts   string // e.g. \"{1, 3}\"\n+\tRStack []string\n+}\n+\n+func (a *Ambiguity) Error() string {\n+\treturn fmt.Sprintf(\"ambiguity: %s, alts: %s\", a.Text, a.Alts)\n+}\n+\n+type ErrorListener struct {\n+\tantlr.DefaultErrorListener\n+\n+\tSyntaxErrors []*SyntaxErr\n+\tAmbigs       []*Ambiguity\n+}\n+\n+func NewErrorListener() *ErrorListener { return &ErrorListener{} }\n+\n+func (l *ErrorListener) SyntaxError(\n+\trec antlr.Recognizer,\n+\toff any,\n+\tline, column int,\n+\tmsg string,\n+\te antlr.RecognitionException,\n+) {\n+\terr := &SyntaxErr{Line: line, Col: column, Msg: msg}\n+\n+\tif tok, ok := off.(antlr.Token); ok {\n+\t\tif tok.GetTokenType() == antlr.TokenEOF {\n+\t\t\terr.TokenTxt = \"EOF\"\n+\t\t\terr.TokenType = tok.GetTokenType()\n+\t\t} else {\n+\t\t\terr.TokenTxt = fmt.Sprintf(\"'%s'\", tok.GetText())\n+\t\t\terr.TokenType = tok.GetTokenType()\n+\t\t}\n+\t}\n+\n+\tif p, ok := rec.(antlr.Parser); ok {\n+\t\tset := p.GetExpectedTokens()\n+\n+\t\t// Heuristic: if KEY appears in the expected set *alongside* any literal\n+\t\t// value tokens, we assume it stands for a bare value. Otherwise, it stands\n+\t\t// for a left\u2011hand identifier.\n+\t\tvalueTokens := map[int]struct{}{\n+\t\t\tpGetTokenType(p, \"QUOTED_TEXT\"): {},\n+\t\t\tpGetTokenType(p, \"NUMBER\"):      {},\n+\t\t\tpGetTokenType(p, \"BOOL\"):        {},\n+\t\t}\n+\t\thasValueLiterals := false\n+\t\tfor _, iv := range set.GetIntervals() {\n+\t\t\tfor t := iv.Start; t <= iv.Stop; t++ {\n+\t\t\t\tif _, ok := valueTokens[t]; ok {\n+\t\t\t\t\thasValueLiterals = true\n+\t\t\t\t\tbreak\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tif hasValueLiterals {\n+\t\t\t\tbreak\n+\t\t\t}\n+\t\t}\n+\n+\t\tuniq := map[string]struct{}{}\n+\t\tfor _, iv := range set.GetIntervals() {\n+\t\t\tfor t := iv.Start; t <= iv.Stop; t++ {\n+\t\t\t\tsym := tokenName(p, t)\n+\t\t\t\tif sym == \"KEY\" {\n+\t\t\t\t\tif !hasValueLiterals {\n+\t\t\t\t\t\tuniq[\"field name (ex: service.name)\"] = struct{}{}\n+\t\t\t\t\t}\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t\tif label, ok := prettyToken(p, t); ok {\n+\t\t\t\t\tuniq[label] = struct{}{}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\terr.Expected = make([]string, 0, len(uniq))\n+\t\tfor k := range uniq {\n+\t\t\terr.Expected = append(err.Expected, k)\n+\t\t}\n+\t\tsort.Strings(err.Expected)\n+\t\terr.RuleStack = p.GetRuleInvocationStack(nil)\n+\t}\n+\n+\tl.SyntaxErrors = append(l.SyntaxErrors, err)\n+}\n+\n+func (l *ErrorListener) ReportAmbiguity(\n+\trec antlr.Parser,\n+\tdfa *antlr.DFA,\n+\tstartIdx, stopIdx int,\n+\texact bool,\n+\tambigAlts *antlr.BitSet,\n+\tconfigs *antlr.ATNConfigSet,\n+) {\n+\tif !exact {\n+\t\treturn\n+\t}\n+\tstream := rec.GetTokenStream()\n+\ttxt := textSlice(stream, startIdx, stopIdx)\n+\tl.Ambigs = append(l.Ambigs, &Ambiguity{\n+\t\tText:   txt,\n+\t\tAlts:   ambigAlts.String(),\n+\t\tRStack: rec.GetRuleInvocationStack(nil),\n+\t})\n+}\n+\n+func pGetTokenType(p antlr.Parser, tName string) int {\n+\tsyms := p.GetSymbolicNames()\n+\tfor i, sym := range syms {\n+\t\tif sym == tName {\n+\t\t\treturn i\n+\t\t}\n+\t}\n+\treturn -1\n+}\n+\n+// tokenName prefers literal > symbolic > numeric.\n+func tokenName(p antlr.Parser, tType int) string {\n+\tlits := p.GetLiteralNames()\n+\tif tType >= 0 && tType < len(lits) && lits[tType] != \"\" {\n+\t\treturn lits[tType]\n+\t}\n+\tsyms := p.GetSymbolicNames()\n+\tif tType >= 0 && tType < len(syms) && syms[tType] != \"\" {\n+\t\treturn syms[tType]\n+\t}\n+\treturn fmt.Sprintf(\"<%d>\", tType)\n+}\n+\n+// textSlice pulls raw input text between two token indexes.\n+func textSlice(ts antlr.TokenStream, start, stop int) string {\n+\tvar b strings.Builder\n+\tfor i := start; i <= stop && i >= 0; i++ {\n+\t\tif tok := ts.Get(i); tok != nil && tok.GetTokenType() != antlr.TokenEOF {\n+\t\t\tb.WriteString(tok.GetText())\n+\t\t}\n+\t}\n+\treturn b.String()",
    "repo_full_name": "SigNoz/signoz",
    "discussion_comments": [
      {
        "comment_id": "2095519980",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 7972,
        "pr_file": "pkg/querybuilder/filter_error_listener.go",
        "discussion_id": "2095519980",
        "commented_code": "@@ -0,0 +1,235 @@\n+package querybuilder\n+\n+import (\n+\t\"fmt\"\n+\t\"slices\"\n+\t\"sort\"\n+\t\"strings\"\n+\n+\t\"github.com/antlr4-go/antlr/v4\"\n+)\n+\n+var skipTokens = []string{\"WS\", \"COMMENT\"}\n+\n+// friendly maps SYMBOLIC_NAME -> what the user should see.\n+var friendly = map[string]string{\n+\t// punctuation & operators\n+\t\"LPAREN\": \"(\", \"RPAREN\": \")\",\n+\t\"LBRACK\": \"[\", \"RBRACK\": \"]\",\n+\t\"COMMA\":      \",\",\n+\t\"EQUALS\":     \"=\",\n+\t\"NOT_EQUALS\": \"!=\",\n+\t\"NEQ\":        \"<>\",\n+\t\"LT\":         \"<\", \"LE\": \"<=\",\n+\t\"GT\": \">\", \"GE\": \">=\",\n+\n+\t// keywords / functions\n+\t\"AND\":  \"AND\",\n+\t\"OR\":   \"OR\",\n+\t\"NOT\":  \"NOT\",\n+\t\"LIKE\": \"LIKE\", \"ILIKE\": \"ILIKE\",\n+\t\"NOT_LIKE\": \"NOT LIKE\", \"NOT_ILIKE\": \"NOT ILIKE\",\n+\t\"BETWEEN\": \"BETWEEN\", \"IN\": \"IN\", \"EXISTS\": \"EXISTS\",\n+\t\"REGEXP\": \"REGEXP\", \"CONTAINS\": \"CONTAINS\",\n+\t\"HAS\": \"has()\", \"HASANY\": \"hasAny()\", \"HASALL\": \"hasAll()\",\n+\n+\t// literals / identifiers\n+\t\"NUMBER\":      \"number\",\n+\t\"BOOL\":        \"boolean\",\n+\t\"QUOTED_TEXT\": \"quoted text\",\n+\t\"KEY\":         \"field name (ex: service.name)\",\n+}\n+\n+// prettyToken returns the nicest human label for token type tType.\n+//\n+// Order of preference:\n+//  1. hard-coded friendly table\n+//  2. literal name from grammar  e.g.  \"'('\"\n+//  3. symbolic name              e.g.  AND\n+//  4. numeric fallback           e.g.  <34>\n+func prettyToken(p antlr.Parser, tType int) (string, bool) {\n+\tif slices.Contains(skipTokens, tokenName(p, tType)) {\n+\t\treturn \"\", false\n+\t}\n+\n+\t// symbolic name -> friendly ?\n+\tsyms := p.GetSymbolicNames()\n+\tif tType >= 0 && tType < len(syms) {\n+\t\tif nice, ok := friendly[syms[tType]]; ok {\n+\t\t\treturn nice, true\n+\t\t}\n+\t}\n+\n+\t// literal name (the quoted punctuation that ANTLR generates)\n+\tlits := p.GetLiteralNames()\n+\tif tType >= 0 && tType < len(lits) && lits[tType] != \"\" {\n+\t\treturn lits[tType], true\n+\t}\n+\n+\t// symbolic name as last resort (but hide WS, EOF, \u2026)\n+\tif tType >= 0 && tType < len(syms) && syms[tType] != \"\" && syms[tType] != \"WS\" {\n+\t\treturn syms[tType], true\n+\t}\n+\n+\treturn \"\", false // tell caller to skip this entry\n+}\n+\n+type SyntaxErr struct {\n+\tLine, Col int\n+\tTokenTxt  string   // offending text (or EOF)\n+\tTokenType int      // offending token type\n+\tExpected  []string // token names the parser still expected\n+\tRuleStack []string\n+\tMsg       string\n+}\n+\n+func (e *SyntaxErr) Error() string {\n+\texp := \"\"\n+\tif len(e.Expected) > 0 {\n+\t\texp = \"expecting one of {\" + strings.Join(e.Expected, \", \") + \"}\" + \" but got \" + e.TokenTxt\n+\t}\n+\treturn fmt.Sprintf(\"line %d:%d %s\", e.Line, e.Col, exp)\n+}\n+\n+type Ambiguity struct {\n+\tText   string // slice of raw input that was ambiguous\n+\tAlts   string // e.g. \"{1, 3}\"\n+\tRStack []string\n+}\n+\n+func (a *Ambiguity) Error() string {\n+\treturn fmt.Sprintf(\"ambiguity: %s, alts: %s\", a.Text, a.Alts)\n+}\n+\n+type ErrorListener struct {\n+\tantlr.DefaultErrorListener\n+\n+\tSyntaxErrors []*SyntaxErr\n+\tAmbigs       []*Ambiguity\n+}\n+\n+func NewErrorListener() *ErrorListener { return &ErrorListener{} }\n+\n+func (l *ErrorListener) SyntaxError(\n+\trec antlr.Recognizer,\n+\toff any,\n+\tline, column int,\n+\tmsg string,\n+\te antlr.RecognitionException,\n+) {\n+\terr := &SyntaxErr{Line: line, Col: column, Msg: msg}\n+\n+\tif tok, ok := off.(antlr.Token); ok {\n+\t\tif tok.GetTokenType() == antlr.TokenEOF {\n+\t\t\terr.TokenTxt = \"EOF\"\n+\t\t\terr.TokenType = tok.GetTokenType()\n+\t\t} else {\n+\t\t\terr.TokenTxt = fmt.Sprintf(\"'%s'\", tok.GetText())\n+\t\t\terr.TokenType = tok.GetTokenType()\n+\t\t}\n+\t}\n+\n+\tif p, ok := rec.(antlr.Parser); ok {\n+\t\tset := p.GetExpectedTokens()\n+\n+\t\t// Heuristic: if KEY appears in the expected set *alongside* any literal\n+\t\t// value tokens, we assume it stands for a bare value. Otherwise, it stands\n+\t\t// for a left\u2011hand identifier.\n+\t\tvalueTokens := map[int]struct{}{\n+\t\t\tpGetTokenType(p, \"QUOTED_TEXT\"): {},\n+\t\t\tpGetTokenType(p, \"NUMBER\"):      {},\n+\t\t\tpGetTokenType(p, \"BOOL\"):        {},\n+\t\t}\n+\t\thasValueLiterals := false\n+\t\tfor _, iv := range set.GetIntervals() {\n+\t\t\tfor t := iv.Start; t <= iv.Stop; t++ {\n+\t\t\t\tif _, ok := valueTokens[t]; ok {\n+\t\t\t\t\thasValueLiterals = true\n+\t\t\t\t\tbreak\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tif hasValueLiterals {\n+\t\t\t\tbreak\n+\t\t\t}\n+\t\t}\n+\n+\t\tuniq := map[string]struct{}{}\n+\t\tfor _, iv := range set.GetIntervals() {\n+\t\t\tfor t := iv.Start; t <= iv.Stop; t++ {\n+\t\t\t\tsym := tokenName(p, t)\n+\t\t\t\tif sym == \"KEY\" {\n+\t\t\t\t\tif !hasValueLiterals {\n+\t\t\t\t\t\tuniq[\"field name (ex: service.name)\"] = struct{}{}\n+\t\t\t\t\t}\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t\tif label, ok := prettyToken(p, t); ok {\n+\t\t\t\t\tuniq[label] = struct{}{}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\terr.Expected = make([]string, 0, len(uniq))\n+\t\tfor k := range uniq {\n+\t\t\terr.Expected = append(err.Expected, k)\n+\t\t}\n+\t\tsort.Strings(err.Expected)\n+\t\terr.RuleStack = p.GetRuleInvocationStack(nil)\n+\t}\n+\n+\tl.SyntaxErrors = append(l.SyntaxErrors, err)\n+}\n+\n+func (l *ErrorListener) ReportAmbiguity(\n+\trec antlr.Parser,\n+\tdfa *antlr.DFA,\n+\tstartIdx, stopIdx int,\n+\texact bool,\n+\tambigAlts *antlr.BitSet,\n+\tconfigs *antlr.ATNConfigSet,\n+) {\n+\tif !exact {\n+\t\treturn\n+\t}\n+\tstream := rec.GetTokenStream()\n+\ttxt := textSlice(stream, startIdx, stopIdx)\n+\tl.Ambigs = append(l.Ambigs, &Ambiguity{\n+\t\tText:   txt,\n+\t\tAlts:   ambigAlts.String(),\n+\t\tRStack: rec.GetRuleInvocationStack(nil),\n+\t})\n+}\n+\n+func pGetTokenType(p antlr.Parser, tName string) int {\n+\tsyms := p.GetSymbolicNames()\n+\tfor i, sym := range syms {\n+\t\tif sym == tName {\n+\t\t\treturn i\n+\t\t}\n+\t}\n+\treturn -1\n+}\n+\n+// tokenName prefers literal > symbolic > numeric.\n+func tokenName(p antlr.Parser, tType int) string {\n+\tlits := p.GetLiteralNames()\n+\tif tType >= 0 && tType < len(lits) && lits[tType] != \"\" {\n+\t\treturn lits[tType]\n+\t}\n+\tsyms := p.GetSymbolicNames()\n+\tif tType >= 0 && tType < len(syms) && syms[tType] != \"\" {\n+\t\treturn syms[tType]\n+\t}\n+\treturn fmt.Sprintf(\"<%d>\", tType)\n+}\n+\n+// textSlice pulls raw input text between two token indexes.\n+func textSlice(ts antlr.TokenStream, start, stop int) string {\n+\tvar b strings.Builder\n+\tfor i := start; i <= stop && i >= 0; i++ {\n+\t\tif tok := ts.Get(i); tok != nil && tok.GetTokenType() != antlr.TokenEOF {\n+\t\t\tb.WriteString(tok.GetText())\n+\t\t}\n+\t}\n+\treturn b.String()",
        "comment_created_at": "2025-05-19T11:42:41+00:00",
        "comment_author": "eKuG",
        "comment_body": "By adding && i < size to the loop condition, the function would prevent potential index out-of-bounds issues when the stop parameter exceeds the token stream's length.\r\n\r\n```\r\nsize := ts.Size()  // Get the stream size\r\n    for i := start; i <= stop && i >= 0 && i < size; i++ {\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2095998718",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 7972,
        "pr_file": "pkg/querybuilder/filter_error_listener.go",
        "discussion_id": "2095519980",
        "commented_code": "@@ -0,0 +1,235 @@\n+package querybuilder\n+\n+import (\n+\t\"fmt\"\n+\t\"slices\"\n+\t\"sort\"\n+\t\"strings\"\n+\n+\t\"github.com/antlr4-go/antlr/v4\"\n+)\n+\n+var skipTokens = []string{\"WS\", \"COMMENT\"}\n+\n+// friendly maps SYMBOLIC_NAME -> what the user should see.\n+var friendly = map[string]string{\n+\t// punctuation & operators\n+\t\"LPAREN\": \"(\", \"RPAREN\": \")\",\n+\t\"LBRACK\": \"[\", \"RBRACK\": \"]\",\n+\t\"COMMA\":      \",\",\n+\t\"EQUALS\":     \"=\",\n+\t\"NOT_EQUALS\": \"!=\",\n+\t\"NEQ\":        \"<>\",\n+\t\"LT\":         \"<\", \"LE\": \"<=\",\n+\t\"GT\": \">\", \"GE\": \">=\",\n+\n+\t// keywords / functions\n+\t\"AND\":  \"AND\",\n+\t\"OR\":   \"OR\",\n+\t\"NOT\":  \"NOT\",\n+\t\"LIKE\": \"LIKE\", \"ILIKE\": \"ILIKE\",\n+\t\"NOT_LIKE\": \"NOT LIKE\", \"NOT_ILIKE\": \"NOT ILIKE\",\n+\t\"BETWEEN\": \"BETWEEN\", \"IN\": \"IN\", \"EXISTS\": \"EXISTS\",\n+\t\"REGEXP\": \"REGEXP\", \"CONTAINS\": \"CONTAINS\",\n+\t\"HAS\": \"has()\", \"HASANY\": \"hasAny()\", \"HASALL\": \"hasAll()\",\n+\n+\t// literals / identifiers\n+\t\"NUMBER\":      \"number\",\n+\t\"BOOL\":        \"boolean\",\n+\t\"QUOTED_TEXT\": \"quoted text\",\n+\t\"KEY\":         \"field name (ex: service.name)\",\n+}\n+\n+// prettyToken returns the nicest human label for token type tType.\n+//\n+// Order of preference:\n+//  1. hard-coded friendly table\n+//  2. literal name from grammar  e.g.  \"'('\"\n+//  3. symbolic name              e.g.  AND\n+//  4. numeric fallback           e.g.  <34>\n+func prettyToken(p antlr.Parser, tType int) (string, bool) {\n+\tif slices.Contains(skipTokens, tokenName(p, tType)) {\n+\t\treturn \"\", false\n+\t}\n+\n+\t// symbolic name -> friendly ?\n+\tsyms := p.GetSymbolicNames()\n+\tif tType >= 0 && tType < len(syms) {\n+\t\tif nice, ok := friendly[syms[tType]]; ok {\n+\t\t\treturn nice, true\n+\t\t}\n+\t}\n+\n+\t// literal name (the quoted punctuation that ANTLR generates)\n+\tlits := p.GetLiteralNames()\n+\tif tType >= 0 && tType < len(lits) && lits[tType] != \"\" {\n+\t\treturn lits[tType], true\n+\t}\n+\n+\t// symbolic name as last resort (but hide WS, EOF, \u2026)\n+\tif tType >= 0 && tType < len(syms) && syms[tType] != \"\" && syms[tType] != \"WS\" {\n+\t\treturn syms[tType], true\n+\t}\n+\n+\treturn \"\", false // tell caller to skip this entry\n+}\n+\n+type SyntaxErr struct {\n+\tLine, Col int\n+\tTokenTxt  string   // offending text (or EOF)\n+\tTokenType int      // offending token type\n+\tExpected  []string // token names the parser still expected\n+\tRuleStack []string\n+\tMsg       string\n+}\n+\n+func (e *SyntaxErr) Error() string {\n+\texp := \"\"\n+\tif len(e.Expected) > 0 {\n+\t\texp = \"expecting one of {\" + strings.Join(e.Expected, \", \") + \"}\" + \" but got \" + e.TokenTxt\n+\t}\n+\treturn fmt.Sprintf(\"line %d:%d %s\", e.Line, e.Col, exp)\n+}\n+\n+type Ambiguity struct {\n+\tText   string // slice of raw input that was ambiguous\n+\tAlts   string // e.g. \"{1, 3}\"\n+\tRStack []string\n+}\n+\n+func (a *Ambiguity) Error() string {\n+\treturn fmt.Sprintf(\"ambiguity: %s, alts: %s\", a.Text, a.Alts)\n+}\n+\n+type ErrorListener struct {\n+\tantlr.DefaultErrorListener\n+\n+\tSyntaxErrors []*SyntaxErr\n+\tAmbigs       []*Ambiguity\n+}\n+\n+func NewErrorListener() *ErrorListener { return &ErrorListener{} }\n+\n+func (l *ErrorListener) SyntaxError(\n+\trec antlr.Recognizer,\n+\toff any,\n+\tline, column int,\n+\tmsg string,\n+\te antlr.RecognitionException,\n+) {\n+\terr := &SyntaxErr{Line: line, Col: column, Msg: msg}\n+\n+\tif tok, ok := off.(antlr.Token); ok {\n+\t\tif tok.GetTokenType() == antlr.TokenEOF {\n+\t\t\terr.TokenTxt = \"EOF\"\n+\t\t\terr.TokenType = tok.GetTokenType()\n+\t\t} else {\n+\t\t\terr.TokenTxt = fmt.Sprintf(\"'%s'\", tok.GetText())\n+\t\t\terr.TokenType = tok.GetTokenType()\n+\t\t}\n+\t}\n+\n+\tif p, ok := rec.(antlr.Parser); ok {\n+\t\tset := p.GetExpectedTokens()\n+\n+\t\t// Heuristic: if KEY appears in the expected set *alongside* any literal\n+\t\t// value tokens, we assume it stands for a bare value. Otherwise, it stands\n+\t\t// for a left\u2011hand identifier.\n+\t\tvalueTokens := map[int]struct{}{\n+\t\t\tpGetTokenType(p, \"QUOTED_TEXT\"): {},\n+\t\t\tpGetTokenType(p, \"NUMBER\"):      {},\n+\t\t\tpGetTokenType(p, \"BOOL\"):        {},\n+\t\t}\n+\t\thasValueLiterals := false\n+\t\tfor _, iv := range set.GetIntervals() {\n+\t\t\tfor t := iv.Start; t <= iv.Stop; t++ {\n+\t\t\t\tif _, ok := valueTokens[t]; ok {\n+\t\t\t\t\thasValueLiterals = true\n+\t\t\t\t\tbreak\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tif hasValueLiterals {\n+\t\t\t\tbreak\n+\t\t\t}\n+\t\t}\n+\n+\t\tuniq := map[string]struct{}{}\n+\t\tfor _, iv := range set.GetIntervals() {\n+\t\t\tfor t := iv.Start; t <= iv.Stop; t++ {\n+\t\t\t\tsym := tokenName(p, t)\n+\t\t\t\tif sym == \"KEY\" {\n+\t\t\t\t\tif !hasValueLiterals {\n+\t\t\t\t\t\tuniq[\"field name (ex: service.name)\"] = struct{}{}\n+\t\t\t\t\t}\n+\t\t\t\t\tcontinue\n+\t\t\t\t}\n+\t\t\t\tif label, ok := prettyToken(p, t); ok {\n+\t\t\t\t\tuniq[label] = struct{}{}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n+\t\terr.Expected = make([]string, 0, len(uniq))\n+\t\tfor k := range uniq {\n+\t\t\terr.Expected = append(err.Expected, k)\n+\t\t}\n+\t\tsort.Strings(err.Expected)\n+\t\terr.RuleStack = p.GetRuleInvocationStack(nil)\n+\t}\n+\n+\tl.SyntaxErrors = append(l.SyntaxErrors, err)\n+}\n+\n+func (l *ErrorListener) ReportAmbiguity(\n+\trec antlr.Parser,\n+\tdfa *antlr.DFA,\n+\tstartIdx, stopIdx int,\n+\texact bool,\n+\tambigAlts *antlr.BitSet,\n+\tconfigs *antlr.ATNConfigSet,\n+) {\n+\tif !exact {\n+\t\treturn\n+\t}\n+\tstream := rec.GetTokenStream()\n+\ttxt := textSlice(stream, startIdx, stopIdx)\n+\tl.Ambigs = append(l.Ambigs, &Ambiguity{\n+\t\tText:   txt,\n+\t\tAlts:   ambigAlts.String(),\n+\t\tRStack: rec.GetRuleInvocationStack(nil),\n+\t})\n+}\n+\n+func pGetTokenType(p antlr.Parser, tName string) int {\n+\tsyms := p.GetSymbolicNames()\n+\tfor i, sym := range syms {\n+\t\tif sym == tName {\n+\t\t\treturn i\n+\t\t}\n+\t}\n+\treturn -1\n+}\n+\n+// tokenName prefers literal > symbolic > numeric.\n+func tokenName(p antlr.Parser, tType int) string {\n+\tlits := p.GetLiteralNames()\n+\tif tType >= 0 && tType < len(lits) && lits[tType] != \"\" {\n+\t\treturn lits[tType]\n+\t}\n+\tsyms := p.GetSymbolicNames()\n+\tif tType >= 0 && tType < len(syms) && syms[tType] != \"\" {\n+\t\treturn syms[tType]\n+\t}\n+\treturn fmt.Sprintf(\"<%d>\", tType)\n+}\n+\n+// textSlice pulls raw input text between two token indexes.\n+func textSlice(ts antlr.TokenStream, start, stop int) string {\n+\tvar b strings.Builder\n+\tfor i := start; i <= stop && i >= 0; i++ {\n+\t\tif tok := ts.Get(i); tok != nil && tok.GetTokenType() != antlr.TokenEOF {\n+\t\t\tb.WriteString(tok.GetText())\n+\t\t}\n+\t}\n+\treturn b.String()",
        "comment_created_at": "2025-05-19T15:32:17+00:00",
        "comment_author": "srikanthccv",
        "comment_body": "That should not happen, the stop wouldn't exceed the stream length.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2072366295",
    "pr_number": 7805,
    "pr_file": "pkg/types/cachetypes/cacheable.go",
    "created_at": "2025-05-03T10:18:22+00:00",
    "commented_code": "+package cachetypes\n+\n+import (\n+\t\"encoding\"\n+\t\"reflect\"\n+\n+\t\"github.com/SigNoz/signoz/pkg/errors\"\n+)\n+\n+type Cacheable interface {\n+\tencoding.BinaryMarshaler\n+\tencoding.BinaryUnmarshaler\n+}\n+\n+func WrapCacheableErrors(rt reflect.Type, caller string) error {\n+\tif rt == nil {\n+\t\treturn errors.Newf(errors.TypeInvalidInput, errors.CodeInvalidInput, \"%s: (nil)\", caller)\n+\t}\n+\n+\tif rt.Kind() != reflect.Pointer {\n+\t\treturn errors.Newf(errors.TypeInvalidInput, errors.CodeInvalidInput, \"%s: (non-pointer \\\"%s\\\")\", caller, rt.String())\n+\t}\n+\n+\treturn errors.Newf(errors.TypeInvalidInput, errors.CodeInvalidInput, \"%s: (nil \\\"%s\\\")\", caller, rt.String())\n+}\n+\n+func ValidatePointer(dest any) error {\n+\trv := reflect.ValueOf(dest)\n+\tif rv.Kind() != reflect.Pointer || rv.IsNil() {\n+\t\treturn WrapCacheableErrors(reflect.TypeOf(dest), \"inmemory\")\n+\t}\n+\treturn nil\n+}",
    "repo_full_name": "SigNoz/signoz",
    "discussion_comments": [
      {
        "comment_id": "2072366295",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 7805,
        "pr_file": "pkg/types/cachetypes/cacheable.go",
        "discussion_id": "2072366295",
        "commented_code": "@@ -0,0 +1,33 @@\n+package cachetypes\n+\n+import (\n+\t\"encoding\"\n+\t\"reflect\"\n+\n+\t\"github.com/SigNoz/signoz/pkg/errors\"\n+)\n+\n+type Cacheable interface {\n+\tencoding.BinaryMarshaler\n+\tencoding.BinaryUnmarshaler\n+}\n+\n+func WrapCacheableErrors(rt reflect.Type, caller string) error {\n+\tif rt == nil {\n+\t\treturn errors.Newf(errors.TypeInvalidInput, errors.CodeInvalidInput, \"%s: (nil)\", caller)\n+\t}\n+\n+\tif rt.Kind() != reflect.Pointer {\n+\t\treturn errors.Newf(errors.TypeInvalidInput, errors.CodeInvalidInput, \"%s: (non-pointer \\\"%s\\\")\", caller, rt.String())\n+\t}\n+\n+\treturn errors.Newf(errors.TypeInvalidInput, errors.CodeInvalidInput, \"%s: (nil \\\"%s\\\")\", caller, rt.String())\n+}\n+\n+func ValidatePointer(dest any) error {\n+\trv := reflect.ValueOf(dest)\n+\tif rv.Kind() != reflect.Pointer || rv.IsNil() {\n+\t\treturn WrapCacheableErrors(reflect.TypeOf(dest), \"inmemory\")\n+\t}\n+\treturn nil\n+}",
        "comment_created_at": "2025-05-03T10:18:22+00:00",
        "comment_author": "grandwizard28",
        "comment_body": "```suggestion\r\nfunc ValidatePointer(dest any, caller string) error {\r\n\trv := reflect.ValueOf(dest)\r\n\tif rv.Kind() != reflect.Pointer || rv.IsNil() {\r\n\t\treturn WrapCacheableErrors(reflect.TypeOf(dest), caller)\r\n\t}\r\n\treturn nil\r\n}\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2072373718",
        "repo_full_name": "SigNoz/signoz",
        "pr_number": 7805,
        "pr_file": "pkg/types/cachetypes/cacheable.go",
        "discussion_id": "2072366295",
        "commented_code": "@@ -0,0 +1,33 @@\n+package cachetypes\n+\n+import (\n+\t\"encoding\"\n+\t\"reflect\"\n+\n+\t\"github.com/SigNoz/signoz/pkg/errors\"\n+)\n+\n+type Cacheable interface {\n+\tencoding.BinaryMarshaler\n+\tencoding.BinaryUnmarshaler\n+}\n+\n+func WrapCacheableErrors(rt reflect.Type, caller string) error {\n+\tif rt == nil {\n+\t\treturn errors.Newf(errors.TypeInvalidInput, errors.CodeInvalidInput, \"%s: (nil)\", caller)\n+\t}\n+\n+\tif rt.Kind() != reflect.Pointer {\n+\t\treturn errors.Newf(errors.TypeInvalidInput, errors.CodeInvalidInput, \"%s: (non-pointer \\\"%s\\\")\", caller, rt.String())\n+\t}\n+\n+\treturn errors.Newf(errors.TypeInvalidInput, errors.CodeInvalidInput, \"%s: (nil \\\"%s\\\")\", caller, rt.String())\n+}\n+\n+func ValidatePointer(dest any) error {\n+\trv := reflect.ValueOf(dest)\n+\tif rv.Kind() != reflect.Pointer || rv.IsNil() {\n+\t\treturn WrapCacheableErrors(reflect.TypeOf(dest), \"inmemory\")\n+\t}\n+\treturn nil\n+}",
        "comment_created_at": "2025-05-03T11:06:36+00:00",
        "comment_author": "vikrantgupta25",
        "comment_body": "done",
        "pr_file_module": null
      }
    ]
  }
]