[
  {
    "discussion_id": "2206221166",
    "pr_number": 51377,
    "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/metric/MergeMetrics.java",
    "created_at": "2025-07-15T03:48:46+00:00",
    "commented_code": "+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.connector.metric;\n+\n+import org.apache.spark.annotation.Evolving;\n+\n+/**\n+ * Data structure encapsulating the execution metrics of a merge operation to write connectors\n+ * that request it.\n+ *\n+ * @since 4.1.0\n+ */\n+@Evolving\n+public interface MergeMetrics {\n+\n+  class Builder {\n+    private long numTargetRowsCopied = -1;",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2206221166",
        "repo_full_name": "apache/spark",
        "pr_number": 51377,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/metric/MergeMetrics.java",
        "discussion_id": "2206221166",
        "commented_code": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.connector.metric;\n+\n+import org.apache.spark.annotation.Evolving;\n+\n+/**\n+ * Data structure encapsulating the execution metrics of a merge operation to write connectors\n+ * that request it.\n+ *\n+ * @since 4.1.0\n+ */\n+@Evolving\n+public interface MergeMetrics {\n+\n+  class Builder {\n+    private long numTargetRowsCopied = -1;",
        "comment_created_at": "2025-07-15T03:48:46+00:00",
        "comment_author": "aokolnychyi",
        "comment_body": "I personally don't mind -1 but I think we have a few places in DSv2 that use `OptionalLong`.\r\nWill it make sense to be consistent?",
        "pr_file_module": null
      },
      {
        "comment_id": "2208737577",
        "repo_full_name": "apache/spark",
        "pr_number": 51377,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/metric/MergeMetrics.java",
        "discussion_id": "2206221166",
        "commented_code": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.connector.metric;\n+\n+import org.apache.spark.annotation.Evolving;\n+\n+/**\n+ * Data structure encapsulating the execution metrics of a merge operation to write connectors\n+ * that request it.\n+ *\n+ * @since 4.1.0\n+ */\n+@Evolving\n+public interface MergeMetrics {\n+\n+  class Builder {\n+    private long numTargetRowsCopied = -1;",
        "comment_created_at": "2025-07-15T21:29:20+00:00",
        "comment_author": "szehon-ho",
        "comment_body": "ok changed to OptionalLong in the API",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2040102976",
    "pr_number": 50230,
    "pr_file": "core/src/main/java/org/apache/spark/shuffle/sort/BypassMergeSortShuffleWriter.java",
    "created_at": "2025-04-11T18:35:49+00:00",
    "commented_code": "while (records.hasNext()) {\n         final Product2<K, V> record = records.next();\n         final K key = record._1();\n-        partitionWriters[partitioner.getPartition(key)].write(key, record._2());\n+        final int partitionId = partitioner.getPartition(key);\n+        partitionWriters[partitionId].write(key, record._2());\n+        if (rowBasedChecksums.length > 0) {",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2040102976",
        "repo_full_name": "apache/spark",
        "pr_number": 50230,
        "pr_file": "core/src/main/java/org/apache/spark/shuffle/sort/BypassMergeSortShuffleWriter.java",
        "discussion_id": "2040102976",
        "commented_code": "@@ -171,7 +182,11 @@ public void write(Iterator<Product2<K, V>> records) throws IOException {\n       while (records.hasNext()) {\n         final Product2<K, V> record = records.next();\n         final K key = record._1();\n-        partitionWriters[partitioner.getPartition(key)].write(key, record._2());\n+        final int partitionId = partitioner.getPartition(key);\n+        partitionWriters[partitionId].write(key, record._2());\n+        if (rowBasedChecksums.length > 0) {",
        "comment_created_at": "2025-04-11T18:35:49+00:00",
        "comment_author": "mridulm",
        "comment_body": "We should consistently use either `null` to indicate checksum is disabled, or `length == 0`/`isEmpty`",
        "pr_file_module": null
      },
      {
        "comment_id": "2052681418",
        "repo_full_name": "apache/spark",
        "pr_number": 50230,
        "pr_file": "core/src/main/java/org/apache/spark/shuffle/sort/BypassMergeSortShuffleWriter.java",
        "discussion_id": "2040102976",
        "commented_code": "@@ -171,7 +182,11 @@ public void write(Iterator<Product2<K, V>> records) throws IOException {\n       while (records.hasNext()) {\n         final Product2<K, V> record = records.next();\n         final K key = record._1();\n-        partitionWriters[partitioner.getPartition(key)].write(key, record._2());\n+        final int partitionId = partitioner.getPartition(key);\n+        partitionWriters[partitionId].write(key, record._2());\n+        if (rowBasedChecksums.length > 0) {",
        "comment_created_at": "2025-04-21T16:27:33+00:00",
        "comment_author": "JiexingLi",
        "comment_body": "Updated to all use length/isEmpty now ",
        "pr_file_module": null
      }
    ]
  }
]