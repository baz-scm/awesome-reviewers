[
  {
    "discussion_id": "2195002785",
    "pr_number": 51419,
    "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/catalog/TableCatalog.java",
    "created_at": "2025-07-09T13:12:36+00:00",
    "commented_code": "*/\n   String PROP_OWNER = \"owner\";\n \n+  /**\n+   * A reserved property to specify the view text of a general table that represents\n+   * a SQL view. The identifiers must be fully qualified in the view text to be\n+   * context-independent, otherwise the behavior is undefined.",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2195002785",
        "repo_full_name": "apache/spark",
        "pr_number": 51419,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/catalog/TableCatalog.java",
        "discussion_id": "2195002785",
        "commented_code": "@@ -88,6 +88,13 @@ public interface TableCatalog extends CatalogPlugin {\n    */\n   String PROP_OWNER = \"owner\";\n \n+  /**\n+   * A reserved property to specify the view text of a general table that represents\n+   * a SQL view. The identifiers must be fully qualified in the view text to be\n+   * context-independent, otherwise the behavior is undefined.",
        "comment_created_at": "2025-07-09T13:12:36+00:00",
        "comment_author": "cloud-fan",
        "comment_body": "I think the current view implementation which stores the original SQL text and a bunch of context is too convoluted to put into the public DS v2 API. It's better if the view text is context-independent. We are going to improve it in https://github.com/apache/spark/pull/51410\r\n\r\nBefore the improvement is done, we only allow to read DS v2 views that has context-independent SQL text.",
        "pr_file_module": null
      },
      {
        "comment_id": "2206241249",
        "repo_full_name": "apache/spark",
        "pr_number": 51419,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/catalog/TableCatalog.java",
        "discussion_id": "2195002785",
        "commented_code": "@@ -88,6 +88,13 @@ public interface TableCatalog extends CatalogPlugin {\n    */\n   String PROP_OWNER = \"owner\";\n \n+  /**\n+   * A reserved property to specify the view text of a general table that represents\n+   * a SQL view. The identifiers must be fully qualified in the view text to be\n+   * context-independent, otherwise the behavior is undefined.",
        "comment_created_at": "2025-07-15T04:12:27+00:00",
        "comment_author": "aokolnychyi",
        "comment_body": "Don't we store the current catalog and namespace in the view metadata? Do we expect the connectors to modify the view SQL text? ",
        "pr_file_module": null
      },
      {
        "comment_id": "2206960749",
        "repo_full_name": "apache/spark",
        "pr_number": 51419,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/catalog/TableCatalog.java",
        "discussion_id": "2195002785",
        "commented_code": "@@ -88,6 +88,13 @@ public interface TableCatalog extends CatalogPlugin {\n    */\n   String PROP_OWNER = \"owner\";\n \n+  /**\n+   * A reserved property to specify the view text of a general table that represents\n+   * a SQL view. The identifiers must be fully qualified in the view text to be\n+   * context-independent, otherwise the behavior is undefined.",
        "comment_created_at": "2025-07-15T09:23:26+00:00",
        "comment_author": "cloud-fan",
        "comment_body": "My proposal is to let Spark modify the view text before saving it into the catalog, so that the catalog does not need to store the current catalog/namespace.",
        "pr_file_module": null
      },
      {
        "comment_id": "2236736216",
        "repo_full_name": "apache/spark",
        "pr_number": 51419,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/catalog/TableCatalog.java",
        "discussion_id": "2195002785",
        "commented_code": "@@ -88,6 +88,13 @@ public interface TableCatalog extends CatalogPlugin {\n    */\n   String PROP_OWNER = \"owner\";\n \n+  /**\n+   * A reserved property to specify the view text of a general table that represents\n+   * a SQL view. The identifiers must be fully qualified in the view text to be\n+   * context-independent, otherwise the behavior is undefined.",
        "comment_created_at": "2025-07-28T14:30:12+00:00",
        "comment_author": "aokolnychyi",
        "comment_body": "So all identifiers in the view text will always include the catalog name as the first name part and the table name as the last name part? How hard will it be to modify the original SQL text? Will it cause any surprises to the users if the original and the persisted SQL text differ?",
        "pr_file_module": null
      },
      {
        "comment_id": "2236737919",
        "repo_full_name": "apache/spark",
        "pr_number": 51419,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/catalog/TableCatalog.java",
        "discussion_id": "2195002785",
        "commented_code": "@@ -88,6 +88,13 @@ public interface TableCatalog extends CatalogPlugin {\n    */\n   String PROP_OWNER = \"owner\";\n \n+  /**\n+   * A reserved property to specify the view text of a general table that represents\n+   * a SQL view. The identifiers must be fully qualified in the view text to be\n+   * context-independent, otherwise the behavior is undefined.",
        "comment_created_at": "2025-07-28T14:30:40+00:00",
        "comment_author": "aokolnychyi",
        "comment_body": "So all identifiers in the view text will always include the catalog name as the first name part and the table name as the last name part? How hard will it be to modify the original SQL text? Will it cause any surprises to the users if the original and the persisted SQL text differ?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2226010443",
    "pr_number": 51577,
    "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/catalog/constraints/BaseConstraint.java",
    "created_at": "2025-07-23T15:46:49+00:00",
    "commented_code": "rely ? \"RELY\" : \"NORELY\");\n   }\n \n+  public String toDescription() {\n+    StringJoiner joiner = new StringJoiner(\" \");\n+    joiner.add(definition());\n+    if (enforced) {\n+      joiner.add(\"ENFORCED\");\n+    }",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2226010443",
        "repo_full_name": "apache/spark",
        "pr_number": 51577,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/catalog/constraints/BaseConstraint.java",
        "discussion_id": "2226010443",
        "commented_code": "@@ -73,6 +73,18 @@ public String toDDL() {\n         rely ? \"RELY\" : \"NORELY\");\n   }\n \n+  public String toDescription() {\n+    StringJoiner joiner = new StringJoiner(\" \");\n+    joiner.add(definition());\n+    if (enforced) {\n+      joiner.add(\"ENFORCED\");\n+    }",
        "comment_created_at": "2025-07-23T15:46:49+00:00",
        "comment_author": "gengliangwang",
        "comment_body": "Currently the ENFORCED behavior can't be set. The check constraint is always enforced while the other constraints are not enforced. We can either:\r\n* Always show `ENFORCED`/`NOT ENFORCED`\r\n* Skip this one in the toDescription method",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2214199791",
    "pr_number": 51541,
    "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/catalog/constraints/BaseConstraint.java",
    "created_at": "2025-07-17T20:10:28+00:00",
    "commented_code": "@Override\n   public String toDDL() {\n+    // The validation status is not included in the DDL output as it's not part of\n+    // the Spark SQL syntax for constraints.\n     return String.format(\n-        \"CONSTRAINT %s %s %s %s %s\",\n+        \"CONSTRAINT %s %s %s %s\",\n         name,\n         definition(),\n         enforced ? \"ENFORCED\" : \"NOT ENFORCED\",\n-        validationStatus,",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2214199791",
        "repo_full_name": "apache/spark",
        "pr_number": 51541,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/catalog/constraints/BaseConstraint.java",
        "discussion_id": "2214199791",
        "commented_code": "@@ -63,12 +63,13 @@ public boolean rely() {\n \n   @Override\n   public String toDDL() {\n+    // The validation status is not included in the DDL output as it's not part of\n+    // the Spark SQL syntax for constraints.\n     return String.format(\n-        \"CONSTRAINT %s %s %s %s %s\",\n+        \"CONSTRAINT %s %s %s %s\",\n         name,\n         definition(),\n         enforced ? \"ENFORCED\" : \"NOT ENFORCED\",\n-        validationStatus,",
        "comment_created_at": "2025-07-17T20:10:28+00:00",
        "comment_author": "gengliangwang",
        "comment_body": "cc @aokolnychyi ",
        "pr_file_module": null
      },
      {
        "comment_id": "2214360740",
        "repo_full_name": "apache/spark",
        "pr_number": 51541,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/catalog/constraints/BaseConstraint.java",
        "discussion_id": "2214199791",
        "commented_code": "@@ -63,12 +63,13 @@ public boolean rely() {\n \n   @Override\n   public String toDDL() {\n+    // The validation status is not included in the DDL output as it's not part of\n+    // the Spark SQL syntax for constraints.\n     return String.format(\n-        \"CONSTRAINT %s %s %s %s %s\",\n+        \"CONSTRAINT %s %s %s %s\",\n         name,\n         definition(),\n         enforced ? \"ENFORCED\" : \"NOT ENFORCED\",\n-        validationStatus,",
        "comment_created_at": "2025-07-17T21:38:37+00:00",
        "comment_author": "dongjoon-hyun",
        "comment_body": "For my understanding, where can we see the status after this, @gengliangwang ?",
        "pr_file_module": null
      },
      {
        "comment_id": "2214366786",
        "repo_full_name": "apache/spark",
        "pr_number": 51541,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/catalog/constraints/BaseConstraint.java",
        "discussion_id": "2214199791",
        "commented_code": "@@ -63,12 +63,13 @@ public boolean rely() {\n \n   @Override\n   public String toDDL() {\n+    // The validation status is not included in the DDL output as it's not part of\n+    // the Spark SQL syntax for constraints.\n     return String.format(\n-        \"CONSTRAINT %s %s %s %s %s\",\n+        \"CONSTRAINT %s %s %s %s\",\n         name,\n         definition(),\n         enforced ? \"ENFORCED\" : \"NOT ENFORCED\",\n-        validationStatus,",
        "comment_created_at": "2025-07-17T21:42:42+00:00",
        "comment_author": "gengliangwang",
        "comment_body": "No. We have to remove it since the validation status is not supported in the parser.\r\nWe can still display it in the \"DESC TABLE\" command",
        "pr_file_module": null
      }
    ]
  }
]