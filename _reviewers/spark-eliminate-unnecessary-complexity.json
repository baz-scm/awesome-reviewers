[
  {
    "discussion_id": "2211608731",
    "pr_number": 51507,
    "pr_file": "python/pyspark/pipelines/cli.py",
    "created_at": "2025-07-16T21:04:17+00:00",
    "commented_code": "os.chdir(prev)\n \n \n-def run(spec_path: Path) -> None:\n-    \"\"\"Run the pipeline defined with the given spec.\"\"\"\n+def run(\n+    spec_path: Path,\n+    full_refresh: Optional[Sequence[str]] = None,",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2211608731",
        "repo_full_name": "apache/spark",
        "pr_number": 51507,
        "pr_file": "python/pyspark/pipelines/cli.py",
        "discussion_id": "2211608731",
        "commented_code": "@@ -217,8 +217,30 @@ def change_dir(path: Path) -> Generator[None, None, None]:\n         os.chdir(prev)\n \n \n-def run(spec_path: Path) -> None:\n-    \"\"\"Run the pipeline defined with the given spec.\"\"\"\n+def run(\n+    spec_path: Path,\n+    full_refresh: Optional[Sequence[str]] = None,",
        "comment_created_at": "2025-07-16T21:04:17+00:00",
        "comment_author": "sryza",
        "comment_body": "This never gets invoked without these parameters specified, so no need to have default values for them.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2211609713",
    "pr_number": 51507,
    "pr_file": "python/pyspark/pipelines/cli.py",
    "created_at": "2025-07-16T21:04:50+00:00",
    "commented_code": "os.chdir(prev)\n \n \n-def run(spec_path: Path) -> None:\n-    \"\"\"Run the pipeline defined with the given spec.\"\"\"\n+def run(\n+    spec_path: Path,\n+    full_refresh: Optional[Sequence[str]] = None,\n+    full_refresh_all: bool = False,\n+    refresh: Optional[Sequence[str]] = None,\n+) -> None:\n+    \"\"\"Run the pipeline defined with the given spec.\n+\n+    :param spec_path: Path to the pipeline specification file.\n+    :param full_refresh: List of datasets to reset and recompute.\n+    :param full_refresh_all: Perform a full graph reset and recompute.\n+    :param refresh: List of datasets to update.\n+    \"\"\"\n+    # Validate conflicting arguments\n+    if full_refresh_all:\n+        if full_refresh:",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2211609713",
        "repo_full_name": "apache/spark",
        "pr_number": 51507,
        "pr_file": "python/pyspark/pipelines/cli.py",
        "discussion_id": "2211609713",
        "commented_code": "@@ -217,8 +217,30 @@ def change_dir(path: Path) -> Generator[None, None, None]:\n         os.chdir(prev)\n \n \n-def run(spec_path: Path) -> None:\n-    \"\"\"Run the pipeline defined with the given spec.\"\"\"\n+def run(\n+    spec_path: Path,\n+    full_refresh: Optional[Sequence[str]] = None,\n+    full_refresh_all: bool = False,\n+    refresh: Optional[Sequence[str]] = None,\n+) -> None:\n+    \"\"\"Run the pipeline defined with the given spec.\n+\n+    :param spec_path: Path to the pipeline specification file.\n+    :param full_refresh: List of datasets to reset and recompute.\n+    :param full_refresh_all: Perform a full graph reset and recompute.\n+    :param refresh: List of datasets to update.\n+    \"\"\"\n+    # Validate conflicting arguments\n+    if full_refresh_all:\n+        if full_refresh:",
        "comment_created_at": "2025-07-16T21:04:50+00:00",
        "comment_author": "sryza",
        "comment_body": "Should these be consolidated into `if full_refresh or refresh`?",
        "pr_file_module": null
      }
    ]
  }
]