[
  {
    "discussion_id": "2206227136",
    "pr_number": 51377,
    "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/metric/MergeMetrics.java",
    "created_at": "2025-07-15T03:55:48+00:00",
    "commented_code": "+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.connector.metric;\n+\n+import org.apache.spark.annotation.Evolving;\n+\n+/**\n+ * Data structure encapsulating the execution metrics of a merge operation to write connectors\n+ * that request it.\n+ *\n+ * @since 4.1.0\n+ */\n+@Evolving\n+public interface MergeMetrics {\n+\n+  class Builder {\n+    private long numTargetRowsCopied = -1;\n+    private long numTargetRowsInserted = -1;\n+    private long numTargetRowsDeleted = -1;\n+    private long numTargetRowsUpdated = -1;\n+    private long numTargetRowsMatchedUpdated = -1;\n+    private long numTargetRowsMatchedDeleted = -1;\n+    private long numTargetRowsNotMatchedBySourceUpdated = -1;\n+    private long numTargetRowsNotMatchedBySourceDeleted = -1;\n+\n+    public Builder numTargetRowsCopied(long numTargetRowsCopied) {\n+      this.numTargetRowsCopied = numTargetRowsCopied;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsInserted(long numTargetRowsInserted) {\n+      this.numTargetRowsInserted = numTargetRowsInserted;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsDeleted(long numTargetRowsDeleted) {\n+      this.numTargetRowsDeleted = numTargetRowsDeleted;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsUpdated(long numTargetRowsUpdated) {\n+      this.numTargetRowsUpdated = numTargetRowsUpdated;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsMatchedUpdated(long numTargetRowsMatchedUpdated) {\n+      this.numTargetRowsMatchedUpdated = numTargetRowsMatchedUpdated;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsMatchedDeleted(long numTargetRowsMatchedDeleted) {\n+      this.numTargetRowsMatchedDeleted = numTargetRowsMatchedDeleted;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsNotMatchedBySourceUpdated(\n+      long numTargetRowsNotMatchedBySourceUpdated) {\n+      this.numTargetRowsNotMatchedBySourceUpdated = numTargetRowsNotMatchedBySourceUpdated;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsNotMatchedBySourceDeleted(\n+      long numTargetRowsNotMatchedBySourceDeleted) {\n+      this.numTargetRowsNotMatchedBySourceDeleted = numTargetRowsNotMatchedBySourceDeleted;\n+      return this;\n+    }\n+\n+    public MergeMetrics build() {\n+      return new MergeMetrics() {\n+        @Override\n+        public long numTargetRowsCopied() {\n+          return numTargetRowsCopied;\n+        }\n+\n+        @Override\n+        public long numTargetRowsInserted() {\n+          return numTargetRowsInserted;\n+        }\n+\n+        @Override\n+        public long numTargetRowsDeleted() {\n+          return numTargetRowsDeleted;\n+        }\n+\n+        @Override\n+        public long numTargetRowsUpdated() {\n+          return numTargetRowsUpdated;\n+        }\n+\n+        @Override\n+        public long numTargetRowsMatchedUpdated() {\n+          return numTargetRowsMatchedUpdated;\n+        }\n+\n+        @Override\n+        public long numTargetRowsMatchedDeleted() {\n+          return numTargetRowsMatchedDeleted;\n+        }\n+\n+        @Override\n+        public long numTargetRowsNotMatchedBySourceUpdated() {\n+          return numTargetRowsNotMatchedBySourceUpdated;\n+        }\n+\n+        @Override\n+        public long numTargetRowsNotMatchedBySourceDeleted() {\n+          return numTargetRowsNotMatchedBySourceDeleted;\n+        }\n+      };\n+    }\n+  }\n+\n+  /**\n+   * Returns a new builder for MergeMetrics.\n+   */\n+  static Builder builder() {",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2206227136",
        "repo_full_name": "apache/spark",
        "pr_number": 51377,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/metric/MergeMetrics.java",
        "discussion_id": "2206227136",
        "commented_code": "@@ -0,0 +1,173 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.spark.sql.connector.metric;\n+\n+import org.apache.spark.annotation.Evolving;\n+\n+/**\n+ * Data structure encapsulating the execution metrics of a merge operation to write connectors\n+ * that request it.\n+ *\n+ * @since 4.1.0\n+ */\n+@Evolving\n+public interface MergeMetrics {\n+\n+  class Builder {\n+    private long numTargetRowsCopied = -1;\n+    private long numTargetRowsInserted = -1;\n+    private long numTargetRowsDeleted = -1;\n+    private long numTargetRowsUpdated = -1;\n+    private long numTargetRowsMatchedUpdated = -1;\n+    private long numTargetRowsMatchedDeleted = -1;\n+    private long numTargetRowsNotMatchedBySourceUpdated = -1;\n+    private long numTargetRowsNotMatchedBySourceDeleted = -1;\n+\n+    public Builder numTargetRowsCopied(long numTargetRowsCopied) {\n+      this.numTargetRowsCopied = numTargetRowsCopied;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsInserted(long numTargetRowsInserted) {\n+      this.numTargetRowsInserted = numTargetRowsInserted;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsDeleted(long numTargetRowsDeleted) {\n+      this.numTargetRowsDeleted = numTargetRowsDeleted;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsUpdated(long numTargetRowsUpdated) {\n+      this.numTargetRowsUpdated = numTargetRowsUpdated;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsMatchedUpdated(long numTargetRowsMatchedUpdated) {\n+      this.numTargetRowsMatchedUpdated = numTargetRowsMatchedUpdated;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsMatchedDeleted(long numTargetRowsMatchedDeleted) {\n+      this.numTargetRowsMatchedDeleted = numTargetRowsMatchedDeleted;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsNotMatchedBySourceUpdated(\n+      long numTargetRowsNotMatchedBySourceUpdated) {\n+      this.numTargetRowsNotMatchedBySourceUpdated = numTargetRowsNotMatchedBySourceUpdated;\n+      return this;\n+    }\n+\n+    public Builder numTargetRowsNotMatchedBySourceDeleted(\n+      long numTargetRowsNotMatchedBySourceDeleted) {\n+      this.numTargetRowsNotMatchedBySourceDeleted = numTargetRowsNotMatchedBySourceDeleted;\n+      return this;\n+    }\n+\n+    public MergeMetrics build() {\n+      return new MergeMetrics() {\n+        @Override\n+        public long numTargetRowsCopied() {\n+          return numTargetRowsCopied;\n+        }\n+\n+        @Override\n+        public long numTargetRowsInserted() {\n+          return numTargetRowsInserted;\n+        }\n+\n+        @Override\n+        public long numTargetRowsDeleted() {\n+          return numTargetRowsDeleted;\n+        }\n+\n+        @Override\n+        public long numTargetRowsUpdated() {\n+          return numTargetRowsUpdated;\n+        }\n+\n+        @Override\n+        public long numTargetRowsMatchedUpdated() {\n+          return numTargetRowsMatchedUpdated;\n+        }\n+\n+        @Override\n+        public long numTargetRowsMatchedDeleted() {\n+          return numTargetRowsMatchedDeleted;\n+        }\n+\n+        @Override\n+        public long numTargetRowsNotMatchedBySourceUpdated() {\n+          return numTargetRowsNotMatchedBySourceUpdated;\n+        }\n+\n+        @Override\n+        public long numTargetRowsNotMatchedBySourceDeleted() {\n+          return numTargetRowsNotMatchedBySourceDeleted;\n+        }\n+      };\n+    }\n+  }\n+\n+  /**\n+   * Returns a new builder for MergeMetrics.\n+   */\n+  static Builder builder() {",
        "comment_created_at": "2025-07-15T03:55:48+00:00",
        "comment_author": "aokolnychyi",
        "comment_body": "Do we expect connectors to construct this object? Seems unlikely. If so, is there a lot of value in offering a public builder that we will have to maintain long term? We can either keep `MergeMetrics` as an interface and add an internal Scala case class like we do for `LogicalWriteInfo` or make this a proper Java class and have a utility method to construct it. I am OK with either option but exposing a public builder seems redundant in this case.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2097014486",
    "pr_number": 50921,
    "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/util/JoinTypeSQLBuilder.java",
    "created_at": "2025-05-20T06:17:14+00:00",
    "commented_code": "+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector.util;\n+\n+import org.apache.spark.SparkIllegalArgumentException;\n+import org.apache.spark.sql.connector.join.*;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * The builder to generate SQL for specific Join type.",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2097014486",
        "repo_full_name": "apache/spark",
        "pr_number": 50921,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/util/JoinTypeSQLBuilder.java",
        "discussion_id": "2097014486",
        "commented_code": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector.util;\n+\n+import org.apache.spark.SparkIllegalArgumentException;\n+import org.apache.spark.sql.connector.join.*;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * The builder to generate SQL for specific Join type.",
        "comment_created_at": "2025-05-20T06:17:14+00:00",
        "comment_author": "cloud-fan",
        "comment_body": "I'm wondering if this is really needed. The join type string is quite simple, and Spark doesn't need to provide a helper to do it.",
        "pr_file_module": null
      },
      {
        "comment_id": "2097728492",
        "repo_full_name": "apache/spark",
        "pr_number": 50921,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/util/JoinTypeSQLBuilder.java",
        "discussion_id": "2097014486",
        "commented_code": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector.util;\n+\n+import org.apache.spark.SparkIllegalArgumentException;\n+import org.apache.spark.sql.connector.join.*;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+/**\n+ * The builder to generate SQL for specific Join type.",
        "comment_created_at": "2025-05-20T11:35:31+00:00",
        "comment_author": "PetarVasiljevic-DB",
        "comment_body": "It might be redundant. The reason why I have it is simply the answer to the following question: what if some dialect calls the specific join type differently. For example, what if there is a dialect that doesn't support `CROSS JOIN` but only `JOIN` syntax.\r\n\r\nWe can get same effect with just string comparison in the dialects, so we can get rid of it if you find it as an overkill.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2206115863",
    "pr_number": 50921,
    "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/join/JoinType.java",
    "created_at": "2025-07-15T01:51:44+00:00",
    "commented_code": "+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector.join;\n+\n+import org.apache.spark.annotation.Evolving;\n+\n+/**\n+ * Enum representing the join type in public API.\n+ *\n+ * @since 4.1.0\n+ */\n+@Evolving\n+public enum JoinType {\n+    INNER_JOIN,",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2206115863",
        "repo_full_name": "apache/spark",
        "pr_number": 50921,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/join/JoinType.java",
        "discussion_id": "2206115863",
        "commented_code": "@@ -0,0 +1,30 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector.join;\n+\n+import org.apache.spark.annotation.Evolving;\n+\n+/**\n+ * Enum representing the join type in public API.\n+ *\n+ * @since 4.1.0\n+ */\n+@Evolving\n+public enum JoinType {\n+    INNER_JOIN,",
        "comment_created_at": "2025-07-15T01:51:44+00:00",
        "comment_author": "agubichev",
        "comment_body": "can't we use the catalyst type? org.apache.spark.sql.catalyst.plans.JoinType",
        "pr_file_module": null
      },
      {
        "comment_id": "2206667234",
        "repo_full_name": "apache/spark",
        "pr_number": 50921,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/join/JoinType.java",
        "discussion_id": "2206115863",
        "commented_code": "@@ -0,0 +1,30 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector.join;\n+\n+import org.apache.spark.annotation.Evolving;\n+\n+/**\n+ * Enum representing the join type in public API.\n+ *\n+ * @since 4.1.0\n+ */\n+@Evolving\n+public enum JoinType {\n+    INNER_JOIN,",
        "comment_created_at": "2025-07-15T07:33:35+00:00",
        "comment_author": "PetarVasiljevic-DB",
        "comment_body": "@cloud-fan is `org.apache.spark.sql.catalyst.plans.JoinType` not public? That was my thinking when I introduced the JoinType in connector side. If we can expose it though, I can remove the JoinType in connector.",
        "pr_file_module": null
      },
      {
        "comment_id": "2206999839",
        "repo_full_name": "apache/spark",
        "pr_number": 50921,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/join/JoinType.java",
        "discussion_id": "2206115863",
        "commented_code": "@@ -0,0 +1,30 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector.join;\n+\n+import org.apache.spark.annotation.Evolving;\n+\n+/**\n+ * Enum representing the join type in public API.\n+ *\n+ * @since 4.1.0\n+ */\n+@Evolving\n+public enum JoinType {\n+    INNER_JOIN,",
        "comment_created_at": "2025-07-15T09:41:12+00:00",
        "comment_author": "cloud-fan",
        "comment_body": "Anything inside the catalyst package is internal.",
        "pr_file_module": null
      },
      {
        "comment_id": "2207009972",
        "repo_full_name": "apache/spark",
        "pr_number": 50921,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/join/JoinType.java",
        "discussion_id": "2206115863",
        "commented_code": "@@ -0,0 +1,30 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector.join;\n+\n+import org.apache.spark.annotation.Evolving;\n+\n+/**\n+ * Enum representing the join type in public API.\n+ *\n+ * @since 4.1.0\n+ */\n+@Evolving\n+public enum JoinType {\n+    INNER_JOIN,",
        "comment_created_at": "2025-07-15T09:45:47+00:00",
        "comment_author": "PetarVasiljevic-DB",
        "comment_body": "@cloud-fan okay then, no changes needed",
        "pr_file_module": null
      }
    ]
  }
]