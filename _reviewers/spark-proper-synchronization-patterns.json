[
  {
    "discussion_id": "2060617666",
    "pr_number": 50595,
    "pr_file": "sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/StateStore.scala",
    "created_at": "2025-04-25T17:15:51+00:00",
    "commented_code": "}\n   }\n \n+  // Block until we can process this partition\n+  private def awaitProcessThisPartition(id: StateStoreProviderId): Unit =\n+    maintenanceThreadPoolLock.synchronized {\n+      while (!processThisPartition(id)) {\n+        maintenanceThreadPoolLock.wait()",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2060617666",
        "repo_full_name": "apache/spark",
        "pr_number": 50595,
        "pr_file": "sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/StateStore.scala",
        "discussion_id": "2060617666",
        "commented_code": "@@ -1095,6 +1131,14 @@ object StateStore extends Logging {\n     }\n   }\n \n+  // Block until we can process this partition\n+  private def awaitProcessThisPartition(id: StateStoreProviderId): Unit =\n+    maintenanceThreadPoolLock.synchronized {\n+      while (!processThisPartition(id)) {\n+        maintenanceThreadPoolLock.wait()",
        "comment_created_at": "2025-04-25T17:15:51+00:00",
        "comment_author": "anishshri-db",
        "comment_body": "Should we wait on some timeout here instead of waiting indefinitely ? also - overall - should be give up waiting for the partition to process if its not making progress on some upper bound ?",
        "pr_file_module": null
      },
      {
        "comment_id": "2060768228",
        "repo_full_name": "apache/spark",
        "pr_number": 50595,
        "pr_file": "sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/StateStore.scala",
        "discussion_id": "2060617666",
        "commented_code": "@@ -1095,6 +1131,14 @@ object StateStore extends Logging {\n     }\n   }\n \n+  // Block until we can process this partition\n+  private def awaitProcessThisPartition(id: StateStoreProviderId): Unit =\n+    maintenanceThreadPoolLock.synchronized {\n+      while (!processThisPartition(id)) {\n+        maintenanceThreadPoolLock.wait()",
        "comment_created_at": "2025-04-25T19:16:59+00:00",
        "comment_author": "ericm-db",
        "comment_body": "Sure yeah - should we have a conf for this timeout?",
        "pr_file_module": null
      },
      {
        "comment_id": "2060769106",
        "repo_full_name": "apache/spark",
        "pr_number": 50595,
        "pr_file": "sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/StateStore.scala",
        "discussion_id": "2060617666",
        "commented_code": "@@ -1095,6 +1131,14 @@ object StateStore extends Logging {\n     }\n   }\n \n+  // Block until we can process this partition\n+  private def awaitProcessThisPartition(id: StateStoreProviderId): Unit =\n+    maintenanceThreadPoolLock.synchronized {\n+      while (!processThisPartition(id)) {\n+        maintenanceThreadPoolLock.wait()",
        "comment_created_at": "2025-04-25T19:17:57+00:00",
        "comment_author": "anishshri-db",
        "comment_body": "Maybe an internal conf ?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2065118202",
    "pr_number": 50595,
    "pr_file": "sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/StateStore.scala",
    "created_at": "2025-04-29T00:27:22+00:00",
    "commented_code": "}\n   }\n \n+  // Wait until this partition can be processed\n+  private def awaitProcessThisPartition(\n+      id: StateStoreProviderId,\n+      timeoutMs: Long\n+  ): Boolean = {\n+    val endTime = System.currentTimeMillis() + timeoutMs\n+\n+    // If immediate processing fails, wait with timeout\n+    var canProcessThisPartition = processThisPartition(id)\n+    while (!canProcessThisPartition && System.currentTimeMillis() < endTime) {\n+      canProcessThisPartition = processThisPartition(id)\n+      Thread.sleep(5000)",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2065118202",
        "repo_full_name": "apache/spark",
        "pr_number": 50595,
        "pr_file": "sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/StateStore.scala",
        "discussion_id": "2065118202",
        "commented_code": "@@ -1111,60 +1160,46 @@ object StateStore extends Logging {\n     }\n   }\n \n+  // Wait until this partition can be processed\n+  private def awaitProcessThisPartition(\n+      id: StateStoreProviderId,\n+      timeoutMs: Long\n+  ): Boolean = {\n+    val endTime = System.currentTimeMillis() + timeoutMs\n+\n+    // If immediate processing fails, wait with timeout\n+    var canProcessThisPartition = processThisPartition(id)\n+    while (!canProcessThisPartition && System.currentTimeMillis() < endTime) {\n+      canProcessThisPartition = processThisPartition(id)\n+      Thread.sleep(5000)",
        "comment_created_at": "2025-04-29T00:27:22+00:00",
        "comment_author": "anishshri-db",
        "comment_body": "Lets not do a busy wait here ? can we do a cond wait/signal as needed",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2071091954",
    "pr_number": 50595,
    "pr_file": "sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/StateStore.scala",
    "created_at": "2025-05-02T04:50:39+00:00",
    "commented_code": "}\n   }\n \n+  // Wait until this partition can be processed\n+  private def awaitProcessThisPartition(\n+      id: StateStoreProviderId,\n+      timeoutMs: Long): Boolean = maintenanceThreadPoolLock synchronized  {\n+    val startTime = System.currentTimeMillis()\n+    val endTime = startTime + timeoutMs\n+\n+    // If immediate processing fails, wait with timeout\n+    var canProcessThisPartition = processThisPartition(id)\n+    while (!canProcessThisPartition && System.currentTimeMillis() < endTime) {\n+      canProcessThisPartition = processThisPartition(id)\n+      maintenanceThreadPoolLock.wait(timeoutMs)",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2071091954",
        "repo_full_name": "apache/spark",
        "pr_number": 50595,
        "pr_file": "sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/state/StateStore.scala",
        "discussion_id": "2071091954",
        "commented_code": "@@ -1111,60 +1159,64 @@ object StateStore extends Logging {\n     }\n   }\n \n+  // Wait until this partition can be processed\n+  private def awaitProcessThisPartition(\n+      id: StateStoreProviderId,\n+      timeoutMs: Long): Boolean = maintenanceThreadPoolLock synchronized  {\n+    val startTime = System.currentTimeMillis()\n+    val endTime = startTime + timeoutMs\n+\n+    // If immediate processing fails, wait with timeout\n+    var canProcessThisPartition = processThisPartition(id)\n+    while (!canProcessThisPartition && System.currentTimeMillis() < endTime) {\n+      canProcessThisPartition = processThisPartition(id)\n+      maintenanceThreadPoolLock.wait(timeoutMs)",
        "comment_created_at": "2025-05-02T04:50:39+00:00",
        "comment_author": "micheal-o",
        "comment_body": "shouldn't the `canProcessThisPartition` be after the wait? Because with this current code if `canProcessThisPartition` becomes true, you will end up still waiting",
        "pr_file_module": null
      }
    ]
  }
]