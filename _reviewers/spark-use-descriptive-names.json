[
  {
    "discussion_id": "2071966473",
    "pr_number": 50230,
    "pr_file": "core/src/main/java/org/apache/spark/util/MyByteArrayOutputStream.java",
    "created_at": "2025-05-02T17:59:48+00:00",
    "commented_code": "+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util;\n+\n+import java.io.ByteArrayOutputStream;\n+\n+/** Subclass of ByteArrayOutputStream that exposes `buf` directly. */\n+public final class MyByteArrayOutputStream extends ByteArrayOutputStream {",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2071966473",
        "repo_full_name": "apache/spark",
        "pr_number": 50230,
        "pr_file": "core/src/main/java/org/apache/spark/util/MyByteArrayOutputStream.java",
        "discussion_id": "2071966473",
        "commented_code": "@@ -0,0 +1,26 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util;\n+\n+import java.io.ByteArrayOutputStream;\n+\n+/** Subclass of ByteArrayOutputStream that exposes `buf` directly. */\n+public final class MyByteArrayOutputStream extends ByteArrayOutputStream {",
        "comment_created_at": "2025-05-02T17:59:48+00:00",
        "comment_author": "mridulm",
        "comment_body": "Rename ? `MyByteArrayOutputStream` was fine when it was internal to the class.\r\nSomething like `ExposedBufferByteArrayOutputStream` or some such ?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2095657080",
    "pr_number": 50933,
    "pr_file": "common/sketch/src/test/java/org/apache/spark/util/sketch/TestSparkBloomFilter.java",
    "created_at": "2025-05-19T12:57:47+00:00",
    "commented_code": "+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.sketch;\n+\n+import org.junit.jupiter.api.*;\n+import org.junit.jupiter.params.provider.ValueSource;\n+import org.junitpioneer.jupiter.cartesian.CartesianTest;\n+import org.junitpioneer.jupiter.cartesian.CartesianTest.Values;\n+\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.stream.Stream;\n+\n+@Disabled\n+public class TestSparkBloomFilter {\n+\n+    // the implemented fpp limit is only approximating the hard boundary,\n+    // so we'll need an error threshold for the assertion\n+    final double FPP_EVEN_ODD_ERROR_FACTOR = 0.05;\n+    final double FPP_RANDOM_ERROR_FACTOR = 0.04;\n+\n+    final long ONE_GB = 1024L * 1024L * 1024L;\n+\n+    private static Instant START;\n+    private Instant start;\n+\n+    @BeforeAll\n+    public static void beforeAll() {\n+        START = Instant.now();\n+    }\n+\n+    @AfterAll\n+    public static void afterAll() {\n+        Duration duration = Duration.between(START, Instant.now());\n+        System.err.println(duration + \" TOTAL\");\n+    }\n+\n+    @BeforeEach\n+    public void beforeEach() {\n+        start = Instant.now();\n+    }\n+\n+    @AfterEach\n+    public void afterEach(TestInfo testInfo) {\n+        Duration duration = Duration.between(start, Instant.now());\n+        System.err.println(duration + \" \" + testInfo.getDisplayName());\n+    }\n+\n+    @CartesianTest\n+    public void testAccuracyEvenOdd(\n+      @Values(longs = {1_000_000L, 1_000_000_000L, 5_000_000_000L}) long numItems,\n+      @Values(doubles = {0.05, 0.03, 0.01, 0.001}) double expectedFpp,\n+      @Values(ints = {BloomFilterImpl.DEFAULT_SEED, 1, 127}) int deterministicSeed\n+    ) {\n+        long optimalNumOfBits = BloomFilter.optimalNumOfBits(numItems, expectedFpp) / Byte.SIZE;\n+        System.err.printf(\n+                \"optimal   bitArray: %d (%d MB)\n\",\n+                optimalNumOfBits,\n+                optimalNumOfBits / Byte.SIZE / 1024 / 1024\n+        );\n+        Assumptions.assumeTrue(\n+                optimalNumOfBits / Byte.SIZE < 4 * ONE_GB,\n+            \"this testcase would require allocating more than 4GB of heap mem (\" + optimalNumOfBits + \" bits)\"\n+        );\n+\n+        BloomFilter bloomFilter = BloomFilter.create(numItems, optimalNumOfBits, deterministicSeed);\n+        System.err.printf(\n+                \"allocated bitArray: %d (%d MB)\n\",\n+                bloomFilter.bitSize(),\n+                bloomFilter.bitSize() / Byte.SIZE / 1024 / 1024\n+        );\n+\n+        for (long i = 0; i < numItems; i++) {\n+            if (i % 10_000_000 == 0) {\n+                System.err.printf(\n+                    \"i: %d, bitCount: %d, saturation: %f\n\",\n+                    i,\n+                    bloomFilter.cardinality(),\n+                    (double) bloomFilter.cardinality() / bloomFilter.bitSize()\n+                );\n+            }\n+            bloomFilter.putLong(2 * i);\n+        }\n+\n+        long mightContainEven = 0;\n+        long mightContainOdd = 0;\n+\n+        for (long i = 0; i < numItems; i++) {\n+            if (i % (numItems / 100) == 0) {\n+                System.err.print(\".\");\n+                System.err.flush();\n+            }\n+\n+            long even = 2 * i;\n+            if (bloomFilter.mightContainLong(even)) {\n+                mightContainEven++;\n+            }\n+\n+            long odd = 2 * i + 1;\n+            if (bloomFilter.mightContainLong(odd)) {\n+                mightContainOdd++;\n+            }\n+        }\n+        System.err.println();\n+\n+        Assertions.assertEquals(\n+                numItems, mightContainEven,\n+                \"mightContainLong must return true for all inserted numbers\"\n+        );\n+\n+        double actualFpp = (double) mightContainOdd / numItems;\n+        double acceptableFpp = expectedFpp * (1 + FPP_EVEN_ODD_ERROR_FACTOR);\n+\n+        System.err.printf(\"expectedFpp:   %f %%\n\", 100 * expectedFpp);\n+        System.err.printf(\"acceptableFpp: %f %%\n\", 100 * acceptableFpp);\n+        System.err.printf(\"actualFpp:     %f %%\n\", 100 * actualFpp);\n+\n+        Assumptions.assumeTrue(\n+                actualFpp <= acceptableFpp,\n+                String.format(\n+                  \"acceptableFpp(%f %%) < actualFpp (%f %%)\",\n+                  100 * acceptableFpp,\n+                  100 * actualFpp\n+                )\n+        );\n+\n+        Assertions.assertTrue(\n+                actualFpp <= acceptableFpp,\n+                String.format(\n+                        \"acceptableFpp(%f %%) < actualFpp (%f %%)\",\n+                        100 * acceptableFpp,\n+                        100 * actualFpp\n+                )\n+        );\n+    }\n+\n+    @CartesianTest\n+    public void testAccuracyRandom(\n+            @Values(longs = {1_000_000L, 1_000_000_000L}) long numItems,\n+            @Values(doubles = {0.05, 0.03, 0.01, 0.001}) double expectedFpp,\n+            @Values(ints = {BloomFilterImpl.DEFAULT_SEED, 1, 127}) int deterministicSeed\n+    ) {\n+        long optimalNumOfBits = BloomFilter.optimalNumOfBits(numItems, expectedFpp);\n+        System.err.printf(\n+                \"optimal   bitArray: %d (%d MB)\n\",\n+                optimalNumOfBits,\n+                optimalNumOfBits / Byte.SIZE / 1024 / 1024\n+        );\n+        Assumptions.assumeTrue(\n+                2 * optimalNumOfBits / Byte.SIZE < 4 * ONE_GB,\n+                \"this testcase would require allocating more than 4GB of heap mem (2x \" + optimalNumOfBits + \" bits)\"\n+        );\n+\n+        BloomFilter bloomFilterPrimary = BloomFilter.create(numItems, optimalNumOfBits, deterministicSeed);\n+        BloomFilter bloomFilterSecondary = BloomFilter.create(numItems, optimalNumOfBits, 0xCAFEBABE);\n+        System.err.printf(\n+                \"allocated bitArray: %d (%d MB)\n\",\n+                bloomFilterPrimary.bitSize(),\n+                bloomFilterPrimary.bitSize() / Byte.SIZE / 1024 / 1024\n+        );\n+\n+\n+        Random pseudoRandom = new Random();\n+        long iterationCount = 2 * numItems;\n+\n+        pseudoRandom.setSeed(deterministicSeed);\n+        for (long i = 0; i < iterationCount; i++) {\n+            if (i % 10_000_000 == 0) {\n+                System.err.printf(\n+                        \"i: %d, bitCount: %d, saturation: %f\n\",\n+                        i,\n+                        bloomFilterPrimary.cardinality(),\n+                        (double) bloomFilterPrimary.cardinality() / bloomFilterPrimary.bitSize()\n+                );\n+            }\n+\n+            long candidate = pseudoRandom.nextLong();\n+            if (i % 2 == 0) {\n+                bloomFilterPrimary.putLong(candidate);\n+                bloomFilterSecondary.putLong(candidate);\n+            }\n+        }\n+\n+        long mightContainEven = 0;",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2095657080",
        "repo_full_name": "apache/spark",
        "pr_number": 50933,
        "pr_file": "common/sketch/src/test/java/org/apache/spark/util/sketch/TestSparkBloomFilter.java",
        "discussion_id": "2095657080",
        "commented_code": "@@ -0,0 +1,259 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.util.sketch;\n+\n+import org.junit.jupiter.api.*;\n+import org.junit.jupiter.params.provider.ValueSource;\n+import org.junitpioneer.jupiter.cartesian.CartesianTest;\n+import org.junitpioneer.jupiter.cartesian.CartesianTest.Values;\n+\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Random;\n+import java.util.stream.Stream;\n+\n+@Disabled\n+public class TestSparkBloomFilter {\n+\n+    // the implemented fpp limit is only approximating the hard boundary,\n+    // so we'll need an error threshold for the assertion\n+    final double FPP_EVEN_ODD_ERROR_FACTOR = 0.05;\n+    final double FPP_RANDOM_ERROR_FACTOR = 0.04;\n+\n+    final long ONE_GB = 1024L * 1024L * 1024L;\n+\n+    private static Instant START;\n+    private Instant start;\n+\n+    @BeforeAll\n+    public static void beforeAll() {\n+        START = Instant.now();\n+    }\n+\n+    @AfterAll\n+    public static void afterAll() {\n+        Duration duration = Duration.between(START, Instant.now());\n+        System.err.println(duration + \" TOTAL\");\n+    }\n+\n+    @BeforeEach\n+    public void beforeEach() {\n+        start = Instant.now();\n+    }\n+\n+    @AfterEach\n+    public void afterEach(TestInfo testInfo) {\n+        Duration duration = Duration.between(start, Instant.now());\n+        System.err.println(duration + \" \" + testInfo.getDisplayName());\n+    }\n+\n+    @CartesianTest\n+    public void testAccuracyEvenOdd(\n+      @Values(longs = {1_000_000L, 1_000_000_000L, 5_000_000_000L}) long numItems,\n+      @Values(doubles = {0.05, 0.03, 0.01, 0.001}) double expectedFpp,\n+      @Values(ints = {BloomFilterImpl.DEFAULT_SEED, 1, 127}) int deterministicSeed\n+    ) {\n+        long optimalNumOfBits = BloomFilter.optimalNumOfBits(numItems, expectedFpp) / Byte.SIZE;\n+        System.err.printf(\n+                \"optimal   bitArray: %d (%d MB)\\n\",\n+                optimalNumOfBits,\n+                optimalNumOfBits / Byte.SIZE / 1024 / 1024\n+        );\n+        Assumptions.assumeTrue(\n+                optimalNumOfBits / Byte.SIZE < 4 * ONE_GB,\n+            \"this testcase would require allocating more than 4GB of heap mem (\" + optimalNumOfBits + \" bits)\"\n+        );\n+\n+        BloomFilter bloomFilter = BloomFilter.create(numItems, optimalNumOfBits, deterministicSeed);\n+        System.err.printf(\n+                \"allocated bitArray: %d (%d MB)\\n\",\n+                bloomFilter.bitSize(),\n+                bloomFilter.bitSize() / Byte.SIZE / 1024 / 1024\n+        );\n+\n+        for (long i = 0; i < numItems; i++) {\n+            if (i % 10_000_000 == 0) {\n+                System.err.printf(\n+                    \"i: %d, bitCount: %d, saturation: %f\\n\",\n+                    i,\n+                    bloomFilter.cardinality(),\n+                    (double) bloomFilter.cardinality() / bloomFilter.bitSize()\n+                );\n+            }\n+            bloomFilter.putLong(2 * i);\n+        }\n+\n+        long mightContainEven = 0;\n+        long mightContainOdd = 0;\n+\n+        for (long i = 0; i < numItems; i++) {\n+            if (i % (numItems / 100) == 0) {\n+                System.err.print(\".\");\n+                System.err.flush();\n+            }\n+\n+            long even = 2 * i;\n+            if (bloomFilter.mightContainLong(even)) {\n+                mightContainEven++;\n+            }\n+\n+            long odd = 2 * i + 1;\n+            if (bloomFilter.mightContainLong(odd)) {\n+                mightContainOdd++;\n+            }\n+        }\n+        System.err.println();\n+\n+        Assertions.assertEquals(\n+                numItems, mightContainEven,\n+                \"mightContainLong must return true for all inserted numbers\"\n+        );\n+\n+        double actualFpp = (double) mightContainOdd / numItems;\n+        double acceptableFpp = expectedFpp * (1 + FPP_EVEN_ODD_ERROR_FACTOR);\n+\n+        System.err.printf(\"expectedFpp:   %f %%\\n\", 100 * expectedFpp);\n+        System.err.printf(\"acceptableFpp: %f %%\\n\", 100 * acceptableFpp);\n+        System.err.printf(\"actualFpp:     %f %%\\n\", 100 * actualFpp);\n+\n+        Assumptions.assumeTrue(\n+                actualFpp <= acceptableFpp,\n+                String.format(\n+                  \"acceptableFpp(%f %%) < actualFpp (%f %%)\",\n+                  100 * acceptableFpp,\n+                  100 * actualFpp\n+                )\n+        );\n+\n+        Assertions.assertTrue(\n+                actualFpp <= acceptableFpp,\n+                String.format(\n+                        \"acceptableFpp(%f %%) < actualFpp (%f %%)\",\n+                        100 * acceptableFpp,\n+                        100 * actualFpp\n+                )\n+        );\n+    }\n+\n+    @CartesianTest\n+    public void testAccuracyRandom(\n+            @Values(longs = {1_000_000L, 1_000_000_000L}) long numItems,\n+            @Values(doubles = {0.05, 0.03, 0.01, 0.001}) double expectedFpp,\n+            @Values(ints = {BloomFilterImpl.DEFAULT_SEED, 1, 127}) int deterministicSeed\n+    ) {\n+        long optimalNumOfBits = BloomFilter.optimalNumOfBits(numItems, expectedFpp);\n+        System.err.printf(\n+                \"optimal   bitArray: %d (%d MB)\\n\",\n+                optimalNumOfBits,\n+                optimalNumOfBits / Byte.SIZE / 1024 / 1024\n+        );\n+        Assumptions.assumeTrue(\n+                2 * optimalNumOfBits / Byte.SIZE < 4 * ONE_GB,\n+                \"this testcase would require allocating more than 4GB of heap mem (2x \" + optimalNumOfBits + \" bits)\"\n+        );\n+\n+        BloomFilter bloomFilterPrimary = BloomFilter.create(numItems, optimalNumOfBits, deterministicSeed);\n+        BloomFilter bloomFilterSecondary = BloomFilter.create(numItems, optimalNumOfBits, 0xCAFEBABE);\n+        System.err.printf(\n+                \"allocated bitArray: %d (%d MB)\\n\",\n+                bloomFilterPrimary.bitSize(),\n+                bloomFilterPrimary.bitSize() / Byte.SIZE / 1024 / 1024\n+        );\n+\n+\n+        Random pseudoRandom = new Random();\n+        long iterationCount = 2 * numItems;\n+\n+        pseudoRandom.setSeed(deterministicSeed);\n+        for (long i = 0; i < iterationCount; i++) {\n+            if (i % 10_000_000 == 0) {\n+                System.err.printf(\n+                        \"i: %d, bitCount: %d, saturation: %f\\n\",\n+                        i,\n+                        bloomFilterPrimary.cardinality(),\n+                        (double) bloomFilterPrimary.cardinality() / bloomFilterPrimary.bitSize()\n+                );\n+            }\n+\n+            long candidate = pseudoRandom.nextLong();\n+            if (i % 2 == 0) {\n+                bloomFilterPrimary.putLong(candidate);\n+                bloomFilterSecondary.putLong(candidate);\n+            }\n+        }\n+\n+        long mightContainEven = 0;",
        "comment_created_at": "2025-05-19T12:57:47+00:00",
        "comment_author": "peter-toth",
        "comment_body": "Please rename these 2 in this test case to clarify that these are actually indices of numbers in a randomly generated stream.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2126596098",
    "pr_number": 50921,
    "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/join/Inner.java",
    "created_at": "2025-06-04T13:23:25+00:00",
    "commented_code": "+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector.join;\n+\n+import org.apache.spark.annotation.Evolving;\n+\n+@Evolving\n+public final class Inner implements JoinType { }",
    "repo_full_name": "apache/spark",
    "discussion_comments": [
      {
        "comment_id": "2126596098",
        "repo_full_name": "apache/spark",
        "pr_number": 50921,
        "pr_file": "sql/catalyst/src/main/java/org/apache/spark/sql/connector/join/Inner.java",
        "discussion_id": "2126596098",
        "commented_code": "@@ -0,0 +1,23 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.spark.sql.connector.join;\n+\n+import org.apache.spark.annotation.Evolving;\n+\n+@Evolving\n+public final class Inner implements JoinType { }",
        "comment_created_at": "2025-06-04T13:23:25+00:00",
        "comment_author": "urosstan-db",
        "comment_body": "It would be good to be more specific here, `Inner` is too generic name\r\n```suggestion\r\npublic final class InnerJoinType implements JoinType { }\r\n```",
        "pr_file_module": null
      }
    ]
  }
]