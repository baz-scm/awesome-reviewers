[
  {
    "discussion_id": "1902248631",
    "pr_number": 372,
    "pr_file": "lib/llm/OpenAIClient.ts",
    "created_at": "2025-01-04T00:21:42+00:00",
    "commented_code": "});\n       }\n     }\n+\n+    if (this.modelName === \"o1\") {\n+      delete options.temperature;",
    "repo_full_name": "browserbase/stagehand",
    "discussion_comments": [
      {
        "comment_id": "1902248631",
        "repo_full_name": "browserbase/stagehand",
        "pr_number": 372,
        "pr_file": "lib/llm/OpenAIClient.ts",
        "discussion_id": "1902248631",
        "commented_code": "@@ -100,9 +100,19 @@ export class OpenAIClient extends LLMClient {\n         });\n       }\n     }\n+\n+    if (this.modelName === \"o1\") {\n+      delete options.temperature;",
        "comment_created_at": "2025-01-04T00:21:42+00:00",
        "comment_author": "kamath",
        "comment_body": "can we instead do something like:\r\n```\r\n{ temperature, top_p, frequency_penalty, presence_penalty, ...options } = options\r\n```\r\n\r\nthen we can log each as being removed since model is o1",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2059273327",
    "pr_number": 698,
    "pr_file": "evals/llm_clients/hn_aisdk.ts",
    "created_at": "2025-04-24T21:38:50+00:00",
    "commented_code": "}) => {\n   const stagehand = new Stagehand({\n     ...stagehandConfig,\n-    llmClient: new AISdkClient({\n-      model: openai(\"gpt-4o-mini\"),\n-    }),\n+    modelName: \"aisdk/openai/gpt-4o-mini\",",
    "repo_full_name": "browserbase/stagehand",
    "discussion_comments": [
      {
        "comment_id": "2059273327",
        "repo_full_name": "browserbase/stagehand",
        "pr_number": 698,
        "pr_file": "evals/llm_clients/hn_aisdk.ts",
        "discussion_id": "2059273327",
        "commented_code": "@@ -12,9 +10,7 @@ export const hn_aisdk: EvalFunction = async ({\n }) => {\n   const stagehand = new Stagehand({\n     ...stagehandConfig,\n-    llmClient: new AISdkClient({\n-      model: openai(\"gpt-4o-mini\"),\n-    }),\n+    modelName: \"aisdk/openai/gpt-4o-mini\",",
        "comment_created_at": "2025-04-24T21:38:50+00:00",
        "comment_author": "miguelg719",
        "comment_body": "```suggestion\r\n    modelName: \"openai/gpt-4o-mini\",\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1962432843",
    "pr_number": 502,
    "pr_file": "lib/llm/LLMProvider.ts",
    "created_at": "2025-02-19T22:01:42+00:00",
    "commented_code": "} from \"../../types/model\";\n import { LLMCache } from \"../cache/LLMCache\";\n import { AnthropicClient } from \"./AnthropicClient\";\n+import { CerebrasClient } from \"./CerebrasClient\";\n import { LLMClient } from \"./LLMClient\";\n import { OpenAIClient } from \"./OpenAIClient\";\n \n const modelToProviderMap: { [key in AvailableModel]: ModelProvider } = {\n   \"gpt-4o\": \"openai\",\n   \"gpt-4o-mini\": \"openai\",\n   \"gpt-4o-2024-08-06\": \"openai\",\n-  \"gpt-4o-2024-11-20\": \"openai\",\n-  \"gpt-4o-2024-05-13\": \"openai\",\n   \"o1-mini\": \"openai\",\n   \"o1-preview\": \"openai\",\n   \"o3-mini\": \"openai\",\n   \"claude-3-5-sonnet-latest\": \"anthropic\",\n   \"claude-3-5-sonnet-20240620\": \"anthropic\",\n   \"claude-3-5-sonnet-20241022\": \"anthropic\",\n+  \"llama-3.3-70b\": \"cerebras\",",
    "repo_full_name": "browserbase/stagehand",
    "discussion_comments": [
      {
        "comment_id": "1962432843",
        "repo_full_name": "browserbase/stagehand",
        "pr_number": 502,
        "pr_file": "lib/llm/LLMProvider.ts",
        "discussion_id": "1962432843",
        "commented_code": "@@ -6,21 +6,22 @@ import {\n } from \"../../types/model\";\n import { LLMCache } from \"../cache/LLMCache\";\n import { AnthropicClient } from \"./AnthropicClient\";\n+import { CerebrasClient } from \"./CerebrasClient\";\n import { LLMClient } from \"./LLMClient\";\n import { OpenAIClient } from \"./OpenAIClient\";\n \n const modelToProviderMap: { [key in AvailableModel]: ModelProvider } = {\n   \"gpt-4o\": \"openai\",\n   \"gpt-4o-mini\": \"openai\",\n   \"gpt-4o-2024-08-06\": \"openai\",\n-  \"gpt-4o-2024-11-20\": \"openai\",\n-  \"gpt-4o-2024-05-13\": \"openai\",\n   \"o1-mini\": \"openai\",\n   \"o1-preview\": \"openai\",\n   \"o3-mini\": \"openai\",\n   \"claude-3-5-sonnet-latest\": \"anthropic\",\n   \"claude-3-5-sonnet-20240620\": \"anthropic\",\n   \"claude-3-5-sonnet-20241022\": \"anthropic\",\n+  \"llama-3.3-70b\": \"cerebras\",",
        "comment_created_at": "2025-02-19T22:01:42+00:00",
        "comment_author": "kamath",
        "comment_body": "can we rename to `cerebras-llama-3.3-70b` or `llama-3.3-70b-cerebras`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1962434284",
    "pr_number": 502,
    "pr_file": "types/model.ts",
    "created_at": "2025-02-19T22:03:02+00:00",
    "commented_code": "import type { ClientOptions as AnthropicClientOptions } from \"@anthropic-ai/sdk\";\n import type { ClientOptions as OpenAIClientOptions } from \"openai\";\n+import type { ClientOptions as CerebrasClientOptions } from \"@cerebras/cerebras_cloud_sdk\";",
    "repo_full_name": "browserbase/stagehand",
    "discussion_comments": [
      {
        "comment_id": "1962434284",
        "repo_full_name": "browserbase/stagehand",
        "pr_number": 502,
        "pr_file": "types/model.ts",
        "discussion_id": "1962434284",
        "commented_code": "@@ -1,26 +1,27 @@\n import type { ClientOptions as AnthropicClientOptions } from \"@anthropic-ai/sdk\";\n import type { ClientOptions as OpenAIClientOptions } from \"openai\";\n+import type { ClientOptions as CerebrasClientOptions } from \"@cerebras/cerebras_cloud_sdk\";",
        "comment_created_at": "2025-02-19T22:03:02+00:00",
        "comment_author": "kamath",
        "comment_body": "need to add `@cerebras/cerebras_cloud_sdk` to package.json -- can we instead use the [openai api](https://inference-docs.cerebras.ai/openai) to avoid an additional dependency?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1855501061",
    "pr_number": 217,
    "pr_file": "lib/llm/LLMProvider.ts",
    "created_at": "2024-11-24T17:45:51+00:00",
    "commented_code": "\"gpt-4o\": \"openai\",",
    "repo_full_name": "browserbase/stagehand",
    "discussion_comments": [
      {
        "comment_id": "1855501061",
        "repo_full_name": "browserbase/stagehand",
        "pr_number": 217,
        "pr_file": "lib/llm/LLMProvider.ts",
        "discussion_id": "1855501061",
        "commented_code": "@@ -17,6 +19,8 @@ export class LLMProvider {\n     \"gpt-4o\": \"openai\",",
        "comment_created_at": "2024-11-24T17:45:51+00:00",
        "comment_author": "kamath",
        "comment_body": "might make sense to have a type called `ModelVendor: \"openai\" | \"anthropic\"` and edit `modelToProviderMap` to have type `{ [key in AvailableModel]: ModelVendor }`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1765790620",
    "pr_number": 59,
    "pr_file": "evals/index.eval.ts",
    "created_at": "2024-09-18T22:10:44+00:00",
    "commented_code": "const { price } = await stagehand.extract({\n     instruction: \"get the price of the peeler\",\n     schema: z.object({ price: z.number().nullable() }),\n+    modelName: \"gpt-4o-2024-08-06\",",
    "repo_full_name": "browserbase/stagehand",
    "discussion_comments": [
      {
        "comment_id": "1765790620",
        "repo_full_name": "browserbase/stagehand",
        "pr_number": 59,
        "pr_file": "evals/index.eval.ts",
        "discussion_id": "1765790620",
        "commented_code": "@@ -83,6 +83,7 @@ const peeler_complex = async () => {\n   const { price } = await stagehand.extract({\n     instruction: \"get the price of the peeler\",\n     schema: z.object({ price: z.number().nullable() }),\n+    modelName: \"gpt-4o-2024-08-06\",",
        "comment_created_at": "2024-09-18T22:10:44+00:00",
        "comment_author": "filip-michalsky",
        "comment_body": "since we are using openAI structured outputs, we need to specify the model name... on 10/2/2024 gpt-4o will repoint to the model supporting the structured outputs.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1764055534",
    "pr_number": 56,
    "pr_file": "lib/index.ts",
    "created_at": "2024-09-17T21:44:40+00:00",
    "commented_code": "return observationId;\n   }\n-  async ask(question: string): Promise<string | null> {\n+  async ask(question: string, model_name: string = \"gpt-4o\"): Promise<string | null> {",
    "repo_full_name": "browserbase/stagehand",
    "discussion_comments": [
      {
        "comment_id": "1764055534",
        "repo_full_name": "browserbase/stagehand",
        "pr_number": 56,
        "pr_file": "lib/index.ts",
        "discussion_id": "1764055534",
        "commented_code": "@@ -265,10 +267,11 @@ export class Stagehand {\n \n     return observationId;\n   }\n-  async ask(question: string): Promise<string | null> {\n+  async ask(question: string, model_name: string = \"gpt-4o\"): Promise<string | null> {",
        "comment_created_at": "2024-09-17T21:44:40+00:00",
        "comment_author": "pkiv",
        "comment_body": "I think the model_name should be optional, with the stagehand.init() command setting the default, and they can override on individual calls if needed. This should be the same for all the other calls. ",
        "pr_file_module": null
      },
      {
        "comment_id": "1764302115",
        "repo_full_name": "browserbase/stagehand",
        "pr_number": 56,
        "pr_file": "lib/index.ts",
        "discussion_id": "1764055534",
        "commented_code": "@@ -265,10 +267,11 @@ export class Stagehand {\n \n     return observationId;\n   }\n-  async ask(question: string): Promise<string | null> {\n+  async ask(question: string, model_name: string = \"gpt-4o\"): Promise<string | null> {",
        "comment_created_at": "2024-09-18T02:07:45+00:00",
        "comment_author": "filip-michalsky",
        "comment_body": "Update. The init now has a default model name which can also be optionally set by the user. the default \"defaults\" to gpt-4o.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1764067713",
    "pr_number": 56,
    "pr_file": "examples/index.ts",
    "created_at": "2024-09-17T21:57:48+00:00",
    "commented_code": "});\n   await stagehand.init();\n   await stagehand.page.goto(\"https://www.nytimes.com/games/wordle/index.html\");\n-  await stagehand.act({ action: \"start the game\" });\n-  await stagehand.act({ action: \"close tutorial popup\" });\n+  await stagehand.act({ action: \"start the game\", model_name: \"gpt-4o\" }); // optionally specify model_name, defaults to \"gpt-4o\"",
    "repo_full_name": "browserbase/stagehand",
    "discussion_comments": [
      {
        "comment_id": "1764067713",
        "repo_full_name": "browserbase/stagehand",
        "pr_number": 56,
        "pr_file": "examples/index.ts",
        "discussion_id": "1764067713",
        "commented_code": "@@ -10,8 +10,8 @@ async function example() {\n   });\n   await stagehand.init();\n   await stagehand.page.goto(\"https://www.nytimes.com/games/wordle/index.html\");\n-  await stagehand.act({ action: \"start the game\" });\n-  await stagehand.act({ action: \"close tutorial popup\" });\n+  await stagehand.act({ action: \"start the game\", model_name: \"gpt-4o\" }); // optionally specify model_name, defaults to \"gpt-4o\"",
        "comment_created_at": "2024-09-17T21:57:48+00:00",
        "comment_author": "pkiv",
        "comment_body": "setting the model on the action level is a bit repetitive. what if we could set the models for act, observe, and extract in the stagehand init function, and allow them to be overriden on a per-function basis?",
        "pr_file_module": null
      },
      {
        "comment_id": "1764302188",
        "repo_full_name": "browserbase/stagehand",
        "pr_number": 56,
        "pr_file": "examples/index.ts",
        "discussion_id": "1764067713",
        "commented_code": "@@ -10,8 +10,8 @@ async function example() {\n   });\n   await stagehand.init();\n   await stagehand.page.goto(\"https://www.nytimes.com/games/wordle/index.html\");\n-  await stagehand.act({ action: \"start the game\" });\n-  await stagehand.act({ action: \"close tutorial popup\" });\n+  await stagehand.act({ action: \"start the game\", model_name: \"gpt-4o\" }); // optionally specify model_name, defaults to \"gpt-4o\"",
        "comment_created_at": "2024-09-18T02:07:56+00:00",
        "comment_author": "filip-michalsky",
        "comment_body": "code DRYed.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1761703714",
    "pr_number": 51,
    "pr_file": "lib/inference.ts",
    "created_at": "2024-09-16T18:59:45+00:00",
    "commented_code": "question: string;\n   client: OpenAI;\n }) {\n+  console.log(\"asking question\", question);\n   const response = await client.chat.completions.create({\n-    model: \"gpt-4o\",\n+    model: \"o1-preview\",",
    "repo_full_name": "browserbase/stagehand",
    "discussion_comments": [
      {
        "comment_id": "1761703714",
        "repo_full_name": "browserbase/stagehand",
        "pr_number": 51,
        "pr_file": "lib/inference.ts",
        "discussion_id": "1761703714",
        "commented_code": "@@ -128,8 +128,22 @@ export async function ask({\n   question: string;\n   client: OpenAI;\n }) {\n+  console.log(\"asking question\", question);\n   const response = await client.chat.completions.create({\n-    model: \"gpt-4o\",\n+    model: \"o1-preview\",",
        "comment_created_at": "2024-09-16T18:59:45+00:00",
        "comment_author": "filip-michalsky",
        "comment_body": "I will push these up into env variable or an LLM router. Will add as an open issue. we shouldn't be hardcoding model names",
        "pr_file_module": null
      }
    ]
  }
]