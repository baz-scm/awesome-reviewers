[
  {
    "discussion_id": "2299671731",
    "pr_number": 58065,
    "pr_file": "rfd/0223-k8s-health-checks.md",
    "created_at": "2025-08-26T03:44:49+00:00",
    "commented_code": "+---\n+authors: Rana Ian (rana.ian@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0223 - Kubernetes Health Checks\n+\n+## Required Approvals\n+\n+- Engineering: @rosstimothy && @creack && @tigrato\n+\n+\n+## What\n+\n+Enable automated Kubernetes cluster health checks that are viewed by the Web UI, Teleport Connect, `tctl` command, and Prometheus metrics.\n+\n+## Why\n+\n+Proxied Kubernetes cluster health may be manually exercised with Kubernetes operations in the Web UI, or `kubectl` command, then observing the result. While effective, manual checking is also slow and unscalable. \n+\n+Automated Kubernetes health checks with new methods of viewing improve maintainability of Teleport Kubernetes clusters, while enabling new scenarios.\n+\n+Automated health checks:\n+- Improve time to observe and resolve Kubernetes cluster errors\n+- Improve manageability of Kubernetes clusters, especially at scale\n+- Improve the enrollment experience for Kubernetes clusters\n+- Enables alerting on unhealthy Kubernetes clusters\n+- Provides feature parity with databases and machine workload identities\n+\n+## Details\n+\n+### UX\n+\n+#### User Story: Web UI - Enrolling Kubernetes Clusters\n+\n+Alice enrolls three Amazon EKS clusters into Teleport through the Web UI.\n+\n+The next day she returns to the Web UI _Resources_ tab to find the Amazon EKS clusters are highlighted with warnings. She clicks on an Amazon EKS tile and a health message is displayed in a side panel.\n+\n+```\n+Kubernetes Cluster Issues\n+\n+3 Teleport Kubernetes clusters report issues.\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: sol\n+  UUID: 52dedbd0-b165-4bf6-9bc3-961f95bf481d\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: jupiter\n+  UUID: bb4dc171-ffa7-4a31-ba8c-7bf91c59e250\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: saturn\n+  UUID: 2be08cb1-56a4-401f-a3f3-c755a73f3ff6\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+```\n+\n+Alice notices that each cluster has a similar 503 message saying etcd is the source of the error.\n+\n+Alice resolves the `etcd` error, and each Amazon EKS cluster returns to a healthy state.\n+\n+As she monitors the Teleport Web UI, she sees each Amazon EKS tile switch from a warning state to a normal state.\n+\n+\n+#### User Story: `tctl` - Configuring a New Health Check\n+\n+Bob reads about Kubernetes health checks in a Teleport changelog, and updates a Teleport cluster to the new major version.\n+\n+Bob runs `tctl get health_check_config/default` from a terminal to view the default health settings.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+```\n+\n+He notices a new `kubernetes_labels` matcher.\n+\n+He vets the Kubernetes health checks in non-production environments.\n+\n+Bob runs `tctl edit health_check_config/default` from a terminal, updating the default settings to exclude Kubernetes health checks from a production environment.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Bob runs `tctl get kube_server/luna` from a terminal, validating that the expected Kubernetes cluster is monitoring health. \n+```yaml\n+kind: kube_server\n+metadata:\n+  expires: \"2025-10-26T00:00:00.000000Z\"\n+  name: luna\n+  revision: 43e96231-faaf-43c3-b9b8-15cf91813389\n+spec:\n+  host_id: 278be63c-c87e-4d7e-a286-86002c7c45c3\n+  hostname: luna\n+status:\n+  target_health:\n+    addr: luna:3027\n+    protocol: TLS\n+    transition_timestamp: \"2025-10-25T00:00:00.000000Z\"\n+    transition_reason: \"healthy threshold reached\"\n+    status: healthy\n+  version: 19.0.0\n+version: v3\n+```\n+\n+\n+#### User Story: Prometheus - Alerting on an Unhealthy Kubernetes Cluster\n+\n+Charlie relies on Prometheus to notify him of outages and calls to action.\n+\n+He reads about Kubernetes cluster health being available with Prometheus metrics.\n+\n+Charlie tests the feature.\n+\n+He enrolls three GKE instances into Teleport.\n+\n+He queries the new Teleport Prometheus health metrics.\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 3, the actual number of healthy Kubernetes clusters\n+```\n+\n+Charlie sets one GKE instance into an unhealthy state and requeries.\n+\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 2, the actual number of healthy Kubernetes clusters\n+```\n+\n+Seeing the metric values returning, he sets up a Prometheus alerting rule.\n+\n+```yaml\n+groups:\n+  - name: teleport_kubernetes\n+    rules:\n+      - alert: KubernetesClusterUnhealthy\n+        expr: |\n+          (teleport_health_resources{type=\"kubernetes\"} - \n+           teleport_health_resources_available{type=\"kubernetes\"}) > 0\n+        for: 5m\n+        labels:\n+          severity: warning\n+          team: platform\n+          component: teleport\n+          service: kubernetes\n+        annotations:\n+          summary: \"{{ $value }} Kubernetes cluster(s) unhealthy in Teleport\"\n+          description: \"Teleport reports {{ $value }} unhealthy Kubernetes cluster(s). This indicates that one or more Kubernetes clusters registered with Teleport are not responding or failing health checks. Check Teleport Web UI or use tctl for details.\"\n+          runbook_url: \"https://wiki.goteleport.com/runbooks/teleport-k8s-unhealthy\"\n+          dashboard_url: \"https://grafana.luna.com/d/teleport-k8s/teleport-kubernetes-health\"\n+          query: 'teleport_health_resources{type=\"kubernetes\"} - teleport_health_resources_available{type=\"kubernetes\"}'\n+```\n+\n+Prometheus alerts him about the unhealthy Kubernetes cluster.\n+\n+Charlie sets the GKE instance into a healthy state and moves on with his day.\n+\n+\n+### Implementation Details\n+\n+Kubernetes health checks are discussed by functional areas of core logic, `tctl` command, Web UI, and Prometheus metrics.\n+\n+#### Core Implementation\n+\n+Teleport Kubernetes health checks use the Teleport `healthcheck` package, and is based on existing [database health check](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#user-content-fn-1-b6df2ad8fd7a63ee3ca0af227e74ab87) design patterns. The `healthcheck` components are written, tested, and in production. The focus and effort for Kubernetes health checks is integrating health checks into the Kubernetes agent, extending existing `healthcheck` mechanisms, and updating the UI.\n+\n+##### Core Configuration\n+\n+A first step to enabling Kubernetes health checks is adding new matchers to the `HealthCheckConfig` service. `HealthCheckConfig` identifies servers which choose to participate in health checking. `HealthCheckConfig` supports databases. Kubernetes additions mirror the database features.\n+\n+The configuration adds matchers `kubernetes_labels` and `kubernetes_labels_expression` which specify labeled Kubernetes clusters. By default, all Kubernetes clusters participate in health checks. Matchers may filter Kubernetes clusters. Deleting the matchers excludes all Kubernetes clusters.\n+\n+An example yaml `health_check_config`:\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Change points for health check configuration:\n+- [api/proto/teleport/healthcheckconfig/v1/health_check_config.proto](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/api/proto/teleport/healthcheckconfig/v1/health_check_config.proto#L59)\n+  - Adds `kubernetes_labels` and `kubernetes_labels_expression` to proto message `Matcher`\n+- [lib/services/health_check_config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/health_check_config.go#L58)\n+  - Adds Kubernetes label matcher validation to function `ValidateHealthCheckConfig()`\n+- [lib/healthcheck/config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/config.go#L35)\n+  - Adds Kubernetes label matcher field to type `healthCheckConfig`, and update functions `newHealthCheckConfig()` and `getLabelMatchers()`\n+- [lib/services/presets.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/presets.go#L830)\n+  - Adds wildcard Kubernetes label matchers to function `NewPresetHealthCheckConfig()`\n+\n+`HealthCheckConfig` is communicated via proxy and cached on a Kubernetes agent. Kubernetes interfaces are updated to support the communication and caching.\n+\n+Change points for communication and caching:\n+- [lib/auth/authclient/api.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/auth/authclient/api.go#L472)\n+  - Adds `services.HealthCheckConfigReader` to interfaces `ReadKubernetesAccessPoint` and `ProxyAccessPoint` \n+- api/types/kubernetes_server.go\n+  - Adds functions `GetTargetHealth()`, `SetTargetHealth()`, `GetTargetHealthStatus()`, and `SetTargetHealthStatus()` to the `KubeServer` interface for implementing interface `services.HealthCheckConfigReader`\n+- [lib/cache/cache.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/cache/cache.go#L356)\n+  - Adds watches for `types.KindHealthCheckConfig` in `ForKubernetes()` and `ForProxy()`\n+- [lib/authz/permissions.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/authz/permissions.go#L1183)\n+  - Adds new rules for `types.KindHealthCheckConfig`\n+\n+Details for configuring `HealthCheckConfig` with interval, timeout, and healthy/unhealthy thresholds are described in the [database health check RFD](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#configuration).\n+\n+\n+##### Core Kubernetes Agent\n+\n+The Kubernetes agent registers one or more Kubernetes clusters, checks the health of proxied Kubernetes clusters, and communicates the health state to the auth server. The agent adds a `healthcheck.Manager` which performs the registration and health check operations. The Kubernetes agent is named `TLSServer`, and is located in [lib/kube/proxy/server.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/kube/proxy/server.go#L187).\n+\n+Change points include:\n+\n+Modifying methods:\n+- `(*TLSServerConfig).CheckAndSetDefaults()` - Initializes the `healthcheck.Manager`\n+- `(*TLSServer).Serve()` - Starts `healthcheck.Manager` \n+- `(*TLSServer).startStaticClustersHeartbeat()` - Registers all Kubernetes clusters for health monitoring\n+- `(*TLSServer).close()` - Unregisters all Kubernetes clusters from health monitoring\n+\n+Adding methods:\n+- `(*TLSServer).startTargetHealth()` - Registers a single Kubernetes cluster for health monitoring\n+- `(*TLSServer).stopTargetHealth()` - Unregisters a single Kubernetes cluster from health monitoring\n+- `(*TLSServer).getTargetHealth()` - Gets health for a single Kubernetes cluster\n+\n+\n+##### Core `healthcheck` Package\n+\n+The `healthcheck` package performs recurring health checks on one or more Teleport resources: databases, Kubernetes clusters, etc. It's a general library that currently supports TCP checks. Adding TLS checks is a focus for Kubernetes. \n+\n+Main change points are:\n+- [lib/healthcheck/worker.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/worker.go#L343)\n+  - Modifying the `dialEndpoint()` function to make TLS requests.\n+\n+[manager.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/manager.go) and [target.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/target.go) have minor changes.\n+\n+Prometheus gauge metrics are added to the `healthcheck` package, and described in the [Prometheus Implementation](#prometheus-implementation).\n+\n+\n+#### Health States\n+\n+A Kubernetes cluster may be in a health state of `unknown`, `healthy` or `unhealthy`.\n+- `unknown` indicates a Kubernetes cluster cannot be contacted\n+- `healthy` indicates a Kubernetes cluster is accepting requests\n+- `unhealthy` indicates an error state, and includes an error message with verbose debugging information, if available\n+\n+See the database health check RFD for [more details](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#health-status).\n+\n+\n+##### Health Check Endpoint\n+\n+> [!NOTE]\n+> Kubernetes health checked at `https://<address>/readyz`\n+\n+> [!IMPORTANT]\n+> Requires Kubernetes v1.16 or higher\n+\n+The Kubernetes API `/readyz` endpoint is selected for health checking, and indicates that a Kubernetes API server is ready to accept requests. Kubernetes serves the endpoint through [TLS by default](https://kubernetes.io/docs/concepts/security/controlling-access/#transport-security).\n+\n+The Kubernetes API offers [several health check endpoints](https://kubernetes.io/docs/reference/using-api/health-checks), as well as TCP checks being available.\n+\n+| Approach        | Description                                              |\n+|-----------------|----------------------------------------------------------|\n+| /readyz         | Ready to accept API requests                             |\n+| /readyz?verbose | Ready to accept API requests (detailed)                  |\n+| /livez          | kube-apiserver process is alive/running                  |\n+| /livez?verbose  | kube-apiserver process is alive/running (detailed)       |\n+| /healthz        | Ambiguously alive or ready. Deprecated in 2019 at v1.16  |\n+| TCP             | Can establish TCP connection to API server port          |\n+\n+Let's explore the options and reasoning for selecting `/readyz`.\n+\n+`/readyz` means that the cluster is accepting API requests, and can be used.\n+\n+`/livez` indicates the Kubernetes kube-apiserver process is alive. API requests may or may not be accepted. There's no implication of whole cluster readiness.\n+\n+`/healthz` is deprecated, and not supported with the Kubernetes health check feature. `/healthz` was [deprecated in September of 2019 with Kubernetes v1.16](https://kubernetes.io/blog/2019/09/18/kubernetes-1-16-release-announcement/). At the time of writing, [Kubernetes is at v1.33](https://kubernetes.io/blog/2025/04/23/kubernetes-v1-33-release/), and six years have passed since v1.16. It seems reasonable not to support the `/healthz` endpoint. The choice then sets up a requirement for customers to use Kubernetes v1.16 or higher with Teleport Kubernetes health checks.\n+\n+Moving on to `TCP`, `TCP` indicates that network connectivity is available. No further knowledge of Kubernetes health would be known. In scenarios where servers don't offer explicit health checks, such as databases, `TCP` may be the only choice. Since Kubernetes offers health checks, we can skip `TCP` checks.\n+\n+So, `/livez` and `TCP` indicate some level of health, but do not necessarily mean the Kubernetes cluster can be used. \n+\n+Let's look at the `verbose` query parameter.\n+\n+`/readyz?verbose` provides a list of Kubernetes modules with `ok / not ok` states. The verbose information is not critical in the common case of a healthy cluster returning a `200` HTTP status code. The verbose information may be helpful to an administrator diagnosing an unhealthy cluster.\n+\n+For efficiency in the common case of a healthy cluster, the `/readyz` endpoint is called and checked for a `200` status code. In nearly all cases we only need to check `200`. The `verbose` body message is not sent, reducing unneeded network, memory, and processor consumption. Also, the Kubernetes authors recommend [relying on the status code](https://kubernetes.io/docs/reference/using-api/health-checks/) for checking state.\n+\n+In the case of non-`200` response codes, a follow-up call to `/readyz?verbose` is made. The follow-up verbose message is appended to a Go error, and eventually forwarded to the Web UI for a Teleport administrator to view.\n+\n+An example `/readyz?verbose` response body for a `503 Service Unavailable` HTTP status code:\n+```\n+[+]ping ok\n+[+]log ok\n+[-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+[+]poststarthook/start-kube-apiserver-admission-initializer ok\n+[+]poststarthook/generic-apiserver-start-informers ok\n+...\n+[+]shutdown ok\n+readyz check failed\n+```\n+\n+Alternatives not chosen:\n+- Providing a blend of fallback health checks with `/readyz` -> `/readyz?verbose` -> `/livez?verbose` -> `TCP`. If each call returned a non-`200` error, a fallback approach could be selected. The scenario would capture as much information as is available for the Teleport administrator. The approach is not selected, as it's seen as over-engineering for minimal return.\n+- Monitoring node and pod health starts to walk into a large universe of Kubernetes observability, which is solved with multiple observability products. It's also worth noting that cluster health is distinct from individual node and pod health. The Kubernetes API server can be healthy and accept requests while individual nodes or pods within the cluster are unhealthy. A cluster may also be in a reduced capacity state where there are a mixture of healthy and unhealthy nodes. These all appear beyond the scope of the RFD. Kubernetes cluster checks provide visibility into resources managed by Teleport, and compliment observability solutions. Various in-depth node and pod metrics are available in observability solutions. The [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics?tab=readme-ov-file#overview) project can be added in [Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/metrics-server.html), [Google GKE](https://cloud.google.com/kubernetes-engine/docs/how-to/kube-state-metrics), and [Azure AKS](https://learn.microsoft.com/en-us/azure/azure-monitor/containers/prometheus-metrics-scrape-default). Detailed Kubernetes metrics may or may not be interesting for a future feature.\n+- Checking Kubernetes node health after a cluster is unhealthy may, or may not provide interesting diagnostic information for a Teleport administrator. That could be done via the Kubernetes API. It would add complexity, and may have limited value. Node health could be obtained with an observability solution like kube-state-metrics. Having a downed node doesn't necessarily imply a cluster is unhealthy; perhaps at reduced capacity, or possibly unhealthy. The complexity grows, and may best be addressed by observability solutions.\n+\n+> [!NOTE]\n+> Node health != Kubernetes cluster health\n+\n+> [!NOTE]\n+> Pod health != Kubernetes cluster health\n+\n+Calling `/readyz` with a fallback to `/readyz?verbose` achieves the objective of providing the `healthy / unhealthy` state, with diagnostics when needed. Once an unhealthy Kubernetes cluster is detected as unhealthy, a Teleport administrator is expected to follow up with other approaches.\n+\n+\n+#### `tctl` Implementation\n+\n+Planned changes to `HealthCheckConfig` percolate to `tctl`. \n+\n+No further changes are made for `tctl`.\n+\n+\n+#### Web UI Implementation\n+\n+Previous planning and implementation work from database health checks makes displaying Kubernetes health checks straight-forward. No new visual design patterns or coding design patterns are necessary. A Kubernetes health check UI implementation has surgical insertion points.\n+\n+`TargetHealth` property is added, and `kube_cluster` if/switch case logic is added in approximately nine files: \n+- [lib/web/apiserver.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/apiserver.go#L3414)\n+- [lib/web/ui/server.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/ui/server.go#L117)\n+- [web/packages/shared/components/UnifiedResources/FilterPanel.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/FilterPanel.tsx#L180)\n+- [web/packages/shared/components/UnifiedResources/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/types.ts#L100)\n+- [web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx#L149)\n+- [web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts#L94)\n+- [web/packages/teleport/src/services/kube/makeKube.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/makeKube.ts#L21)\n+- [web/packages/teleport/src/services/kube/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/types.ts#L21)\n+- [web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx#L560)\n+\n+The Teleport Connect UI is implemented at the same time as the Web UI. Teleport Connect  shares UI components, such as `UnifiedResource`, making the implementation closely related.\n+\n+\n+#### Prometheus Implementation\n+\n+Two Prometheus metrics are added to the `healthcheck` package:\n+\n+- `teleport_health_resources` for the expected number of healthy resources\n+- `teleport_health_resources_available` for the actual number of healthy resources",
    "repo_full_name": "gravitational/teleport",
    "discussion_comments": [
      {
        "comment_id": "2299671731",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58065,
        "pr_file": "rfd/0223-k8s-health-checks.md",
        "discussion_id": "2299671731",
        "commented_code": "@@ -0,0 +1,623 @@\n+---\n+authors: Rana Ian (rana.ian@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0223 - Kubernetes Health Checks\n+\n+## Required Approvals\n+\n+- Engineering: @rosstimothy && @creack && @tigrato\n+\n+\n+## What\n+\n+Enable automated Kubernetes cluster health checks that are viewed by the Web UI, Teleport Connect, `tctl` command, and Prometheus metrics.\n+\n+## Why\n+\n+Proxied Kubernetes cluster health may be manually exercised with Kubernetes operations in the Web UI, or `kubectl` command, then observing the result. While effective, manual checking is also slow and unscalable. \n+\n+Automated Kubernetes health checks with new methods of viewing improve maintainability of Teleport Kubernetes clusters, while enabling new scenarios.\n+\n+Automated health checks:\n+- Improve time to observe and resolve Kubernetes cluster errors\n+- Improve manageability of Kubernetes clusters, especially at scale\n+- Improve the enrollment experience for Kubernetes clusters\n+- Enables alerting on unhealthy Kubernetes clusters\n+- Provides feature parity with databases and machine workload identities\n+\n+## Details\n+\n+### UX\n+\n+#### User Story: Web UI - Enrolling Kubernetes Clusters\n+\n+Alice enrolls three Amazon EKS clusters into Teleport through the Web UI.\n+\n+The next day she returns to the Web UI _Resources_ tab to find the Amazon EKS clusters are highlighted with warnings. She clicks on an Amazon EKS tile and a health message is displayed in a side panel.\n+\n+```\n+Kubernetes Cluster Issues\n+\n+3 Teleport Kubernetes clusters report issues.\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: sol\n+  UUID: 52dedbd0-b165-4bf6-9bc3-961f95bf481d\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: jupiter\n+  UUID: bb4dc171-ffa7-4a31-ba8c-7bf91c59e250\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: saturn\n+  UUID: 2be08cb1-56a4-401f-a3f3-c755a73f3ff6\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+```\n+\n+Alice notices that each cluster has a similar 503 message saying etcd is the source of the error.\n+\n+Alice resolves the `etcd` error, and each Amazon EKS cluster returns to a healthy state.\n+\n+As she monitors the Teleport Web UI, she sees each Amazon EKS tile switch from a warning state to a normal state.\n+\n+\n+#### User Story: `tctl` - Configuring a New Health Check\n+\n+Bob reads about Kubernetes health checks in a Teleport changelog, and updates a Teleport cluster to the new major version.\n+\n+Bob runs `tctl get health_check_config/default` from a terminal to view the default health settings.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+```\n+\n+He notices a new `kubernetes_labels` matcher.\n+\n+He vets the Kubernetes health checks in non-production environments.\n+\n+Bob runs `tctl edit health_check_config/default` from a terminal, updating the default settings to exclude Kubernetes health checks from a production environment.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Bob runs `tctl get kube_server/luna` from a terminal, validating that the expected Kubernetes cluster is monitoring health. \n+```yaml\n+kind: kube_server\n+metadata:\n+  expires: \"2025-10-26T00:00:00.000000Z\"\n+  name: luna\n+  revision: 43e96231-faaf-43c3-b9b8-15cf91813389\n+spec:\n+  host_id: 278be63c-c87e-4d7e-a286-86002c7c45c3\n+  hostname: luna\n+status:\n+  target_health:\n+    addr: luna:3027\n+    protocol: TLS\n+    transition_timestamp: \"2025-10-25T00:00:00.000000Z\"\n+    transition_reason: \"healthy threshold reached\"\n+    status: healthy\n+  version: 19.0.0\n+version: v3\n+```\n+\n+\n+#### User Story: Prometheus - Alerting on an Unhealthy Kubernetes Cluster\n+\n+Charlie relies on Prometheus to notify him of outages and calls to action.\n+\n+He reads about Kubernetes cluster health being available with Prometheus metrics.\n+\n+Charlie tests the feature.\n+\n+He enrolls three GKE instances into Teleport.\n+\n+He queries the new Teleport Prometheus health metrics.\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 3, the actual number of healthy Kubernetes clusters\n+```\n+\n+Charlie sets one GKE instance into an unhealthy state and requeries.\n+\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 2, the actual number of healthy Kubernetes clusters\n+```\n+\n+Seeing the metric values returning, he sets up a Prometheus alerting rule.\n+\n+```yaml\n+groups:\n+  - name: teleport_kubernetes\n+    rules:\n+      - alert: KubernetesClusterUnhealthy\n+        expr: |\n+          (teleport_health_resources{type=\"kubernetes\"} - \n+           teleport_health_resources_available{type=\"kubernetes\"}) > 0\n+        for: 5m\n+        labels:\n+          severity: warning\n+          team: platform\n+          component: teleport\n+          service: kubernetes\n+        annotations:\n+          summary: \"{{ $value }} Kubernetes cluster(s) unhealthy in Teleport\"\n+          description: \"Teleport reports {{ $value }} unhealthy Kubernetes cluster(s). This indicates that one or more Kubernetes clusters registered with Teleport are not responding or failing health checks. Check Teleport Web UI or use tctl for details.\"\n+          runbook_url: \"https://wiki.goteleport.com/runbooks/teleport-k8s-unhealthy\"\n+          dashboard_url: \"https://grafana.luna.com/d/teleport-k8s/teleport-kubernetes-health\"\n+          query: 'teleport_health_resources{type=\"kubernetes\"} - teleport_health_resources_available{type=\"kubernetes\"}'\n+```\n+\n+Prometheus alerts him about the unhealthy Kubernetes cluster.\n+\n+Charlie sets the GKE instance into a healthy state and moves on with his day.\n+\n+\n+### Implementation Details\n+\n+Kubernetes health checks are discussed by functional areas of core logic, `tctl` command, Web UI, and Prometheus metrics.\n+\n+#### Core Implementation\n+\n+Teleport Kubernetes health checks use the Teleport `healthcheck` package, and is based on existing [database health check](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#user-content-fn-1-b6df2ad8fd7a63ee3ca0af227e74ab87) design patterns. The `healthcheck` components are written, tested, and in production. The focus and effort for Kubernetes health checks is integrating health checks into the Kubernetes agent, extending existing `healthcheck` mechanisms, and updating the UI.\n+\n+##### Core Configuration\n+\n+A first step to enabling Kubernetes health checks is adding new matchers to the `HealthCheckConfig` service. `HealthCheckConfig` identifies servers which choose to participate in health checking. `HealthCheckConfig` supports databases. Kubernetes additions mirror the database features.\n+\n+The configuration adds matchers `kubernetes_labels` and `kubernetes_labels_expression` which specify labeled Kubernetes clusters. By default, all Kubernetes clusters participate in health checks. Matchers may filter Kubernetes clusters. Deleting the matchers excludes all Kubernetes clusters.\n+\n+An example yaml `health_check_config`:\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Change points for health check configuration:\n+- [api/proto/teleport/healthcheckconfig/v1/health_check_config.proto](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/api/proto/teleport/healthcheckconfig/v1/health_check_config.proto#L59)\n+  - Adds `kubernetes_labels` and `kubernetes_labels_expression` to proto message `Matcher`\n+- [lib/services/health_check_config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/health_check_config.go#L58)\n+  - Adds Kubernetes label matcher validation to function `ValidateHealthCheckConfig()`\n+- [lib/healthcheck/config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/config.go#L35)\n+  - Adds Kubernetes label matcher field to type `healthCheckConfig`, and update functions `newHealthCheckConfig()` and `getLabelMatchers()`\n+- [lib/services/presets.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/presets.go#L830)\n+  - Adds wildcard Kubernetes label matchers to function `NewPresetHealthCheckConfig()`\n+\n+`HealthCheckConfig` is communicated via proxy and cached on a Kubernetes agent. Kubernetes interfaces are updated to support the communication and caching.\n+\n+Change points for communication and caching:\n+- [lib/auth/authclient/api.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/auth/authclient/api.go#L472)\n+  - Adds `services.HealthCheckConfigReader` to interfaces `ReadKubernetesAccessPoint` and `ProxyAccessPoint` \n+- api/types/kubernetes_server.go\n+  - Adds functions `GetTargetHealth()`, `SetTargetHealth()`, `GetTargetHealthStatus()`, and `SetTargetHealthStatus()` to the `KubeServer` interface for implementing interface `services.HealthCheckConfigReader`\n+- [lib/cache/cache.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/cache/cache.go#L356)\n+  - Adds watches for `types.KindHealthCheckConfig` in `ForKubernetes()` and `ForProxy()`\n+- [lib/authz/permissions.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/authz/permissions.go#L1183)\n+  - Adds new rules for `types.KindHealthCheckConfig`\n+\n+Details for configuring `HealthCheckConfig` with interval, timeout, and healthy/unhealthy thresholds are described in the [database health check RFD](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#configuration).\n+\n+\n+##### Core Kubernetes Agent\n+\n+The Kubernetes agent registers one or more Kubernetes clusters, checks the health of proxied Kubernetes clusters, and communicates the health state to the auth server. The agent adds a `healthcheck.Manager` which performs the registration and health check operations. The Kubernetes agent is named `TLSServer`, and is located in [lib/kube/proxy/server.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/kube/proxy/server.go#L187).\n+\n+Change points include:\n+\n+Modifying methods:\n+- `(*TLSServerConfig).CheckAndSetDefaults()` - Initializes the `healthcheck.Manager`\n+- `(*TLSServer).Serve()` - Starts `healthcheck.Manager` \n+- `(*TLSServer).startStaticClustersHeartbeat()` - Registers all Kubernetes clusters for health monitoring\n+- `(*TLSServer).close()` - Unregisters all Kubernetes clusters from health monitoring\n+\n+Adding methods:\n+- `(*TLSServer).startTargetHealth()` - Registers a single Kubernetes cluster for health monitoring\n+- `(*TLSServer).stopTargetHealth()` - Unregisters a single Kubernetes cluster from health monitoring\n+- `(*TLSServer).getTargetHealth()` - Gets health for a single Kubernetes cluster\n+\n+\n+##### Core `healthcheck` Package\n+\n+The `healthcheck` package performs recurring health checks on one or more Teleport resources: databases, Kubernetes clusters, etc. It's a general library that currently supports TCP checks. Adding TLS checks is a focus for Kubernetes. \n+\n+Main change points are:\n+- [lib/healthcheck/worker.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/worker.go#L343)\n+  - Modifying the `dialEndpoint()` function to make TLS requests.\n+\n+[manager.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/manager.go) and [target.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/target.go) have minor changes.\n+\n+Prometheus gauge metrics are added to the `healthcheck` package, and described in the [Prometheus Implementation](#prometheus-implementation).\n+\n+\n+#### Health States\n+\n+A Kubernetes cluster may be in a health state of `unknown`, `healthy` or `unhealthy`.\n+- `unknown` indicates a Kubernetes cluster cannot be contacted\n+- `healthy` indicates a Kubernetes cluster is accepting requests\n+- `unhealthy` indicates an error state, and includes an error message with verbose debugging information, if available\n+\n+See the database health check RFD for [more details](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#health-status).\n+\n+\n+##### Health Check Endpoint\n+\n+> [!NOTE]\n+> Kubernetes health checked at `https://<address>/readyz`\n+\n+> [!IMPORTANT]\n+> Requires Kubernetes v1.16 or higher\n+\n+The Kubernetes API `/readyz` endpoint is selected for health checking, and indicates that a Kubernetes API server is ready to accept requests. Kubernetes serves the endpoint through [TLS by default](https://kubernetes.io/docs/concepts/security/controlling-access/#transport-security).\n+\n+The Kubernetes API offers [several health check endpoints](https://kubernetes.io/docs/reference/using-api/health-checks), as well as TCP checks being available.\n+\n+| Approach        | Description                                              |\n+|-----------------|----------------------------------------------------------|\n+| /readyz         | Ready to accept API requests                             |\n+| /readyz?verbose | Ready to accept API requests (detailed)                  |\n+| /livez          | kube-apiserver process is alive/running                  |\n+| /livez?verbose  | kube-apiserver process is alive/running (detailed)       |\n+| /healthz        | Ambiguously alive or ready. Deprecated in 2019 at v1.16  |\n+| TCP             | Can establish TCP connection to API server port          |\n+\n+Let's explore the options and reasoning for selecting `/readyz`.\n+\n+`/readyz` means that the cluster is accepting API requests, and can be used.\n+\n+`/livez` indicates the Kubernetes kube-apiserver process is alive. API requests may or may not be accepted. There's no implication of whole cluster readiness.\n+\n+`/healthz` is deprecated, and not supported with the Kubernetes health check feature. `/healthz` was [deprecated in September of 2019 with Kubernetes v1.16](https://kubernetes.io/blog/2019/09/18/kubernetes-1-16-release-announcement/). At the time of writing, [Kubernetes is at v1.33](https://kubernetes.io/blog/2025/04/23/kubernetes-v1-33-release/), and six years have passed since v1.16. It seems reasonable not to support the `/healthz` endpoint. The choice then sets up a requirement for customers to use Kubernetes v1.16 or higher with Teleport Kubernetes health checks.\n+\n+Moving on to `TCP`, `TCP` indicates that network connectivity is available. No further knowledge of Kubernetes health would be known. In scenarios where servers don't offer explicit health checks, such as databases, `TCP` may be the only choice. Since Kubernetes offers health checks, we can skip `TCP` checks.\n+\n+So, `/livez` and `TCP` indicate some level of health, but do not necessarily mean the Kubernetes cluster can be used. \n+\n+Let's look at the `verbose` query parameter.\n+\n+`/readyz?verbose` provides a list of Kubernetes modules with `ok / not ok` states. The verbose information is not critical in the common case of a healthy cluster returning a `200` HTTP status code. The verbose information may be helpful to an administrator diagnosing an unhealthy cluster.\n+\n+For efficiency in the common case of a healthy cluster, the `/readyz` endpoint is called and checked for a `200` status code. In nearly all cases we only need to check `200`. The `verbose` body message is not sent, reducing unneeded network, memory, and processor consumption. Also, the Kubernetes authors recommend [relying on the status code](https://kubernetes.io/docs/reference/using-api/health-checks/) for checking state.\n+\n+In the case of non-`200` response codes, a follow-up call to `/readyz?verbose` is made. The follow-up verbose message is appended to a Go error, and eventually forwarded to the Web UI for a Teleport administrator to view.\n+\n+An example `/readyz?verbose` response body for a `503 Service Unavailable` HTTP status code:\n+```\n+[+]ping ok\n+[+]log ok\n+[-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+[+]poststarthook/start-kube-apiserver-admission-initializer ok\n+[+]poststarthook/generic-apiserver-start-informers ok\n+...\n+[+]shutdown ok\n+readyz check failed\n+```\n+\n+Alternatives not chosen:\n+- Providing a blend of fallback health checks with `/readyz` -> `/readyz?verbose` -> `/livez?verbose` -> `TCP`. If each call returned a non-`200` error, a fallback approach could be selected. The scenario would capture as much information as is available for the Teleport administrator. The approach is not selected, as it's seen as over-engineering for minimal return.\n+- Monitoring node and pod health starts to walk into a large universe of Kubernetes observability, which is solved with multiple observability products. It's also worth noting that cluster health is distinct from individual node and pod health. The Kubernetes API server can be healthy and accept requests while individual nodes or pods within the cluster are unhealthy. A cluster may also be in a reduced capacity state where there are a mixture of healthy and unhealthy nodes. These all appear beyond the scope of the RFD. Kubernetes cluster checks provide visibility into resources managed by Teleport, and compliment observability solutions. Various in-depth node and pod metrics are available in observability solutions. The [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics?tab=readme-ov-file#overview) project can be added in [Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/metrics-server.html), [Google GKE](https://cloud.google.com/kubernetes-engine/docs/how-to/kube-state-metrics), and [Azure AKS](https://learn.microsoft.com/en-us/azure/azure-monitor/containers/prometheus-metrics-scrape-default). Detailed Kubernetes metrics may or may not be interesting for a future feature.\n+- Checking Kubernetes node health after a cluster is unhealthy may, or may not provide interesting diagnostic information for a Teleport administrator. That could be done via the Kubernetes API. It would add complexity, and may have limited value. Node health could be obtained with an observability solution like kube-state-metrics. Having a downed node doesn't necessarily imply a cluster is unhealthy; perhaps at reduced capacity, or possibly unhealthy. The complexity grows, and may best be addressed by observability solutions.\n+\n+> [!NOTE]\n+> Node health != Kubernetes cluster health\n+\n+> [!NOTE]\n+> Pod health != Kubernetes cluster health\n+\n+Calling `/readyz` with a fallback to `/readyz?verbose` achieves the objective of providing the `healthy / unhealthy` state, with diagnostics when needed. Once an unhealthy Kubernetes cluster is detected as unhealthy, a Teleport administrator is expected to follow up with other approaches.\n+\n+\n+#### `tctl` Implementation\n+\n+Planned changes to `HealthCheckConfig` percolate to `tctl`. \n+\n+No further changes are made for `tctl`.\n+\n+\n+#### Web UI Implementation\n+\n+Previous planning and implementation work from database health checks makes displaying Kubernetes health checks straight-forward. No new visual design patterns or coding design patterns are necessary. A Kubernetes health check UI implementation has surgical insertion points.\n+\n+`TargetHealth` property is added, and `kube_cluster` if/switch case logic is added in approximately nine files: \n+- [lib/web/apiserver.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/apiserver.go#L3414)\n+- [lib/web/ui/server.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/ui/server.go#L117)\n+- [web/packages/shared/components/UnifiedResources/FilterPanel.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/FilterPanel.tsx#L180)\n+- [web/packages/shared/components/UnifiedResources/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/types.ts#L100)\n+- [web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx#L149)\n+- [web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts#L94)\n+- [web/packages/teleport/src/services/kube/makeKube.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/makeKube.ts#L21)\n+- [web/packages/teleport/src/services/kube/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/types.ts#L21)\n+- [web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx#L560)\n+\n+The Teleport Connect UI is implemented at the same time as the Web UI. Teleport Connect  shares UI components, such as `UnifiedResource`, making the implementation closely related.\n+\n+\n+#### Prometheus Implementation\n+\n+Two Prometheus metrics are added to the `healthcheck` package:\n+\n+- `teleport_health_resources` for the expected number of healthy resources\n+- `teleport_health_resources_available` for the actual number of healthy resources",
        "comment_created_at": "2025-08-26T03:44:49+00:00",
        "comment_author": "GavinFrazar",
        "comment_body": "nit: naming is hard as Tim pointed out already, but I'll add my own suggestion:\r\n\r\n```suggestion\r\n- `teleport_resource_health_check_targets` for the expected number of healthy resources\r\n- `teleport_resource_health_check_targets_available` for the actual number of healthy resources\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2299674610",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58065,
        "pr_file": "rfd/0223-k8s-health-checks.md",
        "discussion_id": "2299671731",
        "commented_code": "@@ -0,0 +1,623 @@\n+---\n+authors: Rana Ian (rana.ian@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0223 - Kubernetes Health Checks\n+\n+## Required Approvals\n+\n+- Engineering: @rosstimothy && @creack && @tigrato\n+\n+\n+## What\n+\n+Enable automated Kubernetes cluster health checks that are viewed by the Web UI, Teleport Connect, `tctl` command, and Prometheus metrics.\n+\n+## Why\n+\n+Proxied Kubernetes cluster health may be manually exercised with Kubernetes operations in the Web UI, or `kubectl` command, then observing the result. While effective, manual checking is also slow and unscalable. \n+\n+Automated Kubernetes health checks with new methods of viewing improve maintainability of Teleport Kubernetes clusters, while enabling new scenarios.\n+\n+Automated health checks:\n+- Improve time to observe and resolve Kubernetes cluster errors\n+- Improve manageability of Kubernetes clusters, especially at scale\n+- Improve the enrollment experience for Kubernetes clusters\n+- Enables alerting on unhealthy Kubernetes clusters\n+- Provides feature parity with databases and machine workload identities\n+\n+## Details\n+\n+### UX\n+\n+#### User Story: Web UI - Enrolling Kubernetes Clusters\n+\n+Alice enrolls three Amazon EKS clusters into Teleport through the Web UI.\n+\n+The next day she returns to the Web UI _Resources_ tab to find the Amazon EKS clusters are highlighted with warnings. She clicks on an Amazon EKS tile and a health message is displayed in a side panel.\n+\n+```\n+Kubernetes Cluster Issues\n+\n+3 Teleport Kubernetes clusters report issues.\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: sol\n+  UUID: 52dedbd0-b165-4bf6-9bc3-961f95bf481d\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: jupiter\n+  UUID: bb4dc171-ffa7-4a31-ba8c-7bf91c59e250\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: saturn\n+  UUID: 2be08cb1-56a4-401f-a3f3-c755a73f3ff6\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+```\n+\n+Alice notices that each cluster has a similar 503 message saying etcd is the source of the error.\n+\n+Alice resolves the `etcd` error, and each Amazon EKS cluster returns to a healthy state.\n+\n+As she monitors the Teleport Web UI, she sees each Amazon EKS tile switch from a warning state to a normal state.\n+\n+\n+#### User Story: `tctl` - Configuring a New Health Check\n+\n+Bob reads about Kubernetes health checks in a Teleport changelog, and updates a Teleport cluster to the new major version.\n+\n+Bob runs `tctl get health_check_config/default` from a terminal to view the default health settings.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+```\n+\n+He notices a new `kubernetes_labels` matcher.\n+\n+He vets the Kubernetes health checks in non-production environments.\n+\n+Bob runs `tctl edit health_check_config/default` from a terminal, updating the default settings to exclude Kubernetes health checks from a production environment.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Bob runs `tctl get kube_server/luna` from a terminal, validating that the expected Kubernetes cluster is monitoring health. \n+```yaml\n+kind: kube_server\n+metadata:\n+  expires: \"2025-10-26T00:00:00.000000Z\"\n+  name: luna\n+  revision: 43e96231-faaf-43c3-b9b8-15cf91813389\n+spec:\n+  host_id: 278be63c-c87e-4d7e-a286-86002c7c45c3\n+  hostname: luna\n+status:\n+  target_health:\n+    addr: luna:3027\n+    protocol: TLS\n+    transition_timestamp: \"2025-10-25T00:00:00.000000Z\"\n+    transition_reason: \"healthy threshold reached\"\n+    status: healthy\n+  version: 19.0.0\n+version: v3\n+```\n+\n+\n+#### User Story: Prometheus - Alerting on an Unhealthy Kubernetes Cluster\n+\n+Charlie relies on Prometheus to notify him of outages and calls to action.\n+\n+He reads about Kubernetes cluster health being available with Prometheus metrics.\n+\n+Charlie tests the feature.\n+\n+He enrolls three GKE instances into Teleport.\n+\n+He queries the new Teleport Prometheus health metrics.\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 3, the actual number of healthy Kubernetes clusters\n+```\n+\n+Charlie sets one GKE instance into an unhealthy state and requeries.\n+\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 2, the actual number of healthy Kubernetes clusters\n+```\n+\n+Seeing the metric values returning, he sets up a Prometheus alerting rule.\n+\n+```yaml\n+groups:\n+  - name: teleport_kubernetes\n+    rules:\n+      - alert: KubernetesClusterUnhealthy\n+        expr: |\n+          (teleport_health_resources{type=\"kubernetes\"} - \n+           teleport_health_resources_available{type=\"kubernetes\"}) > 0\n+        for: 5m\n+        labels:\n+          severity: warning\n+          team: platform\n+          component: teleport\n+          service: kubernetes\n+        annotations:\n+          summary: \"{{ $value }} Kubernetes cluster(s) unhealthy in Teleport\"\n+          description: \"Teleport reports {{ $value }} unhealthy Kubernetes cluster(s). This indicates that one or more Kubernetes clusters registered with Teleport are not responding or failing health checks. Check Teleport Web UI or use tctl for details.\"\n+          runbook_url: \"https://wiki.goteleport.com/runbooks/teleport-k8s-unhealthy\"\n+          dashboard_url: \"https://grafana.luna.com/d/teleport-k8s/teleport-kubernetes-health\"\n+          query: 'teleport_health_resources{type=\"kubernetes\"} - teleport_health_resources_available{type=\"kubernetes\"}'\n+```\n+\n+Prometheus alerts him about the unhealthy Kubernetes cluster.\n+\n+Charlie sets the GKE instance into a healthy state and moves on with his day.\n+\n+\n+### Implementation Details\n+\n+Kubernetes health checks are discussed by functional areas of core logic, `tctl` command, Web UI, and Prometheus metrics.\n+\n+#### Core Implementation\n+\n+Teleport Kubernetes health checks use the Teleport `healthcheck` package, and is based on existing [database health check](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#user-content-fn-1-b6df2ad8fd7a63ee3ca0af227e74ab87) design patterns. The `healthcheck` components are written, tested, and in production. The focus and effort for Kubernetes health checks is integrating health checks into the Kubernetes agent, extending existing `healthcheck` mechanisms, and updating the UI.\n+\n+##### Core Configuration\n+\n+A first step to enabling Kubernetes health checks is adding new matchers to the `HealthCheckConfig` service. `HealthCheckConfig` identifies servers which choose to participate in health checking. `HealthCheckConfig` supports databases. Kubernetes additions mirror the database features.\n+\n+The configuration adds matchers `kubernetes_labels` and `kubernetes_labels_expression` which specify labeled Kubernetes clusters. By default, all Kubernetes clusters participate in health checks. Matchers may filter Kubernetes clusters. Deleting the matchers excludes all Kubernetes clusters.\n+\n+An example yaml `health_check_config`:\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Change points for health check configuration:\n+- [api/proto/teleport/healthcheckconfig/v1/health_check_config.proto](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/api/proto/teleport/healthcheckconfig/v1/health_check_config.proto#L59)\n+  - Adds `kubernetes_labels` and `kubernetes_labels_expression` to proto message `Matcher`\n+- [lib/services/health_check_config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/health_check_config.go#L58)\n+  - Adds Kubernetes label matcher validation to function `ValidateHealthCheckConfig()`\n+- [lib/healthcheck/config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/config.go#L35)\n+  - Adds Kubernetes label matcher field to type `healthCheckConfig`, and update functions `newHealthCheckConfig()` and `getLabelMatchers()`\n+- [lib/services/presets.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/presets.go#L830)\n+  - Adds wildcard Kubernetes label matchers to function `NewPresetHealthCheckConfig()`\n+\n+`HealthCheckConfig` is communicated via proxy and cached on a Kubernetes agent. Kubernetes interfaces are updated to support the communication and caching.\n+\n+Change points for communication and caching:\n+- [lib/auth/authclient/api.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/auth/authclient/api.go#L472)\n+  - Adds `services.HealthCheckConfigReader` to interfaces `ReadKubernetesAccessPoint` and `ProxyAccessPoint` \n+- api/types/kubernetes_server.go\n+  - Adds functions `GetTargetHealth()`, `SetTargetHealth()`, `GetTargetHealthStatus()`, and `SetTargetHealthStatus()` to the `KubeServer` interface for implementing interface `services.HealthCheckConfigReader`\n+- [lib/cache/cache.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/cache/cache.go#L356)\n+  - Adds watches for `types.KindHealthCheckConfig` in `ForKubernetes()` and `ForProxy()`\n+- [lib/authz/permissions.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/authz/permissions.go#L1183)\n+  - Adds new rules for `types.KindHealthCheckConfig`\n+\n+Details for configuring `HealthCheckConfig` with interval, timeout, and healthy/unhealthy thresholds are described in the [database health check RFD](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#configuration).\n+\n+\n+##### Core Kubernetes Agent\n+\n+The Kubernetes agent registers one or more Kubernetes clusters, checks the health of proxied Kubernetes clusters, and communicates the health state to the auth server. The agent adds a `healthcheck.Manager` which performs the registration and health check operations. The Kubernetes agent is named `TLSServer`, and is located in [lib/kube/proxy/server.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/kube/proxy/server.go#L187).\n+\n+Change points include:\n+\n+Modifying methods:\n+- `(*TLSServerConfig).CheckAndSetDefaults()` - Initializes the `healthcheck.Manager`\n+- `(*TLSServer).Serve()` - Starts `healthcheck.Manager` \n+- `(*TLSServer).startStaticClustersHeartbeat()` - Registers all Kubernetes clusters for health monitoring\n+- `(*TLSServer).close()` - Unregisters all Kubernetes clusters from health monitoring\n+\n+Adding methods:\n+- `(*TLSServer).startTargetHealth()` - Registers a single Kubernetes cluster for health monitoring\n+- `(*TLSServer).stopTargetHealth()` - Unregisters a single Kubernetes cluster from health monitoring\n+- `(*TLSServer).getTargetHealth()` - Gets health for a single Kubernetes cluster\n+\n+\n+##### Core `healthcheck` Package\n+\n+The `healthcheck` package performs recurring health checks on one or more Teleport resources: databases, Kubernetes clusters, etc. It's a general library that currently supports TCP checks. Adding TLS checks is a focus for Kubernetes. \n+\n+Main change points are:\n+- [lib/healthcheck/worker.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/worker.go#L343)\n+  - Modifying the `dialEndpoint()` function to make TLS requests.\n+\n+[manager.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/manager.go) and [target.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/target.go) have minor changes.\n+\n+Prometheus gauge metrics are added to the `healthcheck` package, and described in the [Prometheus Implementation](#prometheus-implementation).\n+\n+\n+#### Health States\n+\n+A Kubernetes cluster may be in a health state of `unknown`, `healthy` or `unhealthy`.\n+- `unknown` indicates a Kubernetes cluster cannot be contacted\n+- `healthy` indicates a Kubernetes cluster is accepting requests\n+- `unhealthy` indicates an error state, and includes an error message with verbose debugging information, if available\n+\n+See the database health check RFD for [more details](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#health-status).\n+\n+\n+##### Health Check Endpoint\n+\n+> [!NOTE]\n+> Kubernetes health checked at `https://<address>/readyz`\n+\n+> [!IMPORTANT]\n+> Requires Kubernetes v1.16 or higher\n+\n+The Kubernetes API `/readyz` endpoint is selected for health checking, and indicates that a Kubernetes API server is ready to accept requests. Kubernetes serves the endpoint through [TLS by default](https://kubernetes.io/docs/concepts/security/controlling-access/#transport-security).\n+\n+The Kubernetes API offers [several health check endpoints](https://kubernetes.io/docs/reference/using-api/health-checks), as well as TCP checks being available.\n+\n+| Approach        | Description                                              |\n+|-----------------|----------------------------------------------------------|\n+| /readyz         | Ready to accept API requests                             |\n+| /readyz?verbose | Ready to accept API requests (detailed)                  |\n+| /livez          | kube-apiserver process is alive/running                  |\n+| /livez?verbose  | kube-apiserver process is alive/running (detailed)       |\n+| /healthz        | Ambiguously alive or ready. Deprecated in 2019 at v1.16  |\n+| TCP             | Can establish TCP connection to API server port          |\n+\n+Let's explore the options and reasoning for selecting `/readyz`.\n+\n+`/readyz` means that the cluster is accepting API requests, and can be used.\n+\n+`/livez` indicates the Kubernetes kube-apiserver process is alive. API requests may or may not be accepted. There's no implication of whole cluster readiness.\n+\n+`/healthz` is deprecated, and not supported with the Kubernetes health check feature. `/healthz` was [deprecated in September of 2019 with Kubernetes v1.16](https://kubernetes.io/blog/2019/09/18/kubernetes-1-16-release-announcement/). At the time of writing, [Kubernetes is at v1.33](https://kubernetes.io/blog/2025/04/23/kubernetes-v1-33-release/), and six years have passed since v1.16. It seems reasonable not to support the `/healthz` endpoint. The choice then sets up a requirement for customers to use Kubernetes v1.16 or higher with Teleport Kubernetes health checks.\n+\n+Moving on to `TCP`, `TCP` indicates that network connectivity is available. No further knowledge of Kubernetes health would be known. In scenarios where servers don't offer explicit health checks, such as databases, `TCP` may be the only choice. Since Kubernetes offers health checks, we can skip `TCP` checks.\n+\n+So, `/livez` and `TCP` indicate some level of health, but do not necessarily mean the Kubernetes cluster can be used. \n+\n+Let's look at the `verbose` query parameter.\n+\n+`/readyz?verbose` provides a list of Kubernetes modules with `ok / not ok` states. The verbose information is not critical in the common case of a healthy cluster returning a `200` HTTP status code. The verbose information may be helpful to an administrator diagnosing an unhealthy cluster.\n+\n+For efficiency in the common case of a healthy cluster, the `/readyz` endpoint is called and checked for a `200` status code. In nearly all cases we only need to check `200`. The `verbose` body message is not sent, reducing unneeded network, memory, and processor consumption. Also, the Kubernetes authors recommend [relying on the status code](https://kubernetes.io/docs/reference/using-api/health-checks/) for checking state.\n+\n+In the case of non-`200` response codes, a follow-up call to `/readyz?verbose` is made. The follow-up verbose message is appended to a Go error, and eventually forwarded to the Web UI for a Teleport administrator to view.\n+\n+An example `/readyz?verbose` response body for a `503 Service Unavailable` HTTP status code:\n+```\n+[+]ping ok\n+[+]log ok\n+[-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+[+]poststarthook/start-kube-apiserver-admission-initializer ok\n+[+]poststarthook/generic-apiserver-start-informers ok\n+...\n+[+]shutdown ok\n+readyz check failed\n+```\n+\n+Alternatives not chosen:\n+- Providing a blend of fallback health checks with `/readyz` -> `/readyz?verbose` -> `/livez?verbose` -> `TCP`. If each call returned a non-`200` error, a fallback approach could be selected. The scenario would capture as much information as is available for the Teleport administrator. The approach is not selected, as it's seen as over-engineering for minimal return.\n+- Monitoring node and pod health starts to walk into a large universe of Kubernetes observability, which is solved with multiple observability products. It's also worth noting that cluster health is distinct from individual node and pod health. The Kubernetes API server can be healthy and accept requests while individual nodes or pods within the cluster are unhealthy. A cluster may also be in a reduced capacity state where there are a mixture of healthy and unhealthy nodes. These all appear beyond the scope of the RFD. Kubernetes cluster checks provide visibility into resources managed by Teleport, and compliment observability solutions. Various in-depth node and pod metrics are available in observability solutions. The [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics?tab=readme-ov-file#overview) project can be added in [Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/metrics-server.html), [Google GKE](https://cloud.google.com/kubernetes-engine/docs/how-to/kube-state-metrics), and [Azure AKS](https://learn.microsoft.com/en-us/azure/azure-monitor/containers/prometheus-metrics-scrape-default). Detailed Kubernetes metrics may or may not be interesting for a future feature.\n+- Checking Kubernetes node health after a cluster is unhealthy may, or may not provide interesting diagnostic information for a Teleport administrator. That could be done via the Kubernetes API. It would add complexity, and may have limited value. Node health could be obtained with an observability solution like kube-state-metrics. Having a downed node doesn't necessarily imply a cluster is unhealthy; perhaps at reduced capacity, or possibly unhealthy. The complexity grows, and may best be addressed by observability solutions.\n+\n+> [!NOTE]\n+> Node health != Kubernetes cluster health\n+\n+> [!NOTE]\n+> Pod health != Kubernetes cluster health\n+\n+Calling `/readyz` with a fallback to `/readyz?verbose` achieves the objective of providing the `healthy / unhealthy` state, with diagnostics when needed. Once an unhealthy Kubernetes cluster is detected as unhealthy, a Teleport administrator is expected to follow up with other approaches.\n+\n+\n+#### `tctl` Implementation\n+\n+Planned changes to `HealthCheckConfig` percolate to `tctl`. \n+\n+No further changes are made for `tctl`.\n+\n+\n+#### Web UI Implementation\n+\n+Previous planning and implementation work from database health checks makes displaying Kubernetes health checks straight-forward. No new visual design patterns or coding design patterns are necessary. A Kubernetes health check UI implementation has surgical insertion points.\n+\n+`TargetHealth` property is added, and `kube_cluster` if/switch case logic is added in approximately nine files: \n+- [lib/web/apiserver.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/apiserver.go#L3414)\n+- [lib/web/ui/server.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/ui/server.go#L117)\n+- [web/packages/shared/components/UnifiedResources/FilterPanel.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/FilterPanel.tsx#L180)\n+- [web/packages/shared/components/UnifiedResources/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/types.ts#L100)\n+- [web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx#L149)\n+- [web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts#L94)\n+- [web/packages/teleport/src/services/kube/makeKube.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/makeKube.ts#L21)\n+- [web/packages/teleport/src/services/kube/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/types.ts#L21)\n+- [web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx#L560)\n+\n+The Teleport Connect UI is implemented at the same time as the Web UI. Teleport Connect  shares UI components, such as `UnifiedResource`, making the implementation closely related.\n+\n+\n+#### Prometheus Implementation\n+\n+Two Prometheus metrics are added to the `healthcheck` package:\n+\n+- `teleport_health_resources` for the expected number of healthy resources\n+- `teleport_health_resources_available` for the actual number of healthy resources",
        "comment_created_at": "2025-08-26T03:47:26+00:00",
        "comment_author": "GavinFrazar",
        "comment_body": "also what do you think about splitting \"_available\" into \"_healthy\" and \"_unhealthy?\r\n\r\nThere's 3 health states, so doing this will allow them to disambiguate unhealthy/unknown targets.",
        "pr_file_module": null
      },
      {
        "comment_id": "2301259755",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58065,
        "pr_file": "rfd/0223-k8s-health-checks.md",
        "discussion_id": "2299671731",
        "commented_code": "@@ -0,0 +1,623 @@\n+---\n+authors: Rana Ian (rana.ian@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0223 - Kubernetes Health Checks\n+\n+## Required Approvals\n+\n+- Engineering: @rosstimothy && @creack && @tigrato\n+\n+\n+## What\n+\n+Enable automated Kubernetes cluster health checks that are viewed by the Web UI, Teleport Connect, `tctl` command, and Prometheus metrics.\n+\n+## Why\n+\n+Proxied Kubernetes cluster health may be manually exercised with Kubernetes operations in the Web UI, or `kubectl` command, then observing the result. While effective, manual checking is also slow and unscalable. \n+\n+Automated Kubernetes health checks with new methods of viewing improve maintainability of Teleport Kubernetes clusters, while enabling new scenarios.\n+\n+Automated health checks:\n+- Improve time to observe and resolve Kubernetes cluster errors\n+- Improve manageability of Kubernetes clusters, especially at scale\n+- Improve the enrollment experience for Kubernetes clusters\n+- Enables alerting on unhealthy Kubernetes clusters\n+- Provides feature parity with databases and machine workload identities\n+\n+## Details\n+\n+### UX\n+\n+#### User Story: Web UI - Enrolling Kubernetes Clusters\n+\n+Alice enrolls three Amazon EKS clusters into Teleport through the Web UI.\n+\n+The next day she returns to the Web UI _Resources_ tab to find the Amazon EKS clusters are highlighted with warnings. She clicks on an Amazon EKS tile and a health message is displayed in a side panel.\n+\n+```\n+Kubernetes Cluster Issues\n+\n+3 Teleport Kubernetes clusters report issues.\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: sol\n+  UUID: 52dedbd0-b165-4bf6-9bc3-961f95bf481d\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: jupiter\n+  UUID: bb4dc171-ffa7-4a31-ba8c-7bf91c59e250\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: saturn\n+  UUID: 2be08cb1-56a4-401f-a3f3-c755a73f3ff6\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+```\n+\n+Alice notices that each cluster has a similar 503 message saying etcd is the source of the error.\n+\n+Alice resolves the `etcd` error, and each Amazon EKS cluster returns to a healthy state.\n+\n+As she monitors the Teleport Web UI, she sees each Amazon EKS tile switch from a warning state to a normal state.\n+\n+\n+#### User Story: `tctl` - Configuring a New Health Check\n+\n+Bob reads about Kubernetes health checks in a Teleport changelog, and updates a Teleport cluster to the new major version.\n+\n+Bob runs `tctl get health_check_config/default` from a terminal to view the default health settings.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+```\n+\n+He notices a new `kubernetes_labels` matcher.\n+\n+He vets the Kubernetes health checks in non-production environments.\n+\n+Bob runs `tctl edit health_check_config/default` from a terminal, updating the default settings to exclude Kubernetes health checks from a production environment.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Bob runs `tctl get kube_server/luna` from a terminal, validating that the expected Kubernetes cluster is monitoring health. \n+```yaml\n+kind: kube_server\n+metadata:\n+  expires: \"2025-10-26T00:00:00.000000Z\"\n+  name: luna\n+  revision: 43e96231-faaf-43c3-b9b8-15cf91813389\n+spec:\n+  host_id: 278be63c-c87e-4d7e-a286-86002c7c45c3\n+  hostname: luna\n+status:\n+  target_health:\n+    addr: luna:3027\n+    protocol: TLS\n+    transition_timestamp: \"2025-10-25T00:00:00.000000Z\"\n+    transition_reason: \"healthy threshold reached\"\n+    status: healthy\n+  version: 19.0.0\n+version: v3\n+```\n+\n+\n+#### User Story: Prometheus - Alerting on an Unhealthy Kubernetes Cluster\n+\n+Charlie relies on Prometheus to notify him of outages and calls to action.\n+\n+He reads about Kubernetes cluster health being available with Prometheus metrics.\n+\n+Charlie tests the feature.\n+\n+He enrolls three GKE instances into Teleport.\n+\n+He queries the new Teleport Prometheus health metrics.\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 3, the actual number of healthy Kubernetes clusters\n+```\n+\n+Charlie sets one GKE instance into an unhealthy state and requeries.\n+\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 2, the actual number of healthy Kubernetes clusters\n+```\n+\n+Seeing the metric values returning, he sets up a Prometheus alerting rule.\n+\n+```yaml\n+groups:\n+  - name: teleport_kubernetes\n+    rules:\n+      - alert: KubernetesClusterUnhealthy\n+        expr: |\n+          (teleport_health_resources{type=\"kubernetes\"} - \n+           teleport_health_resources_available{type=\"kubernetes\"}) > 0\n+        for: 5m\n+        labels:\n+          severity: warning\n+          team: platform\n+          component: teleport\n+          service: kubernetes\n+        annotations:\n+          summary: \"{{ $value }} Kubernetes cluster(s) unhealthy in Teleport\"\n+          description: \"Teleport reports {{ $value }} unhealthy Kubernetes cluster(s). This indicates that one or more Kubernetes clusters registered with Teleport are not responding or failing health checks. Check Teleport Web UI or use tctl for details.\"\n+          runbook_url: \"https://wiki.goteleport.com/runbooks/teleport-k8s-unhealthy\"\n+          dashboard_url: \"https://grafana.luna.com/d/teleport-k8s/teleport-kubernetes-health\"\n+          query: 'teleport_health_resources{type=\"kubernetes\"} - teleport_health_resources_available{type=\"kubernetes\"}'\n+```\n+\n+Prometheus alerts him about the unhealthy Kubernetes cluster.\n+\n+Charlie sets the GKE instance into a healthy state and moves on with his day.\n+\n+\n+### Implementation Details\n+\n+Kubernetes health checks are discussed by functional areas of core logic, `tctl` command, Web UI, and Prometheus metrics.\n+\n+#### Core Implementation\n+\n+Teleport Kubernetes health checks use the Teleport `healthcheck` package, and is based on existing [database health check](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#user-content-fn-1-b6df2ad8fd7a63ee3ca0af227e74ab87) design patterns. The `healthcheck` components are written, tested, and in production. The focus and effort for Kubernetes health checks is integrating health checks into the Kubernetes agent, extending existing `healthcheck` mechanisms, and updating the UI.\n+\n+##### Core Configuration\n+\n+A first step to enabling Kubernetes health checks is adding new matchers to the `HealthCheckConfig` service. `HealthCheckConfig` identifies servers which choose to participate in health checking. `HealthCheckConfig` supports databases. Kubernetes additions mirror the database features.\n+\n+The configuration adds matchers `kubernetes_labels` and `kubernetes_labels_expression` which specify labeled Kubernetes clusters. By default, all Kubernetes clusters participate in health checks. Matchers may filter Kubernetes clusters. Deleting the matchers excludes all Kubernetes clusters.\n+\n+An example yaml `health_check_config`:\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Change points for health check configuration:\n+- [api/proto/teleport/healthcheckconfig/v1/health_check_config.proto](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/api/proto/teleport/healthcheckconfig/v1/health_check_config.proto#L59)\n+  - Adds `kubernetes_labels` and `kubernetes_labels_expression` to proto message `Matcher`\n+- [lib/services/health_check_config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/health_check_config.go#L58)\n+  - Adds Kubernetes label matcher validation to function `ValidateHealthCheckConfig()`\n+- [lib/healthcheck/config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/config.go#L35)\n+  - Adds Kubernetes label matcher field to type `healthCheckConfig`, and update functions `newHealthCheckConfig()` and `getLabelMatchers()`\n+- [lib/services/presets.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/presets.go#L830)\n+  - Adds wildcard Kubernetes label matchers to function `NewPresetHealthCheckConfig()`\n+\n+`HealthCheckConfig` is communicated via proxy and cached on a Kubernetes agent. Kubernetes interfaces are updated to support the communication and caching.\n+\n+Change points for communication and caching:\n+- [lib/auth/authclient/api.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/auth/authclient/api.go#L472)\n+  - Adds `services.HealthCheckConfigReader` to interfaces `ReadKubernetesAccessPoint` and `ProxyAccessPoint` \n+- api/types/kubernetes_server.go\n+  - Adds functions `GetTargetHealth()`, `SetTargetHealth()`, `GetTargetHealthStatus()`, and `SetTargetHealthStatus()` to the `KubeServer` interface for implementing interface `services.HealthCheckConfigReader`\n+- [lib/cache/cache.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/cache/cache.go#L356)\n+  - Adds watches for `types.KindHealthCheckConfig` in `ForKubernetes()` and `ForProxy()`\n+- [lib/authz/permissions.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/authz/permissions.go#L1183)\n+  - Adds new rules for `types.KindHealthCheckConfig`\n+\n+Details for configuring `HealthCheckConfig` with interval, timeout, and healthy/unhealthy thresholds are described in the [database health check RFD](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#configuration).\n+\n+\n+##### Core Kubernetes Agent\n+\n+The Kubernetes agent registers one or more Kubernetes clusters, checks the health of proxied Kubernetes clusters, and communicates the health state to the auth server. The agent adds a `healthcheck.Manager` which performs the registration and health check operations. The Kubernetes agent is named `TLSServer`, and is located in [lib/kube/proxy/server.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/kube/proxy/server.go#L187).\n+\n+Change points include:\n+\n+Modifying methods:\n+- `(*TLSServerConfig).CheckAndSetDefaults()` - Initializes the `healthcheck.Manager`\n+- `(*TLSServer).Serve()` - Starts `healthcheck.Manager` \n+- `(*TLSServer).startStaticClustersHeartbeat()` - Registers all Kubernetes clusters for health monitoring\n+- `(*TLSServer).close()` - Unregisters all Kubernetes clusters from health monitoring\n+\n+Adding methods:\n+- `(*TLSServer).startTargetHealth()` - Registers a single Kubernetes cluster for health monitoring\n+- `(*TLSServer).stopTargetHealth()` - Unregisters a single Kubernetes cluster from health monitoring\n+- `(*TLSServer).getTargetHealth()` - Gets health for a single Kubernetes cluster\n+\n+\n+##### Core `healthcheck` Package\n+\n+The `healthcheck` package performs recurring health checks on one or more Teleport resources: databases, Kubernetes clusters, etc. It's a general library that currently supports TCP checks. Adding TLS checks is a focus for Kubernetes. \n+\n+Main change points are:\n+- [lib/healthcheck/worker.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/worker.go#L343)\n+  - Modifying the `dialEndpoint()` function to make TLS requests.\n+\n+[manager.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/manager.go) and [target.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/target.go) have minor changes.\n+\n+Prometheus gauge metrics are added to the `healthcheck` package, and described in the [Prometheus Implementation](#prometheus-implementation).\n+\n+\n+#### Health States\n+\n+A Kubernetes cluster may be in a health state of `unknown`, `healthy` or `unhealthy`.\n+- `unknown` indicates a Kubernetes cluster cannot be contacted\n+- `healthy` indicates a Kubernetes cluster is accepting requests\n+- `unhealthy` indicates an error state, and includes an error message with verbose debugging information, if available\n+\n+See the database health check RFD for [more details](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#health-status).\n+\n+\n+##### Health Check Endpoint\n+\n+> [!NOTE]\n+> Kubernetes health checked at `https://<address>/readyz`\n+\n+> [!IMPORTANT]\n+> Requires Kubernetes v1.16 or higher\n+\n+The Kubernetes API `/readyz` endpoint is selected for health checking, and indicates that a Kubernetes API server is ready to accept requests. Kubernetes serves the endpoint through [TLS by default](https://kubernetes.io/docs/concepts/security/controlling-access/#transport-security).\n+\n+The Kubernetes API offers [several health check endpoints](https://kubernetes.io/docs/reference/using-api/health-checks), as well as TCP checks being available.\n+\n+| Approach        | Description                                              |\n+|-----------------|----------------------------------------------------------|\n+| /readyz         | Ready to accept API requests                             |\n+| /readyz?verbose | Ready to accept API requests (detailed)                  |\n+| /livez          | kube-apiserver process is alive/running                  |\n+| /livez?verbose  | kube-apiserver process is alive/running (detailed)       |\n+| /healthz        | Ambiguously alive or ready. Deprecated in 2019 at v1.16  |\n+| TCP             | Can establish TCP connection to API server port          |\n+\n+Let's explore the options and reasoning for selecting `/readyz`.\n+\n+`/readyz` means that the cluster is accepting API requests, and can be used.\n+\n+`/livez` indicates the Kubernetes kube-apiserver process is alive. API requests may or may not be accepted. There's no implication of whole cluster readiness.\n+\n+`/healthz` is deprecated, and not supported with the Kubernetes health check feature. `/healthz` was [deprecated in September of 2019 with Kubernetes v1.16](https://kubernetes.io/blog/2019/09/18/kubernetes-1-16-release-announcement/). At the time of writing, [Kubernetes is at v1.33](https://kubernetes.io/blog/2025/04/23/kubernetes-v1-33-release/), and six years have passed since v1.16. It seems reasonable not to support the `/healthz` endpoint. The choice then sets up a requirement for customers to use Kubernetes v1.16 or higher with Teleport Kubernetes health checks.\n+\n+Moving on to `TCP`, `TCP` indicates that network connectivity is available. No further knowledge of Kubernetes health would be known. In scenarios where servers don't offer explicit health checks, such as databases, `TCP` may be the only choice. Since Kubernetes offers health checks, we can skip `TCP` checks.\n+\n+So, `/livez` and `TCP` indicate some level of health, but do not necessarily mean the Kubernetes cluster can be used. \n+\n+Let's look at the `verbose` query parameter.\n+\n+`/readyz?verbose` provides a list of Kubernetes modules with `ok / not ok` states. The verbose information is not critical in the common case of a healthy cluster returning a `200` HTTP status code. The verbose information may be helpful to an administrator diagnosing an unhealthy cluster.\n+\n+For efficiency in the common case of a healthy cluster, the `/readyz` endpoint is called and checked for a `200` status code. In nearly all cases we only need to check `200`. The `verbose` body message is not sent, reducing unneeded network, memory, and processor consumption. Also, the Kubernetes authors recommend [relying on the status code](https://kubernetes.io/docs/reference/using-api/health-checks/) for checking state.\n+\n+In the case of non-`200` response codes, a follow-up call to `/readyz?verbose` is made. The follow-up verbose message is appended to a Go error, and eventually forwarded to the Web UI for a Teleport administrator to view.\n+\n+An example `/readyz?verbose` response body for a `503 Service Unavailable` HTTP status code:\n+```\n+[+]ping ok\n+[+]log ok\n+[-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+[+]poststarthook/start-kube-apiserver-admission-initializer ok\n+[+]poststarthook/generic-apiserver-start-informers ok\n+...\n+[+]shutdown ok\n+readyz check failed\n+```\n+\n+Alternatives not chosen:\n+- Providing a blend of fallback health checks with `/readyz` -> `/readyz?verbose` -> `/livez?verbose` -> `TCP`. If each call returned a non-`200` error, a fallback approach could be selected. The scenario would capture as much information as is available for the Teleport administrator. The approach is not selected, as it's seen as over-engineering for minimal return.\n+- Monitoring node and pod health starts to walk into a large universe of Kubernetes observability, which is solved with multiple observability products. It's also worth noting that cluster health is distinct from individual node and pod health. The Kubernetes API server can be healthy and accept requests while individual nodes or pods within the cluster are unhealthy. A cluster may also be in a reduced capacity state where there are a mixture of healthy and unhealthy nodes. These all appear beyond the scope of the RFD. Kubernetes cluster checks provide visibility into resources managed by Teleport, and compliment observability solutions. Various in-depth node and pod metrics are available in observability solutions. The [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics?tab=readme-ov-file#overview) project can be added in [Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/metrics-server.html), [Google GKE](https://cloud.google.com/kubernetes-engine/docs/how-to/kube-state-metrics), and [Azure AKS](https://learn.microsoft.com/en-us/azure/azure-monitor/containers/prometheus-metrics-scrape-default). Detailed Kubernetes metrics may or may not be interesting for a future feature.\n+- Checking Kubernetes node health after a cluster is unhealthy may, or may not provide interesting diagnostic information for a Teleport administrator. That could be done via the Kubernetes API. It would add complexity, and may have limited value. Node health could be obtained with an observability solution like kube-state-metrics. Having a downed node doesn't necessarily imply a cluster is unhealthy; perhaps at reduced capacity, or possibly unhealthy. The complexity grows, and may best be addressed by observability solutions.\n+\n+> [!NOTE]\n+> Node health != Kubernetes cluster health\n+\n+> [!NOTE]\n+> Pod health != Kubernetes cluster health\n+\n+Calling `/readyz` with a fallback to `/readyz?verbose` achieves the objective of providing the `healthy / unhealthy` state, with diagnostics when needed. Once an unhealthy Kubernetes cluster is detected as unhealthy, a Teleport administrator is expected to follow up with other approaches.\n+\n+\n+#### `tctl` Implementation\n+\n+Planned changes to `HealthCheckConfig` percolate to `tctl`. \n+\n+No further changes are made for `tctl`.\n+\n+\n+#### Web UI Implementation\n+\n+Previous planning and implementation work from database health checks makes displaying Kubernetes health checks straight-forward. No new visual design patterns or coding design patterns are necessary. A Kubernetes health check UI implementation has surgical insertion points.\n+\n+`TargetHealth` property is added, and `kube_cluster` if/switch case logic is added in approximately nine files: \n+- [lib/web/apiserver.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/apiserver.go#L3414)\n+- [lib/web/ui/server.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/ui/server.go#L117)\n+- [web/packages/shared/components/UnifiedResources/FilterPanel.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/FilterPanel.tsx#L180)\n+- [web/packages/shared/components/UnifiedResources/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/types.ts#L100)\n+- [web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx#L149)\n+- [web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts#L94)\n+- [web/packages/teleport/src/services/kube/makeKube.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/makeKube.ts#L21)\n+- [web/packages/teleport/src/services/kube/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/types.ts#L21)\n+- [web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx#L560)\n+\n+The Teleport Connect UI is implemented at the same time as the Web UI. Teleport Connect  shares UI components, such as `UnifiedResource`, making the implementation closely related.\n+\n+\n+#### Prometheus Implementation\n+\n+Two Prometheus metrics are added to the `healthcheck` package:\n+\n+- `teleport_health_resources` for the expected number of healthy resources\n+- `teleport_health_resources_available` for the actual number of healthy resources",
        "comment_created_at": "2025-08-26T14:50:47+00:00",
        "comment_author": "rosstimothy",
        "comment_body": "The main motivator for the metrics is to allow alerting when some number of resources are not healthy. Can we achieve that when unhealthy and unknown targets are grouped together? My main concern is that we disambiguate these, which then makes consuming the metrics and calculating the number of unhealthy/unreachable hosts harder. \r\n\r\nAs an admin, If I were to set up alerting for these health checks, would the distinction between unhealthy and unknown allow me to take different actions?",
        "pr_file_module": null
      },
      {
        "comment_id": "2301883326",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58065,
        "pr_file": "rfd/0223-k8s-health-checks.md",
        "discussion_id": "2299671731",
        "commented_code": "@@ -0,0 +1,623 @@\n+---\n+authors: Rana Ian (rana.ian@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0223 - Kubernetes Health Checks\n+\n+## Required Approvals\n+\n+- Engineering: @rosstimothy && @creack && @tigrato\n+\n+\n+## What\n+\n+Enable automated Kubernetes cluster health checks that are viewed by the Web UI, Teleport Connect, `tctl` command, and Prometheus metrics.\n+\n+## Why\n+\n+Proxied Kubernetes cluster health may be manually exercised with Kubernetes operations in the Web UI, or `kubectl` command, then observing the result. While effective, manual checking is also slow and unscalable. \n+\n+Automated Kubernetes health checks with new methods of viewing improve maintainability of Teleport Kubernetes clusters, while enabling new scenarios.\n+\n+Automated health checks:\n+- Improve time to observe and resolve Kubernetes cluster errors\n+- Improve manageability of Kubernetes clusters, especially at scale\n+- Improve the enrollment experience for Kubernetes clusters\n+- Enables alerting on unhealthy Kubernetes clusters\n+- Provides feature parity with databases and machine workload identities\n+\n+## Details\n+\n+### UX\n+\n+#### User Story: Web UI - Enrolling Kubernetes Clusters\n+\n+Alice enrolls three Amazon EKS clusters into Teleport through the Web UI.\n+\n+The next day she returns to the Web UI _Resources_ tab to find the Amazon EKS clusters are highlighted with warnings. She clicks on an Amazon EKS tile and a health message is displayed in a side panel.\n+\n+```\n+Kubernetes Cluster Issues\n+\n+3 Teleport Kubernetes clusters report issues.\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: sol\n+  UUID: 52dedbd0-b165-4bf6-9bc3-961f95bf481d\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: jupiter\n+  UUID: bb4dc171-ffa7-4a31-ba8c-7bf91c59e250\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: saturn\n+  UUID: 2be08cb1-56a4-401f-a3f3-c755a73f3ff6\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+```\n+\n+Alice notices that each cluster has a similar 503 message saying etcd is the source of the error.\n+\n+Alice resolves the `etcd` error, and each Amazon EKS cluster returns to a healthy state.\n+\n+As she monitors the Teleport Web UI, she sees each Amazon EKS tile switch from a warning state to a normal state.\n+\n+\n+#### User Story: `tctl` - Configuring a New Health Check\n+\n+Bob reads about Kubernetes health checks in a Teleport changelog, and updates a Teleport cluster to the new major version.\n+\n+Bob runs `tctl get health_check_config/default` from a terminal to view the default health settings.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+```\n+\n+He notices a new `kubernetes_labels` matcher.\n+\n+He vets the Kubernetes health checks in non-production environments.\n+\n+Bob runs `tctl edit health_check_config/default` from a terminal, updating the default settings to exclude Kubernetes health checks from a production environment.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Bob runs `tctl get kube_server/luna` from a terminal, validating that the expected Kubernetes cluster is monitoring health. \n+```yaml\n+kind: kube_server\n+metadata:\n+  expires: \"2025-10-26T00:00:00.000000Z\"\n+  name: luna\n+  revision: 43e96231-faaf-43c3-b9b8-15cf91813389\n+spec:\n+  host_id: 278be63c-c87e-4d7e-a286-86002c7c45c3\n+  hostname: luna\n+status:\n+  target_health:\n+    addr: luna:3027\n+    protocol: TLS\n+    transition_timestamp: \"2025-10-25T00:00:00.000000Z\"\n+    transition_reason: \"healthy threshold reached\"\n+    status: healthy\n+  version: 19.0.0\n+version: v3\n+```\n+\n+\n+#### User Story: Prometheus - Alerting on an Unhealthy Kubernetes Cluster\n+\n+Charlie relies on Prometheus to notify him of outages and calls to action.\n+\n+He reads about Kubernetes cluster health being available with Prometheus metrics.\n+\n+Charlie tests the feature.\n+\n+He enrolls three GKE instances into Teleport.\n+\n+He queries the new Teleport Prometheus health metrics.\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 3, the actual number of healthy Kubernetes clusters\n+```\n+\n+Charlie sets one GKE instance into an unhealthy state and requeries.\n+\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 2, the actual number of healthy Kubernetes clusters\n+```\n+\n+Seeing the metric values returning, he sets up a Prometheus alerting rule.\n+\n+```yaml\n+groups:\n+  - name: teleport_kubernetes\n+    rules:\n+      - alert: KubernetesClusterUnhealthy\n+        expr: |\n+          (teleport_health_resources{type=\"kubernetes\"} - \n+           teleport_health_resources_available{type=\"kubernetes\"}) > 0\n+        for: 5m\n+        labels:\n+          severity: warning\n+          team: platform\n+          component: teleport\n+          service: kubernetes\n+        annotations:\n+          summary: \"{{ $value }} Kubernetes cluster(s) unhealthy in Teleport\"\n+          description: \"Teleport reports {{ $value }} unhealthy Kubernetes cluster(s). This indicates that one or more Kubernetes clusters registered with Teleport are not responding or failing health checks. Check Teleport Web UI or use tctl for details.\"\n+          runbook_url: \"https://wiki.goteleport.com/runbooks/teleport-k8s-unhealthy\"\n+          dashboard_url: \"https://grafana.luna.com/d/teleport-k8s/teleport-kubernetes-health\"\n+          query: 'teleport_health_resources{type=\"kubernetes\"} - teleport_health_resources_available{type=\"kubernetes\"}'\n+```\n+\n+Prometheus alerts him about the unhealthy Kubernetes cluster.\n+\n+Charlie sets the GKE instance into a healthy state and moves on with his day.\n+\n+\n+### Implementation Details\n+\n+Kubernetes health checks are discussed by functional areas of core logic, `tctl` command, Web UI, and Prometheus metrics.\n+\n+#### Core Implementation\n+\n+Teleport Kubernetes health checks use the Teleport `healthcheck` package, and is based on existing [database health check](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#user-content-fn-1-b6df2ad8fd7a63ee3ca0af227e74ab87) design patterns. The `healthcheck` components are written, tested, and in production. The focus and effort for Kubernetes health checks is integrating health checks into the Kubernetes agent, extending existing `healthcheck` mechanisms, and updating the UI.\n+\n+##### Core Configuration\n+\n+A first step to enabling Kubernetes health checks is adding new matchers to the `HealthCheckConfig` service. `HealthCheckConfig` identifies servers which choose to participate in health checking. `HealthCheckConfig` supports databases. Kubernetes additions mirror the database features.\n+\n+The configuration adds matchers `kubernetes_labels` and `kubernetes_labels_expression` which specify labeled Kubernetes clusters. By default, all Kubernetes clusters participate in health checks. Matchers may filter Kubernetes clusters. Deleting the matchers excludes all Kubernetes clusters.\n+\n+An example yaml `health_check_config`:\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Change points for health check configuration:\n+- [api/proto/teleport/healthcheckconfig/v1/health_check_config.proto](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/api/proto/teleport/healthcheckconfig/v1/health_check_config.proto#L59)\n+  - Adds `kubernetes_labels` and `kubernetes_labels_expression` to proto message `Matcher`\n+- [lib/services/health_check_config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/health_check_config.go#L58)\n+  - Adds Kubernetes label matcher validation to function `ValidateHealthCheckConfig()`\n+- [lib/healthcheck/config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/config.go#L35)\n+  - Adds Kubernetes label matcher field to type `healthCheckConfig`, and update functions `newHealthCheckConfig()` and `getLabelMatchers()`\n+- [lib/services/presets.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/presets.go#L830)\n+  - Adds wildcard Kubernetes label matchers to function `NewPresetHealthCheckConfig()`\n+\n+`HealthCheckConfig` is communicated via proxy and cached on a Kubernetes agent. Kubernetes interfaces are updated to support the communication and caching.\n+\n+Change points for communication and caching:\n+- [lib/auth/authclient/api.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/auth/authclient/api.go#L472)\n+  - Adds `services.HealthCheckConfigReader` to interfaces `ReadKubernetesAccessPoint` and `ProxyAccessPoint` \n+- api/types/kubernetes_server.go\n+  - Adds functions `GetTargetHealth()`, `SetTargetHealth()`, `GetTargetHealthStatus()`, and `SetTargetHealthStatus()` to the `KubeServer` interface for implementing interface `services.HealthCheckConfigReader`\n+- [lib/cache/cache.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/cache/cache.go#L356)\n+  - Adds watches for `types.KindHealthCheckConfig` in `ForKubernetes()` and `ForProxy()`\n+- [lib/authz/permissions.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/authz/permissions.go#L1183)\n+  - Adds new rules for `types.KindHealthCheckConfig`\n+\n+Details for configuring `HealthCheckConfig` with interval, timeout, and healthy/unhealthy thresholds are described in the [database health check RFD](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#configuration).\n+\n+\n+##### Core Kubernetes Agent\n+\n+The Kubernetes agent registers one or more Kubernetes clusters, checks the health of proxied Kubernetes clusters, and communicates the health state to the auth server. The agent adds a `healthcheck.Manager` which performs the registration and health check operations. The Kubernetes agent is named `TLSServer`, and is located in [lib/kube/proxy/server.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/kube/proxy/server.go#L187).\n+\n+Change points include:\n+\n+Modifying methods:\n+- `(*TLSServerConfig).CheckAndSetDefaults()` - Initializes the `healthcheck.Manager`\n+- `(*TLSServer).Serve()` - Starts `healthcheck.Manager` \n+- `(*TLSServer).startStaticClustersHeartbeat()` - Registers all Kubernetes clusters for health monitoring\n+- `(*TLSServer).close()` - Unregisters all Kubernetes clusters from health monitoring\n+\n+Adding methods:\n+- `(*TLSServer).startTargetHealth()` - Registers a single Kubernetes cluster for health monitoring\n+- `(*TLSServer).stopTargetHealth()` - Unregisters a single Kubernetes cluster from health monitoring\n+- `(*TLSServer).getTargetHealth()` - Gets health for a single Kubernetes cluster\n+\n+\n+##### Core `healthcheck` Package\n+\n+The `healthcheck` package performs recurring health checks on one or more Teleport resources: databases, Kubernetes clusters, etc. It's a general library that currently supports TCP checks. Adding TLS checks is a focus for Kubernetes. \n+\n+Main change points are:\n+- [lib/healthcheck/worker.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/worker.go#L343)\n+  - Modifying the `dialEndpoint()` function to make TLS requests.\n+\n+[manager.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/manager.go) and [target.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/target.go) have minor changes.\n+\n+Prometheus gauge metrics are added to the `healthcheck` package, and described in the [Prometheus Implementation](#prometheus-implementation).\n+\n+\n+#### Health States\n+\n+A Kubernetes cluster may be in a health state of `unknown`, `healthy` or `unhealthy`.\n+- `unknown` indicates a Kubernetes cluster cannot be contacted\n+- `healthy` indicates a Kubernetes cluster is accepting requests\n+- `unhealthy` indicates an error state, and includes an error message with verbose debugging information, if available\n+\n+See the database health check RFD for [more details](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#health-status).\n+\n+\n+##### Health Check Endpoint\n+\n+> [!NOTE]\n+> Kubernetes health checked at `https://<address>/readyz`\n+\n+> [!IMPORTANT]\n+> Requires Kubernetes v1.16 or higher\n+\n+The Kubernetes API `/readyz` endpoint is selected for health checking, and indicates that a Kubernetes API server is ready to accept requests. Kubernetes serves the endpoint through [TLS by default](https://kubernetes.io/docs/concepts/security/controlling-access/#transport-security).\n+\n+The Kubernetes API offers [several health check endpoints](https://kubernetes.io/docs/reference/using-api/health-checks), as well as TCP checks being available.\n+\n+| Approach        | Description                                              |\n+|-----------------|----------------------------------------------------------|\n+| /readyz         | Ready to accept API requests                             |\n+| /readyz?verbose | Ready to accept API requests (detailed)                  |\n+| /livez          | kube-apiserver process is alive/running                  |\n+| /livez?verbose  | kube-apiserver process is alive/running (detailed)       |\n+| /healthz        | Ambiguously alive or ready. Deprecated in 2019 at v1.16  |\n+| TCP             | Can establish TCP connection to API server port          |\n+\n+Let's explore the options and reasoning for selecting `/readyz`.\n+\n+`/readyz` means that the cluster is accepting API requests, and can be used.\n+\n+`/livez` indicates the Kubernetes kube-apiserver process is alive. API requests may or may not be accepted. There's no implication of whole cluster readiness.\n+\n+`/healthz` is deprecated, and not supported with the Kubernetes health check feature. `/healthz` was [deprecated in September of 2019 with Kubernetes v1.16](https://kubernetes.io/blog/2019/09/18/kubernetes-1-16-release-announcement/). At the time of writing, [Kubernetes is at v1.33](https://kubernetes.io/blog/2025/04/23/kubernetes-v1-33-release/), and six years have passed since v1.16. It seems reasonable not to support the `/healthz` endpoint. The choice then sets up a requirement for customers to use Kubernetes v1.16 or higher with Teleport Kubernetes health checks.\n+\n+Moving on to `TCP`, `TCP` indicates that network connectivity is available. No further knowledge of Kubernetes health would be known. In scenarios where servers don't offer explicit health checks, such as databases, `TCP` may be the only choice. Since Kubernetes offers health checks, we can skip `TCP` checks.\n+\n+So, `/livez` and `TCP` indicate some level of health, but do not necessarily mean the Kubernetes cluster can be used. \n+\n+Let's look at the `verbose` query parameter.\n+\n+`/readyz?verbose` provides a list of Kubernetes modules with `ok / not ok` states. The verbose information is not critical in the common case of a healthy cluster returning a `200` HTTP status code. The verbose information may be helpful to an administrator diagnosing an unhealthy cluster.\n+\n+For efficiency in the common case of a healthy cluster, the `/readyz` endpoint is called and checked for a `200` status code. In nearly all cases we only need to check `200`. The `verbose` body message is not sent, reducing unneeded network, memory, and processor consumption. Also, the Kubernetes authors recommend [relying on the status code](https://kubernetes.io/docs/reference/using-api/health-checks/) for checking state.\n+\n+In the case of non-`200` response codes, a follow-up call to `/readyz?verbose` is made. The follow-up verbose message is appended to a Go error, and eventually forwarded to the Web UI for a Teleport administrator to view.\n+\n+An example `/readyz?verbose` response body for a `503 Service Unavailable` HTTP status code:\n+```\n+[+]ping ok\n+[+]log ok\n+[-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+[+]poststarthook/start-kube-apiserver-admission-initializer ok\n+[+]poststarthook/generic-apiserver-start-informers ok\n+...\n+[+]shutdown ok\n+readyz check failed\n+```\n+\n+Alternatives not chosen:\n+- Providing a blend of fallback health checks with `/readyz` -> `/readyz?verbose` -> `/livez?verbose` -> `TCP`. If each call returned a non-`200` error, a fallback approach could be selected. The scenario would capture as much information as is available for the Teleport administrator. The approach is not selected, as it's seen as over-engineering for minimal return.\n+- Monitoring node and pod health starts to walk into a large universe of Kubernetes observability, which is solved with multiple observability products. It's also worth noting that cluster health is distinct from individual node and pod health. The Kubernetes API server can be healthy and accept requests while individual nodes or pods within the cluster are unhealthy. A cluster may also be in a reduced capacity state where there are a mixture of healthy and unhealthy nodes. These all appear beyond the scope of the RFD. Kubernetes cluster checks provide visibility into resources managed by Teleport, and compliment observability solutions. Various in-depth node and pod metrics are available in observability solutions. The [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics?tab=readme-ov-file#overview) project can be added in [Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/metrics-server.html), [Google GKE](https://cloud.google.com/kubernetes-engine/docs/how-to/kube-state-metrics), and [Azure AKS](https://learn.microsoft.com/en-us/azure/azure-monitor/containers/prometheus-metrics-scrape-default). Detailed Kubernetes metrics may or may not be interesting for a future feature.\n+- Checking Kubernetes node health after a cluster is unhealthy may, or may not provide interesting diagnostic information for a Teleport administrator. That could be done via the Kubernetes API. It would add complexity, and may have limited value. Node health could be obtained with an observability solution like kube-state-metrics. Having a downed node doesn't necessarily imply a cluster is unhealthy; perhaps at reduced capacity, or possibly unhealthy. The complexity grows, and may best be addressed by observability solutions.\n+\n+> [!NOTE]\n+> Node health != Kubernetes cluster health\n+\n+> [!NOTE]\n+> Pod health != Kubernetes cluster health\n+\n+Calling `/readyz` with a fallback to `/readyz?verbose` achieves the objective of providing the `healthy / unhealthy` state, with diagnostics when needed. Once an unhealthy Kubernetes cluster is detected as unhealthy, a Teleport administrator is expected to follow up with other approaches.\n+\n+\n+#### `tctl` Implementation\n+\n+Planned changes to `HealthCheckConfig` percolate to `tctl`. \n+\n+No further changes are made for `tctl`.\n+\n+\n+#### Web UI Implementation\n+\n+Previous planning and implementation work from database health checks makes displaying Kubernetes health checks straight-forward. No new visual design patterns or coding design patterns are necessary. A Kubernetes health check UI implementation has surgical insertion points.\n+\n+`TargetHealth` property is added, and `kube_cluster` if/switch case logic is added in approximately nine files: \n+- [lib/web/apiserver.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/apiserver.go#L3414)\n+- [lib/web/ui/server.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/ui/server.go#L117)\n+- [web/packages/shared/components/UnifiedResources/FilterPanel.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/FilterPanel.tsx#L180)\n+- [web/packages/shared/components/UnifiedResources/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/types.ts#L100)\n+- [web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx#L149)\n+- [web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts#L94)\n+- [web/packages/teleport/src/services/kube/makeKube.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/makeKube.ts#L21)\n+- [web/packages/teleport/src/services/kube/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/types.ts#L21)\n+- [web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx#L560)\n+\n+The Teleport Connect UI is implemented at the same time as the Web UI. Teleport Connect  shares UI components, such as `UnifiedResource`, making the implementation closely related.\n+\n+\n+#### Prometheus Implementation\n+\n+Two Prometheus metrics are added to the `healthcheck` package:\n+\n+- `teleport_health_resources` for the expected number of healthy resources\n+- `teleport_health_resources_available` for the actual number of healthy resources",
        "comment_created_at": "2025-08-26T19:03:23+00:00",
        "comment_author": "GavinFrazar",
        "comment_body": "I think it would, because resources may have health checks disabled (such as MySQL) and they are in an \"unknown\" state indefinitely. Only \"unhealthy\" indicates failing health checks that should be alerted on",
        "pr_file_module": null
      },
      {
        "comment_id": "2302056941",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58065,
        "pr_file": "rfd/0223-k8s-health-checks.md",
        "discussion_id": "2299671731",
        "commented_code": "@@ -0,0 +1,623 @@\n+---\n+authors: Rana Ian (rana.ian@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0223 - Kubernetes Health Checks\n+\n+## Required Approvals\n+\n+- Engineering: @rosstimothy && @creack && @tigrato\n+\n+\n+## What\n+\n+Enable automated Kubernetes cluster health checks that are viewed by the Web UI, Teleport Connect, `tctl` command, and Prometheus metrics.\n+\n+## Why\n+\n+Proxied Kubernetes cluster health may be manually exercised with Kubernetes operations in the Web UI, or `kubectl` command, then observing the result. While effective, manual checking is also slow and unscalable. \n+\n+Automated Kubernetes health checks with new methods of viewing improve maintainability of Teleport Kubernetes clusters, while enabling new scenarios.\n+\n+Automated health checks:\n+- Improve time to observe and resolve Kubernetes cluster errors\n+- Improve manageability of Kubernetes clusters, especially at scale\n+- Improve the enrollment experience for Kubernetes clusters\n+- Enables alerting on unhealthy Kubernetes clusters\n+- Provides feature parity with databases and machine workload identities\n+\n+## Details\n+\n+### UX\n+\n+#### User Story: Web UI - Enrolling Kubernetes Clusters\n+\n+Alice enrolls three Amazon EKS clusters into Teleport through the Web UI.\n+\n+The next day she returns to the Web UI _Resources_ tab to find the Amazon EKS clusters are highlighted with warnings. She clicks on an Amazon EKS tile and a health message is displayed in a side panel.\n+\n+```\n+Kubernetes Cluster Issues\n+\n+3 Teleport Kubernetes clusters report issues.\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: sol\n+  UUID: 52dedbd0-b165-4bf6-9bc3-961f95bf481d\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: jupiter\n+  UUID: bb4dc171-ffa7-4a31-ba8c-7bf91c59e250\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: saturn\n+  UUID: 2be08cb1-56a4-401f-a3f3-c755a73f3ff6\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+```\n+\n+Alice notices that each cluster has a similar 503 message saying etcd is the source of the error.\n+\n+Alice resolves the `etcd` error, and each Amazon EKS cluster returns to a healthy state.\n+\n+As she monitors the Teleport Web UI, she sees each Amazon EKS tile switch from a warning state to a normal state.\n+\n+\n+#### User Story: `tctl` - Configuring a New Health Check\n+\n+Bob reads about Kubernetes health checks in a Teleport changelog, and updates a Teleport cluster to the new major version.\n+\n+Bob runs `tctl get health_check_config/default` from a terminal to view the default health settings.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+```\n+\n+He notices a new `kubernetes_labels` matcher.\n+\n+He vets the Kubernetes health checks in non-production environments.\n+\n+Bob runs `tctl edit health_check_config/default` from a terminal, updating the default settings to exclude Kubernetes health checks from a production environment.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Bob runs `tctl get kube_server/luna` from a terminal, validating that the expected Kubernetes cluster is monitoring health. \n+```yaml\n+kind: kube_server\n+metadata:\n+  expires: \"2025-10-26T00:00:00.000000Z\"\n+  name: luna\n+  revision: 43e96231-faaf-43c3-b9b8-15cf91813389\n+spec:\n+  host_id: 278be63c-c87e-4d7e-a286-86002c7c45c3\n+  hostname: luna\n+status:\n+  target_health:\n+    addr: luna:3027\n+    protocol: TLS\n+    transition_timestamp: \"2025-10-25T00:00:00.000000Z\"\n+    transition_reason: \"healthy threshold reached\"\n+    status: healthy\n+  version: 19.0.0\n+version: v3\n+```\n+\n+\n+#### User Story: Prometheus - Alerting on an Unhealthy Kubernetes Cluster\n+\n+Charlie relies on Prometheus to notify him of outages and calls to action.\n+\n+He reads about Kubernetes cluster health being available with Prometheus metrics.\n+\n+Charlie tests the feature.\n+\n+He enrolls three GKE instances into Teleport.\n+\n+He queries the new Teleport Prometheus health metrics.\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 3, the actual number of healthy Kubernetes clusters\n+```\n+\n+Charlie sets one GKE instance into an unhealthy state and requeries.\n+\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 2, the actual number of healthy Kubernetes clusters\n+```\n+\n+Seeing the metric values returning, he sets up a Prometheus alerting rule.\n+\n+```yaml\n+groups:\n+  - name: teleport_kubernetes\n+    rules:\n+      - alert: KubernetesClusterUnhealthy\n+        expr: |\n+          (teleport_health_resources{type=\"kubernetes\"} - \n+           teleport_health_resources_available{type=\"kubernetes\"}) > 0\n+        for: 5m\n+        labels:\n+          severity: warning\n+          team: platform\n+          component: teleport\n+          service: kubernetes\n+        annotations:\n+          summary: \"{{ $value }} Kubernetes cluster(s) unhealthy in Teleport\"\n+          description: \"Teleport reports {{ $value }} unhealthy Kubernetes cluster(s). This indicates that one or more Kubernetes clusters registered with Teleport are not responding or failing health checks. Check Teleport Web UI or use tctl for details.\"\n+          runbook_url: \"https://wiki.goteleport.com/runbooks/teleport-k8s-unhealthy\"\n+          dashboard_url: \"https://grafana.luna.com/d/teleport-k8s/teleport-kubernetes-health\"\n+          query: 'teleport_health_resources{type=\"kubernetes\"} - teleport_health_resources_available{type=\"kubernetes\"}'\n+```\n+\n+Prometheus alerts him about the unhealthy Kubernetes cluster.\n+\n+Charlie sets the GKE instance into a healthy state and moves on with his day.\n+\n+\n+### Implementation Details\n+\n+Kubernetes health checks are discussed by functional areas of core logic, `tctl` command, Web UI, and Prometheus metrics.\n+\n+#### Core Implementation\n+\n+Teleport Kubernetes health checks use the Teleport `healthcheck` package, and is based on existing [database health check](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#user-content-fn-1-b6df2ad8fd7a63ee3ca0af227e74ab87) design patterns. The `healthcheck` components are written, tested, and in production. The focus and effort for Kubernetes health checks is integrating health checks into the Kubernetes agent, extending existing `healthcheck` mechanisms, and updating the UI.\n+\n+##### Core Configuration\n+\n+A first step to enabling Kubernetes health checks is adding new matchers to the `HealthCheckConfig` service. `HealthCheckConfig` identifies servers which choose to participate in health checking. `HealthCheckConfig` supports databases. Kubernetes additions mirror the database features.\n+\n+The configuration adds matchers `kubernetes_labels` and `kubernetes_labels_expression` which specify labeled Kubernetes clusters. By default, all Kubernetes clusters participate in health checks. Matchers may filter Kubernetes clusters. Deleting the matchers excludes all Kubernetes clusters.\n+\n+An example yaml `health_check_config`:\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Change points for health check configuration:\n+- [api/proto/teleport/healthcheckconfig/v1/health_check_config.proto](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/api/proto/teleport/healthcheckconfig/v1/health_check_config.proto#L59)\n+  - Adds `kubernetes_labels` and `kubernetes_labels_expression` to proto message `Matcher`\n+- [lib/services/health_check_config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/health_check_config.go#L58)\n+  - Adds Kubernetes label matcher validation to function `ValidateHealthCheckConfig()`\n+- [lib/healthcheck/config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/config.go#L35)\n+  - Adds Kubernetes label matcher field to type `healthCheckConfig`, and update functions `newHealthCheckConfig()` and `getLabelMatchers()`\n+- [lib/services/presets.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/presets.go#L830)\n+  - Adds wildcard Kubernetes label matchers to function `NewPresetHealthCheckConfig()`\n+\n+`HealthCheckConfig` is communicated via proxy and cached on a Kubernetes agent. Kubernetes interfaces are updated to support the communication and caching.\n+\n+Change points for communication and caching:\n+- [lib/auth/authclient/api.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/auth/authclient/api.go#L472)\n+  - Adds `services.HealthCheckConfigReader` to interfaces `ReadKubernetesAccessPoint` and `ProxyAccessPoint` \n+- api/types/kubernetes_server.go\n+  - Adds functions `GetTargetHealth()`, `SetTargetHealth()`, `GetTargetHealthStatus()`, and `SetTargetHealthStatus()` to the `KubeServer` interface for implementing interface `services.HealthCheckConfigReader`\n+- [lib/cache/cache.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/cache/cache.go#L356)\n+  - Adds watches for `types.KindHealthCheckConfig` in `ForKubernetes()` and `ForProxy()`\n+- [lib/authz/permissions.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/authz/permissions.go#L1183)\n+  - Adds new rules for `types.KindHealthCheckConfig`\n+\n+Details for configuring `HealthCheckConfig` with interval, timeout, and healthy/unhealthy thresholds are described in the [database health check RFD](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#configuration).\n+\n+\n+##### Core Kubernetes Agent\n+\n+The Kubernetes agent registers one or more Kubernetes clusters, checks the health of proxied Kubernetes clusters, and communicates the health state to the auth server. The agent adds a `healthcheck.Manager` which performs the registration and health check operations. The Kubernetes agent is named `TLSServer`, and is located in [lib/kube/proxy/server.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/kube/proxy/server.go#L187).\n+\n+Change points include:\n+\n+Modifying methods:\n+- `(*TLSServerConfig).CheckAndSetDefaults()` - Initializes the `healthcheck.Manager`\n+- `(*TLSServer).Serve()` - Starts `healthcheck.Manager` \n+- `(*TLSServer).startStaticClustersHeartbeat()` - Registers all Kubernetes clusters for health monitoring\n+- `(*TLSServer).close()` - Unregisters all Kubernetes clusters from health monitoring\n+\n+Adding methods:\n+- `(*TLSServer).startTargetHealth()` - Registers a single Kubernetes cluster for health monitoring\n+- `(*TLSServer).stopTargetHealth()` - Unregisters a single Kubernetes cluster from health monitoring\n+- `(*TLSServer).getTargetHealth()` - Gets health for a single Kubernetes cluster\n+\n+\n+##### Core `healthcheck` Package\n+\n+The `healthcheck` package performs recurring health checks on one or more Teleport resources: databases, Kubernetes clusters, etc. It's a general library that currently supports TCP checks. Adding TLS checks is a focus for Kubernetes. \n+\n+Main change points are:\n+- [lib/healthcheck/worker.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/worker.go#L343)\n+  - Modifying the `dialEndpoint()` function to make TLS requests.\n+\n+[manager.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/manager.go) and [target.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/target.go) have minor changes.\n+\n+Prometheus gauge metrics are added to the `healthcheck` package, and described in the [Prometheus Implementation](#prometheus-implementation).\n+\n+\n+#### Health States\n+\n+A Kubernetes cluster may be in a health state of `unknown`, `healthy` or `unhealthy`.\n+- `unknown` indicates a Kubernetes cluster cannot be contacted\n+- `healthy` indicates a Kubernetes cluster is accepting requests\n+- `unhealthy` indicates an error state, and includes an error message with verbose debugging information, if available\n+\n+See the database health check RFD for [more details](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#health-status).\n+\n+\n+##### Health Check Endpoint\n+\n+> [!NOTE]\n+> Kubernetes health checked at `https://<address>/readyz`\n+\n+> [!IMPORTANT]\n+> Requires Kubernetes v1.16 or higher\n+\n+The Kubernetes API `/readyz` endpoint is selected for health checking, and indicates that a Kubernetes API server is ready to accept requests. Kubernetes serves the endpoint through [TLS by default](https://kubernetes.io/docs/concepts/security/controlling-access/#transport-security).\n+\n+The Kubernetes API offers [several health check endpoints](https://kubernetes.io/docs/reference/using-api/health-checks), as well as TCP checks being available.\n+\n+| Approach        | Description                                              |\n+|-----------------|----------------------------------------------------------|\n+| /readyz         | Ready to accept API requests                             |\n+| /readyz?verbose | Ready to accept API requests (detailed)                  |\n+| /livez          | kube-apiserver process is alive/running                  |\n+| /livez?verbose  | kube-apiserver process is alive/running (detailed)       |\n+| /healthz        | Ambiguously alive or ready. Deprecated in 2019 at v1.16  |\n+| TCP             | Can establish TCP connection to API server port          |\n+\n+Let's explore the options and reasoning for selecting `/readyz`.\n+\n+`/readyz` means that the cluster is accepting API requests, and can be used.\n+\n+`/livez` indicates the Kubernetes kube-apiserver process is alive. API requests may or may not be accepted. There's no implication of whole cluster readiness.\n+\n+`/healthz` is deprecated, and not supported with the Kubernetes health check feature. `/healthz` was [deprecated in September of 2019 with Kubernetes v1.16](https://kubernetes.io/blog/2019/09/18/kubernetes-1-16-release-announcement/). At the time of writing, [Kubernetes is at v1.33](https://kubernetes.io/blog/2025/04/23/kubernetes-v1-33-release/), and six years have passed since v1.16. It seems reasonable not to support the `/healthz` endpoint. The choice then sets up a requirement for customers to use Kubernetes v1.16 or higher with Teleport Kubernetes health checks.\n+\n+Moving on to `TCP`, `TCP` indicates that network connectivity is available. No further knowledge of Kubernetes health would be known. In scenarios where servers don't offer explicit health checks, such as databases, `TCP` may be the only choice. Since Kubernetes offers health checks, we can skip `TCP` checks.\n+\n+So, `/livez` and `TCP` indicate some level of health, but do not necessarily mean the Kubernetes cluster can be used. \n+\n+Let's look at the `verbose` query parameter.\n+\n+`/readyz?verbose` provides a list of Kubernetes modules with `ok / not ok` states. The verbose information is not critical in the common case of a healthy cluster returning a `200` HTTP status code. The verbose information may be helpful to an administrator diagnosing an unhealthy cluster.\n+\n+For efficiency in the common case of a healthy cluster, the `/readyz` endpoint is called and checked for a `200` status code. In nearly all cases we only need to check `200`. The `verbose` body message is not sent, reducing unneeded network, memory, and processor consumption. Also, the Kubernetes authors recommend [relying on the status code](https://kubernetes.io/docs/reference/using-api/health-checks/) for checking state.\n+\n+In the case of non-`200` response codes, a follow-up call to `/readyz?verbose` is made. The follow-up verbose message is appended to a Go error, and eventually forwarded to the Web UI for a Teleport administrator to view.\n+\n+An example `/readyz?verbose` response body for a `503 Service Unavailable` HTTP status code:\n+```\n+[+]ping ok\n+[+]log ok\n+[-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+[+]poststarthook/start-kube-apiserver-admission-initializer ok\n+[+]poststarthook/generic-apiserver-start-informers ok\n+...\n+[+]shutdown ok\n+readyz check failed\n+```\n+\n+Alternatives not chosen:\n+- Providing a blend of fallback health checks with `/readyz` -> `/readyz?verbose` -> `/livez?verbose` -> `TCP`. If each call returned a non-`200` error, a fallback approach could be selected. The scenario would capture as much information as is available for the Teleport administrator. The approach is not selected, as it's seen as over-engineering for minimal return.\n+- Monitoring node and pod health starts to walk into a large universe of Kubernetes observability, which is solved with multiple observability products. It's also worth noting that cluster health is distinct from individual node and pod health. The Kubernetes API server can be healthy and accept requests while individual nodes or pods within the cluster are unhealthy. A cluster may also be in a reduced capacity state where there are a mixture of healthy and unhealthy nodes. These all appear beyond the scope of the RFD. Kubernetes cluster checks provide visibility into resources managed by Teleport, and compliment observability solutions. Various in-depth node and pod metrics are available in observability solutions. The [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics?tab=readme-ov-file#overview) project can be added in [Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/metrics-server.html), [Google GKE](https://cloud.google.com/kubernetes-engine/docs/how-to/kube-state-metrics), and [Azure AKS](https://learn.microsoft.com/en-us/azure/azure-monitor/containers/prometheus-metrics-scrape-default). Detailed Kubernetes metrics may or may not be interesting for a future feature.\n+- Checking Kubernetes node health after a cluster is unhealthy may, or may not provide interesting diagnostic information for a Teleport administrator. That could be done via the Kubernetes API. It would add complexity, and may have limited value. Node health could be obtained with an observability solution like kube-state-metrics. Having a downed node doesn't necessarily imply a cluster is unhealthy; perhaps at reduced capacity, or possibly unhealthy. The complexity grows, and may best be addressed by observability solutions.\n+\n+> [!NOTE]\n+> Node health != Kubernetes cluster health\n+\n+> [!NOTE]\n+> Pod health != Kubernetes cluster health\n+\n+Calling `/readyz` with a fallback to `/readyz?verbose` achieves the objective of providing the `healthy / unhealthy` state, with diagnostics when needed. Once an unhealthy Kubernetes cluster is detected as unhealthy, a Teleport administrator is expected to follow up with other approaches.\n+\n+\n+#### `tctl` Implementation\n+\n+Planned changes to `HealthCheckConfig` percolate to `tctl`. \n+\n+No further changes are made for `tctl`.\n+\n+\n+#### Web UI Implementation\n+\n+Previous planning and implementation work from database health checks makes displaying Kubernetes health checks straight-forward. No new visual design patterns or coding design patterns are necessary. A Kubernetes health check UI implementation has surgical insertion points.\n+\n+`TargetHealth` property is added, and `kube_cluster` if/switch case logic is added in approximately nine files: \n+- [lib/web/apiserver.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/apiserver.go#L3414)\n+- [lib/web/ui/server.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/ui/server.go#L117)\n+- [web/packages/shared/components/UnifiedResources/FilterPanel.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/FilterPanel.tsx#L180)\n+- [web/packages/shared/components/UnifiedResources/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/types.ts#L100)\n+- [web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx#L149)\n+- [web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts#L94)\n+- [web/packages/teleport/src/services/kube/makeKube.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/makeKube.ts#L21)\n+- [web/packages/teleport/src/services/kube/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/types.ts#L21)\n+- [web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx#L560)\n+\n+The Teleport Connect UI is implemented at the same time as the Web UI. Teleport Connect  shares UI components, such as `UnifiedResource`, making the implementation closely related.\n+\n+\n+#### Prometheus Implementation\n+\n+Two Prometheus metrics are added to the `healthcheck` package:\n+\n+- `teleport_health_resources` for the expected number of healthy resources\n+- `teleport_health_resources_available` for the actual number of healthy resources",
        "comment_created_at": "2025-08-26T20:22:33+00:00",
        "comment_author": "rana",
        "comment_body": "#### Quantity of Metrics\r\n\r\n> Can we achieve that when unhealthy and unknown targets are grouped together?\r\n\r\nSomewhat, but not clearly. With a two metric design the `unknown` health state is ambiguous. An unknown resource isn't available, so it could imply unhealthy with `_targets - _targets_available`. To address that, `_targets` could be decremented when a resource is `unknown` to make the unhealthy calculation more accurate. Information would be lost on `unknown` targets in that case. Neither is quite clear, and motivates adding more metrics.\r\n\r\n> also what do you think about splitting \"_available\" into \"_healthy\" and \"_unhealthy?\r\n> There's 3 health states, so doing this will allow them to disambiguate unhealthy/unknown targets.\r\n\r\nYes, three or four metrics would make things clearer.\r\n\r\nOption A. Three metrics with `_targets`:\r\n- `_targets` // total\r\n- `_healthy_targets`\r\n- `_unhealthy_targets`\r\n- unknown = `_targets - _healthy_targets - _unhealthy_targets`\r\n\r\nOption B. Three metrics with `_unknown`:\r\n- `_healthy_targets`\r\n- `_unhealthy_targets`\r\n- `_unknown_targets`\r\n- total = `_healthy_targets + _unhealthy_targets + _unknown_targets`\r\n\r\nOption C. Four metrics:\r\n- `_targets` // total\r\n- `_healthy_targets`\r\n- `_unhealthy_targets`\r\n- `_unknown_targets`\r\n\r\nFour metrics have instant readability without the need to calculate. The drawback being it's less efficient, creating +1 time series and using disk space for something that could be calculated.\r\n\r\nOne scenario that Gavin designs for in `healthcheck` is config updates which affect the matchers. A resource (db|k8s|mwi) can be added or removed at runtime, and transition from unknown -> (healthy|unhealthy), or (healthy|unhealthy) -> unknown. Having three or four metrics would disambiguate.\r\n\r\n#### Naming of Metrics\r\n\r\nI like the explicitness of:\r\n- `teleport_resource_health_check_targets` for the expected number of healthy resources\r\n- `teleport_resource_health_check_targets_available` for the actual number of healthy resources\r\n\r\nLet's continue thinking it through.\r\n\r\n`_resource` and `_targets` are a bit redundant. Essentially `resource` = `target` = `db|k8s|mwi`. Pick one if possible?\r\n\r\nFrom the UI, `resource` is a keyword for all the things. In the [existing Teleport metrics](https://github.com/gravitational/teleport/blob/master/docs/pages/includes/metrics.mdx), there's one mention of `resource` in `teleport_connected_resources` for Auth server. Metrics are specifically named `db`, `kubernetes`, etc. But prior metric naming doesn't necessarily have to determine future names.\r\n\r\n`health_check_targets` points to health, which I find helpful. But is it only helpful to engineers designing the feature? From a customer point of view, `health_check_targets` might be an additional level of indirection. What is a health target? Oh, it's a resource. What's a resource? Oh, it's a db, or Kubernetes cluster. `health_check_targets` -> `resource` -> `db|k8s|mwi`. Also consider redundancy of the word \"health\" in Option D.\r\n\r\nOption D. Three metrics with `_health_check_targets` (Redundant `health`)\r\n- `teleport_health_check_targets`\r\n- `teleport_health_check_targets_healthy`\r\n- `teleport_health_check_targets_unhealthy`\r\n\r\nBringing it all together. I'm leaning towards three or four metrics with explicit naming `db|k8s|mwi` or `_health_checks`.\r\n\r\nOption E. Four metrics with explicit resource names\r\n- `teleport_db_total`|`teleport_db_connected`|`teleport_db_enrolled`|`teleport_db`\r\n- `teleport_db_healthy`\r\n- `teleport_db_unhealthy`\r\n- `teleport_db_unknown`\r\n\r\nEach resource would have an explicitly named metric generated by the `healthcheck` package. Easier reading for a customer. Less efficient on disk. No calculation for `unknown`. `teleport_db_total` goes against a Prometheus \"best practice\" of not naming Gauge types with `_total`. I find it helpful here.\r\n\r\nI'm just realizing that Option E naming, missing the `health` keyword in `teleport_db_total`, doesn't account for health configuration total being different than total enrolled/connected, which Tim points out in another thread.\r\n\r\nOption F. Three metrics with `_health_checks`\r\n- `teleport_health_checks`\r\n- `teleport_health_checks_healthy`\r\n- `teleport_health_checks_unhealthy`\r\n- unknown = `teleport_health_checks - teleport_health_checks_healthy - teleport_health_checks_unhealthy`\r\n- type=\"db|k8s|mwi\"\r\n\r\nHealth check naming focus. Efficient with three metrics. Calculate `unknown`.\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2302296898",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58065,
        "pr_file": "rfd/0223-k8s-health-checks.md",
        "discussion_id": "2299671731",
        "commented_code": "@@ -0,0 +1,623 @@\n+---\n+authors: Rana Ian (rana.ian@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0223 - Kubernetes Health Checks\n+\n+## Required Approvals\n+\n+- Engineering: @rosstimothy && @creack && @tigrato\n+\n+\n+## What\n+\n+Enable automated Kubernetes cluster health checks that are viewed by the Web UI, Teleport Connect, `tctl` command, and Prometheus metrics.\n+\n+## Why\n+\n+Proxied Kubernetes cluster health may be manually exercised with Kubernetes operations in the Web UI, or `kubectl` command, then observing the result. While effective, manual checking is also slow and unscalable. \n+\n+Automated Kubernetes health checks with new methods of viewing improve maintainability of Teleport Kubernetes clusters, while enabling new scenarios.\n+\n+Automated health checks:\n+- Improve time to observe and resolve Kubernetes cluster errors\n+- Improve manageability of Kubernetes clusters, especially at scale\n+- Improve the enrollment experience for Kubernetes clusters\n+- Enables alerting on unhealthy Kubernetes clusters\n+- Provides feature parity with databases and machine workload identities\n+\n+## Details\n+\n+### UX\n+\n+#### User Story: Web UI - Enrolling Kubernetes Clusters\n+\n+Alice enrolls three Amazon EKS clusters into Teleport through the Web UI.\n+\n+The next day she returns to the Web UI _Resources_ tab to find the Amazon EKS clusters are highlighted with warnings. She clicks on an Amazon EKS tile and a health message is displayed in a side panel.\n+\n+```\n+Kubernetes Cluster Issues\n+\n+3 Teleport Kubernetes clusters report issues.\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: sol\n+  UUID: 52dedbd0-b165-4bf6-9bc3-961f95bf481d\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: jupiter\n+  UUID: bb4dc171-ffa7-4a31-ba8c-7bf91c59e250\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: saturn\n+  UUID: 2be08cb1-56a4-401f-a3f3-c755a73f3ff6\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+```\n+\n+Alice notices that each cluster has a similar 503 message saying etcd is the source of the error.\n+\n+Alice resolves the `etcd` error, and each Amazon EKS cluster returns to a healthy state.\n+\n+As she monitors the Teleport Web UI, she sees each Amazon EKS tile switch from a warning state to a normal state.\n+\n+\n+#### User Story: `tctl` - Configuring a New Health Check\n+\n+Bob reads about Kubernetes health checks in a Teleport changelog, and updates a Teleport cluster to the new major version.\n+\n+Bob runs `tctl get health_check_config/default` from a terminal to view the default health settings.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+```\n+\n+He notices a new `kubernetes_labels` matcher.\n+\n+He vets the Kubernetes health checks in non-production environments.\n+\n+Bob runs `tctl edit health_check_config/default` from a terminal, updating the default settings to exclude Kubernetes health checks from a production environment.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Bob runs `tctl get kube_server/luna` from a terminal, validating that the expected Kubernetes cluster is monitoring health. \n+```yaml\n+kind: kube_server\n+metadata:\n+  expires: \"2025-10-26T00:00:00.000000Z\"\n+  name: luna\n+  revision: 43e96231-faaf-43c3-b9b8-15cf91813389\n+spec:\n+  host_id: 278be63c-c87e-4d7e-a286-86002c7c45c3\n+  hostname: luna\n+status:\n+  target_health:\n+    addr: luna:3027\n+    protocol: TLS\n+    transition_timestamp: \"2025-10-25T00:00:00.000000Z\"\n+    transition_reason: \"healthy threshold reached\"\n+    status: healthy\n+  version: 19.0.0\n+version: v3\n+```\n+\n+\n+#### User Story: Prometheus - Alerting on an Unhealthy Kubernetes Cluster\n+\n+Charlie relies on Prometheus to notify him of outages and calls to action.\n+\n+He reads about Kubernetes cluster health being available with Prometheus metrics.\n+\n+Charlie tests the feature.\n+\n+He enrolls three GKE instances into Teleport.\n+\n+He queries the new Teleport Prometheus health metrics.\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 3, the actual number of healthy Kubernetes clusters\n+```\n+\n+Charlie sets one GKE instance into an unhealthy state and requeries.\n+\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 2, the actual number of healthy Kubernetes clusters\n+```\n+\n+Seeing the metric values returning, he sets up a Prometheus alerting rule.\n+\n+```yaml\n+groups:\n+  - name: teleport_kubernetes\n+    rules:\n+      - alert: KubernetesClusterUnhealthy\n+        expr: |\n+          (teleport_health_resources{type=\"kubernetes\"} - \n+           teleport_health_resources_available{type=\"kubernetes\"}) > 0\n+        for: 5m\n+        labels:\n+          severity: warning\n+          team: platform\n+          component: teleport\n+          service: kubernetes\n+        annotations:\n+          summary: \"{{ $value }} Kubernetes cluster(s) unhealthy in Teleport\"\n+          description: \"Teleport reports {{ $value }} unhealthy Kubernetes cluster(s). This indicates that one or more Kubernetes clusters registered with Teleport are not responding or failing health checks. Check Teleport Web UI or use tctl for details.\"\n+          runbook_url: \"https://wiki.goteleport.com/runbooks/teleport-k8s-unhealthy\"\n+          dashboard_url: \"https://grafana.luna.com/d/teleport-k8s/teleport-kubernetes-health\"\n+          query: 'teleport_health_resources{type=\"kubernetes\"} - teleport_health_resources_available{type=\"kubernetes\"}'\n+```\n+\n+Prometheus alerts him about the unhealthy Kubernetes cluster.\n+\n+Charlie sets the GKE instance into a healthy state and moves on with his day.\n+\n+\n+### Implementation Details\n+\n+Kubernetes health checks are discussed by functional areas of core logic, `tctl` command, Web UI, and Prometheus metrics.\n+\n+#### Core Implementation\n+\n+Teleport Kubernetes health checks use the Teleport `healthcheck` package, and is based on existing [database health check](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#user-content-fn-1-b6df2ad8fd7a63ee3ca0af227e74ab87) design patterns. The `healthcheck` components are written, tested, and in production. The focus and effort for Kubernetes health checks is integrating health checks into the Kubernetes agent, extending existing `healthcheck` mechanisms, and updating the UI.\n+\n+##### Core Configuration\n+\n+A first step to enabling Kubernetes health checks is adding new matchers to the `HealthCheckConfig` service. `HealthCheckConfig` identifies servers which choose to participate in health checking. `HealthCheckConfig` supports databases. Kubernetes additions mirror the database features.\n+\n+The configuration adds matchers `kubernetes_labels` and `kubernetes_labels_expression` which specify labeled Kubernetes clusters. By default, all Kubernetes clusters participate in health checks. Matchers may filter Kubernetes clusters. Deleting the matchers excludes all Kubernetes clusters.\n+\n+An example yaml `health_check_config`:\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Change points for health check configuration:\n+- [api/proto/teleport/healthcheckconfig/v1/health_check_config.proto](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/api/proto/teleport/healthcheckconfig/v1/health_check_config.proto#L59)\n+  - Adds `kubernetes_labels` and `kubernetes_labels_expression` to proto message `Matcher`\n+- [lib/services/health_check_config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/health_check_config.go#L58)\n+  - Adds Kubernetes label matcher validation to function `ValidateHealthCheckConfig()`\n+- [lib/healthcheck/config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/config.go#L35)\n+  - Adds Kubernetes label matcher field to type `healthCheckConfig`, and update functions `newHealthCheckConfig()` and `getLabelMatchers()`\n+- [lib/services/presets.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/presets.go#L830)\n+  - Adds wildcard Kubernetes label matchers to function `NewPresetHealthCheckConfig()`\n+\n+`HealthCheckConfig` is communicated via proxy and cached on a Kubernetes agent. Kubernetes interfaces are updated to support the communication and caching.\n+\n+Change points for communication and caching:\n+- [lib/auth/authclient/api.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/auth/authclient/api.go#L472)\n+  - Adds `services.HealthCheckConfigReader` to interfaces `ReadKubernetesAccessPoint` and `ProxyAccessPoint` \n+- api/types/kubernetes_server.go\n+  - Adds functions `GetTargetHealth()`, `SetTargetHealth()`, `GetTargetHealthStatus()`, and `SetTargetHealthStatus()` to the `KubeServer` interface for implementing interface `services.HealthCheckConfigReader`\n+- [lib/cache/cache.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/cache/cache.go#L356)\n+  - Adds watches for `types.KindHealthCheckConfig` in `ForKubernetes()` and `ForProxy()`\n+- [lib/authz/permissions.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/authz/permissions.go#L1183)\n+  - Adds new rules for `types.KindHealthCheckConfig`\n+\n+Details for configuring `HealthCheckConfig` with interval, timeout, and healthy/unhealthy thresholds are described in the [database health check RFD](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#configuration).\n+\n+\n+##### Core Kubernetes Agent\n+\n+The Kubernetes agent registers one or more Kubernetes clusters, checks the health of proxied Kubernetes clusters, and communicates the health state to the auth server. The agent adds a `healthcheck.Manager` which performs the registration and health check operations. The Kubernetes agent is named `TLSServer`, and is located in [lib/kube/proxy/server.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/kube/proxy/server.go#L187).\n+\n+Change points include:\n+\n+Modifying methods:\n+- `(*TLSServerConfig).CheckAndSetDefaults()` - Initializes the `healthcheck.Manager`\n+- `(*TLSServer).Serve()` - Starts `healthcheck.Manager` \n+- `(*TLSServer).startStaticClustersHeartbeat()` - Registers all Kubernetes clusters for health monitoring\n+- `(*TLSServer).close()` - Unregisters all Kubernetes clusters from health monitoring\n+\n+Adding methods:\n+- `(*TLSServer).startTargetHealth()` - Registers a single Kubernetes cluster for health monitoring\n+- `(*TLSServer).stopTargetHealth()` - Unregisters a single Kubernetes cluster from health monitoring\n+- `(*TLSServer).getTargetHealth()` - Gets health for a single Kubernetes cluster\n+\n+\n+##### Core `healthcheck` Package\n+\n+The `healthcheck` package performs recurring health checks on one or more Teleport resources: databases, Kubernetes clusters, etc. It's a general library that currently supports TCP checks. Adding TLS checks is a focus for Kubernetes. \n+\n+Main change points are:\n+- [lib/healthcheck/worker.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/worker.go#L343)\n+  - Modifying the `dialEndpoint()` function to make TLS requests.\n+\n+[manager.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/manager.go) and [target.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/target.go) have minor changes.\n+\n+Prometheus gauge metrics are added to the `healthcheck` package, and described in the [Prometheus Implementation](#prometheus-implementation).\n+\n+\n+#### Health States\n+\n+A Kubernetes cluster may be in a health state of `unknown`, `healthy` or `unhealthy`.\n+- `unknown` indicates a Kubernetes cluster cannot be contacted\n+- `healthy` indicates a Kubernetes cluster is accepting requests\n+- `unhealthy` indicates an error state, and includes an error message with verbose debugging information, if available\n+\n+See the database health check RFD for [more details](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#health-status).\n+\n+\n+##### Health Check Endpoint\n+\n+> [!NOTE]\n+> Kubernetes health checked at `https://<address>/readyz`\n+\n+> [!IMPORTANT]\n+> Requires Kubernetes v1.16 or higher\n+\n+The Kubernetes API `/readyz` endpoint is selected for health checking, and indicates that a Kubernetes API server is ready to accept requests. Kubernetes serves the endpoint through [TLS by default](https://kubernetes.io/docs/concepts/security/controlling-access/#transport-security).\n+\n+The Kubernetes API offers [several health check endpoints](https://kubernetes.io/docs/reference/using-api/health-checks), as well as TCP checks being available.\n+\n+| Approach        | Description                                              |\n+|-----------------|----------------------------------------------------------|\n+| /readyz         | Ready to accept API requests                             |\n+| /readyz?verbose | Ready to accept API requests (detailed)                  |\n+| /livez          | kube-apiserver process is alive/running                  |\n+| /livez?verbose  | kube-apiserver process is alive/running (detailed)       |\n+| /healthz        | Ambiguously alive or ready. Deprecated in 2019 at v1.16  |\n+| TCP             | Can establish TCP connection to API server port          |\n+\n+Let's explore the options and reasoning for selecting `/readyz`.\n+\n+`/readyz` means that the cluster is accepting API requests, and can be used.\n+\n+`/livez` indicates the Kubernetes kube-apiserver process is alive. API requests may or may not be accepted. There's no implication of whole cluster readiness.\n+\n+`/healthz` is deprecated, and not supported with the Kubernetes health check feature. `/healthz` was [deprecated in September of 2019 with Kubernetes v1.16](https://kubernetes.io/blog/2019/09/18/kubernetes-1-16-release-announcement/). At the time of writing, [Kubernetes is at v1.33](https://kubernetes.io/blog/2025/04/23/kubernetes-v1-33-release/), and six years have passed since v1.16. It seems reasonable not to support the `/healthz` endpoint. The choice then sets up a requirement for customers to use Kubernetes v1.16 or higher with Teleport Kubernetes health checks.\n+\n+Moving on to `TCP`, `TCP` indicates that network connectivity is available. No further knowledge of Kubernetes health would be known. In scenarios where servers don't offer explicit health checks, such as databases, `TCP` may be the only choice. Since Kubernetes offers health checks, we can skip `TCP` checks.\n+\n+So, `/livez` and `TCP` indicate some level of health, but do not necessarily mean the Kubernetes cluster can be used. \n+\n+Let's look at the `verbose` query parameter.\n+\n+`/readyz?verbose` provides a list of Kubernetes modules with `ok / not ok` states. The verbose information is not critical in the common case of a healthy cluster returning a `200` HTTP status code. The verbose information may be helpful to an administrator diagnosing an unhealthy cluster.\n+\n+For efficiency in the common case of a healthy cluster, the `/readyz` endpoint is called and checked for a `200` status code. In nearly all cases we only need to check `200`. The `verbose` body message is not sent, reducing unneeded network, memory, and processor consumption. Also, the Kubernetes authors recommend [relying on the status code](https://kubernetes.io/docs/reference/using-api/health-checks/) for checking state.\n+\n+In the case of non-`200` response codes, a follow-up call to `/readyz?verbose` is made. The follow-up verbose message is appended to a Go error, and eventually forwarded to the Web UI for a Teleport administrator to view.\n+\n+An example `/readyz?verbose` response body for a `503 Service Unavailable` HTTP status code:\n+```\n+[+]ping ok\n+[+]log ok\n+[-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+[+]poststarthook/start-kube-apiserver-admission-initializer ok\n+[+]poststarthook/generic-apiserver-start-informers ok\n+...\n+[+]shutdown ok\n+readyz check failed\n+```\n+\n+Alternatives not chosen:\n+- Providing a blend of fallback health checks with `/readyz` -> `/readyz?verbose` -> `/livez?verbose` -> `TCP`. If each call returned a non-`200` error, a fallback approach could be selected. The scenario would capture as much information as is available for the Teleport administrator. The approach is not selected, as it's seen as over-engineering for minimal return.\n+- Monitoring node and pod health starts to walk into a large universe of Kubernetes observability, which is solved with multiple observability products. It's also worth noting that cluster health is distinct from individual node and pod health. The Kubernetes API server can be healthy and accept requests while individual nodes or pods within the cluster are unhealthy. A cluster may also be in a reduced capacity state where there are a mixture of healthy and unhealthy nodes. These all appear beyond the scope of the RFD. Kubernetes cluster checks provide visibility into resources managed by Teleport, and compliment observability solutions. Various in-depth node and pod metrics are available in observability solutions. The [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics?tab=readme-ov-file#overview) project can be added in [Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/metrics-server.html), [Google GKE](https://cloud.google.com/kubernetes-engine/docs/how-to/kube-state-metrics), and [Azure AKS](https://learn.microsoft.com/en-us/azure/azure-monitor/containers/prometheus-metrics-scrape-default). Detailed Kubernetes metrics may or may not be interesting for a future feature.\n+- Checking Kubernetes node health after a cluster is unhealthy may, or may not provide interesting diagnostic information for a Teleport administrator. That could be done via the Kubernetes API. It would add complexity, and may have limited value. Node health could be obtained with an observability solution like kube-state-metrics. Having a downed node doesn't necessarily imply a cluster is unhealthy; perhaps at reduced capacity, or possibly unhealthy. The complexity grows, and may best be addressed by observability solutions.\n+\n+> [!NOTE]\n+> Node health != Kubernetes cluster health\n+\n+> [!NOTE]\n+> Pod health != Kubernetes cluster health\n+\n+Calling `/readyz` with a fallback to `/readyz?verbose` achieves the objective of providing the `healthy / unhealthy` state, with diagnostics when needed. Once an unhealthy Kubernetes cluster is detected as unhealthy, a Teleport administrator is expected to follow up with other approaches.\n+\n+\n+#### `tctl` Implementation\n+\n+Planned changes to `HealthCheckConfig` percolate to `tctl`. \n+\n+No further changes are made for `tctl`.\n+\n+\n+#### Web UI Implementation\n+\n+Previous planning and implementation work from database health checks makes displaying Kubernetes health checks straight-forward. No new visual design patterns or coding design patterns are necessary. A Kubernetes health check UI implementation has surgical insertion points.\n+\n+`TargetHealth` property is added, and `kube_cluster` if/switch case logic is added in approximately nine files: \n+- [lib/web/apiserver.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/apiserver.go#L3414)\n+- [lib/web/ui/server.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/ui/server.go#L117)\n+- [web/packages/shared/components/UnifiedResources/FilterPanel.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/FilterPanel.tsx#L180)\n+- [web/packages/shared/components/UnifiedResources/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/types.ts#L100)\n+- [web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx#L149)\n+- [web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts#L94)\n+- [web/packages/teleport/src/services/kube/makeKube.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/makeKube.ts#L21)\n+- [web/packages/teleport/src/services/kube/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/types.ts#L21)\n+- [web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx#L560)\n+\n+The Teleport Connect UI is implemented at the same time as the Web UI. Teleport Connect  shares UI components, such as `UnifiedResource`, making the implementation closely related.\n+\n+\n+#### Prometheus Implementation\n+\n+Two Prometheus metrics are added to the `healthcheck` package:\n+\n+- `teleport_health_resources` for the expected number of healthy resources\n+- `teleport_health_resources_available` for the actual number of healthy resources",
        "comment_created_at": "2025-08-26T22:37:23+00:00",
        "comment_author": "GavinFrazar",
        "comment_body": "I prefer option B.\r\nNo redundant metric, explicit about the 3 health states, and you can just sum them to get the total.\r\nI also prefer to keep the resource type as a label instead of splitting out metric names for each resource kind.\r\n\r\n> _resource and _targets are a bit redundant. Essentially resource = target = db|k8s|mwi. Pick one if possible?\r\n\r\nYeah it is a little redundant naming.\r\nHow about this:\r\n\r\n```\r\nteleport_resources_health_status_healthy\r\nteleport_resources_health_status_unhealthy\r\nteleport_resources_health_status_unknown\r\n```\r\n\r\nI'd like to keep \"teleport_resource(s)\" specifically because to me it indicates that these are health checks on \"teleport resources\" which I take to mean \"connected resources\" instead of internal teleport components being health checked.",
        "pr_file_module": null
      },
      {
        "comment_id": "2302353693",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58065,
        "pr_file": "rfd/0223-k8s-health-checks.md",
        "discussion_id": "2299671731",
        "commented_code": "@@ -0,0 +1,623 @@\n+---\n+authors: Rana Ian (rana.ian@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0223 - Kubernetes Health Checks\n+\n+## Required Approvals\n+\n+- Engineering: @rosstimothy && @creack && @tigrato\n+\n+\n+## What\n+\n+Enable automated Kubernetes cluster health checks that are viewed by the Web UI, Teleport Connect, `tctl` command, and Prometheus metrics.\n+\n+## Why\n+\n+Proxied Kubernetes cluster health may be manually exercised with Kubernetes operations in the Web UI, or `kubectl` command, then observing the result. While effective, manual checking is also slow and unscalable. \n+\n+Automated Kubernetes health checks with new methods of viewing improve maintainability of Teleport Kubernetes clusters, while enabling new scenarios.\n+\n+Automated health checks:\n+- Improve time to observe and resolve Kubernetes cluster errors\n+- Improve manageability of Kubernetes clusters, especially at scale\n+- Improve the enrollment experience for Kubernetes clusters\n+- Enables alerting on unhealthy Kubernetes clusters\n+- Provides feature parity with databases and machine workload identities\n+\n+## Details\n+\n+### UX\n+\n+#### User Story: Web UI - Enrolling Kubernetes Clusters\n+\n+Alice enrolls three Amazon EKS clusters into Teleport through the Web UI.\n+\n+The next day she returns to the Web UI _Resources_ tab to find the Amazon EKS clusters are highlighted with warnings. She clicks on an Amazon EKS tile and a health message is displayed in a side panel.\n+\n+```\n+Kubernetes Cluster Issues\n+\n+3 Teleport Kubernetes clusters report issues.\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: sol\n+  UUID: 52dedbd0-b165-4bf6-9bc3-961f95bf481d\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: jupiter\n+  UUID: bb4dc171-ffa7-4a31-ba8c-7bf91c59e250\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: saturn\n+  UUID: 2be08cb1-56a4-401f-a3f3-c755a73f3ff6\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+```\n+\n+Alice notices that each cluster has a similar 503 message saying etcd is the source of the error.\n+\n+Alice resolves the `etcd` error, and each Amazon EKS cluster returns to a healthy state.\n+\n+As she monitors the Teleport Web UI, she sees each Amazon EKS tile switch from a warning state to a normal state.\n+\n+\n+#### User Story: `tctl` - Configuring a New Health Check\n+\n+Bob reads about Kubernetes health checks in a Teleport changelog, and updates a Teleport cluster to the new major version.\n+\n+Bob runs `tctl get health_check_config/default` from a terminal to view the default health settings.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+```\n+\n+He notices a new `kubernetes_labels` matcher.\n+\n+He vets the Kubernetes health checks in non-production environments.\n+\n+Bob runs `tctl edit health_check_config/default` from a terminal, updating the default settings to exclude Kubernetes health checks from a production environment.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Bob runs `tctl get kube_server/luna` from a terminal, validating that the expected Kubernetes cluster is monitoring health. \n+```yaml\n+kind: kube_server\n+metadata:\n+  expires: \"2025-10-26T00:00:00.000000Z\"\n+  name: luna\n+  revision: 43e96231-faaf-43c3-b9b8-15cf91813389\n+spec:\n+  host_id: 278be63c-c87e-4d7e-a286-86002c7c45c3\n+  hostname: luna\n+status:\n+  target_health:\n+    addr: luna:3027\n+    protocol: TLS\n+    transition_timestamp: \"2025-10-25T00:00:00.000000Z\"\n+    transition_reason: \"healthy threshold reached\"\n+    status: healthy\n+  version: 19.0.0\n+version: v3\n+```\n+\n+\n+#### User Story: Prometheus - Alerting on an Unhealthy Kubernetes Cluster\n+\n+Charlie relies on Prometheus to notify him of outages and calls to action.\n+\n+He reads about Kubernetes cluster health being available with Prometheus metrics.\n+\n+Charlie tests the feature.\n+\n+He enrolls three GKE instances into Teleport.\n+\n+He queries the new Teleport Prometheus health metrics.\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 3, the actual number of healthy Kubernetes clusters\n+```\n+\n+Charlie sets one GKE instance into an unhealthy state and requeries.\n+\n+```promql\n+teleport_health_resources{type=\"kubernetes\"}\n+# Returns 3, the expected number of healthy Kubernetes clusters\n+\n+teleport_health_resources_available{type=\"kubernetes\"}\n+# Returns 2, the actual number of healthy Kubernetes clusters\n+```\n+\n+Seeing the metric values returning, he sets up a Prometheus alerting rule.\n+\n+```yaml\n+groups:\n+  - name: teleport_kubernetes\n+    rules:\n+      - alert: KubernetesClusterUnhealthy\n+        expr: |\n+          (teleport_health_resources{type=\"kubernetes\"} - \n+           teleport_health_resources_available{type=\"kubernetes\"}) > 0\n+        for: 5m\n+        labels:\n+          severity: warning\n+          team: platform\n+          component: teleport\n+          service: kubernetes\n+        annotations:\n+          summary: \"{{ $value }} Kubernetes cluster(s) unhealthy in Teleport\"\n+          description: \"Teleport reports {{ $value }} unhealthy Kubernetes cluster(s). This indicates that one or more Kubernetes clusters registered with Teleport are not responding or failing health checks. Check Teleport Web UI or use tctl for details.\"\n+          runbook_url: \"https://wiki.goteleport.com/runbooks/teleport-k8s-unhealthy\"\n+          dashboard_url: \"https://grafana.luna.com/d/teleport-k8s/teleport-kubernetes-health\"\n+          query: 'teleport_health_resources{type=\"kubernetes\"} - teleport_health_resources_available{type=\"kubernetes\"}'\n+```\n+\n+Prometheus alerts him about the unhealthy Kubernetes cluster.\n+\n+Charlie sets the GKE instance into a healthy state and moves on with his day.\n+\n+\n+### Implementation Details\n+\n+Kubernetes health checks are discussed by functional areas of core logic, `tctl` command, Web UI, and Prometheus metrics.\n+\n+#### Core Implementation\n+\n+Teleport Kubernetes health checks use the Teleport `healthcheck` package, and is based on existing [database health check](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#user-content-fn-1-b6df2ad8fd7a63ee3ca0af227e74ab87) design patterns. The `healthcheck` components are written, tested, and in production. The focus and effort for Kubernetes health checks is integrating health checks into the Kubernetes agent, extending existing `healthcheck` mechanisms, and updating the UI.\n+\n+##### Core Configuration\n+\n+A first step to enabling Kubernetes health checks is adding new matchers to the `HealthCheckConfig` service. `HealthCheckConfig` identifies servers which choose to participate in health checking. `HealthCheckConfig` supports databases. Kubernetes additions mirror the database features.\n+\n+The configuration adds matchers `kubernetes_labels` and `kubernetes_labels_expression` which specify labeled Kubernetes clusters. By default, all Kubernetes clusters participate in health checks. Matchers may filter Kubernetes clusters. Deleting the matchers excludes all Kubernetes clusters.\n+\n+An example yaml `health_check_config`:\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Change points for health check configuration:\n+- [api/proto/teleport/healthcheckconfig/v1/health_check_config.proto](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/api/proto/teleport/healthcheckconfig/v1/health_check_config.proto#L59)\n+  - Adds `kubernetes_labels` and `kubernetes_labels_expression` to proto message `Matcher`\n+- [lib/services/health_check_config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/health_check_config.go#L58)\n+  - Adds Kubernetes label matcher validation to function `ValidateHealthCheckConfig()`\n+- [lib/healthcheck/config.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/config.go#L35)\n+  - Adds Kubernetes label matcher field to type `healthCheckConfig`, and update functions `newHealthCheckConfig()` and `getLabelMatchers()`\n+- [lib/services/presets.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/services/presets.go#L830)\n+  - Adds wildcard Kubernetes label matchers to function `NewPresetHealthCheckConfig()`\n+\n+`HealthCheckConfig` is communicated via proxy and cached on a Kubernetes agent. Kubernetes interfaces are updated to support the communication and caching.\n+\n+Change points for communication and caching:\n+- [lib/auth/authclient/api.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/auth/authclient/api.go#L472)\n+  - Adds `services.HealthCheckConfigReader` to interfaces `ReadKubernetesAccessPoint` and `ProxyAccessPoint` \n+- api/types/kubernetes_server.go\n+  - Adds functions `GetTargetHealth()`, `SetTargetHealth()`, `GetTargetHealthStatus()`, and `SetTargetHealthStatus()` to the `KubeServer` interface for implementing interface `services.HealthCheckConfigReader`\n+- [lib/cache/cache.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/cache/cache.go#L356)\n+  - Adds watches for `types.KindHealthCheckConfig` in `ForKubernetes()` and `ForProxy()`\n+- [lib/authz/permissions.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/authz/permissions.go#L1183)\n+  - Adds new rules for `types.KindHealthCheckConfig`\n+\n+Details for configuring `HealthCheckConfig` with interval, timeout, and healthy/unhealthy thresholds are described in the [database health check RFD](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#configuration).\n+\n+\n+##### Core Kubernetes Agent\n+\n+The Kubernetes agent registers one or more Kubernetes clusters, checks the health of proxied Kubernetes clusters, and communicates the health state to the auth server. The agent adds a `healthcheck.Manager` which performs the registration and health check operations. The Kubernetes agent is named `TLSServer`, and is located in [lib/kube/proxy/server.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/kube/proxy/server.go#L187).\n+\n+Change points include:\n+\n+Modifying methods:\n+- `(*TLSServerConfig).CheckAndSetDefaults()` - Initializes the `healthcheck.Manager`\n+- `(*TLSServer).Serve()` - Starts `healthcheck.Manager` \n+- `(*TLSServer).startStaticClustersHeartbeat()` - Registers all Kubernetes clusters for health monitoring\n+- `(*TLSServer).close()` - Unregisters all Kubernetes clusters from health monitoring\n+\n+Adding methods:\n+- `(*TLSServer).startTargetHealth()` - Registers a single Kubernetes cluster for health monitoring\n+- `(*TLSServer).stopTargetHealth()` - Unregisters a single Kubernetes cluster from health monitoring\n+- `(*TLSServer).getTargetHealth()` - Gets health for a single Kubernetes cluster\n+\n+\n+##### Core `healthcheck` Package\n+\n+The `healthcheck` package performs recurring health checks on one or more Teleport resources: databases, Kubernetes clusters, etc. It's a general library that currently supports TCP checks. Adding TLS checks is a focus for Kubernetes. \n+\n+Main change points are:\n+- [lib/healthcheck/worker.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/worker.go#L343)\n+  - Modifying the `dialEndpoint()` function to make TLS requests.\n+\n+[manager.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/manager.go) and [target.go](https://github.com/gravitational/teleport/blob/590c85a765a6d8d16d5f34503179f27a97a4625c/lib/healthcheck/target.go) have minor changes.\n+\n+Prometheus gauge metrics are added to the `healthcheck` package, and described in the [Prometheus Implementation](#prometheus-implementation).\n+\n+\n+#### Health States\n+\n+A Kubernetes cluster may be in a health state of `unknown`, `healthy` or `unhealthy`.\n+- `unknown` indicates a Kubernetes cluster cannot be contacted\n+- `healthy` indicates a Kubernetes cluster is accepting requests\n+- `unhealthy` indicates an error state, and includes an error message with verbose debugging information, if available\n+\n+See the database health check RFD for [more details](https://github.com/gravitational/teleport/blob/master/rfd/0203-database-healthchecks.md#health-status).\n+\n+\n+##### Health Check Endpoint\n+\n+> [!NOTE]\n+> Kubernetes health checked at `https://<address>/readyz`\n+\n+> [!IMPORTANT]\n+> Requires Kubernetes v1.16 or higher\n+\n+The Kubernetes API `/readyz` endpoint is selected for health checking, and indicates that a Kubernetes API server is ready to accept requests. Kubernetes serves the endpoint through [TLS by default](https://kubernetes.io/docs/concepts/security/controlling-access/#transport-security).\n+\n+The Kubernetes API offers [several health check endpoints](https://kubernetes.io/docs/reference/using-api/health-checks), as well as TCP checks being available.\n+\n+| Approach        | Description                                              |\n+|-----------------|----------------------------------------------------------|\n+| /readyz         | Ready to accept API requests                             |\n+| /readyz?verbose | Ready to accept API requests (detailed)                  |\n+| /livez          | kube-apiserver process is alive/running                  |\n+| /livez?verbose  | kube-apiserver process is alive/running (detailed)       |\n+| /healthz        | Ambiguously alive or ready. Deprecated in 2019 at v1.16  |\n+| TCP             | Can establish TCP connection to API server port          |\n+\n+Let's explore the options and reasoning for selecting `/readyz`.\n+\n+`/readyz` means that the cluster is accepting API requests, and can be used.\n+\n+`/livez` indicates the Kubernetes kube-apiserver process is alive. API requests may or may not be accepted. There's no implication of whole cluster readiness.\n+\n+`/healthz` is deprecated, and not supported with the Kubernetes health check feature. `/healthz` was [deprecated in September of 2019 with Kubernetes v1.16](https://kubernetes.io/blog/2019/09/18/kubernetes-1-16-release-announcement/). At the time of writing, [Kubernetes is at v1.33](https://kubernetes.io/blog/2025/04/23/kubernetes-v1-33-release/), and six years have passed since v1.16. It seems reasonable not to support the `/healthz` endpoint. The choice then sets up a requirement for customers to use Kubernetes v1.16 or higher with Teleport Kubernetes health checks.\n+\n+Moving on to `TCP`, `TCP` indicates that network connectivity is available. No further knowledge of Kubernetes health would be known. In scenarios where servers don't offer explicit health checks, such as databases, `TCP` may be the only choice. Since Kubernetes offers health checks, we can skip `TCP` checks.\n+\n+So, `/livez` and `TCP` indicate some level of health, but do not necessarily mean the Kubernetes cluster can be used. \n+\n+Let's look at the `verbose` query parameter.\n+\n+`/readyz?verbose` provides a list of Kubernetes modules with `ok / not ok` states. The verbose information is not critical in the common case of a healthy cluster returning a `200` HTTP status code. The verbose information may be helpful to an administrator diagnosing an unhealthy cluster.\n+\n+For efficiency in the common case of a healthy cluster, the `/readyz` endpoint is called and checked for a `200` status code. In nearly all cases we only need to check `200`. The `verbose` body message is not sent, reducing unneeded network, memory, and processor consumption. Also, the Kubernetes authors recommend [relying on the status code](https://kubernetes.io/docs/reference/using-api/health-checks/) for checking state.\n+\n+In the case of non-`200` response codes, a follow-up call to `/readyz?verbose` is made. The follow-up verbose message is appended to a Go error, and eventually forwarded to the Web UI for a Teleport administrator to view.\n+\n+An example `/readyz?verbose` response body for a `503 Service Unavailable` HTTP status code:\n+```\n+[+]ping ok\n+[+]log ok\n+[-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+[+]poststarthook/start-kube-apiserver-admission-initializer ok\n+[+]poststarthook/generic-apiserver-start-informers ok\n+...\n+[+]shutdown ok\n+readyz check failed\n+```\n+\n+Alternatives not chosen:\n+- Providing a blend of fallback health checks with `/readyz` -> `/readyz?verbose` -> `/livez?verbose` -> `TCP`. If each call returned a non-`200` error, a fallback approach could be selected. The scenario would capture as much information as is available for the Teleport administrator. The approach is not selected, as it's seen as over-engineering for minimal return.\n+- Monitoring node and pod health starts to walk into a large universe of Kubernetes observability, which is solved with multiple observability products. It's also worth noting that cluster health is distinct from individual node and pod health. The Kubernetes API server can be healthy and accept requests while individual nodes or pods within the cluster are unhealthy. A cluster may also be in a reduced capacity state where there are a mixture of healthy and unhealthy nodes. These all appear beyond the scope of the RFD. Kubernetes cluster checks provide visibility into resources managed by Teleport, and compliment observability solutions. Various in-depth node and pod metrics are available in observability solutions. The [kube-state-metrics](https://github.com/kubernetes/kube-state-metrics?tab=readme-ov-file#overview) project can be added in [Amazon EKS](https://docs.aws.amazon.com/eks/latest/userguide/metrics-server.html), [Google GKE](https://cloud.google.com/kubernetes-engine/docs/how-to/kube-state-metrics), and [Azure AKS](https://learn.microsoft.com/en-us/azure/azure-monitor/containers/prometheus-metrics-scrape-default). Detailed Kubernetes metrics may or may not be interesting for a future feature.\n+- Checking Kubernetes node health after a cluster is unhealthy may, or may not provide interesting diagnostic information for a Teleport administrator. That could be done via the Kubernetes API. It would add complexity, and may have limited value. Node health could be obtained with an observability solution like kube-state-metrics. Having a downed node doesn't necessarily imply a cluster is unhealthy; perhaps at reduced capacity, or possibly unhealthy. The complexity grows, and may best be addressed by observability solutions.\n+\n+> [!NOTE]\n+> Node health != Kubernetes cluster health\n+\n+> [!NOTE]\n+> Pod health != Kubernetes cluster health\n+\n+Calling `/readyz` with a fallback to `/readyz?verbose` achieves the objective of providing the `healthy / unhealthy` state, with diagnostics when needed. Once an unhealthy Kubernetes cluster is detected as unhealthy, a Teleport administrator is expected to follow up with other approaches.\n+\n+\n+#### `tctl` Implementation\n+\n+Planned changes to `HealthCheckConfig` percolate to `tctl`. \n+\n+No further changes are made for `tctl`.\n+\n+\n+#### Web UI Implementation\n+\n+Previous planning and implementation work from database health checks makes displaying Kubernetes health checks straight-forward. No new visual design patterns or coding design patterns are necessary. A Kubernetes health check UI implementation has surgical insertion points.\n+\n+`TargetHealth` property is added, and `kube_cluster` if/switch case logic is added in approximately nine files: \n+- [lib/web/apiserver.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/apiserver.go#L3414)\n+- [lib/web/ui/server.go](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/lib/web/ui/server.go#L117)\n+- [web/packages/shared/components/UnifiedResources/FilterPanel.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/FilterPanel.tsx#L180)\n+- [web/packages/shared/components/UnifiedResources/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/types.ts#L100)\n+- [web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/StatusInfo.tsx#L149)\n+- [web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/shared/components/UnifiedResources/shared/viewItemsFactory.ts#L94)\n+- [web/packages/teleport/src/services/kube/makeKube.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/makeKube.ts#L21)\n+- [web/packages/teleport/src/services/kube/types.ts](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleport/src/services/kube/types.ts#L21)\n+- [web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx](https://github.com/gravitational/teleport/blob/d08586408b3ad2af327af4af2644f7ac8de4e825/web/packages/teleterm/src/ui/DocumentCluster/UnifiedResources.tsx#L560)\n+\n+The Teleport Connect UI is implemented at the same time as the Web UI. Teleport Connect  shares UI components, such as `UnifiedResource`, making the implementation closely related.\n+\n+\n+#### Prometheus Implementation\n+\n+Two Prometheus metrics are added to the `healthcheck` package:\n+\n+- `teleport_health_resources` for the expected number of healthy resources\n+- `teleport_health_resources_available` for the actual number of healthy resources",
        "comment_created_at": "2025-08-26T23:15:10+00:00",
        "comment_author": "rana",
        "comment_body": "Sounds good.\r\nVery readable, no ambiguity across metric count or naming.\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2301245874",
    "pr_number": 58065,
    "pr_file": "rfd/0223-k8s-health-checks.md",
    "created_at": "2025-08-26T14:46:20+00:00",
    "commented_code": "+---\n+authors: Rana Ian (rana.ian@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0223 - Kubernetes Health Checks\n+\n+## Required Approvals\n+\n+- Engineering: @rosstimothy && @creack && @tigrato\n+\n+\n+## What\n+\n+Enable automated Kubernetes cluster health checks that are viewed by the Web UI, Teleport Connect, `tctl` command, and Prometheus metrics.\n+\n+## Why\n+\n+Proxied Kubernetes cluster health may be manually exercised with Kubernetes operations in the Web UI, or `kubectl` command, then observing the result. While effective, manual checking is also slow and unscalable. \n+\n+Automated Kubernetes health checks with new methods of viewing improve maintainability of Teleport Kubernetes clusters, while enabling new scenarios.\n+\n+Automated health checks:\n+- Improve time to observe and resolve Kubernetes cluster errors\n+- Improve manageability of Kubernetes clusters, especially at scale\n+- Improve the enrollment experience for Kubernetes clusters\n+- Enables alerting on unhealthy Kubernetes clusters\n+- Provides feature parity with databases and machine workload identities\n+\n+## Details\n+\n+### UX\n+\n+#### User Story: Web UI - Enrolling Kubernetes Clusters\n+\n+Alice enrolls three Amazon EKS clusters into Teleport through the Web UI.\n+\n+The next day she returns to the Web UI _Resources_ tab to find the Amazon EKS clusters are highlighted with warnings. She clicks on an Amazon EKS tile and a health message is displayed in a side panel.\n+\n+```\n+Kubernetes Cluster Issues\n+\n+3 Teleport Kubernetes clusters report issues.\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: sol\n+  UUID: 52dedbd0-b165-4bf6-9bc3-961f95bf481d\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: jupiter\n+  UUID: bb4dc171-ffa7-4a31-ba8c-7bf91c59e250\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: saturn\n+  UUID: 2be08cb1-56a4-401f-a3f3-c755a73f3ff6\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+```\n+\n+Alice notices that each cluster has a similar 503 message saying etcd is the source of the error.\n+\n+Alice resolves the `etcd` error, and each Amazon EKS cluster returns to a healthy state.\n+\n+As she monitors the Teleport Web UI, she sees each Amazon EKS tile switch from a warning state to a normal state.\n+\n+\n+#### User Story: `tctl` - Configuring a New Health Check\n+\n+Bob reads about Kubernetes health checks in a Teleport changelog, and updates a Teleport cluster to the new major version.\n+\n+Bob runs `tctl get health_check_config/default` from a terminal to view the default health settings.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+```\n+\n+He notices a new `kubernetes_labels` matcher.\n+\n+He vets the Kubernetes health checks in non-production environments.\n+\n+Bob runs `tctl edit health_check_config/default` from a terminal, updating the default settings to exclude Kubernetes health checks from a production environment.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Bob runs `tctl get kube_server/luna` from a terminal, validating that the expected Kubernetes cluster is monitoring health. \n+```yaml\n+kind: kube_server\n+metadata:\n+  expires: \"2025-10-26T00:00:00.000000Z\"\n+  name: luna\n+  revision: 43e96231-faaf-43c3-b9b8-15cf91813389\n+spec:\n+  host_id: 278be63c-c87e-4d7e-a286-86002c7c45c3\n+  hostname: luna\n+status:\n+  target_health:\n+    addr: luna:3027\n+    protocol: TLS\n+    transition_timestamp: \"2025-10-25T00:00:00.000000Z\"\n+    transition_reason: \"healthy threshold reached\"\n+    status: healthy\n+  version: 19.0.0\n+version: v3\n+```\n+\n+\n+#### User Story: Prometheus - Alerting on an Unhealthy Kubernetes Cluster",
    "repo_full_name": "gravitational/teleport",
    "discussion_comments": [
      {
        "comment_id": "2301245874",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58065,
        "pr_file": "rfd/0223-k8s-health-checks.md",
        "discussion_id": "2301245874",
        "commented_code": "@@ -0,0 +1,623 @@\n+---\n+authors: Rana Ian (rana.ian@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0223 - Kubernetes Health Checks\n+\n+## Required Approvals\n+\n+- Engineering: @rosstimothy && @creack && @tigrato\n+\n+\n+## What\n+\n+Enable automated Kubernetes cluster health checks that are viewed by the Web UI, Teleport Connect, `tctl` command, and Prometheus metrics.\n+\n+## Why\n+\n+Proxied Kubernetes cluster health may be manually exercised with Kubernetes operations in the Web UI, or `kubectl` command, then observing the result. While effective, manual checking is also slow and unscalable. \n+\n+Automated Kubernetes health checks with new methods of viewing improve maintainability of Teleport Kubernetes clusters, while enabling new scenarios.\n+\n+Automated health checks:\n+- Improve time to observe and resolve Kubernetes cluster errors\n+- Improve manageability of Kubernetes clusters, especially at scale\n+- Improve the enrollment experience for Kubernetes clusters\n+- Enables alerting on unhealthy Kubernetes clusters\n+- Provides feature parity with databases and machine workload identities\n+\n+## Details\n+\n+### UX\n+\n+#### User Story: Web UI - Enrolling Kubernetes Clusters\n+\n+Alice enrolls three Amazon EKS clusters into Teleport through the Web UI.\n+\n+The next day she returns to the Web UI _Resources_ tab to find the Amazon EKS clusters are highlighted with warnings. She clicks on an Amazon EKS tile and a health message is displayed in a side panel.\n+\n+```\n+Kubernetes Cluster Issues\n+\n+3 Teleport Kubernetes clusters report issues.\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: sol\n+  UUID: 52dedbd0-b165-4bf6-9bc3-961f95bf481d\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: jupiter\n+  UUID: bb4dc171-ffa7-4a31-ba8c-7bf91c59e250\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: saturn\n+  UUID: 2be08cb1-56a4-401f-a3f3-c755a73f3ff6\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+```\n+\n+Alice notices that each cluster has a similar 503 message saying etcd is the source of the error.\n+\n+Alice resolves the `etcd` error, and each Amazon EKS cluster returns to a healthy state.\n+\n+As she monitors the Teleport Web UI, she sees each Amazon EKS tile switch from a warning state to a normal state.\n+\n+\n+#### User Story: `tctl` - Configuring a New Health Check\n+\n+Bob reads about Kubernetes health checks in a Teleport changelog, and updates a Teleport cluster to the new major version.\n+\n+Bob runs `tctl get health_check_config/default` from a terminal to view the default health settings.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+```\n+\n+He notices a new `kubernetes_labels` matcher.\n+\n+He vets the Kubernetes health checks in non-production environments.\n+\n+Bob runs `tctl edit health_check_config/default` from a terminal, updating the default settings to exclude Kubernetes health checks from a production environment.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Bob runs `tctl get kube_server/luna` from a terminal, validating that the expected Kubernetes cluster is monitoring health. \n+```yaml\n+kind: kube_server\n+metadata:\n+  expires: \"2025-10-26T00:00:00.000000Z\"\n+  name: luna\n+  revision: 43e96231-faaf-43c3-b9b8-15cf91813389\n+spec:\n+  host_id: 278be63c-c87e-4d7e-a286-86002c7c45c3\n+  hostname: luna\n+status:\n+  target_health:\n+    addr: luna:3027\n+    protocol: TLS\n+    transition_timestamp: \"2025-10-25T00:00:00.000000Z\"\n+    transition_reason: \"healthy threshold reached\"\n+    status: healthy\n+  version: 19.0.0\n+version: v3\n+```\n+\n+\n+#### User Story: Prometheus - Alerting on an Unhealthy Kubernetes Cluster",
        "comment_created_at": "2025-08-26T14:46:20+00:00",
        "comment_author": "rosstimothy",
        "comment_body": "There is one potential downside to the prometheus metrics in the current proposal: they only count resources that are covered by health checks. If I have 20 Kubernetes Clusters, but configure my health_check_resource to only match on labels of 10 of them I may never get alerted that any of the other 10 are offline. \r\n\r\nI think this is probably fine, as we can't count what we don't know, but it's maybe something we should call out better in the metrics documentation.",
        "pr_file_module": null
      },
      {
        "comment_id": "2302165466",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58065,
        "pr_file": "rfd/0223-k8s-health-checks.md",
        "discussion_id": "2301245874",
        "commented_code": "@@ -0,0 +1,623 @@\n+---\n+authors: Rana Ian (rana.ian@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0223 - Kubernetes Health Checks\n+\n+## Required Approvals\n+\n+- Engineering: @rosstimothy && @creack && @tigrato\n+\n+\n+## What\n+\n+Enable automated Kubernetes cluster health checks that are viewed by the Web UI, Teleport Connect, `tctl` command, and Prometheus metrics.\n+\n+## Why\n+\n+Proxied Kubernetes cluster health may be manually exercised with Kubernetes operations in the Web UI, or `kubectl` command, then observing the result. While effective, manual checking is also slow and unscalable. \n+\n+Automated Kubernetes health checks with new methods of viewing improve maintainability of Teleport Kubernetes clusters, while enabling new scenarios.\n+\n+Automated health checks:\n+- Improve time to observe and resolve Kubernetes cluster errors\n+- Improve manageability of Kubernetes clusters, especially at scale\n+- Improve the enrollment experience for Kubernetes clusters\n+- Enables alerting on unhealthy Kubernetes clusters\n+- Provides feature parity with databases and machine workload identities\n+\n+## Details\n+\n+### UX\n+\n+#### User Story: Web UI - Enrolling Kubernetes Clusters\n+\n+Alice enrolls three Amazon EKS clusters into Teleport through the Web UI.\n+\n+The next day she returns to the Web UI _Resources_ tab to find the Amazon EKS clusters are highlighted with warnings. She clicks on an Amazon EKS tile and a health message is displayed in a side panel.\n+\n+```\n+Kubernetes Cluster Issues\n+\n+3 Teleport Kubernetes clusters report issues.\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: sol\n+  UUID: 52dedbd0-b165-4bf6-9bc3-961f95bf481d\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: jupiter\n+  UUID: bb4dc171-ffa7-4a31-ba8c-7bf91c59e250\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: saturn\n+  UUID: 2be08cb1-56a4-401f-a3f3-c755a73f3ff6\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+```\n+\n+Alice notices that each cluster has a similar 503 message saying etcd is the source of the error.\n+\n+Alice resolves the `etcd` error, and each Amazon EKS cluster returns to a healthy state.\n+\n+As she monitors the Teleport Web UI, she sees each Amazon EKS tile switch from a warning state to a normal state.\n+\n+\n+#### User Story: `tctl` - Configuring a New Health Check\n+\n+Bob reads about Kubernetes health checks in a Teleport changelog, and updates a Teleport cluster to the new major version.\n+\n+Bob runs `tctl get health_check_config/default` from a terminal to view the default health settings.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+```\n+\n+He notices a new `kubernetes_labels` matcher.\n+\n+He vets the Kubernetes health checks in non-production environments.\n+\n+Bob runs `tctl edit health_check_config/default` from a terminal, updating the default settings to exclude Kubernetes health checks from a production environment.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Bob runs `tctl get kube_server/luna` from a terminal, validating that the expected Kubernetes cluster is monitoring health. \n+```yaml\n+kind: kube_server\n+metadata:\n+  expires: \"2025-10-26T00:00:00.000000Z\"\n+  name: luna\n+  revision: 43e96231-faaf-43c3-b9b8-15cf91813389\n+spec:\n+  host_id: 278be63c-c87e-4d7e-a286-86002c7c45c3\n+  hostname: luna\n+status:\n+  target_health:\n+    addr: luna:3027\n+    protocol: TLS\n+    transition_timestamp: \"2025-10-25T00:00:00.000000Z\"\n+    transition_reason: \"healthy threshold reached\"\n+    status: healthy\n+  version: 19.0.0\n+version: v3\n+```\n+\n+\n+#### User Story: Prometheus - Alerting on an Unhealthy Kubernetes Cluster",
        "comment_created_at": "2025-08-26T21:18:02+00:00",
        "comment_author": "rana",
        "comment_body": "Nice observation.\r\n\r\nThe RFD [documentation section](https://github.com/gravitational/teleport/blob/rfd/0223-k8s-health-checks/rfd/0223-k8s-health-checks.md#documentation) is updated to explicitly mention the distinction between enrolled resources and configured health checking resources.\r\n\r\nA bit after that fact, but why omit any resource from health checking? To support unknown circumstances? Exclude deployment environments? Simply make it opt-out? Excluding `mysql` could be a use case as a temporary workaround until a fix is applied?",
        "pr_file_module": null
      },
      {
        "comment_id": "2302278178",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58065,
        "pr_file": "rfd/0223-k8s-health-checks.md",
        "discussion_id": "2301245874",
        "commented_code": "@@ -0,0 +1,623 @@\n+---\n+authors: Rana Ian (rana.ian@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0223 - Kubernetes Health Checks\n+\n+## Required Approvals\n+\n+- Engineering: @rosstimothy && @creack && @tigrato\n+\n+\n+## What\n+\n+Enable automated Kubernetes cluster health checks that are viewed by the Web UI, Teleport Connect, `tctl` command, and Prometheus metrics.\n+\n+## Why\n+\n+Proxied Kubernetes cluster health may be manually exercised with Kubernetes operations in the Web UI, or `kubectl` command, then observing the result. While effective, manual checking is also slow and unscalable. \n+\n+Automated Kubernetes health checks with new methods of viewing improve maintainability of Teleport Kubernetes clusters, while enabling new scenarios.\n+\n+Automated health checks:\n+- Improve time to observe and resolve Kubernetes cluster errors\n+- Improve manageability of Kubernetes clusters, especially at scale\n+- Improve the enrollment experience for Kubernetes clusters\n+- Enables alerting on unhealthy Kubernetes clusters\n+- Provides feature parity with databases and machine workload identities\n+\n+## Details\n+\n+### UX\n+\n+#### User Story: Web UI - Enrolling Kubernetes Clusters\n+\n+Alice enrolls three Amazon EKS clusters into Teleport through the Web UI.\n+\n+The next day she returns to the Web UI _Resources_ tab to find the Amazon EKS clusters are highlighted with warnings. She clicks on an Amazon EKS tile and a health message is displayed in a side panel.\n+\n+```\n+Kubernetes Cluster Issues\n+\n+3 Teleport Kubernetes clusters report issues.\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: sol\n+  UUID: 52dedbd0-b165-4bf6-9bc3-961f95bf481d\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: jupiter\n+  UUID: bb4dc171-ffa7-4a31-ba8c-7bf91c59e250\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+\n+Affected Teleport Kubernetes cluster:\n+- Hostname: saturn\n+  UUID: 2be08cb1-56a4-401f-a3f3-c755a73f3ff6\n+  Error: 503 Service Unavailable\n+    [+]ping ok\n+    [+]log ok\n+    [-]etcd not ok: client: etcd cluster is unavailable or misconfigured: context deadline exceeded\n+```\n+\n+Alice notices that each cluster has a similar 503 message saying etcd is the source of the error.\n+\n+Alice resolves the `etcd` error, and each Amazon EKS cluster returns to a healthy state.\n+\n+As she monitors the Teleport Web UI, she sees each Amazon EKS tile switch from a warning state to a normal state.\n+\n+\n+#### User Story: `tctl` - Configuring a New Health Check\n+\n+Bob reads about Kubernetes health checks in a Teleport changelog, and updates a Teleport cluster to the new major version.\n+\n+Bob runs `tctl get health_check_config/default` from a terminal to view the default health settings.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+```\n+\n+He notices a new `kubernetes_labels` matcher.\n+\n+He vets the Kubernetes health checks in non-production environments.\n+\n+Bob runs `tctl edit health_check_config/default` from a terminal, updating the default settings to exclude Kubernetes health checks from a production environment.\n+\n+```yaml\n+version: v1\n+metadata:\n+  name: \"default\"\n+  labels:\n+    teleport.internal/resource-type: preset\n+spec:\n+  match:\n+    db_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels:\n+      - name: \"*\"\n+        values:\n+          - \"*\"\n+    kubernetes_labels_expression: \"labels.env != `prod`\"\n+```\n+\n+Bob runs `tctl get kube_server/luna` from a terminal, validating that the expected Kubernetes cluster is monitoring health. \n+```yaml\n+kind: kube_server\n+metadata:\n+  expires: \"2025-10-26T00:00:00.000000Z\"\n+  name: luna\n+  revision: 43e96231-faaf-43c3-b9b8-15cf91813389\n+spec:\n+  host_id: 278be63c-c87e-4d7e-a286-86002c7c45c3\n+  hostname: luna\n+status:\n+  target_health:\n+    addr: luna:3027\n+    protocol: TLS\n+    transition_timestamp: \"2025-10-25T00:00:00.000000Z\"\n+    transition_reason: \"healthy threshold reached\"\n+    status: healthy\n+  version: 19.0.0\n+version: v3\n+```\n+\n+\n+#### User Story: Prometheus - Alerting on an Unhealthy Kubernetes Cluster",
        "comment_created_at": "2025-08-26T22:25:59+00:00",
        "comment_author": "GavinFrazar",
        "comment_body": "If we support health checks for a resource, then we should always add it to the health check manager as a target.\r\nThe healthcheck package watches health_check_config resources and figures out which config applies to a target.\r\nIf no config applies, then the manager just marks that target `status: unknown, reason: disabled`.\r\nWe should therefore be able to count disabled health check targets in the \"unknown\" metric in the healthcheck package.\r\nIf we disambiguate unhealthy/unknown in the metrics then you can alert on unknown if you want, or not.\r\n\r\nMySQL is in the \"does not support health checks\" category (for now), hence we don't need to count it just like we don't count any of the other resources connected to Teleport which don't support health checks.",
        "pr_file_module": null
      }
    ]
  }
]