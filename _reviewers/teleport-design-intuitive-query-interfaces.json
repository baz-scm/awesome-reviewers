[
  {
    "discussion_id": "2310217975",
    "pr_number": 57888,
    "pr_file": "rfd/0222-bot-instances-at-scale.md",
    "created_at": "2025-08-29T13:50:24+00:00",
    "commented_code": "+---\n+authors: Nick Marais (nicholas.marais@goteleport.com), Dan Upton (dan.upton@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+## Required Approvers\n+\n+- Engineering: @strideynet\n+- Product: @thedevelopnik\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+# What\n+\n+This proposal seeks to address the pain points of configuring and running a large fleet of Machine & Workload ID bots.\n+\n+It will focus solely on the Day 1 experience, and users are expected to be familiar with Teleport in general as well as the config and setup of their respective clusters. Day 0 tutorialization of setup steps and guided beginner scenarios are left to other initiatives.\n+\n+# Why\n+\n+As adoption of Machine & Workload ID increases, in part due to the drive to increase efficiency through automation as well as trends like Agentive AI, customers expect managing large fleets of bots to be simple and easy.\n+\n+It\u2019s the responsibility of the **infrastructure security team** to own and manage the Teleport cluster and enrol protected resources. For teams which make extensive use of Machine & Workload ID, it has become cumbersome to manage many bots and hundreds of instances. Where Dev/Dev Ops teams deploy bot instances themselves, it can be doubly difficult to coordinate upgrades and security initiatives.\n+\n+# Details\n+\n+## UX\n+\n+### User Stories\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are blocking a safe cluster upgrade (major) due to their version.**\n+\n+The upgrade process can vary depending on the flavour of Teleport in use (cloud, oss, etc), and how it\u2019s deployed. A common step is to query for agents running a version which would become incompatible should an upgrade be done - using `tctl inventory ls --older-than=v18.0.0`. This command does not include bot instances, and `tctl bots instances ls` doesn\u2019t return versions numbers for instances.\n+\n+As such, it is a difficult task to identify bot instances that may be running an old version of `tbot`. This is especially difficult at scale. The current bot instance list available in the web app allows filtering by version, although it\u2019s a text search and it is not aware of semantic versioning - finding versions older than a given version is not possible.\n+\n+A breakdown of active instance versions will make the process of monitoring the version status easy at a glance, as well as provide convenient links to filter the instance list for versions already one or more major version behind the control plane (thereby preventing a safe upgrade). To facilitate this, the filter will allow queries such as `semver_lt(version, \"18.1\")`. The instance list will also indicate the status of an instance\u2019s most recent version (as up-to-date, upgrade available, patch available, or incompatible).\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are running vulnerable versions.**\n+\n+Currently the instances list can be filtered by version, but this is a text search and it is not aware of semantic versioning. It\u2019s possible to find a specific version number, but it\u2019s not easy to isolate a range of versions, such as \u201c>18 & <18.2.1\u201d, which is likely required to find instances between a vulnerable and patched version.\n+\n+To support this use-case, the filter for bot instances will support the predicate language and allow queries such as `semver_gte(version, \"18.1.0\") && semver_lt(version, \"19\")`.\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances are running with deprecated/problematic configuration.**\n+\n+Issues in `tbot` (or just typos) can be difficult to detect and logs may not adequately highlight these. To improve the rate of these events reaching users, `tbot` will detect and collate notices which are sent with the next heartbeat. They will then be available to view for a bot instance. To help in situations where it\u2019s infeasible to check each individual instance, notices will be summarized by title and presented in aggregate form. Each aggregated item will be selectable and will filter the bot instances list. A filter such as `contains(notices, \"Proxy URL not set\")` will be pre-populated.\n+\n+**As a cluster owner (Infrastructure Security team), I'd like to be able to figure out what a Bot Instance is for/who it belongs to when making decisions (e.g can we upgrade/break this Bot safely).**\n+\n+How bot/instances are tagged with an owner, organizational area or purpose will be the subject of a later phase of delivery. As such it is left undefined for the time being. It may simply be a series of optional fields (or labels) which can be included in the `tbot` configuration, via flags or environment variables. These would be sent along with heartbeats and be visible in the web UI.\n+\n+**As a Bot Instance owner (Dev/Dev Ops team), I'd like help in understanding why my Bot Instance is not working properly.**\n+\n+For somebody diagnosing an issue with `tbot`, they\u2019re likely to have access to the `tbot` log output. Such as;\n+\n+```\n+INFO [TBOT:IDENTITY] Fetched new bot identity identity:mwi-demo-aws-manager, id=5c6af2e6-13a4-48c1-855f-74d8b8e01d86 | valid: after=2025-08-21T12:10:15Z, before=2025-08-21T12:31:13Z, duration=20m58s | kind=tls, renewable=false, disallow-reissue=false, roles=[bot-mwi-demo-aws-manager], principals=[-teleport-internal-join], generation=1 tbot/service_bot_identity.go:224\n+```\n+\n+This log entry contains the bot name (as `identity`) and the instance\u2019s ID. Either of these values can be used to filter the instances list, and should make finding the relevant instance easy.\n+\n+Once found, the instance can be selected to view instance details. Here a health status can be found for each `tbot` service (outputs, tunnels, etc), which includes failure info for those services which are unhealthy. Additionally, a listing of all notices raised by the instance in it\u2019s last run can be viewed, which may reveal the root cause of a failure.\n+\n+### Instances dashboard\n+\n+![](assets/0222-dashboard.png)\n+\n+### Instance details\n+\n+![](assets/0222-details-overview.png)\n+\n+![](assets/0222-details-services.png)\n+\n+![](assets/0222-details-notices.png)\n+\n+![](assets/0222-details-config.png)\n+\n+### Predicate language for instance filters\n+\n+The predicate language will be used to provide advanced filtering for instances. The filter query will be applied in the same way the existing filters work, and no changes to indexes are required. As items are read out of the backend storage, they are filtered one by one until the page size is reached or the end of the list. For a narrow filter, many or even all records will be scanned - this inefficiency is mitigated by the in-memory caching layer's performance. A custom language parser will be used to provide instance-specific functions such as those in the table below.",
    "repo_full_name": "gravitational/teleport",
    "discussion_comments": [
      {
        "comment_id": "2310217975",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 57888,
        "pr_file": "rfd/0222-bot-instances-at-scale.md",
        "discussion_id": "2310217975",
        "commented_code": "@@ -0,0 +1,367 @@\n+---\n+authors: Nick Marais (nicholas.marais@goteleport.com), Dan Upton (dan.upton@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+## Required Approvers\n+\n+- Engineering: @strideynet\n+- Product: @thedevelopnik\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+# What\n+\n+This proposal seeks to address the pain points of configuring and running a large fleet of Machine & Workload ID bots.\n+\n+It will focus solely on the Day 1 experience, and users are expected to be familiar with Teleport in general as well as the config and setup of their respective clusters. Day 0 tutorialization of setup steps and guided beginner scenarios are left to other initiatives.\n+\n+# Why\n+\n+As adoption of Machine & Workload ID increases, in part due to the drive to increase efficiency through automation as well as trends like Agentive AI, customers expect managing large fleets of bots to be simple and easy.\n+\n+It\u2019s the responsibility of the **infrastructure security team** to own and manage the Teleport cluster and enrol protected resources. For teams which make extensive use of Machine & Workload ID, it has become cumbersome to manage many bots and hundreds of instances. Where Dev/Dev Ops teams deploy bot instances themselves, it can be doubly difficult to coordinate upgrades and security initiatives.\n+\n+# Details\n+\n+## UX\n+\n+### User Stories\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are blocking a safe cluster upgrade (major) due to their version.**\n+\n+The upgrade process can vary depending on the flavour of Teleport in use (cloud, oss, etc), and how it\u2019s deployed. A common step is to query for agents running a version which would become incompatible should an upgrade be done - using `tctl inventory ls --older-than=v18.0.0`. This command does not include bot instances, and `tctl bots instances ls` doesn\u2019t return versions numbers for instances.\n+\n+As such, it is a difficult task to identify bot instances that may be running an old version of `tbot`. This is especially difficult at scale. The current bot instance list available in the web app allows filtering by version, although it\u2019s a text search and it is not aware of semantic versioning - finding versions older than a given version is not possible.\n+\n+A breakdown of active instance versions will make the process of monitoring the version status easy at a glance, as well as provide convenient links to filter the instance list for versions already one or more major version behind the control plane (thereby preventing a safe upgrade). To facilitate this, the filter will allow queries such as `semver_lt(version, \"18.1\")`. The instance list will also indicate the status of an instance\u2019s most recent version (as up-to-date, upgrade available, patch available, or incompatible).\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are running vulnerable versions.**\n+\n+Currently the instances list can be filtered by version, but this is a text search and it is not aware of semantic versioning. It\u2019s possible to find a specific version number, but it\u2019s not easy to isolate a range of versions, such as \u201c>18 & <18.2.1\u201d, which is likely required to find instances between a vulnerable and patched version.\n+\n+To support this use-case, the filter for bot instances will support the predicate language and allow queries such as `semver_gte(version, \"18.1.0\") && semver_lt(version, \"19\")`.\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances are running with deprecated/problematic configuration.**\n+\n+Issues in `tbot` (or just typos) can be difficult to detect and logs may not adequately highlight these. To improve the rate of these events reaching users, `tbot` will detect and collate notices which are sent with the next heartbeat. They will then be available to view for a bot instance. To help in situations where it\u2019s infeasible to check each individual instance, notices will be summarized by title and presented in aggregate form. Each aggregated item will be selectable and will filter the bot instances list. A filter such as `contains(notices, \"Proxy URL not set\")` will be pre-populated.\n+\n+**As a cluster owner (Infrastructure Security team), I'd like to be able to figure out what a Bot Instance is for/who it belongs to when making decisions (e.g can we upgrade/break this Bot safely).**\n+\n+How bot/instances are tagged with an owner, organizational area or purpose will be the subject of a later phase of delivery. As such it is left undefined for the time being. It may simply be a series of optional fields (or labels) which can be included in the `tbot` configuration, via flags or environment variables. These would be sent along with heartbeats and be visible in the web UI.\n+\n+**As a Bot Instance owner (Dev/Dev Ops team), I'd like help in understanding why my Bot Instance is not working properly.**\n+\n+For somebody diagnosing an issue with `tbot`, they\u2019re likely to have access to the `tbot` log output. Such as;\n+\n+```\n+INFO [TBOT:IDENTITY] Fetched new bot identity identity:mwi-demo-aws-manager, id=5c6af2e6-13a4-48c1-855f-74d8b8e01d86 | valid: after=2025-08-21T12:10:15Z, before=2025-08-21T12:31:13Z, duration=20m58s | kind=tls, renewable=false, disallow-reissue=false, roles=[bot-mwi-demo-aws-manager], principals=[-teleport-internal-join], generation=1 tbot/service_bot_identity.go:224\n+```\n+\n+This log entry contains the bot name (as `identity`) and the instance\u2019s ID. Either of these values can be used to filter the instances list, and should make finding the relevant instance easy.\n+\n+Once found, the instance can be selected to view instance details. Here a health status can be found for each `tbot` service (outputs, tunnels, etc), which includes failure info for those services which are unhealthy. Additionally, a listing of all notices raised by the instance in it\u2019s last run can be viewed, which may reveal the root cause of a failure.\n+\n+### Instances dashboard\n+\n+![](assets/0222-dashboard.png)\n+\n+### Instance details\n+\n+![](assets/0222-details-overview.png)\n+\n+![](assets/0222-details-services.png)\n+\n+![](assets/0222-details-notices.png)\n+\n+![](assets/0222-details-config.png)\n+\n+### Predicate language for instance filters\n+\n+The predicate language will be used to provide advanced filtering for instances. The filter query will be applied in the same way the existing filters work, and no changes to indexes are required. As items are read out of the backend storage, they are filtered one by one until the page size is reached or the end of the list. For a narrow filter, many or even all records will be scanned - this inefficiency is mitigated by the in-memory caching layer's performance. A custom language parser will be used to provide instance-specific functions such as those in the table below.",
        "comment_created_at": "2025-08-29T13:50:24+00:00",
        "comment_author": "rosstimothy",
        "comment_body": "> A custom language parser will be used to provide instance-specific functions such as those in the table below.\r\n\r\nWhat is a custom language parser?",
        "pr_file_module": null
      },
      {
        "comment_id": "2313678432",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 57888,
        "pr_file": "rfd/0222-bot-instances-at-scale.md",
        "discussion_id": "2310217975",
        "commented_code": "@@ -0,0 +1,367 @@\n+---\n+authors: Nick Marais (nicholas.marais@goteleport.com), Dan Upton (dan.upton@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+## Required Approvers\n+\n+- Engineering: @strideynet\n+- Product: @thedevelopnik\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+# What\n+\n+This proposal seeks to address the pain points of configuring and running a large fleet of Machine & Workload ID bots.\n+\n+It will focus solely on the Day 1 experience, and users are expected to be familiar with Teleport in general as well as the config and setup of their respective clusters. Day 0 tutorialization of setup steps and guided beginner scenarios are left to other initiatives.\n+\n+# Why\n+\n+As adoption of Machine & Workload ID increases, in part due to the drive to increase efficiency through automation as well as trends like Agentive AI, customers expect managing large fleets of bots to be simple and easy.\n+\n+It\u2019s the responsibility of the **infrastructure security team** to own and manage the Teleport cluster and enrol protected resources. For teams which make extensive use of Machine & Workload ID, it has become cumbersome to manage many bots and hundreds of instances. Where Dev/Dev Ops teams deploy bot instances themselves, it can be doubly difficult to coordinate upgrades and security initiatives.\n+\n+# Details\n+\n+## UX\n+\n+### User Stories\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are blocking a safe cluster upgrade (major) due to their version.**\n+\n+The upgrade process can vary depending on the flavour of Teleport in use (cloud, oss, etc), and how it\u2019s deployed. A common step is to query for agents running a version which would become incompatible should an upgrade be done - using `tctl inventory ls --older-than=v18.0.0`. This command does not include bot instances, and `tctl bots instances ls` doesn\u2019t return versions numbers for instances.\n+\n+As such, it is a difficult task to identify bot instances that may be running an old version of `tbot`. This is especially difficult at scale. The current bot instance list available in the web app allows filtering by version, although it\u2019s a text search and it is not aware of semantic versioning - finding versions older than a given version is not possible.\n+\n+A breakdown of active instance versions will make the process of monitoring the version status easy at a glance, as well as provide convenient links to filter the instance list for versions already one or more major version behind the control plane (thereby preventing a safe upgrade). To facilitate this, the filter will allow queries such as `semver_lt(version, \"18.1\")`. The instance list will also indicate the status of an instance\u2019s most recent version (as up-to-date, upgrade available, patch available, or incompatible).\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are running vulnerable versions.**\n+\n+Currently the instances list can be filtered by version, but this is a text search and it is not aware of semantic versioning. It\u2019s possible to find a specific version number, but it\u2019s not easy to isolate a range of versions, such as \u201c>18 & <18.2.1\u201d, which is likely required to find instances between a vulnerable and patched version.\n+\n+To support this use-case, the filter for bot instances will support the predicate language and allow queries such as `semver_gte(version, \"18.1.0\") && semver_lt(version, \"19\")`.\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances are running with deprecated/problematic configuration.**\n+\n+Issues in `tbot` (or just typos) can be difficult to detect and logs may not adequately highlight these. To improve the rate of these events reaching users, `tbot` will detect and collate notices which are sent with the next heartbeat. They will then be available to view for a bot instance. To help in situations where it\u2019s infeasible to check each individual instance, notices will be summarized by title and presented in aggregate form. Each aggregated item will be selectable and will filter the bot instances list. A filter such as `contains(notices, \"Proxy URL not set\")` will be pre-populated.\n+\n+**As a cluster owner (Infrastructure Security team), I'd like to be able to figure out what a Bot Instance is for/who it belongs to when making decisions (e.g can we upgrade/break this Bot safely).**\n+\n+How bot/instances are tagged with an owner, organizational area or purpose will be the subject of a later phase of delivery. As such it is left undefined for the time being. It may simply be a series of optional fields (or labels) which can be included in the `tbot` configuration, via flags or environment variables. These would be sent along with heartbeats and be visible in the web UI.\n+\n+**As a Bot Instance owner (Dev/Dev Ops team), I'd like help in understanding why my Bot Instance is not working properly.**\n+\n+For somebody diagnosing an issue with `tbot`, they\u2019re likely to have access to the `tbot` log output. Such as;\n+\n+```\n+INFO [TBOT:IDENTITY] Fetched new bot identity identity:mwi-demo-aws-manager, id=5c6af2e6-13a4-48c1-855f-74d8b8e01d86 | valid: after=2025-08-21T12:10:15Z, before=2025-08-21T12:31:13Z, duration=20m58s | kind=tls, renewable=false, disallow-reissue=false, roles=[bot-mwi-demo-aws-manager], principals=[-teleport-internal-join], generation=1 tbot/service_bot_identity.go:224\n+```\n+\n+This log entry contains the bot name (as `identity`) and the instance\u2019s ID. Either of these values can be used to filter the instances list, and should make finding the relevant instance easy.\n+\n+Once found, the instance can be selected to view instance details. Here a health status can be found for each `tbot` service (outputs, tunnels, etc), which includes failure info for those services which are unhealthy. Additionally, a listing of all notices raised by the instance in it\u2019s last run can be viewed, which may reveal the root cause of a failure.\n+\n+### Instances dashboard\n+\n+![](assets/0222-dashboard.png)\n+\n+### Instance details\n+\n+![](assets/0222-details-overview.png)\n+\n+![](assets/0222-details-services.png)\n+\n+![](assets/0222-details-notices.png)\n+\n+![](assets/0222-details-config.png)\n+\n+### Predicate language for instance filters\n+\n+The predicate language will be used to provide advanced filtering for instances. The filter query will be applied in the same way the existing filters work, and no changes to indexes are required. As items are read out of the backend storage, they are filtered one by one until the page size is reached or the end of the list. For a narrow filter, many or even all records will be scanned - this inefficiency is mitigated by the in-memory caching layer's performance. A custom language parser will be used to provide instance-specific functions such as those in the table below.",
        "comment_created_at": "2025-09-01T11:20:05+00:00",
        "comment_author": "boxofrad",
        "comment_body": "I think this means a custom `typical.ParserSpec` with those functions attached.",
        "pr_file_module": null
      },
      {
        "comment_id": "2314328850",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 57888,
        "pr_file": "rfd/0222-bot-instances-at-scale.md",
        "discussion_id": "2310217975",
        "commented_code": "@@ -0,0 +1,367 @@\n+---\n+authors: Nick Marais (nicholas.marais@goteleport.com), Dan Upton (dan.upton@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+## Required Approvers\n+\n+- Engineering: @strideynet\n+- Product: @thedevelopnik\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+# What\n+\n+This proposal seeks to address the pain points of configuring and running a large fleet of Machine & Workload ID bots.\n+\n+It will focus solely on the Day 1 experience, and users are expected to be familiar with Teleport in general as well as the config and setup of their respective clusters. Day 0 tutorialization of setup steps and guided beginner scenarios are left to other initiatives.\n+\n+# Why\n+\n+As adoption of Machine & Workload ID increases, in part due to the drive to increase efficiency through automation as well as trends like Agentive AI, customers expect managing large fleets of bots to be simple and easy.\n+\n+It\u2019s the responsibility of the **infrastructure security team** to own and manage the Teleport cluster and enrol protected resources. For teams which make extensive use of Machine & Workload ID, it has become cumbersome to manage many bots and hundreds of instances. Where Dev/Dev Ops teams deploy bot instances themselves, it can be doubly difficult to coordinate upgrades and security initiatives.\n+\n+# Details\n+\n+## UX\n+\n+### User Stories\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are blocking a safe cluster upgrade (major) due to their version.**\n+\n+The upgrade process can vary depending on the flavour of Teleport in use (cloud, oss, etc), and how it\u2019s deployed. A common step is to query for agents running a version which would become incompatible should an upgrade be done - using `tctl inventory ls --older-than=v18.0.0`. This command does not include bot instances, and `tctl bots instances ls` doesn\u2019t return versions numbers for instances.\n+\n+As such, it is a difficult task to identify bot instances that may be running an old version of `tbot`. This is especially difficult at scale. The current bot instance list available in the web app allows filtering by version, although it\u2019s a text search and it is not aware of semantic versioning - finding versions older than a given version is not possible.\n+\n+A breakdown of active instance versions will make the process of monitoring the version status easy at a glance, as well as provide convenient links to filter the instance list for versions already one or more major version behind the control plane (thereby preventing a safe upgrade). To facilitate this, the filter will allow queries such as `semver_lt(version, \"18.1\")`. The instance list will also indicate the status of an instance\u2019s most recent version (as up-to-date, upgrade available, patch available, or incompatible).\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are running vulnerable versions.**\n+\n+Currently the instances list can be filtered by version, but this is a text search and it is not aware of semantic versioning. It\u2019s possible to find a specific version number, but it\u2019s not easy to isolate a range of versions, such as \u201c>18 & <18.2.1\u201d, which is likely required to find instances between a vulnerable and patched version.\n+\n+To support this use-case, the filter for bot instances will support the predicate language and allow queries such as `semver_gte(version, \"18.1.0\") && semver_lt(version, \"19\")`.\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances are running with deprecated/problematic configuration.**\n+\n+Issues in `tbot` (or just typos) can be difficult to detect and logs may not adequately highlight these. To improve the rate of these events reaching users, `tbot` will detect and collate notices which are sent with the next heartbeat. They will then be available to view for a bot instance. To help in situations where it\u2019s infeasible to check each individual instance, notices will be summarized by title and presented in aggregate form. Each aggregated item will be selectable and will filter the bot instances list. A filter such as `contains(notices, \"Proxy URL not set\")` will be pre-populated.\n+\n+**As a cluster owner (Infrastructure Security team), I'd like to be able to figure out what a Bot Instance is for/who it belongs to when making decisions (e.g can we upgrade/break this Bot safely).**\n+\n+How bot/instances are tagged with an owner, organizational area or purpose will be the subject of a later phase of delivery. As such it is left undefined for the time being. It may simply be a series of optional fields (or labels) which can be included in the `tbot` configuration, via flags or environment variables. These would be sent along with heartbeats and be visible in the web UI.\n+\n+**As a Bot Instance owner (Dev/Dev Ops team), I'd like help in understanding why my Bot Instance is not working properly.**\n+\n+For somebody diagnosing an issue with `tbot`, they\u2019re likely to have access to the `tbot` log output. Such as;\n+\n+```\n+INFO [TBOT:IDENTITY] Fetched new bot identity identity:mwi-demo-aws-manager, id=5c6af2e6-13a4-48c1-855f-74d8b8e01d86 | valid: after=2025-08-21T12:10:15Z, before=2025-08-21T12:31:13Z, duration=20m58s | kind=tls, renewable=false, disallow-reissue=false, roles=[bot-mwi-demo-aws-manager], principals=[-teleport-internal-join], generation=1 tbot/service_bot_identity.go:224\n+```\n+\n+This log entry contains the bot name (as `identity`) and the instance\u2019s ID. Either of these values can be used to filter the instances list, and should make finding the relevant instance easy.\n+\n+Once found, the instance can be selected to view instance details. Here a health status can be found for each `tbot` service (outputs, tunnels, etc), which includes failure info for those services which are unhealthy. Additionally, a listing of all notices raised by the instance in it\u2019s last run can be viewed, which may reveal the root cause of a failure.\n+\n+### Instances dashboard\n+\n+![](assets/0222-dashboard.png)\n+\n+### Instance details\n+\n+![](assets/0222-details-overview.png)\n+\n+![](assets/0222-details-services.png)\n+\n+![](assets/0222-details-notices.png)\n+\n+![](assets/0222-details-config.png)\n+\n+### Predicate language for instance filters\n+\n+The predicate language will be used to provide advanced filtering for instances. The filter query will be applied in the same way the existing filters work, and no changes to indexes are required. As items are read out of the backend storage, they are filtered one by one until the page size is reached or the end of the list. For a narrow filter, many or even all records will be scanned - this inefficiency is mitigated by the in-memory caching layer's performance. A custom language parser will be used to provide instance-specific functions such as those in the table below.",
        "comment_created_at": "2025-09-01T16:35:08+00:00",
        "comment_author": "nicholasmarais1158",
        "comment_body": "I've clarified this point, thanks.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2310223707",
    "pr_number": 57888,
    "pr_file": "rfd/0222-bot-instances-at-scale.md",
    "created_at": "2025-08-29T13:52:41+00:00",
    "commented_code": "+---\n+authors: Nick Marais (nicholas.marais@goteleport.com), Dan Upton (dan.upton@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+## Required Approvers\n+\n+- Engineering: @strideynet\n+- Product: @thedevelopnik\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+# What\n+\n+This proposal seeks to address the pain points of configuring and running a large fleet of Machine & Workload ID bots.\n+\n+It will focus solely on the Day 1 experience, and users are expected to be familiar with Teleport in general as well as the config and setup of their respective clusters. Day 0 tutorialization of setup steps and guided beginner scenarios are left to other initiatives.\n+\n+# Why\n+\n+As adoption of Machine & Workload ID increases, in part due to the drive to increase efficiency through automation as well as trends like Agentive AI, customers expect managing large fleets of bots to be simple and easy.\n+\n+It\u2019s the responsibility of the **infrastructure security team** to own and manage the Teleport cluster and enrol protected resources. For teams which make extensive use of Machine & Workload ID, it has become cumbersome to manage many bots and hundreds of instances. Where Dev/Dev Ops teams deploy bot instances themselves, it can be doubly difficult to coordinate upgrades and security initiatives.\n+\n+# Details\n+\n+## UX\n+\n+### User Stories\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are blocking a safe cluster upgrade (major) due to their version.**\n+\n+The upgrade process can vary depending on the flavour of Teleport in use (cloud, oss, etc), and how it\u2019s deployed. A common step is to query for agents running a version which would become incompatible should an upgrade be done - using `tctl inventory ls --older-than=v18.0.0`. This command does not include bot instances, and `tctl bots instances ls` doesn\u2019t return versions numbers for instances.\n+\n+As such, it is a difficult task to identify bot instances that may be running an old version of `tbot`. This is especially difficult at scale. The current bot instance list available in the web app allows filtering by version, although it\u2019s a text search and it is not aware of semantic versioning - finding versions older than a given version is not possible.\n+\n+A breakdown of active instance versions will make the process of monitoring the version status easy at a glance, as well as provide convenient links to filter the instance list for versions already one or more major version behind the control plane (thereby preventing a safe upgrade). To facilitate this, the filter will allow queries such as `semver_lt(version, \"18.1\")`. The instance list will also indicate the status of an instance\u2019s most recent version (as up-to-date, upgrade available, patch available, or incompatible).\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are running vulnerable versions.**\n+\n+Currently the instances list can be filtered by version, but this is a text search and it is not aware of semantic versioning. It\u2019s possible to find a specific version number, but it\u2019s not easy to isolate a range of versions, such as \u201c>18 & <18.2.1\u201d, which is likely required to find instances between a vulnerable and patched version.\n+\n+To support this use-case, the filter for bot instances will support the predicate language and allow queries such as `semver_gte(version, \"18.1.0\") && semver_lt(version, \"19\")`.\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances are running with deprecated/problematic configuration.**\n+\n+Issues in `tbot` (or just typos) can be difficult to detect and logs may not adequately highlight these. To improve the rate of these events reaching users, `tbot` will detect and collate notices which are sent with the next heartbeat. They will then be available to view for a bot instance. To help in situations where it\u2019s infeasible to check each individual instance, notices will be summarized by title and presented in aggregate form. Each aggregated item will be selectable and will filter the bot instances list. A filter such as `contains(notices, \"Proxy URL not set\")` will be pre-populated.\n+\n+**As a cluster owner (Infrastructure Security team), I'd like to be able to figure out what a Bot Instance is for/who it belongs to when making decisions (e.g can we upgrade/break this Bot safely).**\n+\n+How bot/instances are tagged with an owner, organizational area or purpose will be the subject of a later phase of delivery. As such it is left undefined for the time being. It may simply be a series of optional fields (or labels) which can be included in the `tbot` configuration, via flags or environment variables. These would be sent along with heartbeats and be visible in the web UI.\n+\n+**As a Bot Instance owner (Dev/Dev Ops team), I'd like help in understanding why my Bot Instance is not working properly.**\n+\n+For somebody diagnosing an issue with `tbot`, they\u2019re likely to have access to the `tbot` log output. Such as;\n+\n+```\n+INFO [TBOT:IDENTITY] Fetched new bot identity identity:mwi-demo-aws-manager, id=5c6af2e6-13a4-48c1-855f-74d8b8e01d86 | valid: after=2025-08-21T12:10:15Z, before=2025-08-21T12:31:13Z, duration=20m58s | kind=tls, renewable=false, disallow-reissue=false, roles=[bot-mwi-demo-aws-manager], principals=[-teleport-internal-join], generation=1 tbot/service_bot_identity.go:224\n+```\n+\n+This log entry contains the bot name (as `identity`) and the instance\u2019s ID. Either of these values can be used to filter the instances list, and should make finding the relevant instance easy.\n+\n+Once found, the instance can be selected to view instance details. Here a health status can be found for each `tbot` service (outputs, tunnels, etc), which includes failure info for those services which are unhealthy. Additionally, a listing of all notices raised by the instance in it\u2019s last run can be viewed, which may reveal the root cause of a failure.\n+\n+### Instances dashboard\n+\n+![](assets/0222-dashboard.png)\n+\n+### Instance details\n+\n+![](assets/0222-details-overview.png)\n+\n+![](assets/0222-details-services.png)\n+\n+![](assets/0222-details-notices.png)\n+\n+![](assets/0222-details-config.png)\n+\n+### Predicate language for instance filters\n+\n+The predicate language will be used to provide advanced filtering for instances. The filter query will be applied in the same way the existing filters work, and no changes to indexes are required. As items are read out of the backend storage, they are filtered one by one until the page size is reached or the end of the list. For a narrow filter, many or even all records will be scanned - this inefficiency is mitigated by the in-memory caching layer's performance. A custom language parser will be used to provide instance-specific functions such as those in the table below.\n+\n+| Purpose | Example |\n+| --- | --- |\n+| Find instances running versions less than a given version - based on the most recent heartbeat | `semver_lt(version, 18.1)` |\n+| Find instances running versions between a vulnerable version and a fix version - based on the most recent heartbeat | `semver_gte(version, \"18\") && semver_lt(version, \"18.1\")` |",
    "repo_full_name": "gravitational/teleport",
    "discussion_comments": [
      {
        "comment_id": "2310223707",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 57888,
        "pr_file": "rfd/0222-bot-instances-at-scale.md",
        "discussion_id": "2310223707",
        "commented_code": "@@ -0,0 +1,367 @@\n+---\n+authors: Nick Marais (nicholas.marais@goteleport.com), Dan Upton (dan.upton@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+## Required Approvers\n+\n+- Engineering: @strideynet\n+- Product: @thedevelopnik\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+# What\n+\n+This proposal seeks to address the pain points of configuring and running a large fleet of Machine & Workload ID bots.\n+\n+It will focus solely on the Day 1 experience, and users are expected to be familiar with Teleport in general as well as the config and setup of their respective clusters. Day 0 tutorialization of setup steps and guided beginner scenarios are left to other initiatives.\n+\n+# Why\n+\n+As adoption of Machine & Workload ID increases, in part due to the drive to increase efficiency through automation as well as trends like Agentive AI, customers expect managing large fleets of bots to be simple and easy.\n+\n+It\u2019s the responsibility of the **infrastructure security team** to own and manage the Teleport cluster and enrol protected resources. For teams which make extensive use of Machine & Workload ID, it has become cumbersome to manage many bots and hundreds of instances. Where Dev/Dev Ops teams deploy bot instances themselves, it can be doubly difficult to coordinate upgrades and security initiatives.\n+\n+# Details\n+\n+## UX\n+\n+### User Stories\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are blocking a safe cluster upgrade (major) due to their version.**\n+\n+The upgrade process can vary depending on the flavour of Teleport in use (cloud, oss, etc), and how it\u2019s deployed. A common step is to query for agents running a version which would become incompatible should an upgrade be done - using `tctl inventory ls --older-than=v18.0.0`. This command does not include bot instances, and `tctl bots instances ls` doesn\u2019t return versions numbers for instances.\n+\n+As such, it is a difficult task to identify bot instances that may be running an old version of `tbot`. This is especially difficult at scale. The current bot instance list available in the web app allows filtering by version, although it\u2019s a text search and it is not aware of semantic versioning - finding versions older than a given version is not possible.\n+\n+A breakdown of active instance versions will make the process of monitoring the version status easy at a glance, as well as provide convenient links to filter the instance list for versions already one or more major version behind the control plane (thereby preventing a safe upgrade). To facilitate this, the filter will allow queries such as `semver_lt(version, \"18.1\")`. The instance list will also indicate the status of an instance\u2019s most recent version (as up-to-date, upgrade available, patch available, or incompatible).\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are running vulnerable versions.**\n+\n+Currently the instances list can be filtered by version, but this is a text search and it is not aware of semantic versioning. It\u2019s possible to find a specific version number, but it\u2019s not easy to isolate a range of versions, such as \u201c>18 & <18.2.1\u201d, which is likely required to find instances between a vulnerable and patched version.\n+\n+To support this use-case, the filter for bot instances will support the predicate language and allow queries such as `semver_gte(version, \"18.1.0\") && semver_lt(version, \"19\")`.\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances are running with deprecated/problematic configuration.**\n+\n+Issues in `tbot` (or just typos) can be difficult to detect and logs may not adequately highlight these. To improve the rate of these events reaching users, `tbot` will detect and collate notices which are sent with the next heartbeat. They will then be available to view for a bot instance. To help in situations where it\u2019s infeasible to check each individual instance, notices will be summarized by title and presented in aggregate form. Each aggregated item will be selectable and will filter the bot instances list. A filter such as `contains(notices, \"Proxy URL not set\")` will be pre-populated.\n+\n+**As a cluster owner (Infrastructure Security team), I'd like to be able to figure out what a Bot Instance is for/who it belongs to when making decisions (e.g can we upgrade/break this Bot safely).**\n+\n+How bot/instances are tagged with an owner, organizational area or purpose will be the subject of a later phase of delivery. As such it is left undefined for the time being. It may simply be a series of optional fields (or labels) which can be included in the `tbot` configuration, via flags or environment variables. These would be sent along with heartbeats and be visible in the web UI.\n+\n+**As a Bot Instance owner (Dev/Dev Ops team), I'd like help in understanding why my Bot Instance is not working properly.**\n+\n+For somebody diagnosing an issue with `tbot`, they\u2019re likely to have access to the `tbot` log output. Such as;\n+\n+```\n+INFO [TBOT:IDENTITY] Fetched new bot identity identity:mwi-demo-aws-manager, id=5c6af2e6-13a4-48c1-855f-74d8b8e01d86 | valid: after=2025-08-21T12:10:15Z, before=2025-08-21T12:31:13Z, duration=20m58s | kind=tls, renewable=false, disallow-reissue=false, roles=[bot-mwi-demo-aws-manager], principals=[-teleport-internal-join], generation=1 tbot/service_bot_identity.go:224\n+```\n+\n+This log entry contains the bot name (as `identity`) and the instance\u2019s ID. Either of these values can be used to filter the instances list, and should make finding the relevant instance easy.\n+\n+Once found, the instance can be selected to view instance details. Here a health status can be found for each `tbot` service (outputs, tunnels, etc), which includes failure info for those services which are unhealthy. Additionally, a listing of all notices raised by the instance in it\u2019s last run can be viewed, which may reveal the root cause of a failure.\n+\n+### Instances dashboard\n+\n+![](assets/0222-dashboard.png)\n+\n+### Instance details\n+\n+![](assets/0222-details-overview.png)\n+\n+![](assets/0222-details-services.png)\n+\n+![](assets/0222-details-notices.png)\n+\n+![](assets/0222-details-config.png)\n+\n+### Predicate language for instance filters\n+\n+The predicate language will be used to provide advanced filtering for instances. The filter query will be applied in the same way the existing filters work, and no changes to indexes are required. As items are read out of the backend storage, they are filtered one by one until the page size is reached or the end of the list. For a narrow filter, many or even all records will be scanned - this inefficiency is mitigated by the in-memory caching layer's performance. A custom language parser will be used to provide instance-specific functions such as those in the table below.\n+\n+| Purpose | Example |\n+| --- | --- |\n+| Find instances running versions less than a given version - based on the most recent heartbeat | `semver_lt(version, 18.1)` |\n+| Find instances running versions between a vulnerable version and a fix version - based on the most recent heartbeat | `semver_gte(version, \"18\") && semver_lt(version, \"18.1\")` |",
        "comment_created_at": "2025-08-29T13:52:41+00:00",
        "comment_author": "rosstimothy",
        "comment_body": "Do you think including semver in the name will cause more harm than good? I could see some people not being aware of semantic versioning being very confused by this. Should we consider alternatives that are less technical and maybe align with things users of tctl inventory ls might already be familiar with?\r\n\r\nPerhaps something like `older_than(version, 18.1)` and `newer_than(version, 18)`?",
        "pr_file_module": null
      },
      {
        "comment_id": "2314330045",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 57888,
        "pr_file": "rfd/0222-bot-instances-at-scale.md",
        "discussion_id": "2310223707",
        "commented_code": "@@ -0,0 +1,367 @@\n+---\n+authors: Nick Marais (nicholas.marais@goteleport.com), Dan Upton (dan.upton@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+## Required Approvers\n+\n+- Engineering: @strideynet\n+- Product: @thedevelopnik\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+# What\n+\n+This proposal seeks to address the pain points of configuring and running a large fleet of Machine & Workload ID bots.\n+\n+It will focus solely on the Day 1 experience, and users are expected to be familiar with Teleport in general as well as the config and setup of their respective clusters. Day 0 tutorialization of setup steps and guided beginner scenarios are left to other initiatives.\n+\n+# Why\n+\n+As adoption of Machine & Workload ID increases, in part due to the drive to increase efficiency through automation as well as trends like Agentive AI, customers expect managing large fleets of bots to be simple and easy.\n+\n+It\u2019s the responsibility of the **infrastructure security team** to own and manage the Teleport cluster and enrol protected resources. For teams which make extensive use of Machine & Workload ID, it has become cumbersome to manage many bots and hundreds of instances. Where Dev/Dev Ops teams deploy bot instances themselves, it can be doubly difficult to coordinate upgrades and security initiatives.\n+\n+# Details\n+\n+## UX\n+\n+### User Stories\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are blocking a safe cluster upgrade (major) due to their version.**\n+\n+The upgrade process can vary depending on the flavour of Teleport in use (cloud, oss, etc), and how it\u2019s deployed. A common step is to query for agents running a version which would become incompatible should an upgrade be done - using `tctl inventory ls --older-than=v18.0.0`. This command does not include bot instances, and `tctl bots instances ls` doesn\u2019t return versions numbers for instances.\n+\n+As such, it is a difficult task to identify bot instances that may be running an old version of `tbot`. This is especially difficult at scale. The current bot instance list available in the web app allows filtering by version, although it\u2019s a text search and it is not aware of semantic versioning - finding versions older than a given version is not possible.\n+\n+A breakdown of active instance versions will make the process of monitoring the version status easy at a glance, as well as provide convenient links to filter the instance list for versions already one or more major version behind the control plane (thereby preventing a safe upgrade). To facilitate this, the filter will allow queries such as `semver_lt(version, \"18.1\")`. The instance list will also indicate the status of an instance\u2019s most recent version (as up-to-date, upgrade available, patch available, or incompatible).\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are running vulnerable versions.**\n+\n+Currently the instances list can be filtered by version, but this is a text search and it is not aware of semantic versioning. It\u2019s possible to find a specific version number, but it\u2019s not easy to isolate a range of versions, such as \u201c>18 & <18.2.1\u201d, which is likely required to find instances between a vulnerable and patched version.\n+\n+To support this use-case, the filter for bot instances will support the predicate language and allow queries such as `semver_gte(version, \"18.1.0\") && semver_lt(version, \"19\")`.\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances are running with deprecated/problematic configuration.**\n+\n+Issues in `tbot` (or just typos) can be difficult to detect and logs may not adequately highlight these. To improve the rate of these events reaching users, `tbot` will detect and collate notices which are sent with the next heartbeat. They will then be available to view for a bot instance. To help in situations where it\u2019s infeasible to check each individual instance, notices will be summarized by title and presented in aggregate form. Each aggregated item will be selectable and will filter the bot instances list. A filter such as `contains(notices, \"Proxy URL not set\")` will be pre-populated.\n+\n+**As a cluster owner (Infrastructure Security team), I'd like to be able to figure out what a Bot Instance is for/who it belongs to when making decisions (e.g can we upgrade/break this Bot safely).**\n+\n+How bot/instances are tagged with an owner, organizational area or purpose will be the subject of a later phase of delivery. As such it is left undefined for the time being. It may simply be a series of optional fields (or labels) which can be included in the `tbot` configuration, via flags or environment variables. These would be sent along with heartbeats and be visible in the web UI.\n+\n+**As a Bot Instance owner (Dev/Dev Ops team), I'd like help in understanding why my Bot Instance is not working properly.**\n+\n+For somebody diagnosing an issue with `tbot`, they\u2019re likely to have access to the `tbot` log output. Such as;\n+\n+```\n+INFO [TBOT:IDENTITY] Fetched new bot identity identity:mwi-demo-aws-manager, id=5c6af2e6-13a4-48c1-855f-74d8b8e01d86 | valid: after=2025-08-21T12:10:15Z, before=2025-08-21T12:31:13Z, duration=20m58s | kind=tls, renewable=false, disallow-reissue=false, roles=[bot-mwi-demo-aws-manager], principals=[-teleport-internal-join], generation=1 tbot/service_bot_identity.go:224\n+```\n+\n+This log entry contains the bot name (as `identity`) and the instance\u2019s ID. Either of these values can be used to filter the instances list, and should make finding the relevant instance easy.\n+\n+Once found, the instance can be selected to view instance details. Here a health status can be found for each `tbot` service (outputs, tunnels, etc), which includes failure info for those services which are unhealthy. Additionally, a listing of all notices raised by the instance in it\u2019s last run can be viewed, which may reveal the root cause of a failure.\n+\n+### Instances dashboard\n+\n+![](assets/0222-dashboard.png)\n+\n+### Instance details\n+\n+![](assets/0222-details-overview.png)\n+\n+![](assets/0222-details-services.png)\n+\n+![](assets/0222-details-notices.png)\n+\n+![](assets/0222-details-config.png)\n+\n+### Predicate language for instance filters\n+\n+The predicate language will be used to provide advanced filtering for instances. The filter query will be applied in the same way the existing filters work, and no changes to indexes are required. As items are read out of the backend storage, they are filtered one by one until the page size is reached or the end of the list. For a narrow filter, many or even all records will be scanned - this inefficiency is mitigated by the in-memory caching layer's performance. A custom language parser will be used to provide instance-specific functions such as those in the table below.\n+\n+| Purpose | Example |\n+| --- | --- |\n+| Find instances running versions less than a given version - based on the most recent heartbeat | `semver_lt(version, 18.1)` |\n+| Find instances running versions between a vulnerable version and a fix version - based on the most recent heartbeat | `semver_gte(version, \"18\") && semver_lt(version, \"18.1\")` |",
        "comment_created_at": "2025-09-01T16:36:10+00:00",
        "comment_author": "nicholasmarais1158",
        "comment_body": "I've updated the functions names. Is `newer_than_or_equal` awkwardly long? \ud83e\udd14 ",
        "pr_file_module": null
      },
      {
        "comment_id": "2316108112",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 57888,
        "pr_file": "rfd/0222-bot-instances-at-scale.md",
        "discussion_id": "2310223707",
        "commented_code": "@@ -0,0 +1,367 @@\n+---\n+authors: Nick Marais (nicholas.marais@goteleport.com), Dan Upton (dan.upton@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+## Required Approvers\n+\n+- Engineering: @strideynet\n+- Product: @thedevelopnik\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+# What\n+\n+This proposal seeks to address the pain points of configuring and running a large fleet of Machine & Workload ID bots.\n+\n+It will focus solely on the Day 1 experience, and users are expected to be familiar with Teleport in general as well as the config and setup of their respective clusters. Day 0 tutorialization of setup steps and guided beginner scenarios are left to other initiatives.\n+\n+# Why\n+\n+As adoption of Machine & Workload ID increases, in part due to the drive to increase efficiency through automation as well as trends like Agentive AI, customers expect managing large fleets of bots to be simple and easy.\n+\n+It\u2019s the responsibility of the **infrastructure security team** to own and manage the Teleport cluster and enrol protected resources. For teams which make extensive use of Machine & Workload ID, it has become cumbersome to manage many bots and hundreds of instances. Where Dev/Dev Ops teams deploy bot instances themselves, it can be doubly difficult to coordinate upgrades and security initiatives.\n+\n+# Details\n+\n+## UX\n+\n+### User Stories\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are blocking a safe cluster upgrade (major) due to their version.**\n+\n+The upgrade process can vary depending on the flavour of Teleport in use (cloud, oss, etc), and how it\u2019s deployed. A common step is to query for agents running a version which would become incompatible should an upgrade be done - using `tctl inventory ls --older-than=v18.0.0`. This command does not include bot instances, and `tctl bots instances ls` doesn\u2019t return versions numbers for instances.\n+\n+As such, it is a difficult task to identify bot instances that may be running an old version of `tbot`. This is especially difficult at scale. The current bot instance list available in the web app allows filtering by version, although it\u2019s a text search and it is not aware of semantic versioning - finding versions older than a given version is not possible.\n+\n+A breakdown of active instance versions will make the process of monitoring the version status easy at a glance, as well as provide convenient links to filter the instance list for versions already one or more major version behind the control plane (thereby preventing a safe upgrade). To facilitate this, the filter will allow queries such as `semver_lt(version, \"18.1\")`. The instance list will also indicate the status of an instance\u2019s most recent version (as up-to-date, upgrade available, patch available, or incompatible).\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are running vulnerable versions.**\n+\n+Currently the instances list can be filtered by version, but this is a text search and it is not aware of semantic versioning. It\u2019s possible to find a specific version number, but it\u2019s not easy to isolate a range of versions, such as \u201c>18 & <18.2.1\u201d, which is likely required to find instances between a vulnerable and patched version.\n+\n+To support this use-case, the filter for bot instances will support the predicate language and allow queries such as `semver_gte(version, \"18.1.0\") && semver_lt(version, \"19\")`.\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances are running with deprecated/problematic configuration.**\n+\n+Issues in `tbot` (or just typos) can be difficult to detect and logs may not adequately highlight these. To improve the rate of these events reaching users, `tbot` will detect and collate notices which are sent with the next heartbeat. They will then be available to view for a bot instance. To help in situations where it\u2019s infeasible to check each individual instance, notices will be summarized by title and presented in aggregate form. Each aggregated item will be selectable and will filter the bot instances list. A filter such as `contains(notices, \"Proxy URL not set\")` will be pre-populated.\n+\n+**As a cluster owner (Infrastructure Security team), I'd like to be able to figure out what a Bot Instance is for/who it belongs to when making decisions (e.g can we upgrade/break this Bot safely).**\n+\n+How bot/instances are tagged with an owner, organizational area or purpose will be the subject of a later phase of delivery. As such it is left undefined for the time being. It may simply be a series of optional fields (or labels) which can be included in the `tbot` configuration, via flags or environment variables. These would be sent along with heartbeats and be visible in the web UI.\n+\n+**As a Bot Instance owner (Dev/Dev Ops team), I'd like help in understanding why my Bot Instance is not working properly.**\n+\n+For somebody diagnosing an issue with `tbot`, they\u2019re likely to have access to the `tbot` log output. Such as;\n+\n+```\n+INFO [TBOT:IDENTITY] Fetched new bot identity identity:mwi-demo-aws-manager, id=5c6af2e6-13a4-48c1-855f-74d8b8e01d86 | valid: after=2025-08-21T12:10:15Z, before=2025-08-21T12:31:13Z, duration=20m58s | kind=tls, renewable=false, disallow-reissue=false, roles=[bot-mwi-demo-aws-manager], principals=[-teleport-internal-join], generation=1 tbot/service_bot_identity.go:224\n+```\n+\n+This log entry contains the bot name (as `identity`) and the instance\u2019s ID. Either of these values can be used to filter the instances list, and should make finding the relevant instance easy.\n+\n+Once found, the instance can be selected to view instance details. Here a health status can be found for each `tbot` service (outputs, tunnels, etc), which includes failure info for those services which are unhealthy. Additionally, a listing of all notices raised by the instance in it\u2019s last run can be viewed, which may reveal the root cause of a failure.\n+\n+### Instances dashboard\n+\n+![](assets/0222-dashboard.png)\n+\n+### Instance details\n+\n+![](assets/0222-details-overview.png)\n+\n+![](assets/0222-details-services.png)\n+\n+![](assets/0222-details-notices.png)\n+\n+![](assets/0222-details-config.png)\n+\n+### Predicate language for instance filters\n+\n+The predicate language will be used to provide advanced filtering for instances. The filter query will be applied in the same way the existing filters work, and no changes to indexes are required. As items are read out of the backend storage, they are filtered one by one until the page size is reached or the end of the list. For a narrow filter, many or even all records will be scanned - this inefficiency is mitigated by the in-memory caching layer's performance. A custom language parser will be used to provide instance-specific functions such as those in the table below.\n+\n+| Purpose | Example |\n+| --- | --- |\n+| Find instances running versions less than a given version - based on the most recent heartbeat | `semver_lt(version, 18.1)` |\n+| Find instances running versions between a vulnerable version and a fix version - based on the most recent heartbeat | `semver_gte(version, \"18\") && semver_lt(version, \"18.1\")` |",
        "comment_created_at": "2025-09-02T13:31:11+00:00",
        "comment_author": "rosstimothy",
        "comment_body": "Do we need to support _or_equal though, you could get that via `newer_than(version, 17.999999.9999)` to find all releases that would include 18.0.0 and all newer releases.\r\n\r\nAlternatively we could add an `equal_to(version, 18.0.0)` predicate that could be combined via `newer_then(version, 18.0.0) || equal_to(version, 18.0.0)` to achieve the same behavior. ",
        "pr_file_module": null
      },
      {
        "comment_id": "2322569128",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 57888,
        "pr_file": "rfd/0222-bot-instances-at-scale.md",
        "discussion_id": "2310223707",
        "commented_code": "@@ -0,0 +1,367 @@\n+---\n+authors: Nick Marais (nicholas.marais@goteleport.com), Dan Upton (dan.upton@goteleport.com)\n+state: draft\n+---\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+## Required Approvers\n+\n+- Engineering: @strideynet\n+- Product: @thedevelopnik\n+\n+# RFD 0222 - Bot Instances at Scale\n+\n+# What\n+\n+This proposal seeks to address the pain points of configuring and running a large fleet of Machine & Workload ID bots.\n+\n+It will focus solely on the Day 1 experience, and users are expected to be familiar with Teleport in general as well as the config and setup of their respective clusters. Day 0 tutorialization of setup steps and guided beginner scenarios are left to other initiatives.\n+\n+# Why\n+\n+As adoption of Machine & Workload ID increases, in part due to the drive to increase efficiency through automation as well as trends like Agentive AI, customers expect managing large fleets of bots to be simple and easy.\n+\n+It\u2019s the responsibility of the **infrastructure security team** to own and manage the Teleport cluster and enrol protected resources. For teams which make extensive use of Machine & Workload ID, it has become cumbersome to manage many bots and hundreds of instances. Where Dev/Dev Ops teams deploy bot instances themselves, it can be doubly difficult to coordinate upgrades and security initiatives.\n+\n+# Details\n+\n+## UX\n+\n+### User Stories\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are blocking a safe cluster upgrade (major) due to their version.**\n+\n+The upgrade process can vary depending on the flavour of Teleport in use (cloud, oss, etc), and how it\u2019s deployed. A common step is to query for agents running a version which would become incompatible should an upgrade be done - using `tctl inventory ls --older-than=v18.0.0`. This command does not include bot instances, and `tctl bots instances ls` doesn\u2019t return versions numbers for instances.\n+\n+As such, it is a difficult task to identify bot instances that may be running an old version of `tbot`. This is especially difficult at scale. The current bot instance list available in the web app allows filtering by version, although it\u2019s a text search and it is not aware of semantic versioning - finding versions older than a given version is not possible.\n+\n+A breakdown of active instance versions will make the process of monitoring the version status easy at a glance, as well as provide convenient links to filter the instance list for versions already one or more major version behind the control plane (thereby preventing a safe upgrade). To facilitate this, the filter will allow queries such as `semver_lt(version, \"18.1\")`. The instance list will also indicate the status of an instance\u2019s most recent version (as up-to-date, upgrade available, patch available, or incompatible).\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances, across all Bots, are running vulnerable versions.**\n+\n+Currently the instances list can be filtered by version, but this is a text search and it is not aware of semantic versioning. It\u2019s possible to find a specific version number, but it\u2019s not easy to isolate a range of versions, such as \u201c>18 & <18.2.1\u201d, which is likely required to find instances between a vulnerable and patched version.\n+\n+To support this use-case, the filter for bot instances will support the predicate language and allow queries such as `semver_gte(version, \"18.1.0\") && semver_lt(version, \"19\")`.\n+\n+**As a cluster owner (Infrastructure Security team), I want to know which Bot Instances are running with deprecated/problematic configuration.**\n+\n+Issues in `tbot` (or just typos) can be difficult to detect and logs may not adequately highlight these. To improve the rate of these events reaching users, `tbot` will detect and collate notices which are sent with the next heartbeat. They will then be available to view for a bot instance. To help in situations where it\u2019s infeasible to check each individual instance, notices will be summarized by title and presented in aggregate form. Each aggregated item will be selectable and will filter the bot instances list. A filter such as `contains(notices, \"Proxy URL not set\")` will be pre-populated.\n+\n+**As a cluster owner (Infrastructure Security team), I'd like to be able to figure out what a Bot Instance is for/who it belongs to when making decisions (e.g can we upgrade/break this Bot safely).**\n+\n+How bot/instances are tagged with an owner, organizational area or purpose will be the subject of a later phase of delivery. As such it is left undefined for the time being. It may simply be a series of optional fields (or labels) which can be included in the `tbot` configuration, via flags or environment variables. These would be sent along with heartbeats and be visible in the web UI.\n+\n+**As a Bot Instance owner (Dev/Dev Ops team), I'd like help in understanding why my Bot Instance is not working properly.**\n+\n+For somebody diagnosing an issue with `tbot`, they\u2019re likely to have access to the `tbot` log output. Such as;\n+\n+```\n+INFO [TBOT:IDENTITY] Fetched new bot identity identity:mwi-demo-aws-manager, id=5c6af2e6-13a4-48c1-855f-74d8b8e01d86 | valid: after=2025-08-21T12:10:15Z, before=2025-08-21T12:31:13Z, duration=20m58s | kind=tls, renewable=false, disallow-reissue=false, roles=[bot-mwi-demo-aws-manager], principals=[-teleport-internal-join], generation=1 tbot/service_bot_identity.go:224\n+```\n+\n+This log entry contains the bot name (as `identity`) and the instance\u2019s ID. Either of these values can be used to filter the instances list, and should make finding the relevant instance easy.\n+\n+Once found, the instance can be selected to view instance details. Here a health status can be found for each `tbot` service (outputs, tunnels, etc), which includes failure info for those services which are unhealthy. Additionally, a listing of all notices raised by the instance in it\u2019s last run can be viewed, which may reveal the root cause of a failure.\n+\n+### Instances dashboard\n+\n+![](assets/0222-dashboard.png)\n+\n+### Instance details\n+\n+![](assets/0222-details-overview.png)\n+\n+![](assets/0222-details-services.png)\n+\n+![](assets/0222-details-notices.png)\n+\n+![](assets/0222-details-config.png)\n+\n+### Predicate language for instance filters\n+\n+The predicate language will be used to provide advanced filtering for instances. The filter query will be applied in the same way the existing filters work, and no changes to indexes are required. As items are read out of the backend storage, they are filtered one by one until the page size is reached or the end of the list. For a narrow filter, many or even all records will be scanned - this inefficiency is mitigated by the in-memory caching layer's performance. A custom language parser will be used to provide instance-specific functions such as those in the table below.\n+\n+| Purpose | Example |\n+| --- | --- |\n+| Find instances running versions less than a given version - based on the most recent heartbeat | `semver_lt(version, 18.1)` |\n+| Find instances running versions between a vulnerable version and a fix version - based on the most recent heartbeat | `semver_gte(version, \"18\") && semver_lt(version, \"18.1\")` |",
        "comment_created_at": "2025-09-04T15:32:13+00:00",
        "comment_author": "nicholasmarais1158",
        "comment_body": "I've gone with `between(version, \"18.0.0\", \"18.1.0\")` instead.",
        "pr_file_module": null
      }
    ]
  }
]