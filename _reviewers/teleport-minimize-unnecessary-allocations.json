[
  {
    "discussion_id": "2301610532",
    "pr_number": 58116,
    "pr_file": "lib/web/recordingplayback.go",
    "created_at": "2025-08-26T17:02:53+00:00",
    "commented_code": "+/**\n+ * Teleport\n+ * Copyright (C) 2025  Gravitational, Inc.\n+ *\n+ * This program is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+\n+package web\n+\n+import (\n+\t\"context\"\n+\t\"encoding/binary\"\n+\t\"fmt\"\n+\t\"log/slog\"\n+\t\"net/http\"\n+\t\"sync\"\n+\t\"time\"\n+\n+\t\"github.com/gorilla/websocket\"\n+\t\"github.com/gravitational/trace\"\n+\t\"github.com/hinshun/vt10x\"\n+\t\"github.com/julienschmidt/httprouter\"\n+\n+\t\"github.com/gravitational/teleport\"\n+\t\"github.com/gravitational/teleport/api/metadata\"\n+\tapievents \"github.com/gravitational/teleport/api/types/events\"\n+\t\"github.com/gravitational/teleport/lib/events\"\n+\t\"github.com/gravitational/teleport/lib/reversetunnelclient\"\n+\t\"github.com/gravitational/teleport/lib/session\"\n+\t\"github.com/gravitational/teleport/lib/terminal\"\n+\t\"github.com/gravitational/teleport/lib/utils\"\n+)\n+\n+type requestType byte\n+\n+// Identifies requests coming from the client (web UI)\n+const (\n+\t// requestTypeFetch requests event data\n+\trequestTypeFetch requestType = 1\n+)\n+\n+type responseType byte\n+\n+// Response types send back to the client\n+const (\n+\t// eventTypeStart indicates the start of a response of events\n+\teventTypeStart responseType = 1\n+\t// eventTypeStop indicates the stop of a response of events\n+\teventTypeStop responseType = 2\n+\t// eventTypeError indicates an error\n+\teventTypeError responseType = 3\n+\t// eventTypeSessionStart indicates session started\n+\teventTypeSessionStart responseType = 4\n+\t// eventTypeSessionPrint contains terminal output\n+\teventTypeSessionPrint responseType = 5\n+\t// eventTypeSessionEnd indicates session ended\n+\teventTypeSessionEnd responseType = 6\n+\t// eventTypeResize indicates terminal resize\n+\teventTypeResize responseType = 7\n+\t// eventTypeScreen contains terminal screen state\n+\teventTypeScreen responseType = 8\n+\t// eventTypeBatch indicates a batch of events\n+\teventTypeBatch responseType = 9\n+)\n+\n+const (\n+\t// maxRequestRange is the maximum allowed time range for a request\n+\tmaxRequestRange = 10 * time.Minute\n+\t// requestHeaderSize is the size of the request header (event type, start time, end time, request ID, and current screen flag)\n+\trequestHeaderSize = 22\n+\t// responseHeaderSize is the size of the response header (event type, timestamp, data size, and request ID)\n+\tresponseHeaderSize = 17\n+)\n+\n+const websocketCloseTimeout = 5 * time.Second\n+\n+// websocketMessage represents a message to be written to the websocket\n+type websocketMessage struct {\n+\tmessageType int\n+\tdata        []byte\n+}\n+\n+// recordingPlayback manages session event streaming\n+type recordingPlayback struct {\n+\tctx              context.Context\n+\tcancel           context.CancelFunc\n+\tclt              events.SessionStreamer\n+\tsessionID        string\n+\tlogger           *slog.Logger\n+\tmu               sync.Mutex\n+\tcancelActiveTask context.CancelFunc\n+\ttaskWg           *sync.WaitGroup\n+\tws               *websocket.Conn\n+\twriteChan        chan websocketMessage\n+\tcloseSent        bool // tracks if a close message has been sent\n+\n+\tstream struct {\n+\t\tsync.Mutex\n+\t\teventsChan    <-chan apievents.AuditEvent\n+\t\terrorsChan    <-chan error\n+\t\tlastEndTime   int64\n+\t\tbufferedEvent apievents.AuditEvent\n+\t}\n+\n+\tterminal struct {\n+\t\tsync.Mutex\n+\t\tvt          vt10x.Terminal\n+\t\tcurrentTime int64\n+\t}\n+}\n+\n+// fetchRequest represents a request for session events.\n+type fetchRequest struct {\n+\trequestType          requestType\n+\tstartOffset          int64\n+\tendOffset            int64\n+\trequestID            int\n+\trequestCurrentScreen bool\n+}\n+\n+// sessionEvent represents a single session event with its type, timestamp, and data.\n+type sessionEvent struct {\n+\teventType responseType\n+\ttimestamp int64\n+\tdata      []byte\n+}\n+\n+func (h *Handler) recordingPlaybackWs(\n+\tw http.ResponseWriter,\n+\tr *http.Request,\n+\tp httprouter.Params,\n+\tsctx *SessionContext,\n+\tcluster reversetunnelclient.Cluster,\n+\tws *websocket.Conn,\n+) (interface{}, error) {\n+\tsessionID := p.ByName(\"session_id\")\n+\tif sessionID == \"\" {\n+\t\treturn nil, trace.BadParameter(\"missing session ID in request URL\")\n+\t}\n+\n+\tctx := r.Context()\n+\tclt, err := sctx.GetUserClient(ctx, cluster)\n+\tif err != nil {\n+\t\tdata := []byte(err.Error())\n+\n+\t\ttotalSize := responseHeaderSize + len(data)\n+\t\tbuf := make([]byte, totalSize)\n+\n+\t\tencodeEvent(buf, 0, eventTypeError, 0, data, 0)\n+\n+\t\tif err := ws.WriteMessage(websocket.BinaryMessage, buf); err != nil {\n+\t\t\th.logger.ErrorContext(ctx, \"failed to send event\", \"session_id\", sessionID, \"error\", err)\n+\t\t}\n+\n+\t\tgracefulWebSocketClose(ws, websocketCloseTimeout)\n+\n+\t\treturn nil, nil\n+\t}\n+\n+\tplayback := newRecordingPlayback(ctx, ws, clt, sessionID, h.logger)\n+\n+\tplayback.run()\n+\n+\treturn nil, nil\n+}\n+\n+// newRecordingPlayback creates a new session recording playback handler.\n+// This provides a way for the client to request session events within a specific time range, as well as the current\n+// terminal screen state at a given time (when seeking).\n+// This allows for faster seeking without having to send the client extra events to reconstruct the terminal state.\n+func newRecordingPlayback(ctx context.Context, ws *websocket.Conn, clt events.SessionStreamer, sessionID string, logger *slog.Logger) *recordingPlayback {\n+\tctx, cancel := context.WithCancel(ctx)\n+\n+\ts := &recordingPlayback{\n+\t\tctx:       ctx,\n+\t\tcancel:    cancel,\n+\t\tclt:       clt,\n+\t\tsessionID: sessionID,\n+\t\tlogger:    logger,\n+\t\tws:        ws,\n+\t\twriteChan: make(chan websocketMessage),\n+\t}\n+\n+\treturn s\n+}\n+\n+// run starts the recording playback handler.\n+func (s *recordingPlayback) run() {\n+\tdefer s.cleanup()\n+\n+\tgo s.writeLoop()\n+\n+\ts.readLoop()\n+}\n+\n+// cleanup cleans up the recording playback resources.\n+func (s *recordingPlayback) cleanup() {\n+\ts.cancel()\n+\n+\t// Wait for any active task to complete\n+\ts.mu.Lock()\n+\twg := s.taskWg\n+\talreadySent := s.closeSent\n+\ts.mu.Unlock()\n+\n+\tif wg != nil {\n+\t\twg.Wait()\n+\t}\n+\n+\t// Only send close message if we haven't already sent one\n+\tif !alreadySent {\n+\t\tselect {\n+\t\tcase s.writeChan <- websocketMessage{\n+\t\t\tmessageType: websocket.CloseMessage,\n+\t\t\tdata:        websocket.FormatCloseMessage(websocket.CloseNormalClosure, \"\"),\n+\t\t}:\n+\t\tcase <-time.After(websocketCloseTimeout):\n+\t\t}\n+\t}\n+\n+\tclose(s.writeChan)\n+\n+\t// Wait for peer's close frame response (or timeout)\n+\tdeadline := time.Now().Add(websocketCloseTimeout)\n+\t_ = s.ws.SetReadDeadline(deadline)\n+\t_, _, _ = s.ws.ReadMessage()\n+\n+\t// Finally close the underlying connection\n+\ts.ws.Close()\n+}\n+\n+// writeLoop handles all websocket writes from a dedicated goroutine.\n+func (s *recordingPlayback) writeLoop() {\n+\tfor {\n+\t\tselect {\n+\t\tcase <-s.ctx.Done():\n+\t\t\treturn\n+\t\tcase msg, ok := <-s.writeChan:\n+\t\t\tif !ok {\n+\t\t\t\treturn\n+\t\t\t}\n+\n+\t\t\tif err := s.ws.SetWriteDeadline(time.Now().Add(10 * time.Second)); err != nil {\n+\t\t\t\ts.logWebsocketError(err)\n+\t\t\t\treturn\n+\t\t\t}\n+\n+\t\t\tif err := s.ws.WriteMessage(msg.messageType, msg.data); err != nil {\n+\t\t\t\ts.logWebsocketError(err)\n+\t\t\t\treturn\n+\t\t\t}\n+\n+\t\t\t// If we just sent a close message, exit the loop\n+\t\t\tif msg.messageType == websocket.CloseMessage {\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t}\n+\t}\n+}\n+\n+// logWebsocketError handles errors that occur during websocket writes.\n+func (s *recordingPlayback) logWebsocketError(err error) {\n+\tif !websocket.IsCloseError(err, websocket.CloseNormalClosure, websocket.CloseGoingAway) &&\n+\t\t!utils.IsOKNetworkError(err) {\n+\t\ts.logger.ErrorContext(s.ctx, \"websocket write error\", \"error\", err)\n+\t}\n+}\n+\n+// readLoop reads messages from the websocket connection and processes them.\n+func (s *recordingPlayback) readLoop() {\n+\tfor {\n+\t\tmsgType, data, err := s.ws.ReadMessage()\n+\t\tif err != nil {\n+\t\t\ts.logWebsocketError(err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\tif msgType != websocket.BinaryMessage {\n+\t\t\ts.logger.ErrorContext(s.ctx, \"ignoring non-binary websocket message\", \"session_id\", s.sessionID, \"type\", msgType)\n+\n+\t\t\t// Mark that we're sending a close message\n+\t\t\ts.mu.Lock()\n+\t\t\ts.closeSent = true\n+\t\t\ts.mu.Unlock()\n+\n+\t\t\t// Send close message through the write channel\n+\t\t\tselect {\n+\t\t\tcase s.writeChan <- websocketMessage{\n+\t\t\t\tmessageType: websocket.CloseMessage,\n+\t\t\t\tdata:        websocket.FormatCloseMessage(websocket.CloseUnsupportedData, \"only binary messages are supported\"),\n+\t\t\t}:\n+\t\t\tdefault:\n+\t\t\t}\n+\n+\t\t\treturn\n+\t\t}\n+\n+\t\treq, err := decodeBinaryRequest(data)\n+\t\tif err != nil {\n+\t\t\ts.logger.ErrorContext(s.ctx, \"failed to decode request\", \"session_id\", s.sessionID, \"error\", err)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\tswitch req.requestType {\n+\t\tcase requestTypeFetch:\n+\t\t\ts.handleFetchRequest(req)\n+\t\tdefault:\n+\t\t\ts.sendError(trace.BadParameter(\"unknown request type: %d\", req.requestType), req.requestID)\n+\n+\t\t\ts.logger.ErrorContext(s.ctx, \"received unknown request type\", \"session_id\", s.sessionID, \"type\", req.requestType)\n+\t\t}\n+\t}\n+}\n+\n+// createTaskContext creates a new context for a task and cancels any previous task.\n+// A task context is used to manage the lifecycle of a fetch request, ensuring that only one fetch request is active at a time.\n+func (s *recordingPlayback) createTaskContext() context.Context {\n+\ts.mu.Lock()\n+\n+\tif s.cancelActiveTask != nil {\n+\t\t// Cancel the active task first\n+\t\ts.cancelActiveTask()\n+\t\toldWg := s.taskWg\n+\t\ts.mu.Unlock()\n+\n+\t\t// Wait for streamEvents to terminate before continuing\n+\t\t// We unlock the mutex while waiting to avoid deadlock\n+\t\tif oldWg != nil {\n+\t\t\toldWg.Wait()\n+\t\t}\n+\n+\t\ts.mu.Lock()\n+\t}\n+\n+\t// Create a new WaitGroup for the new task\n+\ts.taskWg = &sync.WaitGroup{}\n+\n+\tctx, taskCancel := context.WithCancel(s.ctx)\n+\ts.cancelActiveTask = taskCancel\n+\ts.mu.Unlock()\n+\n+\treturn ctx\n+}\n+\n+// handleFetchRequest processes a fetch request for session events.\n+func (s *recordingPlayback) handleFetchRequest(req *fetchRequest) {\n+\tif err := validateRequest(req); err != nil {\n+\t\ts.sendError(err, req.requestID)\n+\n+\t\treturn\n+\t}\n+\n+\tctx := s.createTaskContext()\n+\n+\ts.stream.Lock()\n+\n+\t// start the stream if it doesn't exist or if we need to go back in time\n+\tneedNewStream := s.stream.eventsChan == nil || req.startOffset < s.stream.lastEndTime\n+\n+\tif needNewStream {\n+\t\tevents, errors := s.clt.StreamSessionEvents(\n+\t\t\tmetadata.WithSessionRecordingFormatContext(ctx, teleport.PTY),\n+\t\t\tsession.ID(s.sessionID),\n+\t\t\t0,\n+\t\t)\n+\n+\t\tif events == nil || errors == nil {\n+\t\t\ts.sendError(fmt.Errorf(\"failed to start session event stream\"), req.requestID)\n+\t\t\ts.stream.Unlock()\n+\n+\t\t\treturn\n+\t\t}\n+\n+\t\ts.stream.eventsChan = events\n+\t\ts.stream.errorsChan = errors\n+\t\ts.stream.lastEndTime = 0\n+\n+\t\ts.terminal.Lock()\n+\t\ts.terminal.vt = vt10x.New()\n+\t\ts.terminal.Unlock()\n+\t}\n+\n+\ts.stream.lastEndTime = req.endOffset\n+\n+\teventsChan := s.stream.eventsChan\n+\terrorsChan := s.stream.errorsChan\n+\n+\ts.stream.Unlock()\n+\n+\t// Get the current task's WaitGroup\n+\ts.mu.Lock()\n+\twg := s.taskWg\n+\ts.mu.Unlock()\n+\n+\tif wg != nil {\n+\t\twg.Add(1)\n+\t\tgo func() {\n+\t\t\tdefer wg.Done()\n+\t\t\ts.streamEvents(ctx, req, eventsChan, errorsChan)\n+\t\t}()\n+\t} else {\n+\t\tgo s.streamEvents(ctx, req, eventsChan, errorsChan)\n+\t}\n+}\n+\n+// streamEvents streams session events to the client.\n+func (s *recordingPlayback) streamEvents(ctx context.Context, req *fetchRequest, eventsChan <-chan apievents.AuditEvent, errorsChan <-chan error) {\n+\n+\tstartSent := false\n+\tscreenSent := false\n+\tinTimeRange := false\n+\tvar streamStartTime time.Time\n+\n+\tconst maxBatchSize = 200\n+\teventBatch := make([]sessionEvent, 0, maxBatchSize)\n+\n+\tflushBatch := func() {\n+\t\t// Send start event if not already sent\n+\t\tif !startSent {\n+\t\t\ts.sendEvent(eventTypeStart, req.startOffset, nil, req.requestID)\n+\t\t\tstartSent = true\n+\t\t}\n+\n+\t\tif len(eventBatch) == 0 {\n+\t\t\treturn\n+\t\t}\n+\n+\t\ts.sendEventBatch(eventBatch, req.requestID)\n+\t\teventBatch = eventBatch[:0]\n+\t}\n+\n+\taddToBatch := func(eventType responseType, timestamp int64, data []byte) {\n+\t\teventBatch = append(eventBatch, sessionEvent{eventType, timestamp, data})\n+\n+\t\tif len(eventBatch) >= maxBatchSize {\n+\t\t\tflushBatch()\n+\t\t}\n+\t}\n+\n+\tsendStop := func() {\n+\t\t// Send start event if not already sent\n+\t\tif !startSent {\n+\t\t\ts.sendEvent(eventTypeStart, req.startOffset, nil, req.requestID)\n+\t\t\tstartSent = true\n+\t\t}\n+\n+\t\ts.sendEvent(eventTypeStop, 0, encodeTime(req.startOffset, req.endOffset), req.requestID)\n+\t}\n+\n+\t// process an event, returning a boolean indicating if the events should continue being\n+\t// processed (i.e. returns false once we have reached the end of the requested time window)\n+\tprocessEvent := func(evt apievents.AuditEvent) bool {\n+\t\tif _, ok := evt.(*apievents.SessionStart); ok && streamStartTime.IsZero() {\n+\t\t\tstreamStartTime = evt.GetTime()\n+\t\t}\n+\n+\t\teventTime := getEventTime(evt)\n+\n+\t\tif !inTimeRange && eventTime >= req.startOffset {\n+\t\t\tinTimeRange = true\n+\n+\t\t\tif req.requestCurrentScreen && !screenSent {\n+\t\t\t\tflushBatch()\n+\t\t\t\ts.sendCurrentScreen(req.requestID, eventTime)\n+\n+\t\t\t\tscreenSent = true\n+\t\t\t}\n+\t\t}\n+\n+\t\tif eventTime > req.endOffset {\n+\t\t\ts.stream.Lock()\n+\t\t\t// store the event for the next request as it is outside the current time range\n+\t\t\t// and won't be returned by the stream on the next request\n+\t\t\t// this will only store print or end events as they are the only ones with a timestamp\n+\t\t\ts.stream.bufferedEvent = evt\n+\t\t\ts.stream.Unlock()\n+\n+\t\t\treturn false\n+\t\t}\n+\n+\t\tswitch evt := evt.(type) {\n+\t\tcase *apievents.SessionStart:\n+\t\t\tif err := s.resizeTerminal(evt.TerminalSize); err != nil {\n+\t\t\t\ts.logger.ErrorContext(s.ctx, \"failed to resize terminal\", \"session_id\", s.sessionID, \"error\", err)\n+\n+\t\t\t\t// continue returning events even if resize fails\n+\t\t\t}\n+\n+\t\t\tif inTimeRange {\n+\t\t\t\taddToBatch(eventTypeSessionStart, 0, []byte(evt.TerminalSize))\n+\t\t\t}\n+\n+\t\tcase *apievents.SessionPrint:\n+\t\t\ts.terminal.Lock()\n+\t\t\tif _, err := s.terminal.vt.Write(evt.Data); err != nil {\n+\t\t\t\ts.logger.ErrorContext(s.ctx, \"failed to write to terminal\", \"session_id\", s.sessionID, \"error\", err)\n+\t\t\t}\n+\t\t\ts.terminal.Unlock()\n+\n+\t\t\tif inTimeRange {\n+\t\t\t\taddToBatch(eventTypeSessionPrint, evt.DelayMilliseconds, evt.Data)\n+\t\t\t}\n+\n+\t\tcase *apievents.SessionEnd:\n+\t\t\tendTime := int64(evt.EndTime.Sub(evt.StartTime) / time.Millisecond)\n+\n+\t\t\tif inTimeRange {\n+\t\t\t\taddToBatch(eventTypeSessionEnd, endTime, []byte(evt.EndTime.Format(time.RFC3339)))\n+\t\t\t}\n+\n+\t\t\treturn false\n+\n+\t\tcase *apievents.Resize:\n+\t\t\tif err := s.resizeTerminal(evt.TerminalSize); err != nil {\n+\t\t\t\ts.logger.ErrorContext(s.ctx, \"failed to resize terminal\", \"session_id\", s.sessionID, \"error\", err)\n+\n+\t\t\t\t// continue returning events even if resize fails\n+\t\t\t}\n+\n+\t\t\t// always add resize events as they do not have a timestamp\n+\t\t\taddToBatch(eventTypeResize, 0, []byte(evt.TerminalSize))\n+\t\t}\n+\n+\t\treturn true\n+\t}\n+\n+\ts.stream.Lock()\n+\n+\tbuffered := s.stream.bufferedEvent\n+\ts.stream.bufferedEvent = nil\n+\n+\ts.stream.Unlock()\n+\n+\tif buffered != nil {\n+\t\t// process any buffered event from a previous request first\n+\t\t// the processEvent will ignore it if it's outside the requested time range\n+\t\t_ = processEvent(buffered)\n+\t}\n+\n+\tfor {\n+\t\tselect {\n+\t\tcase <-ctx.Done():\n+\t\t\t// Don't send any more events after context cancellation\n+\t\t\treturn\n+\n+\t\tcase err := <-errorsChan:\n+\t\t\tflushBatch()\n+\t\t\tif err != nil {\n+\t\t\t\ts.sendError(err, req.requestID)\n+\t\t\t}\n+\t\t\tsendStop()\n+\n+\t\t\treturn\n+\n+\t\tcase evt, ok := <-eventsChan:\n+\t\t\tif !ok {\n+\t\t\t\tflushBatch()\n+\t\t\t\tif req.requestCurrentScreen && !screenSent && inTimeRange {\n+\t\t\t\t\ts.sendCurrentScreen(req.requestID, req.startOffset)\n+\t\t\t\t}\n+\t\t\t\tsendStop()\n+\n+\t\t\t\treturn\n+\t\t\t}\n+\n+\t\t\tif !processEvent(evt) {\n+\t\t\t\tflushBatch()\n+\t\t\t\tsendStop()\n+\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t}\n+\t}\n+}\n+\n+// resizeTerminal resizes the terminal based on the provided size string.\n+func (s *recordingPlayback) resizeTerminal(size string) error {\n+\tparams, err := session.UnmarshalTerminalParams(size)\n+\tif err != nil {\n+\t\treturn trace.Wrap(err)\n+\t}\n+\n+\ts.terminal.Lock()\n+\tdefer s.terminal.Unlock()\n+\n+\ts.terminal.vt.Resize(params.W, params.H)\n+\n+\treturn nil\n+}\n+\n+// writeMessage sends a message through the write channel.\n+func (s *recordingPlayback) writeMessage(data []byte) error {\n+\tselect {\n+\tcase <-s.ctx.Done():\n+\t\treturn s.ctx.Err()\n+\tcase s.writeChan <- websocketMessage{messageType: websocket.BinaryMessage, data: data}:\n+\t\treturn nil\n+\tcase <-time.After(10 * time.Second):\n+\t\treturn fmt.Errorf(\"timeout sending message\")\n+\t}\n+}\n+\n+// sendEvent sends a single event to the client.\n+func (s *recordingPlayback) sendEvent(eventType responseType, timestamp int64, data []byte, requestID int) {\n+\ttotalSize := responseHeaderSize + len(data)\n+\tbuf := make([]byte, totalSize)\n+\n+\tencodeEvent(buf, 0, eventType, timestamp, data, requestID)\n+\n+\tif err := s.writeMessage(buf); err != nil {\n+\t\ts.logger.ErrorContext(s.ctx, \"failed to send event\", \"session_id\", s.sessionID, \"error\", err)\n+\t}\n+}\n+\n+// sendEventBatch sends a batch of events to the client.\n+func (s *recordingPlayback) sendEventBatch(batch []sessionEvent, requestID int) {\n+\ttotalSize := responseHeaderSize\n+\tfor _, evt := range batch {\n+\t\ttotalSize += responseHeaderSize + len(evt.data)\n+\t}\n+\n+\tbuf := make([]byte, totalSize)\n+\n+\tbuf[0] = byte(eventTypeBatch)\n+\tbinary.BigEndian.PutUint32(buf[1:5], uint32(len(batch)))\n+\tbinary.BigEndian.PutUint32(buf[5:9], uint32(requestID))\n+\n+\toffset := responseHeaderSize\n+\tfor _, evt := range batch {\n+\t\tencodeEvent(buf, offset, evt.eventType, evt.timestamp, evt.data, requestID)\n+\n+\t\toffset += responseHeaderSize + len(evt.data)\n+\t}\n+\n+\tif err := s.writeMessage(buf); err != nil {\n+\t\ts.logger.ErrorContext(s.ctx, \"failed to send event batch\",\n+\t\t\t\"session_id\", s.sessionID,\n+\t\t\t\"error\", err,\n+\t\t\t\"batch_size\", len(batch),\n+\t\t\t\"buffer_size\", totalSize)\n+\t}\n+}\n+\n+// sendError sends an error event to the client.\n+func (s *recordingPlayback) sendError(err error, requestID int) {\n+\ts.sendEvent(eventTypeError, 0, []byte(err.Error()), requestID)\n+}\n+\n+// sendCurrentScreen sends the current terminal screen state to the client.\n+func (s *recordingPlayback) sendCurrentScreen(requestID int, timestamp int64) {\n+\ts.terminal.Lock()\n+\tstate := s.terminal.vt.DumpState()\n+\tcols, rows := s.terminal.vt.Size()\n+\tcursor := s.terminal.vt.Cursor()\n+\ts.terminal.Unlock()\n+\n+\tdata := encodeScreenEvent(state, cols, rows, cursor)\n+\n+\ts.sendEvent(eventTypeScreen, timestamp, data, requestID)\n+}\n+\n+// encodeScreenEvent encodes the current terminal screen state into a byte slice.\n+func encodeScreenEvent(state vt10x.TerminalState, cols, rows int, cursor vt10x.Cursor) []byte {\n+\tdata := terminal.VtStateToANSI(state)\n+\n+\teventData := make([]byte, requestHeaderSize+len(data))\n+\teventData[0] = byte(eventTypeScreen)\n+\n+\tbinary.BigEndian.PutUint32(eventData[1:5], uint32(cols))\n+\tbinary.BigEndian.PutUint32(eventData[5:9], uint32(rows))\n+\tbinary.BigEndian.PutUint32(eventData[9:13], uint32(cursor.X))\n+\tbinary.BigEndian.PutUint32(eventData[13:17], uint32(cursor.Y))\n+\tbinary.BigEndian.PutUint32(eventData[17:21], uint32(len(data)))\n+\n+\tcopy(eventData[requestHeaderSize:], data)",
    "repo_full_name": "gravitational/teleport",
    "discussion_comments": [
      {
        "comment_id": "2301610532",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58116,
        "pr_file": "lib/web/recordingplayback.go",
        "discussion_id": "2301610532",
        "commented_code": "@@ -0,0 +1,773 @@\n+/**\n+ * Teleport\n+ * Copyright (C) 2025  Gravitational, Inc.\n+ *\n+ * This program is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+\n+package web\n+\n+import (\n+\t\"context\"\n+\t\"encoding/binary\"\n+\t\"fmt\"\n+\t\"log/slog\"\n+\t\"net/http\"\n+\t\"sync\"\n+\t\"time\"\n+\n+\t\"github.com/gorilla/websocket\"\n+\t\"github.com/gravitational/trace\"\n+\t\"github.com/hinshun/vt10x\"\n+\t\"github.com/julienschmidt/httprouter\"\n+\n+\t\"github.com/gravitational/teleport\"\n+\t\"github.com/gravitational/teleport/api/metadata\"\n+\tapievents \"github.com/gravitational/teleport/api/types/events\"\n+\t\"github.com/gravitational/teleport/lib/events\"\n+\t\"github.com/gravitational/teleport/lib/reversetunnelclient\"\n+\t\"github.com/gravitational/teleport/lib/session\"\n+\t\"github.com/gravitational/teleport/lib/terminal\"\n+\t\"github.com/gravitational/teleport/lib/utils\"\n+)\n+\n+type requestType byte\n+\n+// Identifies requests coming from the client (web UI)\n+const (\n+\t// requestTypeFetch requests event data\n+\trequestTypeFetch requestType = 1\n+)\n+\n+type responseType byte\n+\n+// Response types send back to the client\n+const (\n+\t// eventTypeStart indicates the start of a response of events\n+\teventTypeStart responseType = 1\n+\t// eventTypeStop indicates the stop of a response of events\n+\teventTypeStop responseType = 2\n+\t// eventTypeError indicates an error\n+\teventTypeError responseType = 3\n+\t// eventTypeSessionStart indicates session started\n+\teventTypeSessionStart responseType = 4\n+\t// eventTypeSessionPrint contains terminal output\n+\teventTypeSessionPrint responseType = 5\n+\t// eventTypeSessionEnd indicates session ended\n+\teventTypeSessionEnd responseType = 6\n+\t// eventTypeResize indicates terminal resize\n+\teventTypeResize responseType = 7\n+\t// eventTypeScreen contains terminal screen state\n+\teventTypeScreen responseType = 8\n+\t// eventTypeBatch indicates a batch of events\n+\teventTypeBatch responseType = 9\n+)\n+\n+const (\n+\t// maxRequestRange is the maximum allowed time range for a request\n+\tmaxRequestRange = 10 * time.Minute\n+\t// requestHeaderSize is the size of the request header (event type, start time, end time, request ID, and current screen flag)\n+\trequestHeaderSize = 22\n+\t// responseHeaderSize is the size of the response header (event type, timestamp, data size, and request ID)\n+\tresponseHeaderSize = 17\n+)\n+\n+const websocketCloseTimeout = 5 * time.Second\n+\n+// websocketMessage represents a message to be written to the websocket\n+type websocketMessage struct {\n+\tmessageType int\n+\tdata        []byte\n+}\n+\n+// recordingPlayback manages session event streaming\n+type recordingPlayback struct {\n+\tctx              context.Context\n+\tcancel           context.CancelFunc\n+\tclt              events.SessionStreamer\n+\tsessionID        string\n+\tlogger           *slog.Logger\n+\tmu               sync.Mutex\n+\tcancelActiveTask context.CancelFunc\n+\ttaskWg           *sync.WaitGroup\n+\tws               *websocket.Conn\n+\twriteChan        chan websocketMessage\n+\tcloseSent        bool // tracks if a close message has been sent\n+\n+\tstream struct {\n+\t\tsync.Mutex\n+\t\teventsChan    <-chan apievents.AuditEvent\n+\t\terrorsChan    <-chan error\n+\t\tlastEndTime   int64\n+\t\tbufferedEvent apievents.AuditEvent\n+\t}\n+\n+\tterminal struct {\n+\t\tsync.Mutex\n+\t\tvt          vt10x.Terminal\n+\t\tcurrentTime int64\n+\t}\n+}\n+\n+// fetchRequest represents a request for session events.\n+type fetchRequest struct {\n+\trequestType          requestType\n+\tstartOffset          int64\n+\tendOffset            int64\n+\trequestID            int\n+\trequestCurrentScreen bool\n+}\n+\n+// sessionEvent represents a single session event with its type, timestamp, and data.\n+type sessionEvent struct {\n+\teventType responseType\n+\ttimestamp int64\n+\tdata      []byte\n+}\n+\n+func (h *Handler) recordingPlaybackWs(\n+\tw http.ResponseWriter,\n+\tr *http.Request,\n+\tp httprouter.Params,\n+\tsctx *SessionContext,\n+\tcluster reversetunnelclient.Cluster,\n+\tws *websocket.Conn,\n+) (interface{}, error) {\n+\tsessionID := p.ByName(\"session_id\")\n+\tif sessionID == \"\" {\n+\t\treturn nil, trace.BadParameter(\"missing session ID in request URL\")\n+\t}\n+\n+\tctx := r.Context()\n+\tclt, err := sctx.GetUserClient(ctx, cluster)\n+\tif err != nil {\n+\t\tdata := []byte(err.Error())\n+\n+\t\ttotalSize := responseHeaderSize + len(data)\n+\t\tbuf := make([]byte, totalSize)\n+\n+\t\tencodeEvent(buf, 0, eventTypeError, 0, data, 0)\n+\n+\t\tif err := ws.WriteMessage(websocket.BinaryMessage, buf); err != nil {\n+\t\t\th.logger.ErrorContext(ctx, \"failed to send event\", \"session_id\", sessionID, \"error\", err)\n+\t\t}\n+\n+\t\tgracefulWebSocketClose(ws, websocketCloseTimeout)\n+\n+\t\treturn nil, nil\n+\t}\n+\n+\tplayback := newRecordingPlayback(ctx, ws, clt, sessionID, h.logger)\n+\n+\tplayback.run()\n+\n+\treturn nil, nil\n+}\n+\n+// newRecordingPlayback creates a new session recording playback handler.\n+// This provides a way for the client to request session events within a specific time range, as well as the current\n+// terminal screen state at a given time (when seeking).\n+// This allows for faster seeking without having to send the client extra events to reconstruct the terminal state.\n+func newRecordingPlayback(ctx context.Context, ws *websocket.Conn, clt events.SessionStreamer, sessionID string, logger *slog.Logger) *recordingPlayback {\n+\tctx, cancel := context.WithCancel(ctx)\n+\n+\ts := &recordingPlayback{\n+\t\tctx:       ctx,\n+\t\tcancel:    cancel,\n+\t\tclt:       clt,\n+\t\tsessionID: sessionID,\n+\t\tlogger:    logger,\n+\t\tws:        ws,\n+\t\twriteChan: make(chan websocketMessage),\n+\t}\n+\n+\treturn s\n+}\n+\n+// run starts the recording playback handler.\n+func (s *recordingPlayback) run() {\n+\tdefer s.cleanup()\n+\n+\tgo s.writeLoop()\n+\n+\ts.readLoop()\n+}\n+\n+// cleanup cleans up the recording playback resources.\n+func (s *recordingPlayback) cleanup() {\n+\ts.cancel()\n+\n+\t// Wait for any active task to complete\n+\ts.mu.Lock()\n+\twg := s.taskWg\n+\talreadySent := s.closeSent\n+\ts.mu.Unlock()\n+\n+\tif wg != nil {\n+\t\twg.Wait()\n+\t}\n+\n+\t// Only send close message if we haven't already sent one\n+\tif !alreadySent {\n+\t\tselect {\n+\t\tcase s.writeChan <- websocketMessage{\n+\t\t\tmessageType: websocket.CloseMessage,\n+\t\t\tdata:        websocket.FormatCloseMessage(websocket.CloseNormalClosure, \"\"),\n+\t\t}:\n+\t\tcase <-time.After(websocketCloseTimeout):\n+\t\t}\n+\t}\n+\n+\tclose(s.writeChan)\n+\n+\t// Wait for peer's close frame response (or timeout)\n+\tdeadline := time.Now().Add(websocketCloseTimeout)\n+\t_ = s.ws.SetReadDeadline(deadline)\n+\t_, _, _ = s.ws.ReadMessage()\n+\n+\t// Finally close the underlying connection\n+\ts.ws.Close()\n+}\n+\n+// writeLoop handles all websocket writes from a dedicated goroutine.\n+func (s *recordingPlayback) writeLoop() {\n+\tfor {\n+\t\tselect {\n+\t\tcase <-s.ctx.Done():\n+\t\t\treturn\n+\t\tcase msg, ok := <-s.writeChan:\n+\t\t\tif !ok {\n+\t\t\t\treturn\n+\t\t\t}\n+\n+\t\t\tif err := s.ws.SetWriteDeadline(time.Now().Add(10 * time.Second)); err != nil {\n+\t\t\t\ts.logWebsocketError(err)\n+\t\t\t\treturn\n+\t\t\t}\n+\n+\t\t\tif err := s.ws.WriteMessage(msg.messageType, msg.data); err != nil {\n+\t\t\t\ts.logWebsocketError(err)\n+\t\t\t\treturn\n+\t\t\t}\n+\n+\t\t\t// If we just sent a close message, exit the loop\n+\t\t\tif msg.messageType == websocket.CloseMessage {\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t}\n+\t}\n+}\n+\n+// logWebsocketError handles errors that occur during websocket writes.\n+func (s *recordingPlayback) logWebsocketError(err error) {\n+\tif !websocket.IsCloseError(err, websocket.CloseNormalClosure, websocket.CloseGoingAway) &&\n+\t\t!utils.IsOKNetworkError(err) {\n+\t\ts.logger.ErrorContext(s.ctx, \"websocket write error\", \"error\", err)\n+\t}\n+}\n+\n+// readLoop reads messages from the websocket connection and processes them.\n+func (s *recordingPlayback) readLoop() {\n+\tfor {\n+\t\tmsgType, data, err := s.ws.ReadMessage()\n+\t\tif err != nil {\n+\t\t\ts.logWebsocketError(err)\n+\t\t\treturn\n+\t\t}\n+\n+\t\tif msgType != websocket.BinaryMessage {\n+\t\t\ts.logger.ErrorContext(s.ctx, \"ignoring non-binary websocket message\", \"session_id\", s.sessionID, \"type\", msgType)\n+\n+\t\t\t// Mark that we're sending a close message\n+\t\t\ts.mu.Lock()\n+\t\t\ts.closeSent = true\n+\t\t\ts.mu.Unlock()\n+\n+\t\t\t// Send close message through the write channel\n+\t\t\tselect {\n+\t\t\tcase s.writeChan <- websocketMessage{\n+\t\t\t\tmessageType: websocket.CloseMessage,\n+\t\t\t\tdata:        websocket.FormatCloseMessage(websocket.CloseUnsupportedData, \"only binary messages are supported\"),\n+\t\t\t}:\n+\t\t\tdefault:\n+\t\t\t}\n+\n+\t\t\treturn\n+\t\t}\n+\n+\t\treq, err := decodeBinaryRequest(data)\n+\t\tif err != nil {\n+\t\t\ts.logger.ErrorContext(s.ctx, \"failed to decode request\", \"session_id\", s.sessionID, \"error\", err)\n+\t\t\tcontinue\n+\t\t}\n+\n+\t\tswitch req.requestType {\n+\t\tcase requestTypeFetch:\n+\t\t\ts.handleFetchRequest(req)\n+\t\tdefault:\n+\t\t\ts.sendError(trace.BadParameter(\"unknown request type: %d\", req.requestType), req.requestID)\n+\n+\t\t\ts.logger.ErrorContext(s.ctx, \"received unknown request type\", \"session_id\", s.sessionID, \"type\", req.requestType)\n+\t\t}\n+\t}\n+}\n+\n+// createTaskContext creates a new context for a task and cancels any previous task.\n+// A task context is used to manage the lifecycle of a fetch request, ensuring that only one fetch request is active at a time.\n+func (s *recordingPlayback) createTaskContext() context.Context {\n+\ts.mu.Lock()\n+\n+\tif s.cancelActiveTask != nil {\n+\t\t// Cancel the active task first\n+\t\ts.cancelActiveTask()\n+\t\toldWg := s.taskWg\n+\t\ts.mu.Unlock()\n+\n+\t\t// Wait for streamEvents to terminate before continuing\n+\t\t// We unlock the mutex while waiting to avoid deadlock\n+\t\tif oldWg != nil {\n+\t\t\toldWg.Wait()\n+\t\t}\n+\n+\t\ts.mu.Lock()\n+\t}\n+\n+\t// Create a new WaitGroup for the new task\n+\ts.taskWg = &sync.WaitGroup{}\n+\n+\tctx, taskCancel := context.WithCancel(s.ctx)\n+\ts.cancelActiveTask = taskCancel\n+\ts.mu.Unlock()\n+\n+\treturn ctx\n+}\n+\n+// handleFetchRequest processes a fetch request for session events.\n+func (s *recordingPlayback) handleFetchRequest(req *fetchRequest) {\n+\tif err := validateRequest(req); err != nil {\n+\t\ts.sendError(err, req.requestID)\n+\n+\t\treturn\n+\t}\n+\n+\tctx := s.createTaskContext()\n+\n+\ts.stream.Lock()\n+\n+\t// start the stream if it doesn't exist or if we need to go back in time\n+\tneedNewStream := s.stream.eventsChan == nil || req.startOffset < s.stream.lastEndTime\n+\n+\tif needNewStream {\n+\t\tevents, errors := s.clt.StreamSessionEvents(\n+\t\t\tmetadata.WithSessionRecordingFormatContext(ctx, teleport.PTY),\n+\t\t\tsession.ID(s.sessionID),\n+\t\t\t0,\n+\t\t)\n+\n+\t\tif events == nil || errors == nil {\n+\t\t\ts.sendError(fmt.Errorf(\"failed to start session event stream\"), req.requestID)\n+\t\t\ts.stream.Unlock()\n+\n+\t\t\treturn\n+\t\t}\n+\n+\t\ts.stream.eventsChan = events\n+\t\ts.stream.errorsChan = errors\n+\t\ts.stream.lastEndTime = 0\n+\n+\t\ts.terminal.Lock()\n+\t\ts.terminal.vt = vt10x.New()\n+\t\ts.terminal.Unlock()\n+\t}\n+\n+\ts.stream.lastEndTime = req.endOffset\n+\n+\teventsChan := s.stream.eventsChan\n+\terrorsChan := s.stream.errorsChan\n+\n+\ts.stream.Unlock()\n+\n+\t// Get the current task's WaitGroup\n+\ts.mu.Lock()\n+\twg := s.taskWg\n+\ts.mu.Unlock()\n+\n+\tif wg != nil {\n+\t\twg.Add(1)\n+\t\tgo func() {\n+\t\t\tdefer wg.Done()\n+\t\t\ts.streamEvents(ctx, req, eventsChan, errorsChan)\n+\t\t}()\n+\t} else {\n+\t\tgo s.streamEvents(ctx, req, eventsChan, errorsChan)\n+\t}\n+}\n+\n+// streamEvents streams session events to the client.\n+func (s *recordingPlayback) streamEvents(ctx context.Context, req *fetchRequest, eventsChan <-chan apievents.AuditEvent, errorsChan <-chan error) {\n+\n+\tstartSent := false\n+\tscreenSent := false\n+\tinTimeRange := false\n+\tvar streamStartTime time.Time\n+\n+\tconst maxBatchSize = 200\n+\teventBatch := make([]sessionEvent, 0, maxBatchSize)\n+\n+\tflushBatch := func() {\n+\t\t// Send start event if not already sent\n+\t\tif !startSent {\n+\t\t\ts.sendEvent(eventTypeStart, req.startOffset, nil, req.requestID)\n+\t\t\tstartSent = true\n+\t\t}\n+\n+\t\tif len(eventBatch) == 0 {\n+\t\t\treturn\n+\t\t}\n+\n+\t\ts.sendEventBatch(eventBatch, req.requestID)\n+\t\teventBatch = eventBatch[:0]\n+\t}\n+\n+\taddToBatch := func(eventType responseType, timestamp int64, data []byte) {\n+\t\teventBatch = append(eventBatch, sessionEvent{eventType, timestamp, data})\n+\n+\t\tif len(eventBatch) >= maxBatchSize {\n+\t\t\tflushBatch()\n+\t\t}\n+\t}\n+\n+\tsendStop := func() {\n+\t\t// Send start event if not already sent\n+\t\tif !startSent {\n+\t\t\ts.sendEvent(eventTypeStart, req.startOffset, nil, req.requestID)\n+\t\t\tstartSent = true\n+\t\t}\n+\n+\t\ts.sendEvent(eventTypeStop, 0, encodeTime(req.startOffset, req.endOffset), req.requestID)\n+\t}\n+\n+\t// process an event, returning a boolean indicating if the events should continue being\n+\t// processed (i.e. returns false once we have reached the end of the requested time window)\n+\tprocessEvent := func(evt apievents.AuditEvent) bool {\n+\t\tif _, ok := evt.(*apievents.SessionStart); ok && streamStartTime.IsZero() {\n+\t\t\tstreamStartTime = evt.GetTime()\n+\t\t}\n+\n+\t\teventTime := getEventTime(evt)\n+\n+\t\tif !inTimeRange && eventTime >= req.startOffset {\n+\t\t\tinTimeRange = true\n+\n+\t\t\tif req.requestCurrentScreen && !screenSent {\n+\t\t\t\tflushBatch()\n+\t\t\t\ts.sendCurrentScreen(req.requestID, eventTime)\n+\n+\t\t\t\tscreenSent = true\n+\t\t\t}\n+\t\t}\n+\n+\t\tif eventTime > req.endOffset {\n+\t\t\ts.stream.Lock()\n+\t\t\t// store the event for the next request as it is outside the current time range\n+\t\t\t// and won't be returned by the stream on the next request\n+\t\t\t// this will only store print or end events as they are the only ones with a timestamp\n+\t\t\ts.stream.bufferedEvent = evt\n+\t\t\ts.stream.Unlock()\n+\n+\t\t\treturn false\n+\t\t}\n+\n+\t\tswitch evt := evt.(type) {\n+\t\tcase *apievents.SessionStart:\n+\t\t\tif err := s.resizeTerminal(evt.TerminalSize); err != nil {\n+\t\t\t\ts.logger.ErrorContext(s.ctx, \"failed to resize terminal\", \"session_id\", s.sessionID, \"error\", err)\n+\n+\t\t\t\t// continue returning events even if resize fails\n+\t\t\t}\n+\n+\t\t\tif inTimeRange {\n+\t\t\t\taddToBatch(eventTypeSessionStart, 0, []byte(evt.TerminalSize))\n+\t\t\t}\n+\n+\t\tcase *apievents.SessionPrint:\n+\t\t\ts.terminal.Lock()\n+\t\t\tif _, err := s.terminal.vt.Write(evt.Data); err != nil {\n+\t\t\t\ts.logger.ErrorContext(s.ctx, \"failed to write to terminal\", \"session_id\", s.sessionID, \"error\", err)\n+\t\t\t}\n+\t\t\ts.terminal.Unlock()\n+\n+\t\t\tif inTimeRange {\n+\t\t\t\taddToBatch(eventTypeSessionPrint, evt.DelayMilliseconds, evt.Data)\n+\t\t\t}\n+\n+\t\tcase *apievents.SessionEnd:\n+\t\t\tendTime := int64(evt.EndTime.Sub(evt.StartTime) / time.Millisecond)\n+\n+\t\t\tif inTimeRange {\n+\t\t\t\taddToBatch(eventTypeSessionEnd, endTime, []byte(evt.EndTime.Format(time.RFC3339)))\n+\t\t\t}\n+\n+\t\t\treturn false\n+\n+\t\tcase *apievents.Resize:\n+\t\t\tif err := s.resizeTerminal(evt.TerminalSize); err != nil {\n+\t\t\t\ts.logger.ErrorContext(s.ctx, \"failed to resize terminal\", \"session_id\", s.sessionID, \"error\", err)\n+\n+\t\t\t\t// continue returning events even if resize fails\n+\t\t\t}\n+\n+\t\t\t// always add resize events as they do not have a timestamp\n+\t\t\taddToBatch(eventTypeResize, 0, []byte(evt.TerminalSize))\n+\t\t}\n+\n+\t\treturn true\n+\t}\n+\n+\ts.stream.Lock()\n+\n+\tbuffered := s.stream.bufferedEvent\n+\ts.stream.bufferedEvent = nil\n+\n+\ts.stream.Unlock()\n+\n+\tif buffered != nil {\n+\t\t// process any buffered event from a previous request first\n+\t\t// the processEvent will ignore it if it's outside the requested time range\n+\t\t_ = processEvent(buffered)\n+\t}\n+\n+\tfor {\n+\t\tselect {\n+\t\tcase <-ctx.Done():\n+\t\t\t// Don't send any more events after context cancellation\n+\t\t\treturn\n+\n+\t\tcase err := <-errorsChan:\n+\t\t\tflushBatch()\n+\t\t\tif err != nil {\n+\t\t\t\ts.sendError(err, req.requestID)\n+\t\t\t}\n+\t\t\tsendStop()\n+\n+\t\t\treturn\n+\n+\t\tcase evt, ok := <-eventsChan:\n+\t\t\tif !ok {\n+\t\t\t\tflushBatch()\n+\t\t\t\tif req.requestCurrentScreen && !screenSent && inTimeRange {\n+\t\t\t\t\ts.sendCurrentScreen(req.requestID, req.startOffset)\n+\t\t\t\t}\n+\t\t\t\tsendStop()\n+\n+\t\t\t\treturn\n+\t\t\t}\n+\n+\t\t\tif !processEvent(evt) {\n+\t\t\t\tflushBatch()\n+\t\t\t\tsendStop()\n+\n+\t\t\t\treturn\n+\t\t\t}\n+\t\t}\n+\t}\n+}\n+\n+// resizeTerminal resizes the terminal based on the provided size string.\n+func (s *recordingPlayback) resizeTerminal(size string) error {\n+\tparams, err := session.UnmarshalTerminalParams(size)\n+\tif err != nil {\n+\t\treturn trace.Wrap(err)\n+\t}\n+\n+\ts.terminal.Lock()\n+\tdefer s.terminal.Unlock()\n+\n+\ts.terminal.vt.Resize(params.W, params.H)\n+\n+\treturn nil\n+}\n+\n+// writeMessage sends a message through the write channel.\n+func (s *recordingPlayback) writeMessage(data []byte) error {\n+\tselect {\n+\tcase <-s.ctx.Done():\n+\t\treturn s.ctx.Err()\n+\tcase s.writeChan <- websocketMessage{messageType: websocket.BinaryMessage, data: data}:\n+\t\treturn nil\n+\tcase <-time.After(10 * time.Second):\n+\t\treturn fmt.Errorf(\"timeout sending message\")\n+\t}\n+}\n+\n+// sendEvent sends a single event to the client.\n+func (s *recordingPlayback) sendEvent(eventType responseType, timestamp int64, data []byte, requestID int) {\n+\ttotalSize := responseHeaderSize + len(data)\n+\tbuf := make([]byte, totalSize)\n+\n+\tencodeEvent(buf, 0, eventType, timestamp, data, requestID)\n+\n+\tif err := s.writeMessage(buf); err != nil {\n+\t\ts.logger.ErrorContext(s.ctx, \"failed to send event\", \"session_id\", s.sessionID, \"error\", err)\n+\t}\n+}\n+\n+// sendEventBatch sends a batch of events to the client.\n+func (s *recordingPlayback) sendEventBatch(batch []sessionEvent, requestID int) {\n+\ttotalSize := responseHeaderSize\n+\tfor _, evt := range batch {\n+\t\ttotalSize += responseHeaderSize + len(evt.data)\n+\t}\n+\n+\tbuf := make([]byte, totalSize)\n+\n+\tbuf[0] = byte(eventTypeBatch)\n+\tbinary.BigEndian.PutUint32(buf[1:5], uint32(len(batch)))\n+\tbinary.BigEndian.PutUint32(buf[5:9], uint32(requestID))\n+\n+\toffset := responseHeaderSize\n+\tfor _, evt := range batch {\n+\t\tencodeEvent(buf, offset, evt.eventType, evt.timestamp, evt.data, requestID)\n+\n+\t\toffset += responseHeaderSize + len(evt.data)\n+\t}\n+\n+\tif err := s.writeMessage(buf); err != nil {\n+\t\ts.logger.ErrorContext(s.ctx, \"failed to send event batch\",\n+\t\t\t\"session_id\", s.sessionID,\n+\t\t\t\"error\", err,\n+\t\t\t\"batch_size\", len(batch),\n+\t\t\t\"buffer_size\", totalSize)\n+\t}\n+}\n+\n+// sendError sends an error event to the client.\n+func (s *recordingPlayback) sendError(err error, requestID int) {\n+\ts.sendEvent(eventTypeError, 0, []byte(err.Error()), requestID)\n+}\n+\n+// sendCurrentScreen sends the current terminal screen state to the client.\n+func (s *recordingPlayback) sendCurrentScreen(requestID int, timestamp int64) {\n+\ts.terminal.Lock()\n+\tstate := s.terminal.vt.DumpState()\n+\tcols, rows := s.terminal.vt.Size()\n+\tcursor := s.terminal.vt.Cursor()\n+\ts.terminal.Unlock()\n+\n+\tdata := encodeScreenEvent(state, cols, rows, cursor)\n+\n+\ts.sendEvent(eventTypeScreen, timestamp, data, requestID)\n+}\n+\n+// encodeScreenEvent encodes the current terminal screen state into a byte slice.\n+func encodeScreenEvent(state vt10x.TerminalState, cols, rows int, cursor vt10x.Cursor) []byte {\n+\tdata := terminal.VtStateToANSI(state)\n+\n+\teventData := make([]byte, requestHeaderSize+len(data))\n+\teventData[0] = byte(eventTypeScreen)\n+\n+\tbinary.BigEndian.PutUint32(eventData[1:5], uint32(cols))\n+\tbinary.BigEndian.PutUint32(eventData[5:9], uint32(rows))\n+\tbinary.BigEndian.PutUint32(eventData[9:13], uint32(cursor.X))\n+\tbinary.BigEndian.PutUint32(eventData[13:17], uint32(cursor.Y))\n+\tbinary.BigEndian.PutUint32(eventData[17:21], uint32(len(data)))\n+\n+\tcopy(eventData[requestHeaderSize:], data)",
        "comment_created_at": "2025-08-26T17:02:53+00:00",
        "comment_author": "zmb3",
        "comment_body": "Minor nit: if `VtStateToANSI` accepted an `io.Writer` instead of making its own `bytes.Buffer`, then you could make the buffer here and pass it in, avoiding the extra copy and allocation.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2320297010",
    "pr_number": 58475,
    "pr_file": "lib/services/app.go",
    "created_at": "2025-09-03T21:43:52+00:00",
    "commented_code": "DeleteAllApps(context.Context) error\n }\n \n+// ValidateApp validates the Application resource.\n+func ValidateApp(app types.Application, proxyGetter ProxyGetter) error {\n+\t// Prevent routing conflicts and session hijacking by ensuring the application's public address\n+\t// does not match any of the proxy's public addresses. If both addresses are identical,\n+\t// requests intended for the proxy could be misrouted to the application, compromising security.\n+\tif app.GetPublicAddr() != \"\" {\n+\t\tproxyServers, err := proxyGetter.GetProxies()\n+\t\tif err != nil {\n+\t\t\treturn trace.Wrap(err)\n+\t\t}\n+\n+\t\tproxyAddrs := make([]string, 0, len(proxyServers))\n+\t\tfor _, proxyServer := range proxyServers {\n+\t\t\tproxyAddrs = append(proxyAddrs, proxyServer.GetPublicAddr())\n+\t\t}\n+\n+\t\tfor _, proxyAddr := range proxyAddrs {",
    "repo_full_name": "gravitational/teleport",
    "discussion_comments": [
      {
        "comment_id": "2320297010",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58475,
        "pr_file": "lib/services/app.go",
        "discussion_id": "2320297010",
        "commented_code": "@@ -64,6 +64,47 @@ type Applications interface {\n \tDeleteAllApps(context.Context) error\n }\n \n+// ValidateApp validates the Application resource.\n+func ValidateApp(app types.Application, proxyGetter ProxyGetter) error {\n+\t// Prevent routing conflicts and session hijacking by ensuring the application's public address\n+\t// does not match any of the proxy's public addresses. If both addresses are identical,\n+\t// requests intended for the proxy could be misrouted to the application, compromising security.\n+\tif app.GetPublicAddr() != \"\" {\n+\t\tproxyServers, err := proxyGetter.GetProxies()\n+\t\tif err != nil {\n+\t\t\treturn trace.Wrap(err)\n+\t\t}\n+\n+\t\tproxyAddrs := make([]string, 0, len(proxyServers))\n+\t\tfor _, proxyServer := range proxyServers {\n+\t\t\tproxyAddrs = append(proxyAddrs, proxyServer.GetPublicAddr())\n+\t\t}\n+\n+\t\tfor _, proxyAddr := range proxyAddrs {",
        "comment_created_at": "2025-09-03T21:43:52+00:00",
        "comment_author": "rosstimothy",
        "comment_body": "Do we need the intermediate slice?\n```suggestion\n\t\tfor _, proxyServer := range proxyServers {\n\t\t\tproxyAddr := proxyServer.GetPublicAddr()\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2322014191",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58475,
        "pr_file": "lib/services/app.go",
        "discussion_id": "2320297010",
        "commented_code": "@@ -64,6 +64,47 @@ type Applications interface {\n \tDeleteAllApps(context.Context) error\n }\n \n+// ValidateApp validates the Application resource.\n+func ValidateApp(app types.Application, proxyGetter ProxyGetter) error {\n+\t// Prevent routing conflicts and session hijacking by ensuring the application's public address\n+\t// does not match any of the proxy's public addresses. If both addresses are identical,\n+\t// requests intended for the proxy could be misrouted to the application, compromising security.\n+\tif app.GetPublicAddr() != \"\" {\n+\t\tproxyServers, err := proxyGetter.GetProxies()\n+\t\tif err != nil {\n+\t\t\treturn trace.Wrap(err)\n+\t\t}\n+\n+\t\tproxyAddrs := make([]string, 0, len(proxyServers))\n+\t\tfor _, proxyServer := range proxyServers {\n+\t\t\tproxyAddrs = append(proxyAddrs, proxyServer.GetPublicAddr())\n+\t\t}\n+\n+\t\tfor _, proxyAddr := range proxyAddrs {",
        "comment_created_at": "2025-09-04T12:50:02+00:00",
        "comment_author": "cthach",
        "comment_body": "Great catch. No idea how I missed that \ud83d\ude06 \r\n\r\nDone in https://github.com/gravitational/teleport/pull/58475/commits/0042a49d8597c116056a138c081c7909cd8926ad",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2299068229",
    "pr_number": 58187,
    "pr_file": "lib/srv/uacc/uacc.go",
    "created_at": "2025-08-25T20:31:48+00:00",
    "commented_code": "+/*\n+ * Teleport\n+ * Copyright (C) 2023  Gravitational, Inc.\n+ *\n+ * This program is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+\n+package uacc\n+\n+import (\n+\t\"net\"\n+\t\"os\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/gravitational/trace\"\n+)\n+\n+// UserAccountHandler handles user accounting across multiple backends.\n+type UserAccountHandler struct {\n+\tutmp   *UtmpBackend\n+\twtmpdb *WtmpdbBackend\n+}\n+\n+// UaccConfig configures NewUserAccounting.\n+type UaccConfig struct {\n+\t// WtmpdbFile is the path to an alternate wtmpdb database.\n+\tWtmpdbFile string\n+\t// UtmpFile is the path to an alternate utmp file.\n+\tUtmpFile string\n+\t// WtmpFile is the path to an alternate wtmp file.\n+\tWtmpFile string\n+\t// BtmpFile is the path to an alternate btmp file.\n+\tBtmpFile string\n+}\n+\n+// NewUserAccountHandler creates a new UserAccountHandler.\n+func NewUserAccountHandler(cfg UaccConfig) (*UserAccountHandler, error) {\n+\tuacc := &UserAccountHandler{}\n+\tutmp, err := NewUtmpBackend(cfg.UtmpFile, cfg.WtmpFile, cfg.BtmpFile)\n+\tif err == nil {\n+\t\tuacc.utmp = utmp\n+\t}\n+\twtmpdb, err := NewWtmpdbBackend(cfg.WtmpdbFile)\n+\tif err == nil {\n+\t\tuacc.wtmpdb = wtmpdb\n+\t}\n+\tif uacc.utmp == nil && uacc.wtmpdb == nil {\n+\t\treturn nil, trace.BadParameter(\"no valid backends available\")\n+\t}\n+\treturn uacc, nil\n+}\n+\n+// Session represents a login session. It must be closed when the session is finished.\n+type Session struct {\n+\tuacc      *UserAccountHandler\n+\tutmpKey   string\n+\twtmpdbKey *int64\n+}\n+\n+// OpenSession opens a new login session. It will succeed if at least one backend succeeds.\n+func (uacc *UserAccountHandler) OpenSession(tty *os.File, username string, remote net.Addr) (*Session, error) {\n+\tloginTime := time.Now()\n+\tttyFullName, err := os.Readlink(tty.Name())\n+\tif err != nil {\n+\t\treturn nil, trace.Wrap(err)\n+\t}\n+\tttyName := strings.TrimPrefix(ttyFullName, \"/dev/\")\n+\n+\tvar anySucceeded bool\n+\tsession := &Session{\n+\t\tuacc: uacc,\n+\t}\n+\terrors := make([]error, 0, 2)",
    "repo_full_name": "gravitational/teleport",
    "discussion_comments": [
      {
        "comment_id": "2299068229",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58187,
        "pr_file": "lib/srv/uacc/uacc.go",
        "discussion_id": "2299068229",
        "commented_code": "@@ -0,0 +1,151 @@\n+/*\n+ * Teleport\n+ * Copyright (C) 2023  Gravitational, Inc.\n+ *\n+ * This program is free software: you can redistribute it and/or modify\n+ * it under the terms of the GNU Affero General Public License as published by\n+ * the Free Software Foundation, either version 3 of the License, or\n+ * (at your option) any later version.\n+ *\n+ * This program is distributed in the hope that it will be useful,\n+ * but WITHOUT ANY WARRANTY; without even the implied warranty of\n+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n+ * GNU Affero General Public License for more details.\n+ *\n+ * You should have received a copy of the GNU Affero General Public License\n+ * along with this program.  If not, see <http://www.gnu.org/licenses/>.\n+ */\n+\n+package uacc\n+\n+import (\n+\t\"net\"\n+\t\"os\"\n+\t\"strings\"\n+\t\"time\"\n+\n+\t\"github.com/gravitational/trace\"\n+)\n+\n+// UserAccountHandler handles user accounting across multiple backends.\n+type UserAccountHandler struct {\n+\tutmp   *UtmpBackend\n+\twtmpdb *WtmpdbBackend\n+}\n+\n+// UaccConfig configures NewUserAccounting.\n+type UaccConfig struct {\n+\t// WtmpdbFile is the path to an alternate wtmpdb database.\n+\tWtmpdbFile string\n+\t// UtmpFile is the path to an alternate utmp file.\n+\tUtmpFile string\n+\t// WtmpFile is the path to an alternate wtmp file.\n+\tWtmpFile string\n+\t// BtmpFile is the path to an alternate btmp file.\n+\tBtmpFile string\n+}\n+\n+// NewUserAccountHandler creates a new UserAccountHandler.\n+func NewUserAccountHandler(cfg UaccConfig) (*UserAccountHandler, error) {\n+\tuacc := &UserAccountHandler{}\n+\tutmp, err := NewUtmpBackend(cfg.UtmpFile, cfg.WtmpFile, cfg.BtmpFile)\n+\tif err == nil {\n+\t\tuacc.utmp = utmp\n+\t}\n+\twtmpdb, err := NewWtmpdbBackend(cfg.WtmpdbFile)\n+\tif err == nil {\n+\t\tuacc.wtmpdb = wtmpdb\n+\t}\n+\tif uacc.utmp == nil && uacc.wtmpdb == nil {\n+\t\treturn nil, trace.BadParameter(\"no valid backends available\")\n+\t}\n+\treturn uacc, nil\n+}\n+\n+// Session represents a login session. It must be closed when the session is finished.\n+type Session struct {\n+\tuacc      *UserAccountHandler\n+\tutmpKey   string\n+\twtmpdbKey *int64\n+}\n+\n+// OpenSession opens a new login session. It will succeed if at least one backend succeeds.\n+func (uacc *UserAccountHandler) OpenSession(tty *os.File, username string, remote net.Addr) (*Session, error) {\n+\tloginTime := time.Now()\n+\tttyFullName, err := os.Readlink(tty.Name())\n+\tif err != nil {\n+\t\treturn nil, trace.Wrap(err)\n+\t}\n+\tttyName := strings.TrimPrefix(ttyFullName, \"/dev/\")\n+\n+\tvar anySucceeded bool\n+\tsession := &Session{\n+\t\tuacc: uacc,\n+\t}\n+\terrors := make([]error, 0, 2)",
        "comment_created_at": "2025-08-25T20:31:48+00:00",
        "comment_author": "rosstimothy",
        "comment_body": "I don't know that we should be preallocating these. This results in allocations for slices which should never have any items in the happy path of most user sessions.\r\n```suggestion\r\n\tvar errors []error\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2314521977",
    "pr_number": 58525,
    "pr_file": "lib/healthcheck/manager.go",
    "created_at": "2025-09-01T19:59:13+00:00",
    "commented_code": "}\n \treturn nil\n }\n+\n+// startMetricUpdater starts a goroutine for updating health check metrics.\n+func (m *manager) startMetricUpdater(ctx context.Context) error {\n+\tvar metricType string\n+\tswitch m.cfg.Component {\n+\tcase teleport.ComponentDatabase:\n+\t\tmetricType = teleport.MetricResourceDB\n+\tcase teleport.ComponentKube:\n+\t\tmetricType = teleport.MetricResourceKubernetes\n+\tdefault:\n+\t\treturn fmt.Errorf(\"unsupported component %q\", m.cfg.Component)\n+\t}\n+\tmetricInterval := interval.New(interval.Config{\n+\t\tDuration:      defaults.HealthCheckInterval,\n+\t\tJitter:        retryutils.SeventhJitter,\n+\t\tFirstDuration: retryutils.HalfJitter(defaults.HealthCheckInterval),\n+\t\tClock:         m.cfg.Clock,\n+\t})\n+\tgo func() {\n+\t\tdefer func() {\n+\t\t\tmetricInterval.Stop()\n+\t\t\t// Reset metrics to zero on exit.\n+\t\t\tresourceHealthyGauge.WithLabelValues(metricType).Set(0.0)\n+\t\t\tresourceUnhealthyGauge.WithLabelValues(metricType).Set(0.0)\n+\t\t\tresourceUnknownGauge.WithLabelValues(metricType).Set(0.0)\n+\t\t}()\n+\t\tprvSums := map[types.TargetHealthStatus]int{\n+\t\t\ttypes.TargetHealthStatusHealthy:   0,\n+\t\t\ttypes.TargetHealthStatusUnhealthy: 0,\n+\t\t\ttypes.TargetHealthStatusUnknown:   0,\n+\t\t}\n+\t\tcurSums := map[types.TargetHealthStatus]int{\n+\t\t\ttypes.TargetHealthStatusHealthy:   0,\n+\t\t\ttypes.TargetHealthStatusUnhealthy: 0,\n+\t\t\ttypes.TargetHealthStatusUnknown:   0,\n+\t\t}\n+\t\tfor {\n+\t\t\tselect {\n+\t\t\tcase <-metricInterval.Next():\n+\t\t\t\tm.updateMetrics(ctx, metricType, prvSums, curSums)\n+\t\t\t\tprvSums, curSums = curSums, prvSums",
    "repo_full_name": "gravitational/teleport",
    "discussion_comments": [
      {
        "comment_id": "2314521977",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58525,
        "pr_file": "lib/healthcheck/manager.go",
        "discussion_id": "2314521977",
        "commented_code": "@@ -347,3 +354,132 @@ func (m *manager) getConfigLocked(ctx context.Context, r types.ResourceWithLabel\n \t}\n \treturn nil\n }\n+\n+// startMetricUpdater starts a goroutine for updating health check metrics.\n+func (m *manager) startMetricUpdater(ctx context.Context) error {\n+\tvar metricType string\n+\tswitch m.cfg.Component {\n+\tcase teleport.ComponentDatabase:\n+\t\tmetricType = teleport.MetricResourceDB\n+\tcase teleport.ComponentKube:\n+\t\tmetricType = teleport.MetricResourceKubernetes\n+\tdefault:\n+\t\treturn fmt.Errorf(\"unsupported component %q\", m.cfg.Component)\n+\t}\n+\tmetricInterval := interval.New(interval.Config{\n+\t\tDuration:      defaults.HealthCheckInterval,\n+\t\tJitter:        retryutils.SeventhJitter,\n+\t\tFirstDuration: retryutils.HalfJitter(defaults.HealthCheckInterval),\n+\t\tClock:         m.cfg.Clock,\n+\t})\n+\tgo func() {\n+\t\tdefer func() {\n+\t\t\tmetricInterval.Stop()\n+\t\t\t// Reset metrics to zero on exit.\n+\t\t\tresourceHealthyGauge.WithLabelValues(metricType).Set(0.0)\n+\t\t\tresourceUnhealthyGauge.WithLabelValues(metricType).Set(0.0)\n+\t\t\tresourceUnknownGauge.WithLabelValues(metricType).Set(0.0)\n+\t\t}()\n+\t\tprvSums := map[types.TargetHealthStatus]int{\n+\t\t\ttypes.TargetHealthStatusHealthy:   0,\n+\t\t\ttypes.TargetHealthStatusUnhealthy: 0,\n+\t\t\ttypes.TargetHealthStatusUnknown:   0,\n+\t\t}\n+\t\tcurSums := map[types.TargetHealthStatus]int{\n+\t\t\ttypes.TargetHealthStatusHealthy:   0,\n+\t\t\ttypes.TargetHealthStatusUnhealthy: 0,\n+\t\t\ttypes.TargetHealthStatusUnknown:   0,\n+\t\t}\n+\t\tfor {\n+\t\t\tselect {\n+\t\t\tcase <-metricInterval.Next():\n+\t\t\t\tm.updateMetrics(ctx, metricType, prvSums, curSums)\n+\t\t\t\tprvSums, curSums = curSums, prvSums",
        "comment_created_at": "2025-09-01T19:59:13+00:00",
        "comment_author": "GavinFrazar",
        "comment_body": "I assume this is to avoid allocating a new map? It's strange to swap cur/prev, but after reading updateMetrics I see that curSums just gets zero'd out.",
        "pr_file_module": null
      },
      {
        "comment_id": "2316693924",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58525,
        "pr_file": "lib/healthcheck/manager.go",
        "discussion_id": "2314521977",
        "commented_code": "@@ -347,3 +354,132 @@ func (m *manager) getConfigLocked(ctx context.Context, r types.ResourceWithLabel\n \t}\n \treturn nil\n }\n+\n+// startMetricUpdater starts a goroutine for updating health check metrics.\n+func (m *manager) startMetricUpdater(ctx context.Context) error {\n+\tvar metricType string\n+\tswitch m.cfg.Component {\n+\tcase teleport.ComponentDatabase:\n+\t\tmetricType = teleport.MetricResourceDB\n+\tcase teleport.ComponentKube:\n+\t\tmetricType = teleport.MetricResourceKubernetes\n+\tdefault:\n+\t\treturn fmt.Errorf(\"unsupported component %q\", m.cfg.Component)\n+\t}\n+\tmetricInterval := interval.New(interval.Config{\n+\t\tDuration:      defaults.HealthCheckInterval,\n+\t\tJitter:        retryutils.SeventhJitter,\n+\t\tFirstDuration: retryutils.HalfJitter(defaults.HealthCheckInterval),\n+\t\tClock:         m.cfg.Clock,\n+\t})\n+\tgo func() {\n+\t\tdefer func() {\n+\t\t\tmetricInterval.Stop()\n+\t\t\t// Reset metrics to zero on exit.\n+\t\t\tresourceHealthyGauge.WithLabelValues(metricType).Set(0.0)\n+\t\t\tresourceUnhealthyGauge.WithLabelValues(metricType).Set(0.0)\n+\t\t\tresourceUnknownGauge.WithLabelValues(metricType).Set(0.0)\n+\t\t}()\n+\t\tprvSums := map[types.TargetHealthStatus]int{\n+\t\t\ttypes.TargetHealthStatusHealthy:   0,\n+\t\t\ttypes.TargetHealthStatusUnhealthy: 0,\n+\t\t\ttypes.TargetHealthStatusUnknown:   0,\n+\t\t}\n+\t\tcurSums := map[types.TargetHealthStatus]int{\n+\t\t\ttypes.TargetHealthStatusHealthy:   0,\n+\t\t\ttypes.TargetHealthStatusUnhealthy: 0,\n+\t\t\ttypes.TargetHealthStatusUnknown:   0,\n+\t\t}\n+\t\tfor {\n+\t\t\tselect {\n+\t\t\tcase <-metricInterval.Next():\n+\t\t\t\tm.updateMetrics(ctx, metricType, prvSums, curSums)\n+\t\t\t\tprvSums, curSums = curSums, prvSums",
        "comment_created_at": "2025-09-02T17:10:20+00:00",
        "comment_author": "rana",
        "comment_body": "Yes, the map swapping is to avoid allocating new maps. The two maps exist to detect when actual changes need to be communicated to Prometheus.\r\n\r\nThe swapping isn't immediately clear until reading `updateMetrics`. The alternative would be to move `updateMetrics` into `startMetricUpdater`, but would make `startMetricUpdater` less readable.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2298979124",
    "pr_number": 58323,
    "pr_file": "lib/cache/access_list.go",
    "created_at": "2025-08-25T19:48:46+00:00",
    "commented_code": "type accessListIndex string\n \n-const accessListNameIndex accessListIndex = \"name\"\n+const (\n+\taccessListNameIndex          accessListIndex = \"name\"\n+\taccessListAuditNextDateIndex accessListIndex = \"auditNextDate\"\n+)\n+\n+func accessListNameIndexFn(al *accesslist.AccessList) string {\n+\treturn al.GetMetadata().Name\n+}\n+\n+func accessListAuditNextDateIndexFn(al *accesslist.AccessList) string {\n+\treturn fmt.Sprintf(\"%s/%s\", al.Spec.Audit.NextAuditDate.Format(time.RFC3339), al.GetMetadata().Name)",
    "repo_full_name": "gravitational/teleport",
    "discussion_comments": [
      {
        "comment_id": "2298979124",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58323,
        "pr_file": "lib/cache/access_list.go",
        "discussion_id": "2298979124",
        "commented_code": "@@ -34,7 +36,18 @@ import (\n \n type accessListIndex string\n \n-const accessListNameIndex accessListIndex = \"name\"\n+const (\n+\taccessListNameIndex          accessListIndex = \"name\"\n+\taccessListAuditNextDateIndex accessListIndex = \"auditNextDate\"\n+)\n+\n+func accessListNameIndexFn(al *accesslist.AccessList) string {\n+\treturn al.GetMetadata().Name\n+}\n+\n+func accessListAuditNextDateIndexFn(al *accesslist.AccessList) string {\n+\treturn fmt.Sprintf(\"%s/%s\", al.Spec.Audit.NextAuditDate.Format(time.RFC3339), al.GetMetadata().Name)",
        "comment_created_at": "2025-08-25T19:48:46+00:00",
        "comment_author": "smallinsky",
        "comment_body": "We probably should avoid `fmt.Sprintf( call in the index func especially knowing that we  will have 50k items in this collection. \r\n\r\n```suggestion\r\n    if l.Spec.Audit.NextAuditDate.IsZero() {\r\n      return \"z\"  +\"/\"+ name // last lexical char make sure that if ACL don't have aduit date ti will be in the end. Otherwise we will compare agains `0001-01-01 00:00:00` that lexical is first element but means that access list is not eligible for review.   \r\n    }\r\n\treturn al.Spec.Audit.NextAuditDate.Format(\"20060102\") + \"/\" +  al.GetMetadata().GetName()\r\n```\r\n\r\n The NextAuditDate can be zero so we need to make sure that it will be and the end of the collection.\r\n Also `20060102` time format (per day grouping) seems to be good enough precision for review\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2299499462",
        "repo_full_name": "gravitational/teleport",
        "pr_number": 58323,
        "pr_file": "lib/cache/access_list.go",
        "discussion_id": "2298979124",
        "commented_code": "@@ -34,7 +36,18 @@ import (\n \n type accessListIndex string\n \n-const accessListNameIndex accessListIndex = \"name\"\n+const (\n+\taccessListNameIndex          accessListIndex = \"name\"\n+\taccessListAuditNextDateIndex accessListIndex = \"auditNextDate\"\n+)\n+\n+func accessListNameIndexFn(al *accesslist.AccessList) string {\n+\treturn al.GetMetadata().Name\n+}\n+\n+func accessListAuditNextDateIndexFn(al *accesslist.AccessList) string {\n+\treturn fmt.Sprintf(\"%s/%s\", al.Spec.Audit.NextAuditDate.Format(time.RFC3339), al.GetMetadata().Name)",
        "comment_created_at": "2025-08-26T01:31:50+00:00",
        "comment_author": "avatus",
        "comment_body": "good callout. i didnt know the performance hits for `fmt.Sprintf`. ",
        "pr_file_module": null
      }
    ]
  }
]