[
  {
    "discussion_id": "1340457293",
    "pr_number": 60161,
    "pr_file": "ci/official/envs/continuous_linux_x86_cpu_py310",
    "created_at": "2023-09-28T17:15:21+00:00",
    "commented_code": null,
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1340457293",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 60161,
        "pr_file": "ci/official/envs/continuous_linux_x86_cpu_py310",
        "discussion_id": "1340457293",
        "commented_code": null,
        "comment_created_at": "2023-09-28T17:15:21+00:00",
        "comment_author": "MichaelHudgins",
        "comment_body": "You can update in only a single place within the root .bazelrc instead of in each env if this is needed in either all release configs or all linux release configs by adding to release_base or release_cpu_linux respectively. ",
        "pr_file_module": null
      },
      {
        "comment_id": "1340458334",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 60161,
        "pr_file": "ci/official/envs/continuous_linux_x86_cpu_py310",
        "discussion_id": "1340457293",
        "commented_code": null,
        "comment_created_at": "2023-09-28T17:16:26+00:00",
        "comment_author": "MichaelHudgins",
        "comment_body": "Also side note, those envs are currently not used by the prod jobs.  We will be switching to them in the near future though.  Adding to the root .bazelrc will catch both the older and newer ci jobs. ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1930178233",
    "pr_number": 84975,
    "pr_file": "third_party/mkl_dnn/mkldnn_acl.BUILD",
    "created_at": "2025-01-27T09:03:20+00:00",
    "commented_code": "\"#cmakedefine01 BUILD_XEHPG\": \"#define BUILD_XEHPG 0\",\n     \"#cmakedefine01 BUILD_XEHPC\": \"#define BUILD_XEHPC 0\",\n     \"#cmakedefine01 BUILD_XEHP\": \"#define BUILD_XEHP 0\",\n+    \"#cmakedefine01 BUILD_GROUP_NORMALIZATION\": \"#define BUILD_GROUP_NORMALIZATION 0\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_ALL\": \"#define BUILD_GEMM_KERNELS_ALL 1\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_NONE\": \"#define BUILD_GEMM_KERNELS_NONE 0\",\n+    \"#cmakedefine01 BUILD_GEMM_SSE41\": \"#define BUILD_GEMM_SSE41 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX2\": \"#define BUILD_GEMM_AVX2 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX512\": \"#define BUILD_GEMM_AVX512 0\",\n+    \"#cmakedefine DNNL_GPU_VENDOR\": \"#define DNNL_GPU_VENDOR INTEL\",\n+    \"#cmakedefine DNNL_SYCL_GENERIC\": \"#undef DNNL_SYCL_GENERIC\",\n+    \"#cmakedefine DNNL_DISABLE_GPU_REF_KERNELS\": \"#undef DNNL_DISABLE_GPU_REF_KERNELS\",\n+    \"#cmakedefine01 BUILD_SDPA\": \"#define BUILD_SDPA 0\",\n+    \"#cmakedefine01 BUILD_XE2\": \"#define BUILD_XE2 0\",",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1930178233",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 84975,
        "pr_file": "third_party/mkl_dnn/mkldnn_acl.BUILD",
        "discussion_id": "1930178233",
        "commented_code": "@@ -111,6 +123,17 @@ _DNNL_RUNTIME_OMP = {\n     \"#cmakedefine01 BUILD_XEHPG\": \"#define BUILD_XEHPG 0\",\n     \"#cmakedefine01 BUILD_XEHPC\": \"#define BUILD_XEHPC 0\",\n     \"#cmakedefine01 BUILD_XEHP\": \"#define BUILD_XEHP 0\",\n+    \"#cmakedefine01 BUILD_GROUP_NORMALIZATION\": \"#define BUILD_GROUP_NORMALIZATION 0\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_ALL\": \"#define BUILD_GEMM_KERNELS_ALL 1\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_NONE\": \"#define BUILD_GEMM_KERNELS_NONE 0\",\n+    \"#cmakedefine01 BUILD_GEMM_SSE41\": \"#define BUILD_GEMM_SSE41 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX2\": \"#define BUILD_GEMM_AVX2 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX512\": \"#define BUILD_GEMM_AVX512 0\",\n+    \"#cmakedefine DNNL_GPU_VENDOR\": \"#define DNNL_GPU_VENDOR INTEL\",\n+    \"#cmakedefine DNNL_SYCL_GENERIC\": \"#undef DNNL_SYCL_GENERIC\",\n+    \"#cmakedefine DNNL_DISABLE_GPU_REF_KERNELS\": \"#undef DNNL_DISABLE_GPU_REF_KERNELS\",\n+    \"#cmakedefine01 BUILD_SDPA\": \"#define BUILD_SDPA 0\",\n+    \"#cmakedefine01 BUILD_XE2\": \"#define BUILD_XE2 0\",",
        "comment_created_at": "2025-01-27T09:03:20+00:00",
        "comment_author": "penpornk",
        "comment_body": "Let's avoid having to update same things in two places (`_DNNL_RUNTIME_THREADPOOL` and `_DNNL_RUNTIME_OMP`). Could you please refactor common options to `_CMAKE_COMMON_LIST` like in `mkldnn_v1.BUILD`?\r\nhttps://github.com/tensorflow/tensorflow/blob/a944fd9a5abd82db10ea633c235228fe59f14199/third_party/mkl_dnn/mkldnn_v1.BUILD#L7-L73",
        "pr_file_module": null
      },
      {
        "comment_id": "1937459238",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 84975,
        "pr_file": "third_party/mkl_dnn/mkldnn_acl.BUILD",
        "discussion_id": "1930178233",
        "commented_code": "@@ -111,6 +123,17 @@ _DNNL_RUNTIME_OMP = {\n     \"#cmakedefine01 BUILD_XEHPG\": \"#define BUILD_XEHPG 0\",\n     \"#cmakedefine01 BUILD_XEHPC\": \"#define BUILD_XEHPC 0\",\n     \"#cmakedefine01 BUILD_XEHP\": \"#define BUILD_XEHP 0\",\n+    \"#cmakedefine01 BUILD_GROUP_NORMALIZATION\": \"#define BUILD_GROUP_NORMALIZATION 0\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_ALL\": \"#define BUILD_GEMM_KERNELS_ALL 1\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_NONE\": \"#define BUILD_GEMM_KERNELS_NONE 0\",\n+    \"#cmakedefine01 BUILD_GEMM_SSE41\": \"#define BUILD_GEMM_SSE41 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX2\": \"#define BUILD_GEMM_AVX2 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX512\": \"#define BUILD_GEMM_AVX512 0\",\n+    \"#cmakedefine DNNL_GPU_VENDOR\": \"#define DNNL_GPU_VENDOR INTEL\",\n+    \"#cmakedefine DNNL_SYCL_GENERIC\": \"#undef DNNL_SYCL_GENERIC\",\n+    \"#cmakedefine DNNL_DISABLE_GPU_REF_KERNELS\": \"#undef DNNL_DISABLE_GPU_REF_KERNELS\",\n+    \"#cmakedefine01 BUILD_SDPA\": \"#define BUILD_SDPA 0\",\n+    \"#cmakedefine01 BUILD_XE2\": \"#define BUILD_XE2 0\",",
        "comment_created_at": "2025-01-31T15:06:43+00:00",
        "comment_author": "Sqvid",
        "comment_body": "We do not actually support the OMP build of TF on aarch64 anymore. So I might go ahead and just delete the OMP list.",
        "pr_file_module": null
      },
      {
        "comment_id": "1937495095",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 84975,
        "pr_file": "third_party/mkl_dnn/mkldnn_acl.BUILD",
        "discussion_id": "1930178233",
        "commented_code": "@@ -111,6 +123,17 @@ _DNNL_RUNTIME_OMP = {\n     \"#cmakedefine01 BUILD_XEHPG\": \"#define BUILD_XEHPG 0\",\n     \"#cmakedefine01 BUILD_XEHPC\": \"#define BUILD_XEHPC 0\",\n     \"#cmakedefine01 BUILD_XEHP\": \"#define BUILD_XEHP 0\",\n+    \"#cmakedefine01 BUILD_GROUP_NORMALIZATION\": \"#define BUILD_GROUP_NORMALIZATION 0\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_ALL\": \"#define BUILD_GEMM_KERNELS_ALL 1\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_NONE\": \"#define BUILD_GEMM_KERNELS_NONE 0\",\n+    \"#cmakedefine01 BUILD_GEMM_SSE41\": \"#define BUILD_GEMM_SSE41 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX2\": \"#define BUILD_GEMM_AVX2 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX512\": \"#define BUILD_GEMM_AVX512 0\",\n+    \"#cmakedefine DNNL_GPU_VENDOR\": \"#define DNNL_GPU_VENDOR INTEL\",\n+    \"#cmakedefine DNNL_SYCL_GENERIC\": \"#undef DNNL_SYCL_GENERIC\",\n+    \"#cmakedefine DNNL_DISABLE_GPU_REF_KERNELS\": \"#undef DNNL_DISABLE_GPU_REF_KERNELS\",\n+    \"#cmakedefine01 BUILD_SDPA\": \"#define BUILD_SDPA 0\",\n+    \"#cmakedefine01 BUILD_XE2\": \"#define BUILD_XE2 0\",",
        "comment_created_at": "2025-01-31T15:30:06+00:00",
        "comment_author": "penpornk",
        "comment_body": "Deleting the OMP list sounds good too.",
        "pr_file_module": null
      },
      {
        "comment_id": "1944686922",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 84975,
        "pr_file": "third_party/mkl_dnn/mkldnn_acl.BUILD",
        "discussion_id": "1930178233",
        "commented_code": "@@ -111,6 +123,17 @@ _DNNL_RUNTIME_OMP = {\n     \"#cmakedefine01 BUILD_XEHPG\": \"#define BUILD_XEHPG 0\",\n     \"#cmakedefine01 BUILD_XEHPC\": \"#define BUILD_XEHPC 0\",\n     \"#cmakedefine01 BUILD_XEHP\": \"#define BUILD_XEHP 0\",\n+    \"#cmakedefine01 BUILD_GROUP_NORMALIZATION\": \"#define BUILD_GROUP_NORMALIZATION 0\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_ALL\": \"#define BUILD_GEMM_KERNELS_ALL 1\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_NONE\": \"#define BUILD_GEMM_KERNELS_NONE 0\",\n+    \"#cmakedefine01 BUILD_GEMM_SSE41\": \"#define BUILD_GEMM_SSE41 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX2\": \"#define BUILD_GEMM_AVX2 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX512\": \"#define BUILD_GEMM_AVX512 0\",\n+    \"#cmakedefine DNNL_GPU_VENDOR\": \"#define DNNL_GPU_VENDOR INTEL\",\n+    \"#cmakedefine DNNL_SYCL_GENERIC\": \"#undef DNNL_SYCL_GENERIC\",\n+    \"#cmakedefine DNNL_DISABLE_GPU_REF_KERNELS\": \"#undef DNNL_DISABLE_GPU_REF_KERNELS\",\n+    \"#cmakedefine01 BUILD_SDPA\": \"#define BUILD_SDPA 0\",\n+    \"#cmakedefine01 BUILD_XE2\": \"#define BUILD_XE2 0\",",
        "comment_created_at": "2025-02-06T13:03:06+00:00",
        "comment_author": "Sqvid",
        "comment_body": "Have removed OMP builds for this platform: [link](https://github.com/tensorflow/tensorflow/pull/84975/commits/4007b6f5974e41d5f0105e98a86c319f82bae5fe#diff-544556920c45b42cbfe40159b082ce8af6bd929e492d076769226265f215832f)",
        "pr_file_module": null
      },
      {
        "comment_id": "1944691147",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 84975,
        "pr_file": "third_party/mkl_dnn/mkldnn_acl.BUILD",
        "discussion_id": "1930178233",
        "commented_code": "@@ -111,6 +123,17 @@ _DNNL_RUNTIME_OMP = {\n     \"#cmakedefine01 BUILD_XEHPG\": \"#define BUILD_XEHPG 0\",\n     \"#cmakedefine01 BUILD_XEHPC\": \"#define BUILD_XEHPC 0\",\n     \"#cmakedefine01 BUILD_XEHP\": \"#define BUILD_XEHP 0\",\n+    \"#cmakedefine01 BUILD_GROUP_NORMALIZATION\": \"#define BUILD_GROUP_NORMALIZATION 0\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_ALL\": \"#define BUILD_GEMM_KERNELS_ALL 1\",\n+    \"#cmakedefine01 BUILD_GEMM_KERNELS_NONE\": \"#define BUILD_GEMM_KERNELS_NONE 0\",\n+    \"#cmakedefine01 BUILD_GEMM_SSE41\": \"#define BUILD_GEMM_SSE41 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX2\": \"#define BUILD_GEMM_AVX2 0\",\n+    \"#cmakedefine01 BUILD_GEMM_AVX512\": \"#define BUILD_GEMM_AVX512 0\",\n+    \"#cmakedefine DNNL_GPU_VENDOR\": \"#define DNNL_GPU_VENDOR INTEL\",\n+    \"#cmakedefine DNNL_SYCL_GENERIC\": \"#undef DNNL_SYCL_GENERIC\",\n+    \"#cmakedefine DNNL_DISABLE_GPU_REF_KERNELS\": \"#undef DNNL_DISABLE_GPU_REF_KERNELS\",\n+    \"#cmakedefine01 BUILD_SDPA\": \"#define BUILD_SDPA 0\",\n+    \"#cmakedefine01 BUILD_XE2\": \"#define BUILD_XE2 0\",",
        "comment_created_at": "2025-02-06T13:06:17+00:00",
        "comment_author": "Sqvid",
        "comment_body": "@penpornk As a result of removing OMP support (the `mkl_aarch64` build is now an alias for `mkl_aarch64_threadpool`) I suspect [your patch](https://github.com/tensorflow/tensorflow/pull/84975/files#diff-340c9a27dd3b532e0caeb7ecfdcaaf22eb410e0ca8b5875972dfc2654320b981) is no longer necessary, and I have therefore deleted it. Could you please confirm if this is assumption is correct?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1702194860",
    "pr_number": 66633,
    "pr_file": "tensorflow/tools/pip_package/utils/tf_wheel.bzl",
    "created_at": "2024-08-02T18:39:09+00:00",
    "commented_code": "6) `--xla_aot` - paths to files that should be in xla_aot directory. \n \"\"\"\n \n-load(\"@python_version_repo//:py_version.bzl\", \"WHEEL_COLLAB\", \"WHEEL_NAME\")\n+load(\"@python_version_repo//:py_version.bzl\", \"WHEEL_COLLAB\", \"WHEEL_NAME\", \"OUTPUT_PATH\")\n load(\"//tensorflow:tensorflow.bzl\", \"VERSION\")\n \n def _tf_wheel_impl(ctx):\n     executable = ctx.executable.wheel_binary\n \n     output = ctx.actions.declare_directory(\"wheel_house\")\n+    output_path = OUTPUT_PATH if OUTPUT_PATH else output.path\n     args = ctx.actions.args()\n     args.add(\"--project-name\", WHEEL_NAME)\n     args.add(\"--collab\", str(WHEEL_COLLAB))\n-    args.add(\"--output-name\", output.path)\n+    args.add(\"--output-name\", output_path)",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1702194860",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 66633,
        "pr_file": "tensorflow/tools/pip_package/utils/tf_wheel.bzl",
        "discussion_id": "1702194860",
        "commented_code": "@@ -23,17 +23,18 @@ Should be set via --repo_env=WHEEL_NAME=tensorflow_cpu.\n 6) `--xla_aot` - paths to files that should be in xla_aot directory. \n \"\"\"\n \n-load(\"@python_version_repo//:py_version.bzl\", \"WHEEL_COLLAB\", \"WHEEL_NAME\")\n+load(\"@python_version_repo//:py_version.bzl\", \"WHEEL_COLLAB\", \"WHEEL_NAME\", \"OUTPUT_PATH\")\n load(\"//tensorflow:tensorflow.bzl\", \"VERSION\")\n \n def _tf_wheel_impl(ctx):\n     executable = ctx.executable.wheel_binary\n \n     output = ctx.actions.declare_directory(\"wheel_house\")\n+    output_path = OUTPUT_PATH if OUTPUT_PATH else output.path\n     args = ctx.actions.args()\n     args.add(\"--project-name\", WHEEL_NAME)\n     args.add(\"--collab\", str(WHEEL_COLLAB))\n-    args.add(\"--output-name\", output.path)\n+    args.add(\"--output-name\", output_path)",
        "comment_created_at": "2024-08-02T18:39:09+00:00",
        "comment_author": "vam-google",
        "comment_body": "To the best of my understanding this should make action on line 56 fail, because it declares that it outputs a directory (on line 59) which it would not actually create if output_path is chosen instead of output.path on line 33.\r\n\r\nAlso, this attempts to use a rule in a non-conventional way, exactly what we were trying to prevent by introducing this rule - the wheel must be created under bazel's cache, not under some random directory on file system.\r\n\r\nSorry, we can't let this PR in. If you need a wheel to be created in a different directory, you should add a simple post-build script which will simply copy it there. Please do not attempt to do it in the rule itself.\r\n\r\nProbably it would be helpful to explain why passing WHEEL_NAME as an env var is ok-ish (tough I don't like it too, tbh), and passing OUTPUT_PATH is not ok. Wheel name selects only the name of resultant files, but regardless what the names they all of them will be placed under bazel's cache keeping things hermetic. In case of OUTPUT_PATH now it can put stuff outside of the cache in random location breaking hermeticity. Also, to the best of my understanding it should simply not work, because action on 56 should complain that the requested directory \"wheel_house\" was not actually created (if it doesn't then it is some bug in the original rule).",
        "pr_file_module": null
      },
      {
        "comment_id": "1702286067",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 66633,
        "pr_file": "tensorflow/tools/pip_package/utils/tf_wheel.bzl",
        "discussion_id": "1702194860",
        "commented_code": "@@ -23,17 +23,18 @@ Should be set via --repo_env=WHEEL_NAME=tensorflow_cpu.\n 6) `--xla_aot` - paths to files that should be in xla_aot directory. \n \"\"\"\n \n-load(\"@python_version_repo//:py_version.bzl\", \"WHEEL_COLLAB\", \"WHEEL_NAME\")\n+load(\"@python_version_repo//:py_version.bzl\", \"WHEEL_COLLAB\", \"WHEEL_NAME\", \"OUTPUT_PATH\")\n load(\"//tensorflow:tensorflow.bzl\", \"VERSION\")\n \n def _tf_wheel_impl(ctx):\n     executable = ctx.executable.wheel_binary\n \n     output = ctx.actions.declare_directory(\"wheel_house\")\n+    output_path = OUTPUT_PATH if OUTPUT_PATH else output.path\n     args = ctx.actions.args()\n     args.add(\"--project-name\", WHEEL_NAME)\n     args.add(\"--collab\", str(WHEEL_COLLAB))\n-    args.add(\"--output-name\", output.path)\n+    args.add(\"--output-name\", output_path)",
        "comment_created_at": "2024-08-02T20:22:11+00:00",
        "comment_author": "hsharsha",
        "comment_body": "Should hermeticity apply to the output artifacts as well? \r\nThe main reason for introducing this was the wheel location within bazel cache was changing quite often and the post copying script needed to change accordingly.\r\nSecondly, when using docker containers to build tf wheels, we cannot access the symblic link to bazel cache within container.",
        "pr_file_module": null
      },
      {
        "comment_id": "1702360431",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 66633,
        "pr_file": "tensorflow/tools/pip_package/utils/tf_wheel.bzl",
        "discussion_id": "1702194860",
        "commented_code": "@@ -23,17 +23,18 @@ Should be set via --repo_env=WHEEL_NAME=tensorflow_cpu.\n 6) `--xla_aot` - paths to files that should be in xla_aot directory. \n \"\"\"\n \n-load(\"@python_version_repo//:py_version.bzl\", \"WHEEL_COLLAB\", \"WHEEL_NAME\")\n+load(\"@python_version_repo//:py_version.bzl\", \"WHEEL_COLLAB\", \"WHEEL_NAME\", \"OUTPUT_PATH\")\n load(\"//tensorflow:tensorflow.bzl\", \"VERSION\")\n \n def _tf_wheel_impl(ctx):\n     executable = ctx.executable.wheel_binary\n \n     output = ctx.actions.declare_directory(\"wheel_house\")\n+    output_path = OUTPUT_PATH if OUTPUT_PATH else output.path\n     args = ctx.actions.args()\n     args.add(\"--project-name\", WHEEL_NAME)\n     args.add(\"--collab\", str(WHEEL_COLLAB))\n-    args.add(\"--output-name\", output.path)\n+    args.add(\"--output-name\", output_path)",
        "comment_created_at": "2024-08-02T22:03:33+00:00",
        "comment_author": "vam-google",
        "comment_body": "> Should hermeticity apply to the output artifacts as well?\r\n\r\nYes, they should, in fact all bazel build artifacts, regardless if they are temporary or intermediate, are always output in cache. That is why i'm saying that to the best of my understanding **this PR would not work**, as it is trying to do what is explicitly forbidden by bazel core architecture decision: `bazel build` never writes anything outside of bazel cache. \r\n\r\n> the wheel location within bazel cache was changing quite often and the post copying script needed to change accordingly.\r\n\r\nI'm surprised to hear this. It did change once recently, that was exactly when we introduced the `wheel` rule. Before that it was stable and it will remain stable from now on.\r\n\r\n> Secondly, when using docker containers to build tf wheels, we cannot access the symblic link to bazel cache within container.\r\n\r\nWe are on the way of not needing to ever do that (using containers), as with proper hermetic build building it from container or building it from you raw system would make no difference,a s hermetic build does not care about local environment. The wheel creation is part of that. Whe have hermetic python introduced, we are on final stages of pushing hermetic cuda (https://github.com/openxla/xla/pull/10673). After that we will cleanup the devtoolset9 stuff from our images and likely bump manlinux tag for released pacakges. This will bring us in a situation when the only real local dependency you would need would be clang (and even that will possible become hermetic if we find time to do that).",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1327644390",
    "pr_number": 61871,
    "pr_file": "BUILD",
    "created_at": "2023-09-15T18:23:39+00:00",
    "commented_code": "\"ACKNOWLEDGEMENTS\",\n     \"LICENSE\",\n ])\n+# Add a platform target to support clang-cl on Windows\n+platform(",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1327644390",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 61871,
        "pr_file": "BUILD",
        "discussion_id": "1327644390",
        "commented_code": "@@ -4,3 +4,12 @@ exports_files([\n     \"ACKNOWLEDGEMENTS\",\n     \"LICENSE\",\n ])\n+# Add a platform target to support clang-cl on Windows\n+platform(",
        "comment_created_at": "2023-09-15T18:23:39+00:00",
        "comment_author": "MichaelHudgins",
        "comment_body": "The platform here should not be in the root build file.  Maybe down in tools/toolchains.",
        "pr_file_module": null
      },
      {
        "comment_id": "1328954506",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 61871,
        "pr_file": "BUILD",
        "discussion_id": "1327644390",
        "commented_code": "@@ -4,3 +4,12 @@ exports_files([\n     \"ACKNOWLEDGEMENTS\",\n     \"LICENSE\",\n ])\n+# Add a platform target to support clang-cl on Windows\n+platform(",
        "comment_created_at": "2023-09-18T16:02:32+00:00",
        "comment_author": "mraunak",
        "comment_body": "Done",
        "pr_file_module": null
      }
    ]
  }
]