[
  {
    "discussion_id": "2116528217",
    "pr_number": 94484,
    "pr_file": "tensorflow/tools/android/test/jni/object_tracking/frame_pair.cc",
    "created_at": "2025-05-30T19:39:38+00:00",
    "commented_code": "float delta;\n };\n \n-// Sort by delta, not by weight.\n+/**\n+ * @brief Comparison function for sorting WeightedDelta structs by delta value.\n+ *\n+ * Returns -1 if a < b, 1 if a > b, and 0 if equal.\n+ * This is suitable for use with qsort and ensures stable ordering when deltas are equal.\n+ *\n+ * @param a Pointer to first WeightedDelta.\n+ * @param b Pointer to second WeightedDelta.\n+ * @return int Comparison result.\n+ */\n inline int WeightedDeltaCompare(const void* const a, const void* const b) {\n-  return (reinterpret_cast<const WeightedDelta*>(a)->delta -\n-          reinterpret_cast<const WeightedDelta*>(b)->delta) <= 0 ? 1 : -1;\n+    float delta_a = reinterpret_cast<const WeightedDelta*>(a)->delta;\n+    float delta_b = reinterpret_cast<const WeightedDelta*>(b)->delta;\n+    if (delta_a < delta_b) return -1;\n+    if (delta_a > delta_b) return 1;\n+    return 0;",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "2116528217",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 94484,
        "pr_file": "tensorflow/tools/android/test/jni/object_tracking/frame_pair.cc",
        "discussion_id": "2116528217",
        "commented_code": "@@ -192,10 +192,22 @@ struct WeightedDelta {\n   float delta;\n };\n \n-// Sort by delta, not by weight.\n+/**\n+ * @brief Comparison function for sorting WeightedDelta structs by delta value.\n+ *\n+ * Returns -1 if a < b, 1 if a > b, and 0 if equal.\n+ * This is suitable for use with qsort and ensures stable ordering when deltas are equal.\n+ *\n+ * @param a Pointer to first WeightedDelta.\n+ * @param b Pointer to second WeightedDelta.\n+ * @return int Comparison result.\n+ */\n inline int WeightedDeltaCompare(const void* const a, const void* const b) {\n-  return (reinterpret_cast<const WeightedDelta*>(a)->delta -\n-          reinterpret_cast<const WeightedDelta*>(b)->delta) <= 0 ? 1 : -1;\n+    float delta_a = reinterpret_cast<const WeightedDelta*>(a)->delta;\n+    float delta_b = reinterpret_cast<const WeightedDelta*>(b)->delta;\n+    if (delta_a < delta_b) return -1;\n+    if (delta_a > delta_b) return 1;\n+    return 0;",
        "comment_created_at": "2025-05-30T19:39:38+00:00",
        "comment_author": "mihaimaruseac",
        "comment_body": "This changes the order of the results. Previously if `a->delta == 1` and `b->delta == 2` the code would return 1 whereas now it would return -1.\r\n\r\nRecommend to skip the clamping to 1/-1 and instead return just the difference.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2007003919",
    "pr_number": 89337,
    "pr_file": "tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.cc",
    "created_at": "2025-03-21T07:25:58+00:00",
    "commented_code": "qnn_tensor_.v2.clientBuf.data = owned_data_.data();\n }\n \n+void TensorWrapper::ConvertQint16ToQuint16() {\n+  if (GetDataType() != QNN_DATATYPE_SFIXED_POINT_16) {\n+    return;\n+  }\n+\n+  // adjust static data\n+  if (IsTensorStatic()) {\n+    std::vector<std::uint16_t> uint16_data;",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "2007003919",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 89337,
        "pr_file": "tensorflow/lite/experimental/litert/vendors/qualcomm/core/wrappers/tensor_wrapper.cc",
        "discussion_id": "2007003919",
        "commented_code": "@@ -214,4 +212,63 @@ void TensorWrapper::SetDataBy(std::uint32_t bytes, const void* data) {\n   qnn_tensor_.v2.clientBuf.data = owned_data_.data();\n }\n \n+void TensorWrapper::ConvertQint16ToQuint16() {\n+  if (GetDataType() != QNN_DATATYPE_SFIXED_POINT_16) {\n+    return;\n+  }\n+\n+  // adjust static data\n+  if (IsTensorStatic()) {\n+    std::vector<std::uint16_t> uint16_data;",
        "comment_created_at": "2025-03-21T07:25:58+00:00",
        "comment_author": "weilhuan-quic",
        "comment_body": "Because we may early return if get `int16_data`, and `uint16_data` won't be used. So we can create `uint16_data` later (until we really need it).",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1990711056",
    "pr_number": 89005,
    "pr_file": "tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/qnn_compose_graph.cc",
    "created_at": "2025-03-12T06:41:59+00:00",
    "commented_code": "std::vector<::qnn::OpWrapper> op_wrappers;\n     LITERT_RETURN_IF_ERROR(\n         ConvertOp(op, tensor_pool, input_tensors, output_tensors, op_wrappers));\n-\n-    for (const auto& op_wrapper : op_wrappers) {\n+    graph_op_wrappers.emplace_back(std::move(op_wrappers));",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1990711056",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 89005,
        "pr_file": "tensorflow/lite/experimental/litert/vendors/qualcomm/compiler/qnn_compose_graph.cc",
        "discussion_id": "1990711056",
        "commented_code": "@@ -648,8 +646,17 @@ LiteRtStatus MapGraph(QnnManager& qnn, Qnn_ContextHandle_t context_handle,\n     std::vector<::qnn::OpWrapper> op_wrappers;\n     LITERT_RETURN_IF_ERROR(\n         ConvertOp(op, tensor_pool, input_tensors, output_tensors, op_wrappers));\n-\n-    for (const auto& op_wrapper : op_wrappers) {\n+    graph_op_wrappers.emplace_back(std::move(op_wrappers));",
        "comment_created_at": "2025-03-12T06:41:59+00:00",
        "comment_author": "chunhsue",
        "comment_body": "```suggestion\r\n    std::move(op_wrappers.begin(), op_wrappers.end(),\r\n              std::back_inserter(graph_op_wrappers));\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2003004092",
    "pr_number": 83717,
    "pr_file": "tensorflow/lite/kernels/strided_slice_test.cc",
    "created_at": "2025-03-19T10:39:30+00:00",
    "commented_code": "// NNAPI does not support graphs with all constant inputs.\n       continue;\n     }\n-    std::vector<TypeParam> values;\n+    std::vector<int> values;\n     for (int i = 0; i < 32768; i++) {\n       values.push_back(i);\n     }\n-    StridedSliceOpModel<TypeParam> m({32768}, {1}, {1}, {1}, values, {0},\n+    auto casted_values = CastVector<TypeParam>(values);",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "2003004092",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 83717,
        "pr_file": "tensorflow/lite/kernels/strided_slice_test.cc",
        "discussion_id": "2003004092",
        "commented_code": "@@ -309,16 +336,18 @@ TYPED_TEST(StridedSliceOpTest, In1D_Int32End) {\n       // NNAPI does not support graphs with all constant inputs.\n       continue;\n     }\n-    std::vector<TypeParam> values;\n+    std::vector<int> values;\n     for (int i = 0; i < 32768; i++) {\n       values.push_back(i);\n     }\n-    StridedSliceOpModel<TypeParam> m({32768}, {1}, {1}, {1}, values, {0},\n+    auto casted_values = CastVector<TypeParam>(values);",
        "comment_created_at": "2025-03-19T10:39:30+00:00",
        "comment_author": "qukhan",
        "comment_body": "``` suggestion\r\n    std::vector<TypeParam> values(32768);\r\n    std::iota(values.begin(), values.end(), TypeParam(0));\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1059052203",
    "pr_number": 58410,
    "pr_file": "tensorflow/compiler/mlir/tosa/transforms/legalize_common.cc",
    "created_at": "2022-12-29T16:42:07+00:00",
    "commented_code": "Operation* op, Value result_value,\n                                         Value lhs_value, Value rhs_value) {\n   // FloorMod lowering:\n-  // (1/rhs * lhs) - floor(1/rhs * lhs)\n+  // ((1/rhs * lhs) - floor(1/rhs * lhs)) * rhs\n   // a1 = reciprocal(rhs);\n   // a2 = mul(lhs, a1);",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1059052203",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 58410,
        "pr_file": "tensorflow/compiler/mlir/tosa/transforms/legalize_common.cc",
        "discussion_id": "1059052203",
        "commented_code": "@@ -2494,12 +2494,13 @@ llvm::Optional<Value> convertFloorModOp(PatternRewriter& rewriter,\n                                         Operation* op, Value result_value,\n                                         Value lhs_value, Value rhs_value) {\n   // FloorMod lowering:\n-  // (1/rhs * lhs) - floor(1/rhs * lhs)\n+  // ((1/rhs * lhs) - floor(1/rhs * lhs)) * rhs\n   // a1 = reciprocal(rhs);\n   // a2 = mul(lhs, a1);",
        "comment_created_at": "2022-12-29T16:42:07+00:00",
        "comment_author": "jpienaar",
        "comment_body": "Any reason a2 has the multiplication order inverted from the formula in 2497?",
        "pr_file_module": null
      },
      {
        "comment_id": "1164721706",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 58410,
        "pr_file": "tensorflow/compiler/mlir/tosa/transforms/legalize_common.cc",
        "discussion_id": "1059052203",
        "commented_code": "@@ -2494,12 +2494,13 @@ llvm::Optional<Value> convertFloorModOp(PatternRewriter& rewriter,\n                                         Operation* op, Value result_value,\n                                         Value lhs_value, Value rhs_value) {\n   // FloorMod lowering:\n-  // (1/rhs * lhs) - floor(1/rhs * lhs)\n+  // ((1/rhs * lhs) - floor(1/rhs * lhs)) * rhs\n   // a1 = reciprocal(rhs);\n   // a2 = mul(lhs, a1);",
        "comment_created_at": "2023-04-12T22:34:29+00:00",
        "comment_author": "sachinprasadhs",
        "comment_body": "In the existing implementation floormod equation is` floormod(x,y) = (x/y) - floor(x/y)` which is wrong. \r\nAccording to the actual formula this PR would equate by multiplying rhs (y) to the whole equation as below.\r\n\r\n`floormod(x,y) = ((x/y) - floor(x/y))*y`   -->  `floormod(x,y) = x- floor(x/y)*y`",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1785614473",
    "pr_number": 76252,
    "pr_file": "tensorflow/core/kernels/sequence_ops.cc",
    "created_at": "2024-10-03T04:28:04+00:00",
    "commented_code": "errors::InvalidArgument(\n               \"Requires start >= limit when delta < 0: \", start, \"/\", limit));\n     }\n-    int64_t size;\n+    uint64_t size;\n     if constexpr (std::is_integral<T>::value) {\n-      size = Eigen::divup(Eigen::numext::abs(limit - start),\n-                          Eigen::numext::abs(delta));\n+      uint64_t range;\n+      if ((limit > 0 && start < 0) || (limit < 0 && start > 0)) {\n+        range = static_cast<uint64_t>(Eigen::numext::abs(limit)) \n+                + static_cast<uint64_t>(Eigen::numext::abs(start));\n+      } else {\n+        range = static_cast<uint64_t>(Eigen::numext::abs(limit - start)); \n+      }\n+\n+      size = Eigen::divup(range,\n+                          static_cast<uint64_t>(Eigen::numext::abs(delta)));",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1785614473",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 76252,
        "pr_file": "tensorflow/core/kernels/sequence_ops.cc",
        "discussion_id": "1785614473",
        "commented_code": "@@ -91,18 +91,26 @@ class RangeOp : public OpKernel {\n           errors::InvalidArgument(\n               \"Requires start >= limit when delta < 0: \", start, \"/\", limit));\n     }\n-    int64_t size;\n+    uint64_t size;\n     if constexpr (std::is_integral<T>::value) {\n-      size = Eigen::divup(Eigen::numext::abs(limit - start),\n-                          Eigen::numext::abs(delta));\n+      uint64_t range;\n+      if ((limit > 0 && start < 0) || (limit < 0 && start > 0)) {\n+        range = static_cast<uint64_t>(Eigen::numext::abs(limit)) \n+                + static_cast<uint64_t>(Eigen::numext::abs(start));\n+      } else {\n+        range = static_cast<uint64_t>(Eigen::numext::abs(limit - start)); \n+      }\n+\n+      size = Eigen::divup(range,\n+                          static_cast<uint64_t>(Eigen::numext::abs(delta)));",
        "comment_created_at": "2024-10-03T04:28:04+00:00",
        "comment_author": "mattbahr",
        "comment_body": "@mihaimaruseac I think we should add a check here that `size` is less than or equal to `std::numeric_limits<int64_t>::max()`.",
        "pr_file_module": null
      }
    ]
  }
]