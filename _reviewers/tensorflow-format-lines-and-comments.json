[
  {
    "discussion_id": "1496125741",
    "pr_number": 62750,
    "pr_file": "tensorflow/python/ops/math_ops.py",
    "created_at": "2024-02-20T16:28:35+00:00",
    "commented_code": "name=name,\n     )\n \n+@tf_export(\"sparse.sampled_addmm\")\n+def sampled_addmm(indices,\n+      values,\n+      dense_shape,\n+      mat1,\n+      mat2,\n+      beta=1.0,\n+      alpha=1.0,\n+      output_type=dtypes.float32\n+):\n+  \"\"\"Multiplies matrix `mat1` by matrix `mat2` at the locations defined by\n+  `indices`. The product is scaled and added to `values`, \n+  producing `alpha` * (`mat1` @ `mat2`) * spy(`indices`) + `beta` * `values`\n+\n+  The function `spy(indices)` is the sparsity pattern matrix derived from\n+  `indices`.\n+\n+  The `mat1` and `mat2` inputs must be tensors of rank >= 2 where the inner 2\n+  dimensions specify valid matrix multiplication dimensions, and any further\n+  dimensions specify matching batch size.\n+\n+  The `indices`, `values`, and `dense_shape` inputs make up the components of a\n+  `SparseTensor` which defines the sparsity pattern of the output. The sparsity\n+  pattern has values of 1 at the positions defined by the `SparseTensor`, and 0\n+  elsewhere.\n+\n+  The `alpha` and `beta` inputs are the scaling factors.\n+\n+  The supported types for `values`, `mat1`, and `mat2` are:\n+  `bfloat16`, `float16`, `float32`, `float64`.\n+\n+  A simple 2-D tensor operation:\n+\n+  >>> indices = tf.constant([0, 0, 1, 1], shape=[2, 2])\n+  >>> indices\n+  <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n+  array([[0, 0],\n+         [1, 1]], dtype=int32)>\n+  >>> values = tf.constant([0.5, 0.3])\n+  >>> values\n+  <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.5, 0.3], dtype=float32)>\n+  >>> dense_shape = tf.constant([2, 2])\n+  >>> dense_shape\n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>\n+  >>> mat1 = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n+  >>> mat1\n+  <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n+  array([[1, 2, 3],\n+         [4, 5, 6]], dtype=int32)>\n+  >>> mat2 = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n+  >>> mat2\n+  <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n+  array([[ 7,  8],\n+         [ 9, 10],\n+         [11, 12]], dtype=int32)>\n+  >>> tf.sparse.sampled_addmm(indices, values, dense_shape, mat1, mat2,\n+  ... alpha=0.75, beta=0.25)\n+  (<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n+  array([[0, 0],\n+         [1, 1]], dtype=int32)>, \n+  <tf.Tensor: shape=(2,), dtype=float32, numpy=\n+  array([ 43.625, 115.575], dtype=float32)>, \n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>)\n+\n+  A batch operation:\n+\n+  >>> indices = tf.constant([0, 1, 1, 0, 0, 0, 1, 0], shape=[2, 2, 2])\n+  >>> indices\n+  <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n+  array([[[0, 1],\n+          [1, 0]],\n+         [[0, 0],\n+          [1, 0]]], dtype=int32)>\n+  >>> values = tf.constant([3, 5, 2, 7], shape=[2, 2])\n+  >>> values\n+  <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n+  array([[3, 5],\n+         [2, 7]], dtype=int32)>\n+  >>> dense_shape = tf.constant([2, 2])\n+  >>> dense_shape\n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>\n+  >>> mat1 = tf.constant(np.arange(1, 13), shape=[2, 2, 3])\n+  >>> mat1\n+  <tf.Tensor: shape=(2, 2, 3), dtype=int64, numpy=\n+  array([[[ 1,  2,  3],\n+          [ 4,  5,  6]],\n+         [[ 7,  8,  9],\n+          [10, 11, 12]]])>\n+  >>> mat2 = tf.constant(np.arange(13, 25), shape=[2, 3, 2])\n+  >>> mat2\n+  <tf.Tensor: shape=(2, 3, 2), dtype=int64, numpy=\n+  array([[[13, 14],\n+          [15, 16],\n+          [17, 18]],\n+         [[19, 20],\n+          [21, 22],\n+          [23, 24]]])>\n+  >>> tf.sparse.sampled_addmm(indices, values, dense_shape, mat1, mat2,\n+  ... alpha=0.75, beta=0.25)\n+  (<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n+  array([[[0, 1],\n+          [1, 0]],\n+         [[0, 0],\n+          [1, 0]]], dtype=int32)>, <tf.Tensor: shape=(2, 2), dtype=float32,\n+  numpy=array([[ 75.75, 173.  ],\n+         [381.5 , 524.5 ]], dtype=float32)>, \n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>)\n \n+  Args:\n+    indices: `tf.Tensor` containing coordinates for the rows and columns to be\n+      multiplied. Must have rank > 1.\n+    values: `tf.Tensor` containing the values to be scaled and added to the\n+      sampled dot product.\n+    dense_shape: `tf.Tensor` defining the dense shape of the output.\n+    mat1: `tf.Tensor` to be multiplied. Must have rank > 1.\n+    mat2: `tf.Tensor` to be multiplied. Must have rank > 1.\n+    beta: Number to be multipled with `values`. Defaults to 1.0.\n+    alpha: Number to be multiplied with the sampled dot product of `mat1` and\n+      `mat2`. Defaults to 1.0.\n+    output_type: the output datatype if needed. Defaults to float32.\n+\n+  Returns:\n+    A tuple of three `tf.Tensor` objects (indices, result, dense_shape) making\n+    up the components of a `SparseTensor` representing the result of the\n+    operation.\n+\n+    result = `alpha` * (`mat1` @ `mat2`) * spy(`indices`) + `beta` * `values`\n+\n+    The function `spy(indices)` is the sparsity pattern matrix derived from\n+    `indices`. \n+  \"\"\"\n+  indices = ops.convert_to_tensor(indices)\n+  values = ops.convert_to_tensor(values, dtype=output_type)\n+  dense_shape = ops.convert_to_tensor(dense_shape, dtype=dtypes.int32)\n+  mat1 = ops.convert_to_tensor(mat1, dtype=output_type)\n+  mat2 = ops.convert_to_tensor(mat2, dtype=output_type)\n+\n+  mat1_shape = mat1.shape\n+  mat2_shape = mat2.shape\n+  \n+  if mat1_shape is None:\n+    mat1_shape = array_ops.shape(mat1)\n+  if mat2_shape is None:\n+    mat2_shape = array_ops.shape(mat2)\n+\n+  dense_rows = mat1_shape[-2]\n+  dense_cols = mat2_shape[-1]\n+\n+  output_shape = constant_op.constant([dense_rows, dense_cols], \n+                                      dtype=dtypes.int32)\n+\n+  condition = reduce_all(equal(dense_shape, output_shape))\n+\n+  # Use dense_shape to validate matrix shapes",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1496125741",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 62750,
        "pr_file": "tensorflow/python/ops/math_ops.py",
        "discussion_id": "1496125741",
        "commented_code": "@@ -4857,7 +4858,207 @@ def sparse_segment_sum(\n         name=name,\n     )\n \n+@tf_export(\"sparse.sampled_addmm\")\n+def sampled_addmm(indices,\n+      values,\n+      dense_shape,\n+      mat1,\n+      mat2,\n+      beta=1.0,\n+      alpha=1.0,\n+      output_type=dtypes.float32\n+):\n+  \"\"\"Multiplies matrix `mat1` by matrix `mat2` at the locations defined by\n+  `indices`. The product is scaled and added to `values`, \n+  producing `alpha` * (`mat1` @ `mat2`) * spy(`indices`) + `beta` * `values`\n+\n+  The function `spy(indices)` is the sparsity pattern matrix derived from\n+  `indices`.\n+\n+  The `mat1` and `mat2` inputs must be tensors of rank >= 2 where the inner 2\n+  dimensions specify valid matrix multiplication dimensions, and any further\n+  dimensions specify matching batch size.\n+\n+  The `indices`, `values`, and `dense_shape` inputs make up the components of a\n+  `SparseTensor` which defines the sparsity pattern of the output. The sparsity\n+  pattern has values of 1 at the positions defined by the `SparseTensor`, and 0\n+  elsewhere.\n+\n+  The `alpha` and `beta` inputs are the scaling factors.\n+\n+  The supported types for `values`, `mat1`, and `mat2` are:\n+  `bfloat16`, `float16`, `float32`, `float64`.\n+\n+  A simple 2-D tensor operation:\n+\n+  >>> indices = tf.constant([0, 0, 1, 1], shape=[2, 2])\n+  >>> indices\n+  <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n+  array([[0, 0],\n+         [1, 1]], dtype=int32)>\n+  >>> values = tf.constant([0.5, 0.3])\n+  >>> values\n+  <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.5, 0.3], dtype=float32)>\n+  >>> dense_shape = tf.constant([2, 2])\n+  >>> dense_shape\n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>\n+  >>> mat1 = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n+  >>> mat1\n+  <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n+  array([[1, 2, 3],\n+         [4, 5, 6]], dtype=int32)>\n+  >>> mat2 = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n+  >>> mat2\n+  <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n+  array([[ 7,  8],\n+         [ 9, 10],\n+         [11, 12]], dtype=int32)>\n+  >>> tf.sparse.sampled_addmm(indices, values, dense_shape, mat1, mat2,\n+  ... alpha=0.75, beta=0.25)\n+  (<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n+  array([[0, 0],\n+         [1, 1]], dtype=int32)>, \n+  <tf.Tensor: shape=(2,), dtype=float32, numpy=\n+  array([ 43.625, 115.575], dtype=float32)>, \n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>)\n+\n+  A batch operation:\n+\n+  >>> indices = tf.constant([0, 1, 1, 0, 0, 0, 1, 0], shape=[2, 2, 2])\n+  >>> indices\n+  <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n+  array([[[0, 1],\n+          [1, 0]],\n+         [[0, 0],\n+          [1, 0]]], dtype=int32)>\n+  >>> values = tf.constant([3, 5, 2, 7], shape=[2, 2])\n+  >>> values\n+  <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n+  array([[3, 5],\n+         [2, 7]], dtype=int32)>\n+  >>> dense_shape = tf.constant([2, 2])\n+  >>> dense_shape\n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>\n+  >>> mat1 = tf.constant(np.arange(1, 13), shape=[2, 2, 3])\n+  >>> mat1\n+  <tf.Tensor: shape=(2, 2, 3), dtype=int64, numpy=\n+  array([[[ 1,  2,  3],\n+          [ 4,  5,  6]],\n+         [[ 7,  8,  9],\n+          [10, 11, 12]]])>\n+  >>> mat2 = tf.constant(np.arange(13, 25), shape=[2, 3, 2])\n+  >>> mat2\n+  <tf.Tensor: shape=(2, 3, 2), dtype=int64, numpy=\n+  array([[[13, 14],\n+          [15, 16],\n+          [17, 18]],\n+         [[19, 20],\n+          [21, 22],\n+          [23, 24]]])>\n+  >>> tf.sparse.sampled_addmm(indices, values, dense_shape, mat1, mat2,\n+  ... alpha=0.75, beta=0.25)\n+  (<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n+  array([[[0, 1],\n+          [1, 0]],\n+         [[0, 0],\n+          [1, 0]]], dtype=int32)>, <tf.Tensor: shape=(2, 2), dtype=float32,\n+  numpy=array([[ 75.75, 173.  ],\n+         [381.5 , 524.5 ]], dtype=float32)>, \n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>)\n \n+  Args:\n+    indices: `tf.Tensor` containing coordinates for the rows and columns to be\n+      multiplied. Must have rank > 1.\n+    values: `tf.Tensor` containing the values to be scaled and added to the\n+      sampled dot product.\n+    dense_shape: `tf.Tensor` defining the dense shape of the output.\n+    mat1: `tf.Tensor` to be multiplied. Must have rank > 1.\n+    mat2: `tf.Tensor` to be multiplied. Must have rank > 1.\n+    beta: Number to be multipled with `values`. Defaults to 1.0.\n+    alpha: Number to be multiplied with the sampled dot product of `mat1` and\n+      `mat2`. Defaults to 1.0.\n+    output_type: the output datatype if needed. Defaults to float32.\n+\n+  Returns:\n+    A tuple of three `tf.Tensor` objects (indices, result, dense_shape) making\n+    up the components of a `SparseTensor` representing the result of the\n+    operation.\n+\n+    result = `alpha` * (`mat1` @ `mat2`) * spy(`indices`) + `beta` * `values`\n+\n+    The function `spy(indices)` is the sparsity pattern matrix derived from\n+    `indices`. \n+  \"\"\"\n+  indices = ops.convert_to_tensor(indices)\n+  values = ops.convert_to_tensor(values, dtype=output_type)\n+  dense_shape = ops.convert_to_tensor(dense_shape, dtype=dtypes.int32)\n+  mat1 = ops.convert_to_tensor(mat1, dtype=output_type)\n+  mat2 = ops.convert_to_tensor(mat2, dtype=output_type)\n+\n+  mat1_shape = mat1.shape\n+  mat2_shape = mat2.shape\n+  \n+  if mat1_shape is None:\n+    mat1_shape = array_ops.shape(mat1)\n+  if mat2_shape is None:\n+    mat2_shape = array_ops.shape(mat2)\n+\n+  dense_rows = mat1_shape[-2]\n+  dense_cols = mat2_shape[-1]\n+\n+  output_shape = constant_op.constant([dense_rows, dense_cols], \n+                                      dtype=dtypes.int32)\n+\n+  condition = reduce_all(equal(dense_shape, output_shape))\n+\n+  # Use dense_shape to validate matrix shapes",
        "comment_created_at": "2024-02-20T16:28:35+00:00",
        "comment_author": "cantonios",
        "comment_body": "nit: all comments should be sentence-like, with punctuation and capitalization.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1053546359",
    "pr_number": 58909,
    "pr_file": "tensorflow/python/framework/config.py",
    "created_at": "2022-12-20T17:02:28+00:00",
    "commented_code": "- disable_meta_optimizer: Disable the entire meta optimizer.\n       - min_graph_nodes: The minimum number of nodes in a graph to optimizer.\n         For smaller graphs, optimization is skipped.\n-      - Autoparallel optimizer - Automatically parallelizes graphs by splitting along the batch dimension\n+      - auto_parallel : Automatically parallelizes graphs by splitting along the batch dimension",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1053546359",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 58909,
        "pr_file": "tensorflow/python/framework/config.py",
        "discussion_id": "1053546359",
        "commented_code": "@@ -237,7 +237,7 @@ def set_optimizer_experimental_options(options):\n       - disable_meta_optimizer: Disable the entire meta optimizer.\n       - min_graph_nodes: The minimum number of nodes in a graph to optimizer.\n         For smaller graphs, optimization is skipped.\n-      - Autoparallel optimizer - Automatically parallelizes graphs by splitting along the batch dimension\n+      - auto_parallel : Automatically parallelizes graphs by splitting along the batch dimension",
        "comment_created_at": "2022-12-20T17:02:28+00:00",
        "comment_author": "kenfranko",
        "comment_body": "Remove the space after auto_parallel for consistency.  Split across two lines, see min_graph_nodes as an example.  Max line length is 80 characters and this current change fails the linter.",
        "pr_file_module": null
      },
      {
        "comment_id": "1071925215",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 58909,
        "pr_file": "tensorflow/python/framework/config.py",
        "discussion_id": "1053546359",
        "commented_code": "@@ -237,7 +237,7 @@ def set_optimizer_experimental_options(options):\n       - disable_meta_optimizer: Disable the entire meta optimizer.\n       - min_graph_nodes: The minimum number of nodes in a graph to optimizer.\n         For smaller graphs, optimization is skipped.\n-      - Autoparallel optimizer - Automatically parallelizes graphs by splitting along the batch dimension\n+      - auto_parallel : Automatically parallelizes graphs by splitting along the batch dimension",
        "comment_created_at": "2023-01-17T08:54:37+00:00",
        "comment_author": "SuryanarayanaY",
        "comment_body": "Changes done as required.Thank you!",
        "pr_file_module": null
      }
    ]
  }
]