[
  {
    "discussion_id": "1486624026",
    "pr_number": 62807,
    "pr_file": "tensorflow/python/ops/random_ops.py",
    "created_at": "2024-02-12T18:50:52+00:00",
    "commented_code": "if dtype.is_integer:\n       raise ValueError(\"Must specify maxval for integer dtype %r\" % dtype)\n     maxval = 1\n+  if minval >= maxval:",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1486624026",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 62807,
        "pr_file": "tensorflow/python/ops/random_ops.py",
        "discussion_id": "1486624026",
        "commented_code": "@@ -291,6 +291,11 @@ def random_uniform(shape,\n     if dtype.is_integer:\n       raise ValueError(\"Must specify maxval for integer dtype %r\" % dtype)\n     maxval = 1\n+  if minval >= maxval:",
        "comment_created_at": "2024-02-12T18:50:52+00:00",
        "comment_author": "cantonios",
        "comment_body": "since these are potentially tensor arguments, you cannot do this comparison in python",
        "pr_file_module": null
      },
      {
        "comment_id": "1500854106",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 62807,
        "pr_file": "tensorflow/python/ops/random_ops.py",
        "discussion_id": "1486624026",
        "commented_code": "@@ -291,6 +291,11 @@ def random_uniform(shape,\n     if dtype.is_integer:\n       raise ValueError(\"Must specify maxval for integer dtype %r\" % dtype)\n     maxval = 1\n+  if minval >= maxval:",
        "comment_created_at": "2024-02-23T15:49:36+00:00",
        "comment_author": "SuryanarayanaY",
        "comment_body": "@cantonios , That's True. How about modifying the class PhiloxRandomOp in [random_op.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/random_op.cc#L64) like below. It may verify other dtypes. Amended code commented as **//added code**. Is this works?\r\n\r\n```\r\ntemplate <typename Device, class Distribution>\r\nclass PhiloxRandomOp : public OpKernel {\r\n public:\r\n  typedef typename Distribution::ResultElementType T;\r\n  explicit PhiloxRandomOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\r\n    OP_REQUIRES_OK(ctx, generator_.Init(ctx));\r\n  }\r\n\r\n  void Compute(OpKernelContext* ctx) override {\r\n    const Tensor& shape = ctx->input(0);\r\n    const Tensor& minval = ctx->input(1); //added code\r\n    const Tensor& maxval = ctx->input(2); //added code\r\n    Tensor* output;\r\n    OP_REQUIRES_OK(ctx, AllocateOutputWithShape(ctx, shape, 0, &output));\r\n    auto output_flat = output->flat<T>();\r\n    \r\n    Distribution lo = minval.scalar<Distribution>()();//added code\r\n    Distribution hi = maxval.scalar<Distribution>()();//added code\r\n    OP_REQUIRES(\r\n        ctx, lo < hi,\r\n        errors::InvalidArgument(\"Need minval < maxval, got \", lo, \" >= \", hi));//added code\r\n        \r\n    functor::FillPhiloxRandom<Device, Distribution>()(\r\n        ctx, ctx->eigen_device<Device>(), /*key=*/nullptr, /*counter=*/nullptr,\r\n        // Multiplier 256 is the same as in FillPhiloxRandomTask; do not change\r\n        // it just here.\r\n        generator_.ReserveRandomOutputs(output_flat.size(), 256),\r\n        output_flat.data(), output_flat.size(), Distribution());\r\n  }\r\n\r\n private:\r\n  GuardedPhiloxRandom generator_;\r\n};\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1501002086",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 62807,
        "pr_file": "tensorflow/python/ops/random_ops.py",
        "discussion_id": "1486624026",
        "commented_code": "@@ -291,6 +291,11 @@ def random_uniform(shape,\n     if dtype.is_integer:\n       raise ValueError(\"Must specify maxval for integer dtype %r\" % dtype)\n     maxval = 1\n+  if minval >= maxval:",
        "comment_created_at": "2024-02-23T17:57:28+00:00",
        "comment_author": "cantonios",
        "comment_body": "No, the min/max are not arguments to the op.\r\n\r\nYou either need to use something in `check_ops.py`, or you clamp the maximum to the minimum, or you keep the behavior as it is.",
        "pr_file_module": null
      },
      {
        "comment_id": "1502722978",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 62807,
        "pr_file": "tensorflow/python/ops/random_ops.py",
        "discussion_id": "1486624026",
        "commented_code": "@@ -291,6 +291,11 @@ def random_uniform(shape,\n     if dtype.is_integer:\n       raise ValueError(\"Must specify maxval for integer dtype %r\" % dtype)\n     maxval = 1\n+  if minval >= maxval:",
        "comment_created_at": "2024-02-26T14:40:24+00:00",
        "comment_author": "SuryanarayanaY",
        "comment_body": "Changed the validation using `check_ops.assert_less ` as suggested.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1427013654",
    "pr_number": 60727,
    "pr_file": "tensorflow/python/ops/numpy_ops/np_array_ops.py",
    "created_at": "2023-12-14T17:17:26+00:00",
    "commented_code": "x = array_ops.where_v2(x < 0, np_utils.add(x, a_rank), x)\n       return x\n     return nest.map_structure(f, axes)\n+  \n+  if axis2 < -array_ops.rank(a) or axis2 >= array_ops.rank(a):",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1427013654",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 60727,
        "pr_file": "tensorflow/python/ops/numpy_ops/np_array_ops.py",
        "discussion_id": "1427013654",
        "commented_code": "@@ -819,6 +819,11 @@ def f(x):\n         x = array_ops.where_v2(x < 0, np_utils.add(x, a_rank), x)\n       return x\n     return nest.map_structure(f, axes)\n+  \n+  if axis2 < -array_ops.rank(a) or axis2 >= array_ops.rank(a):",
        "comment_created_at": "2023-12-14T17:17:26+00:00",
        "comment_author": "cantonios",
        "comment_body": "This fails if these are tensors, since you can't use a tensor as a python bool.   You probably need to use something like this: https://github.com/tensorflow/tensorflow/blob/517df2d259ba27f2ef3da399bf9c3b081d7a57b7/tensorflow/python/ops/image_ops_impl.py#L71\r\n\r\nthough we shouldn't add the dependency on image_ops_impl, so maybe re-implement it, or find another similar function in a shared utility",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1445217338",
    "pr_number": 62750,
    "pr_file": "tensorflow/python/ops/math_ops.py",
    "created_at": "2024-01-08T19:15:14+00:00",
    "commented_code": "name=name,\n     )\n \n+@tf_export(\"sparse.sampled_addmm\")\n+def sampled_addmm(indices,\n+      values,\n+      dense_shape,\n+      mat1,\n+      mat2,\n+      beta=1.0,\n+      alpha=1.0,\n+      output_type=dtypes.float32\n+):\n+  \"\"\"Multiplies matrix `mat1` by matrix `mat2` at the locations defined by\n+  `indices`. The product is scaled and added to `values`, \n+  producing `alpha` * (`mat1` @ `mat2`) * spy(`indices`) + `beta` * `values`\n+\n+  The function `spy(indices)` is the sparsity pattern matrix derived from\n+  `indices`.\n+\n+  The `mat1` and `mat2` inputs must be tensors of rank >= 2 where the inner 2\n+  dimensions specify valid matrix multiplication dimensions, and any further\n+  dimensions specify matching batch size.\n+\n+  The `indices`, `values`, and `dense_shape` inputs make up the components of a\n+  `SparseTensor` which defines the sparsity pattern of the output. The sparsity\n+  pattern has values of 1 at the positions defined by the `SparseTensor`, and 0\n+  elsewhere.\n+\n+  The `alpha` and `beta` inputs are the scaling factors.\n+\n+  The supported types for `values`, `mat1`, and `mat2` are:\n+  `bfloat16`, `float16`, `float32`, `float64`.\n+\n+  A simple 2-D tensor operation:\n+\n+  >>> indices = tf.constant([0, 0, 1, 1], shape=[2, 2])\n+  >>> indices\n+  <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n+  array([[0, 0],\n+         [1, 1]], dtype=int32)>\n+  >>> values = tf.constant([0.5, 0.3])\n+  >>> values\n+  <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.5, 0.3], dtype=float32)>\n+  >>> dense_shape = tf.constant([2, 2])\n+  >>> dense_shape\n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>\n+  >>> mat1 = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n+  >>> mat1\n+  <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n+  array([[1, 2, 3],\n+         [4, 5, 6]], dtype=int32)>\n+  >>> mat2 = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n+  >>> mat2\n+  <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n+  array([[ 7,  8],\n+         [ 9, 10],\n+         [11, 12]], dtype=int32)>\n+  >>> tf.sparse.sampled_addmm(indices, values, dense_shape, mat1, mat2,\n+  ... alpha=0.75, beta=0.25)\n+  (<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n+  array([[0, 0],\n+         [1, 1]], dtype=int32)>, \n+  <tf.Tensor: shape=(2,), dtype=float32, numpy=\n+  array([ 43.625, 115.575], dtype=float32)>, \n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>)\n+\n+  A batch operation:\n+\n+  >>> indices = tf.constant([0, 1, 1, 0, 0, 0, 1, 0], shape=[2, 2, 2])\n+  >>> indices\n+  <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n+  array([[[0, 1],\n+          [1, 0]],\n+         [[0, 0],\n+          [1, 0]]], dtype=int32)>\n+  >>> values = tf.constant([3, 5, 2, 7], shape=[2, 2])\n+  >>> values\n+  <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n+  array([[3, 5],\n+         [2, 7]], dtype=int32)>\n+  >>> dense_shape = tf.constant([2, 2])\n+  >>> dense_shape\n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>\n+  >>> mat1 = tf.constant(np.arange(1, 13), shape=[2, 2, 3])\n+  >>> mat1\n+  <tf.Tensor: shape=(2, 2, 3), dtype=int64, numpy=\n+  array([[[ 1,  2,  3],\n+          [ 4,  5,  6]],\n+         [[ 7,  8,  9],\n+          [10, 11, 12]]])>\n+  >>> mat2 = tf.constant(np.arange(13, 25), shape=[2, 3, 2])\n+  >>> mat2\n+  <tf.Tensor: shape=(2, 3, 2), dtype=int64, numpy=\n+  array([[[13, 14],\n+          [15, 16],\n+          [17, 18]],\n+         [[19, 20],\n+          [21, 22],\n+          [23, 24]]])>\n+  >>> tf.sparse.sampled_addmm(indices, values, dense_shape, mat1, mat2,\n+  ... alpha=0.75, beta=0.25)\n+  (<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n+  array([[[0, 1],\n+          [1, 0]],\n+         [[0, 0],\n+          [1, 0]]], dtype=int32)>, <tf.Tensor: shape=(2, 2), dtype=float32,\n+  numpy=array([[ 75.75, 173.  ],\n+         [381.5 , 524.5 ]], dtype=float32)>, \n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>)\n+\n+  Args:\n+    indices: `tf.Tensor` containing coordinates for the rows and columns to be\n+      multiplied. Must have rank > 1.\n+    values: `tf.Tensor` containing the values to be scaled and added to the\n+      sampled dot product.\n+    dense_shape: `tf.Tensor` defining the dense shape of the output.\n+    mat1: `tf.Tensor` to be multiplied. Must have rank > 1.\n+    mat2: `tf.Tensor` to be multiplied. Must have rank > 1.\n+    beta: Number to be multipled with `values`. Defaults to 1.0.\n+    alpha: Number to be multiplied with the sampled dot product of `mat1` and\n+      `mat2`. Defaults to 1.0.\n+    output_type: the output datatype if needed. Defaults to float32.\n+\n+  Returns:\n+    A tuple of three `tf.Tensor` objects (indices, result, dense_shape) making\n+    up the components of a `SparseTensor` representing the result of the\n+    operation.\n+\n+    result = `alpha` * (`mat1` @ `mat2`) * spy(`indices`) + `beta` * `values`\n \n+    The function `spy(indices)` is the sparsity pattern matrix derived from\n+    `indices`. \n+  \"\"\"\n+  if context.executing_eagerly():\n+    if not isinstance(indices, ops.EagerTensor):\n+      indices = ops.convert_to_tensor(indices)",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1445217338",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 62750,
        "pr_file": "tensorflow/python/ops/math_ops.py",
        "discussion_id": "1445217338",
        "commented_code": "@@ -4857,7 +4857,185 @@ def sparse_segment_sum(\n         name=name,\n     )\n \n+@tf_export(\"sparse.sampled_addmm\")\n+def sampled_addmm(indices,\n+      values,\n+      dense_shape,\n+      mat1,\n+      mat2,\n+      beta=1.0,\n+      alpha=1.0,\n+      output_type=dtypes.float32\n+):\n+  \"\"\"Multiplies matrix `mat1` by matrix `mat2` at the locations defined by\n+  `indices`. The product is scaled and added to `values`, \n+  producing `alpha` * (`mat1` @ `mat2`) * spy(`indices`) + `beta` * `values`\n+\n+  The function `spy(indices)` is the sparsity pattern matrix derived from\n+  `indices`.\n+\n+  The `mat1` and `mat2` inputs must be tensors of rank >= 2 where the inner 2\n+  dimensions specify valid matrix multiplication dimensions, and any further\n+  dimensions specify matching batch size.\n+\n+  The `indices`, `values`, and `dense_shape` inputs make up the components of a\n+  `SparseTensor` which defines the sparsity pattern of the output. The sparsity\n+  pattern has values of 1 at the positions defined by the `SparseTensor`, and 0\n+  elsewhere.\n+\n+  The `alpha` and `beta` inputs are the scaling factors.\n+\n+  The supported types for `values`, `mat1`, and `mat2` are:\n+  `bfloat16`, `float16`, `float32`, `float64`.\n+\n+  A simple 2-D tensor operation:\n+\n+  >>> indices = tf.constant([0, 0, 1, 1], shape=[2, 2])\n+  >>> indices\n+  <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n+  array([[0, 0],\n+         [1, 1]], dtype=int32)>\n+  >>> values = tf.constant([0.5, 0.3])\n+  >>> values\n+  <tf.Tensor: shape=(2,), dtype=float32, numpy=array([0.5, 0.3], dtype=float32)>\n+  >>> dense_shape = tf.constant([2, 2])\n+  >>> dense_shape\n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>\n+  >>> mat1 = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n+  >>> mat1\n+  <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n+  array([[1, 2, 3],\n+         [4, 5, 6]], dtype=int32)>\n+  >>> mat2 = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n+  >>> mat2\n+  <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n+  array([[ 7,  8],\n+         [ 9, 10],\n+         [11, 12]], dtype=int32)>\n+  >>> tf.sparse.sampled_addmm(indices, values, dense_shape, mat1, mat2,\n+  ... alpha=0.75, beta=0.25)\n+  (<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n+  array([[0, 0],\n+         [1, 1]], dtype=int32)>, \n+  <tf.Tensor: shape=(2,), dtype=float32, numpy=\n+  array([ 43.625, 115.575], dtype=float32)>, \n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>)\n+\n+  A batch operation:\n+\n+  >>> indices = tf.constant([0, 1, 1, 0, 0, 0, 1, 0], shape=[2, 2, 2])\n+  >>> indices\n+  <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n+  array([[[0, 1],\n+          [1, 0]],\n+         [[0, 0],\n+          [1, 0]]], dtype=int32)>\n+  >>> values = tf.constant([3, 5, 2, 7], shape=[2, 2])\n+  >>> values\n+  <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n+  array([[3, 5],\n+         [2, 7]], dtype=int32)>\n+  >>> dense_shape = tf.constant([2, 2])\n+  >>> dense_shape\n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>\n+  >>> mat1 = tf.constant(np.arange(1, 13), shape=[2, 2, 3])\n+  >>> mat1\n+  <tf.Tensor: shape=(2, 2, 3), dtype=int64, numpy=\n+  array([[[ 1,  2,  3],\n+          [ 4,  5,  6]],\n+         [[ 7,  8,  9],\n+          [10, 11, 12]]])>\n+  >>> mat2 = tf.constant(np.arange(13, 25), shape=[2, 3, 2])\n+  >>> mat2\n+  <tf.Tensor: shape=(2, 3, 2), dtype=int64, numpy=\n+  array([[[13, 14],\n+          [15, 16],\n+          [17, 18]],\n+         [[19, 20],\n+          [21, 22],\n+          [23, 24]]])>\n+  >>> tf.sparse.sampled_addmm(indices, values, dense_shape, mat1, mat2,\n+  ... alpha=0.75, beta=0.25)\n+  (<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n+  array([[[0, 1],\n+          [1, 0]],\n+         [[0, 0],\n+          [1, 0]]], dtype=int32)>, <tf.Tensor: shape=(2, 2), dtype=float32,\n+  numpy=array([[ 75.75, 173.  ],\n+         [381.5 , 524.5 ]], dtype=float32)>, \n+  <tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>)\n+\n+  Args:\n+    indices: `tf.Tensor` containing coordinates for the rows and columns to be\n+      multiplied. Must have rank > 1.\n+    values: `tf.Tensor` containing the values to be scaled and added to the\n+      sampled dot product.\n+    dense_shape: `tf.Tensor` defining the dense shape of the output.\n+    mat1: `tf.Tensor` to be multiplied. Must have rank > 1.\n+    mat2: `tf.Tensor` to be multiplied. Must have rank > 1.\n+    beta: Number to be multipled with `values`. Defaults to 1.0.\n+    alpha: Number to be multiplied with the sampled dot product of `mat1` and\n+      `mat2`. Defaults to 1.0.\n+    output_type: the output datatype if needed. Defaults to float32.\n+\n+  Returns:\n+    A tuple of three `tf.Tensor` objects (indices, result, dense_shape) making\n+    up the components of a `SparseTensor` representing the result of the\n+    operation.\n+\n+    result = `alpha` * (`mat1` @ `mat2`) * spy(`indices`) + `beta` * `values`\n \n+    The function `spy(indices)` is the sparsity pattern matrix derived from\n+    `indices`. \n+  \"\"\"\n+  if context.executing_eagerly():\n+    if not isinstance(indices, ops.EagerTensor):\n+      indices = ops.convert_to_tensor(indices)",
        "comment_created_at": "2024-01-08T19:15:14+00:00",
        "comment_author": "cantonios",
        "comment_body": "You shouldn't need to do this - these argument should be converted automatically when you call into tf functions.\r\n\r\nIf you want to guarantee it's a tensor so you can check the `dtype`, you can unconditionally call `convert_to_tensor`.  You can even set a `preferred_dtype` to the `output_dtype` rather than casting. ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1344461449",
    "pr_number": 61242,
    "pr_file": "tensorflow/python/ops/clip_ops.py",
    "created_at": "2023-10-03T17:16:30+00:00",
    "commented_code": "values = ops.convert_to_tensor(\n         t.values if isinstance(t, indexed_slices.IndexedSlices) else t,\n         name=\"t\")\n+    clip_norm = tf.cast(math_ops.maximum(clip_norm, 0),dtype = values.dtype)",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1344461449",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 61242,
        "pr_file": "tensorflow/python/ops/clip_ops.py",
        "discussion_id": "1344461449",
        "commented_code": "@@ -212,6 +213,8 @@ def clip_by_norm(t, clip_norm, axes=None, name=None):\n     values = ops.convert_to_tensor(\n         t.values if isinstance(t, indexed_slices.IndexedSlices) else t,\n         name=\"t\")\n+    clip_norm = tf.cast(math_ops.maximum(clip_norm, 0),dtype = values.dtype)",
        "comment_created_at": "2023-10-03T17:16:30+00:00",
        "comment_author": "cantonios",
        "comment_body": "You won't be able to use `tf.cast`.  I think it's in `math_ops`.",
        "pr_file_module": null
      },
      {
        "comment_id": "1354898281",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 61242,
        "pr_file": "tensorflow/python/ops/clip_ops.py",
        "discussion_id": "1344461449",
        "commented_code": "@@ -212,6 +213,8 @@ def clip_by_norm(t, clip_norm, axes=None, name=None):\n     values = ops.convert_to_tensor(\n         t.values if isinstance(t, indexed_slices.IndexedSlices) else t,\n         name=\"t\")\n+    clip_norm = tf.cast(math_ops.maximum(clip_norm, 0),dtype = values.dtype)",
        "comment_created_at": "2023-10-11T12:37:13+00:00",
        "comment_author": "SuryanarayanaY",
        "comment_body": "Apologies.Yes, It should be `math_ops.cast`.",
        "pr_file_module": null
      }
    ]
  }
]