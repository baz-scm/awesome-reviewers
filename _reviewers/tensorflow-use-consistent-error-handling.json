[
  {
    "discussion_id": "1672249227",
    "pr_number": 66085,
    "pr_file": "tensorflow/core/kernels/mkl/mkl_quantize_op.cc",
    "created_at": "2024-07-10T13:15:07+00:00",
    "commented_code": "OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n     OP_REQUIRES_OK(\n         ctx, ctx->GetAttr(\"ensure_minimum_range\", &ensure_minimum_range_));\n+    if (ctx->HasAttr(\"dtype\")) {\n+      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"dtype\", &dtype_));\n+      if (dtype_ == DT_BFLOAT16) {\n+        OP_REQUIRES(\n+            ctx,\n+            ctx->input_type(0) == DT_BFLOAT16 &&\n+                (mode_ == QUANTIZE_MODE_MIN_FIRST ||\n+                 mode_ == QUANTIZE_MODE_SCALED),\n+            errors::InvalidArgument(\"Input type bfloat16 is supported only \"",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1672249227",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 66085,
        "pr_file": "tensorflow/core/kernels/mkl/mkl_quantize_op.cc",
        "discussion_id": "1672249227",
        "commented_code": "@@ -311,6 +311,20 @@ class MklQuantizeV2Op : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n     OP_REQUIRES_OK(\n         ctx, ctx->GetAttr(\"ensure_minimum_range\", &ensure_minimum_range_));\n+    if (ctx->HasAttr(\"dtype\")) {\n+      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"dtype\", &dtype_));\n+      if (dtype_ == DT_BFLOAT16) {\n+        OP_REQUIRES(\n+            ctx,\n+            ctx->input_type(0) == DT_BFLOAT16 &&\n+                (mode_ == QUANTIZE_MODE_MIN_FIRST ||\n+                 mode_ == QUANTIZE_MODE_SCALED),\n+            errors::InvalidArgument(\"Input type bfloat16 is supported only \"",
        "comment_created_at": "2024-07-10T13:15:07+00:00",
        "comment_author": "penpornk",
        "comment_body": "Could you please use `absl::InvalidArgumentError` instead? We are replacing `tsl::errors` with `absl` ones. (You only need to change the ones in the lines that you touched, existing code is okay.)",
        "pr_file_module": null
      },
      {
        "comment_id": "1674645165",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 66085,
        "pr_file": "tensorflow/core/kernels/mkl/mkl_quantize_op.cc",
        "discussion_id": "1672249227",
        "commented_code": "@@ -311,6 +311,20 @@ class MklQuantizeV2Op : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"axis\", &axis_));\n     OP_REQUIRES_OK(\n         ctx, ctx->GetAttr(\"ensure_minimum_range\", &ensure_minimum_range_));\n+    if (ctx->HasAttr(\"dtype\")) {\n+      OP_REQUIRES_OK(ctx, ctx->GetAttr(\"dtype\", &dtype_));\n+      if (dtype_ == DT_BFLOAT16) {\n+        OP_REQUIRES(\n+            ctx,\n+            ctx->input_type(0) == DT_BFLOAT16 &&\n+                (mode_ == QUANTIZE_MODE_MIN_FIRST ||\n+                 mode_ == QUANTIZE_MODE_SCALED),\n+            errors::InvalidArgument(\"Input type bfloat16 is supported only \"",
        "comment_created_at": "2024-07-11T20:23:30+00:00",
        "comment_author": "mdfaijul",
        "comment_body": "Thanks! Done.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1227020092",
    "pr_number": 60701,
    "pr_file": "tensorflow/compiler/mlir/tosa/transforms/legalize_tfl.cc",
    "created_at": "2023-06-12T17:32:38+00:00",
    "commented_code": "return success();\n }\n \n+LogicalResult ConvertTFLCastOp::matchAndRewrite(\n+    Operation* op, PatternRewriter& rewriter) const {\n+  auto tfl_cast_op = cast<TFL::CastOp>(op);\n+\n+  RankedTensorType input_type =\n+      tfl_cast_op.getInput().getType().dyn_cast<RankedTensorType>();\n+  RankedTensorType output_type =\n+      tfl_cast_op.getOutput().getType().dyn_cast<RankedTensorType>();\n+  // Not a ranked tensor input or output\n+  if (!input_type || !output_type) return failure();",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1227020092",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 60701,
        "pr_file": "tensorflow/compiler/mlir/tosa/transforms/legalize_tfl.cc",
        "discussion_id": "1227020092",
        "commented_code": "@@ -835,6 +836,25 @@ LogicalResult ConvertTFLSignOp::matchAndRewrite(\n   return success();\n }\n \n+LogicalResult ConvertTFLCastOp::matchAndRewrite(\n+    Operation* op, PatternRewriter& rewriter) const {\n+  auto tfl_cast_op = cast<TFL::CastOp>(op);\n+\n+  RankedTensorType input_type =\n+      tfl_cast_op.getInput().getType().dyn_cast<RankedTensorType>();\n+  RankedTensorType output_type =\n+      tfl_cast_op.getOutput().getType().dyn_cast<RankedTensorType>();\n+  // Not a ranked tensor input or output\n+  if (!input_type || !output_type) return failure();",
        "comment_created_at": "2023-06-12T17:32:38+00:00",
        "comment_author": "rsuderman",
        "comment_body": "Instead of `return failure()` please include `notifyMatchFailure` debug statements. It makes failure cases easier to debug.",
        "pr_file_module": null
      },
      {
        "comment_id": "1236211844",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 60701,
        "pr_file": "tensorflow/compiler/mlir/tosa/transforms/legalize_tfl.cc",
        "discussion_id": "1227020092",
        "commented_code": "@@ -835,6 +836,25 @@ LogicalResult ConvertTFLSignOp::matchAndRewrite(\n   return success();\n }\n \n+LogicalResult ConvertTFLCastOp::matchAndRewrite(\n+    Operation* op, PatternRewriter& rewriter) const {\n+  auto tfl_cast_op = cast<TFL::CastOp>(op);\n+\n+  RankedTensorType input_type =\n+      tfl_cast_op.getInput().getType().dyn_cast<RankedTensorType>();\n+  RankedTensorType output_type =\n+      tfl_cast_op.getOutput().getType().dyn_cast<RankedTensorType>();\n+  // Not a ranked tensor input or output\n+  if (!input_type || !output_type) return failure();",
        "comment_created_at": "2023-06-21T02:35:55+00:00",
        "comment_author": "Tai78641",
        "comment_body": "done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1665872160",
    "pr_number": 56525,
    "pr_file": "tensorflow/core/grappler/optimizers/implementation_selector.cc",
    "created_at": "2024-07-04T15:49:38+00:00",
    "commented_code": "}\n \n   DeviceNameUtils::ParsedName parsed_name;\n-  if (!DeviceNameUtils::ParseFullName(node_def->device(), &parsed_name) ||\n-      !parsed_name.has_type) {\n-    return errors::Internal(\"Could not parse device name:\", node_def->device());\n+  if (!node_def->device().empty()) {\n+    if (!DeviceNameUtils::ParseFullName(node_def->device(), &parsed_name) ||\n+        !parsed_name.has_type) {\n+      return errors::Internal(\"Could not parse device name:\",",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1665872160",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 56525,
        "pr_file": "tensorflow/core/grappler/optimizers/implementation_selector.cc",
        "discussion_id": "1665872160",
        "commented_code": "@@ -261,12 +272,37 @@ Status ImplementationSelector::MaybeOptimizeFunctionCall(\n   }\n \n   DeviceNameUtils::ParsedName parsed_name;\n-  if (!DeviceNameUtils::ParseFullName(node_def->device(), &parsed_name) ||\n-      !parsed_name.has_type) {\n-    return errors::Internal(\"Could not parse device name:\", node_def->device());\n+  if (!node_def->device().empty()) {\n+    if (!DeviceNameUtils::ParseFullName(node_def->device(), &parsed_name) ||\n+        !parsed_name.has_type) {\n+      return errors::Internal(\"Could not parse device name:\",",
        "comment_created_at": "2024-07-04T15:49:38+00:00",
        "comment_author": "penpornk",
        "comment_body": "We are using absl for error reporting in new code. Please use `absl::InternalError` instead. Here is an example usage:\r\nhttps://github.com/tensorflow/tensorflow/blob/f79cfa4e6de05c38a589cdbd3560da42ad1af8dd/tensorflow/core/kernels/fft_ops.cc#L731",
        "pr_file_module": null
      },
      {
        "comment_id": "1665914469",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 56525,
        "pr_file": "tensorflow/core/grappler/optimizers/implementation_selector.cc",
        "discussion_id": "1665872160",
        "commented_code": "@@ -261,12 +272,37 @@ Status ImplementationSelector::MaybeOptimizeFunctionCall(\n   }\n \n   DeviceNameUtils::ParsedName parsed_name;\n-  if (!DeviceNameUtils::ParseFullName(node_def->device(), &parsed_name) ||\n-      !parsed_name.has_type) {\n-    return errors::Internal(\"Could not parse device name:\", node_def->device());\n+  if (!node_def->device().empty()) {\n+    if (!DeviceNameUtils::ParseFullName(node_def->device(), &parsed_name) ||\n+        !parsed_name.has_type) {\n+      return errors::Internal(\"Could not parse device name:\",",
        "comment_created_at": "2024-07-04T16:48:24+00:00",
        "comment_author": "API92",
        "comment_body": "Fixed.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1666920552",
    "pr_number": 64651,
    "pr_file": "tensorflow/core/kernels/multinomial_op.cc",
    "created_at": "2024-07-05T15:14:07+00:00",
    "commented_code": "const int num_samples = num_samples_t.scalar<int>()();\n     OP_REQUIRES(ctx, num_samples >= 0,\n                 errors::InvalidArgument(\n-                    \"num_samples should be nonnegative, got \", num_samples));\n-\n-    for (int i = 0; i < 2; i++) {\n-      const int64_t dim = logits_t.dim_size(i);\n-      OP_REQUIRES(ctx, static_cast<int>(dim) == dim,\n-                  errors::InvalidArgument(\n-                      \"logits.shape = \", logits_t.shape().DebugString(),\n-                      \" too large for int\"));\n-    }\n+                    \"num_samples should be non-negative, got \", num_samples));\n+\n     const int batch_size = static_cast<int>(logits_t.dim_size(0));\n     const int num_classes = static_cast<int>(logits_t.dim_size(1));\n+\n+    OP_REQUIRES(ctx, batch_size == logits_t.dim_size(0),\n+                errors::InvalidArgument(\"batch_size cannot exceed max int\"));",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1666920552",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 64651,
        "pr_file": "tensorflow/core/kernels/multinomial_op.cc",
        "discussion_id": "1666920552",
        "commented_code": "@@ -163,17 +163,17 @@ class MultinomialOp : public OpKernel {\n     const int num_samples = num_samples_t.scalar<int>()();\n     OP_REQUIRES(ctx, num_samples >= 0,\n                 errors::InvalidArgument(\n-                    \"num_samples should be nonnegative, got \", num_samples));\n-\n-    for (int i = 0; i < 2; i++) {\n-      const int64_t dim = logits_t.dim_size(i);\n-      OP_REQUIRES(ctx, static_cast<int>(dim) == dim,\n-                  errors::InvalidArgument(\n-                      \"logits.shape = \", logits_t.shape().DebugString(),\n-                      \" too large for int\"));\n-    }\n+                    \"num_samples should be non-negative, got \", num_samples));\n+\n     const int batch_size = static_cast<int>(logits_t.dim_size(0));\n     const int num_classes = static_cast<int>(logits_t.dim_size(1));\n+\n+    OP_REQUIRES(ctx, batch_size == logits_t.dim_size(0),\n+                errors::InvalidArgument(\"batch_size cannot exceed max int\"));",
        "comment_created_at": "2024-07-05T15:14:07+00:00",
        "comment_author": "penpornk",
        "comment_body": "`tsl::errors` is being replaced with `absl` errors. We require that new code use `absl` errors instead. Could you please help change this to `absl::InvalidArgumentError`? Here is an example:\r\nhttps://github.com/tensorflow/tensorflow/blob/b643dcd5dc2e50e6c9d64cb0840de48611b3742f/tensorflow/core/kernels/conv_3d.h#L107-L109\r\n\r\n(You only need to change the lines that you touch in this PR. Existing code in the same file can be left as-is.)",
        "pr_file_module": null
      },
      {
        "comment_id": "1671609786",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 64651,
        "pr_file": "tensorflow/core/kernels/multinomial_op.cc",
        "discussion_id": "1666920552",
        "commented_code": "@@ -163,17 +163,17 @@ class MultinomialOp : public OpKernel {\n     const int num_samples = num_samples_t.scalar<int>()();\n     OP_REQUIRES(ctx, num_samples >= 0,\n                 errors::InvalidArgument(\n-                    \"num_samples should be nonnegative, got \", num_samples));\n-\n-    for (int i = 0; i < 2; i++) {\n-      const int64_t dim = logits_t.dim_size(i);\n-      OP_REQUIRES(ctx, static_cast<int>(dim) == dim,\n-                  errors::InvalidArgument(\n-                      \"logits.shape = \", logits_t.shape().DebugString(),\n-                      \" too large for int\"));\n-    }\n+                    \"num_samples should be non-negative, got \", num_samples));\n+\n     const int batch_size = static_cast<int>(logits_t.dim_size(0));\n     const int num_classes = static_cast<int>(logits_t.dim_size(1));\n+\n+    OP_REQUIRES(ctx, batch_size == logits_t.dim_size(0),\n+                errors::InvalidArgument(\"batch_size cannot exceed max int\"));",
        "comment_created_at": "2024-07-10T04:50:02+00:00",
        "comment_author": "redwrasse",
        "comment_body": "Happy to. I updated all error messages in `multinomial_op.cc` to use the `absl::InvalidArgumentError` construct.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1513130576",
    "pr_number": 63106,
    "pr_file": "tensorflow/core/kernels/mkl/mkl_conv_ops.h",
    "created_at": "2024-03-05T16:27:51+00:00",
    "commented_code": "OP_REQUIRES(context, FormatFromString(data_format_str, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n     OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &strides_));\n+    if (strides_.size() < 4) {\n+        return errors::InvalidArgument(\"strides dimensions must not be < 4. \");",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1513130576",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 63106,
        "pr_file": "tensorflow/core/kernels/mkl/mkl_conv_ops.h",
        "discussion_id": "1513130576",
        "commented_code": "@@ -641,6 +641,9 @@ class MklConvBackpropCommonOp : public OpKernel {\n     OP_REQUIRES(context, FormatFromString(data_format_str, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n     OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &strides_));\n+    if (strides_.size() < 4) {\n+        return errors::InvalidArgument(\"strides dimensions must not be < 4. \");",
        "comment_created_at": "2024-03-05T16:27:51+00:00",
        "comment_author": "mihaimaruseac",
        "comment_body": "It seems we no longer need to use TF wrappers around errors:\r\n\r\n> Use absl::AbortedError etc. instead of tsl::errors::Aborted. You will need to write explicitly the e.g. absl::StrCat. This is required to get correct absl::SourceLocation propagation within Google.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1439670241",
    "pr_number": 62648,
    "pr_file": "tensorflow/core/kernels/mkl/mkl_tmp_ops.cc",
    "created_at": "2024-01-02T17:37:33+00:00",
    "commented_code": "namespace tensorflow {\n \n // This file contains temporary registrations for some of the Eigen CPU backend\n-// operators for BFloat16 type. The kernel registered for all these ops simply\n-// raises an error. We do this so that MKL graph pass can rewrite these ops into\n-// corresponding MKL ops. Without such registrations, Placer component in\n-// TensorFlow fails because Eigen CPU backend does not support these ops in\n-// BFloat16 type.\n+// operators for Float32, BFloat16 and Half types. The kernels registered for\n+// all these ops simply raise an error. We do this so that MKL graph pass can\n+// rewrite these ops into corresponding MKL ops. Without such registrations,\n+// Placer component in TensorFlow fails because Eigen CPU backend does not\n+// support these ops for the above types.\n \n namespace {\n-class RaiseBfloat16Error : public OpKernel {\n+template <typename T>\n+class RaiseError : public OpKernel {\n  public:\n-  explicit RaiseBfloat16Error(OpKernelConstruction* context)\n-      : OpKernel(context) {\n+  explicit RaiseError(OpKernelConstruction* context) : OpKernel(context) {\n     OP_REQUIRES(context, false,\n-                errors::InvalidArgument(\"Op does not support bfloat16 inputs\"));\n+                errors::InvalidArgument(absl::StrCat(",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1439670241",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 62648,
        "pr_file": "tensorflow/core/kernels/mkl/mkl_tmp_ops.cc",
        "discussion_id": "1439670241",
        "commented_code": "@@ -21,34 +21,48 @@ limitations under the License.\n namespace tensorflow {\n \n // This file contains temporary registrations for some of the Eigen CPU backend\n-// operators for BFloat16 type. The kernel registered for all these ops simply\n-// raises an error. We do this so that MKL graph pass can rewrite these ops into\n-// corresponding MKL ops. Without such registrations, Placer component in\n-// TensorFlow fails because Eigen CPU backend does not support these ops in\n-// BFloat16 type.\n+// operators for Float32, BFloat16 and Half types. The kernels registered for\n+// all these ops simply raise an error. We do this so that MKL graph pass can\n+// rewrite these ops into corresponding MKL ops. Without such registrations,\n+// Placer component in TensorFlow fails because Eigen CPU backend does not\n+// support these ops for the above types.\n \n namespace {\n-class RaiseBfloat16Error : public OpKernel {\n+template <typename T>\n+class RaiseError : public OpKernel {\n  public:\n-  explicit RaiseBfloat16Error(OpKernelConstruction* context)\n-      : OpKernel(context) {\n+  explicit RaiseError(OpKernelConstruction* context) : OpKernel(context) {\n     OP_REQUIRES(context, false,\n-                errors::InvalidArgument(\"Op does not support bfloat16 inputs\"));\n+                errors::InvalidArgument(absl::StrCat(",
        "comment_created_at": "2024-01-02T17:37:33+00:00",
        "comment_author": "penpornk",
        "comment_body": "Please use `absl::InvalidArgumentError` instead.\r\n```suggestion\r\n                absl::InvalidArgumentError(absl::StrCat(\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1439694303",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 62648,
        "pr_file": "tensorflow/core/kernels/mkl/mkl_tmp_ops.cc",
        "discussion_id": "1439670241",
        "commented_code": "@@ -21,34 +21,48 @@ limitations under the License.\n namespace tensorflow {\n \n // This file contains temporary registrations for some of the Eigen CPU backend\n-// operators for BFloat16 type. The kernel registered for all these ops simply\n-// raises an error. We do this so that MKL graph pass can rewrite these ops into\n-// corresponding MKL ops. Without such registrations, Placer component in\n-// TensorFlow fails because Eigen CPU backend does not support these ops in\n-// BFloat16 type.\n+// operators for Float32, BFloat16 and Half types. The kernels registered for\n+// all these ops simply raise an error. We do this so that MKL graph pass can\n+// rewrite these ops into corresponding MKL ops. Without such registrations,\n+// Placer component in TensorFlow fails because Eigen CPU backend does not\n+// support these ops for the above types.\n \n namespace {\n-class RaiseBfloat16Error : public OpKernel {\n+template <typename T>\n+class RaiseError : public OpKernel {\n  public:\n-  explicit RaiseBfloat16Error(OpKernelConstruction* context)\n-      : OpKernel(context) {\n+  explicit RaiseError(OpKernelConstruction* context) : OpKernel(context) {\n     OP_REQUIRES(context, false,\n-                errors::InvalidArgument(\"Op does not support bfloat16 inputs\"));\n+                errors::InvalidArgument(absl::StrCat(",
        "comment_created_at": "2024-01-02T18:08:18+00:00",
        "comment_author": "bhavani-subramanian",
        "comment_body": "Fixed here and in other files modified by this PR.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1164468941",
    "pr_number": 56792,
    "pr_file": "tensorflow/core/kernels/mkl/mkl_kernel_util.h",
    "created_at": "2023-04-12T17:57:15+00:00",
    "commented_code": "*tensor_min = min();\n     *tensor_max = max();\n   }\n+\n+  // This utlity function mimics Quantization of float/bfloat16 tensor with\n+  // oneDNN backend QuantizeV2 operation. Since the op signature requires min\n+  // and max values to be in float type, min_tensor and max_tensor should have\n+  // their dtype set to DT_FLOAT.\n+  template <typename T>\n+  static void GetQuantizationTensors(const Tensor& input, Tensor* output,\n+                                     DataType out_type, const string mode,\n+                                     Tensor* min_tensor, Tensor* max_tensor) {\n+    CHECK_EQ(min_tensor->dtype(), DT_FLOAT);\n+    CHECK_EQ(max_tensor->dtype(), DT_FLOAT);",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1164468941",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 56792,
        "pr_file": "tensorflow/core/kernels/mkl/mkl_kernel_util.h",
        "discussion_id": "1164468941",
        "commented_code": "@@ -44,6 +44,33 @@ class MklTestingUtil {\n     *tensor_min = min();\n     *tensor_max = max();\n   }\n+\n+  // This utlity function mimics Quantization of float/bfloat16 tensor with\n+  // oneDNN backend QuantizeV2 operation. Since the op signature requires min\n+  // and max values to be in float type, min_tensor and max_tensor should have\n+  // their dtype set to DT_FLOAT.\n+  template <typename T>\n+  static void GetQuantizationTensors(const Tensor& input, Tensor* output,\n+                                     DataType out_type, const string mode,\n+                                     Tensor* min_tensor, Tensor* max_tensor) {\n+    CHECK_EQ(min_tensor->dtype(), DT_FLOAT);\n+    CHECK_EQ(max_tensor->dtype(), DT_FLOAT);",
        "comment_created_at": "2023-04-12T17:57:15+00:00",
        "comment_author": "penpornk",
        "comment_body": "We don't use CHECKs in new code anymore. Could you please make this function return an error status when the conditions fail?",
        "pr_file_module": null
      },
      {
        "comment_id": "1473591787",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 56792,
        "pr_file": "tensorflow/core/kernels/mkl/mkl_kernel_util.h",
        "discussion_id": "1164468941",
        "commented_code": "@@ -44,6 +44,33 @@ class MklTestingUtil {\n     *tensor_min = min();\n     *tensor_max = max();\n   }\n+\n+  // This utlity function mimics Quantization of float/bfloat16 tensor with\n+  // oneDNN backend QuantizeV2 operation. Since the op signature requires min\n+  // and max values to be in float type, min_tensor and max_tensor should have\n+  // their dtype set to DT_FLOAT.\n+  template <typename T>\n+  static void GetQuantizationTensors(const Tensor& input, Tensor* output,\n+                                     DataType out_type, const string mode,\n+                                     Tensor* min_tensor, Tensor* max_tensor) {\n+    CHECK_EQ(min_tensor->dtype(), DT_FLOAT);\n+    CHECK_EQ(max_tensor->dtype(), DT_FLOAT);",
        "comment_created_at": "2024-01-31T23:06:30+00:00",
        "comment_author": "mdfaijul",
        "comment_body": "Corrected in the last commit.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1569087282",
    "pr_number": 65939,
    "pr_file": "tensorflow/lite/experimental/shlo/ops/dot_general.cc",
    "created_at": "2024-04-17T15:57:00+00:00",
    "commented_code": "+/* Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"tensorflow/lite/experimental/shlo/ops/dot_general.h\"\n+\n+#include \"absl/status/status.h\"\n+#include \"tensorflow/lite/experimental/shlo/data_type.h\"\n+#include \"tensorflow/lite/experimental/shlo/dispatch.h\"\n+#include \"tensorflow/lite/experimental/shlo/quantize.h\"\n+#include \"tensorflow/lite/experimental/shlo/quantized_tensor_element_type.h\"\n+#include \"tensorflow/lite/experimental/shlo/shape.h\"\n+#include \"tensorflow/lite/experimental/shlo/tensor.h\"\n+\n+namespace shlo_ref {\n+\n+absl::Status CheckParameters(const Tensor& lhs, const Tensor& rhs,\n+                             const Tensor& lhs_batching_dimensions,\n+                             const Tensor& rhs_batching_dimensions,\n+                             const Tensor& lhs_contracting_dimensions,\n+                             const Tensor& rhs_contracting_dimensions,\n+                             Tensor& output) {\n+  const int32_t* lhsb = lhs_batching_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* rhsb = rhs_batching_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* lhsc = lhs_contracting_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* rhsc = rhs_contracting_dimensions.GetDataAs<DataType::kSI32>();\n+  const DimensionSize lhsb_size = lhs_batching_dimensions.NumElements();\n+  const DimensionSize rhsb_size = rhs_batching_dimensions.NumElements();\n+  const DimensionSize lhsc_size = lhs_contracting_dimensions.NumElements();\n+  const DimensionSize rhsc_size = rhs_contracting_dimensions.NumElements();\n+  const size_t lhs_rank = lhs.Rank();\n+  const size_t rhs_rank = rhs.Rank();\n+  const size_t output_rank = output.Rank();\n+  std::vector<size_t> lhs_result_dims;\n+  std::vector<size_t> rhs_result_dims;\n+  std::vector<size_t> output_shape_check;\n+\n+  if (lhsb_size != rhsb_size) {\n+    return absl::FailedPreconditionError(\n+        \"stablehlo.dot_general: Size of lhs_batching_dimensions and \"\n+        \"rhs_batching_dimensions must be same.\");\n+  } else if (lhsc_size != rhsc_size) {\n+    return absl::FailedPreconditionError(\n+        \"stablehlo.dot_general: Size of lhs_contracting_dimensions and \"\n+        \"rhs_contracting_dimensions must be same.\");\n+  }\n+  for (DimensionSize i = 0; i < lhsb_size; ++i) {\n+    for (DimensionSize j = 0; j < lhsc_size; ++j) {\n+      if (lhsb[i] == lhsc[j]) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: The lhs_batching_dimensions and \"\n+            \"lhs_contracting_dimensions must be unique.\");\n+      }\n+    }\n+  }\n+  for (DimensionSize i = 0; i < rhsb_size; ++i) {\n+    for (DimensionSize j = 0; j < rhsc_size; ++j) {\n+      if (rhsb[i] == rhsc[j]) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: The rhs_batching_dimensions and \"\n+            \"rhs_contracting_dimensions must be unique.\");\n+      }\n+    }\n+  }\n+  for (DimensionSize i = 0; i < lhsb_size; ++i) {\n+    if (lhsb[i] >= lhs_rank || lhsb[i] < 0) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid lhs_batching_dimensions index.\");\n+    }\n+    output_shape_check.push_back(lhs.shape().Dim(lhsb[i]));\n+  }\n+  for (DimensionSize i = 0; i < lhsc_size; ++i) {\n+    if (lhsc[i] >= lhs_rank || lhsc[i] < 0) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid lhs_contracting_dimensions index.\");\n+    }\n+  }\n+  for (DimensionSize i = 0; i < rhsb_size; ++i) {\n+    if (rhsb[i] >= rhs_rank || rhsb[i] < 0) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid rhs_batching_dimensions index.\");\n+    }\n+  }\n+  for (DimensionSize i = 0; i < rhsc_size; ++i) {\n+    if (rhsc[i] >= rhs_rank || rhsc[i] < 0) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid rhs_contracting_dimensions index.\");\n+    }\n+  }\n+  for (DimensionSize i = 0; i < lhsb_size; ++i) {\n+    if (lhs.shape().Dim(lhsb[i]) != rhs.shape().Dim(rhsb[i])) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: The lhs and rhs tensors should have same \"\n+          \"batch dimensions.\");\n+    }\n+  }\n+  for (DimensionSize i = 0; i < lhsc_size; ++i) {\n+    if (lhs.shape().Dim(lhsc[i]) != rhs.shape().Dim(rhsc[i])) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: The lhs and rhs tensors should have same \"\n+          \"contracting dimensions.\");\n+    }\n+  }\n+  for (size_t i = 0; i < lhs_rank; ++i) {\n+    if ((std::count(lhsb, lhsb + lhsb_size, i) == 0) &&\n+        (std::count(lhsc, lhsc + lhsc_size, i) == 0)) {\n+      lhs_result_dims.push_back(i);\n+    }\n+  }\n+  for (size_t i = 0; i < rhs_rank; ++i) {\n+    if ((std::count(rhsb, rhsb + rhsb_size, i) == 0) &&\n+        (std::count(rhsc, rhsc + rhsc_size, i) == 0)) {\n+      rhs_result_dims.push_back(i);\n+    }\n+  }\n+  for (size_t i = 0; i < lhs_result_dims.size(); ++i) {\n+    output_shape_check.push_back(lhs.shape().Dim(lhs_result_dims[i]));\n+  }\n+  for (size_t i = 0; i < rhs_result_dims.size(); ++i) {\n+    output_shape_check.push_back(rhs.shape().Dim(rhs_result_dims[i]));\n+  }\n+  for (size_t i = 0; i < output_rank; ++i) {\n+    if (output.shape().Dim(i) != output_shape_check[i]) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid output shape.\");\n+    }\n+  }\n+  if (lhs.IsPerAxisQuantized()) {\n+    return absl::FailedPreconditionError(\n+        \"stablehlo.dot_general: The lhs tensor cannot be per-axis quantized.\");\n+  }\n+  if (!lhs.IsPerTensorQuantized() && !rhs.IsQuantized() &&\n+      lhs.tensor_element_type() != rhs.tensor_element_type()) {\n+    return absl::FailedPreconditionError(\n+        \"stablehlo.dot_general: For non-quantized tensors the element type of \"\n+        \"lhs and rhs must be the same.\");\n+  }\n+  if (lhs.IsPerTensorQuantized()) {\n+    if (rhs.IsQuantized() && !output.IsQuantized()) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: If lhs and rhs are quantized tensors, than \"\n+          \"the output tensor should also be quantized.\");\n+    } else if (lhs.StorageType() != rhs.StorageType()) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: If the lhs and rhs are quantized tensors, \"\n+          \"than they should have the same storage type.\");\n+    } else if (rhs.IsPerTensorQuantized()) {\n+      if (!output.IsPerTensorQuantized()) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: If lhs and rhs are per-tensor quantized \"\n+            \"than output should also be per-tensor quantized.\");\n+      }\n+      if (lhs.quantized_per_tensor_element_type().ExpressedType() ==\n+          rhs.quantized_per_tensor_element_type().ExpressedType()) {\n+        if (lhs.quantized_per_tensor_element_type().ExpressedType() !=\n+            output.quantized_per_tensor_element_type().ExpressedType()) {\n+          return absl::FailedPreconditionError(\n+              \"stablehlo.dot_general: The expressed_type of output tensor must \"\n+              \"be the same as the expressed_type of lhs and rhs tensors.\");\n+        }\n+      }\n+      auto check_zero_point_value_is_zero =\n+          [](auto zero_point) -> bool {\n+        if (std::holds_alternative<I4>(zero_point)) {\n+          return std::get<I4>(zero_point) == static_cast<I4>(0);\n+        } else if (std::holds_alternative<int8_t>(zero_point)) {\n+          return std::get<int8_t>(zero_point) == static_cast<int8_t>(0);\n+        } else if (std::holds_alternative<int16_t>(zero_point)) {\n+          return std::get<int16_t>(zero_point) == static_cast<int16_t>(0);\n+        }\n+        return false;\n+      };\n+      if (!check_zero_point_value_is_zero(\n+              rhs.quantized_per_tensor_element_type().ZeroPoint())) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: The rhs per-tensor should have zero points \"\n+            \"as 0.\");\n+      }\n+    } else if (rhs.IsPerAxisQuantized()) {\n+      if (output.IsPerTensorQuantized()) {\n+        if (lhs.quantized_per_tensor_element_type().ExpressedType() ==\n+            rhs.quantized_per_axis_element_type().ExpressedType()) {\n+          if (lhs.quantized_per_tensor_element_type().ExpressedType() !=\n+              output.quantized_per_tensor_element_type().ExpressedType()) {\n+            return absl::FailedPreconditionError(\n+                \"stablehlo.dot_general: The expressed_type of output must be \"\n+                \"the same as the expressed_type of lhs and rhs.\");\n+          }\n+        }\n+      } else if (output.IsPerAxisQuantized()) {\n+        if (lhs.quantized_per_tensor_element_type().ExpressedType() ==\n+            rhs.quantized_per_axis_element_type().ExpressedType()) {\n+          if (lhs.quantized_per_tensor_element_type().ExpressedType() !=\n+              output.quantized_per_axis_element_type().ExpressedType()) {\n+            return absl::FailedPreconditionError(\n+                \"stablehlo.dot_general: The expressed_type of output must be \"\n+                \"the same as the expressed_type of lhs and rhs.\");\n+          }\n+        }\n+      }\n+      auto check_zero_points_values_are_zero =\n+          [](auto zero_points) -> bool {\n+        if (std::holds_alternative<absl::InlinedVector<I4, 8>>(zero_points)) {\n+          auto zero_point_value =\n+              std::get<absl::InlinedVector<I4, 8>>(zero_points);\n+          return std::all_of(\n+              zero_point_value.begin(), zero_point_value.end(),\n+              [](I4 value) { return value == static_cast<I4>(0); });\n+        } else if (std::holds_alternative<absl::InlinedVector<int8_t, 8>>(\n+                       zero_points)) {\n+          auto zero_point_value =\n+              std::get<absl::InlinedVector<int8_t, 8>>(zero_points);\n+          return std::all_of(\n+              zero_point_value.begin(), zero_point_value.end(),\n+              [](int8_t value) { return value == static_cast<int8_t>(0); });\n+        } else if (std::holds_alternative<absl::InlinedVector<int16_t, 8>>(\n+                       zero_points)) {\n+          auto zero_point_value =\n+              std::get<absl::InlinedVector<int16_t, 8>>(zero_points);\n+          return std::all_of(\n+              zero_point_value.begin(), zero_point_value.end(),\n+              [](int16_t value) { return value == static_cast<int16_t>(0); });\n+        }\n+        return false;\n+      };\n+      if (!check_zero_points_values_are_zero(\n+              rhs.quantized_per_axis_element_type().ZeroPoints())) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: The rhs per-axis should have zero points \"\n+            \"as 0.\");\n+      }\n+    } else if (rhs.IsPerAxisQuantized()) {\n+      for (DimensionSize i = 0; i < rhsc_size; ++i) {\n+        if (rhsc[i] ==\n+                rhs.quantized_per_axis_element_type().QuantizedDimension() ||\n+            rhsb[i] ==\n+                rhs.quantized_per_axis_element_type().QuantizedDimension()) {\n+          return absl::FailedPreconditionError(\n+              \"stablehlo.dot_general: If the rhs is per-axis quantized than \"\n+              \"the quantization_dimensions of rhs should not be in \"\n+              \"rhs_contracting_dimensions and rhs_batching_dimensions.\");\n+        }\n+      }\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n+template <DataType storage_type>\n+absl::Status EvaluateImpl(DotGeneralOp& op, const Tensor& lhs,\n+                          const Tensor& rhs,\n+                          const Tensor& lhs_batching_dimensions,\n+                          const Tensor& rhs_batching_dimensions,\n+                          const Tensor& lhs_contracting_dimensions,\n+                          const Tensor& rhs_contracting_dimensions,\n+                          Tensor& output) {\n+  using StorageT = StorageType<storage_type>;\n+  const StorageT* lhs_data = lhs.GetDataAs<storage_type>();\n+  const StorageT* rhs_data = rhs.GetDataAs<storage_type>();\n+  StorageT* output_data = output.GetDataAs<storage_type>();\n+  const size_t lhs_size = lhs.NumElements();\n+  const DimensionSize rhs_size = rhs.NumElements();\n+  const DimensionSize output_size = output.NumElements();\n+  const size_t lhs_rank = lhs.Rank();\n+  const size_t rhs_rank = rhs.Rank();\n+  const size_t output_rank = output.Rank();\n+\n+  const int32_t* lhs_batching_dimensions_data =\n+      lhs_batching_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* rhs_batching_dimensions_data =\n+      rhs_batching_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* lhs_contracting_dimensions_data =\n+      lhs_contracting_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* rhs_contracting_dimensions_data =\n+      rhs_contracting_dimensions.GetDataAs<DataType::kSI32>();\n+  const DimensionSize lhsb_size = lhs_batching_dimensions.NumElements();\n+  const DimensionSize lhsc_size = lhs_contracting_dimensions.NumElements();\n+  const DimensionSize rhsb_size = rhs_batching_dimensions.NumElements();\n+  const DimensionSize rhsc_size = rhs_contracting_dimensions.NumElements();\n+\n+  // function to generate indices for output\n+  auto GenerateIndices = [&](size_t index) -> void {\n+    size_t rank = op.output_shape.size();\n+    size_t divisor = 1;\n+    for (size_t i = 0, j = rank - 1; i < rank; ++i, --j) {\n+      op.output_index[j] = (index / divisor) % op.output_shape[j];\n+      divisor *= op.output_shape[j];\n+    }\n+  };\n+  // function to incremement lhs and rhs indices\n+  auto IncrementIndices = [&]() -> bool {\n+    if (lhsc_size == 0) return false;\n+    for (DimensionSize i = lhsc_size - 1; i >= 0; --i) {\n+      op.lhs_index[lhs_contracting_dimensions_data[i]]++;\n+      op.rhs_index[rhs_contracting_dimensions_data[i]]++;\n+      if (op.lhs_index[lhs_contracting_dimensions_data[i]] <\n+          lhs.shape().Dim(lhs_contracting_dimensions_data[i]))\n+        return true;\n+      if (i == 0) return false;\n+      op.lhs_index[lhs_contracting_dimensions_data[i]] = 0;\n+      op.rhs_index[rhs_contracting_dimensions_data[i]] = 0;\n+    }\n+    return true;\n+  };\n+  // pre compute helper for lhs and rhs indices\n+  DimensionSize lhs_dim_accumulator = 1, rhs_dim_accumulator = 1;\n+  for (size_t i = 0; i < lhs_rank; ++i) {\n+    lhs_dim_accumulator *= lhs.shape().Dim(i);\n+    op.lhs_index_helper[i] = lhs_size / lhs_dim_accumulator;\n+  }\n+  for (size_t i = 0; i < rhs_rank; ++i) {\n+    rhs_dim_accumulator *= rhs.shape().Dim(i);\n+    op.rhs_index_helper[i] = rhs_size / rhs_dim_accumulator;\n+  }\n+\n+  StorageT output_element(0);\n+  DimensionSize lhs_element_index = 0, rhs_element_index = 0;\n+  for (DimensionSize k = 0; k < output_size; ++k, ++output_data) {\n+    GenerateIndices(k);\n+    std::fill(op.lhs_index.begin(), op.lhs_index.end(), 0);\n+    std::fill(op.rhs_index.begin(), op.rhs_index.end(), 0);\n+    size_t result_dim = 0;\n+    for (size_t i = 0; i < lhsb_size; ++i, ++result_dim) {\n+      op.lhs_index[lhs_batching_dimensions_data[i]] =\n+          op.output_index[result_dim];\n+      op.rhs_index[rhs_batching_dimensions_data[i]] =\n+          op.output_index[result_dim];\n+    }\n+    for (size_t i = 0; i < op.lhs_result_dims.size(); ++i, ++result_dim) {\n+      op.lhs_index[op.lhs_result_dims[i]] = op.output_index[result_dim];\n+    }\n+    for (size_t i = 0; i < op.rhs_result_dims.size(); ++i, ++result_dim) {\n+      op.rhs_index[op.rhs_result_dims[i]] = op.output_index[result_dim];\n+    }\n+    output_element = 0;\n+    while (true) {\n+      lhs_element_index = 0;\n+      rhs_element_index = 0;\n+      for (size_t i = 0; i < lhs_rank; ++i) {\n+        lhs_element_index += op.lhs_index[i] * op.lhs_index_helper[i];\n+      }\n+      for (size_t i = 0; i < rhs_rank; ++i) {\n+        rhs_element_index += op.rhs_index[i] * op.rhs_index_helper[i];\n+      }\n+      output_element +=\n+          lhs_data[lhs_element_index] * rhs_data[rhs_element_index];\n+      if (!IncrementIndices()) {\n+        break;\n+      }\n+    }\n+    *output_data = output_element;\n+  }\n+  return absl::OkStatus();\n+}\n+\n+DotGeneralOp Create(DotGeneralOp::Attributes attributes) {\n+  return {.attributes = attributes};\n+}\n+\n+absl::Status Prepare(DotGeneralOp& op, const Tensor& lhs, const Tensor& rhs,\n+                     Tensor& output) {\n+  if (absl::Status status =\n+          CheckParameters(lhs, rhs, op.attributes.lhs_batching_dimensions,\n+                          op.attributes.rhs_batching_dimensions,\n+                          op.attributes.lhs_contracting_dimensions,\n+                          op.attributes.rhs_contracting_dimensions, output);\n+      !status.ok()) {\n+    return status;\n+  }",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1569087282",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 65939,
        "pr_file": "tensorflow/lite/experimental/shlo/ops/dot_general.cc",
        "discussion_id": "1569087282",
        "commented_code": "@@ -0,0 +1,441 @@\n+/* Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"tensorflow/lite/experimental/shlo/ops/dot_general.h\"\n+\n+#include \"absl/status/status.h\"\n+#include \"tensorflow/lite/experimental/shlo/data_type.h\"\n+#include \"tensorflow/lite/experimental/shlo/dispatch.h\"\n+#include \"tensorflow/lite/experimental/shlo/quantize.h\"\n+#include \"tensorflow/lite/experimental/shlo/quantized_tensor_element_type.h\"\n+#include \"tensorflow/lite/experimental/shlo/shape.h\"\n+#include \"tensorflow/lite/experimental/shlo/tensor.h\"\n+\n+namespace shlo_ref {\n+\n+absl::Status CheckParameters(const Tensor& lhs, const Tensor& rhs,\n+                             const Tensor& lhs_batching_dimensions,\n+                             const Tensor& rhs_batching_dimensions,\n+                             const Tensor& lhs_contracting_dimensions,\n+                             const Tensor& rhs_contracting_dimensions,\n+                             Tensor& output) {\n+  const int32_t* lhsb = lhs_batching_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* rhsb = rhs_batching_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* lhsc = lhs_contracting_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* rhsc = rhs_contracting_dimensions.GetDataAs<DataType::kSI32>();\n+  const DimensionSize lhsb_size = lhs_batching_dimensions.NumElements();\n+  const DimensionSize rhsb_size = rhs_batching_dimensions.NumElements();\n+  const DimensionSize lhsc_size = lhs_contracting_dimensions.NumElements();\n+  const DimensionSize rhsc_size = rhs_contracting_dimensions.NumElements();\n+  const size_t lhs_rank = lhs.Rank();\n+  const size_t rhs_rank = rhs.Rank();\n+  const size_t output_rank = output.Rank();\n+  std::vector<size_t> lhs_result_dims;\n+  std::vector<size_t> rhs_result_dims;\n+  std::vector<size_t> output_shape_check;\n+\n+  if (lhsb_size != rhsb_size) {\n+    return absl::FailedPreconditionError(\n+        \"stablehlo.dot_general: Size of lhs_batching_dimensions and \"\n+        \"rhs_batching_dimensions must be same.\");\n+  } else if (lhsc_size != rhsc_size) {\n+    return absl::FailedPreconditionError(\n+        \"stablehlo.dot_general: Size of lhs_contracting_dimensions and \"\n+        \"rhs_contracting_dimensions must be same.\");\n+  }\n+  for (DimensionSize i = 0; i < lhsb_size; ++i) {\n+    for (DimensionSize j = 0; j < lhsc_size; ++j) {\n+      if (lhsb[i] == lhsc[j]) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: The lhs_batching_dimensions and \"\n+            \"lhs_contracting_dimensions must be unique.\");\n+      }\n+    }\n+  }\n+  for (DimensionSize i = 0; i < rhsb_size; ++i) {\n+    for (DimensionSize j = 0; j < rhsc_size; ++j) {\n+      if (rhsb[i] == rhsc[j]) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: The rhs_batching_dimensions and \"\n+            \"rhs_contracting_dimensions must be unique.\");\n+      }\n+    }\n+  }\n+  for (DimensionSize i = 0; i < lhsb_size; ++i) {\n+    if (lhsb[i] >= lhs_rank || lhsb[i] < 0) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid lhs_batching_dimensions index.\");\n+    }\n+    output_shape_check.push_back(lhs.shape().Dim(lhsb[i]));\n+  }\n+  for (DimensionSize i = 0; i < lhsc_size; ++i) {\n+    if (lhsc[i] >= lhs_rank || lhsc[i] < 0) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid lhs_contracting_dimensions index.\");\n+    }\n+  }\n+  for (DimensionSize i = 0; i < rhsb_size; ++i) {\n+    if (rhsb[i] >= rhs_rank || rhsb[i] < 0) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid rhs_batching_dimensions index.\");\n+    }\n+  }\n+  for (DimensionSize i = 0; i < rhsc_size; ++i) {\n+    if (rhsc[i] >= rhs_rank || rhsc[i] < 0) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid rhs_contracting_dimensions index.\");\n+    }\n+  }\n+  for (DimensionSize i = 0; i < lhsb_size; ++i) {\n+    if (lhs.shape().Dim(lhsb[i]) != rhs.shape().Dim(rhsb[i])) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: The lhs and rhs tensors should have same \"\n+          \"batch dimensions.\");\n+    }\n+  }\n+  for (DimensionSize i = 0; i < lhsc_size; ++i) {\n+    if (lhs.shape().Dim(lhsc[i]) != rhs.shape().Dim(rhsc[i])) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: The lhs and rhs tensors should have same \"\n+          \"contracting dimensions.\");\n+    }\n+  }\n+  for (size_t i = 0; i < lhs_rank; ++i) {\n+    if ((std::count(lhsb, lhsb + lhsb_size, i) == 0) &&\n+        (std::count(lhsc, lhsc + lhsc_size, i) == 0)) {\n+      lhs_result_dims.push_back(i);\n+    }\n+  }\n+  for (size_t i = 0; i < rhs_rank; ++i) {\n+    if ((std::count(rhsb, rhsb + rhsb_size, i) == 0) &&\n+        (std::count(rhsc, rhsc + rhsc_size, i) == 0)) {\n+      rhs_result_dims.push_back(i);\n+    }\n+  }\n+  for (size_t i = 0; i < lhs_result_dims.size(); ++i) {\n+    output_shape_check.push_back(lhs.shape().Dim(lhs_result_dims[i]));\n+  }\n+  for (size_t i = 0; i < rhs_result_dims.size(); ++i) {\n+    output_shape_check.push_back(rhs.shape().Dim(rhs_result_dims[i]));\n+  }\n+  for (size_t i = 0; i < output_rank; ++i) {\n+    if (output.shape().Dim(i) != output_shape_check[i]) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid output shape.\");\n+    }\n+  }\n+  if (lhs.IsPerAxisQuantized()) {\n+    return absl::FailedPreconditionError(\n+        \"stablehlo.dot_general: The lhs tensor cannot be per-axis quantized.\");\n+  }\n+  if (!lhs.IsPerTensorQuantized() && !rhs.IsQuantized() &&\n+      lhs.tensor_element_type() != rhs.tensor_element_type()) {\n+    return absl::FailedPreconditionError(\n+        \"stablehlo.dot_general: For non-quantized tensors the element type of \"\n+        \"lhs and rhs must be the same.\");\n+  }\n+  if (lhs.IsPerTensorQuantized()) {\n+    if (rhs.IsQuantized() && !output.IsQuantized()) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: If lhs and rhs are quantized tensors, than \"\n+          \"the output tensor should also be quantized.\");\n+    } else if (lhs.StorageType() != rhs.StorageType()) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: If the lhs and rhs are quantized tensors, \"\n+          \"than they should have the same storage type.\");\n+    } else if (rhs.IsPerTensorQuantized()) {\n+      if (!output.IsPerTensorQuantized()) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: If lhs and rhs are per-tensor quantized \"\n+            \"than output should also be per-tensor quantized.\");\n+      }\n+      if (lhs.quantized_per_tensor_element_type().ExpressedType() ==\n+          rhs.quantized_per_tensor_element_type().ExpressedType()) {\n+        if (lhs.quantized_per_tensor_element_type().ExpressedType() !=\n+            output.quantized_per_tensor_element_type().ExpressedType()) {\n+          return absl::FailedPreconditionError(\n+              \"stablehlo.dot_general: The expressed_type of output tensor must \"\n+              \"be the same as the expressed_type of lhs and rhs tensors.\");\n+        }\n+      }\n+      auto check_zero_point_value_is_zero =\n+          [](auto zero_point) -> bool {\n+        if (std::holds_alternative<I4>(zero_point)) {\n+          return std::get<I4>(zero_point) == static_cast<I4>(0);\n+        } else if (std::holds_alternative<int8_t>(zero_point)) {\n+          return std::get<int8_t>(zero_point) == static_cast<int8_t>(0);\n+        } else if (std::holds_alternative<int16_t>(zero_point)) {\n+          return std::get<int16_t>(zero_point) == static_cast<int16_t>(0);\n+        }\n+        return false;\n+      };\n+      if (!check_zero_point_value_is_zero(\n+              rhs.quantized_per_tensor_element_type().ZeroPoint())) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: The rhs per-tensor should have zero points \"\n+            \"as 0.\");\n+      }\n+    } else if (rhs.IsPerAxisQuantized()) {\n+      if (output.IsPerTensorQuantized()) {\n+        if (lhs.quantized_per_tensor_element_type().ExpressedType() ==\n+            rhs.quantized_per_axis_element_type().ExpressedType()) {\n+          if (lhs.quantized_per_tensor_element_type().ExpressedType() !=\n+              output.quantized_per_tensor_element_type().ExpressedType()) {\n+            return absl::FailedPreconditionError(\n+                \"stablehlo.dot_general: The expressed_type of output must be \"\n+                \"the same as the expressed_type of lhs and rhs.\");\n+          }\n+        }\n+      } else if (output.IsPerAxisQuantized()) {\n+        if (lhs.quantized_per_tensor_element_type().ExpressedType() ==\n+            rhs.quantized_per_axis_element_type().ExpressedType()) {\n+          if (lhs.quantized_per_tensor_element_type().ExpressedType() !=\n+              output.quantized_per_axis_element_type().ExpressedType()) {\n+            return absl::FailedPreconditionError(\n+                \"stablehlo.dot_general: The expressed_type of output must be \"\n+                \"the same as the expressed_type of lhs and rhs.\");\n+          }\n+        }\n+      }\n+      auto check_zero_points_values_are_zero =\n+          [](auto zero_points) -> bool {\n+        if (std::holds_alternative<absl::InlinedVector<I4, 8>>(zero_points)) {\n+          auto zero_point_value =\n+              std::get<absl::InlinedVector<I4, 8>>(zero_points);\n+          return std::all_of(\n+              zero_point_value.begin(), zero_point_value.end(),\n+              [](I4 value) { return value == static_cast<I4>(0); });\n+        } else if (std::holds_alternative<absl::InlinedVector<int8_t, 8>>(\n+                       zero_points)) {\n+          auto zero_point_value =\n+              std::get<absl::InlinedVector<int8_t, 8>>(zero_points);\n+          return std::all_of(\n+              zero_point_value.begin(), zero_point_value.end(),\n+              [](int8_t value) { return value == static_cast<int8_t>(0); });\n+        } else if (std::holds_alternative<absl::InlinedVector<int16_t, 8>>(\n+                       zero_points)) {\n+          auto zero_point_value =\n+              std::get<absl::InlinedVector<int16_t, 8>>(zero_points);\n+          return std::all_of(\n+              zero_point_value.begin(), zero_point_value.end(),\n+              [](int16_t value) { return value == static_cast<int16_t>(0); });\n+        }\n+        return false;\n+      };\n+      if (!check_zero_points_values_are_zero(\n+              rhs.quantized_per_axis_element_type().ZeroPoints())) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: The rhs per-axis should have zero points \"\n+            \"as 0.\");\n+      }\n+    } else if (rhs.IsPerAxisQuantized()) {\n+      for (DimensionSize i = 0; i < rhsc_size; ++i) {\n+        if (rhsc[i] ==\n+                rhs.quantized_per_axis_element_type().QuantizedDimension() ||\n+            rhsb[i] ==\n+                rhs.quantized_per_axis_element_type().QuantizedDimension()) {\n+          return absl::FailedPreconditionError(\n+              \"stablehlo.dot_general: If the rhs is per-axis quantized than \"\n+              \"the quantization_dimensions of rhs should not be in \"\n+              \"rhs_contracting_dimensions and rhs_batching_dimensions.\");\n+        }\n+      }\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n+template <DataType storage_type>\n+absl::Status EvaluateImpl(DotGeneralOp& op, const Tensor& lhs,\n+                          const Tensor& rhs,\n+                          const Tensor& lhs_batching_dimensions,\n+                          const Tensor& rhs_batching_dimensions,\n+                          const Tensor& lhs_contracting_dimensions,\n+                          const Tensor& rhs_contracting_dimensions,\n+                          Tensor& output) {\n+  using StorageT = StorageType<storage_type>;\n+  const StorageT* lhs_data = lhs.GetDataAs<storage_type>();\n+  const StorageT* rhs_data = rhs.GetDataAs<storage_type>();\n+  StorageT* output_data = output.GetDataAs<storage_type>();\n+  const size_t lhs_size = lhs.NumElements();\n+  const DimensionSize rhs_size = rhs.NumElements();\n+  const DimensionSize output_size = output.NumElements();\n+  const size_t lhs_rank = lhs.Rank();\n+  const size_t rhs_rank = rhs.Rank();\n+  const size_t output_rank = output.Rank();\n+\n+  const int32_t* lhs_batching_dimensions_data =\n+      lhs_batching_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* rhs_batching_dimensions_data =\n+      rhs_batching_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* lhs_contracting_dimensions_data =\n+      lhs_contracting_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* rhs_contracting_dimensions_data =\n+      rhs_contracting_dimensions.GetDataAs<DataType::kSI32>();\n+  const DimensionSize lhsb_size = lhs_batching_dimensions.NumElements();\n+  const DimensionSize lhsc_size = lhs_contracting_dimensions.NumElements();\n+  const DimensionSize rhsb_size = rhs_batching_dimensions.NumElements();\n+  const DimensionSize rhsc_size = rhs_contracting_dimensions.NumElements();\n+\n+  // function to generate indices for output\n+  auto GenerateIndices = [&](size_t index) -> void {\n+    size_t rank = op.output_shape.size();\n+    size_t divisor = 1;\n+    for (size_t i = 0, j = rank - 1; i < rank; ++i, --j) {\n+      op.output_index[j] = (index / divisor) % op.output_shape[j];\n+      divisor *= op.output_shape[j];\n+    }\n+  };\n+  // function to incremement lhs and rhs indices\n+  auto IncrementIndices = [&]() -> bool {\n+    if (lhsc_size == 0) return false;\n+    for (DimensionSize i = lhsc_size - 1; i >= 0; --i) {\n+      op.lhs_index[lhs_contracting_dimensions_data[i]]++;\n+      op.rhs_index[rhs_contracting_dimensions_data[i]]++;\n+      if (op.lhs_index[lhs_contracting_dimensions_data[i]] <\n+          lhs.shape().Dim(lhs_contracting_dimensions_data[i]))\n+        return true;\n+      if (i == 0) return false;\n+      op.lhs_index[lhs_contracting_dimensions_data[i]] = 0;\n+      op.rhs_index[rhs_contracting_dimensions_data[i]] = 0;\n+    }\n+    return true;\n+  };\n+  // pre compute helper for lhs and rhs indices\n+  DimensionSize lhs_dim_accumulator = 1, rhs_dim_accumulator = 1;\n+  for (size_t i = 0; i < lhs_rank; ++i) {\n+    lhs_dim_accumulator *= lhs.shape().Dim(i);\n+    op.lhs_index_helper[i] = lhs_size / lhs_dim_accumulator;\n+  }\n+  for (size_t i = 0; i < rhs_rank; ++i) {\n+    rhs_dim_accumulator *= rhs.shape().Dim(i);\n+    op.rhs_index_helper[i] = rhs_size / rhs_dim_accumulator;\n+  }\n+\n+  StorageT output_element(0);\n+  DimensionSize lhs_element_index = 0, rhs_element_index = 0;\n+  for (DimensionSize k = 0; k < output_size; ++k, ++output_data) {\n+    GenerateIndices(k);\n+    std::fill(op.lhs_index.begin(), op.lhs_index.end(), 0);\n+    std::fill(op.rhs_index.begin(), op.rhs_index.end(), 0);\n+    size_t result_dim = 0;\n+    for (size_t i = 0; i < lhsb_size; ++i, ++result_dim) {\n+      op.lhs_index[lhs_batching_dimensions_data[i]] =\n+          op.output_index[result_dim];\n+      op.rhs_index[rhs_batching_dimensions_data[i]] =\n+          op.output_index[result_dim];\n+    }\n+    for (size_t i = 0; i < op.lhs_result_dims.size(); ++i, ++result_dim) {\n+      op.lhs_index[op.lhs_result_dims[i]] = op.output_index[result_dim];\n+    }\n+    for (size_t i = 0; i < op.rhs_result_dims.size(); ++i, ++result_dim) {\n+      op.rhs_index[op.rhs_result_dims[i]] = op.output_index[result_dim];\n+    }\n+    output_element = 0;\n+    while (true) {\n+      lhs_element_index = 0;\n+      rhs_element_index = 0;\n+      for (size_t i = 0; i < lhs_rank; ++i) {\n+        lhs_element_index += op.lhs_index[i] * op.lhs_index_helper[i];\n+      }\n+      for (size_t i = 0; i < rhs_rank; ++i) {\n+        rhs_element_index += op.rhs_index[i] * op.rhs_index_helper[i];\n+      }\n+      output_element +=\n+          lhs_data[lhs_element_index] * rhs_data[rhs_element_index];\n+      if (!IncrementIndices()) {\n+        break;\n+      }\n+    }\n+    *output_data = output_element;\n+  }\n+  return absl::OkStatus();\n+}\n+\n+DotGeneralOp Create(DotGeneralOp::Attributes attributes) {\n+  return {.attributes = attributes};\n+}\n+\n+absl::Status Prepare(DotGeneralOp& op, const Tensor& lhs, const Tensor& rhs,\n+                     Tensor& output) {\n+  if (absl::Status status =\n+          CheckParameters(lhs, rhs, op.attributes.lhs_batching_dimensions,\n+                          op.attributes.rhs_batching_dimensions,\n+                          op.attributes.lhs_contracting_dimensions,\n+                          op.attributes.rhs_contracting_dimensions, output);\n+      !status.ok()) {\n+    return status;\n+  }",
        "comment_created_at": "2024-04-17T15:57:00+00:00",
        "comment_author": "qukhan",
        "comment_body": "Use `SHLO_REF_RETURN_ON_ERROR`.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/b19a54c0d9739f9c548222d625c1413628b3a43f/tensorflow/lite/experimental/shlo/ops/util.h#L26-L29\r\n\r\n```suggestion\r\n  SHLO_REF_RETURN_ON_ERROR(CheckParameters(\r\n                          lhs, rhs, op.attributes.lhs_batching_dimensions,\r\n                          op.attributes.rhs_batching_dimensions,\r\n                          op.attributes.lhs_contracting_dimensions,\r\n                          op.attributes.rhs_contracting_dimensions, output));\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1583353586",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 65939,
        "pr_file": "tensorflow/lite/experimental/shlo/ops/dot_general.cc",
        "discussion_id": "1569087282",
        "commented_code": "@@ -0,0 +1,441 @@\n+/* Copyright 2024 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"tensorflow/lite/experimental/shlo/ops/dot_general.h\"\n+\n+#include \"absl/status/status.h\"\n+#include \"tensorflow/lite/experimental/shlo/data_type.h\"\n+#include \"tensorflow/lite/experimental/shlo/dispatch.h\"\n+#include \"tensorflow/lite/experimental/shlo/quantize.h\"\n+#include \"tensorflow/lite/experimental/shlo/quantized_tensor_element_type.h\"\n+#include \"tensorflow/lite/experimental/shlo/shape.h\"\n+#include \"tensorflow/lite/experimental/shlo/tensor.h\"\n+\n+namespace shlo_ref {\n+\n+absl::Status CheckParameters(const Tensor& lhs, const Tensor& rhs,\n+                             const Tensor& lhs_batching_dimensions,\n+                             const Tensor& rhs_batching_dimensions,\n+                             const Tensor& lhs_contracting_dimensions,\n+                             const Tensor& rhs_contracting_dimensions,\n+                             Tensor& output) {\n+  const int32_t* lhsb = lhs_batching_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* rhsb = rhs_batching_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* lhsc = lhs_contracting_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* rhsc = rhs_contracting_dimensions.GetDataAs<DataType::kSI32>();\n+  const DimensionSize lhsb_size = lhs_batching_dimensions.NumElements();\n+  const DimensionSize rhsb_size = rhs_batching_dimensions.NumElements();\n+  const DimensionSize lhsc_size = lhs_contracting_dimensions.NumElements();\n+  const DimensionSize rhsc_size = rhs_contracting_dimensions.NumElements();\n+  const size_t lhs_rank = lhs.Rank();\n+  const size_t rhs_rank = rhs.Rank();\n+  const size_t output_rank = output.Rank();\n+  std::vector<size_t> lhs_result_dims;\n+  std::vector<size_t> rhs_result_dims;\n+  std::vector<size_t> output_shape_check;\n+\n+  if (lhsb_size != rhsb_size) {\n+    return absl::FailedPreconditionError(\n+        \"stablehlo.dot_general: Size of lhs_batching_dimensions and \"\n+        \"rhs_batching_dimensions must be same.\");\n+  } else if (lhsc_size != rhsc_size) {\n+    return absl::FailedPreconditionError(\n+        \"stablehlo.dot_general: Size of lhs_contracting_dimensions and \"\n+        \"rhs_contracting_dimensions must be same.\");\n+  }\n+  for (DimensionSize i = 0; i < lhsb_size; ++i) {\n+    for (DimensionSize j = 0; j < lhsc_size; ++j) {\n+      if (lhsb[i] == lhsc[j]) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: The lhs_batching_dimensions and \"\n+            \"lhs_contracting_dimensions must be unique.\");\n+      }\n+    }\n+  }\n+  for (DimensionSize i = 0; i < rhsb_size; ++i) {\n+    for (DimensionSize j = 0; j < rhsc_size; ++j) {\n+      if (rhsb[i] == rhsc[j]) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: The rhs_batching_dimensions and \"\n+            \"rhs_contracting_dimensions must be unique.\");\n+      }\n+    }\n+  }\n+  for (DimensionSize i = 0; i < lhsb_size; ++i) {\n+    if (lhsb[i] >= lhs_rank || lhsb[i] < 0) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid lhs_batching_dimensions index.\");\n+    }\n+    output_shape_check.push_back(lhs.shape().Dim(lhsb[i]));\n+  }\n+  for (DimensionSize i = 0; i < lhsc_size; ++i) {\n+    if (lhsc[i] >= lhs_rank || lhsc[i] < 0) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid lhs_contracting_dimensions index.\");\n+    }\n+  }\n+  for (DimensionSize i = 0; i < rhsb_size; ++i) {\n+    if (rhsb[i] >= rhs_rank || rhsb[i] < 0) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid rhs_batching_dimensions index.\");\n+    }\n+  }\n+  for (DimensionSize i = 0; i < rhsc_size; ++i) {\n+    if (rhsc[i] >= rhs_rank || rhsc[i] < 0) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid rhs_contracting_dimensions index.\");\n+    }\n+  }\n+  for (DimensionSize i = 0; i < lhsb_size; ++i) {\n+    if (lhs.shape().Dim(lhsb[i]) != rhs.shape().Dim(rhsb[i])) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: The lhs and rhs tensors should have same \"\n+          \"batch dimensions.\");\n+    }\n+  }\n+  for (DimensionSize i = 0; i < lhsc_size; ++i) {\n+    if (lhs.shape().Dim(lhsc[i]) != rhs.shape().Dim(rhsc[i])) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: The lhs and rhs tensors should have same \"\n+          \"contracting dimensions.\");\n+    }\n+  }\n+  for (size_t i = 0; i < lhs_rank; ++i) {\n+    if ((std::count(lhsb, lhsb + lhsb_size, i) == 0) &&\n+        (std::count(lhsc, lhsc + lhsc_size, i) == 0)) {\n+      lhs_result_dims.push_back(i);\n+    }\n+  }\n+  for (size_t i = 0; i < rhs_rank; ++i) {\n+    if ((std::count(rhsb, rhsb + rhsb_size, i) == 0) &&\n+        (std::count(rhsc, rhsc + rhsc_size, i) == 0)) {\n+      rhs_result_dims.push_back(i);\n+    }\n+  }\n+  for (size_t i = 0; i < lhs_result_dims.size(); ++i) {\n+    output_shape_check.push_back(lhs.shape().Dim(lhs_result_dims[i]));\n+  }\n+  for (size_t i = 0; i < rhs_result_dims.size(); ++i) {\n+    output_shape_check.push_back(rhs.shape().Dim(rhs_result_dims[i]));\n+  }\n+  for (size_t i = 0; i < output_rank; ++i) {\n+    if (output.shape().Dim(i) != output_shape_check[i]) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: Invalid output shape.\");\n+    }\n+  }\n+  if (lhs.IsPerAxisQuantized()) {\n+    return absl::FailedPreconditionError(\n+        \"stablehlo.dot_general: The lhs tensor cannot be per-axis quantized.\");\n+  }\n+  if (!lhs.IsPerTensorQuantized() && !rhs.IsQuantized() &&\n+      lhs.tensor_element_type() != rhs.tensor_element_type()) {\n+    return absl::FailedPreconditionError(\n+        \"stablehlo.dot_general: For non-quantized tensors the element type of \"\n+        \"lhs and rhs must be the same.\");\n+  }\n+  if (lhs.IsPerTensorQuantized()) {\n+    if (rhs.IsQuantized() && !output.IsQuantized()) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: If lhs and rhs are quantized tensors, than \"\n+          \"the output tensor should also be quantized.\");\n+    } else if (lhs.StorageType() != rhs.StorageType()) {\n+      return absl::FailedPreconditionError(\n+          \"stablehlo.dot_general: If the lhs and rhs are quantized tensors, \"\n+          \"than they should have the same storage type.\");\n+    } else if (rhs.IsPerTensorQuantized()) {\n+      if (!output.IsPerTensorQuantized()) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: If lhs and rhs are per-tensor quantized \"\n+            \"than output should also be per-tensor quantized.\");\n+      }\n+      if (lhs.quantized_per_tensor_element_type().ExpressedType() ==\n+          rhs.quantized_per_tensor_element_type().ExpressedType()) {\n+        if (lhs.quantized_per_tensor_element_type().ExpressedType() !=\n+            output.quantized_per_tensor_element_type().ExpressedType()) {\n+          return absl::FailedPreconditionError(\n+              \"stablehlo.dot_general: The expressed_type of output tensor must \"\n+              \"be the same as the expressed_type of lhs and rhs tensors.\");\n+        }\n+      }\n+      auto check_zero_point_value_is_zero =\n+          [](auto zero_point) -> bool {\n+        if (std::holds_alternative<I4>(zero_point)) {\n+          return std::get<I4>(zero_point) == static_cast<I4>(0);\n+        } else if (std::holds_alternative<int8_t>(zero_point)) {\n+          return std::get<int8_t>(zero_point) == static_cast<int8_t>(0);\n+        } else if (std::holds_alternative<int16_t>(zero_point)) {\n+          return std::get<int16_t>(zero_point) == static_cast<int16_t>(0);\n+        }\n+        return false;\n+      };\n+      if (!check_zero_point_value_is_zero(\n+              rhs.quantized_per_tensor_element_type().ZeroPoint())) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: The rhs per-tensor should have zero points \"\n+            \"as 0.\");\n+      }\n+    } else if (rhs.IsPerAxisQuantized()) {\n+      if (output.IsPerTensorQuantized()) {\n+        if (lhs.quantized_per_tensor_element_type().ExpressedType() ==\n+            rhs.quantized_per_axis_element_type().ExpressedType()) {\n+          if (lhs.quantized_per_tensor_element_type().ExpressedType() !=\n+              output.quantized_per_tensor_element_type().ExpressedType()) {\n+            return absl::FailedPreconditionError(\n+                \"stablehlo.dot_general: The expressed_type of output must be \"\n+                \"the same as the expressed_type of lhs and rhs.\");\n+          }\n+        }\n+      } else if (output.IsPerAxisQuantized()) {\n+        if (lhs.quantized_per_tensor_element_type().ExpressedType() ==\n+            rhs.quantized_per_axis_element_type().ExpressedType()) {\n+          if (lhs.quantized_per_tensor_element_type().ExpressedType() !=\n+              output.quantized_per_axis_element_type().ExpressedType()) {\n+            return absl::FailedPreconditionError(\n+                \"stablehlo.dot_general: The expressed_type of output must be \"\n+                \"the same as the expressed_type of lhs and rhs.\");\n+          }\n+        }\n+      }\n+      auto check_zero_points_values_are_zero =\n+          [](auto zero_points) -> bool {\n+        if (std::holds_alternative<absl::InlinedVector<I4, 8>>(zero_points)) {\n+          auto zero_point_value =\n+              std::get<absl::InlinedVector<I4, 8>>(zero_points);\n+          return std::all_of(\n+              zero_point_value.begin(), zero_point_value.end(),\n+              [](I4 value) { return value == static_cast<I4>(0); });\n+        } else if (std::holds_alternative<absl::InlinedVector<int8_t, 8>>(\n+                       zero_points)) {\n+          auto zero_point_value =\n+              std::get<absl::InlinedVector<int8_t, 8>>(zero_points);\n+          return std::all_of(\n+              zero_point_value.begin(), zero_point_value.end(),\n+              [](int8_t value) { return value == static_cast<int8_t>(0); });\n+        } else if (std::holds_alternative<absl::InlinedVector<int16_t, 8>>(\n+                       zero_points)) {\n+          auto zero_point_value =\n+              std::get<absl::InlinedVector<int16_t, 8>>(zero_points);\n+          return std::all_of(\n+              zero_point_value.begin(), zero_point_value.end(),\n+              [](int16_t value) { return value == static_cast<int16_t>(0); });\n+        }\n+        return false;\n+      };\n+      if (!check_zero_points_values_are_zero(\n+              rhs.quantized_per_axis_element_type().ZeroPoints())) {\n+        return absl::FailedPreconditionError(\n+            \"stablehlo.dot_general: The rhs per-axis should have zero points \"\n+            \"as 0.\");\n+      }\n+    } else if (rhs.IsPerAxisQuantized()) {\n+      for (DimensionSize i = 0; i < rhsc_size; ++i) {\n+        if (rhsc[i] ==\n+                rhs.quantized_per_axis_element_type().QuantizedDimension() ||\n+            rhsb[i] ==\n+                rhs.quantized_per_axis_element_type().QuantizedDimension()) {\n+          return absl::FailedPreconditionError(\n+              \"stablehlo.dot_general: If the rhs is per-axis quantized than \"\n+              \"the quantization_dimensions of rhs should not be in \"\n+              \"rhs_contracting_dimensions and rhs_batching_dimensions.\");\n+        }\n+      }\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n+template <DataType storage_type>\n+absl::Status EvaluateImpl(DotGeneralOp& op, const Tensor& lhs,\n+                          const Tensor& rhs,\n+                          const Tensor& lhs_batching_dimensions,\n+                          const Tensor& rhs_batching_dimensions,\n+                          const Tensor& lhs_contracting_dimensions,\n+                          const Tensor& rhs_contracting_dimensions,\n+                          Tensor& output) {\n+  using StorageT = StorageType<storage_type>;\n+  const StorageT* lhs_data = lhs.GetDataAs<storage_type>();\n+  const StorageT* rhs_data = rhs.GetDataAs<storage_type>();\n+  StorageT* output_data = output.GetDataAs<storage_type>();\n+  const size_t lhs_size = lhs.NumElements();\n+  const DimensionSize rhs_size = rhs.NumElements();\n+  const DimensionSize output_size = output.NumElements();\n+  const size_t lhs_rank = lhs.Rank();\n+  const size_t rhs_rank = rhs.Rank();\n+  const size_t output_rank = output.Rank();\n+\n+  const int32_t* lhs_batching_dimensions_data =\n+      lhs_batching_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* rhs_batching_dimensions_data =\n+      rhs_batching_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* lhs_contracting_dimensions_data =\n+      lhs_contracting_dimensions.GetDataAs<DataType::kSI32>();\n+  const int32_t* rhs_contracting_dimensions_data =\n+      rhs_contracting_dimensions.GetDataAs<DataType::kSI32>();\n+  const DimensionSize lhsb_size = lhs_batching_dimensions.NumElements();\n+  const DimensionSize lhsc_size = lhs_contracting_dimensions.NumElements();\n+  const DimensionSize rhsb_size = rhs_batching_dimensions.NumElements();\n+  const DimensionSize rhsc_size = rhs_contracting_dimensions.NumElements();\n+\n+  // function to generate indices for output\n+  auto GenerateIndices = [&](size_t index) -> void {\n+    size_t rank = op.output_shape.size();\n+    size_t divisor = 1;\n+    for (size_t i = 0, j = rank - 1; i < rank; ++i, --j) {\n+      op.output_index[j] = (index / divisor) % op.output_shape[j];\n+      divisor *= op.output_shape[j];\n+    }\n+  };\n+  // function to incremement lhs and rhs indices\n+  auto IncrementIndices = [&]() -> bool {\n+    if (lhsc_size == 0) return false;\n+    for (DimensionSize i = lhsc_size - 1; i >= 0; --i) {\n+      op.lhs_index[lhs_contracting_dimensions_data[i]]++;\n+      op.rhs_index[rhs_contracting_dimensions_data[i]]++;\n+      if (op.lhs_index[lhs_contracting_dimensions_data[i]] <\n+          lhs.shape().Dim(lhs_contracting_dimensions_data[i]))\n+        return true;\n+      if (i == 0) return false;\n+      op.lhs_index[lhs_contracting_dimensions_data[i]] = 0;\n+      op.rhs_index[rhs_contracting_dimensions_data[i]] = 0;\n+    }\n+    return true;\n+  };\n+  // pre compute helper for lhs and rhs indices\n+  DimensionSize lhs_dim_accumulator = 1, rhs_dim_accumulator = 1;\n+  for (size_t i = 0; i < lhs_rank; ++i) {\n+    lhs_dim_accumulator *= lhs.shape().Dim(i);\n+    op.lhs_index_helper[i] = lhs_size / lhs_dim_accumulator;\n+  }\n+  for (size_t i = 0; i < rhs_rank; ++i) {\n+    rhs_dim_accumulator *= rhs.shape().Dim(i);\n+    op.rhs_index_helper[i] = rhs_size / rhs_dim_accumulator;\n+  }\n+\n+  StorageT output_element(0);\n+  DimensionSize lhs_element_index = 0, rhs_element_index = 0;\n+  for (DimensionSize k = 0; k < output_size; ++k, ++output_data) {\n+    GenerateIndices(k);\n+    std::fill(op.lhs_index.begin(), op.lhs_index.end(), 0);\n+    std::fill(op.rhs_index.begin(), op.rhs_index.end(), 0);\n+    size_t result_dim = 0;\n+    for (size_t i = 0; i < lhsb_size; ++i, ++result_dim) {\n+      op.lhs_index[lhs_batching_dimensions_data[i]] =\n+          op.output_index[result_dim];\n+      op.rhs_index[rhs_batching_dimensions_data[i]] =\n+          op.output_index[result_dim];\n+    }\n+    for (size_t i = 0; i < op.lhs_result_dims.size(); ++i, ++result_dim) {\n+      op.lhs_index[op.lhs_result_dims[i]] = op.output_index[result_dim];\n+    }\n+    for (size_t i = 0; i < op.rhs_result_dims.size(); ++i, ++result_dim) {\n+      op.rhs_index[op.rhs_result_dims[i]] = op.output_index[result_dim];\n+    }\n+    output_element = 0;\n+    while (true) {\n+      lhs_element_index = 0;\n+      rhs_element_index = 0;\n+      for (size_t i = 0; i < lhs_rank; ++i) {\n+        lhs_element_index += op.lhs_index[i] * op.lhs_index_helper[i];\n+      }\n+      for (size_t i = 0; i < rhs_rank; ++i) {\n+        rhs_element_index += op.rhs_index[i] * op.rhs_index_helper[i];\n+      }\n+      output_element +=\n+          lhs_data[lhs_element_index] * rhs_data[rhs_element_index];\n+      if (!IncrementIndices()) {\n+        break;\n+      }\n+    }\n+    *output_data = output_element;\n+  }\n+  return absl::OkStatus();\n+}\n+\n+DotGeneralOp Create(DotGeneralOp::Attributes attributes) {\n+  return {.attributes = attributes};\n+}\n+\n+absl::Status Prepare(DotGeneralOp& op, const Tensor& lhs, const Tensor& rhs,\n+                     Tensor& output) {\n+  if (absl::Status status =\n+          CheckParameters(lhs, rhs, op.attributes.lhs_batching_dimensions,\n+                          op.attributes.rhs_batching_dimensions,\n+                          op.attributes.lhs_contracting_dimensions,\n+                          op.attributes.rhs_contracting_dimensions, output);\n+      !status.ok()) {\n+    return status;\n+  }",
        "comment_created_at": "2024-04-29T16:12:03+00:00",
        "comment_author": "nishantsarda-mcw",
        "comment_body": "used SHLO_REF_RETURN_ON_ERROR.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1163006196",
    "pr_number": 59843,
    "pr_file": "tensorflow/tsl/util/device_name_utils.cc",
    "created_at": "2023-04-11T15:38:26+00:00",
    "commented_code": "return OkStatus();\n }\n \n+/*static*/ string DeviceNameUtils::GetDeviceNameFromStreamDeviceName(",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1163006196",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 59843,
        "pr_file": "tensorflow/tsl/util/device_name_utils.cc",
        "discussion_id": "1163006196",
        "commented_code": "@@ -618,6 +618,62 @@ std::vector<string> DeviceNameUtils::GetLocalNamesForDeviceMappings(\n   return OkStatus();\n }\n \n+/*static*/ string DeviceNameUtils::GetDeviceNameFromStreamDeviceName(",
        "comment_created_at": "2023-04-11T15:38:26+00:00",
        "comment_author": "cantonios",
        "comment_body": "Do you want to return a `StatusOr<string>` in case of invalid streaming device name?",
        "pr_file_module": null
      },
      {
        "comment_id": "1163950253",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 59843,
        "pr_file": "tensorflow/tsl/util/device_name_utils.cc",
        "discussion_id": "1163006196",
        "commented_code": "@@ -618,6 +618,62 @@ std::vector<string> DeviceNameUtils::GetLocalNamesForDeviceMappings(\n   return OkStatus();\n }\n \n+/*static*/ string DeviceNameUtils::GetDeviceNameFromStreamDeviceName(",
        "comment_created_at": "2023-04-12T10:38:45+00:00",
        "comment_author": "buptzyb",
        "comment_body": "Yes, now it will return `StatusOr<string>`, please see [device_name_utils.cc](https://github.com/tensorflow/tensorflow/pull/59843/commits/0951dd8cfd6afae3941c2648a37d286c03d23a2c#diff-e1cb04fa038c64b95f4eeb92945757327173c2200741f66b5ca08bc44f7b1731R644). Not only that, but I wrote a new function [`bool DeviceNameUtils::IsStreamDeviceName()`](https://github.com/tensorflow/tensorflow/pull/59843/commits/0951dd8cfd6afae3941c2648a37d286c03d23a2c#diff-e1cb04fa038c64b95f4eeb92945757327173c2200741f66b5ca08bc44f7b1731R622) to specifically validate the device name.",
        "pr_file_module": null
      }
    ]
  }
]