[
  {
    "discussion_id": "1969339428",
    "pr_number": 84932,
    "pr_file": "tensorflow/lite/experimental/litert/vendors/qualcomm/dispatch/dispatch_api.cc",
    "created_at": "2025-02-25T09:18:06+00:00",
    "commented_code": "// Basic Execution API\n // /////////////////////////////////////////////////////////////////////////////\n \n-const char* GetSharedLibraryDir(const LiteRtDispatchOption* options,\n-                                int num_options) {\n+litert::Expected<std::any> FindDispatchOption(\n+    const LiteRtDispatchOption* options, int num_options,\n+    const char* option_name) {\n   for (auto i = 0; i < num_options; ++i) {\n     auto& option = options[i];\n-    if (!strcmp(option.name, kDispatchOptionSharedLibraryDir)) {\n-      return option.value.str_value;\n+    if (!strcmp(option.name, option_name)) {\n+      return litert::ToStdAny(option.value);\n     }\n   }\n-  return nullptr;\n+  return litert::Unexpected(kLiteRtStatusErrorInvalidArgument);\n }\n \n LiteRtStatus Initialize(const LiteRtDispatchOption* options, int num_options) {\n-  auto* shared_library_dir = GetSharedLibraryDir(options, num_options);\n+  auto shared_library_dir =\n+      FindDispatchOption(options, num_options, kDispatchOptionSharedLibraryDir);\n   std::optional<std::string> shared_library_dir_opt =\n-      shared_library_dir ? std::make_optional(std::string(shared_library_dir))\n-                         : std::nullopt;\n+      shared_library_dir.HasValue()\n+          ? std::make_optional(std::string(\n+                std::any_cast<const char*>(shared_library_dir.Value())))\n+          : std::nullopt;",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1969339428",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 84932,
        "pr_file": "tensorflow/lite/experimental/litert/vendors/qualcomm/dispatch/dispatch_api.cc",
        "discussion_id": "1969339428",
        "commented_code": "@@ -41,25 +46,38 @@ char BuildId[256];\n // Basic Execution API\n // /////////////////////////////////////////////////////////////////////////////\n \n-const char* GetSharedLibraryDir(const LiteRtDispatchOption* options,\n-                                int num_options) {\n+litert::Expected<std::any> FindDispatchOption(\n+    const LiteRtDispatchOption* options, int num_options,\n+    const char* option_name) {\n   for (auto i = 0; i < num_options; ++i) {\n     auto& option = options[i];\n-    if (!strcmp(option.name, kDispatchOptionSharedLibraryDir)) {\n-      return option.value.str_value;\n+    if (!strcmp(option.name, option_name)) {\n+      return litert::ToStdAny(option.value);\n     }\n   }\n-  return nullptr;\n+  return litert::Unexpected(kLiteRtStatusErrorInvalidArgument);\n }\n \n LiteRtStatus Initialize(const LiteRtDispatchOption* options, int num_options) {\n-  auto* shared_library_dir = GetSharedLibraryDir(options, num_options);\n+  auto shared_library_dir =\n+      FindDispatchOption(options, num_options, kDispatchOptionSharedLibraryDir);\n   std::optional<std::string> shared_library_dir_opt =\n-      shared_library_dir ? std::make_optional(std::string(shared_library_dir))\n-                         : std::nullopt;\n+      shared_library_dir.HasValue()\n+          ? std::make_optional(std::string(\n+                std::any_cast<const char*>(shared_library_dir.Value())))\n+          : std::nullopt;",
        "comment_created_at": "2025-02-25T09:18:06+00:00",
        "comment_author": "weilhuan-quic",
        "comment_body": "```suggestion\r\n      if (shared_library_dir.HasValue()) {\r\n         shared_library_dir_opt.emplace(std::any_cast<const char*>(shared_library_dir.Value());\r\n    }\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1969361452",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 84932,
        "pr_file": "tensorflow/lite/experimental/litert/vendors/qualcomm/dispatch/dispatch_api.cc",
        "discussion_id": "1969339428",
        "commented_code": "@@ -41,25 +46,38 @@ char BuildId[256];\n // Basic Execution API\n // /////////////////////////////////////////////////////////////////////////////\n \n-const char* GetSharedLibraryDir(const LiteRtDispatchOption* options,\n-                                int num_options) {\n+litert::Expected<std::any> FindDispatchOption(\n+    const LiteRtDispatchOption* options, int num_options,\n+    const char* option_name) {\n   for (auto i = 0; i < num_options; ++i) {\n     auto& option = options[i];\n-    if (!strcmp(option.name, kDispatchOptionSharedLibraryDir)) {\n-      return option.value.str_value;\n+    if (!strcmp(option.name, option_name)) {\n+      return litert::ToStdAny(option.value);\n     }\n   }\n-  return nullptr;\n+  return litert::Unexpected(kLiteRtStatusErrorInvalidArgument);\n }\n \n LiteRtStatus Initialize(const LiteRtDispatchOption* options, int num_options) {\n-  auto* shared_library_dir = GetSharedLibraryDir(options, num_options);\n+  auto shared_library_dir =\n+      FindDispatchOption(options, num_options, kDispatchOptionSharedLibraryDir);\n   std::optional<std::string> shared_library_dir_opt =\n-      shared_library_dir ? std::make_optional(std::string(shared_library_dir))\n-                         : std::nullopt;\n+      shared_library_dir.HasValue()\n+          ? std::make_optional(std::string(\n+                std::any_cast<const char*>(shared_library_dir.Value())))\n+          : std::nullopt;",
        "comment_created_at": "2025-02-25T09:29:41+00:00",
        "comment_author": "jiunkaiy",
        "comment_body": "Thanks!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "525546617",
    "pr_number": 44851,
    "pr_file": "tensorflow/compiler/mlir/tosa/transforms/convert_tfl_uint8.cc",
    "created_at": "2020-11-17T21:48:04+00:00",
    "commented_code": "+/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// This pass converts a TFLite uint8 graph to the int8 domain, with adaptors at\n+// input and output tensors. This is needed because TOSA precision is\n+// implemented in the int8 domain. This pass does:\n+// 1. match TFL::QConst with uint8, generate TFL::QConst with int8 with value\n+// remapped.\n+// 2. insert tosa.RESCALE uint8 -> int8 if block argument (placeholder of graph)\n+// is uint8 typed.\n+// 3. insert tosa.RESCALE int8 -> uint8 if original returned tensor is uint8\n+// typed.\n+\n+#include <climits>\n+#include <cstddef>\n+#include <cstdint>\n+#include <iterator>\n+#include <numeric>\n+\n+#include \"mlir/Dialect/Quant/FakeQuantSupport.h\"\n+#include \"mlir/Dialect/Quant/UniformSupport.h\"\n+#include \"mlir/Dialect/StandardOps/IR/Ops.h\"\n+#include \"mlir/Dialect/Tosa/IR/TosaOps.h\"\n+#include \"mlir/Dialect/Tosa/Utils/QuantUtils.h\"\n+#include \"mlir/IR/Attributes.h\"\n+#include \"mlir/IR/Diagnostics.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"mlir/IR/Matchers.h\"\n+#include \"mlir/IR/Module.h\"\n+#include \"mlir/IR/Operation.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/StandardTypes.h\"\n+#include \"mlir/IR/TypeUtilities.h\"\n+#include \"mlir/IR/Types.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Transforms/DialectConversion.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"tensorflow/compiler/mlir/lite/ir/tfl_ops.h\"\n+#include \"tensorflow/compiler/mlir/tosa/transforms/legalize_common.h\"\n+#include \"tensorflow/compiler/mlir/tosa/transforms/legalize_utils.h\"\n+#include \"tensorflow/compiler/mlir/tosa/transforms/passes.h\"\n+\n+#define PASS_NAME \"tosa-convert-tfl-uint8\"\n+#define DEBUG_TYPE PASS_NAME\n+\n+namespace mlir {\n+\n+namespace tosa {\n+\n+namespace {\n+// Performs lowering to TOSA dialect.\n+class ConvertUint8ToInt8\n+    : public PassWrapper<ConvertUint8ToInt8, FunctionPass> {\n+ public:\n+  explicit ConvertUint8ToInt8() {}\n+  void runOnFunction() override;\n+};\n+\n+struct ConvertUint8QConstOp : public RewritePattern {\n+  explicit ConvertUint8QConstOp(MLIRContext *context)\n+      : RewritePattern(TFL::QConstOp::getOperationName(), 1, context) {}\n+\n+  LogicalResult matchAndRewrite(Operation *op, PatternRewriter &builder) const {\n+    auto tfl_qconst_op = cast<TFL::QConstOp>(op);\n+\n+    // Skip if it's not ranked tensor type.\n+    auto output_type =\n+        tfl_qconst_op.getResult().getType().dyn_cast<mlir::RankedTensorType>();\n+    if (!output_type) return failure();\n+\n+    // Skip if output is not per-tensor quantized type.\n+    auto output_element_type =\n+        output_type.getElementType()\n+            .dyn_cast<mlir::quant::UniformQuantizedType>();\n+    if (!output_element_type) return failure();\n+\n+    // Skip if output is not uint8.\n+    if (output_element_type.isSigned() ||\n+        output_element_type.getStorageTypeIntegralWidth() != 8) {\n+      return failure();\n+    }\n+\n+    auto src_dense_attr =\n+        op->getAttr(\"value\").dyn_cast<mlir::DenseElementsAttr>();\n+\n+    double type_range_min = double(output_element_type.getStorageTypeMin() -\n+                                   output_element_type.getZeroPoint()) *\n+                            output_element_type.getScale();\n+    double type_range_max = double(output_element_type.getStorageTypeMax() -\n+                                   output_element_type.getZeroPoint()) *\n+                            output_element_type.getScale();\n+    bool narrow_range =\n+        output_element_type.getStorageTypeMin() == 1 ? true : false;\n+\n+    auto dst_qconst_type = TypeAttr::get(RankedTensorType::get(\n+        output_type.getShape(),\n+        buildQTypeFromMinMax(\n+            builder, output_element_type.getExpressedType(),\n+            builder.getF64FloatAttr(type_range_min),\n+            builder.getF64FloatAttr(type_range_max),\n+            builder.getI32IntegerAttr(\n+                output_element_type.getStorageTypeIntegralWidth()),\n+            0, true /* signed */, builder.getBoolAttr(narrow_range))));\n+\n+    Type dst_dense_element_type = builder.getIntegerType(8);\n+    llvm::function_ref<APInt(const APInt &)> mapping =\n+        [](const APInt &in) -> APInt {\n+      int64_t in_i64 = in.getLimitedValue();\n+      int64_t out_i64 = in_i64 - 128;\n+      return APInt(8, out_i64, true);\n+    };\n+\n+    auto dst_dense_attr =\n+        src_dense_attr.mapValues(dst_dense_element_type, mapping);\n+\n+    auto dst_qconst_op = builder.create<TFL::QConstOp>(\n+        op->getLoc(), dst_qconst_type, dst_dense_attr);\n+\n+    builder.replaceOp(op, {dst_qconst_op.getResult()});\n+    return success();\n+  }\n+};\n+\n+int convert_graph_uint8_tensor(mlir::MLIRContext &context,\n+                               mlir::FuncOp &function) {\n+  size_t num_blocks_in_main = 0;\n+  mlir::Region *region = function.getCallableRegion();\n+  OpBuilder builder(&context);\n+\n+  auto tmp_const_type = RankedTensorType::get({1}, builder.getIntegerType(8));\n+  auto tmp_const_attr = DenseElementsAttr::get(tmp_const_type, {0});\n+\n+  for (mlir::Block &bb : region->getBlocks()) {\n+    // Always have one block for each region right now.\n+    num_blocks_in_main++;\n+    if (num_blocks_in_main > 1) {\n+      llvm::errs() << \"Invalid MLIR: multiple blocks in a region\n\";\n+      return 1;\n+    }\n+\n+    if (!bb.isEntryBlock()) {\n+      llvm::errs() << \"Invalid MLIR: block must be entry block\n\";\n+      return 1;\n+    }\n+\n+    // Insert rescale uint8->int8 after placeholders.\n+    for (Value arg : bb.getArguments()) {\n+      auto uint8_type = arg.getType().dyn_cast<mlir::RankedTensorType>();\n+      if (!uint8_type) continue;\n+\n+      auto uint8_element_type =\n+          uint8_type.getElementType()\n+              .dyn_cast<mlir::quant::UniformQuantizedType>();\n+      if (!uint8_element_type) continue;\n+\n+      if (uint8_element_type.isSigned() ||\n+          uint8_element_type.getStorageTypeIntegralWidth() != 8)\n+        continue;\n+\n+      double type_range_min = double(uint8_element_type.getStorageTypeMin() -\n+                                     uint8_element_type.getZeroPoint()) *\n+                              uint8_element_type.getScale();\n+      double type_range_max = double(uint8_element_type.getStorageTypeMax() -\n+                                     uint8_element_type.getZeroPoint()) *\n+                              uint8_element_type.getScale();\n+      bool narrow_range =\n+          uint8_element_type.getStorageTypeMin() == 1 ? true : false;\n+\n+      Type int8_type = RankedTensorType::get(\n+          uint8_type.getShape(),\n+          buildQTypeFromMinMax(\n+              builder, uint8_element_type.getExpressedType(),\n+              builder.getF64FloatAttr(type_range_min),\n+              builder.getF64FloatAttr(type_range_max),\n+              builder.getI32IntegerAttr(\n+                  uint8_element_type.getStorageTypeIntegralWidth()),\n+              0, true /* signed */, builder.getBoolAttr(narrow_range)));\n+\n+      int32_t uint8_zp = uint8_element_type.getZeroPoint();\n+      int32_t int8_zp = uint8_zp - 128;\n+\n+      // Keep original input_val use with tmp_val.\n+      Value tmp_val = builder.create<TFL::ConstOp>(\n+          builder.getUnknownLoc(), tmp_const_type, tmp_const_attr);\n+      arg.replaceAllUsesWith(tmp_val);\n+      auto rescale_op = builder.create<tosa::RescaleOp>(\n+          builder.getUnknownLoc(), int8_type, arg,\n+          builder.getI32IntegerAttr(uint8_zp),\n+          builder.getI32IntegerAttr(int8_zp),\n+          builder.getI32ArrayAttr({1 << 30}), builder.getI32ArrayAttr({30}),\n+          builder.getBoolAttr(true), builder.getBoolAttr(false),\n+          builder.getBoolAttr(false));\n+\n+      Operation *op_rescale_op = (Operation *)rescale_op;\n+      bb.push_front(op_rescale_op);\n+      tmp_val.replaceAllUsesWith(rescale_op.getResult());\n+    }\n+\n+    // Record types of original graph output before we convert intermediate\n+    // tensor.\n+    auto terminator = bb.getTerminator();\n+    std::vector<Type> output_types;\n+    for (Value val : terminator->getOperands()) {\n+      output_types.push_back(val.getType());\n+    }\n+\n+    // Convert intermediate tensor.\n+    for (auto &op : bb) {\n+      for (Value output_val : op.getResults()) {\n+        // Skip if output value is not RankedTensorType.\n+        auto output_type =\n+            output_val.getType().dyn_cast<mlir::RankedTensorType>();\n+        if (!output_type) continue;\n+\n+        // Skip if output value is not per-tensor quantized element type.\n+        auto output_element_type =\n+            output_type.getElementType()\n+                .dyn_cast<mlir::quant::UniformQuantizedType>();\n+        if (!output_element_type) continue;\n+\n+        // Skip if output is not uint8.\n+        if (output_element_type.isSigned() ||\n+            output_element_type.getStorageTypeIntegralWidth() != 8)\n+          continue;\n+\n+        double type_range_min = double(output_element_type.getStorageTypeMin() -\n+                                       output_element_type.getZeroPoint()) *\n+                                output_element_type.getScale();\n+        double type_range_max = double(output_element_type.getStorageTypeMax() -\n+                                       output_element_type.getZeroPoint()) *\n+                                output_element_type.getScale();\n+        bool narrow_range =\n+            output_element_type.getStorageTypeMin() == 1 ? true : false;\n+\n+        Type new_type = RankedTensorType::get(\n+            output_type.getShape(),\n+            buildQTypeFromMinMax(\n+                builder, output_element_type.getExpressedType(),\n+                builder.getF64FloatAttr(type_range_min),\n+                builder.getF64FloatAttr(type_range_max),\n+                builder.getI32IntegerAttr(\n+                    output_element_type.getStorageTypeIntegralWidth()),\n+                0, true /* signed */, builder.getBoolAttr(narrow_range)));\n+\n+        output_val.setType(new_type);\n+      }\n+    }\n+\n+    if (terminator->getNumOperands() != output_types.size()) {\n+      llvm::errs() << \"Terminator size should be \" << output_types.size()\n+                   << \" instead of \" << terminator->getNumOperands() << \"\n\";\n+      return 1;\n+    }\n+\n+    // Insert int8->uint8 rescale before all terminator's operand.\n+    for (int32_t i = 0; i < terminator->getNumOperands(); i++) {\n+      Value input_val = terminator->getOperand(i).getDefiningOp()->getResult(0);",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "525546617",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 44851,
        "pr_file": "tensorflow/compiler/mlir/tosa/transforms/convert_tfl_uint8.cc",
        "discussion_id": "525546617",
        "commented_code": "@@ -0,0 +1,358 @@\n+/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// This pass converts a TFLite uint8 graph to the int8 domain, with adaptors at\n+// input and output tensors. This is needed because TOSA precision is\n+// implemented in the int8 domain. This pass does:\n+// 1. match TFL::QConst with uint8, generate TFL::QConst with int8 with value\n+// remapped.\n+// 2. insert tosa.RESCALE uint8 -> int8 if block argument (placeholder of graph)\n+// is uint8 typed.\n+// 3. insert tosa.RESCALE int8 -> uint8 if original returned tensor is uint8\n+// typed.\n+\n+#include <climits>\n+#include <cstddef>\n+#include <cstdint>\n+#include <iterator>\n+#include <numeric>\n+\n+#include \"mlir/Dialect/Quant/FakeQuantSupport.h\"\n+#include \"mlir/Dialect/Quant/UniformSupport.h\"\n+#include \"mlir/Dialect/StandardOps/IR/Ops.h\"\n+#include \"mlir/Dialect/Tosa/IR/TosaOps.h\"\n+#include \"mlir/Dialect/Tosa/Utils/QuantUtils.h\"\n+#include \"mlir/IR/Attributes.h\"\n+#include \"mlir/IR/Diagnostics.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"mlir/IR/Matchers.h\"\n+#include \"mlir/IR/Module.h\"\n+#include \"mlir/IR/Operation.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/StandardTypes.h\"\n+#include \"mlir/IR/TypeUtilities.h\"\n+#include \"mlir/IR/Types.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Transforms/DialectConversion.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"tensorflow/compiler/mlir/lite/ir/tfl_ops.h\"\n+#include \"tensorflow/compiler/mlir/tosa/transforms/legalize_common.h\"\n+#include \"tensorflow/compiler/mlir/tosa/transforms/legalize_utils.h\"\n+#include \"tensorflow/compiler/mlir/tosa/transforms/passes.h\"\n+\n+#define PASS_NAME \"tosa-convert-tfl-uint8\"\n+#define DEBUG_TYPE PASS_NAME\n+\n+namespace mlir {\n+\n+namespace tosa {\n+\n+namespace {\n+// Performs lowering to TOSA dialect.\n+class ConvertUint8ToInt8\n+    : public PassWrapper<ConvertUint8ToInt8, FunctionPass> {\n+ public:\n+  explicit ConvertUint8ToInt8() {}\n+  void runOnFunction() override;\n+};\n+\n+struct ConvertUint8QConstOp : public RewritePattern {\n+  explicit ConvertUint8QConstOp(MLIRContext *context)\n+      : RewritePattern(TFL::QConstOp::getOperationName(), 1, context) {}\n+\n+  LogicalResult matchAndRewrite(Operation *op, PatternRewriter &builder) const {\n+    auto tfl_qconst_op = cast<TFL::QConstOp>(op);\n+\n+    // Skip if it's not ranked tensor type.\n+    auto output_type =\n+        tfl_qconst_op.getResult().getType().dyn_cast<mlir::RankedTensorType>();\n+    if (!output_type) return failure();\n+\n+    // Skip if output is not per-tensor quantized type.\n+    auto output_element_type =\n+        output_type.getElementType()\n+            .dyn_cast<mlir::quant::UniformQuantizedType>();\n+    if (!output_element_type) return failure();\n+\n+    // Skip if output is not uint8.\n+    if (output_element_type.isSigned() ||\n+        output_element_type.getStorageTypeIntegralWidth() != 8) {\n+      return failure();\n+    }\n+\n+    auto src_dense_attr =\n+        op->getAttr(\"value\").dyn_cast<mlir::DenseElementsAttr>();\n+\n+    double type_range_min = double(output_element_type.getStorageTypeMin() -\n+                                   output_element_type.getZeroPoint()) *\n+                            output_element_type.getScale();\n+    double type_range_max = double(output_element_type.getStorageTypeMax() -\n+                                   output_element_type.getZeroPoint()) *\n+                            output_element_type.getScale();\n+    bool narrow_range =\n+        output_element_type.getStorageTypeMin() == 1 ? true : false;\n+\n+    auto dst_qconst_type = TypeAttr::get(RankedTensorType::get(\n+        output_type.getShape(),\n+        buildQTypeFromMinMax(\n+            builder, output_element_type.getExpressedType(),\n+            builder.getF64FloatAttr(type_range_min),\n+            builder.getF64FloatAttr(type_range_max),\n+            builder.getI32IntegerAttr(\n+                output_element_type.getStorageTypeIntegralWidth()),\n+            0, true /* signed */, builder.getBoolAttr(narrow_range))));\n+\n+    Type dst_dense_element_type = builder.getIntegerType(8);\n+    llvm::function_ref<APInt(const APInt &)> mapping =\n+        [](const APInt &in) -> APInt {\n+      int64_t in_i64 = in.getLimitedValue();\n+      int64_t out_i64 = in_i64 - 128;\n+      return APInt(8, out_i64, true);\n+    };\n+\n+    auto dst_dense_attr =\n+        src_dense_attr.mapValues(dst_dense_element_type, mapping);\n+\n+    auto dst_qconst_op = builder.create<TFL::QConstOp>(\n+        op->getLoc(), dst_qconst_type, dst_dense_attr);\n+\n+    builder.replaceOp(op, {dst_qconst_op.getResult()});\n+    return success();\n+  }\n+};\n+\n+int convert_graph_uint8_tensor(mlir::MLIRContext &context,\n+                               mlir::FuncOp &function) {\n+  size_t num_blocks_in_main = 0;\n+  mlir::Region *region = function.getCallableRegion();\n+  OpBuilder builder(&context);\n+\n+  auto tmp_const_type = RankedTensorType::get({1}, builder.getIntegerType(8));\n+  auto tmp_const_attr = DenseElementsAttr::get(tmp_const_type, {0});\n+\n+  for (mlir::Block &bb : region->getBlocks()) {\n+    // Always have one block for each region right now.\n+    num_blocks_in_main++;\n+    if (num_blocks_in_main > 1) {\n+      llvm::errs() << \"Invalid MLIR: multiple blocks in a region\\n\";\n+      return 1;\n+    }\n+\n+    if (!bb.isEntryBlock()) {\n+      llvm::errs() << \"Invalid MLIR: block must be entry block\\n\";\n+      return 1;\n+    }\n+\n+    // Insert rescale uint8->int8 after placeholders.\n+    for (Value arg : bb.getArguments()) {\n+      auto uint8_type = arg.getType().dyn_cast<mlir::RankedTensorType>();\n+      if (!uint8_type) continue;\n+\n+      auto uint8_element_type =\n+          uint8_type.getElementType()\n+              .dyn_cast<mlir::quant::UniformQuantizedType>();\n+      if (!uint8_element_type) continue;\n+\n+      if (uint8_element_type.isSigned() ||\n+          uint8_element_type.getStorageTypeIntegralWidth() != 8)\n+        continue;\n+\n+      double type_range_min = double(uint8_element_type.getStorageTypeMin() -\n+                                     uint8_element_type.getZeroPoint()) *\n+                              uint8_element_type.getScale();\n+      double type_range_max = double(uint8_element_type.getStorageTypeMax() -\n+                                     uint8_element_type.getZeroPoint()) *\n+                              uint8_element_type.getScale();\n+      bool narrow_range =\n+          uint8_element_type.getStorageTypeMin() == 1 ? true : false;\n+\n+      Type int8_type = RankedTensorType::get(\n+          uint8_type.getShape(),\n+          buildQTypeFromMinMax(\n+              builder, uint8_element_type.getExpressedType(),\n+              builder.getF64FloatAttr(type_range_min),\n+              builder.getF64FloatAttr(type_range_max),\n+              builder.getI32IntegerAttr(\n+                  uint8_element_type.getStorageTypeIntegralWidth()),\n+              0, true /* signed */, builder.getBoolAttr(narrow_range)));\n+\n+      int32_t uint8_zp = uint8_element_type.getZeroPoint();\n+      int32_t int8_zp = uint8_zp - 128;\n+\n+      // Keep original input_val use with tmp_val.\n+      Value tmp_val = builder.create<TFL::ConstOp>(\n+          builder.getUnknownLoc(), tmp_const_type, tmp_const_attr);\n+      arg.replaceAllUsesWith(tmp_val);\n+      auto rescale_op = builder.create<tosa::RescaleOp>(\n+          builder.getUnknownLoc(), int8_type, arg,\n+          builder.getI32IntegerAttr(uint8_zp),\n+          builder.getI32IntegerAttr(int8_zp),\n+          builder.getI32ArrayAttr({1 << 30}), builder.getI32ArrayAttr({30}),\n+          builder.getBoolAttr(true), builder.getBoolAttr(false),\n+          builder.getBoolAttr(false));\n+\n+      Operation *op_rescale_op = (Operation *)rescale_op;\n+      bb.push_front(op_rescale_op);\n+      tmp_val.replaceAllUsesWith(rescale_op.getResult());\n+    }\n+\n+    // Record types of original graph output before we convert intermediate\n+    // tensor.\n+    auto terminator = bb.getTerminator();\n+    std::vector<Type> output_types;\n+    for (Value val : terminator->getOperands()) {\n+      output_types.push_back(val.getType());\n+    }\n+\n+    // Convert intermediate tensor.\n+    for (auto &op : bb) {\n+      for (Value output_val : op.getResults()) {\n+        // Skip if output value is not RankedTensorType.\n+        auto output_type =\n+            output_val.getType().dyn_cast<mlir::RankedTensorType>();\n+        if (!output_type) continue;\n+\n+        // Skip if output value is not per-tensor quantized element type.\n+        auto output_element_type =\n+            output_type.getElementType()\n+                .dyn_cast<mlir::quant::UniformQuantizedType>();\n+        if (!output_element_type) continue;\n+\n+        // Skip if output is not uint8.\n+        if (output_element_type.isSigned() ||\n+            output_element_type.getStorageTypeIntegralWidth() != 8)\n+          continue;\n+\n+        double type_range_min = double(output_element_type.getStorageTypeMin() -\n+                                       output_element_type.getZeroPoint()) *\n+                                output_element_type.getScale();\n+        double type_range_max = double(output_element_type.getStorageTypeMax() -\n+                                       output_element_type.getZeroPoint()) *\n+                                output_element_type.getScale();\n+        bool narrow_range =\n+            output_element_type.getStorageTypeMin() == 1 ? true : false;\n+\n+        Type new_type = RankedTensorType::get(\n+            output_type.getShape(),\n+            buildQTypeFromMinMax(\n+                builder, output_element_type.getExpressedType(),\n+                builder.getF64FloatAttr(type_range_min),\n+                builder.getF64FloatAttr(type_range_max),\n+                builder.getI32IntegerAttr(\n+                    output_element_type.getStorageTypeIntegralWidth()),\n+                0, true /* signed */, builder.getBoolAttr(narrow_range)));\n+\n+        output_val.setType(new_type);\n+      }\n+    }\n+\n+    if (terminator->getNumOperands() != output_types.size()) {\n+      llvm::errs() << \"Terminator size should be \" << output_types.size()\n+                   << \" instead of \" << terminator->getNumOperands() << \"\\n\";\n+      return 1;\n+    }\n+\n+    // Insert int8->uint8 rescale before all terminator's operand.\n+    for (int32_t i = 0; i < terminator->getNumOperands(); i++) {\n+      Value input_val = terminator->getOperand(i).getDefiningOp()->getResult(0);",
        "comment_created_at": "2020-11-17T21:48:04+00:00",
        "comment_author": "stellaraccident",
        "comment_body": "This will return nullptr/crash if the operand of the terminator is a block arg (function input). Minimally, check for that path and skip.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "525557204",
    "pr_number": 44851,
    "pr_file": "tensorflow/compiler/mlir/tosa/transforms/legalize_common.cc",
    "created_at": "2020-11-17T22:08:10+00:00",
    "commented_code": "+/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// This file contains legalizations common to mapping both TensorFlow and\n+// TensorFlow Lite to TOSA.\n+//\n+// Conversion functions return nullptr on a lowerization failure or a\n+// lowered operator on success.  Callers must check and return a\n+// LogicalResult failure on nullptr.  Helper macros are provided in\n+// legalize_common.h to canonicalize this handling.\n+\n+#include \"tensorflow/compiler/mlir/tosa/transforms/legalize_common.h\"\n+\n+#include <climits>\n+#include <cstddef>\n+#include <cstdint>\n+#include <iterator>\n+#include <numeric>\n+\n+#include \"tensorflow/compiler/mlir/tosa/transforms/legalize_utils.h\"\n+\n+namespace mlir {\n+namespace tosa {\n+\n+// Lowers the Pack operator to TOSA.\n+Operation* convertPackOp(PatternRewriter& rewriter, Operation* op,\n+                         Value result_value, SmallVector<Value, 8>& inputs,\n+                         int32_t axis) {\n+  //////////////////////////////////////////////////\n+  // Operator: output = Pack([values], axis) or output = Stack([values], axis)\n+  // Lowering:\n+  //\n+  // This operator is lowered into a series of pairwise tosa.concat()\n+  // operators and a reshape\n+  // Depending on the inputs, a tranpose operator is also generated:\n+  //\n+  // Step 1: concatenate the tensors\n+  // a1_concat = tosa.concat(input[0], input[1], axis)\n+  // for (i = 2; i < len(input); i++)\n+  //   a1_concat = tosa.concat(a1_concat, input[i], axis)\n+  //\n+  // Step 2: reshape to N+1 dimensions\n+  // a2_reshape = tosa.reshape(a1_concat, new_rank)\n+  //\n+  // Step 3: Transpose if a new dimension is being added:\n+  // if (axis == rank(values[0]):\n+  //   // perm will be [1, 2, 3, 0]\n+  //   a3_transpose = tosa.transpose(a2_reshape, perm)\n+\n+  // Sanity check 1: make sure all input tensors have the same shape\n+  // if input[0] has shape [A, B, C], input[1] to input[N-1] should also have\n+  // shape[A, B, C]\n+  auto result_type = result_value.getType().dyn_cast<RankedTensorType>();\n+\n+  // Check for ranked tensor type.\n+  if (!result_type) {\n+    op->emitOpError(\"PackOp: result type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  // Valid axis in TF is [-rank(input), rank(input))\n+  // Valid axis in TOSA is [0, rank(input))\n+  // Plus rank(input) once if axis is negative.\n+  auto input_type = op->getOperand(0).getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"PackOp: input type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  auto input_rank = input_type.getShape().size();\n+  if (axis < 0) axis += input_rank;\n+\n+  input_type = inputs[0].getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"Input 0 type not ranked tensor.\");\n+    return nullptr;\n+  }\n+  ArrayRef<int64_t> input0_tensor_shape = input_type.getShape();\n+  int input_tensor_rank = input0_tensor_shape.size();\n+\n+  for (int i = 1; i < inputs.size(); i++) {\n+    input_type = inputs[0].getType().dyn_cast<RankedTensorType>();\n+    if (!input_type) {\n+      op->emitOpError(llvm::formatv(\n+          \"reduce axis {} is not in valid range [-rank(input), rank(input))\",\n+          i));\n+      return nullptr;\n+    }\n+    ArrayRef<int64_t> next_tensor_shape = input_type.getShape();\n+    if (next_tensor_shape.size() != input_tensor_rank) {\n+      op->emitOpError(\"PackOp: input tensor rank mismatch.\");\n+      return nullptr;\n+    }\n+    for (int d = 0; d < input0_tensor_shape.size(); d++) {\n+      if (input0_tensor_shape[d] != next_tensor_shape[d]) {\n+        op->emitOpError(\"PackOp: input tensor shape mismatch.\");\n+        return nullptr;\n+      }\n+    }\n+  }\n+\n+  // If input tensors are rank 0, should reshape them to rank 1 size 1 before\n+  // performing concat.\n+  if (input_tensor_rank == 0) {\n+    SmallVector<int64_t, 8> reshape_rank1_size1_shape{1};\n+    auto reshape_rank1_size1_type =\n+        RankedTensorType::get(ArrayRef<int64_t>(reshape_rank1_size1_shape),\n+                              result_type.getElementType());\n+    ArrayAttr shape_rank1_size1_attr =\n+        rewriter.getI64ArrayAttr(reshape_rank1_size1_shape);\n+    for (int i = 0; i < inputs.size(); i++) {\n+      auto a0_reshape_op = rewriter.create<tosa::ReshapeOp>(\n+          op->getLoc(), reshape_rank1_size1_type, inputs[i],\n+          shape_rank1_size1_attr);\n+      inputs[i] = a0_reshape_op.getResult();\n+    }\n+  }\n+\n+  // Sanity check 2: axis can be from [0, rank(input)+1]\n+  // Where rank(input)+1 means create a new dimension\n+  // Negative values are also allowed up to -(rank(input)+1)\n+  // where the axis \"wraps around\".\n+  if (axis < 0) axis += input_rank;\n+\n+  if (axis > (input_tensor_rank + 1)) {\n+    op->emitOpError(\"PackOp: axis out of valid range.\");\n+    return nullptr;\n+  }\n+\n+  // Sanity check 2: if input shape is [A, B, C], output shape should be [N,\n+  // A, B, C]\n+  // 2.a check output is rank(input) + 1\n+  SmallVector<int64_t, 8> output_shape_vals(result_type.getShape().begin(),\n+                                            result_type.getShape().end());\n+  if (output_shape_vals.size() != (input_tensor_rank + 1)) {\n+    op->emitOpError(\"PackOp: output tensor rank mismatch.\");\n+    return nullptr;\n+  }\n+  // 2.b check output rank 0 is N\n+  if (output_shape_vals[axis] != inputs.size()) {\n+    op->emitOpError(\"PackOp: output tensor shape mismatch.\");\n+    return nullptr;\n+  }\n+  ArrayAttr output_shape_attr = rewriter.getI64ArrayAttr(output_shape_vals);\n+\n+  // Most of the cases when PackOp.axis() is within [0, rank(input) - 1].\n+  // We can directly concatenate along that axis and perform the reshape.\n+  // For example, stack N [A, B, C] input tensor ranks along axis = 1\n+  // after concatenation, output will be [A, N * B, C]\n+  // and then reshape it into [A, N, B, C]\n+  // a special case would be PackOp.axis() equal to rank(input), in which case\n+  // we can't directly concatenate along the PackOp.axis(), instead\n+  // we concat along axis=0, and reshape into [N, A, B, C]\n+  // and then we need an extra transpose to [A, B, C, N].\n+  int64_t concat_axis;\n+  SmallVector<int32_t, 8> perm;\n+  SmallVector<int64_t, 8> reshape_output_shape;\n+  if (axis == 0 && input_tensor_rank == 0) {\n+    concat_axis = 0;\n+    // Don't need reshape and perm, since we inputs are reshaped into rank 1\n+    // size 1.  Output will be rank 1 size N.\n+  } else if (axis == input_tensor_rank) {\n+    concat_axis = 0;\n+\n+    // A special case when stack axis is equal to input tensor rank:\n+    // Output shape is [A, B, C, N]\n+    // so reshape output will be [N, A, B, C]\n+    // and perm will be [1, 2, 3, 0].\n+    reshape_output_shape.push_back(output_shape_vals[axis]);\n+    for (int d = 0; d < input_tensor_rank; d++) {\n+      perm.push_back(d + 1);\n+      reshape_output_shape.push_back(output_shape_vals[d]);\n+    }\n+    perm.push_back(0);\n+  } else {\n+    // General case, doesn't need perm vector.\n+    concat_axis = axis;\n+    reshape_output_shape.assign(output_shape_vals.begin(),\n+                                output_shape_vals.end());\n+  }\n+  IntegerAttr concat_axis_attr = rewriter.getI64IntegerAttr(concat_axis);\n+  ArrayAttr shape_attr = rewriter.getI64ArrayAttr(reshape_output_shape);\n+\n+  // For each concat output, shape will be different.\n+  // If input shape is [A, B, C] and concat_axis = 0, 1st concat output will\n+  // be [2 * A, B, C].\n+  int orig_input_dim_on_axis;\n+  std::vector<int64_t> concat_output_shape;\n+  if (input_tensor_rank == 0) {\n+    concat_output_shape.push_back(1);\n+    orig_input_dim_on_axis = 1;\n+  } else {\n+    for (int i = 0; i < input_tensor_rank; i++) {\n+      concat_output_shape.push_back(input0_tensor_shape[i]);\n+    }\n+    orig_input_dim_on_axis = input0_tensor_shape[concat_axis];\n+  }\n+\n+  concat_output_shape[concat_axis] = orig_input_dim_on_axis * 2;\n+  auto concat_type = RankedTensorType::get(\n+      ArrayRef<int64_t>(concat_output_shape), result_type.getElementType());\n+  auto a1_concat_op = rewriter.create<tosa::ConcatOp>(\n+      op->getLoc(), concat_type, inputs[0], inputs[1], concat_axis_attr);\n+\n+  // K-th concat output will be [(k+1) * A, B, C], last output will be [N * A,\n+  // B, C].\n+  for (int i = 2; i < inputs.size(); i++) {\n+    concat_output_shape[concat_axis] = orig_input_dim_on_axis * (i + 1);\n+    concat_type = RankedTensorType::get(ArrayRef<int64_t>(concat_output_shape),\n+                                        result_type.getElementType());\n+    a1_concat_op = rewriter.create<tosa::ConcatOp>(op->getLoc(), concat_type,\n+                                                   a1_concat_op.getResult(),\n+                                                   inputs[i], concat_axis_attr);\n+  }\n+\n+  Operation* lowered_op = nullptr;\n+  // Doesn't need reshape or transpose if input tensor is rank 0, since inputs\n+  // are reshaped beforehand.\n+  if (input_tensor_rank == 0) {\n+    lowered_op = a1_concat_op;\n+  } else {\n+    // Reshape [N * A, B, C] to [N, A, B, C].\n+    auto reshape_output_type = RankedTensorType::get(\n+        ArrayRef<int64_t>(reshape_output_shape), result_type.getElementType());\n+\n+    auto a2_reshape_op =\n+        rewriter.create<tosa::ReshapeOp>(op->getLoc(), reshape_output_type,\n+                                         a1_concat_op.getResult(), shape_attr);\n+\n+    // If axis is equal to input tensor rank, then we need extra transpose\n+    // [N, A, B, C] to [A, B, C, N]\n+    if (axis == input_tensor_rank) {\n+      auto a3_transpose_perm =\n+          get1DConstTensor<tosa::ConstOp, int32_t>(rewriter, op, perm);\n+      auto a3_transpose_op = rewriter.create<tosa::TransposeOp>(\n+          op->getLoc(), result_type, a2_reshape_op.getResult(),\n+          a3_transpose_perm);\n+      lowered_op = a3_transpose_op;\n+    } else {\n+      lowered_op = a2_reshape_op;\n+    }\n+  }\n+\n+  return lowered_op;\n+}\n+\n+// Lowers the Unpack operator to TOSA\n+Operation* convertUnpackOp(PatternRewriter& rewriter, Operation* op,\n+                           Value input_value, int32_t axis) {\n+  auto input_type = input_value.getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) return nullptr;\n+\n+  auto input_shape = input_type.getShape();\n+  int64_t input_rank = input_shape.size();\n+\n+  SmallVector<Value, 4> results_vec;\n+\n+  // Negative axis allowed as long as it's within [-input_rank, input_rank).\n+  if (axis < 0) axis += input_rank;\n+\n+  assert(axis > 0 && axis < input_shape.size());\n+\n+  // A list of the output types for each slice op\n+  SmallVector<Type, 4> outs_type_vec;\n+\n+  // Step 1: transpose 'axis' to leftmost dimension.\n+  Value transposed_input_value;\n+  if (axis != 0) {\n+    SmallVector<int32_t, 8> perm_vec;\n+    SmallVector<int64_t, 2> a1_transpose_shape(input_rank);\n+\n+    perm_vec.push_back(axis);\n+    for (int i = 0; i < input_rank; i++) {\n+      if (i == axis) continue;\n+      perm_vec.push_back(i);\n+    }\n+\n+    auto a1_transpose_perm =\n+        get1DConstTensor<tosa::ConstOp, int32_t>(rewriter, op, perm_vec);\n+\n+    for (int i = 0; i < input_rank; i++) {\n+      a1_transpose_shape[i] = input_shape[perm_vec[i]];\n+    }\n+\n+    auto a1_transpose_op = rewriter.create<tosa::TransposeOp>(\n+        op->getLoc(),\n+        RankedTensorType::get(ArrayRef<int64_t>(a1_transpose_shape),\n+                              input_type.getElementType()),\n+        input_value, a1_transpose_perm);\n+\n+    transposed_input_value = a1_transpose_op.getResult();\n+  } else {\n+    // Do nothing if axis is already at leftmost dimension.\n+    transposed_input_value = input_value;\n+  }\n+\n+  // Step 2: slice [N, A, B, C] into N [A, B, C].\n+  auto transposed_input_type =\n+      transposed_input_value.getType().dyn_cast<RankedTensorType>();\n+  if (!transposed_input_type) return nullptr;\n+\n+  auto transposed_input_shape = transposed_input_type.getShape();\n+  int64_t transposed_input_rank = transposed_input_shape.size();\n+\n+  for (int i = 0; i < transposed_input_shape[0]; i++) {\n+    SmallVector<int64_t, 4> begin_vals, size_vals, shape_vals;\n+\n+    for (int j = 0; j < transposed_input_rank; j++) {\n+      if (j == 0) {\n+        begin_vals.push_back(i);\n+        size_vals.push_back(1);\n+      } else {\n+        begin_vals.push_back(0);\n+        size_vals.push_back(transposed_input_shape[j]);\n+        shape_vals.push_back(transposed_input_shape[j]);\n+      }\n+    }\n+\n+    ArrayAttr begin = rewriter.getI64ArrayAttr(begin_vals);\n+    ArrayAttr size = rewriter.getI64ArrayAttr(size_vals);\n+\n+    auto a2_slice_op = rewriter.create<tosa::SliceOp>(\n+        op->getLoc(),\n+        RankedTensorType::get(ArrayRef<int64_t>(size_vals),\n+                              transposed_input_type.getElementType()),\n+        transposed_input_value, begin, size);\n+\n+    auto a3_reshape_op = rewriter.create<tosa::ReshapeOp>(\n+        op->getLoc(),\n+        RankedTensorType::get(ArrayRef<int64_t>(shape_vals),\n+                              transposed_input_type.getElementType()),\n+        a2_slice_op.getResult(), rewriter.getI64ArrayAttr(shape_vals));\n+\n+    outs_type_vec.push_back(RankedTensorType::get(\n+        ArrayRef<int64_t>(shape_vals), transposed_input_type.getElementType()));\n+\n+    results_vec.push_back(a3_reshape_op.getResult());\n+  }\n+\n+  // Combine the sequence of tosa.slice() ops into a list\n+  // using the IdentityN operator.\n+  auto identityn_op = rewriter.create<tosa::IdentityNOp>(\n+      op->getLoc(), ArrayRef<Type>(outs_type_vec), results_vec);\n+\n+  return identityn_op;\n+}\n+\n+// Lowers the Select operator to TOSA.\n+Operation* convertSelectOp(PatternRewriter& rewriter, Operation* op,\n+                           Value result_value, Value condition_value,\n+                           Value x_value, Value y_value) {\n+  auto result_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  auto condition_type = condition_value.getType().dyn_cast<RankedTensorType>();\n+  auto x_type = x_value.getType().dyn_cast<RankedTensorType>();\n+  auto y_type = y_value.getType().dyn_cast<RankedTensorType>();\n+\n+  Operation* result_op = nullptr;\n+\n+  if (!result_type || !condition_type || !x_type || !y_type) {\n+    op->emitOpError(\"Select: failed ranked tensor type check\");\n+    return nullptr;\n+  }\n+\n+  // First check whether we need to reshape the condition to match\n+  // the same rank as the then/else clauses.\n+  if (result_type.getRank() == condition_type.getRank()) {\n+    // Nothing to reshape.\n+    result_op = rewriter.create<tosa::SelectOp>(\n+        op->getLoc(), result_type, condition_value, x_value, y_value);\n+  } else {\n+    // Need to reshape the condition.\n+    SmallVector<int64_t, 8> new_cond_dims;\n+    for (int i = 0; i < (result_type.getRank() - condition_type.getRank());\n+         i++) {\n+      new_cond_dims.push_back(1);\n+    }\n+    for (int i = 0; i < condition_type.getRank(); i++) {\n+      new_cond_dims.push_back(condition_type.getShape()[i]);\n+    }\n+\n+    auto reshape_op = rewriter.create<tosa::ReshapeOp>(\n+        op->getLoc(),\n+        RankedTensorType::get(ArrayRef<int64_t>(new_cond_dims),\n+                              condition_type.getElementType()),\n+        condition_value, rewriter.getI64ArrayAttr(new_cond_dims));\n+\n+    auto new_select = rewriter.create<tosa::SelectOp>(\n+        op->getLoc(), result_type, reshape_op, x_value, y_value);\n+    result_op = new_select;\n+  }\n+\n+  return result_op;\n+}\n+\n+// Lowers the ZerosLike operator to TOSA by creating a constant\n+// of the desired type and shape.\n+Operation* convertZerosLikeOp(PatternRewriter& rewriter, Operation* op,\n+                              Value result, Value input) {\n+  auto result_type = result.getType().dyn_cast<RankedTensorType>();\n+  if (!result_type) {\n+    op->emitOpError(\"Zeroslike: result not ranked tensor type\");\n+    return nullptr;\n+  }\n+\n+  auto input_type = input.getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"Zeroslike: input not ranked tensor type\");\n+    return nullptr;\n+  }\n+\n+  auto input_shape = input_type.getShape();\n+\n+  ShapedType zero_type =\n+      RankedTensorType::get(input_shape, input_type.getElementType());\n+  Attribute zero_attr = rewriter.getZeroAttr(zero_type);\n+\n+  auto const_op =\n+      rewriter.create<tosa::ConstOp>(op->getLoc(), zero_type, zero_attr);\n+\n+  return const_op;\n+}\n+\n+// Lowers the Mul operator to TOSA.  For quantized types, this requires\n+// inserting rescale operators before and after the operation.\n+Operation* convertMultiplyOp(PatternRewriter& rewriter, Operation* op,\n+                             Value output_val, Value input_lhs_val,\n+                             Value input_rhs_val) {\n+  auto input_lhs_type = input_lhs_val.getType().dyn_cast<RankedTensorType>();\n+  auto input_rhs_type = input_rhs_val.getType().dyn_cast<RankedTensorType>();\n+  auto output_type = output_val.getType().dyn_cast<RankedTensorType>();\n+  // Not a ranked tensor output\n+  if (!input_lhs_type || !input_rhs_type || !output_type) return nullptr;\n+\n+  bool input_lhs_is_qtype =\n+      input_lhs_type.getElementType().isa<mlir::quant::UniformQuantizedType>();\n+  bool input_rhs_is_qtype =\n+      input_rhs_type.getElementType().isa<mlir::quant::UniformQuantizedType>();\n+  bool output_is_qtype =\n+      output_type.getElementType().isa<mlir::quant::UniformQuantizedType>();\n+\n+  if (input_lhs_is_qtype != output_is_qtype ||\n+      input_rhs_is_qtype != output_is_qtype) {\n+    op->emitOpError(\n+        \"ConvertMultiplyOp: input/output tensor should \"\n+        \"be all quantized or all native\");\n+    return nullptr;\n+  }\n+\n+  Value output;\n+  if (output_is_qtype) {\n+    auto rescale_type =\n+        RankedTensorType::get(output_type.getShape(), rewriter.getI32Type());\n+    auto input_lhs_qtype = input_lhs_type.getElementType()\n+                               .dyn_cast<mlir::quant::UniformQuantizedType>();\n+    auto input_rhs_qtype = input_rhs_type.getElementType()\n+                               .dyn_cast<mlir::quant::UniformQuantizedType>();\n+    auto output_qtype = output_type.getElementType()\n+                            .dyn_cast<mlir::quant::UniformQuantizedType>();\n+\n+    double in_lhs_scale = input_lhs_qtype.getScale();\n+    double in_rhs_scale = input_rhs_qtype.getScale();\n+    double output_scale = output_qtype.getScale();\n+\n+    double output_rescale_scale = in_lhs_scale * in_rhs_scale / output_scale;\n+\n+    auto op1_rescale_lhs = buildRescaleToInt32(\n+        rewriter, op, input_lhs_val, 1.0f, input_lhs_qtype.getZeroPoint());\n+    auto op2_rescale_rhs = buildRescaleToInt32(\n+        rewriter, op, input_rhs_val, 1.0f, input_rhs_qtype.getZeroPoint());\n+    auto op3_mul_op1_op2 = rewriter.create<tosa::MulOp>(\n+        op->getLoc(), rescale_type, op1_rescale_lhs, op2_rescale_rhs, 0);\n+    auto op4_rescale_op3 = buildRescaleFromInt32(\n+        rewriter, op, output_type, op3_mul_op1_op2.getResult(),\n+        output_rescale_scale, output_qtype.getZeroPoint());\n+    output = op4_rescale_op3;\n+  } else {\n+    auto op1_mul_in = rewriter.create<tosa::MulOp>(\n+        op->getLoc(), output_type, input_lhs_val, input_rhs_val, 0);\n+\n+    output = op1_mul_in.getResult();\n+  }\n+\n+  return output.getDefiningOp();\n+}\n+\n+// Lowers the SquaredDifference operator to TOSA.\n+Operation* convertSquaredDifferenceOp(PatternRewriter& rewriter, Operation* op,\n+                                      Value result, Value x, Value y) {\n+  // Squared-difference is (x-y)*(x-y).\n+  // This lowering calculates the difference and multiplies.\n+  auto result_type = result.getType().dyn_cast<RankedTensorType>();\n+  if (!result_type) {\n+    op->emitOpError(\"SquaredDifference: result not ranked tensor type\");\n+    return nullptr;\n+  }\n+\n+  auto x_type = x.getType().dyn_cast<RankedTensorType>();\n+  auto y_type = y.getType().dyn_cast<RankedTensorType>();\n+  if (!x_type || !y_type) {\n+    op->emitOpError(\"SquaredDifference: inputs not ranked tensor type\");\n+    return nullptr;\n+  }\n+\n+  auto sub_op = rewriter.create<tosa::SubOp>(op->getLoc(), result_type, x, y);\n+  auto square_op = rewriter.create<tosa::MulOp>(\n+      op->getLoc(), result_type, sub_op.getResult(), sub_op.getResult(), 0);\n+  return square_op;\n+}\n+\n+// Lowers the Round operator to TOSA.\n+Operation* convertRoundOp(PatternRewriter& rewriter, Operation* op,\n+                          Value result, Value input) {\n+  // Implements banker's rounding by calculating floor(input + 0.5).\n+  auto result_type = result.getType().dyn_cast<RankedTensorType>();\n+  if (!result_type) {\n+    op->emitOpError(\"Round: result not ranked tensor type\");\n+    return nullptr;\n+  }\n+\n+  auto input_type = input.getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"Round: input not ranked tensor type\");\n+    return nullptr;\n+  }\n+\n+  auto add_op = rewriter.create<tosa::AddOp>(\n+      op->getLoc(), result_type, input,\n+      getTosaConstTensorSingleF32(rewriter, op, 0.5));\n+  auto floor_op = rewriter.create<tosa::FloorOp>(op->getLoc(), result_type,\n+                                                 add_op.getResult());\n+\n+  return floor_op;\n+}\n+\n+// Lowers ConcatV2 to TOSA.\n+Operation* convertConcatV2Op(PatternRewriter& rewriter, Operation* op,\n+                             Value result_value, SmallVector<Value, 8>& values,\n+                             int32_t axis) {\n+  // ConcatV2 becomes a series of TOSA Concat operators that take pairs of\n+  // tensors as arguments.   Rank-0 tensors are reshaped to Rank-1,\n+  // shape (1,) tensors.\n+  auto result_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  if (!result_type) {\n+    op->emitOpError(\"ConcatV2Op: result type not ranked tensor.\");\n+    return nullptr;\n+  }\n+\n+  // Valid axis in TF is [-rank(input), rank(input)).\n+  // Valid axis in TOSA is [0, rank(input)).\n+  // Plus rank(input) once if axis is negative.\n+  auto input_type = op->getOperand(0).getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"ConcatV2Op: input type not ranked tensor.\");\n+    return nullptr;\n+  }\n+\n+  auto input_rank = input_type.getShape().size();\n+\n+  if (axis < 0) axis += input_rank;\n+\n+  assert(values.size() >= 2);\n+\n+  if (!values[0].getType().dyn_cast<RankedTensorType>() ||\n+      !values[1].getType().dyn_cast<RankedTensorType>()) {\n+    op->emitOpError(\"ConcatV2Op: value type not ranked tensor.\");\n+    return nullptr;\n+  }\n+\n+  Value lhs_val = values[0];\n+  Value rhs_val = values[1];\n+  auto lhs_type = lhs_val.getType().dyn_cast<RankedTensorType>();\n+  auto rhs_type = rhs_val.getType().dyn_cast<RankedTensorType>();\n+  ArrayRef<int64_t> lhs_tensor_shape = lhs_type.getShape();\n+  ArrayRef<int64_t> rhs_tensor_shape = rhs_type.getShape();\n+  int input_tensor_rank = lhs_tensor_shape.size();\n+\n+  // For each concat output, shape will be different.\n+  // If input tensors are rank 0, should reshape them to rank 1 size 1 before\n+  // performing concat. If not, most dimensions should have same size as input\n+  // except the concat'd axis.\n+  //\n+  // If input is [A0, B, C] and [A1, B, C] and axis = 0\n+  // this concat output will be [A0 + A1, B, C].\n+  std::vector<int64_t> concat_result_shape;\n+  if (input_tensor_rank == 0) {\n+    if (axis != 0) {\n+      op->emitOpError(\"ConcatV2Op: axis invalid.\");\n+      return nullptr;\n+    }\n+    SmallVector<int64_t, 8> reshape_rank1_size1_shape{1};\n+    auto reshape_rank1_size1_type =\n+        RankedTensorType::get(ArrayRef<int64_t>(reshape_rank1_size1_shape),\n+                              result_type.getElementType());\n+    ArrayAttr shape_rank1_size1_attr =\n+        rewriter.getI64ArrayAttr(reshape_rank1_size1_shape);\n+    for (int i = 0; i < values.size(); i++) {\n+      auto a0_reshape_op = rewriter.create<tosa::ReshapeOp>(\n+          op->getLoc(), reshape_rank1_size1_type, values[i],\n+          shape_rank1_size1_attr);\n+      values[i] = a0_reshape_op.getResult();\n+    }\n+    concat_result_shape.push_back(2);\n+  } else {\n+    if (axis < 0 || axis >= input_tensor_rank) {\n+      op->emitOpError(\"ConcatV2Op: axis invalid.\");\n+      return nullptr;\n+    }\n+    for (int i = 0; i < input_tensor_rank; i++) {\n+      concat_result_shape.push_back(lhs_tensor_shape[i]);\n+    }\n+    concat_result_shape[axis] = lhs_tensor_shape[axis] + rhs_tensor_shape[axis];\n+  }\n+\n+  auto concat_type = RankedTensorType::get(\n+      ArrayRef<int64_t>(concat_result_shape), result_type.getElementType());\n+\n+  mlir::quant::UniformQuantizedType lhs_quant_type =\n+      lhs_type.getElementType()\n+          .dyn_cast_or_null<mlir::quant::UniformQuantizedType>();\n+  mlir::quant::UniformQuantizedType rhs_quant_type =\n+      rhs_type.getElementType()\n+          .dyn_cast_or_null<mlir::quant::UniformQuantizedType>();\n+  mlir::quant::UniformQuantizedType result_quant_type =\n+      result_type.getElementType()\n+          .dyn_cast_or_null<mlir::quant::UniformQuantizedType>();\n+\n+  double lhs_scale, rhs_scale, result_scale;\n+  int32_t lhs_zeropoint, rhs_zeropoint, result_zeropoint;\n+  RankedTensorType const_type, i32_type;\n+  DenseElementsAttr const_attr;\n+\n+  // tfl.concat currently allows different scales for each input tensor, which\n+  // TFlite team will fix in:\n+  // https://github.com/tensorflow/tensorflow/issues/39658\n+  //\n+  // For backward compatibility, we still need to support this artifact by\n+  // scaling inputs to let them have the same scales.\n+  if (result_quant_type && lhs_quant_type && rhs_quant_type) {\n+    lhs_scale = (double)lhs_quant_type.getScale();\n+    lhs_zeropoint = lhs_quant_type.getZeroPoint();\n+    rhs_scale = (double)rhs_quant_type.getScale();\n+    rhs_zeropoint = rhs_quant_type.getZeroPoint();\n+    result_scale = (double)result_quant_type.getScale();\n+    result_zeropoint = result_quant_type.getZeroPoint();\n+\n+    const_type = RankedTensorType::get({}, result_quant_type);\n+    i32_type = RankedTensorType::get({}, rewriter.getIntegerType(32));\n+    const_attr = DenseElementsAttr::get(i32_type, result_zeropoint);\n+    auto const_op =\n+        rewriter.create<tosa::ConstOp>(op->getLoc(), const_type, const_attr);\n+\n+    // Rescale input if scale is not equal to output tensor scale.\n+    if (lhs_scale != result_scale) {\n+      auto rescale_type =\n+          RankedTensorType::get(lhs_type.getShape(), result_quant_type);\n+\n+      auto rescale_op = buildRescale(rewriter, op, rescale_type, lhs_val,\n+                                     lhs_scale / result_scale, lhs_zeropoint,\n+                                     result_zeropoint);\n+\n+      lhs_val = rescale_op;\n+    }\n+    if (rhs_scale != result_scale) {\n+      auto rescale_type =\n+          RankedTensorType::get(rhs_type.getShape(), result_quant_type);\n+\n+      auto rescale_op = buildRescale(rewriter, op, rescale_type, rhs_val,\n+                                     rhs_scale / result_scale, rhs_zeropoint,\n+                                     result_zeropoint);\n+\n+      rhs_val = rescale_op;\n+    }\n+  }\n+\n+  auto concat_op = rewriter.create<tosa::ConcatOp>(\n+      op->getLoc(), concat_type, lhs_val, rhs_val,\n+      rewriter.getI64IntegerAttr(axis));\n+  for (int i = 2; i < values.size(); i++) {\n+    rhs_val = values[i];\n+    rhs_type = rhs_val.getType().dyn_cast<RankedTensorType>();\n+    rhs_tensor_shape = rhs_type.getShape();\n+    rhs_quant_type = rhs_type.getElementType()\n+                         .dyn_cast_or_null<mlir::quant::UniformQuantizedType>();\n+\n+    if (input_tensor_rank == 0) {\n+      concat_result_shape[axis] = concat_result_shape[axis] + 1;\n+    } else {\n+      concat_result_shape[axis] =\n+          concat_result_shape[axis] + rhs_tensor_shape[axis];\n+    }\n+    concat_type = RankedTensorType::get(ArrayRef<int64_t>(concat_result_shape),\n+                                        result_type.getElementType());\n+\n+    if (rhs_quant_type && result_quant_type) {\n+      rhs_scale = (float)rhs_quant_type.getScale();\n+      rhs_zeropoint = rhs_quant_type.getZeroPoint();\n+\n+      if (rhs_scale != result_scale) {\n+        auto rescale_type =\n+            RankedTensorType::get(rhs_type.getShape(), result_quant_type);\n+\n+        auto rescale_op = buildRescale(rewriter, op, rescale_type, rhs_val,\n+                                       rhs_scale / result_scale, rhs_zeropoint,\n+                                       result_zeropoint);\n+\n+        rhs_val = rescale_op;\n+      }\n+    }\n+\n+    concat_op = rewriter.create<tosa::ConcatOp>(\n+        op->getLoc(), concat_type, concat_op.getResult(), rhs_val,\n+        rewriter.getI64IntegerAttr(axis));\n+  }\n+\n+  return concat_op;\n+}\n+\n+// Lowers SpaceToBatchND to TOSA.\n+Operation* convertSpaceToBatchNDOp(PatternRewriter& rewriter, Operation* op,\n+                                   Value result_value, Value input_value,\n+                                   Value block_shape_value,\n+                                   Value paddings_value) {\n+  /////////////////////////////////////////////////\n+  // Operator: output = SpaceToBatchND(input, block_shape, paddings)\n+  // Lowering:\n+  //\n+  // SpaceToBatch input tensors are broken into three pieces:\n+  //   (a) batch dimension (N in NHWC)\n+  //   (b) input being transformed to batch dimension (typically H, W in NHWC)\n+  //   (c) remainder of input (typically C in NHWC)\n+  //\n+  // Step 0. Generate padding constant for the first reshape.\n+  //   No padding on the batch dimension\n+  //   The input paddings array is addressed as [input_rank][2]\n+  //   No padding on the remaining dimensions\n+  //\n+  //  a0_pad_const = tosa.const(input=Tensor<input_rank, 2>)\n+  //\n+  // Step 1. Pad the input tensor\n+  //\n+  //  a1_pad_input_op = tosa.pad(input=input, shape=a0_pad_const_op)\n+  //\n+  // Step 2. Reshape the padded structure of shape padded_shape to\n+  // [batch + padded_shape[1] / block_shape[0], block_shape[0], ...\n+  //    padded_shape[M] / block_shape[M-1], block_shape[M-1]] +\n+  //    remaining_shape\n+  //\n+  // block_rank = M (number of elements in block_shape)\n+  // New rank: input_rank + block_rank\n+  //\n+  //  a2_reshape_a1_op = tosa.reshape(input=a1_pad_input_op, shape=a2_shape)\n+  //\n+  // Step 3. Transpose dimensions to:\n+  //  block-shape +\n+  //  [batch] +\n+  //  [padded_shape[1] / block_shape[0],\n+  // ...\n+  //  [padded_shape[M] / block_shape[M-1]] +\n+  //  remaining_shape\n+  //\n+  // a3_transpose_a2_op = tosa.tranpose(input=a2_reshape_a1_op,\n+  // perms=a3_perm)\n+  //\n+  // Step 4. Reshape the transposed tensor to flatten block_shape stuff\n+  // into the batch dimension with the following shape:\n+  // [ batch * prod(block_shape)] +\n+  // [ padded_shape[1] / block_shape[0],\n+  //   ...,\n+  // padded_shape[M] / block_shape[M-1]] +\n+  // remaining_shape\n+  //\n+  //  a4_reshape_a3_op = tosa.reshape(input=a3_tranpose_a2_op,\n+  //  shape=a3_shape)\n+  //\n+\n+  auto result_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  auto input_type = input_value.getType().dyn_cast<RankedTensorType>();\n+  auto block_shape_type =\n+      block_shape_value.getType().dyn_cast<RankedTensorType>();\n+  auto paddings_type = paddings_value.getType().dyn_cast<RankedTensorType>();\n+\n+  // Not a ranked tensor output.\n+  if (!result_type) {\n+    op->emitOpError(\"SpaceToBatchND: result type not ranked tensor\");\n+    return nullptr;\n+  }\n+  if (!input_type) {\n+    op->emitOpError(\"SpaceToBatchND: input type not ranked tensor\");\n+    return nullptr;\n+  }\n+  if (!block_shape_type) {\n+    op->emitOpError(\"SpaceToBatchND: block shape type not ranked tensor\");\n+    return nullptr;\n+  }\n+  if (!paddings_type) {\n+    op->emitOpError(\"SpaceToBatchND: paddings type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  // Follow implementation in\n+  // tensorflow/compiler/tf2xla/kernels/spacetobatch_op.cc\n+\n+  // So, to figure out the spatial_shape, remove the batch dimension and\n+  // then use the next block_rank dimensions.  The remaining dimensions are\n+  // remaining_shape.\n+\n+  auto block_shape = block_shape_type.getShape();\n+  auto input_shape = input_type.getShape();\n+\n+  int block_rank = block_shape[0];\n+  int batch_size = input_shape[0];\n+  int input_rank = input_type.getRank();\n+  int remaining_shape_rank = input_rank - block_rank - 1;\n+  int block_num_elems = 1;\n+  int padding_sum = 0;\n+\n+  ElementsAttr block_shape_elems;\n+  ElementsAttr paddings_elems;\n+\n+  if (!matchPattern(block_shape_value, m_Constant(&block_shape_elems)))\n+    return nullptr;\n+\n+  if (!matchPattern(paddings_value, m_Constant(&paddings_elems)))\n+    return nullptr;\n+\n+  SmallVector<int32_t, 2> a0_pad_const(2 * (input_rank));\n+  SmallVector<int64_t, 2> padded_shape(input_rank);\n+\n+  // 1. Pad based on paddings operand.  No padding on the batch dimension.\n+  // The a0_pad_const array is addressed as [input_rank][2], but\n+  // it is flattened to a 1D array because LLVM appears to only accept 1D.\n+  //\n+  // padded_shape[] is the shape of the padded output of step a1.\n+  // The name is retained for consistency with the TF reference code.\n+  padded_shape[0] = input_shape[0];\n+\n+  // Batch dimension padding\n+  a0_pad_const[0] = 0;\n+  a0_pad_const[1] = 0;\n+\n+  // This iterator seems to be the only reliable way to get\n+  // int values out of a multi-dimensional ElementsAttr.\n+  int idx = 0;\n+\n+  for (auto i : paddings_elems.getValues<IntegerAttr>()) {\n+    a0_pad_const[idx + 2] = i.getInt();\n+    padding_sum += i.getInt();\n+    idx++;\n+  }\n+\n+  // Insert padding on the spatial shape dimensions\n+  for (int i = 0; i < block_rank; i++) {\n+    int32_t lo_pad = a0_pad_const[2 * (i + 1) + 0];\n+    int32_t hi_pad = a0_pad_const[2 * (i + 1) + 1];\n+\n+    padded_shape[i + 1] = input_shape[i + 1] + lo_pad + hi_pad;\n+  }\n+\n+  // No padding on the remaining_shape dimensions\n+  for (int i = 0; i < remaining_shape_rank; i++) {\n+    a0_pad_const[2 * (i + block_rank + 1) + 0] = 0;\n+    a0_pad_const[2 * (i + block_rank + 1) + 1] = 0;\n+    padded_shape[i + block_rank + 1] = input_shape[i + block_rank + 1];\n+  }\n+\n+  auto a0_pad_const_attr_type =\n+      RankedTensorType::get({(input_rank), 2}, rewriter.getIntegerType(32));\n+\n+  // Create a const op to generate the tensor type for the input padding array\n+  auto a0_pad_const_op = rewriter.create<tosa::ConstOp>(\n+      op->getLoc(), a0_pad_const_attr_type,\n+      DenseElementsAttr::get(a0_pad_const_attr_type,\n+                             llvm::makeArrayRef<int32_t>(a0_pad_const)));\n+\n+  auto a1_pad_input_op = rewriter.create<tosa::PadOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(padded_shape),\n+                            result_type.getElementType()),\n+      input_value, a0_pad_const_op.getResult());\n+\n+  // 2. Reshape the padded structure of shape padded_shape to\n+  // [batch + padded_shape[1] / block_shape[0], block_shape[0], ...\n+  //    padded_shape[M] / block_shape[M-1], block_shape[M-1]] +\n+  //    remaining_shape\n+\n+  // block_rank = M (number of elements in block_shape)\n+  // New rank: input_rank + block_rank\n+  SmallVector<int64_t, 2> a2_shape(1 + block_rank * 2 + remaining_shape_rank);\n+\n+  // First dimension is batch.\n+  a2_shape[0] = input_type.getShape()[0];\n+  for (int i = 0; i < block_rank; i++) {\n+    int32_t block_shape_val =\n+        rewriter\n+            .getI32IntegerAttr(\n+                block_shape_elems.getValue<IntegerAttr>(i).getInt())\n+            .getInt();\n+    a2_shape[1 + i * 2 + 0] = padded_shape[1 + i] / block_shape_val;\n+    a2_shape[1 + i * 2 + 1] = block_shape_val;\n+    block_num_elems *= block_shape_val;\n+  }\n+\n+  // Copy in the remaining block shape.\n+  for (int i = 0; i < remaining_shape_rank; i++) {\n+    a2_shape[1 + block_rank * 2 + i] = input_shape[1 + block_rank + i];\n+  }\n+\n+  auto a2_reshape_a1_op = rewriter.create<tosa::ReshapeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(a2_shape),\n+                            result_type.getElementType()),\n+      a1_pad_input_op.getResult(), rewriter.getI64ArrayAttr(a2_shape));\n+\n+  // 3. Transpose dimensions to:\n+  //  block-shape +\n+  //  [batch] +\n+  //  [padded_shape[1] / block_shape[0],\n+  // ...\n+  //  [padded_shape[M] / block_shape[M-1]] +\n+  //  remaining_shape\n+  int32_t a2_reshape_a1_rank = a2_reshape_a1_op.getResult()\n+                                   .getType()\n+                                   .dyn_cast<RankedTensorType>()\n+                                   .getRank();\n+  SmallVector<int32_t, 8> a3_perm(a2_reshape_a1_rank);\n+  SmallVector<int64_t, 2> a3_transpose_shape(a2_reshape_a1_rank);\n+\n+  for (int i = 0; i < block_rank; i++) {\n+    a3_perm[i] = 1 + 2 * i + 1;\n+    a3_perm[block_rank + 1 + i] = 1 + 2 * i;\n+  }\n+  a3_perm[block_rank] = 0;\n+  for (int i = 1 + block_rank * 2; i < a2_reshape_a1_rank; i++) {\n+    a3_perm[i] = i;\n+  }\n+\n+  for (int i = 0; i < a3_transpose_shape.size(); i++) {\n+    a3_transpose_shape[i] = a2_shape[a3_perm[i]];\n+  }\n+\n+  auto a3_transpose_const =\n+      get1DConstTensor<tosa::ConstOp, int32_t>(rewriter, op, a3_perm);\n+\n+  auto a3_transpose_a2_op = rewriter.create<tosa::TransposeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(a3_transpose_shape),\n+                            result_type.getElementType()),\n+      a2_reshape_a1_op.getResult(), a3_transpose_const);\n+\n+  // 4. Reshape the transposed tensor to flatten block_shape\n+  // into the batch dimension with the following shape:\n+  // [ batch * prod(block_shape)] +\n+  // [ padded_shape[1] / block_shape[0],\n+  //   ...,\n+  // padded_shape[M] / block_shape[M-1]] +\n+  // remaining_shape\n+  SmallVector<int64_t, 2> a4_reshape_shape(input_rank);\n+\n+  // Batch\n+  a4_reshape_shape[0] = batch_size * block_num_elems;\n+\n+  // padded shape / block_shape.\n+  for (int i = 0; i < block_rank; i++) {\n+    int32_t block_shape_val =\n+        rewriter\n+            .getI32IntegerAttr(\n+                block_shape_elems.getValue<IntegerAttr>(i).getInt())\n+            .getInt();\n+    a4_reshape_shape[i + 1] = padded_shape[i + 1] / block_shape_val;\n+  }\n+\n+  // Copy in remainder shape.\n+  for (int i = 0; i < remaining_shape_rank; i++) {\n+    a4_reshape_shape[1 + block_rank + i] = input_shape[1 + block_rank + i];\n+  }\n+\n+  auto a4_reshape_a3_op = rewriter.create<tosa::ReshapeOp>(\n+      op->getLoc(), result_type, a3_transpose_a2_op.getResult(),\n+      rewriter.getI64ArrayAttr(a4_reshape_shape));\n+\n+  return a4_reshape_a3_op;\n+}\n+\n+// Lowers BatchToSpaceND to TOSA.\n+Operation* convertBatchToSpaceNDOp(PatternRewriter& rewriter, Operation* op,\n+                                   Value result_value, Value input_value,\n+                                   Value block_shape_value, Value crops_value) {\n+  /////////////////////////////////////////////////\n+  // Operator: output = BatchToSpaceND(input, block_shape, clips)\n+  // Lowering:\n+  //\n+  // BatchToSpace input tensors are broken into three pieces:\n+  //   (a) batch dimension (N in NHWC)\n+  //   (b) input being transformed from batch dimension (typically H, W in\n+  //   NHWC)\n+  //   (c) remainder of input (typically C in NHWC)\n+  //\n+  // Step 1. Reshape input to:\n+  // [block_shape[0],\n+  // ...\n+  // [block_shape[M-1],\n+  // [batch / prod(block_shape)]\n+  // [input_shape[1],\n+  // ...\n+  // [input_shape[N-1]\n+  //\n+  // a1_reshape_input_op = tosa.reshape(input=input, shape=a1_shape)\n+  //\n+  // Step 2. Permute to shape\n+  // [ batch / prod(block_shape) ],\n+  // [ input_shape[1] ], [ block_shape[1] ]\n+  //  ...\n+  // [ input_shape[M] ], [ block_shape[M-1]\n+  // + remaining_input_shapes input_shape[M .. N-1]\n+  //\n+  // a2_transpose_a1 = tosa.transpose(input=a1_reshape_input_op,\n+  // shape=a2_shape)\n+  //\n+  // Step 3. Reshape to:\n+  // [ batch / prod(block_shape) ],\n+  // [input_shape[1] * block_shape[0] ],\n+  //    ..\n+  // [input_shape[M * block_shape[M-1],\n+  // + remaining input shapes [input_shape[M+1.. N-1]]\n+  //\n+  // a3_reshape_a2 = tosa.reshape(input=a2_transpose_a1, shape=a3_shape)\n+  //\n+  // Step 4. Crop the start/end dimensions according to crops of the\n+  // a3_reshape_a2 shape\n+  //\n+  // a4_slice_a3 = tosa.slice(input=a3_reshape_a2, start=a4_start,\n+  // size=a4_size)\n+\n+  auto result_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  auto input_type = input_value.getType().dyn_cast<RankedTensorType>();\n+  auto block_shape_type =\n+      block_shape_value.getType().dyn_cast<RankedTensorType>();\n+  auto crops_type = crops_value.getType().dyn_cast<RankedTensorType>();\n+\n+  if (!result_type) {\n+    op->emitOpError(\"BatchToSpaceND: result type not ranked tensor\");\n+    return nullptr;\n+  }\n+  if (!input_type) {\n+    op->emitOpError(\"BatchToSpaceND: input type not ranked tensor\");\n+    return nullptr;\n+  }\n+  if (!block_shape_type) {\n+    op->emitOpError(\"BatchToSpaceND: block shape type not ranked tensor\");\n+    return nullptr;\n+  }\n+  if (!crops_type) {\n+    op->emitOpError(\"BatchToSpaceND: crops type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  // Another 4-step process\n+  int block_rank = block_shape_type.getShape()[0];\n+  int input_rank = input_type.getRank();\n+  int crops_dims = crops_type.getShape()[0];\n+  int remaining_shape_rank = input_rank - block_rank - 1;\n+  auto input_shape = input_type.getShape();\n+\n+  ElementsAttr block_shape_elems;\n+  ElementsAttr crops_elems;\n+\n+  if (!matchPattern(block_shape_value, m_Constant(&block_shape_elems))) {\n+    op->emitOpError(\"BatchToSpaceND: block_shape not a constant\");\n+    return nullptr;\n+  }\n+\n+  if (!matchPattern(crops_value, m_Constant(&crops_elems))) {\n+    op->emitOpError(\"BatchToSpaceND: crops not a constant\");\n+    return nullptr;\n+  }\n+\n+  std::vector<int64_t> block_shape(block_rank);\n+  std::vector<std::pair<int64_t, int64_t>> crops(crops_dims);\n+\n+  // Extract values for block_shape and crops now.\n+  int block_num_elems = 1;\n+  for (int i = 0; i < block_rank; i++) {\n+    int block_shape_val =\n+        rewriter\n+            .getI32IntegerAttr(\n+                block_shape_elems.getValue<IntegerAttr>(i).getInt())\n+            .getInt();\n+    block_num_elems *= block_shape_val;\n+    block_shape[i] = block_shape_val;\n+  }\n+\n+  // This iterator seems to be the only reliable way to get\n+  // int values out of a multi-dimensional ElementsAttr\n+  SmallVector<int32_t, 2> crops_const(2 * (crops_dims));\n+  int idx = 0;\n+  for (auto i : crops_elems.getValues<IntegerAttr>()) {\n+    crops_const[idx++] = i.getInt();\n+  }\n+\n+  for (int i = 0; i < crops_dims; i++) {\n+    int crops_lo = crops_const[i * crops_dims + 0];\n+    int crops_hi = crops_const[i * crops_dims + 1];\n+    crops[i] = std::make_pair(crops_lo, crops_hi);\n+  }\n+\n+  // Step 1. Reshape input to:\n+  // [block_shape[0],\n+  // ...\n+  // [block_shape[M-1],\n+  // [batch / prod(block_shape)]\n+  // [input_shape[1],\n+  // ...\n+  // [input_shape[N-1]\n+  SmallVector<int64_t, 2> a1_shape(block_rank + input_rank);\n+\n+  for (int i = 0; i < block_rank; i++) a1_shape[i] = block_shape[i];\n+\n+  a1_shape[block_rank] = input_shape[0] / block_num_elems;\n+\n+  for (int i = 0; i < input_rank - 1; i++)\n+    a1_shape[i + block_rank + 1] = input_shape[i + 1];\n+\n+  auto a1_reshape_input_op = rewriter.create<tosa::ReshapeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(a1_shape),\n+                            result_type.getElementType()),\n+      input_value, rewriter.getI64ArrayAttr(a1_shape));\n+\n+  // 2. Permute to shape\n+  // [ batch / prod(block_shape) ],\n+  // [ input_shape[1] ], [ block_shape[0] ]\n+  //  ...\n+  // [ input_shape[M] ], [ block_shape[M-1]\n+  // + remaining_input_shapes input_shape[M+1 .. N-1]\n+\n+  // 2a. calculate the permutation\n+  SmallVector<int32_t, 8> a2_perm(block_rank + input_rank);\n+  SmallVector<int64_t, 2> a2_transpose_shape(block_rank + input_rank);\n+\n+  a2_perm[0] = block_rank;\n+  for (int i = 0; i < block_rank; i++) {\n+    a2_perm[1 + i * 2 + 0] = block_rank + 1 + i;\n+    a2_perm[1 + i * 2 + 1] = i;\n+  }\n+\n+  for (int i = 0; i < remaining_shape_rank; i++) {\n+    a2_perm[1 + 2 * block_rank + i] = 1 + 2 * block_rank + i;\n+  }\n+\n+  // 2b. calculate the a2_permuted shape\n+  for (int i = 0; i < (block_rank + input_rank); i++) {\n+    a2_transpose_shape[i] = a1_shape[a2_perm[i]];\n+  }\n+\n+  auto a2_transpose_perm =\n+      get1DConstTensor<tosa::ConstOp, int32_t>(rewriter, op, a2_perm);\n+  auto a2_transpose_a1_op = rewriter.create<tosa::TransposeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(a2_transpose_shape),\n+                            result_type.getElementType()),\n+      a1_reshape_input_op.getResult(), a2_transpose_perm);\n+\n+  // Step 3. Reshape to:\n+  // [ batch / prod(block_shape) ],\n+  // [input_shape[1] * block_shape[0] ],\n+  //    ..\n+  // [input_shape[M * block_shape[M-1],\n+  // + remaining input shapes [input_shape[M+1.. N-1]]\n+  SmallVector<int64_t, 2> a4_shape(input_rank);\n+\n+  a4_shape[0] = input_shape[0] / block_num_elems;\n+  for (int i = 0; i < block_rank; i++) {\n+    a4_shape[1 + i] = input_shape[i + 1] * block_shape[i];\n+  }\n+  for (int i = 0; i < remaining_shape_rank; i++) {\n+    a4_shape[1 + block_rank + i] = input_shape[block_rank + 1 + i];\n+  }\n+\n+  auto a3_reshape_a2 = rewriter.create<tosa::ReshapeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(a4_shape),\n+                            result_type.getElementType()),\n+      a2_transpose_a1_op.getResult(), rewriter.getI64ArrayAttr(a4_shape));\n+\n+  // 4. Crop the start/end dimensions on 'spatial dimension' according to\n+  // crops\n+  // Use a slice operator to do the cropping.\n+  //\n+  // Calculate a beginning point and a size:\n+  // - Begin is the origin, offset by the lo crop amount in each dimension\n+  // - Size is the reshaped tensor size, minus the quantity (lo + hi) for each\n+  // dimension\n+  SmallVector<int64_t, 4> a4_begin_vals(input_rank), a4_size_vals(input_rank);\n+\n+  for (int i = 0; i < input_rank; i++) {\n+    // Batch dimension and remaining dimensions.\n+    if (i == 0 || i > crops_dims) {\n+      a4_begin_vals[i] = 0;\n+      a4_size_vals[i] = result_type.getShape()[i];\n+    }\n+    // Spatial dimension.\n+    else {\n+      assert(i - 1 >= 0 && i - 1 < crops_dims);\n+      a4_begin_vals[i] = crops[i - 1].first;\n+      a4_size_vals[i] = a4_shape[i] - crops[i - 1].first - crops[i - 1].second;\n+    }\n+  }\n+\n+  auto a4_slice_a3_op = rewriter.create<tosa::SliceOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(a4_size_vals),\n+                            result_type.getElementType()),\n+      a3_reshape_a2.getResult(), rewriter.getI64ArrayAttr(a4_begin_vals),\n+      rewriter.getI64ArrayAttr(a4_size_vals));\n+\n+  return a4_slice_a3_op;\n+}\n+\n+// Lowers ExpandDims to TOSA.\n+Operation* convertExpandDimsOp(PatternRewriter& rewriter, Operation* op,\n+                               Value result_value, Value input_value,\n+                               Value dim_value) {\n+  // Lowers to a reshape op with 1's inserted in the appropriate dimensions.\n+  auto output_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  // Not a ranked tensor output\n+  if (!output_type) {\n+    op->emitOpError(\"ExpandDims: output type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  auto input_type = input_value.getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"ExpandDims: input type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  auto input_shape = input_type.getShape();\n+\n+  ElementsAttr dim_elem;\n+  if (!matchPattern(dim_value, m_Constant(&dim_elem))) return nullptr;\n+\n+  assert(dim_elem.getNumElements() == 1);\n+  int32_t dim = dim_elem.getValue<IntegerAttr>(0).getInt();\n+\n+  SmallVector<int64_t, 4> reshape_dims;\n+  if (dim < 0 || dim >= input_shape.size()) {  // add dim at end of tensor\n+    dim = input_shape.size();\n+    for (int i = 0; i < input_shape.size(); i++) {\n+      reshape_dims.emplace_back(input_shape[i]);\n+    }\n+    reshape_dims.emplace_back(1);\n+  } else {\n+    for (int i = 0; i < input_shape.size(); i++) {\n+      if (i == dim) {\n+        reshape_dims.emplace_back(1);\n+      }\n+      reshape_dims.emplace_back(input_shape[i]);\n+    }\n+  }\n+\n+  ArrayAttr shape_attr = rewriter.getI64ArrayAttr(reshape_dims);\n+\n+  auto reshape_op = rewriter.create<tosa::ReshapeOp>(op->getLoc(), output_type,\n+                                                     input_value, shape_attr);\n+\n+  return reshape_op;\n+}\n+\n+// Lowers Squeeze to TOSA.\n+Operation* convertSqueezeOp(PatternRewriter& rewriter, Operation* op,\n+                            Value result_value, Value input_value,\n+                            SmallVector<int32_t, 8>& squeeze_dims) {\n+  // Lowers to a reshape op where dimensions in squeeze_dims with size=1\n+  // are removed.\n+  auto output_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  // Not a ranked tensor output\n+  if (!output_type) {\n+    op->emitOpError(\"Squeeze: output type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  auto input_type = input_value.getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"Squeeze: input type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  auto input_shape = input_type.getShape();\n+\n+  SmallVector<int64_t, 8> reshape_dims;\n+\n+  if (squeeze_dims.size() == 0) {  // remove all 1-dims\n+    for (int i = 0; i < input_shape.size(); i++) {\n+      if (input_shape[i] != 1) {\n+        reshape_dims.emplace_back(input_shape[i]);\n+      }\n+    }\n+  } else {\n+    // Remove only specified dims.\n+    // First sort the array so they can be picked off in sequence.\n+    std::sort(squeeze_dims.begin(), squeeze_dims.end(),\n+              [](const int32_t& a, const int32_t& b) { return a < b; });\n+\n+    int pos = 0;\n+    auto dim = squeeze_dims[pos];\n+    for (int i = 0; i < input_shape.size(); i++) {\n+      if (i == dim) {\n+        pos = pos + 1;\n+        if (pos < squeeze_dims.size())\n+          dim = squeeze_dims[pos];\n+        else\n+          dim = -1;  // Invalid\n+      } else {\n+        reshape_dims.emplace_back(input_shape[i]);\n+      }\n+    }\n+  }\n+\n+  ArrayAttr shape_attr = rewriter.getI64ArrayAttr(reshape_dims);\n+\n+  auto reshape_op = rewriter.create<tosa::ReshapeOp>(op->getLoc(), output_type,\n+                                                     input_value, shape_attr);\n+  return reshape_op;\n+}\n+\n+// Lowers ELU to a sequence of TOSA ops.\n+Operation* convertEluOp(PatternRewriter& rewriter, Operation* op,\n+                        Value result_value, Value features_value) {\n+  // Lowers Elu using the following formula:\n+  // elu(x) = x < 0 ? (exp(x) - 1) : x\n+  // one = const({1});\n+  // zero = const({0});\n+  // one_bcast = reshape(one, [1, ..., rank(x) - 1])\n+  // zero_bcast = reshape(zero, [1, ..., rank(x) - 1])\n+  // a1 = exp(x);\n+  // a2 = sub(a1, one_bcast)\n+  // a3 = ge(x, zero_bcast)\n+  // a4 = select(a3, x, a2)\n+  auto output_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  // Not a ranked tensor output\n+  if (!output_type) {\n+    op->emitOpError(\"Elu: output type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  int32_t input_rank = output_type.getShape().size();\n+  std::vector<int64_t> bcast_shape;\n+  for (int i = 0; i < input_rank; i++) {\n+    bcast_shape.push_back(1);\n+  }\n+\n+  // Can't directly create size=1, rank=rank(input) tensor because\n+  // it will be optimized out.  Instead, create rank0 tensor and reshape later.\n+  auto one_const_op = getTosaConstTensorSingleF32(rewriter, op, 1.0);\n+\n+  auto zero_const_op = getTosaConstTensorSingleF32(rewriter, op, 0.0);\n+\n+  auto one_reshape_op = rewriter.create<tosa::ReshapeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(bcast_shape),\n+                            output_type.getElementType()),\n+      one_const_op, rewriter.getI64ArrayAttr(bcast_shape));\n+\n+  auto zero_reshape_op = rewriter.create<tosa::ReshapeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(bcast_shape),\n+                            output_type.getElementType()),\n+      zero_const_op, rewriter.getI64ArrayAttr(bcast_shape));\n+\n+  auto a1_exp_in_op =\n+      rewriter.create<tosa::ExpOp>(op->getLoc(), output_type, features_value);\n+\n+  auto a2_sub_a1_one_op = rewriter.create<tosa::SubOp>(\n+      op->getLoc(), output_type, a1_exp_in_op.getResult(), one_const_op);\n+\n+  auto a3_ge_in_zero_op = rewriter.create<tosa::GreaterEqualOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(output_type.getShape(), rewriter.getIntegerType(1)),\n+      features_value, zero_const_op);\n+\n+  auto a4_select_a3_op = rewriter.create<tosa::SelectOp>(\n+      op->getLoc(), output_type, a3_ge_in_zero_op.getResult(), features_value,\n+      a2_sub_a1_one_op.getResult());\n+\n+  return a4_select_a3_op;\n+}\n+\n+// Lowers Softmax to a sequence of TOSA ops.\n+Operation* convertSoftmaxOp(PatternRewriter& rewriter, Operation* op,\n+                            Value result_value, Value logits_value) {\n+  // softmax = exp(logits) / reduce_sum(exp(logits), -1)\n+  //\n+  // or equivalently multiply exp(-max(logits)) to both numerator and\n+  // denominator we get:\n+  //\n+  // softmax = exp(logits - max(logits)) / reduce_sum(exp(logits -\n+  // max(logits)), -1)\n+  //\n+  // We'll use first version for direct fp lowering, and second version for\n+  // quantized lowering since second one we can restrict input to exp() be\n+  // negative, and thus LUT can always be within [0.0, 1.0].\n+  auto output_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  auto input_type = logits_value.getType().dyn_cast<RankedTensorType>();\n+\n+  // Not a ranked tensor input/output\n+  if (!output_type || !input_type) {\n+    op->emitOpError(\"Softmax: input and result not ranked tensors\");\n+    return nullptr;\n+  }\n+\n+  // reduce_sum on last dimension\n+  int32_t input_rank = input_type.getShape().size();\n+  ArrayAttr axis_attr = rewriter.getI64ArrayAttr({input_rank - 1});\n+  ArrayRef<int64_t> logits_shape = output_type.getShape();\n+\n+  if (input_type.getElementType().isa<mlir::quant::QuantizedType>() &&\n+      output_type.getElementType().isa<mlir::quant::QuantizedType>()) {\n+    std::vector<int64_t> rsum_shape_v(input_type.getShape().begin(),\n+                                      input_type.getShape().end() - 1);\n+    rsum_shape_v.push_back(1);\n+    ArrayRef<int64_t> rsum_shape(rsum_shape_v);\n+    mlir::quant::UniformQuantizedType in_quant_type =\n+        input_type.getElementType()\n+            .dyn_cast_or_null<mlir::quant::UniformQuantizedType>();",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "525557204",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 44851,
        "pr_file": "tensorflow/compiler/mlir/tosa/transforms/legalize_common.cc",
        "discussion_id": "525557204",
        "commented_code": "@@ -0,0 +1,2821 @@\n+/* Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+// This file contains legalizations common to mapping both TensorFlow and\n+// TensorFlow Lite to TOSA.\n+//\n+// Conversion functions return nullptr on a lowerization failure or a\n+// lowered operator on success.  Callers must check and return a\n+// LogicalResult failure on nullptr.  Helper macros are provided in\n+// legalize_common.h to canonicalize this handling.\n+\n+#include \"tensorflow/compiler/mlir/tosa/transforms/legalize_common.h\"\n+\n+#include <climits>\n+#include <cstddef>\n+#include <cstdint>\n+#include <iterator>\n+#include <numeric>\n+\n+#include \"tensorflow/compiler/mlir/tosa/transforms/legalize_utils.h\"\n+\n+namespace mlir {\n+namespace tosa {\n+\n+// Lowers the Pack operator to TOSA.\n+Operation* convertPackOp(PatternRewriter& rewriter, Operation* op,\n+                         Value result_value, SmallVector<Value, 8>& inputs,\n+                         int32_t axis) {\n+  //////////////////////////////////////////////////\n+  // Operator: output = Pack([values], axis) or output = Stack([values], axis)\n+  // Lowering:\n+  //\n+  // This operator is lowered into a series of pairwise tosa.concat()\n+  // operators and a reshape\n+  // Depending on the inputs, a tranpose operator is also generated:\n+  //\n+  // Step 1: concatenate the tensors\n+  // a1_concat = tosa.concat(input[0], input[1], axis)\n+  // for (i = 2; i < len(input); i++)\n+  //   a1_concat = tosa.concat(a1_concat, input[i], axis)\n+  //\n+  // Step 2: reshape to N+1 dimensions\n+  // a2_reshape = tosa.reshape(a1_concat, new_rank)\n+  //\n+  // Step 3: Transpose if a new dimension is being added:\n+  // if (axis == rank(values[0]):\n+  //   // perm will be [1, 2, 3, 0]\n+  //   a3_transpose = tosa.transpose(a2_reshape, perm)\n+\n+  // Sanity check 1: make sure all input tensors have the same shape\n+  // if input[0] has shape [A, B, C], input[1] to input[N-1] should also have\n+  // shape[A, B, C]\n+  auto result_type = result_value.getType().dyn_cast<RankedTensorType>();\n+\n+  // Check for ranked tensor type.\n+  if (!result_type) {\n+    op->emitOpError(\"PackOp: result type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  // Valid axis in TF is [-rank(input), rank(input))\n+  // Valid axis in TOSA is [0, rank(input))\n+  // Plus rank(input) once if axis is negative.\n+  auto input_type = op->getOperand(0).getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"PackOp: input type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  auto input_rank = input_type.getShape().size();\n+  if (axis < 0) axis += input_rank;\n+\n+  input_type = inputs[0].getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"Input 0 type not ranked tensor.\");\n+    return nullptr;\n+  }\n+  ArrayRef<int64_t> input0_tensor_shape = input_type.getShape();\n+  int input_tensor_rank = input0_tensor_shape.size();\n+\n+  for (int i = 1; i < inputs.size(); i++) {\n+    input_type = inputs[0].getType().dyn_cast<RankedTensorType>();\n+    if (!input_type) {\n+      op->emitOpError(llvm::formatv(\n+          \"reduce axis {} is not in valid range [-rank(input), rank(input))\",\n+          i));\n+      return nullptr;\n+    }\n+    ArrayRef<int64_t> next_tensor_shape = input_type.getShape();\n+    if (next_tensor_shape.size() != input_tensor_rank) {\n+      op->emitOpError(\"PackOp: input tensor rank mismatch.\");\n+      return nullptr;\n+    }\n+    for (int d = 0; d < input0_tensor_shape.size(); d++) {\n+      if (input0_tensor_shape[d] != next_tensor_shape[d]) {\n+        op->emitOpError(\"PackOp: input tensor shape mismatch.\");\n+        return nullptr;\n+      }\n+    }\n+  }\n+\n+  // If input tensors are rank 0, should reshape them to rank 1 size 1 before\n+  // performing concat.\n+  if (input_tensor_rank == 0) {\n+    SmallVector<int64_t, 8> reshape_rank1_size1_shape{1};\n+    auto reshape_rank1_size1_type =\n+        RankedTensorType::get(ArrayRef<int64_t>(reshape_rank1_size1_shape),\n+                              result_type.getElementType());\n+    ArrayAttr shape_rank1_size1_attr =\n+        rewriter.getI64ArrayAttr(reshape_rank1_size1_shape);\n+    for (int i = 0; i < inputs.size(); i++) {\n+      auto a0_reshape_op = rewriter.create<tosa::ReshapeOp>(\n+          op->getLoc(), reshape_rank1_size1_type, inputs[i],\n+          shape_rank1_size1_attr);\n+      inputs[i] = a0_reshape_op.getResult();\n+    }\n+  }\n+\n+  // Sanity check 2: axis can be from [0, rank(input)+1]\n+  // Where rank(input)+1 means create a new dimension\n+  // Negative values are also allowed up to -(rank(input)+1)\n+  // where the axis \"wraps around\".\n+  if (axis < 0) axis += input_rank;\n+\n+  if (axis > (input_tensor_rank + 1)) {\n+    op->emitOpError(\"PackOp: axis out of valid range.\");\n+    return nullptr;\n+  }\n+\n+  // Sanity check 2: if input shape is [A, B, C], output shape should be [N,\n+  // A, B, C]\n+  // 2.a check output is rank(input) + 1\n+  SmallVector<int64_t, 8> output_shape_vals(result_type.getShape().begin(),\n+                                            result_type.getShape().end());\n+  if (output_shape_vals.size() != (input_tensor_rank + 1)) {\n+    op->emitOpError(\"PackOp: output tensor rank mismatch.\");\n+    return nullptr;\n+  }\n+  // 2.b check output rank 0 is N\n+  if (output_shape_vals[axis] != inputs.size()) {\n+    op->emitOpError(\"PackOp: output tensor shape mismatch.\");\n+    return nullptr;\n+  }\n+  ArrayAttr output_shape_attr = rewriter.getI64ArrayAttr(output_shape_vals);\n+\n+  // Most of the cases when PackOp.axis() is within [0, rank(input) - 1].\n+  // We can directly concatenate along that axis and perform the reshape.\n+  // For example, stack N [A, B, C] input tensor ranks along axis = 1\n+  // after concatenation, output will be [A, N * B, C]\n+  // and then reshape it into [A, N, B, C]\n+  // a special case would be PackOp.axis() equal to rank(input), in which case\n+  // we can't directly concatenate along the PackOp.axis(), instead\n+  // we concat along axis=0, and reshape into [N, A, B, C]\n+  // and then we need an extra transpose to [A, B, C, N].\n+  int64_t concat_axis;\n+  SmallVector<int32_t, 8> perm;\n+  SmallVector<int64_t, 8> reshape_output_shape;\n+  if (axis == 0 && input_tensor_rank == 0) {\n+    concat_axis = 0;\n+    // Don't need reshape and perm, since we inputs are reshaped into rank 1\n+    // size 1.  Output will be rank 1 size N.\n+  } else if (axis == input_tensor_rank) {\n+    concat_axis = 0;\n+\n+    // A special case when stack axis is equal to input tensor rank:\n+    // Output shape is [A, B, C, N]\n+    // so reshape output will be [N, A, B, C]\n+    // and perm will be [1, 2, 3, 0].\n+    reshape_output_shape.push_back(output_shape_vals[axis]);\n+    for (int d = 0; d < input_tensor_rank; d++) {\n+      perm.push_back(d + 1);\n+      reshape_output_shape.push_back(output_shape_vals[d]);\n+    }\n+    perm.push_back(0);\n+  } else {\n+    // General case, doesn't need perm vector.\n+    concat_axis = axis;\n+    reshape_output_shape.assign(output_shape_vals.begin(),\n+                                output_shape_vals.end());\n+  }\n+  IntegerAttr concat_axis_attr = rewriter.getI64IntegerAttr(concat_axis);\n+  ArrayAttr shape_attr = rewriter.getI64ArrayAttr(reshape_output_shape);\n+\n+  // For each concat output, shape will be different.\n+  // If input shape is [A, B, C] and concat_axis = 0, 1st concat output will\n+  // be [2 * A, B, C].\n+  int orig_input_dim_on_axis;\n+  std::vector<int64_t> concat_output_shape;\n+  if (input_tensor_rank == 0) {\n+    concat_output_shape.push_back(1);\n+    orig_input_dim_on_axis = 1;\n+  } else {\n+    for (int i = 0; i < input_tensor_rank; i++) {\n+      concat_output_shape.push_back(input0_tensor_shape[i]);\n+    }\n+    orig_input_dim_on_axis = input0_tensor_shape[concat_axis];\n+  }\n+\n+  concat_output_shape[concat_axis] = orig_input_dim_on_axis * 2;\n+  auto concat_type = RankedTensorType::get(\n+      ArrayRef<int64_t>(concat_output_shape), result_type.getElementType());\n+  auto a1_concat_op = rewriter.create<tosa::ConcatOp>(\n+      op->getLoc(), concat_type, inputs[0], inputs[1], concat_axis_attr);\n+\n+  // K-th concat output will be [(k+1) * A, B, C], last output will be [N * A,\n+  // B, C].\n+  for (int i = 2; i < inputs.size(); i++) {\n+    concat_output_shape[concat_axis] = orig_input_dim_on_axis * (i + 1);\n+    concat_type = RankedTensorType::get(ArrayRef<int64_t>(concat_output_shape),\n+                                        result_type.getElementType());\n+    a1_concat_op = rewriter.create<tosa::ConcatOp>(op->getLoc(), concat_type,\n+                                                   a1_concat_op.getResult(),\n+                                                   inputs[i], concat_axis_attr);\n+  }\n+\n+  Operation* lowered_op = nullptr;\n+  // Doesn't need reshape or transpose if input tensor is rank 0, since inputs\n+  // are reshaped beforehand.\n+  if (input_tensor_rank == 0) {\n+    lowered_op = a1_concat_op;\n+  } else {\n+    // Reshape [N * A, B, C] to [N, A, B, C].\n+    auto reshape_output_type = RankedTensorType::get(\n+        ArrayRef<int64_t>(reshape_output_shape), result_type.getElementType());\n+\n+    auto a2_reshape_op =\n+        rewriter.create<tosa::ReshapeOp>(op->getLoc(), reshape_output_type,\n+                                         a1_concat_op.getResult(), shape_attr);\n+\n+    // If axis is equal to input tensor rank, then we need extra transpose\n+    // [N, A, B, C] to [A, B, C, N]\n+    if (axis == input_tensor_rank) {\n+      auto a3_transpose_perm =\n+          get1DConstTensor<tosa::ConstOp, int32_t>(rewriter, op, perm);\n+      auto a3_transpose_op = rewriter.create<tosa::TransposeOp>(\n+          op->getLoc(), result_type, a2_reshape_op.getResult(),\n+          a3_transpose_perm);\n+      lowered_op = a3_transpose_op;\n+    } else {\n+      lowered_op = a2_reshape_op;\n+    }\n+  }\n+\n+  return lowered_op;\n+}\n+\n+// Lowers the Unpack operator to TOSA\n+Operation* convertUnpackOp(PatternRewriter& rewriter, Operation* op,\n+                           Value input_value, int32_t axis) {\n+  auto input_type = input_value.getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) return nullptr;\n+\n+  auto input_shape = input_type.getShape();\n+  int64_t input_rank = input_shape.size();\n+\n+  SmallVector<Value, 4> results_vec;\n+\n+  // Negative axis allowed as long as it's within [-input_rank, input_rank).\n+  if (axis < 0) axis += input_rank;\n+\n+  assert(axis > 0 && axis < input_shape.size());\n+\n+  // A list of the output types for each slice op\n+  SmallVector<Type, 4> outs_type_vec;\n+\n+  // Step 1: transpose 'axis' to leftmost dimension.\n+  Value transposed_input_value;\n+  if (axis != 0) {\n+    SmallVector<int32_t, 8> perm_vec;\n+    SmallVector<int64_t, 2> a1_transpose_shape(input_rank);\n+\n+    perm_vec.push_back(axis);\n+    for (int i = 0; i < input_rank; i++) {\n+      if (i == axis) continue;\n+      perm_vec.push_back(i);\n+    }\n+\n+    auto a1_transpose_perm =\n+        get1DConstTensor<tosa::ConstOp, int32_t>(rewriter, op, perm_vec);\n+\n+    for (int i = 0; i < input_rank; i++) {\n+      a1_transpose_shape[i] = input_shape[perm_vec[i]];\n+    }\n+\n+    auto a1_transpose_op = rewriter.create<tosa::TransposeOp>(\n+        op->getLoc(),\n+        RankedTensorType::get(ArrayRef<int64_t>(a1_transpose_shape),\n+                              input_type.getElementType()),\n+        input_value, a1_transpose_perm);\n+\n+    transposed_input_value = a1_transpose_op.getResult();\n+  } else {\n+    // Do nothing if axis is already at leftmost dimension.\n+    transposed_input_value = input_value;\n+  }\n+\n+  // Step 2: slice [N, A, B, C] into N [A, B, C].\n+  auto transposed_input_type =\n+      transposed_input_value.getType().dyn_cast<RankedTensorType>();\n+  if (!transposed_input_type) return nullptr;\n+\n+  auto transposed_input_shape = transposed_input_type.getShape();\n+  int64_t transposed_input_rank = transposed_input_shape.size();\n+\n+  for (int i = 0; i < transposed_input_shape[0]; i++) {\n+    SmallVector<int64_t, 4> begin_vals, size_vals, shape_vals;\n+\n+    for (int j = 0; j < transposed_input_rank; j++) {\n+      if (j == 0) {\n+        begin_vals.push_back(i);\n+        size_vals.push_back(1);\n+      } else {\n+        begin_vals.push_back(0);\n+        size_vals.push_back(transposed_input_shape[j]);\n+        shape_vals.push_back(transposed_input_shape[j]);\n+      }\n+    }\n+\n+    ArrayAttr begin = rewriter.getI64ArrayAttr(begin_vals);\n+    ArrayAttr size = rewriter.getI64ArrayAttr(size_vals);\n+\n+    auto a2_slice_op = rewriter.create<tosa::SliceOp>(\n+        op->getLoc(),\n+        RankedTensorType::get(ArrayRef<int64_t>(size_vals),\n+                              transposed_input_type.getElementType()),\n+        transposed_input_value, begin, size);\n+\n+    auto a3_reshape_op = rewriter.create<tosa::ReshapeOp>(\n+        op->getLoc(),\n+        RankedTensorType::get(ArrayRef<int64_t>(shape_vals),\n+                              transposed_input_type.getElementType()),\n+        a2_slice_op.getResult(), rewriter.getI64ArrayAttr(shape_vals));\n+\n+    outs_type_vec.push_back(RankedTensorType::get(\n+        ArrayRef<int64_t>(shape_vals), transposed_input_type.getElementType()));\n+\n+    results_vec.push_back(a3_reshape_op.getResult());\n+  }\n+\n+  // Combine the sequence of tosa.slice() ops into a list\n+  // using the IdentityN operator.\n+  auto identityn_op = rewriter.create<tosa::IdentityNOp>(\n+      op->getLoc(), ArrayRef<Type>(outs_type_vec), results_vec);\n+\n+  return identityn_op;\n+}\n+\n+// Lowers the Select operator to TOSA.\n+Operation* convertSelectOp(PatternRewriter& rewriter, Operation* op,\n+                           Value result_value, Value condition_value,\n+                           Value x_value, Value y_value) {\n+  auto result_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  auto condition_type = condition_value.getType().dyn_cast<RankedTensorType>();\n+  auto x_type = x_value.getType().dyn_cast<RankedTensorType>();\n+  auto y_type = y_value.getType().dyn_cast<RankedTensorType>();\n+\n+  Operation* result_op = nullptr;\n+\n+  if (!result_type || !condition_type || !x_type || !y_type) {\n+    op->emitOpError(\"Select: failed ranked tensor type check\");\n+    return nullptr;\n+  }\n+\n+  // First check whether we need to reshape the condition to match\n+  // the same rank as the then/else clauses.\n+  if (result_type.getRank() == condition_type.getRank()) {\n+    // Nothing to reshape.\n+    result_op = rewriter.create<tosa::SelectOp>(\n+        op->getLoc(), result_type, condition_value, x_value, y_value);\n+  } else {\n+    // Need to reshape the condition.\n+    SmallVector<int64_t, 8> new_cond_dims;\n+    for (int i = 0; i < (result_type.getRank() - condition_type.getRank());\n+         i++) {\n+      new_cond_dims.push_back(1);\n+    }\n+    for (int i = 0; i < condition_type.getRank(); i++) {\n+      new_cond_dims.push_back(condition_type.getShape()[i]);\n+    }\n+\n+    auto reshape_op = rewriter.create<tosa::ReshapeOp>(\n+        op->getLoc(),\n+        RankedTensorType::get(ArrayRef<int64_t>(new_cond_dims),\n+                              condition_type.getElementType()),\n+        condition_value, rewriter.getI64ArrayAttr(new_cond_dims));\n+\n+    auto new_select = rewriter.create<tosa::SelectOp>(\n+        op->getLoc(), result_type, reshape_op, x_value, y_value);\n+    result_op = new_select;\n+  }\n+\n+  return result_op;\n+}\n+\n+// Lowers the ZerosLike operator to TOSA by creating a constant\n+// of the desired type and shape.\n+Operation* convertZerosLikeOp(PatternRewriter& rewriter, Operation* op,\n+                              Value result, Value input) {\n+  auto result_type = result.getType().dyn_cast<RankedTensorType>();\n+  if (!result_type) {\n+    op->emitOpError(\"Zeroslike: result not ranked tensor type\");\n+    return nullptr;\n+  }\n+\n+  auto input_type = input.getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"Zeroslike: input not ranked tensor type\");\n+    return nullptr;\n+  }\n+\n+  auto input_shape = input_type.getShape();\n+\n+  ShapedType zero_type =\n+      RankedTensorType::get(input_shape, input_type.getElementType());\n+  Attribute zero_attr = rewriter.getZeroAttr(zero_type);\n+\n+  auto const_op =\n+      rewriter.create<tosa::ConstOp>(op->getLoc(), zero_type, zero_attr);\n+\n+  return const_op;\n+}\n+\n+// Lowers the Mul operator to TOSA.  For quantized types, this requires\n+// inserting rescale operators before and after the operation.\n+Operation* convertMultiplyOp(PatternRewriter& rewriter, Operation* op,\n+                             Value output_val, Value input_lhs_val,\n+                             Value input_rhs_val) {\n+  auto input_lhs_type = input_lhs_val.getType().dyn_cast<RankedTensorType>();\n+  auto input_rhs_type = input_rhs_val.getType().dyn_cast<RankedTensorType>();\n+  auto output_type = output_val.getType().dyn_cast<RankedTensorType>();\n+  // Not a ranked tensor output\n+  if (!input_lhs_type || !input_rhs_type || !output_type) return nullptr;\n+\n+  bool input_lhs_is_qtype =\n+      input_lhs_type.getElementType().isa<mlir::quant::UniformQuantizedType>();\n+  bool input_rhs_is_qtype =\n+      input_rhs_type.getElementType().isa<mlir::quant::UniformQuantizedType>();\n+  bool output_is_qtype =\n+      output_type.getElementType().isa<mlir::quant::UniformQuantizedType>();\n+\n+  if (input_lhs_is_qtype != output_is_qtype ||\n+      input_rhs_is_qtype != output_is_qtype) {\n+    op->emitOpError(\n+        \"ConvertMultiplyOp: input/output tensor should \"\n+        \"be all quantized or all native\");\n+    return nullptr;\n+  }\n+\n+  Value output;\n+  if (output_is_qtype) {\n+    auto rescale_type =\n+        RankedTensorType::get(output_type.getShape(), rewriter.getI32Type());\n+    auto input_lhs_qtype = input_lhs_type.getElementType()\n+                               .dyn_cast<mlir::quant::UniformQuantizedType>();\n+    auto input_rhs_qtype = input_rhs_type.getElementType()\n+                               .dyn_cast<mlir::quant::UniformQuantizedType>();\n+    auto output_qtype = output_type.getElementType()\n+                            .dyn_cast<mlir::quant::UniformQuantizedType>();\n+\n+    double in_lhs_scale = input_lhs_qtype.getScale();\n+    double in_rhs_scale = input_rhs_qtype.getScale();\n+    double output_scale = output_qtype.getScale();\n+\n+    double output_rescale_scale = in_lhs_scale * in_rhs_scale / output_scale;\n+\n+    auto op1_rescale_lhs = buildRescaleToInt32(\n+        rewriter, op, input_lhs_val, 1.0f, input_lhs_qtype.getZeroPoint());\n+    auto op2_rescale_rhs = buildRescaleToInt32(\n+        rewriter, op, input_rhs_val, 1.0f, input_rhs_qtype.getZeroPoint());\n+    auto op3_mul_op1_op2 = rewriter.create<tosa::MulOp>(\n+        op->getLoc(), rescale_type, op1_rescale_lhs, op2_rescale_rhs, 0);\n+    auto op4_rescale_op3 = buildRescaleFromInt32(\n+        rewriter, op, output_type, op3_mul_op1_op2.getResult(),\n+        output_rescale_scale, output_qtype.getZeroPoint());\n+    output = op4_rescale_op3;\n+  } else {\n+    auto op1_mul_in = rewriter.create<tosa::MulOp>(\n+        op->getLoc(), output_type, input_lhs_val, input_rhs_val, 0);\n+\n+    output = op1_mul_in.getResult();\n+  }\n+\n+  return output.getDefiningOp();\n+}\n+\n+// Lowers the SquaredDifference operator to TOSA.\n+Operation* convertSquaredDifferenceOp(PatternRewriter& rewriter, Operation* op,\n+                                      Value result, Value x, Value y) {\n+  // Squared-difference is (x-y)*(x-y).\n+  // This lowering calculates the difference and multiplies.\n+  auto result_type = result.getType().dyn_cast<RankedTensorType>();\n+  if (!result_type) {\n+    op->emitOpError(\"SquaredDifference: result not ranked tensor type\");\n+    return nullptr;\n+  }\n+\n+  auto x_type = x.getType().dyn_cast<RankedTensorType>();\n+  auto y_type = y.getType().dyn_cast<RankedTensorType>();\n+  if (!x_type || !y_type) {\n+    op->emitOpError(\"SquaredDifference: inputs not ranked tensor type\");\n+    return nullptr;\n+  }\n+\n+  auto sub_op = rewriter.create<tosa::SubOp>(op->getLoc(), result_type, x, y);\n+  auto square_op = rewriter.create<tosa::MulOp>(\n+      op->getLoc(), result_type, sub_op.getResult(), sub_op.getResult(), 0);\n+  return square_op;\n+}\n+\n+// Lowers the Round operator to TOSA.\n+Operation* convertRoundOp(PatternRewriter& rewriter, Operation* op,\n+                          Value result, Value input) {\n+  // Implements banker's rounding by calculating floor(input + 0.5).\n+  auto result_type = result.getType().dyn_cast<RankedTensorType>();\n+  if (!result_type) {\n+    op->emitOpError(\"Round: result not ranked tensor type\");\n+    return nullptr;\n+  }\n+\n+  auto input_type = input.getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"Round: input not ranked tensor type\");\n+    return nullptr;\n+  }\n+\n+  auto add_op = rewriter.create<tosa::AddOp>(\n+      op->getLoc(), result_type, input,\n+      getTosaConstTensorSingleF32(rewriter, op, 0.5));\n+  auto floor_op = rewriter.create<tosa::FloorOp>(op->getLoc(), result_type,\n+                                                 add_op.getResult());\n+\n+  return floor_op;\n+}\n+\n+// Lowers ConcatV2 to TOSA.\n+Operation* convertConcatV2Op(PatternRewriter& rewriter, Operation* op,\n+                             Value result_value, SmallVector<Value, 8>& values,\n+                             int32_t axis) {\n+  // ConcatV2 becomes a series of TOSA Concat operators that take pairs of\n+  // tensors as arguments.   Rank-0 tensors are reshaped to Rank-1,\n+  // shape (1,) tensors.\n+  auto result_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  if (!result_type) {\n+    op->emitOpError(\"ConcatV2Op: result type not ranked tensor.\");\n+    return nullptr;\n+  }\n+\n+  // Valid axis in TF is [-rank(input), rank(input)).\n+  // Valid axis in TOSA is [0, rank(input)).\n+  // Plus rank(input) once if axis is negative.\n+  auto input_type = op->getOperand(0).getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"ConcatV2Op: input type not ranked tensor.\");\n+    return nullptr;\n+  }\n+\n+  auto input_rank = input_type.getShape().size();\n+\n+  if (axis < 0) axis += input_rank;\n+\n+  assert(values.size() >= 2);\n+\n+  if (!values[0].getType().dyn_cast<RankedTensorType>() ||\n+      !values[1].getType().dyn_cast<RankedTensorType>()) {\n+    op->emitOpError(\"ConcatV2Op: value type not ranked tensor.\");\n+    return nullptr;\n+  }\n+\n+  Value lhs_val = values[0];\n+  Value rhs_val = values[1];\n+  auto lhs_type = lhs_val.getType().dyn_cast<RankedTensorType>();\n+  auto rhs_type = rhs_val.getType().dyn_cast<RankedTensorType>();\n+  ArrayRef<int64_t> lhs_tensor_shape = lhs_type.getShape();\n+  ArrayRef<int64_t> rhs_tensor_shape = rhs_type.getShape();\n+  int input_tensor_rank = lhs_tensor_shape.size();\n+\n+  // For each concat output, shape will be different.\n+  // If input tensors are rank 0, should reshape them to rank 1 size 1 before\n+  // performing concat. If not, most dimensions should have same size as input\n+  // except the concat'd axis.\n+  //\n+  // If input is [A0, B, C] and [A1, B, C] and axis = 0\n+  // this concat output will be [A0 + A1, B, C].\n+  std::vector<int64_t> concat_result_shape;\n+  if (input_tensor_rank == 0) {\n+    if (axis != 0) {\n+      op->emitOpError(\"ConcatV2Op: axis invalid.\");\n+      return nullptr;\n+    }\n+    SmallVector<int64_t, 8> reshape_rank1_size1_shape{1};\n+    auto reshape_rank1_size1_type =\n+        RankedTensorType::get(ArrayRef<int64_t>(reshape_rank1_size1_shape),\n+                              result_type.getElementType());\n+    ArrayAttr shape_rank1_size1_attr =\n+        rewriter.getI64ArrayAttr(reshape_rank1_size1_shape);\n+    for (int i = 0; i < values.size(); i++) {\n+      auto a0_reshape_op = rewriter.create<tosa::ReshapeOp>(\n+          op->getLoc(), reshape_rank1_size1_type, values[i],\n+          shape_rank1_size1_attr);\n+      values[i] = a0_reshape_op.getResult();\n+    }\n+    concat_result_shape.push_back(2);\n+  } else {\n+    if (axis < 0 || axis >= input_tensor_rank) {\n+      op->emitOpError(\"ConcatV2Op: axis invalid.\");\n+      return nullptr;\n+    }\n+    for (int i = 0; i < input_tensor_rank; i++) {\n+      concat_result_shape.push_back(lhs_tensor_shape[i]);\n+    }\n+    concat_result_shape[axis] = lhs_tensor_shape[axis] + rhs_tensor_shape[axis];\n+  }\n+\n+  auto concat_type = RankedTensorType::get(\n+      ArrayRef<int64_t>(concat_result_shape), result_type.getElementType());\n+\n+  mlir::quant::UniformQuantizedType lhs_quant_type =\n+      lhs_type.getElementType()\n+          .dyn_cast_or_null<mlir::quant::UniformQuantizedType>();\n+  mlir::quant::UniformQuantizedType rhs_quant_type =\n+      rhs_type.getElementType()\n+          .dyn_cast_or_null<mlir::quant::UniformQuantizedType>();\n+  mlir::quant::UniformQuantizedType result_quant_type =\n+      result_type.getElementType()\n+          .dyn_cast_or_null<mlir::quant::UniformQuantizedType>();\n+\n+  double lhs_scale, rhs_scale, result_scale;\n+  int32_t lhs_zeropoint, rhs_zeropoint, result_zeropoint;\n+  RankedTensorType const_type, i32_type;\n+  DenseElementsAttr const_attr;\n+\n+  // tfl.concat currently allows different scales for each input tensor, which\n+  // TFlite team will fix in:\n+  // https://github.com/tensorflow/tensorflow/issues/39658\n+  //\n+  // For backward compatibility, we still need to support this artifact by\n+  // scaling inputs to let them have the same scales.\n+  if (result_quant_type && lhs_quant_type && rhs_quant_type) {\n+    lhs_scale = (double)lhs_quant_type.getScale();\n+    lhs_zeropoint = lhs_quant_type.getZeroPoint();\n+    rhs_scale = (double)rhs_quant_type.getScale();\n+    rhs_zeropoint = rhs_quant_type.getZeroPoint();\n+    result_scale = (double)result_quant_type.getScale();\n+    result_zeropoint = result_quant_type.getZeroPoint();\n+\n+    const_type = RankedTensorType::get({}, result_quant_type);\n+    i32_type = RankedTensorType::get({}, rewriter.getIntegerType(32));\n+    const_attr = DenseElementsAttr::get(i32_type, result_zeropoint);\n+    auto const_op =\n+        rewriter.create<tosa::ConstOp>(op->getLoc(), const_type, const_attr);\n+\n+    // Rescale input if scale is not equal to output tensor scale.\n+    if (lhs_scale != result_scale) {\n+      auto rescale_type =\n+          RankedTensorType::get(lhs_type.getShape(), result_quant_type);\n+\n+      auto rescale_op = buildRescale(rewriter, op, rescale_type, lhs_val,\n+                                     lhs_scale / result_scale, lhs_zeropoint,\n+                                     result_zeropoint);\n+\n+      lhs_val = rescale_op;\n+    }\n+    if (rhs_scale != result_scale) {\n+      auto rescale_type =\n+          RankedTensorType::get(rhs_type.getShape(), result_quant_type);\n+\n+      auto rescale_op = buildRescale(rewriter, op, rescale_type, rhs_val,\n+                                     rhs_scale / result_scale, rhs_zeropoint,\n+                                     result_zeropoint);\n+\n+      rhs_val = rescale_op;\n+    }\n+  }\n+\n+  auto concat_op = rewriter.create<tosa::ConcatOp>(\n+      op->getLoc(), concat_type, lhs_val, rhs_val,\n+      rewriter.getI64IntegerAttr(axis));\n+  for (int i = 2; i < values.size(); i++) {\n+    rhs_val = values[i];\n+    rhs_type = rhs_val.getType().dyn_cast<RankedTensorType>();\n+    rhs_tensor_shape = rhs_type.getShape();\n+    rhs_quant_type = rhs_type.getElementType()\n+                         .dyn_cast_or_null<mlir::quant::UniformQuantizedType>();\n+\n+    if (input_tensor_rank == 0) {\n+      concat_result_shape[axis] = concat_result_shape[axis] + 1;\n+    } else {\n+      concat_result_shape[axis] =\n+          concat_result_shape[axis] + rhs_tensor_shape[axis];\n+    }\n+    concat_type = RankedTensorType::get(ArrayRef<int64_t>(concat_result_shape),\n+                                        result_type.getElementType());\n+\n+    if (rhs_quant_type && result_quant_type) {\n+      rhs_scale = (float)rhs_quant_type.getScale();\n+      rhs_zeropoint = rhs_quant_type.getZeroPoint();\n+\n+      if (rhs_scale != result_scale) {\n+        auto rescale_type =\n+            RankedTensorType::get(rhs_type.getShape(), result_quant_type);\n+\n+        auto rescale_op = buildRescale(rewriter, op, rescale_type, rhs_val,\n+                                       rhs_scale / result_scale, rhs_zeropoint,\n+                                       result_zeropoint);\n+\n+        rhs_val = rescale_op;\n+      }\n+    }\n+\n+    concat_op = rewriter.create<tosa::ConcatOp>(\n+        op->getLoc(), concat_type, concat_op.getResult(), rhs_val,\n+        rewriter.getI64IntegerAttr(axis));\n+  }\n+\n+  return concat_op;\n+}\n+\n+// Lowers SpaceToBatchND to TOSA.\n+Operation* convertSpaceToBatchNDOp(PatternRewriter& rewriter, Operation* op,\n+                                   Value result_value, Value input_value,\n+                                   Value block_shape_value,\n+                                   Value paddings_value) {\n+  /////////////////////////////////////////////////\n+  // Operator: output = SpaceToBatchND(input, block_shape, paddings)\n+  // Lowering:\n+  //\n+  // SpaceToBatch input tensors are broken into three pieces:\n+  //   (a) batch dimension (N in NHWC)\n+  //   (b) input being transformed to batch dimension (typically H, W in NHWC)\n+  //   (c) remainder of input (typically C in NHWC)\n+  //\n+  // Step 0. Generate padding constant for the first reshape.\n+  //   No padding on the batch dimension\n+  //   The input paddings array is addressed as [input_rank][2]\n+  //   No padding on the remaining dimensions\n+  //\n+  //  a0_pad_const = tosa.const(input=Tensor<input_rank, 2>)\n+  //\n+  // Step 1. Pad the input tensor\n+  //\n+  //  a1_pad_input_op = tosa.pad(input=input, shape=a0_pad_const_op)\n+  //\n+  // Step 2. Reshape the padded structure of shape padded_shape to\n+  // [batch + padded_shape[1] / block_shape[0], block_shape[0], ...\n+  //    padded_shape[M] / block_shape[M-1], block_shape[M-1]] +\n+  //    remaining_shape\n+  //\n+  // block_rank = M (number of elements in block_shape)\n+  // New rank: input_rank + block_rank\n+  //\n+  //  a2_reshape_a1_op = tosa.reshape(input=a1_pad_input_op, shape=a2_shape)\n+  //\n+  // Step 3. Transpose dimensions to:\n+  //  block-shape +\n+  //  [batch] +\n+  //  [padded_shape[1] / block_shape[0],\n+  // ...\n+  //  [padded_shape[M] / block_shape[M-1]] +\n+  //  remaining_shape\n+  //\n+  // a3_transpose_a2_op = tosa.tranpose(input=a2_reshape_a1_op,\n+  // perms=a3_perm)\n+  //\n+  // Step 4. Reshape the transposed tensor to flatten block_shape stuff\n+  // into the batch dimension with the following shape:\n+  // [ batch * prod(block_shape)] +\n+  // [ padded_shape[1] / block_shape[0],\n+  //   ...,\n+  // padded_shape[M] / block_shape[M-1]] +\n+  // remaining_shape\n+  //\n+  //  a4_reshape_a3_op = tosa.reshape(input=a3_tranpose_a2_op,\n+  //  shape=a3_shape)\n+  //\n+\n+  auto result_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  auto input_type = input_value.getType().dyn_cast<RankedTensorType>();\n+  auto block_shape_type =\n+      block_shape_value.getType().dyn_cast<RankedTensorType>();\n+  auto paddings_type = paddings_value.getType().dyn_cast<RankedTensorType>();\n+\n+  // Not a ranked tensor output.\n+  if (!result_type) {\n+    op->emitOpError(\"SpaceToBatchND: result type not ranked tensor\");\n+    return nullptr;\n+  }\n+  if (!input_type) {\n+    op->emitOpError(\"SpaceToBatchND: input type not ranked tensor\");\n+    return nullptr;\n+  }\n+  if (!block_shape_type) {\n+    op->emitOpError(\"SpaceToBatchND: block shape type not ranked tensor\");\n+    return nullptr;\n+  }\n+  if (!paddings_type) {\n+    op->emitOpError(\"SpaceToBatchND: paddings type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  // Follow implementation in\n+  // tensorflow/compiler/tf2xla/kernels/spacetobatch_op.cc\n+\n+  // So, to figure out the spatial_shape, remove the batch dimension and\n+  // then use the next block_rank dimensions.  The remaining dimensions are\n+  // remaining_shape.\n+\n+  auto block_shape = block_shape_type.getShape();\n+  auto input_shape = input_type.getShape();\n+\n+  int block_rank = block_shape[0];\n+  int batch_size = input_shape[0];\n+  int input_rank = input_type.getRank();\n+  int remaining_shape_rank = input_rank - block_rank - 1;\n+  int block_num_elems = 1;\n+  int padding_sum = 0;\n+\n+  ElementsAttr block_shape_elems;\n+  ElementsAttr paddings_elems;\n+\n+  if (!matchPattern(block_shape_value, m_Constant(&block_shape_elems)))\n+    return nullptr;\n+\n+  if (!matchPattern(paddings_value, m_Constant(&paddings_elems)))\n+    return nullptr;\n+\n+  SmallVector<int32_t, 2> a0_pad_const(2 * (input_rank));\n+  SmallVector<int64_t, 2> padded_shape(input_rank);\n+\n+  // 1. Pad based on paddings operand.  No padding on the batch dimension.\n+  // The a0_pad_const array is addressed as [input_rank][2], but\n+  // it is flattened to a 1D array because LLVM appears to only accept 1D.\n+  //\n+  // padded_shape[] is the shape of the padded output of step a1.\n+  // The name is retained for consistency with the TF reference code.\n+  padded_shape[0] = input_shape[0];\n+\n+  // Batch dimension padding\n+  a0_pad_const[0] = 0;\n+  a0_pad_const[1] = 0;\n+\n+  // This iterator seems to be the only reliable way to get\n+  // int values out of a multi-dimensional ElementsAttr.\n+  int idx = 0;\n+\n+  for (auto i : paddings_elems.getValues<IntegerAttr>()) {\n+    a0_pad_const[idx + 2] = i.getInt();\n+    padding_sum += i.getInt();\n+    idx++;\n+  }\n+\n+  // Insert padding on the spatial shape dimensions\n+  for (int i = 0; i < block_rank; i++) {\n+    int32_t lo_pad = a0_pad_const[2 * (i + 1) + 0];\n+    int32_t hi_pad = a0_pad_const[2 * (i + 1) + 1];\n+\n+    padded_shape[i + 1] = input_shape[i + 1] + lo_pad + hi_pad;\n+  }\n+\n+  // No padding on the remaining_shape dimensions\n+  for (int i = 0; i < remaining_shape_rank; i++) {\n+    a0_pad_const[2 * (i + block_rank + 1) + 0] = 0;\n+    a0_pad_const[2 * (i + block_rank + 1) + 1] = 0;\n+    padded_shape[i + block_rank + 1] = input_shape[i + block_rank + 1];\n+  }\n+\n+  auto a0_pad_const_attr_type =\n+      RankedTensorType::get({(input_rank), 2}, rewriter.getIntegerType(32));\n+\n+  // Create a const op to generate the tensor type for the input padding array\n+  auto a0_pad_const_op = rewriter.create<tosa::ConstOp>(\n+      op->getLoc(), a0_pad_const_attr_type,\n+      DenseElementsAttr::get(a0_pad_const_attr_type,\n+                             llvm::makeArrayRef<int32_t>(a0_pad_const)));\n+\n+  auto a1_pad_input_op = rewriter.create<tosa::PadOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(padded_shape),\n+                            result_type.getElementType()),\n+      input_value, a0_pad_const_op.getResult());\n+\n+  // 2. Reshape the padded structure of shape padded_shape to\n+  // [batch + padded_shape[1] / block_shape[0], block_shape[0], ...\n+  //    padded_shape[M] / block_shape[M-1], block_shape[M-1]] +\n+  //    remaining_shape\n+\n+  // block_rank = M (number of elements in block_shape)\n+  // New rank: input_rank + block_rank\n+  SmallVector<int64_t, 2> a2_shape(1 + block_rank * 2 + remaining_shape_rank);\n+\n+  // First dimension is batch.\n+  a2_shape[0] = input_type.getShape()[0];\n+  for (int i = 0; i < block_rank; i++) {\n+    int32_t block_shape_val =\n+        rewriter\n+            .getI32IntegerAttr(\n+                block_shape_elems.getValue<IntegerAttr>(i).getInt())\n+            .getInt();\n+    a2_shape[1 + i * 2 + 0] = padded_shape[1 + i] / block_shape_val;\n+    a2_shape[1 + i * 2 + 1] = block_shape_val;\n+    block_num_elems *= block_shape_val;\n+  }\n+\n+  // Copy in the remaining block shape.\n+  for (int i = 0; i < remaining_shape_rank; i++) {\n+    a2_shape[1 + block_rank * 2 + i] = input_shape[1 + block_rank + i];\n+  }\n+\n+  auto a2_reshape_a1_op = rewriter.create<tosa::ReshapeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(a2_shape),\n+                            result_type.getElementType()),\n+      a1_pad_input_op.getResult(), rewriter.getI64ArrayAttr(a2_shape));\n+\n+  // 3. Transpose dimensions to:\n+  //  block-shape +\n+  //  [batch] +\n+  //  [padded_shape[1] / block_shape[0],\n+  // ...\n+  //  [padded_shape[M] / block_shape[M-1]] +\n+  //  remaining_shape\n+  int32_t a2_reshape_a1_rank = a2_reshape_a1_op.getResult()\n+                                   .getType()\n+                                   .dyn_cast<RankedTensorType>()\n+                                   .getRank();\n+  SmallVector<int32_t, 8> a3_perm(a2_reshape_a1_rank);\n+  SmallVector<int64_t, 2> a3_transpose_shape(a2_reshape_a1_rank);\n+\n+  for (int i = 0; i < block_rank; i++) {\n+    a3_perm[i] = 1 + 2 * i + 1;\n+    a3_perm[block_rank + 1 + i] = 1 + 2 * i;\n+  }\n+  a3_perm[block_rank] = 0;\n+  for (int i = 1 + block_rank * 2; i < a2_reshape_a1_rank; i++) {\n+    a3_perm[i] = i;\n+  }\n+\n+  for (int i = 0; i < a3_transpose_shape.size(); i++) {\n+    a3_transpose_shape[i] = a2_shape[a3_perm[i]];\n+  }\n+\n+  auto a3_transpose_const =\n+      get1DConstTensor<tosa::ConstOp, int32_t>(rewriter, op, a3_perm);\n+\n+  auto a3_transpose_a2_op = rewriter.create<tosa::TransposeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(a3_transpose_shape),\n+                            result_type.getElementType()),\n+      a2_reshape_a1_op.getResult(), a3_transpose_const);\n+\n+  // 4. Reshape the transposed tensor to flatten block_shape\n+  // into the batch dimension with the following shape:\n+  // [ batch * prod(block_shape)] +\n+  // [ padded_shape[1] / block_shape[0],\n+  //   ...,\n+  // padded_shape[M] / block_shape[M-1]] +\n+  // remaining_shape\n+  SmallVector<int64_t, 2> a4_reshape_shape(input_rank);\n+\n+  // Batch\n+  a4_reshape_shape[0] = batch_size * block_num_elems;\n+\n+  // padded shape / block_shape.\n+  for (int i = 0; i < block_rank; i++) {\n+    int32_t block_shape_val =\n+        rewriter\n+            .getI32IntegerAttr(\n+                block_shape_elems.getValue<IntegerAttr>(i).getInt())\n+            .getInt();\n+    a4_reshape_shape[i + 1] = padded_shape[i + 1] / block_shape_val;\n+  }\n+\n+  // Copy in remainder shape.\n+  for (int i = 0; i < remaining_shape_rank; i++) {\n+    a4_reshape_shape[1 + block_rank + i] = input_shape[1 + block_rank + i];\n+  }\n+\n+  auto a4_reshape_a3_op = rewriter.create<tosa::ReshapeOp>(\n+      op->getLoc(), result_type, a3_transpose_a2_op.getResult(),\n+      rewriter.getI64ArrayAttr(a4_reshape_shape));\n+\n+  return a4_reshape_a3_op;\n+}\n+\n+// Lowers BatchToSpaceND to TOSA.\n+Operation* convertBatchToSpaceNDOp(PatternRewriter& rewriter, Operation* op,\n+                                   Value result_value, Value input_value,\n+                                   Value block_shape_value, Value crops_value) {\n+  /////////////////////////////////////////////////\n+  // Operator: output = BatchToSpaceND(input, block_shape, clips)\n+  // Lowering:\n+  //\n+  // BatchToSpace input tensors are broken into three pieces:\n+  //   (a) batch dimension (N in NHWC)\n+  //   (b) input being transformed from batch dimension (typically H, W in\n+  //   NHWC)\n+  //   (c) remainder of input (typically C in NHWC)\n+  //\n+  // Step 1. Reshape input to:\n+  // [block_shape[0],\n+  // ...\n+  // [block_shape[M-1],\n+  // [batch / prod(block_shape)]\n+  // [input_shape[1],\n+  // ...\n+  // [input_shape[N-1]\n+  //\n+  // a1_reshape_input_op = tosa.reshape(input=input, shape=a1_shape)\n+  //\n+  // Step 2. Permute to shape\n+  // [ batch / prod(block_shape) ],\n+  // [ input_shape[1] ], [ block_shape[1] ]\n+  //  ...\n+  // [ input_shape[M] ], [ block_shape[M-1]\n+  // + remaining_input_shapes input_shape[M .. N-1]\n+  //\n+  // a2_transpose_a1 = tosa.transpose(input=a1_reshape_input_op,\n+  // shape=a2_shape)\n+  //\n+  // Step 3. Reshape to:\n+  // [ batch / prod(block_shape) ],\n+  // [input_shape[1] * block_shape[0] ],\n+  //    ..\n+  // [input_shape[M * block_shape[M-1],\n+  // + remaining input shapes [input_shape[M+1.. N-1]]\n+  //\n+  // a3_reshape_a2 = tosa.reshape(input=a2_transpose_a1, shape=a3_shape)\n+  //\n+  // Step 4. Crop the start/end dimensions according to crops of the\n+  // a3_reshape_a2 shape\n+  //\n+  // a4_slice_a3 = tosa.slice(input=a3_reshape_a2, start=a4_start,\n+  // size=a4_size)\n+\n+  auto result_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  auto input_type = input_value.getType().dyn_cast<RankedTensorType>();\n+  auto block_shape_type =\n+      block_shape_value.getType().dyn_cast<RankedTensorType>();\n+  auto crops_type = crops_value.getType().dyn_cast<RankedTensorType>();\n+\n+  if (!result_type) {\n+    op->emitOpError(\"BatchToSpaceND: result type not ranked tensor\");\n+    return nullptr;\n+  }\n+  if (!input_type) {\n+    op->emitOpError(\"BatchToSpaceND: input type not ranked tensor\");\n+    return nullptr;\n+  }\n+  if (!block_shape_type) {\n+    op->emitOpError(\"BatchToSpaceND: block shape type not ranked tensor\");\n+    return nullptr;\n+  }\n+  if (!crops_type) {\n+    op->emitOpError(\"BatchToSpaceND: crops type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  // Another 4-step process\n+  int block_rank = block_shape_type.getShape()[0];\n+  int input_rank = input_type.getRank();\n+  int crops_dims = crops_type.getShape()[0];\n+  int remaining_shape_rank = input_rank - block_rank - 1;\n+  auto input_shape = input_type.getShape();\n+\n+  ElementsAttr block_shape_elems;\n+  ElementsAttr crops_elems;\n+\n+  if (!matchPattern(block_shape_value, m_Constant(&block_shape_elems))) {\n+    op->emitOpError(\"BatchToSpaceND: block_shape not a constant\");\n+    return nullptr;\n+  }\n+\n+  if (!matchPattern(crops_value, m_Constant(&crops_elems))) {\n+    op->emitOpError(\"BatchToSpaceND: crops not a constant\");\n+    return nullptr;\n+  }\n+\n+  std::vector<int64_t> block_shape(block_rank);\n+  std::vector<std::pair<int64_t, int64_t>> crops(crops_dims);\n+\n+  // Extract values for block_shape and crops now.\n+  int block_num_elems = 1;\n+  for (int i = 0; i < block_rank; i++) {\n+    int block_shape_val =\n+        rewriter\n+            .getI32IntegerAttr(\n+                block_shape_elems.getValue<IntegerAttr>(i).getInt())\n+            .getInt();\n+    block_num_elems *= block_shape_val;\n+    block_shape[i] = block_shape_val;\n+  }\n+\n+  // This iterator seems to be the only reliable way to get\n+  // int values out of a multi-dimensional ElementsAttr\n+  SmallVector<int32_t, 2> crops_const(2 * (crops_dims));\n+  int idx = 0;\n+  for (auto i : crops_elems.getValues<IntegerAttr>()) {\n+    crops_const[idx++] = i.getInt();\n+  }\n+\n+  for (int i = 0; i < crops_dims; i++) {\n+    int crops_lo = crops_const[i * crops_dims + 0];\n+    int crops_hi = crops_const[i * crops_dims + 1];\n+    crops[i] = std::make_pair(crops_lo, crops_hi);\n+  }\n+\n+  // Step 1. Reshape input to:\n+  // [block_shape[0],\n+  // ...\n+  // [block_shape[M-1],\n+  // [batch / prod(block_shape)]\n+  // [input_shape[1],\n+  // ...\n+  // [input_shape[N-1]\n+  SmallVector<int64_t, 2> a1_shape(block_rank + input_rank);\n+\n+  for (int i = 0; i < block_rank; i++) a1_shape[i] = block_shape[i];\n+\n+  a1_shape[block_rank] = input_shape[0] / block_num_elems;\n+\n+  for (int i = 0; i < input_rank - 1; i++)\n+    a1_shape[i + block_rank + 1] = input_shape[i + 1];\n+\n+  auto a1_reshape_input_op = rewriter.create<tosa::ReshapeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(a1_shape),\n+                            result_type.getElementType()),\n+      input_value, rewriter.getI64ArrayAttr(a1_shape));\n+\n+  // 2. Permute to shape\n+  // [ batch / prod(block_shape) ],\n+  // [ input_shape[1] ], [ block_shape[0] ]\n+  //  ...\n+  // [ input_shape[M] ], [ block_shape[M-1]\n+  // + remaining_input_shapes input_shape[M+1 .. N-1]\n+\n+  // 2a. calculate the permutation\n+  SmallVector<int32_t, 8> a2_perm(block_rank + input_rank);\n+  SmallVector<int64_t, 2> a2_transpose_shape(block_rank + input_rank);\n+\n+  a2_perm[0] = block_rank;\n+  for (int i = 0; i < block_rank; i++) {\n+    a2_perm[1 + i * 2 + 0] = block_rank + 1 + i;\n+    a2_perm[1 + i * 2 + 1] = i;\n+  }\n+\n+  for (int i = 0; i < remaining_shape_rank; i++) {\n+    a2_perm[1 + 2 * block_rank + i] = 1 + 2 * block_rank + i;\n+  }\n+\n+  // 2b. calculate the a2_permuted shape\n+  for (int i = 0; i < (block_rank + input_rank); i++) {\n+    a2_transpose_shape[i] = a1_shape[a2_perm[i]];\n+  }\n+\n+  auto a2_transpose_perm =\n+      get1DConstTensor<tosa::ConstOp, int32_t>(rewriter, op, a2_perm);\n+  auto a2_transpose_a1_op = rewriter.create<tosa::TransposeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(a2_transpose_shape),\n+                            result_type.getElementType()),\n+      a1_reshape_input_op.getResult(), a2_transpose_perm);\n+\n+  // Step 3. Reshape to:\n+  // [ batch / prod(block_shape) ],\n+  // [input_shape[1] * block_shape[0] ],\n+  //    ..\n+  // [input_shape[M * block_shape[M-1],\n+  // + remaining input shapes [input_shape[M+1.. N-1]]\n+  SmallVector<int64_t, 2> a4_shape(input_rank);\n+\n+  a4_shape[0] = input_shape[0] / block_num_elems;\n+  for (int i = 0; i < block_rank; i++) {\n+    a4_shape[1 + i] = input_shape[i + 1] * block_shape[i];\n+  }\n+  for (int i = 0; i < remaining_shape_rank; i++) {\n+    a4_shape[1 + block_rank + i] = input_shape[block_rank + 1 + i];\n+  }\n+\n+  auto a3_reshape_a2 = rewriter.create<tosa::ReshapeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(a4_shape),\n+                            result_type.getElementType()),\n+      a2_transpose_a1_op.getResult(), rewriter.getI64ArrayAttr(a4_shape));\n+\n+  // 4. Crop the start/end dimensions on 'spatial dimension' according to\n+  // crops\n+  // Use a slice operator to do the cropping.\n+  //\n+  // Calculate a beginning point and a size:\n+  // - Begin is the origin, offset by the lo crop amount in each dimension\n+  // - Size is the reshaped tensor size, minus the quantity (lo + hi) for each\n+  // dimension\n+  SmallVector<int64_t, 4> a4_begin_vals(input_rank), a4_size_vals(input_rank);\n+\n+  for (int i = 0; i < input_rank; i++) {\n+    // Batch dimension and remaining dimensions.\n+    if (i == 0 || i > crops_dims) {\n+      a4_begin_vals[i] = 0;\n+      a4_size_vals[i] = result_type.getShape()[i];\n+    }\n+    // Spatial dimension.\n+    else {\n+      assert(i - 1 >= 0 && i - 1 < crops_dims);\n+      a4_begin_vals[i] = crops[i - 1].first;\n+      a4_size_vals[i] = a4_shape[i] - crops[i - 1].first - crops[i - 1].second;\n+    }\n+  }\n+\n+  auto a4_slice_a3_op = rewriter.create<tosa::SliceOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(a4_size_vals),\n+                            result_type.getElementType()),\n+      a3_reshape_a2.getResult(), rewriter.getI64ArrayAttr(a4_begin_vals),\n+      rewriter.getI64ArrayAttr(a4_size_vals));\n+\n+  return a4_slice_a3_op;\n+}\n+\n+// Lowers ExpandDims to TOSA.\n+Operation* convertExpandDimsOp(PatternRewriter& rewriter, Operation* op,\n+                               Value result_value, Value input_value,\n+                               Value dim_value) {\n+  // Lowers to a reshape op with 1's inserted in the appropriate dimensions.\n+  auto output_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  // Not a ranked tensor output\n+  if (!output_type) {\n+    op->emitOpError(\"ExpandDims: output type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  auto input_type = input_value.getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"ExpandDims: input type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  auto input_shape = input_type.getShape();\n+\n+  ElementsAttr dim_elem;\n+  if (!matchPattern(dim_value, m_Constant(&dim_elem))) return nullptr;\n+\n+  assert(dim_elem.getNumElements() == 1);\n+  int32_t dim = dim_elem.getValue<IntegerAttr>(0).getInt();\n+\n+  SmallVector<int64_t, 4> reshape_dims;\n+  if (dim < 0 || dim >= input_shape.size()) {  // add dim at end of tensor\n+    dim = input_shape.size();\n+    for (int i = 0; i < input_shape.size(); i++) {\n+      reshape_dims.emplace_back(input_shape[i]);\n+    }\n+    reshape_dims.emplace_back(1);\n+  } else {\n+    for (int i = 0; i < input_shape.size(); i++) {\n+      if (i == dim) {\n+        reshape_dims.emplace_back(1);\n+      }\n+      reshape_dims.emplace_back(input_shape[i]);\n+    }\n+  }\n+\n+  ArrayAttr shape_attr = rewriter.getI64ArrayAttr(reshape_dims);\n+\n+  auto reshape_op = rewriter.create<tosa::ReshapeOp>(op->getLoc(), output_type,\n+                                                     input_value, shape_attr);\n+\n+  return reshape_op;\n+}\n+\n+// Lowers Squeeze to TOSA.\n+Operation* convertSqueezeOp(PatternRewriter& rewriter, Operation* op,\n+                            Value result_value, Value input_value,\n+                            SmallVector<int32_t, 8>& squeeze_dims) {\n+  // Lowers to a reshape op where dimensions in squeeze_dims with size=1\n+  // are removed.\n+  auto output_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  // Not a ranked tensor output\n+  if (!output_type) {\n+    op->emitOpError(\"Squeeze: output type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  auto input_type = input_value.getType().dyn_cast<RankedTensorType>();\n+  if (!input_type) {\n+    op->emitOpError(\"Squeeze: input type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  auto input_shape = input_type.getShape();\n+\n+  SmallVector<int64_t, 8> reshape_dims;\n+\n+  if (squeeze_dims.size() == 0) {  // remove all 1-dims\n+    for (int i = 0; i < input_shape.size(); i++) {\n+      if (input_shape[i] != 1) {\n+        reshape_dims.emplace_back(input_shape[i]);\n+      }\n+    }\n+  } else {\n+    // Remove only specified dims.\n+    // First sort the array so they can be picked off in sequence.\n+    std::sort(squeeze_dims.begin(), squeeze_dims.end(),\n+              [](const int32_t& a, const int32_t& b) { return a < b; });\n+\n+    int pos = 0;\n+    auto dim = squeeze_dims[pos];\n+    for (int i = 0; i < input_shape.size(); i++) {\n+      if (i == dim) {\n+        pos = pos + 1;\n+        if (pos < squeeze_dims.size())\n+          dim = squeeze_dims[pos];\n+        else\n+          dim = -1;  // Invalid\n+      } else {\n+        reshape_dims.emplace_back(input_shape[i]);\n+      }\n+    }\n+  }\n+\n+  ArrayAttr shape_attr = rewriter.getI64ArrayAttr(reshape_dims);\n+\n+  auto reshape_op = rewriter.create<tosa::ReshapeOp>(op->getLoc(), output_type,\n+                                                     input_value, shape_attr);\n+  return reshape_op;\n+}\n+\n+// Lowers ELU to a sequence of TOSA ops.\n+Operation* convertEluOp(PatternRewriter& rewriter, Operation* op,\n+                        Value result_value, Value features_value) {\n+  // Lowers Elu using the following formula:\n+  // elu(x) = x < 0 ? (exp(x) - 1) : x\n+  // one = const({1});\n+  // zero = const({0});\n+  // one_bcast = reshape(one, [1, ..., rank(x) - 1])\n+  // zero_bcast = reshape(zero, [1, ..., rank(x) - 1])\n+  // a1 = exp(x);\n+  // a2 = sub(a1, one_bcast)\n+  // a3 = ge(x, zero_bcast)\n+  // a4 = select(a3, x, a2)\n+  auto output_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  // Not a ranked tensor output\n+  if (!output_type) {\n+    op->emitOpError(\"Elu: output type not ranked tensor\");\n+    return nullptr;\n+  }\n+\n+  int32_t input_rank = output_type.getShape().size();\n+  std::vector<int64_t> bcast_shape;\n+  for (int i = 0; i < input_rank; i++) {\n+    bcast_shape.push_back(1);\n+  }\n+\n+  // Can't directly create size=1, rank=rank(input) tensor because\n+  // it will be optimized out.  Instead, create rank0 tensor and reshape later.\n+  auto one_const_op = getTosaConstTensorSingleF32(rewriter, op, 1.0);\n+\n+  auto zero_const_op = getTosaConstTensorSingleF32(rewriter, op, 0.0);\n+\n+  auto one_reshape_op = rewriter.create<tosa::ReshapeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(bcast_shape),\n+                            output_type.getElementType()),\n+      one_const_op, rewriter.getI64ArrayAttr(bcast_shape));\n+\n+  auto zero_reshape_op = rewriter.create<tosa::ReshapeOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(ArrayRef<int64_t>(bcast_shape),\n+                            output_type.getElementType()),\n+      zero_const_op, rewriter.getI64ArrayAttr(bcast_shape));\n+\n+  auto a1_exp_in_op =\n+      rewriter.create<tosa::ExpOp>(op->getLoc(), output_type, features_value);\n+\n+  auto a2_sub_a1_one_op = rewriter.create<tosa::SubOp>(\n+      op->getLoc(), output_type, a1_exp_in_op.getResult(), one_const_op);\n+\n+  auto a3_ge_in_zero_op = rewriter.create<tosa::GreaterEqualOp>(\n+      op->getLoc(),\n+      RankedTensorType::get(output_type.getShape(), rewriter.getIntegerType(1)),\n+      features_value, zero_const_op);\n+\n+  auto a4_select_a3_op = rewriter.create<tosa::SelectOp>(\n+      op->getLoc(), output_type, a3_ge_in_zero_op.getResult(), features_value,\n+      a2_sub_a1_one_op.getResult());\n+\n+  return a4_select_a3_op;\n+}\n+\n+// Lowers Softmax to a sequence of TOSA ops.\n+Operation* convertSoftmaxOp(PatternRewriter& rewriter, Operation* op,\n+                            Value result_value, Value logits_value) {\n+  // softmax = exp(logits) / reduce_sum(exp(logits), -1)\n+  //\n+  // or equivalently multiply exp(-max(logits)) to both numerator and\n+  // denominator we get:\n+  //\n+  // softmax = exp(logits - max(logits)) / reduce_sum(exp(logits -\n+  // max(logits)), -1)\n+  //\n+  // We'll use first version for direct fp lowering, and second version for\n+  // quantized lowering since second one we can restrict input to exp() be\n+  // negative, and thus LUT can always be within [0.0, 1.0].\n+  auto output_type = result_value.getType().dyn_cast<RankedTensorType>();\n+  auto input_type = logits_value.getType().dyn_cast<RankedTensorType>();\n+\n+  // Not a ranked tensor input/output\n+  if (!output_type || !input_type) {\n+    op->emitOpError(\"Softmax: input and result not ranked tensors\");\n+    return nullptr;\n+  }\n+\n+  // reduce_sum on last dimension\n+  int32_t input_rank = input_type.getShape().size();\n+  ArrayAttr axis_attr = rewriter.getI64ArrayAttr({input_rank - 1});\n+  ArrayRef<int64_t> logits_shape = output_type.getShape();\n+\n+  if (input_type.getElementType().isa<mlir::quant::QuantizedType>() &&\n+      output_type.getElementType().isa<mlir::quant::QuantizedType>()) {\n+    std::vector<int64_t> rsum_shape_v(input_type.getShape().begin(),\n+                                      input_type.getShape().end() - 1);\n+    rsum_shape_v.push_back(1);\n+    ArrayRef<int64_t> rsum_shape(rsum_shape_v);\n+    mlir::quant::UniformQuantizedType in_quant_type =\n+        input_type.getElementType()\n+            .dyn_cast_or_null<mlir::quant::UniformQuantizedType>();",
        "comment_created_at": "2020-11-17T22:08:10+00:00",
        "comment_author": "stellaraccident",
        "comment_body": "You are doing a `dyn_cast_or_null` and then not error checking. Either switch to `cast` or guard appropriately.\r\n\r\nI suggest you hoist these outside of the condition then change to `if (in_quant_type && out_quant_type) {`. Also, I believe that `dyn_cast` is the right thing. The element type cannot be null.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1348959514",
    "pr_number": 60227,
    "pr_file": "tensorflow/core/common_runtime/direct_session.cc",
    "created_at": "2023-10-06T16:34:54+00:00",
    "commented_code": "executor_step_count, &debugger_state));\n   }\n \n-  if (run_metadata != nullptr &&\n-      options_.config.experimental().has_session_metadata()) {\n+  if (run_metadata == nullptr) {\n+    return absl::InternalError(\"Metadata output is not set.\");\n+  }",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1348959514",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 60227,
        "pr_file": "tensorflow/core/common_runtime/direct_session.cc",
        "discussion_id": "1348959514",
        "commented_code": "@@ -542,8 +542,11 @@ Status DirectSession::RunInternal(\n                             executor_step_count, &debugger_state));\n   }\n \n-  if (run_metadata != nullptr &&\n-      options_.config.experimental().has_session_metadata()) {\n+  if (run_metadata == nullptr) {\n+    return absl::InternalError(\"Metadata output is not set.\");\n+  }",
        "comment_created_at": "2023-10-06T16:34:54+00:00",
        "comment_author": "mrry",
        "comment_body": "Unfortunately, this is a breaking change to the API, which results in at least some of the test failures. The `run_metadata` has to be optional. \r\n\r\nBut the fundamental observation in the PR is correct: it is possible to trigger a segfault or other undefined behavior via particular combinations of `RunOptions` and a null `run_metadata`.\r\n\r\nUnfortunately that means that we need guards on each subsequent use of `run_metadata`. Would you be able to take this on? Thanks!",
        "pr_file_module": null
      },
      {
        "comment_id": "1354902661",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 60227,
        "pr_file": "tensorflow/core/common_runtime/direct_session.cc",
        "discussion_id": "1348959514",
        "commented_code": "@@ -542,8 +542,11 @@ Status DirectSession::RunInternal(\n                             executor_step_count, &debugger_state));\n   }\n \n-  if (run_metadata != nullptr &&\n-      options_.config.experimental().has_session_metadata()) {\n+  if (run_metadata == nullptr) {\n+    return absl::InternalError(\"Metadata output is not set.\");\n+  }",
        "comment_created_at": "2023-10-11T12:40:53+00:00",
        "comment_author": "PaDarochek",
        "comment_body": "Thank you for the revision! I'll fix it in near future.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1330413587",
    "pr_number": 61913,
    "pr_file": "tensorflow/core/lib/gif/gif_io.cc",
    "created_at": "2023-09-19T16:34:44+00:00",
    "commented_code": "if (DGifSlurp(gif_file) != GIF_OK) {\n     *error_string = absl::StrCat(\"failed to slurp gif file: \",\n                                  GifErrorStringNonNull(gif_file->Error));\n-    // Only stop load if no images are detected.\n-    if (gif_file->ImageCount <= 0) {\n-      return nullptr;\n-    }\n-    LOG(WARNING) << *error_string;\n+    LOG(ERROR) << *error_string;",
    "repo_full_name": "tensorflow/tensorflow",
    "discussion_comments": [
      {
        "comment_id": "1330413587",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 61913,
        "pr_file": "tensorflow/core/lib/gif/gif_io.cc",
        "discussion_id": "1330413587",
        "commented_code": "@@ -78,11 +78,8 @@ uint8* Decode(const void* srcdata, int datasize,\n   if (DGifSlurp(gif_file) != GIF_OK) {\n     *error_string = absl::StrCat(\"failed to slurp gif file: \",\n                                  GifErrorStringNonNull(gif_file->Error));\n-    // Only stop load if no images are detected.\n-    if (gif_file->ImageCount <= 0) {\n-      return nullptr;\n-    }\n-    LOG(WARNING) << *error_string;\n+    LOG(ERROR) << *error_string;",
        "comment_created_at": "2023-09-19T16:34:44+00:00",
        "comment_author": "mihaimaruseac",
        "comment_body": "You still have a `gif_file` dereference when building the `error_string`.\r\n\r\nCan we make this first check if `gif_file` is `nullptr` and return a standard error string there and then return the existing logic otherwise?\r\n\r\n(Unless I'm misunderstanding which ptr is null)",
        "pr_file_module": null
      },
      {
        "comment_id": "1331334246",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 61913,
        "pr_file": "tensorflow/core/lib/gif/gif_io.cc",
        "discussion_id": "1330413587",
        "commented_code": "@@ -78,11 +78,8 @@ uint8* Decode(const void* srcdata, int datasize,\n   if (DGifSlurp(gif_file) != GIF_OK) {\n     *error_string = absl::StrCat(\"failed to slurp gif file: \",\n                                  GifErrorStringNonNull(gif_file->Error));\n-    // Only stop load if no images are detected.\n-    if (gif_file->ImageCount <= 0) {\n-      return nullptr;\n-    }\n-    LOG(WARNING) << *error_string;\n+    LOG(ERROR) << *error_string;",
        "comment_created_at": "2023-09-20T09:22:16+00:00",
        "comment_author": "kobrineli",
        "comment_body": "`gif_file` is not `nullptr` in this case, it's ok. The `RasterBits` field in `gif_file` is `nullptr` and is dereferenced at `gif_io.cc:178`. \r\n\r\nBut maybe we should check `gif_file` for `nullptr` as well.",
        "pr_file_module": null
      },
      {
        "comment_id": "1331743404",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 61913,
        "pr_file": "tensorflow/core/lib/gif/gif_io.cc",
        "discussion_id": "1330413587",
        "commented_code": "@@ -78,11 +78,8 @@ uint8* Decode(const void* srcdata, int datasize,\n   if (DGifSlurp(gif_file) != GIF_OK) {\n     *error_string = absl::StrCat(\"failed to slurp gif file: \",\n                                  GifErrorStringNonNull(gif_file->Error));\n-    // Only stop load if no images are detected.\n-    if (gif_file->ImageCount <= 0) {\n-      return nullptr;\n-    }\n-    LOG(WARNING) << *error_string;\n+    LOG(ERROR) << *error_string;",
        "comment_created_at": "2023-09-20T14:41:05+00:00",
        "comment_author": "mihaimaruseac",
        "comment_body": "That makes sense, I'll resolve this. Thanks for clarification",
        "pr_file_module": null
      },
      {
        "comment_id": "1331743917",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 61913,
        "pr_file": "tensorflow/core/lib/gif/gif_io.cc",
        "discussion_id": "1330413587",
        "commented_code": "@@ -78,11 +78,8 @@ uint8* Decode(const void* srcdata, int datasize,\n   if (DGifSlurp(gif_file) != GIF_OK) {\n     *error_string = absl::StrCat(\"failed to slurp gif file: \",\n                                  GifErrorStringNonNull(gif_file->Error));\n-    // Only stop load if no images are detected.\n-    if (gif_file->ImageCount <= 0) {\n-      return nullptr;\n-    }\n-    LOG(WARNING) << *error_string;\n+    LOG(ERROR) << *error_string;",
        "comment_created_at": "2023-09-20T14:41:27+00:00",
        "comment_author": "mihaimaruseac",
        "comment_body": "Actually, can we check the `git_file->RasterBits` field directly?",
        "pr_file_module": null
      },
      {
        "comment_id": "1331901208",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 61913,
        "pr_file": "tensorflow/core/lib/gif/gif_io.cc",
        "discussion_id": "1330413587",
        "commented_code": "@@ -78,11 +78,8 @@ uint8* Decode(const void* srcdata, int datasize,\n   if (DGifSlurp(gif_file) != GIF_OK) {\n     *error_string = absl::StrCat(\"failed to slurp gif file: \",\n                                  GifErrorStringNonNull(gif_file->Error));\n-    // Only stop load if no images are detected.\n-    if (gif_file->ImageCount <= 0) {\n-      return nullptr;\n-    }\n-    LOG(WARNING) << *error_string;\n+    LOG(ERROR) << *error_string;",
        "comment_created_at": "2023-09-20T16:26:30+00:00",
        "comment_author": "kobrineli",
        "comment_body": "@mihaimaruseac\r\nWe can, but the logic of returning error relying on incorrect image counter is still wrong",
        "pr_file_module": null
      },
      {
        "comment_id": "1339194227",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 61913,
        "pr_file": "tensorflow/core/lib/gif/gif_io.cc",
        "discussion_id": "1330413587",
        "commented_code": "@@ -78,11 +78,8 @@ uint8* Decode(const void* srcdata, int datasize,\n   if (DGifSlurp(gif_file) != GIF_OK) {\n     *error_string = absl::StrCat(\"failed to slurp gif file: \",\n                                  GifErrorStringNonNull(gif_file->Error));\n-    // Only stop load if no images are detected.\n-    if (gif_file->ImageCount <= 0) {\n-      return nullptr;\n-    }\n-    LOG(WARNING) << *error_string;\n+    LOG(ERROR) << *error_string;",
        "comment_created_at": "2023-09-27T20:45:33+00:00",
        "comment_author": "cantonios",
        "comment_body": "The image counter should be fixed in the dependency, and here we can check both the image counter and the `RasterBits` field until the upstream fix has landed.",
        "pr_file_module": null
      },
      {
        "comment_id": "1340642597",
        "repo_full_name": "tensorflow/tensorflow",
        "pr_number": 61913,
        "pr_file": "tensorflow/core/lib/gif/gif_io.cc",
        "discussion_id": "1330413587",
        "commented_code": "@@ -78,11 +78,8 @@ uint8* Decode(const void* srcdata, int datasize,\n   if (DGifSlurp(gif_file) != GIF_OK) {\n     *error_string = absl::StrCat(\"failed to slurp gif file: \",\n                                  GifErrorStringNonNull(gif_file->Error));\n-    // Only stop load if no images are detected.\n-    if (gif_file->ImageCount <= 0) {\n-      return nullptr;\n-    }\n-    LOG(WARNING) << *error_string;\n+    LOG(ERROR) << *error_string;",
        "comment_created_at": "2023-09-28T20:37:19+00:00",
        "comment_author": "kobrineli",
        "comment_body": "Ok, I'll try to fix the dependency library and send the PR",
        "pr_file_module": null
      }
    ]
  }
]