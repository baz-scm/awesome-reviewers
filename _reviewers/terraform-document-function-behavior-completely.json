[
  {
    "discussion_id": "2192198843",
    "pr_number": 37286,
    "pr_file": "internal/command/workdir/backend_config_state.go",
    "created_at": "2025-07-08T11:10:37+00:00",
    "commented_code": "//\n // The backend configuration schema is required in order to properly\n // encode the backend-specific configuration settings.\n-func (s *BackendConfigState) PlanData(schema *configschema.Block, workspaceName string) (*plans.Backend, error) {\n+//\n+// As backends are not implemented by providers, the provider schema argument should always be nil\n+func (s *BackendConfigState) PlanData(schema *configschema.Block, providerSchema *configschema.Block, workspaceName string) (*plans.Backend, error) {",
    "repo_full_name": "hashicorp/terraform",
    "discussion_comments": [
      {
        "comment_id": "2192198843",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 37286,
        "pr_file": "internal/command/workdir/backend_config_state.go",
        "discussion_id": "2192198843",
        "commented_code": "@@ -72,7 +72,9 @@ func (s *BackendConfigState) SetConfig(val cty.Value, schema *configschema.Block\n //\n // The backend configuration schema is required in order to properly\n // encode the backend-specific configuration settings.\n-func (s *BackendConfigState) PlanData(schema *configschema.Block, workspaceName string) (*plans.Backend, error) {\n+//\n+// As backends are not implemented by providers, the provider schema argument should always be nil\n+func (s *BackendConfigState) PlanData(schema *configschema.Block, providerSchema *configschema.Block, workspaceName string) (*plans.Backend, error) {",
        "comment_created_at": "2025-07-08T11:10:37+00:00",
        "comment_author": "radeksimko",
        "comment_body": "```suggestion\r\nfunc (s *BackendConfigState) PlanData(schema *configschema.Block, _ *configschema.Block, workspaceName string) (*plans.Backend, error) {\r\n```\r\nnitpick - this would just further help reinforce what is being documented above",
        "pr_file_module": null
      },
      {
        "comment_id": "2192555729",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 37286,
        "pr_file": "internal/command/workdir/backend_config_state.go",
        "discussion_id": "2192198843",
        "commented_code": "@@ -72,7 +72,9 @@ func (s *BackendConfigState) SetConfig(val cty.Value, schema *configschema.Block\n //\n // The backend configuration schema is required in order to properly\n // encode the backend-specific configuration settings.\n-func (s *BackendConfigState) PlanData(schema *configschema.Block, workspaceName string) (*plans.Backend, error) {\n+//\n+// As backends are not implemented by providers, the provider schema argument should always be nil\n+func (s *BackendConfigState) PlanData(schema *configschema.Block, providerSchema *configschema.Block, workspaceName string) (*plans.Backend, error) {",
        "comment_created_at": "2025-07-08T13:35:17+00:00",
        "comment_author": "SarahFrench",
        "comment_body": "Ah yes, of course \ud83e\udd26\ud83c\udffb\u200d\u2640\ufe0f Good idea!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1972146112",
    "pr_number": 36579,
    "pr_file": "internal/tfdiags/compare.go",
    "created_at": "2025-02-26T18:38:46+00:00",
    "commented_code": null,
    "repo_full_name": "hashicorp/terraform",
    "discussion_comments": [
      {
        "comment_id": "1972146112",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36579,
        "pr_file": "internal/tfdiags/compare.go",
        "discussion_id": "1972146112",
        "commented_code": null,
        "comment_created_at": "2025-02-26T18:38:46+00:00",
        "comment_author": "SarahFrench",
        "comment_body": "Could you please update the comment above `DiagnosticComparer`? It looks like the new comment should say that comparison is only possible if the diagnostics have the same underlying type (e.g. cannot compare hclDiagnostic and rpcFriendlyDiag) and the comparison is implemented differently per diagnostic type.\r\n\r\nThis PR's changes doesn't have an impact on test assertions as [the test helpers convert to RPC-friendly diags](https://github.com/hashicorp/terraform/blob/ebbe1e9fb4be89d4b69e123d13773ce6f3236027/internal/tfdiags/testing.go#L27-L35) before comparison, but if anyone tried to use the comparer directly they might be misled by the old comment",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1972175464",
    "pr_number": 36579,
    "pr_file": "internal/tfdiags/diagnostics.go",
    "created_at": "2025-02-26T18:53:31+00:00",
    "commented_code": "return diags\n }\n \n+func (diags Diagnostics) ContainsDiagnostic(diag ComparableDiagnostic) bool {\n+\tfor _, d := range diags {\n+\t\tif cd, ok := d.(ComparableDiagnostic); ok && diag.Equals(cd) {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+func (diags Diagnostics) AppendWithoutDuplicates(newDiags ...Diagnostic) Diagnostics {",
    "repo_full_name": "hashicorp/terraform",
    "discussion_comments": [
      {
        "comment_id": "1972175464",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36579,
        "pr_file": "internal/tfdiags/diagnostics.go",
        "discussion_id": "1972175464",
        "commented_code": "@@ -83,6 +83,41 @@ func (diags Diagnostics) Append(new ...interface{}) Diagnostics {\n \treturn diags\n }\n \n+func (diags Diagnostics) ContainsDiagnostic(diag ComparableDiagnostic) bool {\n+\tfor _, d := range diags {\n+\t\tif cd, ok := d.(ComparableDiagnostic); ok && diag.Equals(cd) {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+func (diags Diagnostics) AppendWithoutDuplicates(newDiags ...Diagnostic) Diagnostics {",
        "comment_created_at": "2025-02-26T18:53:31+00:00",
        "comment_author": "jbardin",
        "comment_body": "We should probably document that `AppendWithoutDuplicates` only classifies \"duplicates\" as things which implement `ComparableDiagnostic` and return true for `Equals`. As it is this we can still collect things which won't be deduped.",
        "pr_file_module": null
      },
      {
        "comment_id": "1973882535",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36579,
        "pr_file": "internal/tfdiags/diagnostics.go",
        "discussion_id": "1972175464",
        "commented_code": "@@ -83,6 +83,41 @@ func (diags Diagnostics) Append(new ...interface{}) Diagnostics {\n \treturn diags\n }\n \n+func (diags Diagnostics) ContainsDiagnostic(diag ComparableDiagnostic) bool {\n+\tfor _, d := range diags {\n+\t\tif cd, ok := d.(ComparableDiagnostic); ok && diag.Equals(cd) {\n+\t\t\treturn true\n+\t\t}\n+\t}\n+\treturn false\n+}\n+\n+func (diags Diagnostics) AppendWithoutDuplicates(newDiags ...Diagnostic) Diagnostics {",
        "comment_created_at": "2025-02-27T15:56:56+00:00",
        "comment_author": "radeksimko",
        "comment_body": "I added docs, good call out.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1924915640",
    "pr_number": 36300,
    "pr_file": "internal/backend/local/test.go",
    "created_at": "2025-01-22T08:39:27+00:00",
    "commented_code": "file.Status = file.Status.Merge(moduletest.Pass)\n \t}\n \n-\t// Now execute the runs.\n-\tfor _, run := range file.Runs {\n+\t// Build the graph for the file.\n+\tb := graph.TestGraphBuilder{File: file, GlobalVars: runner.EvalContext.VariableCaches.GlobalVariables}\n+\tgraph, diags := b.Build()\n+\tfile.Diagnostics = file.Diagnostics.Append(diags)\n+\tif diags.HasErrors() {\n+\t\tfile.Status = file.Status.Merge(moduletest.Error)\n+\t\treturn\n+\t}\n+\n+\t// walk and execute the graph\n+\tdiags = runner.walkGraph(graph)\n+\n+\t// If the graph walk was terminated, we don't want to add the diagnostics.\n+\t// The error the user receives will just be:\n+\t// \t\t\tFailure! 0 passed, 1 failed.\n+\t// \t\t\texit status 1\n+\tif diags.HasErrors() && diags.Err().Error() == dag.GraphTerminatedError.Error() {\n+\t\tlog.Printf(\"[TRACE] TestFileRunner: graph walk terminated for %s due to error: %s\", file.Name, dag.GraphTerminatedError)\n+\t\treturn\n+\t}\n+\n+\tfile.Diagnostics = file.Diagnostics.Append(diags)\n+}\n+\n+// walkGraph goes through the graph and execute each run it finds.\n+func (runner *TestFileRunner) walkGraph(g *terraform.Graph) tfdiags.Diagnostics {\n+\tsem := runner.Suite.semaphore\n+\n+\t// Walk the graph.\n+\twalkFn := func(v dag.Vertex) (diags tfdiags.Diagnostics) {\n+\t\t// the walkFn is called asynchronously, and needs to be recovered\n+\t\t// separately in the case of a panic.\n+\t\tdefer logging.PanicHandler()\n+\n+\t\tlog.Printf(\"[TRACE] vertex %q: starting visit (%T)\", dag.VertexName(v), v)\n+\n+\t\tdefer func() {\n+\t\t\tif r := recover(); r != nil {\n+\t\t\t\t// If the walkFn panics, we get confusing logs about how the\n+\t\t\t\t// visit was complete. To stop this, we'll catch the panic log\n+\t\t\t\t// that the vertex panicked without finishing and re-panic.\n+\t\t\t\tlog.Printf(\"[ERROR] vertex %q panicked\", dag.VertexName(v))\n+\t\t\t\tpanic(r) // re-panic\n+\t\t\t}\n+\n+\t\t\tif diags.HasErrors() {\n+\t\t\t\tfor _, diag := range diags {\n+\t\t\t\t\tif diag.Severity() == tfdiags.Error {\n+\t\t\t\t\t\tdesc := diag.Description()\n+\t\t\t\t\t\tlog.Printf(\"[ERROR] vertex %q error: %s\", dag.VertexName(v), desc.Summary)\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\tlog.Printf(\"[TRACE] vertex %q: visit complete, with errors\", dag.VertexName(v))\n+\t\t\t} else {\n+\t\t\t\tlog.Printf(\"[TRACE] vertex %q: visit complete\", dag.VertexName(v))\n+\t\t\t}\n+\t\t}()\n+\n+\t\t// Acquire a lock on the semaphore\n+\t\tsem.Acquire()\n+\t\tdefer sem.Release()\n+\n+\t\tswitch v := v.(type) {\n+\t\tcase *graph.NodeTestRun:\n+\t\t\tdiags = v.Execute(runner.EvalContext)",
    "repo_full_name": "hashicorp/terraform",
    "discussion_comments": [
      {
        "comment_id": "1924915640",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36300,
        "pr_file": "internal/backend/local/test.go",
        "discussion_id": "1924915640",
        "commented_code": "@@ -309,15 +269,97 @@ func (runner *TestFileRunner) Test(file *moduletest.File) {\n \t\tfile.Status = file.Status.Merge(moduletest.Pass)\n \t}\n \n-\t// Now execute the runs.\n-\tfor _, run := range file.Runs {\n+\t// Build the graph for the file.\n+\tb := graph.TestGraphBuilder{File: file, GlobalVars: runner.EvalContext.VariableCaches.GlobalVariables}\n+\tgraph, diags := b.Build()\n+\tfile.Diagnostics = file.Diagnostics.Append(diags)\n+\tif diags.HasErrors() {\n+\t\tfile.Status = file.Status.Merge(moduletest.Error)\n+\t\treturn\n+\t}\n+\n+\t// walk and execute the graph\n+\tdiags = runner.walkGraph(graph)\n+\n+\t// If the graph walk was terminated, we don't want to add the diagnostics.\n+\t// The error the user receives will just be:\n+\t// \t\t\tFailure! 0 passed, 1 failed.\n+\t// \t\t\texit status 1\n+\tif diags.HasErrors() && diags.Err().Error() == dag.GraphTerminatedError.Error() {\n+\t\tlog.Printf(\"[TRACE] TestFileRunner: graph walk terminated for %s due to error: %s\", file.Name, dag.GraphTerminatedError)\n+\t\treturn\n+\t}\n+\n+\tfile.Diagnostics = file.Diagnostics.Append(diags)\n+}\n+\n+// walkGraph goes through the graph and execute each run it finds.\n+func (runner *TestFileRunner) walkGraph(g *terraform.Graph) tfdiags.Diagnostics {\n+\tsem := runner.Suite.semaphore\n+\n+\t// Walk the graph.\n+\twalkFn := func(v dag.Vertex) (diags tfdiags.Diagnostics) {\n+\t\t// the walkFn is called asynchronously, and needs to be recovered\n+\t\t// separately in the case of a panic.\n+\t\tdefer logging.PanicHandler()\n+\n+\t\tlog.Printf(\"[TRACE] vertex %q: starting visit (%T)\", dag.VertexName(v), v)\n+\n+\t\tdefer func() {\n+\t\t\tif r := recover(); r != nil {\n+\t\t\t\t// If the walkFn panics, we get confusing logs about how the\n+\t\t\t\t// visit was complete. To stop this, we'll catch the panic log\n+\t\t\t\t// that the vertex panicked without finishing and re-panic.\n+\t\t\t\tlog.Printf(\"[ERROR] vertex %q panicked\", dag.VertexName(v))\n+\t\t\t\tpanic(r) // re-panic\n+\t\t\t}\n+\n+\t\t\tif diags.HasErrors() {\n+\t\t\t\tfor _, diag := range diags {\n+\t\t\t\t\tif diag.Severity() == tfdiags.Error {\n+\t\t\t\t\t\tdesc := diag.Description()\n+\t\t\t\t\t\tlog.Printf(\"[ERROR] vertex %q error: %s\", dag.VertexName(v), desc.Summary)\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t\tlog.Printf(\"[TRACE] vertex %q: visit complete, with errors\", dag.VertexName(v))\n+\t\t\t} else {\n+\t\t\t\tlog.Printf(\"[TRACE] vertex %q: visit complete\", dag.VertexName(v))\n+\t\t\t}\n+\t\t}()\n+\n+\t\t// Acquire a lock on the semaphore\n+\t\tsem.Acquire()\n+\t\tdefer sem.Release()\n+\n+\t\tswitch v := v.(type) {\n+\t\tcase *graph.NodeTestRun:\n+\t\t\tdiags = v.Execute(runner.EvalContext)",
        "comment_created_at": "2025-01-22T08:39:27+00:00",
        "comment_author": "liamcervante",
        "comment_body": "I've made a note of this elsewhere, but perhaps leave a comment here that explicitly documents this execute function isn't actually executing the tests but simply preparing the node for execution, so we'll slowly port more functionality over to the graph as we need it?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1909143276",
    "pr_number": 36258,
    "pr_file": "internal/backend/remote-state/azure/backend.go",
    "created_at": "2025-01-09T16:42:28+00:00",
    "commented_code": "\"container_name\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tRequired:    true,\n-\t\t\t\tDescription: \"The container name.\",\n+\t\t\t\tDescription: \"The container name to use in the Storage Account.\",\n \t\t\t},\n \n \t\t\t\"key\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tRequired:    true,\n-\t\t\t\tDescription: \"The blob key.\",\n+\t\t\t\tDescription: \"The blob key to use in the Storage Container.\",\n \t\t\t},\n \n-\t\t\t\"metadata_host\": {\n-\t\t\t\tType:        schema.TypeString,\n-\t\t\t\tRequired:    true,\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_METADATA_HOST\", \"\"),\n-\t\t\t\tDescription: \"The Metadata URL which will be used to obtain the Cloud Environment.\",\n+\t\t\t\"snapshot\": {\n+\t\t\t\tType:        schema.TypeBool,\n+\t\t\t\tOptional:    true,\n+\t\t\t\tDescription: \"Whether to enable automatic blob snapshotting.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SNAPSHOT\", false),\n \t\t\t},\n \n \t\t\t\"environment\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The Azure cloud environment.\",\n+\t\t\t\tDescription: \"The Cloud Environment which should be used. Possible values are public, usgovernment, and china. Defaults to public. Not used and should not be specified when `metadata_host` is specified.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ENVIRONMENT\", \"public\"),\n \t\t\t},\n \n+\t\t\t\"metadata_host\": {\n+\t\t\t\tType:        schema.TypeString,\n+\t\t\t\tRequired:    true,\n+\t\t\t\tDefaultFunc: schema.MultiEnvDefaultFunc([]string{\"ARM_METADATA_HOSTNAME\", \"ARM_METADATA_HOST\"}, \"\"), // TODO: remove support for `METADATA_HOST` in a future version\n+\t\t\t\tDescription: \"The Hostname which should be used for the Azure Metadata Service.\",\n+\t\t\t},\n+\n \t\t\t\"access_key\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The access key.\",\n+\t\t\t\tDescription: \"The access key to use when authenticating using a Storage Access Key.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ACCESS_KEY\", \"\"),\n \t\t\t},\n \n \t\t\t\"sas_token\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"A SAS Token used to interact with the Blob Storage Account.\",\n+\t\t\t\tDescription: \"The SAS Token to use when authenticating using a SAS Token.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SAS_TOKEN\", \"\"),\n \t\t\t},\n \n-\t\t\t\"snapshot\": {\n-\t\t\t\tType:        schema.TypeBool,\n-\t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"Enable/Disable automatic blob snapshotting\",\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SNAPSHOT\", false),\n-\t\t\t},\n-\n-\t\t\t\"resource_group_name\": {\n+\t\t\t\"tenant_id\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The resource group name.\",\n+\t\t\t\tDescription: \"The Tenant ID to use when authenticating using Azure Active Directory.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_TENANT_ID\", \"\"),\n \t\t\t},\n \n \t\t\t\"client_id\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The Client ID.\",\n+\t\t\t\tDescription: \"The Client ID to use when authenticating using Azure Active Directory.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_CLIENT_ID\", \"\"),\n \t\t\t},\n \n-\t\t\t\"endpoint\": {\n+\t\t\t\"client_id_file_path\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"A custom Endpoint used to access the Azure Resource Manager API's.\",\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ENDPOINT\", \"\"),\n+\t\t\t\tDescription: \"The path to a file containing the Client ID which should be used.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_CLIENT_ID_FILE_PATH\", nil),\n \t\t\t},\n \n-\t\t\t\"subscription_id\": {\n+\t\t\t\"endpoint\": {\n+\t\t\t\tType:       schema.TypeString,\n+\t\t\t\tOptional:   true,\n+\t\t\t\tDeprecated: \"`endpoint` is deprecated and no longer used, it will be removed in a future version of Terraform\",",
    "repo_full_name": "hashicorp/terraform",
    "discussion_comments": [
      {
        "comment_id": "1909143276",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36258,
        "pr_file": "internal/backend/remote-state/azure/backend.go",
        "discussion_id": "1909143276",
        "commented_code": "@@ -24,157 +39,187 @@ func New() backend.Backend {\n \t\t\t\"container_name\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tRequired:    true,\n-\t\t\t\tDescription: \"The container name.\",\n+\t\t\t\tDescription: \"The container name to use in the Storage Account.\",\n \t\t\t},\n \n \t\t\t\"key\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tRequired:    true,\n-\t\t\t\tDescription: \"The blob key.\",\n+\t\t\t\tDescription: \"The blob key to use in the Storage Container.\",\n \t\t\t},\n \n-\t\t\t\"metadata_host\": {\n-\t\t\t\tType:        schema.TypeString,\n-\t\t\t\tRequired:    true,\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_METADATA_HOST\", \"\"),\n-\t\t\t\tDescription: \"The Metadata URL which will be used to obtain the Cloud Environment.\",\n+\t\t\t\"snapshot\": {\n+\t\t\t\tType:        schema.TypeBool,\n+\t\t\t\tOptional:    true,\n+\t\t\t\tDescription: \"Whether to enable automatic blob snapshotting.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SNAPSHOT\", false),\n \t\t\t},\n \n \t\t\t\"environment\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The Azure cloud environment.\",\n+\t\t\t\tDescription: \"The Cloud Environment which should be used. Possible values are public, usgovernment, and china. Defaults to public. Not used and should not be specified when `metadata_host` is specified.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ENVIRONMENT\", \"public\"),\n \t\t\t},\n \n+\t\t\t\"metadata_host\": {\n+\t\t\t\tType:        schema.TypeString,\n+\t\t\t\tRequired:    true,\n+\t\t\t\tDefaultFunc: schema.MultiEnvDefaultFunc([]string{\"ARM_METADATA_HOSTNAME\", \"ARM_METADATA_HOST\"}, \"\"), // TODO: remove support for `METADATA_HOST` in a future version\n+\t\t\t\tDescription: \"The Hostname which should be used for the Azure Metadata Service.\",\n+\t\t\t},\n+\n \t\t\t\"access_key\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The access key.\",\n+\t\t\t\tDescription: \"The access key to use when authenticating using a Storage Access Key.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ACCESS_KEY\", \"\"),\n \t\t\t},\n \n \t\t\t\"sas_token\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"A SAS Token used to interact with the Blob Storage Account.\",\n+\t\t\t\tDescription: \"The SAS Token to use when authenticating using a SAS Token.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SAS_TOKEN\", \"\"),\n \t\t\t},\n \n-\t\t\t\"snapshot\": {\n-\t\t\t\tType:        schema.TypeBool,\n-\t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"Enable/Disable automatic blob snapshotting\",\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SNAPSHOT\", false),\n-\t\t\t},\n-\n-\t\t\t\"resource_group_name\": {\n+\t\t\t\"tenant_id\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The resource group name.\",\n+\t\t\t\tDescription: \"The Tenant ID to use when authenticating using Azure Active Directory.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_TENANT_ID\", \"\"),\n \t\t\t},\n \n \t\t\t\"client_id\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The Client ID.\",\n+\t\t\t\tDescription: \"The Client ID to use when authenticating using Azure Active Directory.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_CLIENT_ID\", \"\"),\n \t\t\t},\n \n-\t\t\t\"endpoint\": {\n+\t\t\t\"client_id_file_path\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"A custom Endpoint used to access the Azure Resource Manager API's.\",\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ENDPOINT\", \"\"),\n+\t\t\t\tDescription: \"The path to a file containing the Client ID which should be used.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_CLIENT_ID_FILE_PATH\", nil),\n \t\t\t},\n \n-\t\t\t\"subscription_id\": {\n+\t\t\t\"endpoint\": {\n+\t\t\t\tType:       schema.TypeString,\n+\t\t\t\tOptional:   true,\n+\t\t\t\tDeprecated: \"`endpoint` is deprecated and no longer used, it will be removed in a future version of Terraform\",",
        "comment_created_at": "2025-01-09T16:42:28+00:00",
        "comment_author": "mbfrahry",
        "comment_body": "Should this be deprecated? ",
        "pr_file_module": null
      },
      {
        "comment_id": "1921704242",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36258,
        "pr_file": "internal/backend/remote-state/azure/backend.go",
        "discussion_id": "1909143276",
        "commented_code": "@@ -24,157 +39,187 @@ func New() backend.Backend {\n \t\t\t\"container_name\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tRequired:    true,\n-\t\t\t\tDescription: \"The container name.\",\n+\t\t\t\tDescription: \"The container name to use in the Storage Account.\",\n \t\t\t},\n \n \t\t\t\"key\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tRequired:    true,\n-\t\t\t\tDescription: \"The blob key.\",\n+\t\t\t\tDescription: \"The blob key to use in the Storage Container.\",\n \t\t\t},\n \n-\t\t\t\"metadata_host\": {\n-\t\t\t\tType:        schema.TypeString,\n-\t\t\t\tRequired:    true,\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_METADATA_HOST\", \"\"),\n-\t\t\t\tDescription: \"The Metadata URL which will be used to obtain the Cloud Environment.\",\n+\t\t\t\"snapshot\": {\n+\t\t\t\tType:        schema.TypeBool,\n+\t\t\t\tOptional:    true,\n+\t\t\t\tDescription: \"Whether to enable automatic blob snapshotting.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SNAPSHOT\", false),\n \t\t\t},\n \n \t\t\t\"environment\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The Azure cloud environment.\",\n+\t\t\t\tDescription: \"The Cloud Environment which should be used. Possible values are public, usgovernment, and china. Defaults to public. Not used and should not be specified when `metadata_host` is specified.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ENVIRONMENT\", \"public\"),\n \t\t\t},\n \n+\t\t\t\"metadata_host\": {\n+\t\t\t\tType:        schema.TypeString,\n+\t\t\t\tRequired:    true,\n+\t\t\t\tDefaultFunc: schema.MultiEnvDefaultFunc([]string{\"ARM_METADATA_HOSTNAME\", \"ARM_METADATA_HOST\"}, \"\"), // TODO: remove support for `METADATA_HOST` in a future version\n+\t\t\t\tDescription: \"The Hostname which should be used for the Azure Metadata Service.\",\n+\t\t\t},\n+\n \t\t\t\"access_key\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The access key.\",\n+\t\t\t\tDescription: \"The access key to use when authenticating using a Storage Access Key.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ACCESS_KEY\", \"\"),\n \t\t\t},\n \n \t\t\t\"sas_token\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"A SAS Token used to interact with the Blob Storage Account.\",\n+\t\t\t\tDescription: \"The SAS Token to use when authenticating using a SAS Token.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SAS_TOKEN\", \"\"),\n \t\t\t},\n \n-\t\t\t\"snapshot\": {\n-\t\t\t\tType:        schema.TypeBool,\n-\t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"Enable/Disable automatic blob snapshotting\",\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SNAPSHOT\", false),\n-\t\t\t},\n-\n-\t\t\t\"resource_group_name\": {\n+\t\t\t\"tenant_id\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The resource group name.\",\n+\t\t\t\tDescription: \"The Tenant ID to use when authenticating using Azure Active Directory.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_TENANT_ID\", \"\"),\n \t\t\t},\n \n \t\t\t\"client_id\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The Client ID.\",\n+\t\t\t\tDescription: \"The Client ID to use when authenticating using Azure Active Directory.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_CLIENT_ID\", \"\"),\n \t\t\t},\n \n-\t\t\t\"endpoint\": {\n+\t\t\t\"client_id_file_path\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"A custom Endpoint used to access the Azure Resource Manager API's.\",\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ENDPOINT\", \"\"),\n+\t\t\t\tDescription: \"The path to a file containing the Client ID which should be used.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_CLIENT_ID_FILE_PATH\", nil),\n \t\t\t},\n \n-\t\t\t\"subscription_id\": {\n+\t\t\t\"endpoint\": {\n+\t\t\t\tType:       schema.TypeString,\n+\t\t\t\tOptional:   true,\n+\t\t\t\tDeprecated: \"`endpoint` is deprecated and no longer used, it will be removed in a future version of Terraform\",",
        "comment_created_at": "2025-01-20T02:02:54+00:00",
        "comment_author": "magodo",
        "comment_body": "This is marked as deprecated when I took over the PR from Tom B. I think the main reason is that this field is not used in the azurerm provider (probably is superseded by the `msi_endpoint`).",
        "pr_file_module": null
      },
      {
        "comment_id": "1932537283",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36258,
        "pr_file": "internal/backend/remote-state/azure/backend.go",
        "discussion_id": "1909143276",
        "commented_code": "@@ -24,157 +39,187 @@ func New() backend.Backend {\n \t\t\t\"container_name\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tRequired:    true,\n-\t\t\t\tDescription: \"The container name.\",\n+\t\t\t\tDescription: \"The container name to use in the Storage Account.\",\n \t\t\t},\n \n \t\t\t\"key\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tRequired:    true,\n-\t\t\t\tDescription: \"The blob key.\",\n+\t\t\t\tDescription: \"The blob key to use in the Storage Container.\",\n \t\t\t},\n \n-\t\t\t\"metadata_host\": {\n-\t\t\t\tType:        schema.TypeString,\n-\t\t\t\tRequired:    true,\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_METADATA_HOST\", \"\"),\n-\t\t\t\tDescription: \"The Metadata URL which will be used to obtain the Cloud Environment.\",\n+\t\t\t\"snapshot\": {\n+\t\t\t\tType:        schema.TypeBool,\n+\t\t\t\tOptional:    true,\n+\t\t\t\tDescription: \"Whether to enable automatic blob snapshotting.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SNAPSHOT\", false),\n \t\t\t},\n \n \t\t\t\"environment\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The Azure cloud environment.\",\n+\t\t\t\tDescription: \"The Cloud Environment which should be used. Possible values are public, usgovernment, and china. Defaults to public. Not used and should not be specified when `metadata_host` is specified.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ENVIRONMENT\", \"public\"),\n \t\t\t},\n \n+\t\t\t\"metadata_host\": {\n+\t\t\t\tType:        schema.TypeString,\n+\t\t\t\tRequired:    true,\n+\t\t\t\tDefaultFunc: schema.MultiEnvDefaultFunc([]string{\"ARM_METADATA_HOSTNAME\", \"ARM_METADATA_HOST\"}, \"\"), // TODO: remove support for `METADATA_HOST` in a future version\n+\t\t\t\tDescription: \"The Hostname which should be used for the Azure Metadata Service.\",\n+\t\t\t},\n+\n \t\t\t\"access_key\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The access key.\",\n+\t\t\t\tDescription: \"The access key to use when authenticating using a Storage Access Key.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ACCESS_KEY\", \"\"),\n \t\t\t},\n \n \t\t\t\"sas_token\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"A SAS Token used to interact with the Blob Storage Account.\",\n+\t\t\t\tDescription: \"The SAS Token to use when authenticating using a SAS Token.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SAS_TOKEN\", \"\"),\n \t\t\t},\n \n-\t\t\t\"snapshot\": {\n-\t\t\t\tType:        schema.TypeBool,\n-\t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"Enable/Disable automatic blob snapshotting\",\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SNAPSHOT\", false),\n-\t\t\t},\n-\n-\t\t\t\"resource_group_name\": {\n+\t\t\t\"tenant_id\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The resource group name.\",\n+\t\t\t\tDescription: \"The Tenant ID to use when authenticating using Azure Active Directory.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_TENANT_ID\", \"\"),\n \t\t\t},\n \n \t\t\t\"client_id\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The Client ID.\",\n+\t\t\t\tDescription: \"The Client ID to use when authenticating using Azure Active Directory.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_CLIENT_ID\", \"\"),\n \t\t\t},\n \n-\t\t\t\"endpoint\": {\n+\t\t\t\"client_id_file_path\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"A custom Endpoint used to access the Azure Resource Manager API's.\",\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ENDPOINT\", \"\"),\n+\t\t\t\tDescription: \"The path to a file containing the Client ID which should be used.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_CLIENT_ID_FILE_PATH\", nil),\n \t\t\t},\n \n-\t\t\t\"subscription_id\": {\n+\t\t\t\"endpoint\": {\n+\t\t\t\tType:       schema.TypeString,\n+\t\t\t\tOptional:   true,\n+\t\t\t\tDeprecated: \"`endpoint` is deprecated and no longer used, it will be removed in a future version of Terraform\",",
        "comment_created_at": "2025-01-28T16:56:48+00:00",
        "comment_author": "mbfrahry",
        "comment_body": "If we're going to use `msi_endpoint` over `endpoint` we should call that out in the deprecation message. Just saying something is deprecated without a clear alternative isn't a good user experience ",
        "pr_file_module": null
      },
      {
        "comment_id": "1933271937",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36258,
        "pr_file": "internal/backend/remote-state/azure/backend.go",
        "discussion_id": "1909143276",
        "commented_code": "@@ -24,157 +39,187 @@ func New() backend.Backend {\n \t\t\t\"container_name\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tRequired:    true,\n-\t\t\t\tDescription: \"The container name.\",\n+\t\t\t\tDescription: \"The container name to use in the Storage Account.\",\n \t\t\t},\n \n \t\t\t\"key\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tRequired:    true,\n-\t\t\t\tDescription: \"The blob key.\",\n+\t\t\t\tDescription: \"The blob key to use in the Storage Container.\",\n \t\t\t},\n \n-\t\t\t\"metadata_host\": {\n-\t\t\t\tType:        schema.TypeString,\n-\t\t\t\tRequired:    true,\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_METADATA_HOST\", \"\"),\n-\t\t\t\tDescription: \"The Metadata URL which will be used to obtain the Cloud Environment.\",\n+\t\t\t\"snapshot\": {\n+\t\t\t\tType:        schema.TypeBool,\n+\t\t\t\tOptional:    true,\n+\t\t\t\tDescription: \"Whether to enable automatic blob snapshotting.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SNAPSHOT\", false),\n \t\t\t},\n \n \t\t\t\"environment\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The Azure cloud environment.\",\n+\t\t\t\tDescription: \"The Cloud Environment which should be used. Possible values are public, usgovernment, and china. Defaults to public. Not used and should not be specified when `metadata_host` is specified.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ENVIRONMENT\", \"public\"),\n \t\t\t},\n \n+\t\t\t\"metadata_host\": {\n+\t\t\t\tType:        schema.TypeString,\n+\t\t\t\tRequired:    true,\n+\t\t\t\tDefaultFunc: schema.MultiEnvDefaultFunc([]string{\"ARM_METADATA_HOSTNAME\", \"ARM_METADATA_HOST\"}, \"\"), // TODO: remove support for `METADATA_HOST` in a future version\n+\t\t\t\tDescription: \"The Hostname which should be used for the Azure Metadata Service.\",\n+\t\t\t},\n+\n \t\t\t\"access_key\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The access key.\",\n+\t\t\t\tDescription: \"The access key to use when authenticating using a Storage Access Key.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ACCESS_KEY\", \"\"),\n \t\t\t},\n \n \t\t\t\"sas_token\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"A SAS Token used to interact with the Blob Storage Account.\",\n+\t\t\t\tDescription: \"The SAS Token to use when authenticating using a SAS Token.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SAS_TOKEN\", \"\"),\n \t\t\t},\n \n-\t\t\t\"snapshot\": {\n-\t\t\t\tType:        schema.TypeBool,\n-\t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"Enable/Disable automatic blob snapshotting\",\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_SNAPSHOT\", false),\n-\t\t\t},\n-\n-\t\t\t\"resource_group_name\": {\n+\t\t\t\"tenant_id\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The resource group name.\",\n+\t\t\t\tDescription: \"The Tenant ID to use when authenticating using Azure Active Directory.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_TENANT_ID\", \"\"),\n \t\t\t},\n \n \t\t\t\"client_id\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"The Client ID.\",\n+\t\t\t\tDescription: \"The Client ID to use when authenticating using Azure Active Directory.\",\n \t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_CLIENT_ID\", \"\"),\n \t\t\t},\n \n-\t\t\t\"endpoint\": {\n+\t\t\t\"client_id_file_path\": {\n \t\t\t\tType:        schema.TypeString,\n \t\t\t\tOptional:    true,\n-\t\t\t\tDescription: \"A custom Endpoint used to access the Azure Resource Manager API's.\",\n-\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_ENDPOINT\", \"\"),\n+\t\t\t\tDescription: \"The path to a file containing the Client ID which should be used.\",\n+\t\t\t\tDefaultFunc: schema.EnvDefaultFunc(\"ARM_CLIENT_ID_FILE_PATH\", nil),\n \t\t\t},\n \n-\t\t\t\"subscription_id\": {\n+\t\t\t\"endpoint\": {\n+\t\t\t\tType:       schema.TypeString,\n+\t\t\t\tOptional:   true,\n+\t\t\t\tDeprecated: \"`endpoint` is deprecated and no longer used, it will be removed in a future version of Terraform\",",
        "comment_created_at": "2025-01-29T05:09:44+00:00",
        "comment_author": "magodo",
        "comment_body": "Updated the comment, while I guess they are not 100% equivalent.. ",
        "pr_file_module": null
      }
    ]
  }
]