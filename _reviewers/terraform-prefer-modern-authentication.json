[
  {
    "discussion_id": "2069405020",
    "pr_number": 36935,
    "pr_file": "website/docs/language/block/resource.mdx",
    "created_at": "2025-04-30T20:37:08+00:00",
    "commented_code": "+---\n+page_title: resource block reference\n+description: >-\n+   Learn configure `resource` block arguments in Terraform configuration language.\n+---\n+\n+# `resource` block\n+\n+The `resource` block defines a piece of infrastructure and specifies the settings for Terraform to create it with. The arguments that an individual resource supports are determined by the provider. Refer to the provider documentation for more information about specific resource configuration.\n+\n+## Configuration model\n+\n+The `resource` block supports the following arguments:\n+\n+- [`resource \"<TYPE>\" \"<LABEL>\"`](#resource) &nbsp; block\n+   - [Provider-specific arguments](#provider-specific-arguments) &nbsp; block | refer to your provider documentation\n+   - [`count`](#count) &nbsp; number | mutually exclusive with `for_each`\n+   - [`depends_on`](#depends_on) &nbsp; list of references\n+   - [`for_each`](#for_each) &nbsp; map or set of strings | mutually exclusive with `count`\n+   - [`provider`](#provider) &nbsp; reference\n+   - [`lifecycle`](#lifecycle) &nbsp; block\n+      - [`create_before_destroy`](#create_before_destroy) &nbsp; boolean\n+      - [`prevent_destroy`](#prevent_destroy) &nbsp; boolean\n+      - [`ignore_changes`](#ignore_changes) &nbsp; list of attributes\n+      - [`replace_triggered_by`](#replace_triggered_by) &nbsp; list of references\n+      - [`precondition`](#precondition) &nbsp; block\n+        - [`condition`](#precondition) &nbsp; string\n+        - [`error_message`](#precondition) &nbsp; string\n+      - [`postcondition`](#postcondition) &nbsp; block\n+        - [`condition`](#postcondition) &nbsp; string\n+        - [`error_message`](#postcondition) &nbsp; string\n+   - [`connection`](#connection) &nbsp; block\n+        - [`type`](#connection-arguments) &nbsp; string\n+        - [`user`](#connection-arguments) &nbsp; string\n+        - [`password`](#connection-arguments) &nbsp; string\n+        - [`host`](#connection-arguments) &nbsp; string\n+        - [`port`](#connection-arguments) &nbsp; string\n+        - [`timeout`](#connection-arguments) &nbsp; string\n+        - [`script_path`](#connection-arguments) &nbsp; string\n+        - [`private_key`](#connection-arguments) &nbsp; string\n+        - [`certificate`](#connection-arguments) &nbsp; string\n+        - [`agent`](#connection-arguments) &nbsp; string\n+        - [`agent_identity`](#connection-arguments) &nbsp; string\n+        - [`host_key`](#connection-arguments) &nbsp; string\n+        - [`target_platform`](#connection-arguments) &nbsp; string\n+        - [`script_path`](#connection-arguments) &nbsp; string\n+        - [`https`](#connection-arguments) &nbsp; string\n+        - [`insecure`](#connection-arguments) &nbsp; string\n+        - [`use_ntlm`](#connection-arguments) &nbsp; string\n+        - [`cacert`](#connection-arguments) &nbsp; string\n+        - [`bastion_host`](#connection-arguments) &nbsp; string\n+        - [`bastion_host_key`](#connection-arguments) &nbsp; string\n+        - [`bastion_port`](#connection-arguments) &nbsp; string\n+        - [`bastion_user`](#connection-arguments) &nbsp; string\n+        - [`bastion_password`](#connection-arguments) &nbsp; string\n+        - [`bastion_private_key`](#connection-arguments) &nbsp; string\n+        - [`bastion_certificate`](#connection-arguments) &nbsp; string\n+        - [`proxy_scheme`](#connection-arguments) &nbsp; string\n+        - [`proxy_port`](#connection-arguments) &nbsp; string\n+        - [`proxy_user_name`](#connection-arguments) &nbsp; string\n+        - [`proxy_user_password`](#connection-arguments) &nbsp; string\n+   - [`provisioner \"<TYPE>\" \"<LABEL>\"`](#provisioner) &nbsp; block\n+      - [`source`](#source) &nbsp; string\n+      - [`destination`](#destination) &nbsp; string\n+      - [`content`](#content) &nbsp; string      \n+      - [`command`](#command) &nbsp; string\n+      - [`working_dir`](#working_dir) &nbsp; string\n+      - [`interpreter`](#interpreter) &nbsp; string\n+      - [`environment`](#command) &nbsp; string\n+      - [`when`](#when) &nbsp; keyword\n+      - [`quiet`](#quiet) &nbsp; boolean\n+      - [`inline`](#inline) &nbsp; list of strings\n+      - [`script`](#script) &nbsp; string\n+      - [`scripts`](#scripts) &nbsp; string\n+      - [`on_failure`](#on_failure) &nbsp; keyword\n+      - [`connection`](#connection) &nbsp; block\n+\n+## Complete configuration\n+\n+The following `resource` block defines all of the supported built-in arguments you can set on a resource:\n+\n+```hcl\n+resource \"<TYPE>\" \"<LABEL>\" {\n+  <PROVIDER_ARGUMENTS>\n+  count = <NUMBER>      # `for_each` and `count` are mutually exclusive \n+  depends_on = [ <RESOURCE.ADDRESS.EXPRESSION> ]\n+  for_each = {          # `for_each` and `count` are mutually exclusive \n+    <KEY> = <VALUE>\n+  }\n+  for_each = [\t     # `for_each` accepts a map or a set of strings \n+    \"<VALUE>\", \n+    \"<VALUE>\"\n+  ]\n+  provider = <REFERENCE.TO.ALIAS>\n+  lifecycle {\n+    create_before_destroy = <true || false>\n+    prevent_destroy = <true || false>\n+    ignore_changes = [ <ATTRIBUTE> ]\n+    replace_triggered_by = [ <RESOURCE.ADDRESS.EXPRESSION> ]\n+    precondition {\n+      condition = <EXPRESSION>\n+      error_message = \"<STRING>\"\n+    }\n+    postcondition {\n+      condition = <EXPRESSION>\n+      error_message = \"<STRING>\"\n+    }\n+  }\n+  connection {\n+    type = <\"ssh\" or \"winrm\">\n+    host = <EXPRESSION>\n+    <DEFAULT_CONNECTION_SETTINGS>\n+  }\n+  provisioner \"<TYPE>\" \"<LABEL>\" {\n+    source = \"<PATH>\"\n+    destination = \"<PATH>\"\n+    content = \"<CONTENT TO COPY TO `destination`>\"\n+    command = <COMMAND>\n+    working_dir = \"<PATH TO DIR WHERE TERRAFORM EXECUTES `command`>\"\n+    interpreter = [\n+      \"<PATH TO INTERPRETER EXECUTABLE>\",\n+      \"<COMMAND> <ARGUMENTS>\"\n+    ]\n+    environment {\n+      \"<KEY>\" = \"<VALUE>\"\n+    }\n+    when = <TERRAFORM COMMAND>\n+    quiet = <true || false>\n+    inline = [ \"<COMMAND>\" ]\n+    script = \"<PATH>\"\n+    scripts = [\n+      \"<PATH>\"\n+    ]\n+    on_failure = <continue || fail>\n+    connection {\n+      type = <\"ssh\" or \"winrm\">\n+      host = <EXPRESSION>\n+      <SPECIFIC_CONNECTION_SETTINGS>\n+    }\n+  }\n+}\n+```\n+\n+## Specification\n+\n+A `resource` block supports the following configuration. \n+\n+### `resource \"<TYPE>\" \"<LABEL>\"`\n+\n+You must set the following arguments for every `resource` block: \n+\n+- `TYPE`: Specifies the type of resource. This value is determined by the provider developer. Refer to provider documentation for details. The `terraform_data` resource type, which you can use to store values and trigger Terraform operations without creating actual infrastructure, is the exception. \n+- `LABEL`: Specifies a name for the resource. Terraform uses this label to track the resource in your state file. To reference the resource in your configuration, you must refer to it using `<TYPE>.<LABEL>` syntax. The label does not affect settings on the actual infrastructure resource. Refer to [References to Named Values](/terraform/language/expressions/references) and [Resource naming](/terraform/language/style#resource-naming) for expression syntax and label recommendations.\n+\n+### Provider-specific arguments\n+\n+The provider developer determines which arguments you can define for a resource. Refer to the provider documentation for details.  \n+\n+### `count`\n+\n+The `count` meta-argument instructs Terraform to provision multiple instances of the same resource with identical or similar configuration. \n+\n+```hcl\n+resource {\n+  count = <number>\n+}\n+```\n+\n+The value must be a whole number. You can reference variables or local values and use expressions to compute the value, but the value must resolve to a whole number. \n+\n+In blocks where `count` is set, Terraform exposes an additional `count` object. You can reference the object to modify the configuration of each instance. The `count` object has an `index` attribute starting from `0`. \n+\n+To refer to an individual instance of a resource created using the `count` meta-argument, use the `<TYPE>.<NAME>[INDEX]` syntax. For example, `aws_instance.server[0]` refers to the first instance of the `aws_instance` resource named `server`. \n+\n+<Tip>\n+\n+You can use the `count` argument as a conditional for creating resources. For example, setting a `count = var.creator ? 3 : 0` instructs Terraform to create three instances of the resource when a variable named `creator` is set to `true`. Refer to [​​Conditional Expressions](/terraform/language/expressions/conditionals) for additional information.\n+\n+</Tip>\n+\n+The `count` argument is a meta-argument, which is built into Terraform and controls the way that Terraform creates resources. Refer to [Meta-arguments](/terraform/language/meta-arguments) for additional information.\n+\n+#### Summary\n+\n+- Data type: Number. \n+- Default: None.  \n+- Example: [Create multiple instances of a resource](#create-multiple-instances-of-a-resource).\n+\n+### `depends_on`\n+\n+The `depends_on` meta-argument specifies an upstream resource that the resource depends on. Terraform must complete all operations on the upstream resource before performing operations on the resource containing the `depends_on` argument.\n+\n+```hcl\n+resource {\n+  depends_on = [ <resource reference> ]\n+}\n+```\n+\n+When a resource configuration refers to another resource, Terraform identifies the dependency and creates the upstream resource first. In some cases, you may need Terraform to create a resource before creating another, even though the resources are configured independently. \n+\n+Use the `depends_on` argument when Terraform cannot infer a dependency automatically. We recommend always including a comment to explain resource dependencies when using a `depends_on` argument.\n+\n+When using the `depends_on` meta-argument, you can only reference other resources or child modules in the same root module. The list cannot include arbitrary expressions. Any values referenced in the `depends_on` list must be known before Terraform begins the operation so that it can evaluate dependencies.\n+\n+Specifying an entire module in the `depends_on` argument affects the order in which Terraform provisions all of the resources and data sources associated with that module. Refer to [Resource dependencies](/terraform/language/manage-resources#resource-dependencies) <!-- placeholder link -->\n+and [Data resource dependencies](/terraform/language/configure-data-sources#data-resource-dependencies) for additional information.\n+\n+The `depends_on` argument is a meta-argument, which is built into Terraform and controls the way that Terraform creates resources. Refer to [Meta-arguments](/terraform/language/concepts/meta-arguments) for additional information.\n+\n+#### Summary\n+\n+- Data type: List.\n+- Default: None.  \n+- Example: [Specify a dependency](#specify-a-dependency). \n+\n+### `for_each`\n+\n+The `for_each` meta-argument instructs Terraform to provision similar resources without requiring separate configuration blocks for each resource. \n+\n+<Tabs>\n+\n+<Tab heading=\"List of values\">\n+\n+```hcl\n+resource {\n+  for_each = [ \"<VALUE>\" ] \n+  # . . .\n+}\n+```\n+\n+</Tab>\n+\n+<Tab heading=\"Map of key-value pairs\">\n+\n+```hcl\n+resource {\n+  for_each = {\n+    \"<KEY>\" = \"<VALUE>\"\n+  }\n+}\n+```\n+\n+</Tab>\n+\n+</Tabs>\n+\n+The `for_each` meta-argument accepts a map or a set of strings and creates an instance for each item in that map or set. Each instance is associated with a distinct infrastructure object. Terraform creates, updates, or destroys each instance when applying changes to the configuration.\n+\n+You can use pure functions, such as `toset()` and `tomap()`, to create a map or set for use in the `for_each` argument. Whether iterating over the keys of a map or set of strings, all must be known values. Otherwise, Terraform prints an error message that `for_each` has dependencies that it cannot determine before applying the configuration.\n+\n+Keys in the `for_each` argument cannot be the result of or rely on the result of impure functions, including `uuid`, `bcrypt`, or `timestamp`, because Terraform defers evaluating impure functions during the main evaluation step.\n+\n+The `for_each` argument does not implicitly convert lists or tuples to sets. To declare resource instances based on a nested data structure or combinations of elements from multiple data structures, you can use Terraform expressions and functions to derive a suitable value. Refer to the following examples for additional information:\n+\n+- [Transform a multi-level nested structure into a flat list](/terraform/language/functions/flatten#flattening-nested-structures-for-for_each)\n+- [Combine collections to produce a list of element combinations](/terraform/language/functions/setproduct#finding-combinations-for-for_each).\n+\n+You cannot use sensitive values, such as [sensitive input variables](/terraform/language/values/variables#suppressing-values-in-cli-output), [sensitive outputs](/terraform/language/values/outputs#sensitive-suppressing-values-in-cli-output), or [sensitive resource attributes](/terraform/language/expressions/references#sensitive-resource-attributes), as arguments in `for_each`. Terraform uses the value in `for_each` to identify the resource instance and always discloses it in UI output, so sensitive values are not allowed. Terraform returns an error if you attempt to use sensitive values as `for_each` arguments.\n+\n+If you transform a value containing sensitive data into an argument for use in `for_each`, be aware that most functions in Terraform will return a sensitive result if given an argument with any sensitive content. In many cases, you can achieve similar results with a `for` expression. For example, to call `keys(local.map)` where `local.map` is an object with sensitive values, but non-sensitive keys, you can create a value to pass to `for_each` using `toset([for k,v in local.map : k])`.\n+\n+Refer to [Sensitive Data in State](/terraform/language/state/sensitive-data) for additional information. \n+\n+The `for_each` argument exposes an `each` object that you can reference within the same block to modify specific instances of the resource. The object has the following attributes:\n+\n+- `each.key`: Map key or list member that corresponds to an instance.\n+- `each.value`: Map value that corresponds to an instance. \n+\n+Use the `<TYPE>.<NAME>[<KEY>]` syntax to access an instance of a resource created using `for_each`. For example, `azurerm_resource_group.rg[\"a_group\"]` refers to an instance of the `azurrm_resource_group` resource named `rg` created off of the `a_group` key.\n+\n+The `for_each` argument is a meta-argument, which is built into Terraform and controls the way that Terraform creates resources. Refer to [Meta-arguments](/terraform/language/meta-arguments) for additional information.\n+\n+#### Summary\n+\n+- Data type: Map or set of strings.\n+- Default: None.  \n+- Example: [Create multiple instances of a resource](#create-multiple-instances-of-a-resource). \n+\n+### `provider`\n+\n+The `provider` argument instructs Terraform to use an alternate provider configuration to provision the resource. \n+\n+```hcl\n+resource {\n+  provider = <provider>.<alias>\n+}\n+```\n+\n+By default, Terraform automatically selects a provider based on the resource type, but you can create multiple provider configurations and use a non-default configuration for specific resources. \n+\n+Use the `<PROVIDER>.<ALIAS>` syntax to reference a provider configuration in the `provider` argument. Refer to [Multiple Provider Configurations](/terraform/language/providers/configuration#alias-multiple-provider-configurations) for instructions on how to reference a specific provider configuration.     \n+\n+The `provider` argument is a meta-argument, which is built into Terraform and controls the way that Terraform creates resources. Refer to [Meta-arguments](/terraform/language/concepts/meta-arguments) for additional information.\n+\n+#### Summary\n+\n+- Data type: Reference.\n+- Default: None. \n+- Example: [Select an alternate provider configuration](#select-an-alternate-provider-configuration).\n+\n+### `lifecycle`\n+\n+The `lifecycle` block defines lifecycle rules that instruct Terraform when and how to operate on your resource. \n+\n+```hcl\n+resource {\n+  lifecycle { \n+    <lifecycle>\n+  }\n+}\n+```\n+\n+You can specify the following lifecycle rules to manage how Terraform performs operations on the resource:\n+\n+- [`create_before_destroy`](#create_before_destroy): Terraform creates a replacement resource before destroying the previous resource.\n+- [`prevent_destroy`](#prevent_destroy): Terraform rejects operations to destroy the resource and returns an error.\n+- [`ignore_changes`](#ignore_changes):  Specifies a list of resource attributes that, when modified outside of your configuration, Terraform ignores instead of attempting to update the actual resource to match the configuration.  \n+- [`replace_triggered_by`](#replace-triggered_by): Terraform replaces the resource when any of the referenced resources or attributes specified change.\n+- [`precondition`](#precondition): Specifies a condition that Terraform evaluates before creating the resource. Refer to [Test and validate](/terraform/language/test-and-validate) for additional information.\n+- [`postcondition`](#postcondition): Specifies a condition that Terraform evaluates after creating the resource. Refer to [Test and validate](/terraform/language/test-and-validate) for additional information.\n+\n+Configurations defined in the `lifecycle` block affect how Terraform constructs and traverses the dependency graph. You can only use literal values in the lifecycle block because Terraform processes them before it evaluates arbitrary expressions for a run.\n+\n+The `lifecycle` block is a meta-argument. Meta-arguments are built-in arguments that control how Terraform creates resources. Refer to [Meta-arguments](/terraform/language/concepts/meta-arguments) for additional information.  \n+\n+#### Summary\n+\n+- Data type: Block.\n+- Default: None \n+\n+### `create_before_destroy`\n+\n+The `create_before_destroy` argument instructs Terraform to create a replacement resource before destroying the resource it replaces. \n+\n+```hcl\n+resource {\n+  lifecycle { \n+    create_before_destroy = <boolean>\n+  }\n+}\n+```\n+\n+By default, Terraform destroys a resource before creating a replacement. \n+\n+Refer to the documentation for the resource type you are configuring to understand which changes Terraform can make in-place and which require recreating the resource to decide whether to use the `create_before_destroy` argument. \n+\n+Terraform propagates and applies the `create_before_destroy` behavior to all upstream resources. For example, if `create_before_destroy` is enabled on resource A but not on resource B, but resource A is dependent on resource B, then Terraform enables `create_before_destroy` for resource B implicitly and records it in the state file. You cannot override `create_before_destroy` to `false` on resource B because that would imply dependency cycles in the graph.\n+\n+Setting`create_before_destroy` to `true` on a resource stops any configured destroy provisioners. \n+\n+#### Summary\n+\n+- Data type: Boolean\n+- Default: None. \n+\n+### `prevent_destroy`\n+\n+The `prevent_destroy` argument instructs Terraform to reject plans to destroy the resource.\n+\n+```hcl\n+resource {\n+  lifecycle { \n+    prevent_destroy = <boolean>\n+  }\n+}\n+```\n+\n+Use this argument to prevent team members from accidentally replacing critical infrastructure, such as database instances.\n+\n+When the `prevent_destroy` argument is set, you must either remove the resource from the configuration or change the `prevent_destroy` argument to `false` to destroy it. Use this argument with caution. The `prevent_destroy` argument can make applying resource changes or destroying resources more complex. \n+\n+#### Summary\n+\n+- Data type: Boolean.\n+- Default: None.  \n+\n+### `ignore_changes`\n+\n+The `ignore_changes` argument specifies a list of resource attributes for Terraform to ignore when planning updates to the resource. \n+\n+```hcl\n+resource {\n+  lifecycle { \n+    ignore_changes = [ <attribute> ]\n+  }\n+}\n+```\n+\n+Use this argument when the resource references data that may change but does not affect the resource after its creation. \n+\n+By default, Terraform detects any difference in the current settings of a real infrastructure object and plans to update the remote object to match the configuration.\n+\n+Terraform uses the specified arguments to create a resource, but ignores them when planning an `update` operation. You can specify arguments as the relative attribute addresses in the resource and reference members of maps and lists using index notation, such as `tags[\"Name\"]` and `list[0]`. \n+\n+You can also specify `all` instead of a list to ignore future changes to all resource attributes. This lets Terraform create and destroy the resource but it does not propose updates to it. \n+\n+#### Summary\n+\n+- Data type: List.\n+- Default: None. \n+- Example: [Ignore attribute changes](#ignore-attribute-changes).\n+\n+### `replace_triggered_by`\n+\n+The `replace_triggered_by` argument instructs Terraform to replace the resource when any of the referenced items change.\n+\n+```hcl\n+resource {\n+  lifecycle { \n+    replace_triggered_by = [ <address.reference> ]\n+  }\n+}\n+```\n+\n+You can specify a list of expressions that reference managed resources, instances, or instance attributes. You can only reference managed resources in `replace_triggered_by` expressions. This lets you modify these expressions without forcing replacement.\n+\n+The trigger is based on the planned actions for all of the given resources. Terraform does not plan actions for plain values, such as local values or input variables, but you can use the `terraform_data` resource type to apply a resource-like lifecycle to them.\n+\n+References in the argument list trigger a replacement under following conditions:\n+\n+- When referencing a resource with multiple instances, such as those created by `count` or `for_each`, a `terraform plan` command to update or replace any instance triggers replacement.\n+- When referencing a single resource instance, a `terraform plan` command to update or replace that instance triggers replacement.\n+- When referencing a single attribute of a resource instance, any change to the attribute value triggers replacement.\n+\n+Adding the `replace_triggered_by` argument to a resource that uses `count` or `for_each` lets you add the `count.index` or `each.key` resource address to the expression. Use this address segment to reference specific instances of other resources that are configured with the same `count` or collection.\n+\n+#### Summary\n+\n+- Data type: List \n+- Default: None.\n+- Example: [Specify triggers that replace resources](#specify-triggers-that-replace-resources)  \n+\n+### `precondition`\n+\n+The `precondition` block specifies a condition that must return `true` before Terraform evaluates and performs operations on the resource. You can also specify an error message for Terraform to print when the condition returns `false`. \n+\n+```hcl\n+resource {\n+  lifecycle { \n+    precondition {\n+      condition = <expression>\n+      error_message = \"<message>\"\n+    }\n+  }\n+}\n+```\n+\n+The following arguments in the `precondition` block are required:\n+\n+| Argument | Description | Data type |\n+| --- | --- | --- |\n+| `condition` | Expression that must return `true` for Terraform to proceed with an operation. You can refer to any other object in the same configuration scope unless the reference creates a cyclic dependency. | Expression that can include references, strings, and operators. |\n+| `error_message` | Message that Terraform prints to the console if the `condition` returns `false`. | String |\n+\n+Terraform evaluates `precondition` blocks before evaluating the resource's configuration arguments. The `precondition` can take precedence over argument evaluation errors.\n+\n+Terraform evaluates precondition blocks after evaluating `count` and `for_each` meta-arguments. As a result, Terraform can evaluate the `precondition` separately for each instance and makes the `each.key` and `count.index` objects available in the conditions. \n+\n+You can include a `precondition` and [`postcondition` block](#postcondition) in the same resource. Do not add `precondition` blocks to a `resource` block and a `data` block that represent the same object in the same configuration. Doing so can prevent Terraform from understanding that the data block result can be affected by changes in the resource block. \n+\n+Refer to [Test and validate](/terraform/language/test-and-validate) for information about adding validations to your Terraform configuration.\n+\n+#### Summary\n+\n+- Data type: Block.\n+- Default: None.\n+- Example: [Apply custom conditions](#apply-custom-conditions)\n+\n+### `postcondition`\n+\n+The `postcondition` block specifies a condition that must return `true` after Terraform performs operations on the resource. You can also specify an error message for Terraform to print to the console when the condition returns `false`. \n+\n+```hcl\n+resource {\n+  lifecycle { \n+    postcondition {\n+      condition = <expression>\n+      error_message = \"<message>\"\n+    }\n+  }\n+}\n+```\n+\n+The following arguments in the `precondition` block are required:\n+\n+| Argument | Description | Data type |\n+| --- | --- | --- |\n+| `condition` | Expression that must return `true` for Terraform to perform operations on downstream resources. You can refer to any other object in the same configuration scope unless the reference creates a cyclic dependency. | Expression that can include references, strings, and operators. |\n+| `error_message` | Message that Terraform prints to the console if the `condition` returns `false`. | String |\n+\n+Refer to [Test and validate](/terraform/language/test-and-validate) for information about adding validations to your Terraform configuration.\n+\n+Terraform evaluates `postcondition` blocks after planning and applying changes to the resource. Postcondition failures prevent changes to other resources that depend on the failing resource.\n+\n+You can include a `postcondition` and [`precondition` block](#precondition) in the same resource. Do not add `postcondition` blocks to a `resource` block and a `data` block that represent the same object in the same configuration. Doing so can prevent Terraform from understanding that the data block result can be affected by changes in the resource block. \n+\n+#### Summary\n+\n+- Data type: Block.\n+- Default: None.\n+- Example: [Apply custom conditions](#apply-custom-conditions)\n+\n+### `connection`\n+\n+The `connection` block specifies settings that let provisioners connect to resources so that Terraform can perform operations on the resource after creating it.\n+\n+<Warning>\n+\n+We recommend using configuration management tools or other means to perform actions on the local or remote machine instead of using provisioners. Refer to [Perform post-apply action](#)<!--TODO: updated with real link when ready--> for additional information.\n+\n+</Warning>\n+\n+You can add the `connection` block to either the [`resource`](#resource) block or the [`provisioner`](#provisioner) block. When added to the `resource` block, the `connection` block sets default connection settings for all provisioners defined in the resource so that provisioners can connect to the remote resource after Terraform provisions it. \n+\n+```hcl\n+resource {\n+  # . . .\n+  connection {\n+    <settings for all provisioners in the resource>\n+  }\n+}\n+```\n+\n+When added to a `provisioner` block, the `connection` block defines settings specific to the provisioner.\n+\n+```hcl\n+resource {\n+  # . . .\n+  provisioner {\n+    # . . .\n+    connection {\n+      <settings for all provisioners in the resource>\n+    }\n+  }\n+}\n+```\n+\n+Terraform does not validate SSH host keys by default. You can establish a separate mechanism for key distribution and explicitly set the `host_key` argument to verify against a specific key or signing CA.\n+\n+You can use ephemeral values for arguments in the `connection` block. Refer [Ephemerality in resources](/terraform/language/resources/ephemeral) for additional information.\n+\n+Expressions in `connection` blocks cannot refer to their parent resource by name. References create dependencies, and referring to a resource by name within its own block would create a dependency cycle. Instead, use the `self` object in expressions to refer to the `connection` block's parent block, including all of its attributes. For example, use `self.public_ip` to reference the `public_ip` attribute in an `aws_instance`. \n+\n+<span id=\"connection-arguments\"/>\n+\n+<Tip>\n+\n+You can provide multiple connections so that an initial provisioner can connect as the root user to set up user accounts and subsequent provisioners can connect as less-privileged users to perform more specific operations.\n+\n+</Tip>\n+\n+The following table describes the arguments you can use in the `connection` block:\n+\n+| Argument | Description | Data type | Connection | Default |\n+|---------------|--------------|-------------|---------| --- | \n+| `type` | Specifies the type of connection for sending and receiving data from the remote resource. You can specify `ssh` or `winrm`. When set to `winrm`, provisioners implement Windows-specific behaviors, even when `target_platform` is set to `unix`, unless otherwise specified.| string |  | `ssh` |\n+| `user` | Specifies the user to use for the connection. | string | `ssh`<p>`winrm`</p> | <p>`root` when `type` is `ssh`</p><p>`Administrator` when `type` is `winrm`</p> | \n+| `password` | Specifies the password to use for the connection. | string | `ssh`<p>`winrm`</p> | none |\n+| `host` | Specifies the address of the resource to connect to. <p>This argument is required.</p> | string | `ssh`<p>`winrm`</p> | none |\n+| `port` | Specifies the port number to connect to. | number | `ssh`<p>`winrm`</p> | <p>`22` when `type` is `ssh`</p><p>`5985` when `type` is `winrm`</p> |\n+| `timeout` | Specifies how long to wait for the connection to become available. | string | `ssh`<p>`winrm`</p> | `\"5m\"` |\n+| `script_path` | Specifies the path on the remote resource where Terraform copies scripts to. Refer to the [`provisioner` block reference](#provisioner) for additional information. Terraform copies scripts to a path that contains random numbers depending on the `target_platform` configuration. | string | `ssh`<p>`winrm`</p> | <p>`/tmp/terraform_%RAND%.sh` when `target_platform` is `unix`</p><p>`C:/windows/temp/`<br/>`terraform_%RAND%.cmd` when `target_platform` is `windows`</p> |\n+| `private_key` | Specifies the contents of an SSH key to use for the connection. `private_key` takes precedence over `password` when both are provided. | <p>string</p><p>Use a [`file` function](/terraform/language/functions/file) to load keys from file.</p> | `ssh` | none |\n+| `certificate` | Specifies the contents of a signed CA certificate. You must also configure a  `private_key` arugment. | <p>string</p><p>Use a [`file` function](/terraform/language/functions/file) to load certificates from file.</p> | `ssh` | none |\n+| `agent` | Specifies an SSH agent for authentication. Set to `false` to disable using `ssh-agent` to authenticate. On Windows, the only supported SSH authentication agent is [Pageant](http://the.earth.li/\\~sgtatham/putty/0.66/htmldoc/Chapter9.html#pageant). | string | `ssh` | `false` |\n+| `agent_identity` | Specifies the preferred identity from the SSH agent to use for authentication. | string | `ssh` | none |\n+| `host_key` | Specifies the public key from the remote host or the signing CA to verify the connection. | string | `ssh` | none |\n+| `target_platform` | Specifies the target platform, which affects the default value for the `script_path` argument. You can specify either `windows` or `unix`. <p>`windows` sets the default `script_path` to `c:\\windows\\temp\\terraform_%RAND%.cmd` if the default SSH shell on the remote resource is `cmd.exe`. Refer to the [Windows documentation](https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_server_configuration#configuring-the-default-shell-for-openssh-in-windows) for additional information. If the SSH default shell is PowerShell, set `script_path` to `\"c:/windows/temp/terraform_%RAND%.ps1\"`.</p><p>`unix` sets the default `script_path` to `/tmp/terraform_%RAND%.sh`. </p> | string | `ssh` |`unix` |\n+| `https` | Set to `true` to connect using HTTPS instead of HTTP. | boolean | `winrm` | `false` |\n+| `insecure` | Set to `true` to skip validating the HTTPS certificate chain. | boolean | `winrm` | `false` |\n+| `use_ntlm` | Set to `true` to use NTLM authentication instead of basic authentication. Using NTLM removes the requirement for basic authentication to be enabled within the target guest. Refer to [Authentication for Remote Connections](https://docs.microsoft.com/en-us/windows/win32/winrm/authentication-for-remote-connections) in the Windows App Development documentation for more details. | boolean | `winrm` | `false` |\n+| `cacert` | Specifies the CA certificate to validate against. | string | `winrm` | none |\n+| `bastion_host` | Specifies the address of the bastion host. The provisioner connects to `bastion_host` before connecting to `host`. | string | `ssh` | none |\n+| `bastion_host_key` | Specifies the public key from the remote host or the signing CA to verify the host connection. | string | `ssh` | none |\n+| `bastion_port` | Specifies the port number to use for the bastion host connection. | string | `ssh` | value of the `port` field|\n+| `bastion_user`| Specifies the user name for connecting to the bastion host. | string | `ssh` | value of the `user` field |\n+| `bastion_password` | Specifies the user password for connecting to the bastion host. | string | `ssh` | value of the `password` field |\n+| `bastion_private_key` | Specifies the contents of an SSH key file to use for the bastion host. | <p>string</p><p>Use a [`file` function](/terraform/language/functions/file) to load keys from file.</p> | `ssh` | value of the `private_key` field |\n+| `bastion_certificate` |  Specifies the contents of a signed CA certificate. You must also configure the `bastion_private_key` argument when providing the certificate for the bastion host. | <p>string</p><p>Use a [`file` function](/terraform/language/functions/file) to load certificates from file.</p> | `ssh` | value of the `certificate` field |\n+| `proxy_scheme` | Specifies the connection protocol. You can specify one of the following values: <li>`http`</li><li>`https`</li><li> `socks5`</li> | string | `ssh` | none |\n+| `proxy_host` | Specifies the address of the proxy host. The provisioner connects to the proxy host first. When `bastion_host` is configured, the provisioner connects to the bastion host next, otherwise the provisioner connects to the host specified in the `host` argument.  | string | `ssh` | none |\n+| `proxy_port` | Specifies the port number to use for the proxy host connection. | number | `ssh` | none |\n+| `proxy_user_name` | Specifies the user name for connecting to the proxy host. You should only configure this argument when the proxy server requires authentication. | string | `ssh` | none |\n+| `proxy_user_password` | Specifies the user password for connecting to the proxy host. You should only configure this argument when the proxy server requires authentication. | string | `ssh` | none |\n+\n+#### Summary\n+\n+- Data type: Block.\n+- Default: None.\n+- Example: [Connect to remote resources](#connect-to-remote-resources)\n+\n+### `provisioner`\n+\n+The `provisioner` block defines actions to perform on the local machine or created resource, such as preparing servers or other infrastructure objects for service. \n+\n+```hcl\n+resource {\n+  provisioner \"<TYPE>\" \"<LABEL>\" {\n+    <arguments> \n+  }\n+}\n+```\n+\n+<Warning>\n+\n+We recommend using configuration management tools or other means to perform actions on the local or remote machine instead of using the `provisioner` block. Refer to [Perform post-apply action](#)<!--TODO: updated with real link when ready--> for additional information.\n+\n+</Warning>\n+\n+The `provisioner` block supports the following arguments:\n+\n+- `TYPE`: Specifies the type of provisioner to use. You must specify one of the following types:   \n+  - `file`: Copies files or directories from the machine where Terraform is running to the new resource. When the file provisioner communicates with a Windows system over SSH, you must configure OpenSSH to run the commands with `cmd.exe` and not PowerShell. PowerShell causes file parsing errors because it is incompatible with both Unix shells and the Windows command interpreter.\n+  - `local-exec`: Invokes an executable on the local machine after Terraform creates the resource.\n+  - `remote-exec`: Invokes an executable on the remote resource after Terraform creates the resource.  \n+- `LABEL`: Optional attribute for adding a unique name. Refer to [Resource naming](/terraform/language/style#resource-naming) for label recommendations.\n+\n+The type of provisioner determines which arguments you can add to the block. All types can use the [`connection`](#connection) argument. The following table lists each type's supported arguments:\n+\n+| Provisioner type | Arguments |\n+| --- | --- |\n+| `file` | <li>[`source`](#source)</li><li>[`content`](#content)</li><li>[`destination`](#destination)</li> |\n+| `local-exec` | <li>[`command`](#command)</li><li>[`working_dir`](#working_dir)</li><li>[`interpreter`](#interpreter)</li><li>[`environment`](#command)</li><li>[`when`](#when)</li><li>[`quiet`](#quiet)</li> |\n+| `remote-exec` | <li>[`inline`](#inline)</li><li>[`script`](#script)</li><li>[`scripts`](#scripts)</li> |\n+| All types | <li>[`connection`](#connection)</li> <li>[`on_failure`](#on_failure)</li> |\n+\n+#### Summary\n+\n+- Data type: Block.\n+- Default: None.\n+\n+### `source`\n+\n+The `source` specifies the location of a file or directory to copy to the location specified in the [`destination`](#destination) argument. \n+\n+```hcl\n+resource {\n+  provisioner \"file\" \"<LABEL>\" {\n+    source = \"<path>\"\n+  }\n+}\n+```\n+\n+\n+You can specify a string value that contains an expression. You can't use the `source` argument and the [`content`](#content) argument in the same `provisioner \"file\"` block. \n+\n+When the `source` argument specifies a directory and the `type` argument in the [provisioner connection settings](#connection) is set to `ssh`, the corresponding directory specified in the `destination` argument must already exist. You can add a `provisioner \"remote-exec\"` block to your `resource` configuration to create the directory. If the directory does not already exist, Terraform creates it when the `type` argument in the [provisioner connection settings](#connection) is set to `winrm`.\n+\n+Adding a trailing slash to the `source` argument path instructs Terraform to copy the contents of the directory to the `destination` directory. For example, when `source = \"/foo/\"` and `destination = \"/temp\"`, Terraform uploads the contents of `/foo` directory into `/tmp`. \n+\n+Without a trailing slash, Terraform creates the directory under the directory specified in the `destination`. For example, when `source = \"/foo\"` and `destination = \"/temp\"`, Terraform uploads the `/foo` directory to `/tmp/foo`. \n+\n+#### Summary\n+\n+- Data type: String.\n+- Default: None.\n+- Example: [Copy content to new resources](#copy-content-to-new-resources).\n+\n+### `content`\n+\n+The `content` argument specifies content to write directly to the location specified in the [`destination`](#destination) argument. \n+\n+```hcl\n+resource {\n+  provisioner \"file\" \"<LABEL>\" {\n+    content = \"<content>\"\n+  }\n+}\n+```\n+\n+\n+When `destination` points to a file, Terraform writes the value of the `content` argument to the file. When `destination` points to a directory, Terraform creates a file named `tf-file-content` inside the directory. We recommend setting the `destination` argument to a file when using `content` argument. Do not use the `content` argument and the [`source`](#source) argument in the same `provisioner \"file\"` block. \n+\n+You can specify a string value that contains an expression. You can't use the `source` argument and the [`content`](#content) argument in the same `provisioner \"file\"` block. \n+\n+#### Summary\n+\n+- Data type: String.\n+- Default: None.\n+- Example: [Copy content to new resources](#copy-content-to-new-resources).\n+\n+### `destination`\n+\n+The `destination` argument specifies a path on the remote resource that Terraform copies content to. You can use either [`source`](#source) or [`content`](#content) argument to provide content to the `destination` path. \n+\n+```hcl\n+resource {\n+  provisioner \"file\" \"<LABEL>\" {\n+    destination = \"<path>\"\n+  }\n+}\n+```\n+\n+\n+The remote system, not Terraform, evaluates the path you provide in the `destination` argument. As a result, valid values can vary depending on the operating system and remote access software running on the target.\n+\n+When the `type` argument in the [provisioner connection settings](#connection) is set to `ssh`, the provisioner passes the destination path as-is to the `scp` program on the remote host. By default, the OpenSSH `scp` implementation runs in the remote user's home directory. As a result, you can specify a relative path to upload into the home directory or an absolute path to upload to a different location. \n+\n+The remote `scp` process runs with the access level of the user specified in the [provisioner connection settings](#connection), so permissions may prevent Terraform from writing directly to locations outside of the home directory.\n+\n+When the `type` argument in the [provisioner connection settings](#connection) is set to `winrm`, Terraform uses PowerShell to interpret the `destination` path. As a result, you must not use meta-characters that PowerShell might interpret. You should specifically avoid including untrusted external input in your `destination` argument because doing so can let arbitrary PowerShell code execute on the remote system. \n+\n+Terraform performs the following process over WinRM connections:\n+\n+1. Generates a temporary filename in the directory set in the remote system's `TEMP` environment variable. \n+1. Generates a sequence of `echo` commands to gradually append base64-encoded chunks of the source file to the temporary file.\n+1. Uses an uploaded PowerShell script to read the temporary file, base64-decode, and write the raw result into the destination file.\n+\n+Modern Windows systems support running an OpenSSH server, so we strongly recommend choosing SSH over WinRM.\n+\n+#### Summary\n+\n+- Data type: String.\n+- Default: None.\n+- Example: [Copy content to new resources](#copy-content-to-new-resources).\n+\n+### `command`\n+\n+The `command` argument specifies a command for a local executable to run. You can specify an absolute path or a relative path to the current working directory. \n+```hcl\n+resource {\n+  provisioner \"local-exec\" \"<LABEL>\" {\n+    command = \"<path>\"\n+  }\n+}\n+```\n+\n+Terraform evaluates the command in a local shell and can use environment variables for variable substitution. We do not recommend using Terraform variables for variable substitution because doing so can lead to shell injection vulnerabilities. Instead, you should pass Terraform variables to a command through the environment parameter and use environment variable substitution. Refer to the following OWASP article for additional information about injection flaws: [Code Injection](https://owasp.org/www-community/attacks/Code_Injection).",
    "repo_full_name": "hashicorp/terraform",
    "discussion_comments": [
      {
        "comment_id": "2069405020",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36935,
        "pr_file": "website/docs/language/block/resource.mdx",
        "discussion_id": "2069405020",
        "commented_code": "@@ -0,0 +1,1217 @@\n+---\n+page_title: resource block reference\n+description: >-\n+   Learn configure `resource` block arguments in Terraform configuration language.\n+---\n+\n+# `resource` block\n+\n+The `resource` block defines a piece of infrastructure and specifies the settings for Terraform to create it with. The arguments that an individual resource supports are determined by the provider. Refer to the provider documentation for more information about specific resource configuration.\n+\n+## Configuration model\n+\n+The `resource` block supports the following arguments:\n+\n+- [`resource \"<TYPE>\" \"<LABEL>\"`](#resource) &nbsp; block\n+   - [Provider-specific arguments](#provider-specific-arguments) &nbsp; block | refer to your provider documentation\n+   - [`count`](#count) &nbsp; number | mutually exclusive with `for_each`\n+   - [`depends_on`](#depends_on) &nbsp; list of references\n+   - [`for_each`](#for_each) &nbsp; map or set of strings | mutually exclusive with `count`\n+   - [`provider`](#provider) &nbsp; reference\n+   - [`lifecycle`](#lifecycle) &nbsp; block\n+      - [`create_before_destroy`](#create_before_destroy) &nbsp; boolean\n+      - [`prevent_destroy`](#prevent_destroy) &nbsp; boolean\n+      - [`ignore_changes`](#ignore_changes) &nbsp; list of attributes\n+      - [`replace_triggered_by`](#replace_triggered_by) &nbsp; list of references\n+      - [`precondition`](#precondition) &nbsp; block\n+        - [`condition`](#precondition) &nbsp; string\n+        - [`error_message`](#precondition) &nbsp; string\n+      - [`postcondition`](#postcondition) &nbsp; block\n+        - [`condition`](#postcondition) &nbsp; string\n+        - [`error_message`](#postcondition) &nbsp; string\n+   - [`connection`](#connection) &nbsp; block\n+        - [`type`](#connection-arguments) &nbsp; string\n+        - [`user`](#connection-arguments) &nbsp; string\n+        - [`password`](#connection-arguments) &nbsp; string\n+        - [`host`](#connection-arguments) &nbsp; string\n+        - [`port`](#connection-arguments) &nbsp; string\n+        - [`timeout`](#connection-arguments) &nbsp; string\n+        - [`script_path`](#connection-arguments) &nbsp; string\n+        - [`private_key`](#connection-arguments) &nbsp; string\n+        - [`certificate`](#connection-arguments) &nbsp; string\n+        - [`agent`](#connection-arguments) &nbsp; string\n+        - [`agent_identity`](#connection-arguments) &nbsp; string\n+        - [`host_key`](#connection-arguments) &nbsp; string\n+        - [`target_platform`](#connection-arguments) &nbsp; string\n+        - [`script_path`](#connection-arguments) &nbsp; string\n+        - [`https`](#connection-arguments) &nbsp; string\n+        - [`insecure`](#connection-arguments) &nbsp; string\n+        - [`use_ntlm`](#connection-arguments) &nbsp; string\n+        - [`cacert`](#connection-arguments) &nbsp; string\n+        - [`bastion_host`](#connection-arguments) &nbsp; string\n+        - [`bastion_host_key`](#connection-arguments) &nbsp; string\n+        - [`bastion_port`](#connection-arguments) &nbsp; string\n+        - [`bastion_user`](#connection-arguments) &nbsp; string\n+        - [`bastion_password`](#connection-arguments) &nbsp; string\n+        - [`bastion_private_key`](#connection-arguments) &nbsp; string\n+        - [`bastion_certificate`](#connection-arguments) &nbsp; string\n+        - [`proxy_scheme`](#connection-arguments) &nbsp; string\n+        - [`proxy_port`](#connection-arguments) &nbsp; string\n+        - [`proxy_user_name`](#connection-arguments) &nbsp; string\n+        - [`proxy_user_password`](#connection-arguments) &nbsp; string\n+   - [`provisioner \"<TYPE>\" \"<LABEL>\"`](#provisioner) &nbsp; block\n+      - [`source`](#source) &nbsp; string\n+      - [`destination`](#destination) &nbsp; string\n+      - [`content`](#content) &nbsp; string      \n+      - [`command`](#command) &nbsp; string\n+      - [`working_dir`](#working_dir) &nbsp; string\n+      - [`interpreter`](#interpreter) &nbsp; string\n+      - [`environment`](#command) &nbsp; string\n+      - [`when`](#when) &nbsp; keyword\n+      - [`quiet`](#quiet) &nbsp; boolean\n+      - [`inline`](#inline) &nbsp; list of strings\n+      - [`script`](#script) &nbsp; string\n+      - [`scripts`](#scripts) &nbsp; string\n+      - [`on_failure`](#on_failure) &nbsp; keyword\n+      - [`connection`](#connection) &nbsp; block\n+\n+## Complete configuration\n+\n+The following `resource` block defines all of the supported built-in arguments you can set on a resource:\n+\n+```hcl\n+resource \"<TYPE>\" \"<LABEL>\" {\n+  <PROVIDER_ARGUMENTS>\n+  count = <NUMBER>      # `for_each` and `count` are mutually exclusive \n+  depends_on = [ <RESOURCE.ADDRESS.EXPRESSION> ]\n+  for_each = {          # `for_each` and `count` are mutually exclusive \n+    <KEY> = <VALUE>\n+  }\n+  for_each = [\t     # `for_each` accepts a map or a set of strings \n+    \"<VALUE>\", \n+    \"<VALUE>\"\n+  ]\n+  provider = <REFERENCE.TO.ALIAS>\n+  lifecycle {\n+    create_before_destroy = <true || false>\n+    prevent_destroy = <true || false>\n+    ignore_changes = [ <ATTRIBUTE> ]\n+    replace_triggered_by = [ <RESOURCE.ADDRESS.EXPRESSION> ]\n+    precondition {\n+      condition = <EXPRESSION>\n+      error_message = \"<STRING>\"\n+    }\n+    postcondition {\n+      condition = <EXPRESSION>\n+      error_message = \"<STRING>\"\n+    }\n+  }\n+  connection {\n+    type = <\"ssh\" or \"winrm\">\n+    host = <EXPRESSION>\n+    <DEFAULT_CONNECTION_SETTINGS>\n+  }\n+  provisioner \"<TYPE>\" \"<LABEL>\" {\n+    source = \"<PATH>\"\n+    destination = \"<PATH>\"\n+    content = \"<CONTENT TO COPY TO `destination`>\"\n+    command = <COMMAND>\n+    working_dir = \"<PATH TO DIR WHERE TERRAFORM EXECUTES `command`>\"\n+    interpreter = [\n+      \"<PATH TO INTERPRETER EXECUTABLE>\",\n+      \"<COMMAND> <ARGUMENTS>\"\n+    ]\n+    environment {\n+      \"<KEY>\" = \"<VALUE>\"\n+    }\n+    when = <TERRAFORM COMMAND>\n+    quiet = <true || false>\n+    inline = [ \"<COMMAND>\" ]\n+    script = \"<PATH>\"\n+    scripts = [\n+      \"<PATH>\"\n+    ]\n+    on_failure = <continue || fail>\n+    connection {\n+      type = <\"ssh\" or \"winrm\">\n+      host = <EXPRESSION>\n+      <SPECIFIC_CONNECTION_SETTINGS>\n+    }\n+  }\n+}\n+```\n+\n+## Specification\n+\n+A `resource` block supports the following configuration. \n+\n+### `resource \"<TYPE>\" \"<LABEL>\"`\n+\n+You must set the following arguments for every `resource` block: \n+\n+- `TYPE`: Specifies the type of resource. This value is determined by the provider developer. Refer to provider documentation for details. The `terraform_data` resource type, which you can use to store values and trigger Terraform operations without creating actual infrastructure, is the exception. \n+- `LABEL`: Specifies a name for the resource. Terraform uses this label to track the resource in your state file. To reference the resource in your configuration, you must refer to it using `<TYPE>.<LABEL>` syntax. The label does not affect settings on the actual infrastructure resource. Refer to [References to Named Values](/terraform/language/expressions/references) and [Resource naming](/terraform/language/style#resource-naming) for expression syntax and label recommendations.\n+\n+### Provider-specific arguments\n+\n+The provider developer determines which arguments you can define for a resource. Refer to the provider documentation for details.  \n+\n+### `count`\n+\n+The `count` meta-argument instructs Terraform to provision multiple instances of the same resource with identical or similar configuration. \n+\n+```hcl\n+resource {\n+  count = <number>\n+}\n+```\n+\n+The value must be a whole number. You can reference variables or local values and use expressions to compute the value, but the value must resolve to a whole number. \n+\n+In blocks where `count` is set, Terraform exposes an additional `count` object. You can reference the object to modify the configuration of each instance. The `count` object has an `index` attribute starting from `0`. \n+\n+To refer to an individual instance of a resource created using the `count` meta-argument, use the `<TYPE>.<NAME>[INDEX]` syntax. For example, `aws_instance.server[0]` refers to the first instance of the `aws_instance` resource named `server`. \n+\n+<Tip>\n+\n+You can use the `count` argument as a conditional for creating resources. For example, setting a `count = var.creator ? 3 : 0` instructs Terraform to create three instances of the resource when a variable named `creator` is set to `true`. Refer to [​​Conditional Expressions](/terraform/language/expressions/conditionals) for additional information.\n+\n+</Tip>\n+\n+The `count` argument is a meta-argument, which is built into Terraform and controls the way that Terraform creates resources. Refer to [Meta-arguments](/terraform/language/meta-arguments) for additional information.\n+\n+#### Summary\n+\n+- Data type: Number. \n+- Default: None.  \n+- Example: [Create multiple instances of a resource](#create-multiple-instances-of-a-resource).\n+\n+### `depends_on`\n+\n+The `depends_on` meta-argument specifies an upstream resource that the resource depends on. Terraform must complete all operations on the upstream resource before performing operations on the resource containing the `depends_on` argument.\n+\n+```hcl\n+resource {\n+  depends_on = [ <resource reference> ]\n+}\n+```\n+\n+When a resource configuration refers to another resource, Terraform identifies the dependency and creates the upstream resource first. In some cases, you may need Terraform to create a resource before creating another, even though the resources are configured independently. \n+\n+Use the `depends_on` argument when Terraform cannot infer a dependency automatically. We recommend always including a comment to explain resource dependencies when using a `depends_on` argument.\n+\n+When using the `depends_on` meta-argument, you can only reference other resources or child modules in the same root module. The list cannot include arbitrary expressions. Any values referenced in the `depends_on` list must be known before Terraform begins the operation so that it can evaluate dependencies.\n+\n+Specifying an entire module in the `depends_on` argument affects the order in which Terraform provisions all of the resources and data sources associated with that module. Refer to [Resource dependencies](/terraform/language/manage-resources#resource-dependencies) <!-- placeholder link -->\n+and [Data resource dependencies](/terraform/language/configure-data-sources#data-resource-dependencies) for additional information.\n+\n+The `depends_on` argument is a meta-argument, which is built into Terraform and controls the way that Terraform creates resources. Refer to [Meta-arguments](/terraform/language/concepts/meta-arguments) for additional information.\n+\n+#### Summary\n+\n+- Data type: List.\n+- Default: None.  \n+- Example: [Specify a dependency](#specify-a-dependency). \n+\n+### `for_each`\n+\n+The `for_each` meta-argument instructs Terraform to provision similar resources without requiring separate configuration blocks for each resource. \n+\n+<Tabs>\n+\n+<Tab heading=\"List of values\">\n+\n+```hcl\n+resource {\n+  for_each = [ \"<VALUE>\" ] \n+  # . . .\n+}\n+```\n+\n+</Tab>\n+\n+<Tab heading=\"Map of key-value pairs\">\n+\n+```hcl\n+resource {\n+  for_each = {\n+    \"<KEY>\" = \"<VALUE>\"\n+  }\n+}\n+```\n+\n+</Tab>\n+\n+</Tabs>\n+\n+The `for_each` meta-argument accepts a map or a set of strings and creates an instance for each item in that map or set. Each instance is associated with a distinct infrastructure object. Terraform creates, updates, or destroys each instance when applying changes to the configuration.\n+\n+You can use pure functions, such as `toset()` and `tomap()`, to create a map or set for use in the `for_each` argument. Whether iterating over the keys of a map or set of strings, all must be known values. Otherwise, Terraform prints an error message that `for_each` has dependencies that it cannot determine before applying the configuration.\n+\n+Keys in the `for_each` argument cannot be the result of or rely on the result of impure functions, including `uuid`, `bcrypt`, or `timestamp`, because Terraform defers evaluating impure functions during the main evaluation step.\n+\n+The `for_each` argument does not implicitly convert lists or tuples to sets. To declare resource instances based on a nested data structure or combinations of elements from multiple data structures, you can use Terraform expressions and functions to derive a suitable value. Refer to the following examples for additional information:\n+\n+- [Transform a multi-level nested structure into a flat list](/terraform/language/functions/flatten#flattening-nested-structures-for-for_each)\n+- [Combine collections to produce a list of element combinations](/terraform/language/functions/setproduct#finding-combinations-for-for_each).\n+\n+You cannot use sensitive values, such as [sensitive input variables](/terraform/language/values/variables#suppressing-values-in-cli-output), [sensitive outputs](/terraform/language/values/outputs#sensitive-suppressing-values-in-cli-output), or [sensitive resource attributes](/terraform/language/expressions/references#sensitive-resource-attributes), as arguments in `for_each`. Terraform uses the value in `for_each` to identify the resource instance and always discloses it in UI output, so sensitive values are not allowed. Terraform returns an error if you attempt to use sensitive values as `for_each` arguments.\n+\n+If you transform a value containing sensitive data into an argument for use in `for_each`, be aware that most functions in Terraform will return a sensitive result if given an argument with any sensitive content. In many cases, you can achieve similar results with a `for` expression. For example, to call `keys(local.map)` where `local.map` is an object with sensitive values, but non-sensitive keys, you can create a value to pass to `for_each` using `toset([for k,v in local.map : k])`.\n+\n+Refer to [Sensitive Data in State](/terraform/language/state/sensitive-data) for additional information. \n+\n+The `for_each` argument exposes an `each` object that you can reference within the same block to modify specific instances of the resource. The object has the following attributes:\n+\n+- `each.key`: Map key or list member that corresponds to an instance.\n+- `each.value`: Map value that corresponds to an instance. \n+\n+Use the `<TYPE>.<NAME>[<KEY>]` syntax to access an instance of a resource created using `for_each`. For example, `azurerm_resource_group.rg[\"a_group\"]` refers to an instance of the `azurrm_resource_group` resource named `rg` created off of the `a_group` key.\n+\n+The `for_each` argument is a meta-argument, which is built into Terraform and controls the way that Terraform creates resources. Refer to [Meta-arguments](/terraform/language/meta-arguments) for additional information.\n+\n+#### Summary\n+\n+- Data type: Map or set of strings.\n+- Default: None.  \n+- Example: [Create multiple instances of a resource](#create-multiple-instances-of-a-resource). \n+\n+### `provider`\n+\n+The `provider` argument instructs Terraform to use an alternate provider configuration to provision the resource. \n+\n+```hcl\n+resource {\n+  provider = <provider>.<alias>\n+}\n+```\n+\n+By default, Terraform automatically selects a provider based on the resource type, but you can create multiple provider configurations and use a non-default configuration for specific resources. \n+\n+Use the `<PROVIDER>.<ALIAS>` syntax to reference a provider configuration in the `provider` argument. Refer to [Multiple Provider Configurations](/terraform/language/providers/configuration#alias-multiple-provider-configurations) for instructions on how to reference a specific provider configuration.     \n+\n+The `provider` argument is a meta-argument, which is built into Terraform and controls the way that Terraform creates resources. Refer to [Meta-arguments](/terraform/language/concepts/meta-arguments) for additional information.\n+\n+#### Summary\n+\n+- Data type: Reference.\n+- Default: None. \n+- Example: [Select an alternate provider configuration](#select-an-alternate-provider-configuration).\n+\n+### `lifecycle`\n+\n+The `lifecycle` block defines lifecycle rules that instruct Terraform when and how to operate on your resource. \n+\n+```hcl\n+resource {\n+  lifecycle { \n+    <lifecycle>\n+  }\n+}\n+```\n+\n+You can specify the following lifecycle rules to manage how Terraform performs operations on the resource:\n+\n+- [`create_before_destroy`](#create_before_destroy): Terraform creates a replacement resource before destroying the previous resource.\n+- [`prevent_destroy`](#prevent_destroy): Terraform rejects operations to destroy the resource and returns an error.\n+- [`ignore_changes`](#ignore_changes):  Specifies a list of resource attributes that, when modified outside of your configuration, Terraform ignores instead of attempting to update the actual resource to match the configuration.  \n+- [`replace_triggered_by`](#replace-triggered_by): Terraform replaces the resource when any of the referenced resources or attributes specified change.\n+- [`precondition`](#precondition): Specifies a condition that Terraform evaluates before creating the resource. Refer to [Test and validate](/terraform/language/test-and-validate) for additional information.\n+- [`postcondition`](#postcondition): Specifies a condition that Terraform evaluates after creating the resource. Refer to [Test and validate](/terraform/language/test-and-validate) for additional information.\n+\n+Configurations defined in the `lifecycle` block affect how Terraform constructs and traverses the dependency graph. You can only use literal values in the lifecycle block because Terraform processes them before it evaluates arbitrary expressions for a run.\n+\n+The `lifecycle` block is a meta-argument. Meta-arguments are built-in arguments that control how Terraform creates resources. Refer to [Meta-arguments](/terraform/language/concepts/meta-arguments) for additional information.  \n+\n+#### Summary\n+\n+- Data type: Block.\n+- Default: None \n+\n+### `create_before_destroy`\n+\n+The `create_before_destroy` argument instructs Terraform to create a replacement resource before destroying the resource it replaces. \n+\n+```hcl\n+resource {\n+  lifecycle { \n+    create_before_destroy = <boolean>\n+  }\n+}\n+```\n+\n+By default, Terraform destroys a resource before creating a replacement. \n+\n+Refer to the documentation for the resource type you are configuring to understand which changes Terraform can make in-place and which require recreating the resource to decide whether to use the `create_before_destroy` argument. \n+\n+Terraform propagates and applies the `create_before_destroy` behavior to all upstream resources. For example, if `create_before_destroy` is enabled on resource A but not on resource B, but resource A is dependent on resource B, then Terraform enables `create_before_destroy` for resource B implicitly and records it in the state file. You cannot override `create_before_destroy` to `false` on resource B because that would imply dependency cycles in the graph.\n+\n+Setting`create_before_destroy` to `true` on a resource stops any configured destroy provisioners. \n+\n+#### Summary\n+\n+- Data type: Boolean\n+- Default: None. \n+\n+### `prevent_destroy`\n+\n+The `prevent_destroy` argument instructs Terraform to reject plans to destroy the resource.\n+\n+```hcl\n+resource {\n+  lifecycle { \n+    prevent_destroy = <boolean>\n+  }\n+}\n+```\n+\n+Use this argument to prevent team members from accidentally replacing critical infrastructure, such as database instances.\n+\n+When the `prevent_destroy` argument is set, you must either remove the resource from the configuration or change the `prevent_destroy` argument to `false` to destroy it. Use this argument with caution. The `prevent_destroy` argument can make applying resource changes or destroying resources more complex. \n+\n+#### Summary\n+\n+- Data type: Boolean.\n+- Default: None.  \n+\n+### `ignore_changes`\n+\n+The `ignore_changes` argument specifies a list of resource attributes for Terraform to ignore when planning updates to the resource. \n+\n+```hcl\n+resource {\n+  lifecycle { \n+    ignore_changes = [ <attribute> ]\n+  }\n+}\n+```\n+\n+Use this argument when the resource references data that may change but does not affect the resource after its creation. \n+\n+By default, Terraform detects any difference in the current settings of a real infrastructure object and plans to update the remote object to match the configuration.\n+\n+Terraform uses the specified arguments to create a resource, but ignores them when planning an `update` operation. You can specify arguments as the relative attribute addresses in the resource and reference members of maps and lists using index notation, such as `tags[\"Name\"]` and `list[0]`. \n+\n+You can also specify `all` instead of a list to ignore future changes to all resource attributes. This lets Terraform create and destroy the resource but it does not propose updates to it. \n+\n+#### Summary\n+\n+- Data type: List.\n+- Default: None. \n+- Example: [Ignore attribute changes](#ignore-attribute-changes).\n+\n+### `replace_triggered_by`\n+\n+The `replace_triggered_by` argument instructs Terraform to replace the resource when any of the referenced items change.\n+\n+```hcl\n+resource {\n+  lifecycle { \n+    replace_triggered_by = [ <address.reference> ]\n+  }\n+}\n+```\n+\n+You can specify a list of expressions that reference managed resources, instances, or instance attributes. You can only reference managed resources in `replace_triggered_by` expressions. This lets you modify these expressions without forcing replacement.\n+\n+The trigger is based on the planned actions for all of the given resources. Terraform does not plan actions for plain values, such as local values or input variables, but you can use the `terraform_data` resource type to apply a resource-like lifecycle to them.\n+\n+References in the argument list trigger a replacement under following conditions:\n+\n+- When referencing a resource with multiple instances, such as those created by `count` or `for_each`, a `terraform plan` command to update or replace any instance triggers replacement.\n+- When referencing a single resource instance, a `terraform plan` command to update or replace that instance triggers replacement.\n+- When referencing a single attribute of a resource instance, any change to the attribute value triggers replacement.\n+\n+Adding the `replace_triggered_by` argument to a resource that uses `count` or `for_each` lets you add the `count.index` or `each.key` resource address to the expression. Use this address segment to reference specific instances of other resources that are configured with the same `count` or collection.\n+\n+#### Summary\n+\n+- Data type: List \n+- Default: None.\n+- Example: [Specify triggers that replace resources](#specify-triggers-that-replace-resources)  \n+\n+### `precondition`\n+\n+The `precondition` block specifies a condition that must return `true` before Terraform evaluates and performs operations on the resource. You can also specify an error message for Terraform to print when the condition returns `false`. \n+\n+```hcl\n+resource {\n+  lifecycle { \n+    precondition {\n+      condition = <expression>\n+      error_message = \"<message>\"\n+    }\n+  }\n+}\n+```\n+\n+The following arguments in the `precondition` block are required:\n+\n+| Argument | Description | Data type |\n+| --- | --- | --- |\n+| `condition` | Expression that must return `true` for Terraform to proceed with an operation. You can refer to any other object in the same configuration scope unless the reference creates a cyclic dependency. | Expression that can include references, strings, and operators. |\n+| `error_message` | Message that Terraform prints to the console if the `condition` returns `false`. | String |\n+\n+Terraform evaluates `precondition` blocks before evaluating the resource's configuration arguments. The `precondition` can take precedence over argument evaluation errors.\n+\n+Terraform evaluates precondition blocks after evaluating `count` and `for_each` meta-arguments. As a result, Terraform can evaluate the `precondition` separately for each instance and makes the `each.key` and `count.index` objects available in the conditions. \n+\n+You can include a `precondition` and [`postcondition` block](#postcondition) in the same resource. Do not add `precondition` blocks to a `resource` block and a `data` block that represent the same object in the same configuration. Doing so can prevent Terraform from understanding that the data block result can be affected by changes in the resource block. \n+\n+Refer to [Test and validate](/terraform/language/test-and-validate) for information about adding validations to your Terraform configuration.\n+\n+#### Summary\n+\n+- Data type: Block.\n+- Default: None.\n+- Example: [Apply custom conditions](#apply-custom-conditions)\n+\n+### `postcondition`\n+\n+The `postcondition` block specifies a condition that must return `true` after Terraform performs operations on the resource. You can also specify an error message for Terraform to print to the console when the condition returns `false`. \n+\n+```hcl\n+resource {\n+  lifecycle { \n+    postcondition {\n+      condition = <expression>\n+      error_message = \"<message>\"\n+    }\n+  }\n+}\n+```\n+\n+The following arguments in the `precondition` block are required:\n+\n+| Argument | Description | Data type |\n+| --- | --- | --- |\n+| `condition` | Expression that must return `true` for Terraform to perform operations on downstream resources. You can refer to any other object in the same configuration scope unless the reference creates a cyclic dependency. | Expression that can include references, strings, and operators. |\n+| `error_message` | Message that Terraform prints to the console if the `condition` returns `false`. | String |\n+\n+Refer to [Test and validate](/terraform/language/test-and-validate) for information about adding validations to your Terraform configuration.\n+\n+Terraform evaluates `postcondition` blocks after planning and applying changes to the resource. Postcondition failures prevent changes to other resources that depend on the failing resource.\n+\n+You can include a `postcondition` and [`precondition` block](#precondition) in the same resource. Do not add `postcondition` blocks to a `resource` block and a `data` block that represent the same object in the same configuration. Doing so can prevent Terraform from understanding that the data block result can be affected by changes in the resource block. \n+\n+#### Summary\n+\n+- Data type: Block.\n+- Default: None.\n+- Example: [Apply custom conditions](#apply-custom-conditions)\n+\n+### `connection`\n+\n+The `connection` block specifies settings that let provisioners connect to resources so that Terraform can perform operations on the resource after creating it.\n+\n+<Warning>\n+\n+We recommend using configuration management tools or other means to perform actions on the local or remote machine instead of using provisioners. Refer to [Perform post-apply action](#)<!--TODO: updated with real link when ready--> for additional information.\n+\n+</Warning>\n+\n+You can add the `connection` block to either the [`resource`](#resource) block or the [`provisioner`](#provisioner) block. When added to the `resource` block, the `connection` block sets default connection settings for all provisioners defined in the resource so that provisioners can connect to the remote resource after Terraform provisions it. \n+\n+```hcl\n+resource {\n+  # . . .\n+  connection {\n+    <settings for all provisioners in the resource>\n+  }\n+}\n+```\n+\n+When added to a `provisioner` block, the `connection` block defines settings specific to the provisioner.\n+\n+```hcl\n+resource {\n+  # . . .\n+  provisioner {\n+    # . . .\n+    connection {\n+      <settings for all provisioners in the resource>\n+    }\n+  }\n+}\n+```\n+\n+Terraform does not validate SSH host keys by default. You can establish a separate mechanism for key distribution and explicitly set the `host_key` argument to verify against a specific key or signing CA.\n+\n+You can use ephemeral values for arguments in the `connection` block. Refer [Ephemerality in resources](/terraform/language/resources/ephemeral) for additional information.\n+\n+Expressions in `connection` blocks cannot refer to their parent resource by name. References create dependencies, and referring to a resource by name within its own block would create a dependency cycle. Instead, use the `self` object in expressions to refer to the `connection` block's parent block, including all of its attributes. For example, use `self.public_ip` to reference the `public_ip` attribute in an `aws_instance`. \n+\n+<span id=\"connection-arguments\"/>\n+\n+<Tip>\n+\n+You can provide multiple connections so that an initial provisioner can connect as the root user to set up user accounts and subsequent provisioners can connect as less-privileged users to perform more specific operations.\n+\n+</Tip>\n+\n+The following table describes the arguments you can use in the `connection` block:\n+\n+| Argument | Description | Data type | Connection | Default |\n+|---------------|--------------|-------------|---------| --- | \n+| `type` | Specifies the type of connection for sending and receiving data from the remote resource. You can specify `ssh` or `winrm`. When set to `winrm`, provisioners implement Windows-specific behaviors, even when `target_platform` is set to `unix`, unless otherwise specified.| string |  | `ssh` |\n+| `user` | Specifies the user to use for the connection. | string | `ssh`<p>`winrm`</p> | <p>`root` when `type` is `ssh`</p><p>`Administrator` when `type` is `winrm`</p> | \n+| `password` | Specifies the password to use for the connection. | string | `ssh`<p>`winrm`</p> | none |\n+| `host` | Specifies the address of the resource to connect to. <p>This argument is required.</p> | string | `ssh`<p>`winrm`</p> | none |\n+| `port` | Specifies the port number to connect to. | number | `ssh`<p>`winrm`</p> | <p>`22` when `type` is `ssh`</p><p>`5985` when `type` is `winrm`</p> |\n+| `timeout` | Specifies how long to wait for the connection to become available. | string | `ssh`<p>`winrm`</p> | `\"5m\"` |\n+| `script_path` | Specifies the path on the remote resource where Terraform copies scripts to. Refer to the [`provisioner` block reference](#provisioner) for additional information. Terraform copies scripts to a path that contains random numbers depending on the `target_platform` configuration. | string | `ssh`<p>`winrm`</p> | <p>`/tmp/terraform_%RAND%.sh` when `target_platform` is `unix`</p><p>`C:/windows/temp/`<br/>`terraform_%RAND%.cmd` when `target_platform` is `windows`</p> |\n+| `private_key` | Specifies the contents of an SSH key to use for the connection. `private_key` takes precedence over `password` when both are provided. | <p>string</p><p>Use a [`file` function](/terraform/language/functions/file) to load keys from file.</p> | `ssh` | none |\n+| `certificate` | Specifies the contents of a signed CA certificate. You must also configure a  `private_key` arugment. | <p>string</p><p>Use a [`file` function](/terraform/language/functions/file) to load certificates from file.</p> | `ssh` | none |\n+| `agent` | Specifies an SSH agent for authentication. Set to `false` to disable using `ssh-agent` to authenticate. On Windows, the only supported SSH authentication agent is [Pageant](http://the.earth.li/\\~sgtatham/putty/0.66/htmldoc/Chapter9.html#pageant). | string | `ssh` | `false` |\n+| `agent_identity` | Specifies the preferred identity from the SSH agent to use for authentication. | string | `ssh` | none |\n+| `host_key` | Specifies the public key from the remote host or the signing CA to verify the connection. | string | `ssh` | none |\n+| `target_platform` | Specifies the target platform, which affects the default value for the `script_path` argument. You can specify either `windows` or `unix`. <p>`windows` sets the default `script_path` to `c:\\windows\\temp\\terraform_%RAND%.cmd` if the default SSH shell on the remote resource is `cmd.exe`. Refer to the [Windows documentation](https://docs.microsoft.com/en-us/windows-server/administration/openssh/openssh_server_configuration#configuring-the-default-shell-for-openssh-in-windows) for additional information. If the SSH default shell is PowerShell, set `script_path` to `\"c:/windows/temp/terraform_%RAND%.ps1\"`.</p><p>`unix` sets the default `script_path` to `/tmp/terraform_%RAND%.sh`. </p> | string | `ssh` |`unix` |\n+| `https` | Set to `true` to connect using HTTPS instead of HTTP. | boolean | `winrm` | `false` |\n+| `insecure` | Set to `true` to skip validating the HTTPS certificate chain. | boolean | `winrm` | `false` |\n+| `use_ntlm` | Set to `true` to use NTLM authentication instead of basic authentication. Using NTLM removes the requirement for basic authentication to be enabled within the target guest. Refer to [Authentication for Remote Connections](https://docs.microsoft.com/en-us/windows/win32/winrm/authentication-for-remote-connections) in the Windows App Development documentation for more details. | boolean | `winrm` | `false` |\n+| `cacert` | Specifies the CA certificate to validate against. | string | `winrm` | none |\n+| `bastion_host` | Specifies the address of the bastion host. The provisioner connects to `bastion_host` before connecting to `host`. | string | `ssh` | none |\n+| `bastion_host_key` | Specifies the public key from the remote host or the signing CA to verify the host connection. | string | `ssh` | none |\n+| `bastion_port` | Specifies the port number to use for the bastion host connection. | string | `ssh` | value of the `port` field|\n+| `bastion_user`| Specifies the user name for connecting to the bastion host. | string | `ssh` | value of the `user` field |\n+| `bastion_password` | Specifies the user password for connecting to the bastion host. | string | `ssh` | value of the `password` field |\n+| `bastion_private_key` | Specifies the contents of an SSH key file to use for the bastion host. | <p>string</p><p>Use a [`file` function](/terraform/language/functions/file) to load keys from file.</p> | `ssh` | value of the `private_key` field |\n+| `bastion_certificate` |  Specifies the contents of a signed CA certificate. You must also configure the `bastion_private_key` argument when providing the certificate for the bastion host. | <p>string</p><p>Use a [`file` function](/terraform/language/functions/file) to load certificates from file.</p> | `ssh` | value of the `certificate` field |\n+| `proxy_scheme` | Specifies the connection protocol. You can specify one of the following values: <li>`http`</li><li>`https`</li><li> `socks5`</li> | string | `ssh` | none |\n+| `proxy_host` | Specifies the address of the proxy host. The provisioner connects to the proxy host first. When `bastion_host` is configured, the provisioner connects to the bastion host next, otherwise the provisioner connects to the host specified in the `host` argument.  | string | `ssh` | none |\n+| `proxy_port` | Specifies the port number to use for the proxy host connection. | number | `ssh` | none |\n+| `proxy_user_name` | Specifies the user name for connecting to the proxy host. You should only configure this argument when the proxy server requires authentication. | string | `ssh` | none |\n+| `proxy_user_password` | Specifies the user password for connecting to the proxy host. You should only configure this argument when the proxy server requires authentication. | string | `ssh` | none |\n+\n+#### Summary\n+\n+- Data type: Block.\n+- Default: None.\n+- Example: [Connect to remote resources](#connect-to-remote-resources)\n+\n+### `provisioner`\n+\n+The `provisioner` block defines actions to perform on the local machine or created resource, such as preparing servers or other infrastructure objects for service. \n+\n+```hcl\n+resource {\n+  provisioner \"<TYPE>\" \"<LABEL>\" {\n+    <arguments> \n+  }\n+}\n+```\n+\n+<Warning>\n+\n+We recommend using configuration management tools or other means to perform actions on the local or remote machine instead of using the `provisioner` block. Refer to [Perform post-apply action](#)<!--TODO: updated with real link when ready--> for additional information.\n+\n+</Warning>\n+\n+The `provisioner` block supports the following arguments:\n+\n+- `TYPE`: Specifies the type of provisioner to use. You must specify one of the following types:   \n+  - `file`: Copies files or directories from the machine where Terraform is running to the new resource. When the file provisioner communicates with a Windows system over SSH, you must configure OpenSSH to run the commands with `cmd.exe` and not PowerShell. PowerShell causes file parsing errors because it is incompatible with both Unix shells and the Windows command interpreter.\n+  - `local-exec`: Invokes an executable on the local machine after Terraform creates the resource.\n+  - `remote-exec`: Invokes an executable on the remote resource after Terraform creates the resource.  \n+- `LABEL`: Optional attribute for adding a unique name. Refer to [Resource naming](/terraform/language/style#resource-naming) for label recommendations.\n+\n+The type of provisioner determines which arguments you can add to the block. All types can use the [`connection`](#connection) argument. The following table lists each type's supported arguments:\n+\n+| Provisioner type | Arguments |\n+| --- | --- |\n+| `file` | <li>[`source`](#source)</li><li>[`content`](#content)</li><li>[`destination`](#destination)</li> |\n+| `local-exec` | <li>[`command`](#command)</li><li>[`working_dir`](#working_dir)</li><li>[`interpreter`](#interpreter)</li><li>[`environment`](#command)</li><li>[`when`](#when)</li><li>[`quiet`](#quiet)</li> |\n+| `remote-exec` | <li>[`inline`](#inline)</li><li>[`script`](#script)</li><li>[`scripts`](#scripts)</li> |\n+| All types | <li>[`connection`](#connection)</li> <li>[`on_failure`](#on_failure)</li> |\n+\n+#### Summary\n+\n+- Data type: Block.\n+- Default: None.\n+\n+### `source`\n+\n+The `source` specifies the location of a file or directory to copy to the location specified in the [`destination`](#destination) argument. \n+\n+```hcl\n+resource {\n+  provisioner \"file\" \"<LABEL>\" {\n+    source = \"<path>\"\n+  }\n+}\n+```\n+\n+\n+You can specify a string value that contains an expression. You can't use the `source` argument and the [`content`](#content) argument in the same `provisioner \"file\"` block. \n+\n+When the `source` argument specifies a directory and the `type` argument in the [provisioner connection settings](#connection) is set to `ssh`, the corresponding directory specified in the `destination` argument must already exist. You can add a `provisioner \"remote-exec\"` block to your `resource` configuration to create the directory. If the directory does not already exist, Terraform creates it when the `type` argument in the [provisioner connection settings](#connection) is set to `winrm`.\n+\n+Adding a trailing slash to the `source` argument path instructs Terraform to copy the contents of the directory to the `destination` directory. For example, when `source = \"/foo/\"` and `destination = \"/temp\"`, Terraform uploads the contents of `/foo` directory into `/tmp`. \n+\n+Without a trailing slash, Terraform creates the directory under the directory specified in the `destination`. For example, when `source = \"/foo\"` and `destination = \"/temp\"`, Terraform uploads the `/foo` directory to `/tmp/foo`. \n+\n+#### Summary\n+\n+- Data type: String.\n+- Default: None.\n+- Example: [Copy content to new resources](#copy-content-to-new-resources).\n+\n+### `content`\n+\n+The `content` argument specifies content to write directly to the location specified in the [`destination`](#destination) argument. \n+\n+```hcl\n+resource {\n+  provisioner \"file\" \"<LABEL>\" {\n+    content = \"<content>\"\n+  }\n+}\n+```\n+\n+\n+When `destination` points to a file, Terraform writes the value of the `content` argument to the file. When `destination` points to a directory, Terraform creates a file named `tf-file-content` inside the directory. We recommend setting the `destination` argument to a file when using `content` argument. Do not use the `content` argument and the [`source`](#source) argument in the same `provisioner \"file\"` block. \n+\n+You can specify a string value that contains an expression. You can't use the `source` argument and the [`content`](#content) argument in the same `provisioner \"file\"` block. \n+\n+#### Summary\n+\n+- Data type: String.\n+- Default: None.\n+- Example: [Copy content to new resources](#copy-content-to-new-resources).\n+\n+### `destination`\n+\n+The `destination` argument specifies a path on the remote resource that Terraform copies content to. You can use either [`source`](#source) or [`content`](#content) argument to provide content to the `destination` path. \n+\n+```hcl\n+resource {\n+  provisioner \"file\" \"<LABEL>\" {\n+    destination = \"<path>\"\n+  }\n+}\n+```\n+\n+\n+The remote system, not Terraform, evaluates the path you provide in the `destination` argument. As a result, valid values can vary depending on the operating system and remote access software running on the target.\n+\n+When the `type` argument in the [provisioner connection settings](#connection) is set to `ssh`, the provisioner passes the destination path as-is to the `scp` program on the remote host. By default, the OpenSSH `scp` implementation runs in the remote user's home directory. As a result, you can specify a relative path to upload into the home directory or an absolute path to upload to a different location. \n+\n+The remote `scp` process runs with the access level of the user specified in the [provisioner connection settings](#connection), so permissions may prevent Terraform from writing directly to locations outside of the home directory.\n+\n+When the `type` argument in the [provisioner connection settings](#connection) is set to `winrm`, Terraform uses PowerShell to interpret the `destination` path. As a result, you must not use meta-characters that PowerShell might interpret. You should specifically avoid including untrusted external input in your `destination` argument because doing so can let arbitrary PowerShell code execute on the remote system. \n+\n+Terraform performs the following process over WinRM connections:\n+\n+1. Generates a temporary filename in the directory set in the remote system's `TEMP` environment variable. \n+1. Generates a sequence of `echo` commands to gradually append base64-encoded chunks of the source file to the temporary file.\n+1. Uses an uploaded PowerShell script to read the temporary file, base64-decode, and write the raw result into the destination file.\n+\n+Modern Windows systems support running an OpenSSH server, so we strongly recommend choosing SSH over WinRM.\n+\n+#### Summary\n+\n+- Data type: String.\n+- Default: None.\n+- Example: [Copy content to new resources](#copy-content-to-new-resources).\n+\n+### `command`\n+\n+The `command` argument specifies a command for a local executable to run. You can specify an absolute path or a relative path to the current working directory. \n+```hcl\n+resource {\n+  provisioner \"local-exec\" \"<LABEL>\" {\n+    command = \"<path>\"\n+  }\n+}\n+```\n+\n+Terraform evaluates the command in a local shell and can use environment variables for variable substitution. We do not recommend using Terraform variables for variable substitution because doing so can lead to shell injection vulnerabilities. Instead, you should pass Terraform variables to a command through the environment parameter and use environment variable substitution. Refer to the following OWASP article for additional information about injection flaws: [Code Injection](https://owasp.org/www-community/attacks/Code_Injection).",
        "comment_created_at": "2025-04-30T20:37:08+00:00",
        "comment_author": "ritsok",
        "comment_body": "```suggestion\r\nTerraform evaluates the command in a local shell and can use environment variables for variable substitution. We do not recommend using Terraform variables for variable substitution because doing so can lead to shell injection vulnerabilities. Instead, use the `environment` parameter and environment variable substitution. Refer to the following OWASP article for additional information about injection flaws: [Code Injection](https://owasp.org/www-community/attacks/Code_Injection).\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1993845886",
    "pr_number": 36641,
    "pr_file": "website/docs/language/backend/azurerm.mdx",
    "created_at": "2025-03-13T16:01:08+00:00",
    "commented_code": "This backend supports state locking and consistency checking with Azure Blob Storage native capabilities.\n \n-~> Terraform 1.1 and 1.2 supported a feature-flag to allow enabling/disabling the use of Microsoft Graph (and MSAL) rather than Azure Active Directory Graph (and ADAL) - however this flag has since been removed in Terraform 1.3. Microsoft Graph (and MSAL) are now enabled by default and Azure Active Directory Graph (and ADAL) can no longer be used.\n-\n ## Authentication\n \n-The `azurerm` backend supports 3 methods of authenticating to the storage account:\n+!> **Warning:**  We recommend using environment variables to supply credentials and other sensitive data. If you use `-backend-config` or hardcode these values directly in your configuration, Terraform will include these values in both the `.terraform` subdirectory and in plan files. Refer to [Credentials and Sensitive Data](/terraform/language/backend#credentials-and-sensitive-data) for details.\n \n-- Access Key (default)\n-- Azure Active Directory\n-- SAS Token\n+The `azurerm` backend needs to authenticate to the storage account data plane in order to manipulate the state file blob in the storage account container. In order to do that, it needs to authenticate and to know the data plane URI for the storage account.\n \n-The *Access Key* method can be used directly, by specifying the access key, or in combination with an Azure AD principal (e.g. user, service principal or managed identity). To use an Access Key directly you must generate one for your state file blob and specify it in the backend configuration. If neither an access key or client ID is specified, Terraform will attempt to use Azure CLI. In both cases where no access key is given, Terraform will attempt to retrieve the access key for the storage account, using the authenticated Azure AD principal.\n+At a high level, the `azurerm` backend has 5 methods it can use to authenticate to the storage account data plane:\n \n-The *Azure Active Directory* method can only be used in combination with an Azure AD principal. To use the Azure Active Directory method you must set the `use_azuread_auth` variable to `true` in your backend configuration. This will cause the backend to use the Access Token of the Azure AD principal to authenticate to the state file blob, instead of authenticating using a shared access key.\n+- [Azure Active Directory](#azure-active-directory) **(Recommended)**\n+- [SAS Token](#sas-token) *(Not recommended for new workloads)*\n+- [Access Key](#access-key) *(Not recommended for new workloads)*\n+- [Access Key Lookup](#access-key-lookup) *(Not recommended for new workloads)*\n \n-The *SAS Token* method can only be used directly. You must generate a SAS Token for your state file blob and pass it to the backend config.\n+### Azure Active Directory and Access Key Lookup Authentication Types\n \n-The `azurerm` backend supports the following authentication scenarios to connect to the storage account, based on the configuration variables provided:\n+There are 5 types of Azure Active Directory authentication supported, which apply to the Azure Active Directory and Access Key Lookup methods.\n \n-| Authentication Method | Storage Account Authentication Type | Minimum Required Configuration† |\n-|-----|---|---|\n-| User Principal via Azure CLI | Access Key | N/A |\n-| User Principal via Azure CLI | Azure AD | `use_azuread_auth = true` |\n-| Service Principal or User Assigned Managed Identity via OIDC (Workload identity federation) | Access Key | `use_oidc = true` |\n-| Service Principal or User Assigned Managed Identity via OIDC (Workload identity federation) | Azure AD | `use_azuread_auth = true`, `use_oidc = true` |\n-| Managed Identity Principal | Access Key | `use_msi = true` |\n-| Managed Identity Principal | Azure AD | `use_azuread_auth = true`, `use_msi = true` |\n-| Service Principal via Client Secret | Access Key | `client_secret = \"...\"` |\n-| Service Principal via Client Secret | Azure AD | `use_azuread_auth = true`, `client_secret = \"...\"` |\n-| Service Principal via Client Certificate | Access Key | `client_certificate_path = \"...\"` |\n-| Service Principal via Client Certificate | Azure AD | `client_certificate_path = \"...`, `use_azuread_auth = true` |\n-| Access Key direct | Access Key | `access_key = \"...\"` |\n-| SAS Token direct | SAS Token | `sas_token = \"...\"` |\n+- OpenID Connect / Workload identity federation **(Recommended)**\n+  - User Assigned Managed Identity with Federated Credentials **(Recommended)**\n+  - Service Princial / App Registration with Federated Credentials\n+- User or System Assigned Managed Identity\n+  - User Assigned Managed Identity attached to Azure compute instance (agent / runner)\n+  - System Assigned Managed Identity attached to Azure compute instance (agent / runner)\n+- Service Principal / App Registration with Client Secret\n+- Service Principal / App REgistration with Client Certificate\n+- User Account with Azure CLI only (for local development cycle)\n \n-† There are sometimes more options needed for successful authentication. The variable shown is the one that triggers the backend to use a given authentication scenario. You can see examples of each option below.\n+These types can be supplied via inputs or via a pre-authenticated Azure CLI. We cover them in more depth in the following sections.\n \n--> Sensitive values should not be hardcoded into your configuration, and should instead be specified using environment variables or partial configuration flags in the `init` command of Terraform CLI.\n+### Data Plane URI\n \n-## Example Backend Configurations\n+In [most cases](https://learn.microsoft.com/en-us/azure/storage/common/storage-account-overview#standard-endpoints) this can simply be inferred from the `storage_account_name` and `container_name`. But if you are using the ['Azure DNS zone endpoints' feature](https://learn.microsoft.com/en-us/azure/storage/common/storage-account-overview#azure-dns-zone-endpoints-preview) the backend will need to lookup the data plane URI from the management plane. This requires the setting the `lookup_blob_endpoint` configuration option to `true` and the `Reader` role assignment on the storage account.\n \n-### Backend: Azure AD User via Azure CLI\n+## Azure Active Directory\n \n-This method is not suitable for automation since it only supports a User Principal. To check which tenant and subscription you are pointed to, run `az account show`.\n+This method requires a valid Azure Active Directory principal and a predictable storage account data plane URI.\n \n-*Connect to Storage Account with Access Key*\n+### Required Inputs\n \n-```hcl\n-terraform {\n-  backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"  # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n-    storage_account_name = \"abcd1234\"                      # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n-    container_name       = \"tfstate\"                       # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n-    key                  = \"prod.terraform.tfstate\"        # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-  }\n-}\n-```\n+The following inputs are always required for this method:\n \n-*Connect to Storage Account with Azure Active Directory authentication*\n+- `use_azuread_auth` - Set to `true` to use Azure Active Directory authentication to the storage account data plane. This can also be set via the `ARM_USE_AZUREAD` environment variable.\n+- `tenant_id` - The tenant ID of the Azure Active Directory principal is required to authenticate to the storage account data plane. If using Azure CLI, this can be inferred from the CLI session. This can also be set via the `ARM_TENANT_ID` environment variable.\n+- `storage_account_name` - The name of the storage account where the state file blob resides in.\n+- `container_name` - The name of the storage account container where the state file blob resides in.\n+- `key` - The name of the blob within the storage account container that the state file will be stored in.\n \n-```hcl\n-terraform {\n-  backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"  # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n-    storage_account_name = \"abcd1234\"                      # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n-    container_name       = \"tfstate\"                       # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n-    key                  = \"prod.terraform.tfstate\"        # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    use_azuread_auth     = true                            # Can also be set via `ARM_USE_AZUREAD` environment variable.\n-  }\n-}\n-```\n+### Optional Inputs\n+\n+These optional inputs apply when [looking up the data plane URI](#data-plane-uri) from the management plane. They are not required when the data plane URI can be inferred from the `storage_account_name` and `container_name`.\n+\n+- `lookup_blob_endpoint` - Set to `true` to lookup the storage account data plane URI from the management plane. This is required if you are using the 'Azure DNS zone endpoints' feature. Defaults to `false`. This value can also be sourced from the `ARM_USE_DNS_ZONE_ENDPOINT` environment variable.\n+- `subscription_id` - The subscription ID of the storage account is required to query the management plane. This is only required if `lookup_blob_endpoint` is set to `true`. If using Azure CLI, this can be inferred from the CLI session. This can also be set via the `ARM_SUBSCRIPTION_ID` environment variable.\n+- `resource_group_name` - The resource group name of the storage account is required to query the management plane. This is only required if `lookup_blob_endpoint` is set to `true`.\n+\n+### Storage Account Required Role Assignments\n+\n+The recommended data plane role assignments required for this method are either one of:\n+\n+- `Storage Blob Data Owner` on the storage account container (Recommended)\n+- `Storage Blob Data Contributor` on the storage account\n+\n+The recommended management plane role assignments required for this method are:\n \n-### Backend: Azure AD Service Principal or User Assigned Managed Identity via OIDC (Workload Identity Federation)\n+- `Reader` on the storage account *(Only required if `lookup_blob_endpoint` is set to `true`)*\n \n-You can use an App Registration (Service Principal) or a User Assigned Managed Identity to configure federated credentials. You must supply the Client ID of the principal.\n+### Azure Active Directory with OpenID Connect / Workload identity federation\n \n-*Connect to Storage Account with Access Key*\n+#### Required Inputs\n+\n+The following additional inputs are always required for this sub-type:\n+\n+- `use_oidc` - Set to `true` to use OpenID Connect / Workload identity federation to authenticate to the storage account data plane. This can also be set via the `ARM_USE_OIDC` environment variable.\n+- `client_id` - The client ID of the Azure Active Directory Service Principal / App Registration or User Assigned Managed Identity is required to authenticate to the storage account data plane. This can also be set via the `ARM_CLIENT_ID` environment variable.\n+\n+#### Example Configuration for GitHub\n+\n+With GitHub, the ID Token environment variables are automatically found, so no further settings are required.\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n+    use_oidc             = true                                    # Can also be set via `ARM_USE_OIDC` environment variable.\n+    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n+    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n     storage_account_name = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name       = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                  = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    use_oidc             = true                                    # Can also be set via `ARM_USE_OIDC` environment variable.\n-    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    subscription_id      = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n   }\n }\n ```\n \n-*Connect to Storage Account with Azure Active Directory authentication*\n+#### Example Configuration for Azure DevOps\n+\n+With Azure DevOps, the ID Token endpoint environment variables are automatically found, but you need to supply the service connection ID in `oidc_azure_service_connection_id`. If you are using the `AzureCLI` or `AzurePowerShell` tasks, the service connection ID is automatically set to the  `AZURESUBSCRIPTION_SERVICE_CONNECTION_ID` environment variable.\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n-    storage_account_name = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n-    container_name       = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n-    key                  = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    use_oidc             = true                                    # Can also be set via `ARM_USE_OIDC` environment variable.\n-    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    subscription_id      = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n-    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    use_oidc                         = true                                    # Can also be set via `ARM_USE_OIDC` environment variable.\n+    oidc_azure_service_connection_id = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_OIDC_AZURE_SERVICE_CONNECTION_ID` environment variable.\n+    use_azuread_auth                 = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    tenant_id                        = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n+    client_id                        = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n+    storage_account_name             = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n+    container_name                   = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n+    key                              = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n   }\n }\n ```\n \n-### Backend: Azure AD Managed Identity Principal\n+### Azure Active Directory with Compute Attached Managed Identity\n \n-You can use a User Assigned Managed Identity as well as a System Assigned Managed Identity on your agent / runner compute environment. However the backend does not currently support specifying the Client ID of the User Assigned Managed Identity, so you can only supply one per compute instance.\n+#### Required Inputs\n \n-*Connect to Storage Account with Access Key*\n+The following additional inputs are always required for this sub-type:\n \n-```hcl\n-terraform {\n-  backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n-    storage_account_name = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n-    container_name       = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n-    key                  = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    use_msi              = true                                    # Can also be set via `ARM_USE_MSI` environment variable.\n-    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    subscription_id      = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n-  }\n-}\n-```\n+- `use_msi` - Set to `true` to use the managed identity to authenticate to the storage account data plane. This can also be set via the `ARM_USE_MSI` environment variable.\n+\n+#### Optional Inputs\n+\n+The following additional inputs are optional for this sub-type:\n+\n+- `client_id` - The client ID of the User Assigned Managed Identity is required to authenticate to the storage account data plane. This is not required for System Assigned Managed Identity. This can also be set via the `ARM_CLIENT_ID` environment variable.\n \n-*Connect to Storage Account with Azure Active Directory authentication*\n+#### Example Configuration\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n+    use_msi              = true                                    # Can also be set via `ARM_USE_MSI` environment variable.\n+    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n+    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable. Not required for System Assigned Managed Identity.\n     storage_account_name = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name       = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                  = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    use_msi              = true                                    # Can also be set via `ARM_USE_MSI` environment variable.\n-    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    subscription_id      = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n-    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n   }\n }\n ```\n \n-### Backend: Azure AD Service Principal via Client Secret\n+### Azure Active Directory with Azure CLI\n \n-~> **Warning!** This method requires you to manage and rotate a secret. Consider using OIDC as a more secure approach.\n+You must have a pre-authenticated Azure CLI session using any supported method.\n \n-*Connect to Storage Account with Access Key*\n+#### Required Inputs\n+\n+The following additional inputs are always required for this sub-type:\n+\n+- `use_cli` - Set to `true` to use the Azure CLI session authenticate to the storage account data plane. This can also be set via the `ARM_USE_CLI` environment variable.\n+\n+#### Example Configuration\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n+    use_cli              = true                                    # Can also be set via `ARM_USE_CLI` environment variable.\n+    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable. Azure CLI will fallback to use the connected tenant ID if not supplied.\n     storage_account_name = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name       = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                  = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    client_secret        = \"************************************\"  # Can also be set via `ARM_CLIENT_SECRET` environment variable.\n-    subscription_id      = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n   }\n }\n ```\n \n-*Connect to Storage Account with Azure Active Directory authentication*\n+### Azure Active Directory with Client Secret\n+\n+We retain this method for backwards compatibility only, do not use it for any new workloads.\n+\n+~> **Warning!** This method requires you to manage and rotate a secret. Use OpenID Connect / Workload identity federation as a more secure approach.\n+\n+#### Required Inputs\n+\n+The following additional inputs are always required for this sub-type:\n+\n+- `client_id` - The client ID of the Azure Active Directory Service Principal / App Registration is required to authenticate to the storage account data plane. This can also be set via the `ARM_CLIENT_ID` environment variable.\n+- `client_secret` - The client secret of the Azure Active Directory Service Principal / App Registration is required to authenticate to the storage account data plane. This can also be set via the `ARM_CLIENT_SECRET` environment variable.\n+\n+#### Example Configuration\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n+    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n+    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n+    client_secret        = \"************************************\"  # Can also be set via `ARM_CLIENT_SECRET` environment variable.\n     storage_account_name = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name       = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                  = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    client_secret        = \"************************************\"  # Can also be set via `ARM_CLIENT_SECRET` environment variable.\n-    subscription_id      = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n-    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n   }\n }\n ```\n \n-### Backend: Azure AD Service Principal via Client Certificate\n+### Azure Active Directory with Client Certificate\n \n-~> **Warning!** This method requires you to manage and rotate a secret. Consider using OIDC as a more secure approach.\n+We retain this method for backwards compatibility only, do not use it for any new workloads.\n+\n+~> **Warning!** This method requires you to manage and rotate a secret. Use OpenID Connect / Workload identity federation as a more secure approach.\n+\n+#### Required Inputs\n+\n+The following additional inputs are always required for this sub-type:\n+\n+- `client_id` - The client ID of the Azure Active Directory Service Principal / App Registration is required to authenticate to the storage account data plane. This can also be set via the `ARM_CLIENT_ID` environment variable.\n+- `client_certificate_path` - The path to the client certificate bundle is required to authenticate to the storage account data plane. This can also be set via the `ARM_CLIENT_CERTIFICATE_PATH` environment variable.\n+- `client_certificate_password` - The password for the client certificate bundle is required to authenticate to the storage account data plane. This can also be set via the `ARM_CLIENT_CERTIFICATE_PASSWORD` environment variable.\n \n-*Connect to Storage Account with Access Key*\n+#### Example Configuration\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name         = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n-    storage_account_name        = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n-    container_name              = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n-    key                         = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n+    use_azuread_auth            = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    tenant_id                   = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n     client_id                   = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n     client_certificate_path     = \"/path/to/bundle.pfx\"                   # Can also be set via `ARM_CLIENT_CERTIFICATE_PATH` environment variable.\n     client_certificate_password = \"************************************\"  # Can also be set via `ARM_CLIENT_CERTIFICATE_PASSWORD` environment variable.\n-    subscription_id             = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id                   = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n-  }\n-}\n-```\n-\n-*Connect to Storage Account with Azure Active Directory authentication*\n-\n-```hcl\n-terraform {\n-  backend \"azurerm\" {\n-    resource_group_name         = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n     storage_account_name        = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name              = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                         = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    client_id                   = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    client_certificate_path     = \"/path/to/bundle.pfx\"                   # Can also be set via `ARM_CLIENT_CERTIFICATE_PATH` environment variable.\n-    client_certificate_password = \"************************************\"  # Can also be set via `ARM_CLIENT_CERTIFICATE_PASSWORD` environment variable.\n-    subscription_id             = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id                   = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n-    use_azuread_auth            = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n   }\n }\n ```\n \n-### Backend: Access Key Direct\n+## Access Key\n+\n+This method requires you find the Access Key for the storage account and supply it to the backend configuration.\n+\n+The Access Key is then used to directly authenticate to the storage account data plane.\n+\n+This method is retained for backwards compatibility, but we do not recommend it for new workloads.\n+\n+### Required Inputs\n+\n+The following inputs are always required for this method:\n+\n+- `access_key` - The Access Key of the storage account is required to authenticate to the storage account data plane. This can also be set via the `ARM_ACCESS_KEY` environment variable.\n+- `storage_account_name` - The name of the storage account where the state file blob resides in.\n+- `container_name` - The name of the storage account container where the state file blob resides in.\n+- `key` - The name of the blob within the storage account container that the state file will be stored in.\n+\n+### Storage Account Required Role Assignments\n+\n+There are no role assignments required on the storage account for this method as the Access Key is used to authenticate to the data plane.\n+\n+### Example Configuration\n \n ~> **Warning!** This method requires you to manage and rotate a secret. Consider using OIDC as a more secure approach.\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"             # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n+    access_key           = \"abcdefghijklmnopqrstuvwxyz0123456789...\"  # Can also be set via `ARM_ACCESS_KEY` environment variable.\n     storage_account_name = \"abcd1234\"                                 # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name       = \"tfstate\"                                  # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                  = \"prod.terraform.tfstate\"                   # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    access_key           = \"abcdefghijklmnopqrstuvwxyz0123456789...\"  # Can also be set via `ARM_ACCESS_KEY` environment variable.\n   }\n }\n ```\n \n-### Backend: SAS Token\n+## SAS Token\n+\n+This method requires you generate a SAS Token for the storage account container or blob and supply it to the backend configuration.\n+\n+The SAS Token is then used to directly authenticate to the storage account data plane.\n+\n+This method is retained for backwards compatibility, but we do not recommend it for new workloads.\n+\n+### Required Inputs\n+\n+The following inputs are always required for this method:\n+\n+- `sas_token` - The SAS Token for the storage account container or blob is required to authenticate to the storage account data plane. This can also be set via the `ARM_SAS_TOKEN` environment variable.\n+- `storage_account_name` - The name of the storage account where the state file blob resides in.\n+- `container_name` - The name of the storage account container where the state file blob resides in.\n+- `key` - The name of the blob within the storage account container that the state file will be stored in.\n+\n+### Storage Account Required Permissions\n+\n+The SAS Token requires `write` and `list` permissions on the container or blob.\n+\n+### Example Configuration\n \n ~> **Warning!** This method requires you to manage and rotate a secret. Consider using OIDC as a more secure approach.\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"             # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n+    sas_token            = \"abcdefghijklmnopqrstuvwxyz0123456789...\"  # Can also be set via `ARM_SAS_TOKEN` environment variable.\n     storage_account_name = \"abcd1234\"                                 # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name       = \"tfstate\"                                  # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                  = \"prod.terraform.tfstate\"                   # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    sas_token            = \"abcdefghijklmnopqrstuvwxyz0123456789...\"  # Can also be set via `ARM_SAS_TOKEN` environment variable.\n   }\n }\n ```\n \n-## Example Data Source Configurations\n+## Access Key Lookup\n \n-### Data Source: Azure AD User Principal via Azure CLI\n+This method requires a valid Azure Active Directory principal and is a fallback for when Azure Active Directory authentication cannot be used on the storage account data plane.\n \n-This method is not suitable for automation since it only supports a User Principal. To check which tenant and subscription you are pointed to, run `az account show`.\n+This method queries the management plane to get the storage account Access Key and then uses that Access Key to authenticate to the storage account data plane. As such it requires elevated permissions on the storage account.",
    "repo_full_name": "hashicorp/terraform",
    "discussion_comments": [
      {
        "comment_id": "1993845886",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36641,
        "pr_file": "website/docs/language/backend/azurerm.mdx",
        "discussion_id": "1993845886",
        "commented_code": "@@ -9,495 +9,501 @@ Stores the state as a Blob with the given Key within the Blob Container within [\n \n This backend supports state locking and consistency checking with Azure Blob Storage native capabilities.\n \n-~> Terraform 1.1 and 1.2 supported a feature-flag to allow enabling/disabling the use of Microsoft Graph (and MSAL) rather than Azure Active Directory Graph (and ADAL) - however this flag has since been removed in Terraform 1.3. Microsoft Graph (and MSAL) are now enabled by default and Azure Active Directory Graph (and ADAL) can no longer be used.\n-\n ## Authentication\n \n-The `azurerm` backend supports 3 methods of authenticating to the storage account:\n+!> **Warning:**  We recommend using environment variables to supply credentials and other sensitive data. If you use `-backend-config` or hardcode these values directly in your configuration, Terraform will include these values in both the `.terraform` subdirectory and in plan files. Refer to [Credentials and Sensitive Data](/terraform/language/backend#credentials-and-sensitive-data) for details.\n \n-- Access Key (default)\n-- Azure Active Directory\n-- SAS Token\n+The `azurerm` backend needs to authenticate to the storage account data plane in order to manipulate the state file blob in the storage account container. In order to do that, it needs to authenticate and to know the data plane URI for the storage account.\n \n-The *Access Key* method can be used directly, by specifying the access key, or in combination with an Azure AD principal (e.g. user, service principal or managed identity). To use an Access Key directly you must generate one for your state file blob and specify it in the backend configuration. If neither an access key or client ID is specified, Terraform will attempt to use Azure CLI. In both cases where no access key is given, Terraform will attempt to retrieve the access key for the storage account, using the authenticated Azure AD principal.\n+At a high level, the `azurerm` backend has 5 methods it can use to authenticate to the storage account data plane:\n \n-The *Azure Active Directory* method can only be used in combination with an Azure AD principal. To use the Azure Active Directory method you must set the `use_azuread_auth` variable to `true` in your backend configuration. This will cause the backend to use the Access Token of the Azure AD principal to authenticate to the state file blob, instead of authenticating using a shared access key.\n+- [Azure Active Directory](#azure-active-directory) **(Recommended)**\n+- [SAS Token](#sas-token) *(Not recommended for new workloads)*\n+- [Access Key](#access-key) *(Not recommended for new workloads)*\n+- [Access Key Lookup](#access-key-lookup) *(Not recommended for new workloads)*\n \n-The *SAS Token* method can only be used directly. You must generate a SAS Token for your state file blob and pass it to the backend config.\n+### Azure Active Directory and Access Key Lookup Authentication Types\n \n-The `azurerm` backend supports the following authentication scenarios to connect to the storage account, based on the configuration variables provided:\n+There are 5 types of Azure Active Directory authentication supported, which apply to the Azure Active Directory and Access Key Lookup methods.\n \n-| Authentication Method | Storage Account Authentication Type | Minimum Required Configuration† |\n-|-----|---|---|\n-| User Principal via Azure CLI | Access Key | N/A |\n-| User Principal via Azure CLI | Azure AD | `use_azuread_auth = true` |\n-| Service Principal or User Assigned Managed Identity via OIDC (Workload identity federation) | Access Key | `use_oidc = true` |\n-| Service Principal or User Assigned Managed Identity via OIDC (Workload identity federation) | Azure AD | `use_azuread_auth = true`, `use_oidc = true` |\n-| Managed Identity Principal | Access Key | `use_msi = true` |\n-| Managed Identity Principal | Azure AD | `use_azuread_auth = true`, `use_msi = true` |\n-| Service Principal via Client Secret | Access Key | `client_secret = \"...\"` |\n-| Service Principal via Client Secret | Azure AD | `use_azuread_auth = true`, `client_secret = \"...\"` |\n-| Service Principal via Client Certificate | Access Key | `client_certificate_path = \"...\"` |\n-| Service Principal via Client Certificate | Azure AD | `client_certificate_path = \"...`, `use_azuread_auth = true` |\n-| Access Key direct | Access Key | `access_key = \"...\"` |\n-| SAS Token direct | SAS Token | `sas_token = \"...\"` |\n+- OpenID Connect / Workload identity federation **(Recommended)**\n+  - User Assigned Managed Identity with Federated Credentials **(Recommended)**\n+  - Service Princial / App Registration with Federated Credentials\n+- User or System Assigned Managed Identity\n+  - User Assigned Managed Identity attached to Azure compute instance (agent / runner)\n+  - System Assigned Managed Identity attached to Azure compute instance (agent / runner)\n+- Service Principal / App Registration with Client Secret\n+- Service Principal / App REgistration with Client Certificate\n+- User Account with Azure CLI only (for local development cycle)\n \n-† There are sometimes more options needed for successful authentication. The variable shown is the one that triggers the backend to use a given authentication scenario. You can see examples of each option below.\n+These types can be supplied via inputs or via a pre-authenticated Azure CLI. We cover them in more depth in the following sections.\n \n--> Sensitive values should not be hardcoded into your configuration, and should instead be specified using environment variables or partial configuration flags in the `init` command of Terraform CLI.\n+### Data Plane URI\n \n-## Example Backend Configurations\n+In [most cases](https://learn.microsoft.com/en-us/azure/storage/common/storage-account-overview#standard-endpoints) this can simply be inferred from the `storage_account_name` and `container_name`. But if you are using the ['Azure DNS zone endpoints' feature](https://learn.microsoft.com/en-us/azure/storage/common/storage-account-overview#azure-dns-zone-endpoints-preview) the backend will need to lookup the data plane URI from the management plane. This requires the setting the `lookup_blob_endpoint` configuration option to `true` and the `Reader` role assignment on the storage account.\n \n-### Backend: Azure AD User via Azure CLI\n+## Azure Active Directory\n \n-This method is not suitable for automation since it only supports a User Principal. To check which tenant and subscription you are pointed to, run `az account show`.\n+This method requires a valid Azure Active Directory principal and a predictable storage account data plane URI.\n \n-*Connect to Storage Account with Access Key*\n+### Required Inputs\n \n-```hcl\n-terraform {\n-  backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"  # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n-    storage_account_name = \"abcd1234\"                      # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n-    container_name       = \"tfstate\"                       # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n-    key                  = \"prod.terraform.tfstate\"        # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-  }\n-}\n-```\n+The following inputs are always required for this method:\n \n-*Connect to Storage Account with Azure Active Directory authentication*\n+- `use_azuread_auth` - Set to `true` to use Azure Active Directory authentication to the storage account data plane. This can also be set via the `ARM_USE_AZUREAD` environment variable.\n+- `tenant_id` - The tenant ID of the Azure Active Directory principal is required to authenticate to the storage account data plane. If using Azure CLI, this can be inferred from the CLI session. This can also be set via the `ARM_TENANT_ID` environment variable.\n+- `storage_account_name` - The name of the storage account where the state file blob resides in.\n+- `container_name` - The name of the storage account container where the state file blob resides in.\n+- `key` - The name of the blob within the storage account container that the state file will be stored in.\n \n-```hcl\n-terraform {\n-  backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"  # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n-    storage_account_name = \"abcd1234\"                      # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n-    container_name       = \"tfstate\"                       # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n-    key                  = \"prod.terraform.tfstate\"        # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    use_azuread_auth     = true                            # Can also be set via `ARM_USE_AZUREAD` environment variable.\n-  }\n-}\n-```\n+### Optional Inputs\n+\n+These optional inputs apply when [looking up the data plane URI](#data-plane-uri) from the management plane. They are not required when the data plane URI can be inferred from the `storage_account_name` and `container_name`.\n+\n+- `lookup_blob_endpoint` - Set to `true` to lookup the storage account data plane URI from the management plane. This is required if you are using the 'Azure DNS zone endpoints' feature. Defaults to `false`. This value can also be sourced from the `ARM_USE_DNS_ZONE_ENDPOINT` environment variable.\n+- `subscription_id` - The subscription ID of the storage account is required to query the management plane. This is only required if `lookup_blob_endpoint` is set to `true`. If using Azure CLI, this can be inferred from the CLI session. This can also be set via the `ARM_SUBSCRIPTION_ID` environment variable.\n+- `resource_group_name` - The resource group name of the storage account is required to query the management plane. This is only required if `lookup_blob_endpoint` is set to `true`.\n+\n+### Storage Account Required Role Assignments\n+\n+The recommended data plane role assignments required for this method are either one of:\n+\n+- `Storage Blob Data Owner` on the storage account container (Recommended)\n+- `Storage Blob Data Contributor` on the storage account\n+\n+The recommended management plane role assignments required for this method are:\n \n-### Backend: Azure AD Service Principal or User Assigned Managed Identity via OIDC (Workload Identity Federation)\n+- `Reader` on the storage account *(Only required if `lookup_blob_endpoint` is set to `true`)*\n \n-You can use an App Registration (Service Principal) or a User Assigned Managed Identity to configure federated credentials. You must supply the Client ID of the principal.\n+### Azure Active Directory with OpenID Connect / Workload identity federation\n \n-*Connect to Storage Account with Access Key*\n+#### Required Inputs\n+\n+The following additional inputs are always required for this sub-type:\n+\n+- `use_oidc` - Set to `true` to use OpenID Connect / Workload identity federation to authenticate to the storage account data plane. This can also be set via the `ARM_USE_OIDC` environment variable.\n+- `client_id` - The client ID of the Azure Active Directory Service Principal / App Registration or User Assigned Managed Identity is required to authenticate to the storage account data plane. This can also be set via the `ARM_CLIENT_ID` environment variable.\n+\n+#### Example Configuration for GitHub\n+\n+With GitHub, the ID Token environment variables are automatically found, so no further settings are required.\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n+    use_oidc             = true                                    # Can also be set via `ARM_USE_OIDC` environment variable.\n+    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n+    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n     storage_account_name = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name       = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                  = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    use_oidc             = true                                    # Can also be set via `ARM_USE_OIDC` environment variable.\n-    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    subscription_id      = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n   }\n }\n ```\n \n-*Connect to Storage Account with Azure Active Directory authentication*\n+#### Example Configuration for Azure DevOps\n+\n+With Azure DevOps, the ID Token endpoint environment variables are automatically found, but you need to supply the service connection ID in `oidc_azure_service_connection_id`. If you are using the `AzureCLI` or `AzurePowerShell` tasks, the service connection ID is automatically set to the  `AZURESUBSCRIPTION_SERVICE_CONNECTION_ID` environment variable.\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n-    storage_account_name = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n-    container_name       = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n-    key                  = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    use_oidc             = true                                    # Can also be set via `ARM_USE_OIDC` environment variable.\n-    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    subscription_id      = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n-    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    use_oidc                         = true                                    # Can also be set via `ARM_USE_OIDC` environment variable.\n+    oidc_azure_service_connection_id = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_OIDC_AZURE_SERVICE_CONNECTION_ID` environment variable.\n+    use_azuread_auth                 = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    tenant_id                        = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n+    client_id                        = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n+    storage_account_name             = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n+    container_name                   = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n+    key                              = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n   }\n }\n ```\n \n-### Backend: Azure AD Managed Identity Principal\n+### Azure Active Directory with Compute Attached Managed Identity\n \n-You can use a User Assigned Managed Identity as well as a System Assigned Managed Identity on your agent / runner compute environment. However the backend does not currently support specifying the Client ID of the User Assigned Managed Identity, so you can only supply one per compute instance.\n+#### Required Inputs\n \n-*Connect to Storage Account with Access Key*\n+The following additional inputs are always required for this sub-type:\n \n-```hcl\n-terraform {\n-  backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n-    storage_account_name = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n-    container_name       = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n-    key                  = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    use_msi              = true                                    # Can also be set via `ARM_USE_MSI` environment variable.\n-    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    subscription_id      = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n-  }\n-}\n-```\n+- `use_msi` - Set to `true` to use the managed identity to authenticate to the storage account data plane. This can also be set via the `ARM_USE_MSI` environment variable.\n+\n+#### Optional Inputs\n+\n+The following additional inputs are optional for this sub-type:\n+\n+- `client_id` - The client ID of the User Assigned Managed Identity is required to authenticate to the storage account data plane. This is not required for System Assigned Managed Identity. This can also be set via the `ARM_CLIENT_ID` environment variable.\n \n-*Connect to Storage Account with Azure Active Directory authentication*\n+#### Example Configuration\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n+    use_msi              = true                                    # Can also be set via `ARM_USE_MSI` environment variable.\n+    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n+    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable. Not required for System Assigned Managed Identity.\n     storage_account_name = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name       = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                  = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    use_msi              = true                                    # Can also be set via `ARM_USE_MSI` environment variable.\n-    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    subscription_id      = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n-    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n   }\n }\n ```\n \n-### Backend: Azure AD Service Principal via Client Secret\n+### Azure Active Directory with Azure CLI\n \n-~> **Warning!** This method requires you to manage and rotate a secret. Consider using OIDC as a more secure approach.\n+You must have a pre-authenticated Azure CLI session using any supported method.\n \n-*Connect to Storage Account with Access Key*\n+#### Required Inputs\n+\n+The following additional inputs are always required for this sub-type:\n+\n+- `use_cli` - Set to `true` to use the Azure CLI session authenticate to the storage account data plane. This can also be set via the `ARM_USE_CLI` environment variable.\n+\n+#### Example Configuration\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n+    use_cli              = true                                    # Can also be set via `ARM_USE_CLI` environment variable.\n+    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable. Azure CLI will fallback to use the connected tenant ID if not supplied.\n     storage_account_name = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name       = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                  = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    client_secret        = \"************************************\"  # Can also be set via `ARM_CLIENT_SECRET` environment variable.\n-    subscription_id      = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n   }\n }\n ```\n \n-*Connect to Storage Account with Azure Active Directory authentication*\n+### Azure Active Directory with Client Secret\n+\n+We retain this method for backwards compatibility only, do not use it for any new workloads.\n+\n+~> **Warning!** This method requires you to manage and rotate a secret. Use OpenID Connect / Workload identity federation as a more secure approach.\n+\n+#### Required Inputs\n+\n+The following additional inputs are always required for this sub-type:\n+\n+- `client_id` - The client ID of the Azure Active Directory Service Principal / App Registration is required to authenticate to the storage account data plane. This can also be set via the `ARM_CLIENT_ID` environment variable.\n+- `client_secret` - The client secret of the Azure Active Directory Service Principal / App Registration is required to authenticate to the storage account data plane. This can also be set via the `ARM_CLIENT_SECRET` environment variable.\n+\n+#### Example Configuration\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n+    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n+    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n+    client_secret        = \"************************************\"  # Can also be set via `ARM_CLIENT_SECRET` environment variable.\n     storage_account_name = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name       = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                  = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    client_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    client_secret        = \"************************************\"  # Can also be set via `ARM_CLIENT_SECRET` environment variable.\n-    subscription_id      = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id            = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n-    use_azuread_auth     = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n   }\n }\n ```\n \n-### Backend: Azure AD Service Principal via Client Certificate\n+### Azure Active Directory with Client Certificate\n \n-~> **Warning!** This method requires you to manage and rotate a secret. Consider using OIDC as a more secure approach.\n+We retain this method for backwards compatibility only, do not use it for any new workloads.\n+\n+~> **Warning!** This method requires you to manage and rotate a secret. Use OpenID Connect / Workload identity federation as a more secure approach.\n+\n+#### Required Inputs\n+\n+The following additional inputs are always required for this sub-type:\n+\n+- `client_id` - The client ID of the Azure Active Directory Service Principal / App Registration is required to authenticate to the storage account data plane. This can also be set via the `ARM_CLIENT_ID` environment variable.\n+- `client_certificate_path` - The path to the client certificate bundle is required to authenticate to the storage account data plane. This can also be set via the `ARM_CLIENT_CERTIFICATE_PATH` environment variable.\n+- `client_certificate_password` - The password for the client certificate bundle is required to authenticate to the storage account data plane. This can also be set via the `ARM_CLIENT_CERTIFICATE_PASSWORD` environment variable.\n \n-*Connect to Storage Account with Access Key*\n+#### Example Configuration\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name         = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n-    storage_account_name        = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n-    container_name              = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n-    key                         = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n+    use_azuread_auth            = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n+    tenant_id                   = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n     client_id                   = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n     client_certificate_path     = \"/path/to/bundle.pfx\"                   # Can also be set via `ARM_CLIENT_CERTIFICATE_PATH` environment variable.\n     client_certificate_password = \"************************************\"  # Can also be set via `ARM_CLIENT_CERTIFICATE_PASSWORD` environment variable.\n-    subscription_id             = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id                   = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n-  }\n-}\n-```\n-\n-*Connect to Storage Account with Azure Active Directory authentication*\n-\n-```hcl\n-terraform {\n-  backend \"azurerm\" {\n-    resource_group_name         = \"StorageAccount-ResourceGroup\"          # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n     storage_account_name        = \"abcd1234\"                              # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name              = \"tfstate\"                               # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                         = \"prod.terraform.tfstate\"                # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    client_id                   = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_CLIENT_ID` environment variable.\n-    client_certificate_path     = \"/path/to/bundle.pfx\"                   # Can also be set via `ARM_CLIENT_CERTIFICATE_PATH` environment variable.\n-    client_certificate_password = \"************************************\"  # Can also be set via `ARM_CLIENT_CERTIFICATE_PASSWORD` environment variable.\n-    subscription_id             = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_SUBSCRIPTION_ID` environment variable.\n-    tenant_id                   = \"00000000-0000-0000-0000-000000000000\"  # Can also be set via `ARM_TENANT_ID` environment variable.\n-    use_azuread_auth            = true                                    # Can also be set via `ARM_USE_AZUREAD` environment variable.\n   }\n }\n ```\n \n-### Backend: Access Key Direct\n+## Access Key\n+\n+This method requires you find the Access Key for the storage account and supply it to the backend configuration.\n+\n+The Access Key is then used to directly authenticate to the storage account data plane.\n+\n+This method is retained for backwards compatibility, but we do not recommend it for new workloads.\n+\n+### Required Inputs\n+\n+The following inputs are always required for this method:\n+\n+- `access_key` - The Access Key of the storage account is required to authenticate to the storage account data plane. This can also be set via the `ARM_ACCESS_KEY` environment variable.\n+- `storage_account_name` - The name of the storage account where the state file blob resides in.\n+- `container_name` - The name of the storage account container where the state file blob resides in.\n+- `key` - The name of the blob within the storage account container that the state file will be stored in.\n+\n+### Storage Account Required Role Assignments\n+\n+There are no role assignments required on the storage account for this method as the Access Key is used to authenticate to the data plane.\n+\n+### Example Configuration\n \n ~> **Warning!** This method requires you to manage and rotate a secret. Consider using OIDC as a more secure approach.\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"             # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n+    access_key           = \"abcdefghijklmnopqrstuvwxyz0123456789...\"  # Can also be set via `ARM_ACCESS_KEY` environment variable.\n     storage_account_name = \"abcd1234\"                                 # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name       = \"tfstate\"                                  # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                  = \"prod.terraform.tfstate\"                   # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    access_key           = \"abcdefghijklmnopqrstuvwxyz0123456789...\"  # Can also be set via `ARM_ACCESS_KEY` environment variable.\n   }\n }\n ```\n \n-### Backend: SAS Token\n+## SAS Token\n+\n+This method requires you generate a SAS Token for the storage account container or blob and supply it to the backend configuration.\n+\n+The SAS Token is then used to directly authenticate to the storage account data plane.\n+\n+This method is retained for backwards compatibility, but we do not recommend it for new workloads.\n+\n+### Required Inputs\n+\n+The following inputs are always required for this method:\n+\n+- `sas_token` - The SAS Token for the storage account container or blob is required to authenticate to the storage account data plane. This can also be set via the `ARM_SAS_TOKEN` environment variable.\n+- `storage_account_name` - The name of the storage account where the state file blob resides in.\n+- `container_name` - The name of the storage account container where the state file blob resides in.\n+- `key` - The name of the blob within the storage account container that the state file will be stored in.\n+\n+### Storage Account Required Permissions\n+\n+The SAS Token requires `write` and `list` permissions on the container or blob.\n+\n+### Example Configuration\n \n ~> **Warning!** This method requires you to manage and rotate a secret. Consider using OIDC as a more secure approach.\n \n ```hcl\n terraform {\n   backend \"azurerm\" {\n-    resource_group_name  = \"StorageAccount-ResourceGroup\"             # Can be passed via `-backend-config=`\"resource_group_name=<resource group name>\"` in the `init` command.\n+    sas_token            = \"abcdefghijklmnopqrstuvwxyz0123456789...\"  # Can also be set via `ARM_SAS_TOKEN` environment variable.\n     storage_account_name = \"abcd1234\"                                 # Can be passed via `-backend-config=`\"storage_account_name=<storage account name>\"` in the `init` command.\n     container_name       = \"tfstate\"                                  # Can be passed via `-backend-config=`\"container_name=<container name>\"` in the `init` command.\n     key                  = \"prod.terraform.tfstate\"                   # Can be passed via `-backend-config=`\"key=<blob key name>\"` in the `init` command.\n-    sas_token            = \"abcdefghijklmnopqrstuvwxyz0123456789...\"  # Can also be set via `ARM_SAS_TOKEN` environment variable.\n   }\n }\n ```\n \n-## Example Data Source Configurations\n+## Access Key Lookup\n \n-### Data Source: Azure AD User Principal via Azure CLI\n+This method requires a valid Azure Active Directory principal and is a fallback for when Azure Active Directory authentication cannot be used on the storage account data plane.\n \n-This method is not suitable for automation since it only supports a User Principal. To check which tenant and subscription you are pointed to, run `az account show`.\n+This method queries the management plane to get the storage account Access Key and then uses that Access Key to authenticate to the storage account data plane. As such it requires elevated permissions on the storage account.",
        "comment_created_at": "2025-03-13T16:01:08+00:00",
        "comment_author": "BrianMMcClain",
        "comment_body": "```suggestion\r\nThis method queries the management plane to get the storage account Access Key and then uses that Access Key to authenticate to the storage account data plane. It requires elevated permissions on the storage account.\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1993999263",
    "pr_number": 36641,
    "pr_file": "website/docs/language/backend/azurerm.mdx",
    "created_at": "2025-03-13T17:23:45+00:00",
    "commented_code": "* `metadata_host` - (Optional) The Hostname of the Azure Metadata Service (for example `management.azure.com`), used to obtain the Cloud Environment when using a Custom Azure Environment. This can also be sourced from the `ARM_METADATA_HOSTNAME` Environment Variable.\n \n-* `snapshot` - (Optional) Should the Blob used to store the Terraform Statefile be snapshotted before use? Defaults to `false`. This value can also be sourced from the `ARM_SNAPSHOT` environment variable.\n-\n-* `use_cli` - (Optional) Should Azure CLI be used for authentication? Defaults to `false`. This value can also be sourced from the `ARM_USE_CLI` environment variable.\n-\n-***\n-\n-When authenticating using a Managed Identity (MSI) - the following fields are also supported:\n+* `lookup_blob_endpoint` - (Optional) Should the Storage Account Data Plane URI be looked up from the Management Plane? Defaults to `false`. This value can also be sourced from the `ARM_USE_DNS_ZONE_ENDPOINT` environment variable.\n \n-* `resource_group_name` - (Required) The Name of the Resource Group in which the Storage Account exists.\n-\n-* `msi_endpoint` - (Optional) The path to a custom Managed Service Identity endpoint which is automatically determined if not specified. This can also be sourced from the `ARM_MSI_ENDPOINT` environment variable.\n-\n-* `subscription_id` - (Optional) The Subscription ID in which the Storage Account exists. This can also be sourced from the `ARM_SUBSCRIPTION_ID` environment variable.\n-\n-* `tenant_id` - (Optional) The Tenant ID in which the Subscription exists. This can also be sourced from the `ARM_TENANT_ID` environment variable.\n-\n-* `use_msi` - (Optional) Should Managed Service Identity authentication be used? This can also be sourced from the `ARM_USE_MSI` environment variable.\n-\n-***\n-\n-When authenticating using a Service Principal with OpenID Connect (OIDC / Workload Identity Federation) - the following fields are also supported:\n-\n-* `ado_pipeline_service_connection_id` - (Optional) The Azure DevOps Pipeline Service Connection ID. This can also be sourced from the `ARM_ADO_PIPELINE_SERVICE_CONNECTION_ID` or `ARM_OIDC_AZURE_SERVICE_CONNECTION_ID` Environment Variables. The provider will look for values in this order and use the first it finds configured.\n-\n-* `oidc_request_url` - (Optional) The URL for the OIDC provider from which to request an ID token. This can also be sourced from the `ARM_OIDC_REQUEST_URL`, `ACTIONS_ID_TOKEN_REQUEST_URL` or `SYSTEM_OIDCREQUESTURI` Environment Variables. The provider will look for values in this order and use the first it finds configured.\n-\n-* `oidc_request_token` - (Optional) The bearer token for the request to the OIDC provider. This can also be sourced from the `ARM_OIDC_REQUEST_TOKEN`, `ACTIONS_ID_TOKEN_REQUEST_TOKEN` or `SYSTEM_ACCESSTOKEN` Environment Variables. The provider will look for values in this order and use the first it finds configured.\n-\n-* `oidc_token` - (Optional) The ID token when authenticating using OpenID Connect (OIDC). This can also be sourced from the `ARM_OIDC_TOKEN` environment variable.\n+* `snapshot` - (Optional) Should the Blob used to store the Terraform Statefile be snapshotted before use? Defaults to `false`. This value can also be sourced from the `ARM_SNAPSHOT` environment variable.\n \n-* `oidc_token_file_path` - (Optional) The path to a file containing an ID token when authenticating using OpenID Connect (OIDC). This can also be sourced from the `ARM_OIDC_TOKEN_FILE_PATH` environment variable.\n+* `tenant_id` - (Optional) The Tenant ID of the principal. This can also be sourced from the `ARM_TENANT_ID` environment variable.\n \n-* `use_oidc` - (Optional) Should OIDC authentication be used? This can also be sourced from the `ARM_USE_OIDC` environment variable.\n+* `use_azuread_auth` - (Optional) Whether Azure Active Directory Authentication for storage account data plane authentication. This can also be sourced from the `ARM_USE_AZUREAD` environment variable.\n \n-* `use_aks_workload_identity` (Optional) Should Azure AKS Workload Identity be used for Authentication? This can also be sourced from the `ARM_USE_AKS_WORKLOAD_IDENTITY` environment variable.\n+* `subscription_id` - (Optional) The Subscription ID of the storage account required for management plane authentication. This can also be sourced from the `ARM_SUBSCRIPTION_ID` environment variable.\n \n-***\n+* `resource_group_name` - (Optional) The Name of the Resource Group in which the Storage Account exists required for management plane authentication.\n \n-When authenticating using a SAS Token associated with the Storage Account - the following fields are also supported:\n+* `access_key` - (Optional) The Access Key used to authenticate to the storage account data plane with the [Direct Access Key](#direct-access-key) authenticaton method. This can also be sourced from the `ARM_ACCESS_KEY` environment variable.\n \n-* `sas_token` - (Optional) The SAS Token used to access the Blob Storage Account. This can also be sourced from the `ARM_SAS_TOKEN` environment variable.\n+* `sas_token` - (Optional) The SAS Token used to authenticate to the storage account data plane with the [Direct SAS Token](#direct-sas-token) authentication method. This can also be sourced from the `ARM_SAS_TOKEN` environment variable.\n \n-***\n+* `use_cli` - (Optional) Should the Azure CLI session be used for authentication to the storage account management and data plane? This value can also be sourced from the `ARM_USE_CLI` environment variable.\n \n-When authenticating using the Storage Account's Access Key - the following fields are also supported:\n+* `use_oidc` - (Optional) Should OpenID Connect / Workload identity federation authentication be used for authentication to the storage account management and data plane? This can also be sourced from the `ARM_USE_OIDC` environment variable.\n \n-* `access_key` - (Optional) The Access Key used to access the Blob Storage Account. This can also be sourced from the `ARM_ACCESS_KEY` environment variable.\n+* `client_id` - (Optional) The Client ID of the Azure Active Directory Principal required for some authentication sub-types. This can also be sourced from the `ARM_CLIENT_ID` environment variable.\n \n-***\n+* `ado_pipeline_service_connection_id` - (Optional) The Azure DevOps Pipeline Service Connection ID required for Open ID Connect / Workload identity federation authentication with Azure DevOps. This can also be sourced from the `ARM_ADO_PIPELINE_SERVICE_CONNECTION_ID` or `ARM_OIDC_AZURE_SERVICE_CONNECTION_ID` Environment Variables. The provider will look for values in this order and use the first it finds configured.\n \n-When authenticating using an Azure AD Service Principal, you have the option to use Azure Active Directory authentication for the storage account (rather than by an Access Key or SAS Token) - the following fields are also supported:\n+* `oidc_request_url` - (Optional) The URL for the Open ID Connect provider from which to request an ID token. This is only required for advanced scenarios or third party integrations. This can also be sourced from the `ARM_OIDC_REQUEST_URL`, `ACTIONS_ID_TOKEN_REQUEST_URL` or `SYSTEM_OIDCREQUESTURI` Environment Variables. The provider will look for values in this order and use the first it finds configured.",
    "repo_full_name": "hashicorp/terraform",
    "discussion_comments": [
      {
        "comment_id": "1993999263",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36641,
        "pr_file": "website/docs/language/backend/azurerm.mdx",
        "discussion_id": "1993999263",
        "commented_code": "@@ -518,69 +526,43 @@ The following configuration options are supported:\n \n * `metadata_host` - (Optional) The Hostname of the Azure Metadata Service (for example `management.azure.com`), used to obtain the Cloud Environment when using a Custom Azure Environment. This can also be sourced from the `ARM_METADATA_HOSTNAME` Environment Variable.\n \n-* `snapshot` - (Optional) Should the Blob used to store the Terraform Statefile be snapshotted before use? Defaults to `false`. This value can also be sourced from the `ARM_SNAPSHOT` environment variable.\n-\n-* `use_cli` - (Optional) Should Azure CLI be used for authentication? Defaults to `false`. This value can also be sourced from the `ARM_USE_CLI` environment variable.\n-\n-***\n-\n-When authenticating using a Managed Identity (MSI) - the following fields are also supported:\n+* `lookup_blob_endpoint` - (Optional) Should the Storage Account Data Plane URI be looked up from the Management Plane? Defaults to `false`. This value can also be sourced from the `ARM_USE_DNS_ZONE_ENDPOINT` environment variable.\n \n-* `resource_group_name` - (Required) The Name of the Resource Group in which the Storage Account exists.\n-\n-* `msi_endpoint` - (Optional) The path to a custom Managed Service Identity endpoint which is automatically determined if not specified. This can also be sourced from the `ARM_MSI_ENDPOINT` environment variable.\n-\n-* `subscription_id` - (Optional) The Subscription ID in which the Storage Account exists. This can also be sourced from the `ARM_SUBSCRIPTION_ID` environment variable.\n-\n-* `tenant_id` - (Optional) The Tenant ID in which the Subscription exists. This can also be sourced from the `ARM_TENANT_ID` environment variable.\n-\n-* `use_msi` - (Optional) Should Managed Service Identity authentication be used? This can also be sourced from the `ARM_USE_MSI` environment variable.\n-\n-***\n-\n-When authenticating using a Service Principal with OpenID Connect (OIDC / Workload Identity Federation) - the following fields are also supported:\n-\n-* `ado_pipeline_service_connection_id` - (Optional) The Azure DevOps Pipeline Service Connection ID. This can also be sourced from the `ARM_ADO_PIPELINE_SERVICE_CONNECTION_ID` or `ARM_OIDC_AZURE_SERVICE_CONNECTION_ID` Environment Variables. The provider will look for values in this order and use the first it finds configured.\n-\n-* `oidc_request_url` - (Optional) The URL for the OIDC provider from which to request an ID token. This can also be sourced from the `ARM_OIDC_REQUEST_URL`, `ACTIONS_ID_TOKEN_REQUEST_URL` or `SYSTEM_OIDCREQUESTURI` Environment Variables. The provider will look for values in this order and use the first it finds configured.\n-\n-* `oidc_request_token` - (Optional) The bearer token for the request to the OIDC provider. This can also be sourced from the `ARM_OIDC_REQUEST_TOKEN`, `ACTIONS_ID_TOKEN_REQUEST_TOKEN` or `SYSTEM_ACCESSTOKEN` Environment Variables. The provider will look for values in this order and use the first it finds configured.\n-\n-* `oidc_token` - (Optional) The ID token when authenticating using OpenID Connect (OIDC). This can also be sourced from the `ARM_OIDC_TOKEN` environment variable.\n+* `snapshot` - (Optional) Should the Blob used to store the Terraform Statefile be snapshotted before use? Defaults to `false`. This value can also be sourced from the `ARM_SNAPSHOT` environment variable.\n \n-* `oidc_token_file_path` - (Optional) The path to a file containing an ID token when authenticating using OpenID Connect (OIDC). This can also be sourced from the `ARM_OIDC_TOKEN_FILE_PATH` environment variable.\n+* `tenant_id` - (Optional) The Tenant ID of the principal. This can also be sourced from the `ARM_TENANT_ID` environment variable.\n \n-* `use_oidc` - (Optional) Should OIDC authentication be used? This can also be sourced from the `ARM_USE_OIDC` environment variable.\n+* `use_azuread_auth` - (Optional) Whether Azure Active Directory Authentication for storage account data plane authentication. This can also be sourced from the `ARM_USE_AZUREAD` environment variable.\n \n-* `use_aks_workload_identity` (Optional) Should Azure AKS Workload Identity be used for Authentication? This can also be sourced from the `ARM_USE_AKS_WORKLOAD_IDENTITY` environment variable.\n+* `subscription_id` - (Optional) The Subscription ID of the storage account required for management plane authentication. This can also be sourced from the `ARM_SUBSCRIPTION_ID` environment variable.\n \n-***\n+* `resource_group_name` - (Optional) The Name of the Resource Group in which the Storage Account exists required for management plane authentication.\n \n-When authenticating using a SAS Token associated with the Storage Account - the following fields are also supported:\n+* `access_key` - (Optional) The Access Key used to authenticate to the storage account data plane with the [Direct Access Key](#direct-access-key) authenticaton method. This can also be sourced from the `ARM_ACCESS_KEY` environment variable.\n \n-* `sas_token` - (Optional) The SAS Token used to access the Blob Storage Account. This can also be sourced from the `ARM_SAS_TOKEN` environment variable.\n+* `sas_token` - (Optional) The SAS Token used to authenticate to the storage account data plane with the [Direct SAS Token](#direct-sas-token) authentication method. This can also be sourced from the `ARM_SAS_TOKEN` environment variable.\n \n-***\n+* `use_cli` - (Optional) Should the Azure CLI session be used for authentication to the storage account management and data plane? This value can also be sourced from the `ARM_USE_CLI` environment variable.\n \n-When authenticating using the Storage Account's Access Key - the following fields are also supported:\n+* `use_oidc` - (Optional) Should OpenID Connect / Workload identity federation authentication be used for authentication to the storage account management and data plane? This can also be sourced from the `ARM_USE_OIDC` environment variable.\n \n-* `access_key` - (Optional) The Access Key used to access the Blob Storage Account. This can also be sourced from the `ARM_ACCESS_KEY` environment variable.\n+* `client_id` - (Optional) The Client ID of the Azure Active Directory Principal required for some authentication sub-types. This can also be sourced from the `ARM_CLIENT_ID` environment variable.\n \n-***\n+* `ado_pipeline_service_connection_id` - (Optional) The Azure DevOps Pipeline Service Connection ID required for Open ID Connect / Workload identity federation authentication with Azure DevOps. This can also be sourced from the `ARM_ADO_PIPELINE_SERVICE_CONNECTION_ID` or `ARM_OIDC_AZURE_SERVICE_CONNECTION_ID` Environment Variables. The provider will look for values in this order and use the first it finds configured.\n \n-When authenticating using an Azure AD Service Principal, you have the option to use Azure Active Directory authentication for the storage account (rather than by an Access Key or SAS Token) - the following fields are also supported:\n+* `oidc_request_url` - (Optional) The URL for the Open ID Connect provider from which to request an ID token. This is only required for advanced scenarios or third party integrations. This can also be sourced from the `ARM_OIDC_REQUEST_URL`, `ACTIONS_ID_TOKEN_REQUEST_URL` or `SYSTEM_OIDCREQUESTURI` Environment Variables. The provider will look for values in this order and use the first it finds configured.",
        "comment_created_at": "2025-03-13T17:23:45+00:00",
        "comment_author": "BrianMMcClain",
        "comment_body": "```suggestion\r\n* `oidc_request_url` - (Optional) The URL for the Open ID Connect provider from which to request an ID token. This is only required for advanced scenarios or third party integrations. This can also be sourced from the `ARM_OIDC_REQUEST_URL`, `ACTIONS_ID_TOKEN_REQUEST_URL` or `SYSTEM_OIDCREQUESTURI` environment variables. The provider will look for values in this order and use the first it finds configured.\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1977643085",
    "pr_number": 36605,
    "pr_file": "website/docs/language/resources/ephemeral/index.mdx",
    "created_at": "2025-03-03T14:45:30+00:00",
    "commented_code": "<CodeBlockConfig highlight=\"11\">\n \n ```hcl\n-ephemeral \"random\" \"password\" {\n+ephemeral \"random_password\" \"db_password\" {",
    "repo_full_name": "hashicorp/terraform",
    "discussion_comments": [
      {
        "comment_id": "1977643085",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36605,
        "pr_file": "website/docs/language/resources/ephemeral/index.mdx",
        "discussion_id": "1977643085",
        "commented_code": "@@ -44,21 +44,43 @@ Use write-only arguments to securely pass temporary values to resources during a\n <CodeBlockConfig highlight=\"11\">\n \n ```hcl\n-ephemeral \"random\" \"password\" {\n+ephemeral \"random_password\" \"db_password\" {",
        "comment_created_at": "2025-03-03T14:45:30+00:00",
        "comment_author": "BrianMMcClain",
        "comment_body": "I think we need to include the `override_special` argument otherwise this could potentially generate an invalid RDS password\r\n\r\n> Only printable ASCII characters besides '/', '@', '\"', ' ' may be used.\r\n\r\nI think this should be valid:\r\n\r\n```\r\noverride_special = \"!#$%&*()-_=+[]{}<>:?\"\r\n```\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "1978151856",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36605,
        "pr_file": "website/docs/language/resources/ephemeral/index.mdx",
        "discussion_id": "1977643085",
        "commented_code": "@@ -44,21 +44,43 @@ Use write-only arguments to securely pass temporary values to resources during a\n <CodeBlockConfig highlight=\"11\">\n \n ```hcl\n-ephemeral \"random\" \"password\" {\n+ephemeral \"random_password\" \"db_password\" {",
        "comment_created_at": "2025-03-03T20:29:38+00:00",
        "comment_author": "bschaatsbergen",
        "comment_body": "Added, thanks",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1936491304",
    "pr_number": 36258,
    "pr_file": "website/docs/language/backend/azurerm.mdx",
    "created_at": "2025-01-31T00:19:41+00:00",
    "commented_code": "* `use_oidc` - (Optional) Should OIDC authentication be used? This can also be sourced from the `ARM_USE_OIDC` environment variable.\n \n+* `use_aks_workload_identity` (Optional) Should Azure AKS Workload Identity be used for Authentication? This can also be sourced from the `ARM_USE_AKS_WORKLOAD_IDENTITY` environment variable.",
    "repo_full_name": "hashicorp/terraform",
    "discussion_comments": [
      {
        "comment_id": "1936491304",
        "repo_full_name": "hashicorp/terraform",
        "pr_number": 36258,
        "pr_file": "website/docs/language/backend/azurerm.mdx",
        "discussion_id": "1936491304",
        "commented_code": "@@ -552,6 +550,8 @@ When authenticating using a Service Principal with OpenID Connect (OIDC / Worklo\n \n * `use_oidc` - (Optional) Should OIDC authentication be used? This can also be sourced from the `ARM_USE_OIDC` environment variable.\n \n+* `use_aks_workload_identity` (Optional) Should Azure AKS Workload Identity be used for Authentication? This can also be sourced from the `ARM_USE_AKS_WORKLOAD_IDENTITY` environment variable.",
        "comment_created_at": "2025-01-31T00:19:41+00:00",
        "comment_author": "trujillo-adam",
        "comment_body": "```suggestion\r\n- `use_aks_workload_identity`: (Optional) Enables Terraform to use the Azure AKS workload identity for authentication. You can  set the `ARM_USE_AKS_WORKLOAD_IDENTITY` environment variable to configure this option.\r\n```",
        "pr_file_module": null
      }
    ]
  }
]