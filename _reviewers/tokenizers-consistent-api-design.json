[
  {
    "discussion_id": "768546672",
    "pr_number": 841,
    "pr_file": "bindings/python/py_src/tokenizers/__init__.pyi",
    "created_at": "2021-12-14T10:54:00+00:00",
    "commented_code": ":obj:`List[str]`: The list of tokens\n         \"\"\"\n         pass\n-    def truncate(self, max_length, stride=0):\n+    def truncate(self, max_length, stride=0, left=True):",
    "repo_full_name": "huggingface/tokenizers",
    "discussion_comments": [
      {
        "comment_id": "768546672",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 841,
        "pr_file": "bindings/python/py_src/tokenizers/__init__.pyi",
        "discussion_id": "768546672",
        "commented_code": "@@ -286,7 +286,7 @@ class Encoding:\n             :obj:`List[str]`: The list of tokens\n         \"\"\"\n         pass\n-    def truncate(self, max_length, stride=0):\n+    def truncate(self, max_length, stride=0, left=True):",
        "comment_created_at": "2021-12-14T10:54:00+00:00",
        "comment_author": "n1t0",
        "comment_body": "Same here. Also, shouldn't the default value be \"right\" (false here)?",
        "pr_file_module": null
      },
      {
        "comment_id": "768648661",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 841,
        "pr_file": "bindings/python/py_src/tokenizers/__init__.pyi",
        "discussion_id": "768546672",
        "commented_code": "@@ -286,7 +286,7 @@ class Encoding:\n             :obj:`List[str]`: The list of tokens\n         \"\"\"\n         pass\n-    def truncate(self, max_length, stride=0):\n+    def truncate(self, max_length, stride=0, left=True):",
        "comment_created_at": "2021-12-14T13:10:47+00:00",
        "comment_author": "McPatate",
        "comment_body": "The current implementation provides left truncation, so to avoid breaking changes I'd put the  default value to `\"left\"` or here `left=True`",
        "pr_file_module": null
      },
      {
        "comment_id": "768655547",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 841,
        "pr_file": "bindings/python/py_src/tokenizers/__init__.pyi",
        "discussion_id": "768546672",
        "commented_code": "@@ -286,7 +286,7 @@ class Encoding:\n             :obj:`List[str]`: The list of tokens\n         \"\"\"\n         pass\n-    def truncate(self, max_length, stride=0):\n+    def truncate(self, max_length, stride=0, left=True):",
        "comment_created_at": "2021-12-14T13:19:40+00:00",
        "comment_author": "n1t0",
        "comment_body": "See, that's where I'm confused (and why I'm wondering about `direction`). For me the current implementation only supports truncation on the right (namely at the end of the different vecs), and we want to add truncation on the left (see #779 also). ",
        "pr_file_module": null
      },
      {
        "comment_id": "769910933",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 841,
        "pr_file": "bindings/python/py_src/tokenizers/__init__.pyi",
        "discussion_id": "768546672",
        "commented_code": "@@ -286,7 +286,7 @@ class Encoding:\n             :obj:`List[str]`: The list of tokens\n         \"\"\"\n         pass\n-    def truncate(self, max_length, stride=0):\n+    def truncate(self, max_length, stride=0, left=True):",
        "comment_created_at": "2021-12-15T18:50:24+00:00",
        "comment_author": "McPatate",
        "comment_body": "I see what you mean, I was thinking about it as \"start truncate from the right of the encoding\" or \"start truncate from the left\". Either make sense to me, I'll go with your way.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "517940487",
    "pr_number": 506,
    "pr_file": "bindings/python/py_src/tokenizers/__init__.pyi",
    "created_at": "2020-11-05T10:20:46+00:00",
    "commented_code": "\"\"\"\n         pass\n     @property\n+    def n_sequences(self) -> int:\n+        \"\"\"The number of sequences represented\n+\n+        Returns:\n+            :obj:`int`: The number of sequences in this :class:`~tokenizers.Encoding`\n+        \"\"\"\n+        pass\n+    def set_sequence_id(self, sequence_index: int):",
    "repo_full_name": "huggingface/tokenizers",
    "discussion_comments": [
      {
        "comment_id": "517940487",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 506,
        "pr_file": "bindings/python/py_src/tokenizers/__init__.pyi",
        "discussion_id": "517940487",
        "commented_code": "@@ -275,6 +275,21 @@ class Encoding:\n         \"\"\"\n         pass\n     @property\n+    def n_sequences(self) -> int:\n+        \"\"\"The number of sequences represented\n+\n+        Returns:\n+            :obj:`int`: The number of sequences in this :class:`~tokenizers.Encoding`\n+        \"\"\"\n+        pass\n+    def set_sequence_id(self, sequence_index: int):",
        "comment_created_at": "2020-11-05T10:20:46+00:00",
        "comment_author": "Narsil",
        "comment_body": "Is that really something we need to expose ?",
        "pr_file_module": null
      },
      {
        "comment_id": "518194684",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 506,
        "pr_file": "bindings/python/py_src/tokenizers/__init__.pyi",
        "discussion_id": "517940487",
        "commented_code": "@@ -275,6 +275,21 @@ class Encoding:\n         \"\"\"\n         pass\n     @property\n+    def n_sequences(self) -> int:\n+        \"\"\"The number of sequences represented\n+\n+        Returns:\n+            :obj:`int`: The number of sequences in this :class:`~tokenizers.Encoding`\n+        \"\"\"\n+        pass\n+    def set_sequence_id(self, sequence_index: int):",
        "comment_created_at": "2020-11-05T16:40:47+00:00",
        "comment_author": "n1t0",
        "comment_body": "Yes, it's just for consistency. The user can manually merge multiple `Encoding`s, and this allows to manually set the sequence id for each of them.",
        "pr_file_module": null
      }
    ]
  }
]