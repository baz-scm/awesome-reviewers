[
  {
    "discussion_id": "1057173816",
    "pr_number": 1136,
    "pr_file": "bindings/python/py_src/tokenizers/implementations/char_level_bpe.py",
    "created_at": "2022-12-26T10:07:45+00:00",
    "commented_code": ")\n             )\n         else:\n-            tokenizer = Tokenizer(BPE())\n+            tokenizer = Tokenizer(BPE(unk_token=str(unk_token),))",
    "repo_full_name": "huggingface/tokenizers",
    "discussion_comments": [
      {
        "comment_id": "1057173816",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 1136,
        "pr_file": "bindings/python/py_src/tokenizers/implementations/char_level_bpe.py",
        "discussion_id": "1057173816",
        "commented_code": "@@ -45,7 +45,7 @@ def __init__(\n                 )\n             )\n         else:\n-            tokenizer = Tokenizer(BPE())\n+            tokenizer = Tokenizer(BPE(unk_token=str(unk_token),))",
        "comment_created_at": "2022-12-26T10:07:45+00:00",
        "comment_author": "Narsil",
        "comment_body": "```suggestion\r\n            tokenizer = Tokenizer(BPE(unk_token=str(unk_token), dropout=dropout, end_of_word_suffix=suffx))\r\n```\r\n\r\nno ?",
        "pr_file_module": null
      },
      {
        "comment_id": "1057183938",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 1136,
        "pr_file": "bindings/python/py_src/tokenizers/implementations/char_level_bpe.py",
        "discussion_id": "1057173816",
        "commented_code": "@@ -45,7 +45,7 @@ def __init__(\n                 )\n             )\n         else:\n-            tokenizer = Tokenizer(BPE())\n+            tokenizer = Tokenizer(BPE(unk_token=str(unk_token),))",
        "comment_created_at": "2022-12-26T10:36:17+00:00",
        "comment_author": "SeongBeomLEE",
        "comment_body": "Yes \ud83d\udc4d",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "519929017",
    "pr_number": 508,
    "pr_file": "bindings/python/py_src/tokenizers/viz/visualizer.py",
    "created_at": "2020-11-09T16:07:44+00:00",
    "commented_code": "+import itertools\n+from typing import List, Optional, Tuple, Dict, Callable, Any\n+from tokenizers import Tokenizer, Encoding\n+from tokenizers.viz.templates import HTMLBody\n+from tokenizers.viz.viztypes import (\n+    AnnotationList,\n+    PartialIntList,\n+    CharState,\n+    Annotation,\n+)\n+\n+\n+class EncodingVisualizer:\n+    def __init__(\n+        self,\n+        tokenizer: Tokenizer,\n+        default_to_notebook: bool = False,\n+        annotation_converter: Optional[Callable[[Any], Annotation]] = None,\n+    ):\n+        \"\"\"\n+\n+        :param tokenizer: A tokenizer\n+        :param default_to_notebook: Whether to render html output in a notebook by default\n+        :param annotation_converter: An optional (lambda) function that takes an annotation in any format and returns\n+               an Annotation object\n+        \"\"\"\n+        self.tokenizer = tokenizer\n+        self.default_to_notebook = default_to_notebook\n+        self.annotation_coverter = annotation_converter\n+        pass\n+\n+    def __call__(\n+        self,\n+        text: str,\n+        annotations: AnnotationList = [],\n+        default_to_notebook: Optional[bool] = None,\n+    ) -> Optional[str]:\n+        \"\"\"\n+\n+        :param text: The text to tokenize\n+        :param annotations:  An optional list of annotations of the text\n+        :param default_to_notebook: If True, will render the html in a notebook. Otherwise returns an html string. Defaults (False)\n+        :return: The raw html or None\n+        \"\"\"\n+        final_default_to_notebook = self.default_to_notebook\n+        if default_to_notebook is not None:\n+            final_default_to_notebook = default_to_notebook\n+        if final_default_to_notebook:\n+            try:\n+                from IPython.core.display import display, HTML\n+            except ImportError as e:\n+                raise Exception(\n+                    \"We coulndt import Ipython utils for html display. Are you running in a notebook ? \"\n+                )\n+        if self.annotation_coverter is not None:\n+            annotations = list(map(self.annotation_coverter, annotations))\n+        encoding = self.tokenizer.encode(text)\n+        html = EncodingVisualizer.__make_html(text, encoding, annotations)\n+        if final_default_to_notebook:\n+            display(HTML(html))\n+        else:\n+            return html\n+\n+    @staticmethod\n+    def calculate_label_colors(annotations: AnnotationList) -> Dict[str, str]:\n+        \"\"\"\n+        Generates a color pallete for all the labels in a given set of annotations\n+        :param annotations: A list of annotations\n+        :return: A dictionary mapping a label name to it's hsl color\n+        \"\"\"\n+        if len(annotations) == 0:\n+            return {}\n+        labels = set(map(lambda x: x.label, annotations))\n+        num_labels = len(labels)\n+        h_step = int(255 / num_labels)\n+        if h_step < 20:\n+            h_step = 20\n+        s = 32\n+        l = 64\n+        h = 10\n+        colors = {}\n+\n+        for label in sorted(\n+            labels\n+        ):  # sort so we always get the same colors for a given set of labels\n+            colors[label] = f\"hsl({h},{s}%,{l}%\"\n+            h += h_step\n+        return colors\n+\n+    @staticmethod\n+    def consecutive_chars_to_html(\n+        consecutive_chars_list: List[CharState],\n+        text: str,\n+        encoding: Encoding,\n+    ):\n+        \"\"\"\n+        Converts a list of \"consecutive chars\" into a single HTML element.\n+        Chars are consecutive if they fall under the same word, token and annotation.\n+        The CharState class is a named tuple with a \"partition_key\" method that makes it easy to compare if two chars\n+        are consecutive.\n+\n+        :param consecutive_chars_list: A list of CharStates that have been grouped together\n+        :param text:  The original text being processed\n+        :param encoding:  The encoding of t\n+        :return:\n+        \"\"\"\n+        first = consecutive_chars_list[0]\n+        if first.char_ix is None:\n+            # its a special token\n+            stoken = encoding.tokens[first.token_ix]\n+            # special tokens are represented as empty spans. We use the data attribute and css magic to display it\n+            return f'<span class=\"special-token\" data-stoken={stoken}></span>'\n+        # We're not in a special token so this group has a start and end.\n+        last = consecutive_chars_list[-1]\n+        start = first.char_ix\n+        end = last.char_ix + 1\n+        span_text = text[start:end]\n+        css_classes = []  # What css classes will we apply on the resulting span\n+        data_items = {}  # What data attributes will we apply on the result span\n+        if first.token_ix is not None:\n+            # We can either be in a token or not (e.g. in white space)\n+            css_classes.append(\"token\")\n+            if first.token_ix % 2:\n+                # We use this to color alternating tokens.\n+                # A token might be split by an annotation that ends in the middle of it, so this lets us visually\n+                # indicate a consecutive token despite its possible splitting in the html markup\n+                css_classes.append(\"odd-token\")\n+            else:\n+                # Like above, but a different color so we can see the tokens alternate\n+                css_classes.append(\"even-token\")\n+            if encoding.tokens[first.token_ix] == \"[UNK]\":",
    "repo_full_name": "huggingface/tokenizers",
    "discussion_comments": [
      {
        "comment_id": "519929017",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 508,
        "pr_file": "bindings/python/py_src/tokenizers/viz/visualizer.py",
        "discussion_id": "519929017",
        "commented_code": "@@ -0,0 +1,277 @@\n+import itertools\n+from typing import List, Optional, Tuple, Dict, Callable, Any\n+from tokenizers import Tokenizer, Encoding\n+from tokenizers.viz.templates import HTMLBody\n+from tokenizers.viz.viztypes import (\n+    AnnotationList,\n+    PartialIntList,\n+    CharState,\n+    Annotation,\n+)\n+\n+\n+class EncodingVisualizer:\n+    def __init__(\n+        self,\n+        tokenizer: Tokenizer,\n+        default_to_notebook: bool = False,\n+        annotation_converter: Optional[Callable[[Any], Annotation]] = None,\n+    ):\n+        \"\"\"\n+\n+        :param tokenizer: A tokenizer\n+        :param default_to_notebook: Whether to render html output in a notebook by default\n+        :param annotation_converter: An optional (lambda) function that takes an annotation in any format and returns\n+               an Annotation object\n+        \"\"\"\n+        self.tokenizer = tokenizer\n+        self.default_to_notebook = default_to_notebook\n+        self.annotation_coverter = annotation_converter\n+        pass\n+\n+    def __call__(\n+        self,\n+        text: str,\n+        annotations: AnnotationList = [],\n+        default_to_notebook: Optional[bool] = None,\n+    ) -> Optional[str]:\n+        \"\"\"\n+\n+        :param text: The text to tokenize\n+        :param annotations:  An optional list of annotations of the text\n+        :param default_to_notebook: If True, will render the html in a notebook. Otherwise returns an html string. Defaults (False)\n+        :return: The raw html or None\n+        \"\"\"\n+        final_default_to_notebook = self.default_to_notebook\n+        if default_to_notebook is not None:\n+            final_default_to_notebook = default_to_notebook\n+        if final_default_to_notebook:\n+            try:\n+                from IPython.core.display import display, HTML\n+            except ImportError as e:\n+                raise Exception(\n+                    \"We coulndt import Ipython utils for html display. Are you running in a notebook ? \"\n+                )\n+        if self.annotation_coverter is not None:\n+            annotations = list(map(self.annotation_coverter, annotations))\n+        encoding = self.tokenizer.encode(text)\n+        html = EncodingVisualizer.__make_html(text, encoding, annotations)\n+        if final_default_to_notebook:\n+            display(HTML(html))\n+        else:\n+            return html\n+\n+    @staticmethod\n+    def calculate_label_colors(annotations: AnnotationList) -> Dict[str, str]:\n+        \"\"\"\n+        Generates a color pallete for all the labels in a given set of annotations\n+        :param annotations: A list of annotations\n+        :return: A dictionary mapping a label name to it's hsl color\n+        \"\"\"\n+        if len(annotations) == 0:\n+            return {}\n+        labels = set(map(lambda x: x.label, annotations))\n+        num_labels = len(labels)\n+        h_step = int(255 / num_labels)\n+        if h_step < 20:\n+            h_step = 20\n+        s = 32\n+        l = 64\n+        h = 10\n+        colors = {}\n+\n+        for label in sorted(\n+            labels\n+        ):  # sort so we always get the same colors for a given set of labels\n+            colors[label] = f\"hsl({h},{s}%,{l}%\"\n+            h += h_step\n+        return colors\n+\n+    @staticmethod\n+    def consecutive_chars_to_html(\n+        consecutive_chars_list: List[CharState],\n+        text: str,\n+        encoding: Encoding,\n+    ):\n+        \"\"\"\n+        Converts a list of \"consecutive chars\" into a single HTML element.\n+        Chars are consecutive if they fall under the same word, token and annotation.\n+        The CharState class is a named tuple with a \"partition_key\" method that makes it easy to compare if two chars\n+        are consecutive.\n+\n+        :param consecutive_chars_list: A list of CharStates that have been grouped together\n+        :param text:  The original text being processed\n+        :param encoding:  The encoding of t\n+        :return:\n+        \"\"\"\n+        first = consecutive_chars_list[0]\n+        if first.char_ix is None:\n+            # its a special token\n+            stoken = encoding.tokens[first.token_ix]\n+            # special tokens are represented as empty spans. We use the data attribute and css magic to display it\n+            return f'<span class=\"special-token\" data-stoken={stoken}></span>'\n+        # We're not in a special token so this group has a start and end.\n+        last = consecutive_chars_list[-1]\n+        start = first.char_ix\n+        end = last.char_ix + 1\n+        span_text = text[start:end]\n+        css_classes = []  # What css classes will we apply on the resulting span\n+        data_items = {}  # What data attributes will we apply on the result span\n+        if first.token_ix is not None:\n+            # We can either be in a token or not (e.g. in white space)\n+            css_classes.append(\"token\")\n+            if first.token_ix % 2:\n+                # We use this to color alternating tokens.\n+                # A token might be split by an annotation that ends in the middle of it, so this lets us visually\n+                # indicate a consecutive token despite its possible splitting in the html markup\n+                css_classes.append(\"odd-token\")\n+            else:\n+                # Like above, but a different color so we can see the tokens alternate\n+                css_classes.append(\"even-token\")\n+            if encoding.tokens[first.token_ix] == \"[UNK]\":",
        "comment_created_at": "2020-11-09T16:07:44+00:00",
        "comment_author": "n1t0",
        "comment_body": "This won't work with a lot of tokenizers that do not use `[UNK]` as their unknown token. Unfortunately there is no easy way at the moment to get the unk token directly from the tokenizer, but maybe we can use something a bit more large. Maybe something like the regex `/^(.{1}\\b)?unk(\\b.{1})?$/i` would work for now (https://regex101.com/r/zh0He9/1/)",
        "pr_file_module": null
      },
      {
        "comment_id": "520103237",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 508,
        "pr_file": "bindings/python/py_src/tokenizers/viz/visualizer.py",
        "discussion_id": "519929017",
        "commented_code": "@@ -0,0 +1,277 @@\n+import itertools\n+from typing import List, Optional, Tuple, Dict, Callable, Any\n+from tokenizers import Tokenizer, Encoding\n+from tokenizers.viz.templates import HTMLBody\n+from tokenizers.viz.viztypes import (\n+    AnnotationList,\n+    PartialIntList,\n+    CharState,\n+    Annotation,\n+)\n+\n+\n+class EncodingVisualizer:\n+    def __init__(\n+        self,\n+        tokenizer: Tokenizer,\n+        default_to_notebook: bool = False,\n+        annotation_converter: Optional[Callable[[Any], Annotation]] = None,\n+    ):\n+        \"\"\"\n+\n+        :param tokenizer: A tokenizer\n+        :param default_to_notebook: Whether to render html output in a notebook by default\n+        :param annotation_converter: An optional (lambda) function that takes an annotation in any format and returns\n+               an Annotation object\n+        \"\"\"\n+        self.tokenizer = tokenizer\n+        self.default_to_notebook = default_to_notebook\n+        self.annotation_coverter = annotation_converter\n+        pass\n+\n+    def __call__(\n+        self,\n+        text: str,\n+        annotations: AnnotationList = [],\n+        default_to_notebook: Optional[bool] = None,\n+    ) -> Optional[str]:\n+        \"\"\"\n+\n+        :param text: The text to tokenize\n+        :param annotations:  An optional list of annotations of the text\n+        :param default_to_notebook: If True, will render the html in a notebook. Otherwise returns an html string. Defaults (False)\n+        :return: The raw html or None\n+        \"\"\"\n+        final_default_to_notebook = self.default_to_notebook\n+        if default_to_notebook is not None:\n+            final_default_to_notebook = default_to_notebook\n+        if final_default_to_notebook:\n+            try:\n+                from IPython.core.display import display, HTML\n+            except ImportError as e:\n+                raise Exception(\n+                    \"We coulndt import Ipython utils for html display. Are you running in a notebook ? \"\n+                )\n+        if self.annotation_coverter is not None:\n+            annotations = list(map(self.annotation_coverter, annotations))\n+        encoding = self.tokenizer.encode(text)\n+        html = EncodingVisualizer.__make_html(text, encoding, annotations)\n+        if final_default_to_notebook:\n+            display(HTML(html))\n+        else:\n+            return html\n+\n+    @staticmethod\n+    def calculate_label_colors(annotations: AnnotationList) -> Dict[str, str]:\n+        \"\"\"\n+        Generates a color pallete for all the labels in a given set of annotations\n+        :param annotations: A list of annotations\n+        :return: A dictionary mapping a label name to it's hsl color\n+        \"\"\"\n+        if len(annotations) == 0:\n+            return {}\n+        labels = set(map(lambda x: x.label, annotations))\n+        num_labels = len(labels)\n+        h_step = int(255 / num_labels)\n+        if h_step < 20:\n+            h_step = 20\n+        s = 32\n+        l = 64\n+        h = 10\n+        colors = {}\n+\n+        for label in sorted(\n+            labels\n+        ):  # sort so we always get the same colors for a given set of labels\n+            colors[label] = f\"hsl({h},{s}%,{l}%\"\n+            h += h_step\n+        return colors\n+\n+    @staticmethod\n+    def consecutive_chars_to_html(\n+        consecutive_chars_list: List[CharState],\n+        text: str,\n+        encoding: Encoding,\n+    ):\n+        \"\"\"\n+        Converts a list of \"consecutive chars\" into a single HTML element.\n+        Chars are consecutive if they fall under the same word, token and annotation.\n+        The CharState class is a named tuple with a \"partition_key\" method that makes it easy to compare if two chars\n+        are consecutive.\n+\n+        :param consecutive_chars_list: A list of CharStates that have been grouped together\n+        :param text:  The original text being processed\n+        :param encoding:  The encoding of t\n+        :return:\n+        \"\"\"\n+        first = consecutive_chars_list[0]\n+        if first.char_ix is None:\n+            # its a special token\n+            stoken = encoding.tokens[first.token_ix]\n+            # special tokens are represented as empty spans. We use the data attribute and css magic to display it\n+            return f'<span class=\"special-token\" data-stoken={stoken}></span>'\n+        # We're not in a special token so this group has a start and end.\n+        last = consecutive_chars_list[-1]\n+        start = first.char_ix\n+        end = last.char_ix + 1\n+        span_text = text[start:end]\n+        css_classes = []  # What css classes will we apply on the resulting span\n+        data_items = {}  # What data attributes will we apply on the result span\n+        if first.token_ix is not None:\n+            # We can either be in a token or not (e.g. in white space)\n+            css_classes.append(\"token\")\n+            if first.token_ix % 2:\n+                # We use this to color alternating tokens.\n+                # A token might be split by an annotation that ends in the middle of it, so this lets us visually\n+                # indicate a consecutive token despite its possible splitting in the html markup\n+                css_classes.append(\"odd-token\")\n+            else:\n+                # Like above, but a different color so we can see the tokens alternate\n+                css_classes.append(\"even-token\")\n+            if encoding.tokens[first.token_ix] == \"[UNK]\":",
        "comment_created_at": "2020-11-09T20:34:53+00:00",
        "comment_author": "talolard",
        "comment_body": "Done\r\n```python\r\n    unk_token_regex = re.compile('(.{1}\\b)?unk(\\b.{1})?',flags=re.IGNORECASE)\r\n```\r\n\r\nI took off the ^ and $, instead of the flag regexone applied ",
        "pr_file_module": null
      }
    ]
  }
]