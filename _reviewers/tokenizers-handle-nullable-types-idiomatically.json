[
  {
    "discussion_id": "1633382467",
    "pr_number": 1542,
    "pr_file": "bindings/python/src/models.rs",
    "created_at": "2024-06-10T14:46:44+00:00",
    "commented_code": "fn get_trainer(&self, py: Python<'_>) -> PyResult<PyObject> {\n         PyTrainer::from(self.model.read().unwrap().get_trainer()).get_as_subtype(py)\n     }\n+    fn __str__(&self) -> PyResult<String> {\n+        Ok(format!(\"{}\", self.model.read().unwrap()))",
    "repo_full_name": "huggingface/tokenizers",
    "discussion_comments": [
      {
        "comment_id": "1633382467",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 1542,
        "pr_file": "bindings/python/src/models.rs",
        "discussion_id": "1633382467",
        "commented_code": "@@ -220,6 +221,12 @@ impl PyModel {\n     fn get_trainer(&self, py: Python<'_>) -> PyResult<PyObject> {\n         PyTrainer::from(self.model.read().unwrap().get_trainer()).get_as_subtype(py)\n     }\n+    fn __str__(&self) -> PyResult<String> {\n+        Ok(format!(\"{}\", self.model.read().unwrap()))",
        "comment_created_at": "2024-06-10T14:46:44+00:00",
        "comment_author": "McPatate",
        "comment_body": "If `read()` returns a `Result`, then you can probably convert it to a `PyResult` here rather than unwrapping it.\r\nIf it returns an `Option`, then perhaps returning a default value rather than `unwrapping` would be preferable.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1237247538",
    "pr_number": 1217,
    "pr_file": "tokenizers/src/models/unigram/model.rs",
    "created_at": "2023-06-21T16:02:36+00:00",
    "commented_code": "impl Default for Unigram {\n     fn default() -> Self {\n         let vocab = vec![(\"<unk>\".to_string(), 0.0)];\n-        Self::from(vocab, Some(0)).unwrap()\n+        Self::from(vocab, Some(0), Some(false)).unwrap()\n     }\n }\n \n+pub fn byte_to_piece(c: u8) -> String {\n+    format!(\"<0x{:02X}>\", c)\n+}\n+\n+pub fn piece_to_byte(piece: &str) -> Option<u8> {\n+    let mut k_map: HashMap<String, u8> = HashMap::new();\n+    for i in 0..=255 {\n+        let byte_piece = byte_to_piece(i);\n+        k_map.insert(byte_piece.clone(), i);\n+    }\n+    k_map.get(piece).copied()\n+}\n+\n impl Unigram {\n     /// Create a `Unigram` model from a given vocabulary.\n     /// Vocabulary are the various tokens and their associated score which is a sort of a logprob of\n     /// their frequency, which will enable tokenization and sampling.\n     /// unk_id, is the index within the vocabulary.\n     /// For now `Unigram` *requires* at least `unk` because we might find a never seen char.\n     /// Further versions might allow that part to be hidden.\n-    pub fn from(vocab: Vec<(String, f64)>, unk_id: Option<usize>) -> Result<Self> {\n+    pub fn from(\n+        vocab: Vec<(String, f64)>,\n+        unk_id: Option<usize>,\n+        byte_fallback: Option<bool>,",
    "repo_full_name": "huggingface/tokenizers",
    "discussion_comments": [
      {
        "comment_id": "1237247538",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 1217,
        "pr_file": "tokenizers/src/models/unigram/model.rs",
        "discussion_id": "1237247538",
        "commented_code": "@@ -78,18 +81,35 @@ pub enum UnigramError {\n impl Default for Unigram {\n     fn default() -> Self {\n         let vocab = vec![(\"<unk>\".to_string(), 0.0)];\n-        Self::from(vocab, Some(0)).unwrap()\n+        Self::from(vocab, Some(0), Some(false)).unwrap()\n     }\n }\n \n+pub fn byte_to_piece(c: u8) -> String {\n+    format!(\"<0x{:02X}>\", c)\n+}\n+\n+pub fn piece_to_byte(piece: &str) -> Option<u8> {\n+    let mut k_map: HashMap<String, u8> = HashMap::new();\n+    for i in 0..=255 {\n+        let byte_piece = byte_to_piece(i);\n+        k_map.insert(byte_piece.clone(), i);\n+    }\n+    k_map.get(piece).copied()\n+}\n+\n impl Unigram {\n     /// Create a `Unigram` model from a given vocabulary.\n     /// Vocabulary are the various tokens and their associated score which is a sort of a logprob of\n     /// their frequency, which will enable tokenization and sampling.\n     /// unk_id, is the index within the vocabulary.\n     /// For now `Unigram` *requires* at least `unk` because we might find a never seen char.\n     /// Further versions might allow that part to be hidden.\n-    pub fn from(vocab: Vec<(String, f64)>, unk_id: Option<usize>) -> Result<Self> {\n+    pub fn from(\n+        vocab: Vec<(String, f64)>,\n+        unk_id: Option<usize>,\n+        byte_fallback: Option<bool>,",
        "comment_created_at": "2023-06-21T16:02:36+00:00",
        "comment_author": "Narsil",
        "comment_body": "Why `Option<bool>` ? It should be `bool` no ?\r\n\r\nThere are no optional arguments in Rust (and it's good)\r\n\r\n`unk_id` is really an Option, it's not at all forced (but it will cause errors if you haven't one and are triggering an unk).",
        "pr_file_module": null
      },
      {
        "comment_id": "1237249774",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 1217,
        "pr_file": "tokenizers/src/models/unigram/model.rs",
        "discussion_id": "1237247538",
        "commented_code": "@@ -78,18 +81,35 @@ pub enum UnigramError {\n impl Default for Unigram {\n     fn default() -> Self {\n         let vocab = vec![(\"<unk>\".to_string(), 0.0)];\n-        Self::from(vocab, Some(0)).unwrap()\n+        Self::from(vocab, Some(0), Some(false)).unwrap()\n     }\n }\n \n+pub fn byte_to_piece(c: u8) -> String {\n+    format!(\"<0x{:02X}>\", c)\n+}\n+\n+pub fn piece_to_byte(piece: &str) -> Option<u8> {\n+    let mut k_map: HashMap<String, u8> = HashMap::new();\n+    for i in 0..=255 {\n+        let byte_piece = byte_to_piece(i);\n+        k_map.insert(byte_piece.clone(), i);\n+    }\n+    k_map.get(piece).copied()\n+}\n+\n impl Unigram {\n     /// Create a `Unigram` model from a given vocabulary.\n     /// Vocabulary are the various tokens and their associated score which is a sort of a logprob of\n     /// their frequency, which will enable tokenization and sampling.\n     /// unk_id, is the index within the vocabulary.\n     /// For now `Unigram` *requires* at least `unk` because we might find a never seen char.\n     /// Further versions might allow that part to be hidden.\n-    pub fn from(vocab: Vec<(String, f64)>, unk_id: Option<usize>) -> Result<Self> {\n+    pub fn from(\n+        vocab: Vec<(String, f64)>,\n+        unk_id: Option<usize>,\n+        byte_fallback: Option<bool>,",
        "comment_created_at": "2023-06-21T16:04:33+00:00",
        "comment_author": "ArthurZucker",
        "comment_body": "I am too pythonic and tried to have a default to False and make it an option ",
        "pr_file_module": null
      },
      {
        "comment_id": "1237850293",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 1217,
        "pr_file": "tokenizers/src/models/unigram/model.rs",
        "discussion_id": "1237247538",
        "commented_code": "@@ -78,18 +81,35 @@ pub enum UnigramError {\n impl Default for Unigram {\n     fn default() -> Self {\n         let vocab = vec![(\"<unk>\".to_string(), 0.0)];\n-        Self::from(vocab, Some(0)).unwrap()\n+        Self::from(vocab, Some(0), Some(false)).unwrap()\n     }\n }\n \n+pub fn byte_to_piece(c: u8) -> String {\n+    format!(\"<0x{:02X}>\", c)\n+}\n+\n+pub fn piece_to_byte(piece: &str) -> Option<u8> {\n+    let mut k_map: HashMap<String, u8> = HashMap::new();\n+    for i in 0..=255 {\n+        let byte_piece = byte_to_piece(i);\n+        k_map.insert(byte_piece.clone(), i);\n+    }\n+    k_map.get(piece).copied()\n+}\n+\n impl Unigram {\n     /// Create a `Unigram` model from a given vocabulary.\n     /// Vocabulary are the various tokens and their associated score which is a sort of a logprob of\n     /// their frequency, which will enable tokenization and sampling.\n     /// unk_id, is the index within the vocabulary.\n     /// For now `Unigram` *requires* at least `unk` because we might find a never seen char.\n     /// Further versions might allow that part to be hidden.\n-    pub fn from(vocab: Vec<(String, f64)>, unk_id: Option<usize>) -> Result<Self> {\n+    pub fn from(\n+        vocab: Vec<(String, f64)>,\n+        unk_id: Option<usize>,\n+        byte_fallback: Option<bool>,",
        "comment_created_at": "2023-06-22T00:28:10+00:00",
        "comment_author": "chris-ha458",
        "comment_body": "@ArthurZucker Tbh I still think pythonically too and I'm wondering what is the idiomatic Rust thing to do here",
        "pr_file_module": null
      },
      {
        "comment_id": "1238109807",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 1217,
        "pr_file": "tokenizers/src/models/unigram/model.rs",
        "discussion_id": "1237247538",
        "commented_code": "@@ -78,18 +81,35 @@ pub enum UnigramError {\n impl Default for Unigram {\n     fn default() -> Self {\n         let vocab = vec![(\"<unk>\".to_string(), 0.0)];\n-        Self::from(vocab, Some(0)).unwrap()\n+        Self::from(vocab, Some(0), Some(false)).unwrap()\n     }\n }\n \n+pub fn byte_to_piece(c: u8) -> String {\n+    format!(\"<0x{:02X}>\", c)\n+}\n+\n+pub fn piece_to_byte(piece: &str) -> Option<u8> {\n+    let mut k_map: HashMap<String, u8> = HashMap::new();\n+    for i in 0..=255 {\n+        let byte_piece = byte_to_piece(i);\n+        k_map.insert(byte_piece.clone(), i);\n+    }\n+    k_map.get(piece).copied()\n+}\n+\n impl Unigram {\n     /// Create a `Unigram` model from a given vocabulary.\n     /// Vocabulary are the various tokens and their associated score which is a sort of a logprob of\n     /// their frequency, which will enable tokenization and sampling.\n     /// unk_id, is the index within the vocabulary.\n     /// For now `Unigram` *requires* at least `unk` because we might find a never seen char.\n     /// Further versions might allow that part to be hidden.\n-    pub fn from(vocab: Vec<(String, f64)>, unk_id: Option<usize>) -> Result<Self> {\n+    pub fn from(\n+        vocab: Vec<(String, f64)>,\n+        unk_id: Option<usize>,\n+        byte_fallback: Option<bool>,",
        "comment_created_at": "2023-06-22T07:22:02+00:00",
        "comment_author": "ArthurZucker",
        "comment_body": "I think that it doesn't make sense to have to init a unigram with `Some(false)` which you have to do rigght now ! ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1181476560",
    "pr_number": 1228,
    "pr_file": "tokenizers/src/models/bpe/trainer.rs",
    "created_at": "2023-05-01T09:12:21+00:00",
    "commented_code": "}\n             }\n             let new_token = format!(\"{}{}\", part_a, part_b);\n+            // implement sentencepiece-like merge.\n+            // if this code were to be merged, integrate a way in the python bindings to communicate this variable\n+            // default should be 0/None to maintain previous behavior. 16 is the spm default.\n+            let max_merge_length: Option<u16> = Some(16);\n+\n+            match max_merge_length {\n+                None | Some(0) => {\n+                // in case 0 was manually entered, treat as None\n+                }\n+                Some(length) => {\n+                    if new_token.chars().count() >\n+                    (length as usize) {\n+                        continue;\n+                    }\n+                }\n+            }",
    "repo_full_name": "huggingface/tokenizers",
    "discussion_comments": [
      {
        "comment_id": "1181476560",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 1228,
        "pr_file": "tokenizers/src/models/bpe/trainer.rs",
        "discussion_id": "1181476560",
        "commented_code": "@@ -502,6 +502,22 @@ impl BpeTrainer {\n                 }\n             }\n             let new_token = format!(\"{}{}\", part_a, part_b);\n+            // implement sentencepiece-like merge.\n+            // if this code were to be merged, integrate a way in the python bindings to communicate this variable\n+            // default should be 0/None to maintain previous behavior. 16 is the spm default.\n+            let max_merge_length: Option<u16> = Some(16);\n+\n+            match max_merge_length {\n+                None | Some(0) => {\n+                // in case 0 was manually entered, treat as None\n+                }\n+                Some(length) => {\n+                    if new_token.chars().count() >\n+                    (length as usize) {\n+                        continue;\n+                    }\n+                }\n+            }",
        "comment_created_at": "2023-05-01T09:12:21+00:00",
        "comment_author": "Narsil",
        "comment_body": "```suggestion\r\n           if let Some(max_token_length) = max_token_length{\r\n               if new_token.chars().count() > max_token_length{\r\n                   continue;\r\n               }\r\n           }\r\n```\r\n\r\nThis is more idiomatic imo.\r\n0 is NOT a special value. `None`  means ignore, `zero` does mean zero. If things starts to do weird things it's not the problem of this function, it's respecting the value which is more important.\r\n\r\nTry to switch to `usize` it makes everything easier to read, and the actual \"size\" isn't important optimization wise.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "464599167",
    "pr_number": 355,
    "pr_file": "bindings/python/src/tokenizer.rs",
    "created_at": "2020-08-03T18:49:57+00:00",
    "commented_code": "}\n \n     #[getter]\n-    fn get_model(&self) -> PyResult<Model> {\n-        Ok(Model {\n-            model: Container::from_ref(self.tokenizer.get_model()),\n-        })\n+    fn get_model(&self) -> PyResult<PyObject> {\n+        self.tokenizer.get_model().get_as_subtype()\n     }\n \n     #[setter]\n-    fn set_model(&mut self, mut model: PyRefMut<Model>) -> PyResult<()> {\n-        if let Some(model) = model.model.to_pointer() {\n-            self.tokenizer.with_model(model);\n-            Ok(())\n-        } else {\n-            Err(exceptions::Exception::py_err(\n-                \"The Model is already being used in another Tokenizer\",\n-            ))\n-        }\n+    fn set_model(&mut self, model: PyRef<PyModel>) {\n+        self.tokenizer.with_model(model.clone());\n     }\n \n     #[getter]\n-    fn get_normalizer(&self) -> PyResult<Option<Normalizer>> {\n-        Ok(self\n-            .tokenizer\n-            .get_normalizer()\n-            .map(|normalizer| Normalizer {\n-                normalizer: Container::from_ref(normalizer),\n-            }))\n+    fn get_normalizer(&self) -> PyResult<PyObject> {\n+        if let Some(n) = self.tokenizer.get_normalizer() {",
    "repo_full_name": "huggingface/tokenizers",
    "discussion_comments": [
      {
        "comment_id": "464599167",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 355,
        "pr_file": "bindings/python/src/tokenizer.rs",
        "discussion_id": "464599167",
        "commented_code": "@@ -689,106 +689,68 @@ impl Tokenizer {\n     }\n \n     #[getter]\n-    fn get_model(&self) -> PyResult<Model> {\n-        Ok(Model {\n-            model: Container::from_ref(self.tokenizer.get_model()),\n-        })\n+    fn get_model(&self) -> PyResult<PyObject> {\n+        self.tokenizer.get_model().get_as_subtype()\n     }\n \n     #[setter]\n-    fn set_model(&mut self, mut model: PyRefMut<Model>) -> PyResult<()> {\n-        if let Some(model) = model.model.to_pointer() {\n-            self.tokenizer.with_model(model);\n-            Ok(())\n-        } else {\n-            Err(exceptions::Exception::py_err(\n-                \"The Model is already being used in another Tokenizer\",\n-            ))\n-        }\n+    fn set_model(&mut self, model: PyRef<PyModel>) {\n+        self.tokenizer.with_model(model.clone());\n     }\n \n     #[getter]\n-    fn get_normalizer(&self) -> PyResult<Option<Normalizer>> {\n-        Ok(self\n-            .tokenizer\n-            .get_normalizer()\n-            .map(|normalizer| Normalizer {\n-                normalizer: Container::from_ref(normalizer),\n-            }))\n+    fn get_normalizer(&self) -> PyResult<PyObject> {\n+        if let Some(n) = self.tokenizer.get_normalizer() {",
        "comment_created_at": "2020-08-03T18:49:57+00:00",
        "comment_author": "n1t0",
        "comment_body": "Is there any reason for `get_as_subtype` to return `PyResult`? If not, this could be rewritten as\r\n```Rust\r\nfn get_normalizer(&self) -> Option<PyObject> {\r\n    self.tokenizer.get_normalizer().map(|n| n.get_as_subtype())\r\n}\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "464866235",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 355,
        "pr_file": "bindings/python/src/tokenizer.rs",
        "discussion_id": "464599167",
        "commented_code": "@@ -689,106 +689,68 @@ impl Tokenizer {\n     }\n \n     #[getter]\n-    fn get_model(&self) -> PyResult<Model> {\n-        Ok(Model {\n-            model: Container::from_ref(self.tokenizer.get_model()),\n-        })\n+    fn get_model(&self) -> PyResult<PyObject> {\n+        self.tokenizer.get_model().get_as_subtype()\n     }\n \n     #[setter]\n-    fn set_model(&mut self, mut model: PyRefMut<Model>) -> PyResult<()> {\n-        if let Some(model) = model.model.to_pointer() {\n-            self.tokenizer.with_model(model);\n-            Ok(())\n-        } else {\n-            Err(exceptions::Exception::py_err(\n-                \"The Model is already being used in another Tokenizer\",\n-            ))\n-        }\n+    fn set_model(&mut self, model: PyRef<PyModel>) {\n+        self.tokenizer.with_model(model.clone());\n     }\n \n     #[getter]\n-    fn get_normalizer(&self) -> PyResult<Option<Normalizer>> {\n-        Ok(self\n-            .tokenizer\n-            .get_normalizer()\n-            .map(|normalizer| Normalizer {\n-                normalizer: Container::from_ref(normalizer),\n-            }))\n+    fn get_normalizer(&self) -> PyResult<PyObject> {\n+        if let Some(n) = self.tokenizer.get_normalizer() {",
        "comment_created_at": "2020-08-04T07:52:07+00:00",
        "comment_author": "sebpuetz",
        "comment_body": "`Py::new` returns `PyResult` since creating the object is fallible, so we can't get rid of that...",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "364404701",
    "pr_number": 42,
    "pr_file": "tokenizers/src/models/bpe/model.rs",
    "created_at": "2020-01-08T19:30:32+00:00",
    "commented_code": "path::{Path, PathBuf},\n };\n \n-#[derive(Default)]\n struct Config {\n-    vocab: Option<HashMap<String, u32>>,\n-    merges: Option<HashMap<Pair, (u32, u32)>>,\n-    cache_capacity: Option<usize>,\n+    vocab: HashMap<String, u32>,\n+    merges: HashMap<Pair, (u32, u32)>,\n+    cache_capacity: usize,\n     dropout: Option<f32>,",
    "repo_full_name": "huggingface/tokenizers",
    "discussion_comments": [
      {
        "comment_id": "364404701",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 42,
        "pr_file": "tokenizers/src/models/bpe/model.rs",
        "discussion_id": "364404701",
        "commented_code": "@@ -10,23 +10,37 @@ use std::{\n     path::{Path, PathBuf},\n };\n \n-#[derive(Default)]\n struct Config {\n-    vocab: Option<HashMap<String, u32>>,\n-    merges: Option<HashMap<Pair, (u32, u32)>>,\n-    cache_capacity: Option<usize>,\n+    vocab: HashMap<String, u32>,\n+    merges: HashMap<Pair, (u32, u32)>,\n+    cache_capacity: usize,\n     dropout: Option<f32>,",
        "comment_created_at": "2020-01-08T19:30:32+00:00",
        "comment_author": "n1t0",
        "comment_body": "I was wondering about those optional parameters. If we were to change the default to some value, it wouldn't be possible with the current setup to actually set them back to `None`. How do you think we could handle this?",
        "pr_file_module": null
      },
      {
        "comment_id": "364420967",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 42,
        "pr_file": "tokenizers/src/models/bpe/model.rs",
        "discussion_id": "364404701",
        "commented_code": "@@ -10,23 +10,37 @@ use std::{\n     path::{Path, PathBuf},\n };\n \n-#[derive(Default)]\n struct Config {\n-    vocab: Option<HashMap<String, u32>>,\n-    merges: Option<HashMap<Pair, (u32, u32)>>,\n-    cache_capacity: Option<usize>,\n+    vocab: HashMap<String, u32>,\n+    merges: HashMap<Pair, (u32, u32)>,\n+    cache_capacity: usize,\n     dropout: Option<f32>,",
        "comment_created_at": "2020-01-08T20:09:23+00:00",
        "comment_author": "epwalsh",
        "comment_body": "Hmm yea I guess in that case we'd have to have the builder setter method take `Option<_>`, or maybe have a `without_dropout` method on the builder, for example",
        "pr_file_module": null
      }
    ]
  }
]