[
  {
    "discussion_id": "823932413",
    "pr_number": 949,
    "pr_file": "bindings/python/src/trainers.rs",
    "created_at": "2022-03-10T16:45:48+00:00",
    "commented_code": "use std::sync::{Arc, RwLock};\n \n+use crate::models::PyModel;\n+use crate::tokenizer::PyAddedToken;\n+use crate::utils::PyChar;\n use pyo3::exceptions;\n use pyo3::prelude::*;\n use pyo3::types::*;\n+use serde::{Deserialize, Serialize};\n use tk::models::TrainerWrapper;\n use tk::Trainer;\n use tokenizers as tk;\n \n-use crate::models::PyModel;\n-use crate::tokenizer::PyAddedToken;\n-use crate::utils::PyChar;\n-\n /// Base class for all trainers\n ///\n /// This class is not supposed to be instantiated directly. Instead, any implementation of a\n /// Trainer will return an instance of this class when instantiated.\n #[pyclass(name=Trainer, module = \"tokenizers.trainers\", name=Trainer)]\n-#[derive(Clone)]\n-#[text_signature = \"(self, vocab_size=30000, min_frequency=0,show_progress=True, special_tokens=[],limit_alphabet=None, initial_alphabet = [], continuing_subword_prefix=None, end_of_word_suffix=None)\"]\n+#[derive(Clone, Deserialize, Serialize)]\n pub struct PyTrainer {\n+    #[serde(flatten)]\n     pub trainer: Arc<RwLock<TrainerWrapper>>,\n }\n \n impl PyTrainer {\n+    #[cfg(test)]\n+    pub(crate) fn new(trainer: Arc<RwLock<TrainerWrapper>>) -> Self {",
    "repo_full_name": "huggingface/tokenizers",
    "discussion_comments": [
      {
        "comment_id": "823932413",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 949,
        "pr_file": "bindings/python/src/trainers.rs",
        "discussion_id": "823932413",
        "commented_code": "@@ -1,28 +1,32 @@\n use std::sync::{Arc, RwLock};\n \n+use crate::models::PyModel;\n+use crate::tokenizer::PyAddedToken;\n+use crate::utils::PyChar;\n use pyo3::exceptions;\n use pyo3::prelude::*;\n use pyo3::types::*;\n+use serde::{Deserialize, Serialize};\n use tk::models::TrainerWrapper;\n use tk::Trainer;\n use tokenizers as tk;\n \n-use crate::models::PyModel;\n-use crate::tokenizer::PyAddedToken;\n-use crate::utils::PyChar;\n-\n /// Base class for all trainers\n ///\n /// This class is not supposed to be instantiated directly. Instead, any implementation of a\n /// Trainer will return an instance of this class when instantiated.\n #[pyclass(name=Trainer, module = \"tokenizers.trainers\", name=Trainer)]\n-#[derive(Clone)]\n-#[text_signature = \"(self, vocab_size=30000, min_frequency=0,show_progress=True, special_tokens=[],limit_alphabet=None, initial_alphabet = [], continuing_subword_prefix=None, end_of_word_suffix=None)\"]\n+#[derive(Clone, Deserialize, Serialize)]\n pub struct PyTrainer {\n+    #[serde(flatten)]\n     pub trainer: Arc<RwLock<TrainerWrapper>>,\n }\n \n impl PyTrainer {\n+    #[cfg(test)]\n+    pub(crate) fn new(trainer: Arc<RwLock<TrainerWrapper>>) -> Self {",
        "comment_created_at": "2022-03-10T16:45:48+00:00",
        "comment_author": "McPatate",
        "comment_body": "Why do we need `Arc<>` here ?",
        "pr_file_module": null
      },
      {
        "comment_id": "823947687",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 949,
        "pr_file": "bindings/python/src/trainers.rs",
        "discussion_id": "823932413",
        "commented_code": "@@ -1,28 +1,32 @@\n use std::sync::{Arc, RwLock};\n \n+use crate::models::PyModel;\n+use crate::tokenizer::PyAddedToken;\n+use crate::utils::PyChar;\n use pyo3::exceptions;\n use pyo3::prelude::*;\n use pyo3::types::*;\n+use serde::{Deserialize, Serialize};\n use tk::models::TrainerWrapper;\n use tk::Trainer;\n use tokenizers as tk;\n \n-use crate::models::PyModel;\n-use crate::tokenizer::PyAddedToken;\n-use crate::utils::PyChar;\n-\n /// Base class for all trainers\n ///\n /// This class is not supposed to be instantiated directly. Instead, any implementation of a\n /// Trainer will return an instance of this class when instantiated.\n #[pyclass(name=Trainer, module = \"tokenizers.trainers\", name=Trainer)]\n-#[derive(Clone)]\n-#[text_signature = \"(self, vocab_size=30000, min_frequency=0,show_progress=True, special_tokens=[],limit_alphabet=None, initial_alphabet = [], continuing_subword_prefix=None, end_of_word_suffix=None)\"]\n+#[derive(Clone, Deserialize, Serialize)]\n pub struct PyTrainer {\n+    #[serde(flatten)]\n     pub trainer: Arc<RwLock<TrainerWrapper>>,\n }\n \n impl PyTrainer {\n+    #[cfg(test)]\n+    pub(crate) fn new(trainer: Arc<RwLock<TrainerWrapper>>) -> Self {",
        "comment_created_at": "2022-03-10T17:00:38+00:00",
        "comment_author": "Narsil",
        "comment_body": "Because it's python a python object holding a ref to a rust object.\r\n\r\nSince Python has the GIL we don't know if we're on the same thread or not, hence `Arc<RwLock<>>` To become `Send+Sync`. This is already what the `PyTrainer` owns as an object.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "521229610",
    "pr_number": 519,
    "pr_file": "bindings/python/src/tokenizer.rs",
    "created_at": "2020-11-11T09:33:26+00:00",
    "commented_code": "use super::*;\n     use crate::models::PyModel;\n     use crate::normalizers::{PyNormalizer, PyNormalizerTypeWrapper};\n-    use std::sync::Arc;\n+    use std::sync::{Arc, RwLock};\n     use tempfile::NamedTempFile;\n     use tk::normalizers::{Lowercase, NFKC};\n \n     #[test]\n     fn serialize() {\n-        let mut tokenizer = Tokenizer::new(PyModel::new(Arc::new(\n+        let mut tokenizer = Tokenizer::new(PyModel::new(Arc::new(RwLock::new(",
    "repo_full_name": "huggingface/tokenizers",
    "discussion_comments": [
      {
        "comment_id": "521229610",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 519,
        "pr_file": "bindings/python/src/tokenizer.rs",
        "discussion_id": "521229610",
        "commented_code": "@@ -1165,15 +1171,15 @@ mod test {\n     use super::*;\n     use crate::models::PyModel;\n     use crate::normalizers::{PyNormalizer, PyNormalizerTypeWrapper};\n-    use std::sync::Arc;\n+    use std::sync::{Arc, RwLock};\n     use tempfile::NamedTempFile;\n     use tk::normalizers::{Lowercase, NFKC};\n \n     #[test]\n     fn serialize() {\n-        let mut tokenizer = Tokenizer::new(PyModel::new(Arc::new(\n+        let mut tokenizer = Tokenizer::new(PyModel::new(Arc::new(RwLock::new(",
        "comment_created_at": "2020-11-11T09:33:26+00:00",
        "comment_author": "Narsil",
        "comment_body": "Could you explain why all those RwLock are need ? I'm not sure why we would need them.",
        "pr_file_module": null
      },
      {
        "comment_id": "522422773",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 519,
        "pr_file": "bindings/python/src/tokenizer.rs",
        "discussion_id": "521229610",
        "commented_code": "@@ -1165,15 +1171,15 @@ mod test {\n     use super::*;\n     use crate::models::PyModel;\n     use crate::normalizers::{PyNormalizer, PyNormalizerTypeWrapper};\n-    use std::sync::Arc;\n+    use std::sync::{Arc, RwLock};\n     use tempfile::NamedTempFile;\n     use tk::normalizers::{Lowercase, NFKC};\n \n     #[test]\n     fn serialize() {\n-        let mut tokenizer = Tokenizer::new(PyModel::new(Arc::new(\n+        let mut tokenizer = Tokenizer::new(PyModel::new(Arc::new(RwLock::new(",
        "comment_created_at": "2020-11-12T20:59:44+00:00",
        "comment_author": "n1t0",
        "comment_body": "Sure, we need them because anything in an `Arc` is immutable. These `RwLock` provides us with a way to actually mutate the `Model` here.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "521233672",
    "pr_number": 519,
    "pr_file": "bindings/python/src/models.rs",
    "created_at": "2020-11-11T09:40:31+00:00",
    "commented_code": "}\n \n impl Model for PyModel {\n+    type Trainer = PyTrainer;\n+\n     fn tokenize(&self, tokens: &str) -> tk::Result<Vec<Token>> {\n-        self.model.tokenize(tokens)\n+        self.model.read().unwrap().tokenize(tokens)",
    "repo_full_name": "huggingface/tokenizers",
    "discussion_comments": [
      {
        "comment_id": "521233672",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 519,
        "pr_file": "bindings/python/src/models.rs",
        "discussion_id": "521233672",
        "commented_code": "@@ -45,28 +46,34 @@ impl PyModel {\n }\n \n impl Model for PyModel {\n+    type Trainer = PyTrainer;\n+\n     fn tokenize(&self, tokens: &str) -> tk::Result<Vec<Token>> {\n-        self.model.tokenize(tokens)\n+        self.model.read().unwrap().tokenize(tokens)",
        "comment_created_at": "2020-11-11T09:40:31+00:00",
        "comment_author": "Narsil",
        "comment_body": "I'm always a bit scared by adding that much `unwrap` everywhere... Do you think there's a way we could avoid them ?",
        "pr_file_module": null
      },
      {
        "comment_id": "522429394",
        "repo_full_name": "huggingface/tokenizers",
        "pr_number": 519,
        "pr_file": "bindings/python/src/models.rs",
        "discussion_id": "521233672",
        "commented_code": "@@ -45,28 +46,34 @@ impl PyModel {\n }\n \n impl Model for PyModel {\n+    type Trainer = PyTrainer;\n+\n     fn tokenize(&self, tokens: &str) -> tk::Result<Vec<Token>> {\n-        self.model.tokenize(tokens)\n+        self.model.read().unwrap().tokenize(tokens)",
        "comment_created_at": "2020-11-12T21:12:41+00:00",
        "comment_author": "n1t0",
        "comment_body": "The `unwrap` here is for the `std::sync::LockResult` that is returned by the `RwLock` when you try to access its content. The `Err` case happens when a thread that was holding the lock panicked. So since this shouldn't happen, and we don't want to recover from it, I think the `unwrap` should be ok.",
        "pr_file_module": null
      }
    ]
  }
]