[
  {
    "discussion_id": "1990667451",
    "pr_number": 7212,
    "pr_file": "tokio-test/src/io.rs",
    "created_at": "2025-03-12T06:02:40+00:00",
    "commented_code": "self\n     }\n \n+    /// Set name of the mock IO object to include in panic messages and debug output\n+    pub fn name(&mut self, name: String) -> &mut Self {",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "1990667451",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7212,
        "pr_file": "tokio-test/src/io.rs",
        "discussion_id": "1990667451",
        "commented_code": "@@ -127,6 +129,12 @@ impl Builder {\n         self\n     }\n \n+    /// Set name of the mock IO object to include in panic messages and debug output\n+    pub fn name(&mut self, name: String) -> &mut Self {",
        "comment_created_at": "2025-03-12T06:02:40+00:00",
        "comment_author": "mox692",
        "comment_body": "How about accepting `Into<String>` for more flexibility?\r\n\r\nFor example: https://github.com/tokio-rs/tokio/blob/8507e28f89916662d2f61af823993483169d912c/tokio/src/runtime/builder.rs#L488",
        "pr_file_module": null
      },
      {
        "comment_id": "1990899510",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7212,
        "pr_file": "tokio-test/src/io.rs",
        "discussion_id": "1990667451",
        "commented_code": "@@ -127,6 +129,12 @@ impl Builder {\n         self\n     }\n \n+    /// Set name of the mock IO object to include in panic messages and debug output\n+    pub fn name(&mut self, name: String) -> &mut Self {",
        "comment_created_at": "2025-03-12T08:02:17+00:00",
        "comment_author": "vi",
        "comment_body": "Adjusted.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1742518848",
    "pr_number": 6815,
    "pr_file": "tokio-util/src/io/sync_bridge.rs",
    "created_at": "2024-09-03T18:46:21+00:00",
    "commented_code": "/// Use a [`tokio::io::AsyncRead`] synchronously as a [`std::io::Read`] or\n /// a [`tokio::io::AsyncWrite`] as a [`std::io::Write`].\n+///\n+/// # Alternatives\n+///\n+/// In many cases, there are better alternatives to using `SyncIoBridge`, especially if you\n+/// want to avoid blocking the async runtime. Consider the following scenarios:\n+///\n+/// ## Example 1: Hashing Data\n+///\n+/// When hashing data, using `SyncIoBridge` can lead to suboptimal performance and might not fully leverage the async capabilities of the system.\n+/// Instead, consider reading the data into memory and then hashing it, or processing the data in chunks.\n+///\n+/// ```rust, no_run\n+/// let mut data = Vec::new();\n+/// reader.read_to_end(&mut data).await?;\n+/// let hash = blake3::hash(&data);\n+/// ```\n+///\n+/// Or, for more complex cases:\n+///\n+/// ```rust, no_run\n+/// let mut data = vec![0; 64 * 1024];\n+/// loop {\n+///     let len = reader.read(&mut data).await?;\n+///     if len == 0 { break; }\n+///     hasher.update(&data[..len]);\n+/// }\n+/// let hash = hasher.finalize();\n+/// ```\n+///\n+/// ## Example 2: Compressing Data\n+///\n+/// When compressing data, avoid using `SyncIoBridge`` with non-async compression libraries, as it may lead to inefficient and blocking code.\n+/// Instead, use `async-compression`, which is designed to work with asynchronous data streams.\n+///\n+/// ```rust, no_run\n+/// use async_compression::tokio::write::GzipEncoder;\n+///\n+/// let mut encoder = GzipEncoder::new(writer);\n+/// tokio::io::copy(&mut reader, &mut encoder).await?;\n+/// ```\n+///\n+/// ## Example 3: Parsing `JSON`\n+///\n+/// When parsing `JSON` data, avoid using `SyncIoBridge` with `serde_json::from_reader` as it may cause blocking operations.\n+/// Instead, read the data into a `Vec<u8>` and parse it using `serde_json::from_slice`.\n+///\n+/// ```rust, no_run\n+/// let mut data = Vec::new();\n+/// reader.read_to_end(&mut data).await?;\n+/// let value: MyStruct = serde_json::from_slice(&data)?;\n+/// ```",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "1742518848",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6815,
        "pr_file": "tokio-util/src/io/sync_bridge.rs",
        "discussion_id": "1742518848",
        "commented_code": "@@ -6,6 +6,81 @@ use tokio::io::{\n \n /// Use a [`tokio::io::AsyncRead`] synchronously as a [`std::io::Read`] or\n /// a [`tokio::io::AsyncWrite`] as a [`std::io::Write`].\n+///\n+/// # Alternatives\n+///\n+/// In many cases, there are better alternatives to using `SyncIoBridge`, especially if you\n+/// want to avoid blocking the async runtime. Consider the following scenarios:\n+///\n+/// ## Example 1: Hashing Data\n+///\n+/// When hashing data, using `SyncIoBridge` can lead to suboptimal performance and might not fully leverage the async capabilities of the system.\n+/// Instead, consider reading the data into memory and then hashing it, or processing the data in chunks.\n+///\n+/// ```rust, no_run\n+/// let mut data = Vec::new();\n+/// reader.read_to_end(&mut data).await?;\n+/// let hash = blake3::hash(&data);\n+/// ```\n+///\n+/// Or, for more complex cases:\n+///\n+/// ```rust, no_run\n+/// let mut data = vec![0; 64 * 1024];\n+/// loop {\n+///     let len = reader.read(&mut data).await?;\n+///     if len == 0 { break; }\n+///     hasher.update(&data[..len]);\n+/// }\n+/// let hash = hasher.finalize();\n+/// ```\n+///\n+/// ## Example 2: Compressing Data\n+///\n+/// When compressing data, avoid using `SyncIoBridge`` with non-async compression libraries, as it may lead to inefficient and blocking code.\n+/// Instead, use `async-compression`, which is designed to work with asynchronous data streams.\n+///\n+/// ```rust, no_run\n+/// use async_compression::tokio::write::GzipEncoder;\n+///\n+/// let mut encoder = GzipEncoder::new(writer);\n+/// tokio::io::copy(&mut reader, &mut encoder).await?;\n+/// ```\n+///\n+/// ## Example 3: Parsing `JSON`\n+///\n+/// When parsing `JSON` data, avoid using `SyncIoBridge` with `serde_json::from_reader` as it may cause blocking operations.\n+/// Instead, read the data into a `Vec<u8>` and parse it using `serde_json::from_slice`.\n+///\n+/// ```rust, no_run\n+/// let mut data = Vec::new();\n+/// reader.read_to_end(&mut data).await?;\n+/// let value: MyStruct = serde_json::from_slice(&data)?;\n+/// ```",
        "comment_created_at": "2024-09-03T18:46:21+00:00",
        "comment_author": "hawkw",
        "comment_body": "This isn't really specific to JSON; this advice applies equally to any other serialization format. What about something like:\r\n\r\n> When parsing serialization formats such as JSON, avoid using `SyncIoBridge` with functions that deserialize data from a type implementing `std::io::Read`, such as `serde_json::from_reader`.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1922079832",
    "pr_number": 7111,
    "pr_file": "tokio/src/task/budget.rs",
    "created_at": "2025-01-20T09:34:38+00:00",
    "commented_code": "})\n     .await\n }\n+\n+/// Polls to see if any budget is available or not.\n+///\n+/// See also the usage example in the [task module](index.html#poll_budget_available).\n+///\n+/// This method returns:\n+/// - `Poll::Pending` if the budget is depleted\n+/// - `Poll::Ready(())` if there is still budget left\n+#[cfg_attr(docsrs, doc(cfg(feature = \"rt\")))]\n+pub fn poll_budget_available(cx: &mut Context<'_>) -> Poll<()> {\n+    ready!(crate::trace::trace_leaf(cx));\n+    if crate::runtime::coop::has_budget_remaining() {\n+        Poll::Ready(())\n+    } else {\n+        cx.waker().wake_by_ref();\n+        Poll::Pending\n+    }\n+}",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "1922079832",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7111,
        "pr_file": "tokio/src/task/budget.rs",
        "discussion_id": "1922079832",
        "commented_code": "@@ -39,3 +39,21 @@ pub async fn consume_budget() {\n     })\n     .await\n }\n+\n+/// Polls to see if any budget is available or not.\n+///\n+/// See also the usage example in the [task module](index.html#poll_budget_available).\n+///\n+/// This method returns:\n+/// - `Poll::Pending` if the budget is depleted\n+/// - `Poll::Ready(())` if there is still budget left\n+#[cfg_attr(docsrs, doc(cfg(feature = \"rt\")))]\n+pub fn poll_budget_available(cx: &mut Context<'_>) -> Poll<()> {\n+    ready!(crate::trace::trace_leaf(cx));\n+    if crate::runtime::coop::has_budget_remaining() {\n+        Poll::Ready(())\n+    } else {\n+        cx.waker().wake_by_ref();\n+        Poll::Pending\n+    }\n+}",
        "comment_created_at": "2025-01-20T09:34:38+00:00",
        "comment_author": "Darksonn",
        "comment_body": "I think that the `poll_proceed` / `made_progress` API we use internally is good. If we're going to expose more of coop, then I think we should expose that API instead of inventing a new one.\r\n\r\nBut I wouldn't do both \"expose coop API\" and \"make select coop aware\" in one PR. I'd like two PRs for the changelog.",
        "pr_file_module": null
      },
      {
        "comment_id": "1923202298",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7111,
        "pr_file": "tokio/src/task/budget.rs",
        "discussion_id": "1922079832",
        "commented_code": "@@ -39,3 +39,21 @@ pub async fn consume_budget() {\n     })\n     .await\n }\n+\n+/// Polls to see if any budget is available or not.\n+///\n+/// See also the usage example in the [task module](index.html#poll_budget_available).\n+///\n+/// This method returns:\n+/// - `Poll::Pending` if the budget is depleted\n+/// - `Poll::Ready(())` if there is still budget left\n+#[cfg_attr(docsrs, doc(cfg(feature = \"rt\")))]\n+pub fn poll_budget_available(cx: &mut Context<'_>) -> Poll<()> {\n+    ready!(crate::trace::trace_leaf(cx));\n+    if crate::runtime::coop::has_budget_remaining() {\n+        Poll::Ready(())\n+    } else {\n+        cx.waker().wake_by_ref();\n+        Poll::Pending\n+    }\n+}",
        "comment_created_at": "2025-01-21T07:38:14+00:00",
        "comment_author": "maminrayej",
        "comment_body": "Makes sense. I'll focus on exposing our coop API in this PR and will make select budget-aware afterwards in a follow-up PR.",
        "pr_file_module": null
      },
      {
        "comment_id": "1924186145",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7111,
        "pr_file": "tokio/src/task/budget.rs",
        "discussion_id": "1922079832",
        "commented_code": "@@ -39,3 +39,21 @@ pub async fn consume_budget() {\n     })\n     .await\n }\n+\n+/// Polls to see if any budget is available or not.\n+///\n+/// See also the usage example in the [task module](index.html#poll_budget_available).\n+///\n+/// This method returns:\n+/// - `Poll::Pending` if the budget is depleted\n+/// - `Poll::Ready(())` if there is still budget left\n+#[cfg_attr(docsrs, doc(cfg(feature = \"rt\")))]\n+pub fn poll_budget_available(cx: &mut Context<'_>) -> Poll<()> {\n+    ready!(crate::trace::trace_leaf(cx));\n+    if crate::runtime::coop::has_budget_remaining() {\n+        Poll::Ready(())\n+    } else {\n+        cx.waker().wake_by_ref();\n+        Poll::Pending\n+    }\n+}",
        "comment_created_at": "2025-01-21T18:20:05+00:00",
        "comment_author": "maminrayej",
        "comment_body": "Or rather I'll close this PR and open another one since renaming the title, rewriting the description, and resetting the labels will be messy for future reference.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1703370343",
    "pr_number": 6589,
    "pr_file": "tokio/src/io/util/mem.rs",
    "created_at": "2024-08-04T19:47:35+00:00",
    "commented_code": "}\n }\n \n-// ===== impl Pipe =====\n+// ===== impl SimplexStream =====\n \n-impl Pipe {\n-    fn new(max_buf_size: usize) -> Self {\n-        Pipe {\n-            buffer: BytesMut::new(),\n-            is_closed: false,\n-            max_buf_size,\n-            read_waker: None,\n-            write_waker: None,\n-        }\n+/// Creates unidirectional buffer that acts like pair of connected single direction sockets.\n+///\n+/// The `max_buf_size` argument is the maximum amount of bytes that can be\n+/// written to a buffer before the it returns `Poll::Pending`.\n+#[cfg_attr(docsrs, doc(cfg(feature = \"io-util\")))]\n+pub fn simplex(max_buf_size: usize) -> SimplexStream {\n+    SimplexStream {\n+        buffer: BytesMut::new(),\n+        is_closed: false,\n+        max_buf_size,\n+        read_waker: None,\n+        write_waker: None,\n     }\n+}",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "1703370343",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6589,
        "pr_file": "tokio/src/io/util/mem.rs",
        "discussion_id": "1703370343",
        "commented_code": "@@ -161,19 +181,24 @@ impl Drop for DuplexStream {\n     }\n }\n \n-// ===== impl Pipe =====\n+// ===== impl SimplexStream =====\n \n-impl Pipe {\n-    fn new(max_buf_size: usize) -> Self {\n-        Pipe {\n-            buffer: BytesMut::new(),\n-            is_closed: false,\n-            max_buf_size,\n-            read_waker: None,\n-            write_waker: None,\n-        }\n+/// Creates unidirectional buffer that acts like pair of connected single direction sockets.\n+///\n+/// The `max_buf_size` argument is the maximum amount of bytes that can be\n+/// written to a buffer before the it returns `Poll::Pending`.\n+#[cfg_attr(docsrs, doc(cfg(feature = \"io-util\")))]\n+pub fn simplex(max_buf_size: usize) -> SimplexStream {\n+    SimplexStream {\n+        buffer: BytesMut::new(),\n+        is_closed: false,\n+        max_buf_size,\n+        read_waker: None,\n+        write_waker: None,\n     }\n+}",
        "comment_created_at": "2024-08-04T19:47:35+00:00",
        "comment_author": "Darksonn",
        "comment_body": "This provides a single object that is both the reader and writer, but in practice I think people will want those to be two different objects.",
        "pr_file_module": null
      },
      {
        "comment_id": "1704207140",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6589,
        "pr_file": "tokio/src/io/util/mem.rs",
        "discussion_id": "1703370343",
        "commented_code": "@@ -161,19 +181,24 @@ impl Drop for DuplexStream {\n     }\n }\n \n-// ===== impl Pipe =====\n+// ===== impl SimplexStream =====\n \n-impl Pipe {\n-    fn new(max_buf_size: usize) -> Self {\n-        Pipe {\n-            buffer: BytesMut::new(),\n-            is_closed: false,\n-            max_buf_size,\n-            read_waker: None,\n-            write_waker: None,\n-        }\n+/// Creates unidirectional buffer that acts like pair of connected single direction sockets.\n+///\n+/// The `max_buf_size` argument is the maximum amount of bytes that can be\n+/// written to a buffer before the it returns `Poll::Pending`.\n+#[cfg_attr(docsrs, doc(cfg(feature = \"io-util\")))]\n+pub fn simplex(max_buf_size: usize) -> SimplexStream {\n+    SimplexStream {\n+        buffer: BytesMut::new(),\n+        is_closed: false,\n+        max_buf_size,\n+        read_waker: None,\n+        write_waker: None,\n     }\n+}",
        "comment_created_at": "2024-08-05T14:26:20+00:00",
        "comment_author": "robgjansen",
        "comment_body": "I agree with the previous comment. In my case I would like to use these stream objects as drop-in replacements for `TcpStream` and related types.\r\n\r\nA `TcpStream` is specific to one \"node\", i.e., the client has a `TcpStream`, and the server has a `TcpStream`. For testing code that uses a `TcpStream`, we can replace with `DuplexStream`s\r\n\r\n```rust\r\nlet (client_rw, server_rw) = tokio::io::duplex(65_536);\r\n```\r\n\r\nHere we have both the client-side and server-side objects, and both are Read+Write. Thus, code written to generically handle IO on a `TcpStream` will function identically when replaced with the `DuplexStream`.\r\n\r\nNow in my use case, each `TcpStream` is split into a reader (`OwnedReadHalf`) and a writer (`OwnedWriteHalf`), \r\n\r\n```rust\r\nlet (read_half, write_half) = tcp_stream.into_split();\r\n```\r\n\r\nand my code operates generically on the Read and on the Write objects. To replicate that, I would need the `SimplexStream` to work similarly:\r\n\r\n```rust\r\nlet (client_read_half, server_write_half) = tokio::io::simplex(65_536);\r\n```\r\n\r\nAnd then you could stack two of these together to get functionality similar to the split of a `TcpStream`\r\n\r\n```rust\r\nlet (client_read_half, server_write_half) = tokio::io::simplex(65_536);\r\nlet (server_read_half, client_write_half) = tokio::io::simplex(65_536);\r\n```\r\n\r\nThen I could pass `client_read_half` / `client_write_half` to my client-side code, and `server_read_half` / `server_write_half ` to my server-side code.\r\n\r\nThere is a bit of a question about the API. Do we want `tokio::io::simplex` to return a `SimplexStream` that is Read+Write, and then support `SimplexStream::into_split` that returns a `SimplexStreamReadHalf` and `SimplexStreamWriteHalf`? Or should `tokio::io::simplex` directly return the tuple `(SimplexStreamReadHalf, SimplexStreamWriteHalf)` as in my examples above?\r\n\r\n(Also, I'm not sure if it makes sense to mix DuplexStreams and SimplexStreams or not, it sorta depends on how the simplex API looks.)",
        "pr_file_module": null
      },
      {
        "comment_id": "1704513085",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6589,
        "pr_file": "tokio/src/io/util/mem.rs",
        "discussion_id": "1703370343",
        "commented_code": "@@ -161,19 +181,24 @@ impl Drop for DuplexStream {\n     }\n }\n \n-// ===== impl Pipe =====\n+// ===== impl SimplexStream =====\n \n-impl Pipe {\n-    fn new(max_buf_size: usize) -> Self {\n-        Pipe {\n-            buffer: BytesMut::new(),\n-            is_closed: false,\n-            max_buf_size,\n-            read_waker: None,\n-            write_waker: None,\n-        }\n+/// Creates unidirectional buffer that acts like pair of connected single direction sockets.\n+///\n+/// The `max_buf_size` argument is the maximum amount of bytes that can be\n+/// written to a buffer before the it returns `Poll::Pending`.\n+#[cfg_attr(docsrs, doc(cfg(feature = \"io-util\")))]\n+pub fn simplex(max_buf_size: usize) -> SimplexStream {\n+    SimplexStream {\n+        buffer: BytesMut::new(),\n+        is_closed: false,\n+        max_buf_size,\n+        read_waker: None,\n+        write_waker: None,\n     }\n+}",
        "comment_created_at": "2024-08-05T18:52:53+00:00",
        "comment_author": "wutchzone",
        "comment_body": "IMO, we should not reinvent the wheel and try to reuse already existing APIs and facilities. It is true that for most of the use cases, we should rather return a pair of reader and writer instead of a single structure, that is a great point. Also, most of the channel-like structures already do this.\r\nFurthermore, since `SimplexStream` already implements `AsyncRead` and `AsyncWrite`, we can use already existing [`split(\u2026)`](https://docs.rs/tokio/latest/tokio/io/fn.split.html) to create reader and writer half (where possibly the split reader and writer half can be [`unsplit`](https://docs.rs/tokio/latest/tokio/io/struct.ReadHalf.html#method.unsplit)).\r\n\r\nWhat do you think of it now?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1438624972",
    "pr_number": 6224,
    "pr_file": "tokio-util/src/task/spawn_aborting.rs",
    "created_at": "2023-12-30T15:04:42+00:00",
    "commented_code": "+use std::ops::{Deref, DerefMut};\n+\n+use tokio::task::JoinHandle;\n+\n+use futures_core::Future;\n+\n+/// This is a wrapper type around JoinHandle that allows it to be dropped.\n+#[derive(Debug)]\n+pub struct DropHandle<T>(JoinHandle<T>);\n+\n+impl<T> Drop for DropHandle<T> {\n+    fn drop(&mut self) {\n+        self.0.abort();\n+    }\n+}\n+\n+impl<T> Deref for DropHandle<T> {\n+    type Target = JoinHandle<T>;\n+\n+    fn deref(&self) -> &Self::Target {\n+        &self.0\n+    }\n+}\n+\n+impl<T> DerefMut for DropHandle<T> {\n+    fn deref_mut(&mut self) -> &mut Self::Target {\n+        &mut self.0\n+    }\n+}\n+\n+/// This function spawns a task that aborts on drop instead of lingering.\n+pub fn spawn_aborting<F>(future: F) -> DropHandle<F::Output>\n+where\n+    F: Future + Send + 'static,\n+    F::Output: Send + 'static,\n+{\n+    DropHandle(tokio::spawn(future))\n+}",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "1438624972",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6224,
        "pr_file": "tokio-util/src/task/spawn_aborting.rs",
        "discussion_id": "1438624972",
        "commented_code": "@@ -0,0 +1,38 @@\n+use std::ops::{Deref, DerefMut};\n+\n+use tokio::task::JoinHandle;\n+\n+use futures_core::Future;\n+\n+/// This is a wrapper type around JoinHandle that allows it to be dropped.\n+#[derive(Debug)]\n+pub struct DropHandle<T>(JoinHandle<T>);\n+\n+impl<T> Drop for DropHandle<T> {\n+    fn drop(&mut self) {\n+        self.0.abort();\n+    }\n+}\n+\n+impl<T> Deref for DropHandle<T> {\n+    type Target = JoinHandle<T>;\n+\n+    fn deref(&self) -> &Self::Target {\n+        &self.0\n+    }\n+}\n+\n+impl<T> DerefMut for DropHandle<T> {\n+    fn deref_mut(&mut self) -> &mut Self::Target {\n+        &mut self.0\n+    }\n+}\n+\n+/// This function spawns a task that aborts on drop instead of lingering.\n+pub fn spawn_aborting<F>(future: F) -> DropHandle<F::Output>\n+where\n+    F: Future + Send + 'static,\n+    F::Output: Send + 'static,\n+{\n+    DropHandle(tokio::spawn(future))\n+}",
        "comment_created_at": "2023-12-30T15:04:42+00:00",
        "comment_author": "Darksonn",
        "comment_body": "I don't like this name. It sounds like something that would immediately make something abort.\r\n\r\nHow about `spawn_with_drop_handle` or `spawn_with_abort_handle`?",
        "pr_file_module": null
      },
      {
        "comment_id": "1438627646",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6224,
        "pr_file": "tokio-util/src/task/spawn_aborting.rs",
        "discussion_id": "1438624972",
        "commented_code": "@@ -0,0 +1,38 @@\n+use std::ops::{Deref, DerefMut};\n+\n+use tokio::task::JoinHandle;\n+\n+use futures_core::Future;\n+\n+/// This is a wrapper type around JoinHandle that allows it to be dropped.\n+#[derive(Debug)]\n+pub struct DropHandle<T>(JoinHandle<T>);\n+\n+impl<T> Drop for DropHandle<T> {\n+    fn drop(&mut self) {\n+        self.0.abort();\n+    }\n+}\n+\n+impl<T> Deref for DropHandle<T> {\n+    type Target = JoinHandle<T>;\n+\n+    fn deref(&self) -> &Self::Target {\n+        &self.0\n+    }\n+}\n+\n+impl<T> DerefMut for DropHandle<T> {\n+    fn deref_mut(&mut self) -> &mut Self::Target {\n+        &mut self.0\n+    }\n+}\n+\n+/// This function spawns a task that aborts on drop instead of lingering.\n+pub fn spawn_aborting<F>(future: F) -> DropHandle<F::Output>\n+where\n+    F: Future + Send + 'static,\n+    F::Output: Send + 'static,\n+{\n+    DropHandle(tokio::spawn(future))\n+}",
        "comment_created_at": "2023-12-30T15:14:52+00:00",
        "comment_author": "Darksonn",
        "comment_body": "Another possibility is to make this a constructor method. Then you would type `DropHandle::spawn`.",
        "pr_file_module": null
      },
      {
        "comment_id": "1462866310",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6224,
        "pr_file": "tokio-util/src/task/spawn_aborting.rs",
        "discussion_id": "1438624972",
        "commented_code": "@@ -0,0 +1,38 @@\n+use std::ops::{Deref, DerefMut};\n+\n+use tokio::task::JoinHandle;\n+\n+use futures_core::Future;\n+\n+/// This is a wrapper type around JoinHandle that allows it to be dropped.\n+#[derive(Debug)]\n+pub struct DropHandle<T>(JoinHandle<T>);\n+\n+impl<T> Drop for DropHandle<T> {\n+    fn drop(&mut self) {\n+        self.0.abort();\n+    }\n+}\n+\n+impl<T> Deref for DropHandle<T> {\n+    type Target = JoinHandle<T>;\n+\n+    fn deref(&self) -> &Self::Target {\n+        &self.0\n+    }\n+}\n+\n+impl<T> DerefMut for DropHandle<T> {\n+    fn deref_mut(&mut self) -> &mut Self::Target {\n+        &mut self.0\n+    }\n+}\n+\n+/// This function spawns a task that aborts on drop instead of lingering.\n+pub fn spawn_aborting<F>(future: F) -> DropHandle<F::Output>\n+where\n+    F: Future + Send + 'static,\n+    F::Output: Send + 'static,\n+{\n+    DropHandle(tokio::spawn(future))\n+}",
        "comment_created_at": "2024-01-23T08:10:43+00:00",
        "comment_author": "Xuanwo",
        "comment_body": "For API naming, how about using `spawn_abortable` which aligns with [Abortable](https://docs.rs/futures/latest/futures/future/struct.Abortable.html) in future crate.",
        "pr_file_module": null
      },
      {
        "comment_id": "1463719955",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6224,
        "pr_file": "tokio-util/src/task/spawn_aborting.rs",
        "discussion_id": "1438624972",
        "commented_code": "@@ -0,0 +1,38 @@\n+use std::ops::{Deref, DerefMut};\n+\n+use tokio::task::JoinHandle;\n+\n+use futures_core::Future;\n+\n+/// This is a wrapper type around JoinHandle that allows it to be dropped.\n+#[derive(Debug)]\n+pub struct DropHandle<T>(JoinHandle<T>);\n+\n+impl<T> Drop for DropHandle<T> {\n+    fn drop(&mut self) {\n+        self.0.abort();\n+    }\n+}\n+\n+impl<T> Deref for DropHandle<T> {\n+    type Target = JoinHandle<T>;\n+\n+    fn deref(&self) -> &Self::Target {\n+        &self.0\n+    }\n+}\n+\n+impl<T> DerefMut for DropHandle<T> {\n+    fn deref_mut(&mut self) -> &mut Self::Target {\n+        &mut self.0\n+    }\n+}\n+\n+/// This function spawns a task that aborts on drop instead of lingering.\n+pub fn spawn_aborting<F>(future: F) -> DropHandle<F::Output>\n+where\n+    F: Future + Send + 'static,\n+    F::Output: Send + 'static,\n+{\n+    DropHandle(tokio::spawn(future))\n+}",
        "comment_created_at": "2024-01-23T17:55:19+00:00",
        "comment_author": "hawkw",
        "comment_body": "Hmm, I don't love `spawn_abortable`, because in Tokio, _all_ spawned tasks are already abortable using `JoinHandle::abort()`. Naming the function `spawn_abortable` kind of implies that all other tasks cannot be aborted.\r\n\r\nMy personal preference would be to make the spawn function a function on the `DropHandle` type. IMO, we also ought to have a `DropHandle::new()` constructor that takes a `JoinHandle`, so that the abort-on-drop behavior can be added to `JoinHandle`s returned by `tokio::task::spawn_local` or `tokio::task::spawn_blocking`. \r\n\r\nI'd probably recommend an interface that looks sort of like this:\r\n\r\n```rust\r\nimpl<T> DropHandle<T> {\r\n    pub fn new<T>(task: JoinHandle<T>) -> Self{\r\n         Self(task)\r\n    }\r\n\r\n    pub fn spawn(future: impl Future<Output = T> + Send + 'static) -> DropHandle<T> {\r\n         Self(tokio::spwan(future))\r\n    }\r\n}\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1556198216",
    "pr_number": 6472,
    "pr_file": "tokio/src/sync/semaphore.rs",
    "created_at": "2024-04-08T17:45:31+00:00",
    "commented_code": "self.permits += other.permits;\n         other.permits = 0;\n     }\n+\n+    /// Detaches `n` permits from `self` and returns a new [`SemaphorePermit`] instance that holds `n` permits.\n+    ///\n+    /// It guarantees at least one permit held by both `self` and the new instance.",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "1556198216",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6472,
        "pr_file": "tokio/src/sync/semaphore.rs",
        "discussion_id": "1556198216",
        "commented_code": "@@ -990,6 +990,24 @@ impl<'a> SemaphorePermit<'a> {\n         self.permits += other.permits;\n         other.permits = 0;\n     }\n+\n+    /// Detaches `n` permits from `self` and returns a new [`SemaphorePermit`] instance that holds `n` permits.\n+    ///\n+    /// It guarantees at least one permit held by both `self` and the new instance.",
        "comment_created_at": "2024-04-08T17:45:31+00:00",
        "comment_author": "mox692",
        "comment_body": "I feel that allowing `detach(0)` (or `detach(n)` for a `SemaphorePermit` with `n` permits) could simplify the API. In fact, it's technically possible to create a zero-permit `SemaphorePermit` with `try_acquire_many(0)` even now.\r\nHave you experienced scenarios where you want the permit to always be more than 1?",
        "pr_file_module": null
      },
      {
        "comment_id": "1556917972",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6472,
        "pr_file": "tokio/src/sync/semaphore.rs",
        "discussion_id": "1556198216",
        "commented_code": "@@ -990,6 +990,24 @@ impl<'a> SemaphorePermit<'a> {\n         self.permits += other.permits;\n         other.permits = 0;\n     }\n+\n+    /// Detaches `n` permits from `self` and returns a new [`SemaphorePermit`] instance that holds `n` permits.\n+    ///\n+    /// It guarantees at least one permit held by both `self` and the new instance.",
        "comment_created_at": "2024-04-09T05:21:46+00:00",
        "comment_author": "vvvviiv",
        "comment_body": "I limited this because the zero-permit `SemaphorePermit` usually makes no sense, and we have no way to tell the user how many permits are held by a `SemaphorePermit`.\r\n\r\nWhat about adding a `held_permits` (or a better name) method to return the number of permits held by a `SemaphorePermit` and removing these restrictions?",
        "pr_file_module": null
      },
      {
        "comment_id": "1557553652",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6472,
        "pr_file": "tokio/src/sync/semaphore.rs",
        "discussion_id": "1556198216",
        "commented_code": "@@ -990,6 +990,24 @@ impl<'a> SemaphorePermit<'a> {\n         self.permits += other.permits;\n         other.permits = 0;\n     }\n+\n+    /// Detaches `n` permits from `self` and returns a new [`SemaphorePermit`] instance that holds `n` permits.\n+    ///\n+    /// It guarantees at least one permit held by both `self` and the new instance.",
        "comment_created_at": "2024-04-09T12:30:22+00:00",
        "comment_author": "mox692",
        "comment_body": "> What about adding a held_permits (or a better name) method to return the number of permits held by a SemaphorePermit and removing these restrictions?\r\n\r\nSounds good to me.\r\n\r\n@Darksonn \r\nDo you see any problems with this approach?",
        "pr_file_module": null
      },
      {
        "comment_id": "1557558357",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6472,
        "pr_file": "tokio/src/sync/semaphore.rs",
        "discussion_id": "1556198216",
        "commented_code": "@@ -990,6 +990,24 @@ impl<'a> SemaphorePermit<'a> {\n         self.permits += other.permits;\n         other.permits = 0;\n     }\n+\n+    /// Detaches `n` permits from `self` and returns a new [`SemaphorePermit`] instance that holds `n` permits.\n+    ///\n+    /// It guarantees at least one permit held by both `self` and the new instance.",
        "comment_created_at": "2024-04-09T12:34:07+00:00",
        "comment_author": "Darksonn",
        "comment_body": "If all of the `*acquire_many` methods already allow zero permits, then I see no harm in allowing it here. I would perhaps all the method `num_permits`?",
        "pr_file_module": null
      }
    ]
  }
]