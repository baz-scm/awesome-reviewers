[
  {
    "discussion_id": "2155498353",
    "pr_number": 7375,
    "pr_file": "tokio-macros/src/entry.rs",
    "created_at": "2025-06-18T21:01:30+00:00",
    "commented_code": "let flavor = self.flavor.unwrap_or(self.default_flavor);\n         let worker_threads = match (flavor, self.worker_threads) {\n-            (F::CurrentThread, Some((_, worker_threads_span))) => {\n+            (F::CurrentThread | F::Local, Some((_, worker_threads_span))) => {\n                 let msg = format!(\n                     \"The `worker_threads` option requires the `multi_thread` runtime flavor. Use `#[{}(flavor = \\\"multi_thread\\\")]`\",\n                     self.macro_name(),\n                 );\n                 return Err(syn::Error::new(worker_threads_span, msg));\n             }\n-            (F::CurrentThread, None) => None,\n+            (F::CurrentThread | F::Local, None) => None,\n             (F::Threaded, worker_threads) if self.rt_multi_thread_available => {",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "2155498353",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7375,
        "pr_file": "tokio-macros/src/entry.rs",
        "discussion_id": "2155498353",
        "commented_code": "@@ -178,14 +180,14 @@ impl Configuration {\n \n         let flavor = self.flavor.unwrap_or(self.default_flavor);\n         let worker_threads = match (flavor, self.worker_threads) {\n-            (F::CurrentThread, Some((_, worker_threads_span))) => {\n+            (F::CurrentThread | F::Local, Some((_, worker_threads_span))) => {\n                 let msg = format!(\n                     \"The `worker_threads` option requires the `multi_thread` runtime flavor. Use `#[{}(flavor = \\\"multi_thread\\\")]`\",\n                     self.macro_name(),\n                 );\n                 return Err(syn::Error::new(worker_threads_span, msg));\n             }\n-            (F::CurrentThread, None) => None,\n+            (F::CurrentThread | F::Local, None) => None,\n             (F::Threaded, worker_threads) if self.rt_multi_thread_available => {",
        "comment_created_at": "2025-06-18T21:01:30+00:00",
        "comment_author": "Darksonn",
        "comment_body": "Please add logic to `rt_multi_thread_available` to detect whether `--cfg tokio_unstable` is set and emit a hard error if it is not.",
        "pr_file_module": null
      },
      {
        "comment_id": "2161474972",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7375,
        "pr_file": "tokio-macros/src/entry.rs",
        "discussion_id": "2155498353",
        "commented_code": "@@ -178,14 +180,14 @@ impl Configuration {\n \n         let flavor = self.flavor.unwrap_or(self.default_flavor);\n         let worker_threads = match (flavor, self.worker_threads) {\n-            (F::CurrentThread, Some((_, worker_threads_span))) => {\n+            (F::CurrentThread | F::Local, Some((_, worker_threads_span))) => {\n                 let msg = format!(\n                     \"The `worker_threads` option requires the `multi_thread` runtime flavor. Use `#[{}(flavor = \\\"multi_thread\\\")]`\",\n                     self.macro_name(),\n                 );\n                 return Err(syn::Error::new(worker_threads_span, msg));\n             }\n-            (F::CurrentThread, None) => None,\n+            (F::CurrentThread | F::Local, None) => None,\n             (F::Threaded, worker_threads) if self.rt_multi_thread_available => {",
        "comment_created_at": "2025-06-23T12:12:15+00:00",
        "comment_author": "Twey",
        "comment_body": "I'm not sure I understand this comment.  Did you mean to add the logic to `RuntimeFlavor::from_str`?",
        "pr_file_module": null
      },
      {
        "comment_id": "2161539006",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7375,
        "pr_file": "tokio-macros/src/entry.rs",
        "discussion_id": "2155498353",
        "commented_code": "@@ -178,14 +180,14 @@ impl Configuration {\n \n         let flavor = self.flavor.unwrap_or(self.default_flavor);\n         let worker_threads = match (flavor, self.worker_threads) {\n-            (F::CurrentThread, Some((_, worker_threads_span))) => {\n+            (F::CurrentThread | F::Local, Some((_, worker_threads_span))) => {\n                 let msg = format!(\n                     \"The `worker_threads` option requires the `multi_thread` runtime flavor. Use `#[{}(flavor = \\\"multi_thread\\\")]`\",\n                     self.macro_name(),\n                 );\n                 return Err(syn::Error::new(worker_threads_span, msg));\n             }\n-            (F::CurrentThread, None) => None,\n+            (F::CurrentThread | F::Local, None) => None,\n             (F::Threaded, worker_threads) if self.rt_multi_thread_available => {",
        "comment_created_at": "2025-06-23T12:46:23+00:00",
        "comment_author": "Darksonn",
        "comment_body": "The error should be similar to this error:\r\n\r\nhttps://github.com/tokio-rs/tokio/blob/2506c9fa9916a1bdffbc762f7eb2ae5c2fd23836/tokio-macros/src/entry.rs#L193-L197",
        "pr_file_module": null
      },
      {
        "comment_id": "2161563571",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7375,
        "pr_file": "tokio-macros/src/entry.rs",
        "discussion_id": "2155498353",
        "commented_code": "@@ -178,14 +180,14 @@ impl Configuration {\n \n         let flavor = self.flavor.unwrap_or(self.default_flavor);\n         let worker_threads = match (flavor, self.worker_threads) {\n-            (F::CurrentThread, Some((_, worker_threads_span))) => {\n+            (F::CurrentThread | F::Local, Some((_, worker_threads_span))) => {\n                 let msg = format!(\n                     \"The `worker_threads` option requires the `multi_thread` runtime flavor. Use `#[{}(flavor = \\\"multi_thread\\\")]`\",\n                     self.macro_name(),\n                 );\n                 return Err(syn::Error::new(worker_threads_span, msg));\n             }\n-            (F::CurrentThread, None) => None,\n+            (F::CurrentThread | F::Local, None) => None,\n             (F::Threaded, worker_threads) if self.rt_multi_thread_available => {",
        "comment_created_at": "2025-06-23T12:57:02+00:00",
        "comment_author": "Twey",
        "comment_body": "Maybe you meant https://github.com/tokio-rs/tokio/pull/7375/commits/a0ca77ee1cc33d1993d1f85aae6bf66641192fa0; if I've misinterpreted please feel free to suggest changes :)",
        "pr_file_module": null
      },
      {
        "comment_id": "2163893554",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7375,
        "pr_file": "tokio-macros/src/entry.rs",
        "discussion_id": "2155498353",
        "commented_code": "@@ -178,14 +180,14 @@ impl Configuration {\n \n         let flavor = self.flavor.unwrap_or(self.default_flavor);\n         let worker_threads = match (flavor, self.worker_threads) {\n-            (F::CurrentThread, Some((_, worker_threads_span))) => {\n+            (F::CurrentThread | F::Local, Some((_, worker_threads_span))) => {\n                 let msg = format!(\n                     \"The `worker_threads` option requires the `multi_thread` runtime flavor. Use `#[{}(flavor = \\\"multi_thread\\\")]`\",\n                     self.macro_name(),\n                 );\n                 return Err(syn::Error::new(worker_threads_span, msg));\n             }\n-            (F::CurrentThread, None) => None,\n+            (F::CurrentThread | F::Local, None) => None,\n             (F::Threaded, worker_threads) if self.rt_multi_thread_available => {",
        "comment_created_at": "2025-06-24T12:44:17+00:00",
        "comment_author": "Twey",
        "comment_body": "Sorry, I just saw your comment.  Is https://github.com/tokio-rs/tokio/commit/4363203e67bb39edf8f959d88fd4940a0771c688 more what you had in mind?",
        "pr_file_module": null
      },
      {
        "comment_id": "2163900325",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7375,
        "pr_file": "tokio-macros/src/entry.rs",
        "discussion_id": "2155498353",
        "commented_code": "@@ -178,14 +180,14 @@ impl Configuration {\n \n         let flavor = self.flavor.unwrap_or(self.default_flavor);\n         let worker_threads = match (flavor, self.worker_threads) {\n-            (F::CurrentThread, Some((_, worker_threads_span))) => {\n+            (F::CurrentThread | F::Local, Some((_, worker_threads_span))) => {\n                 let msg = format!(\n                     \"The `worker_threads` option requires the `multi_thread` runtime flavor. Use `#[{}(flavor = \\\"multi_thread\\\")]`\",\n                     self.macro_name(),\n                 );\n                 return Err(syn::Error::new(worker_threads_span, msg));\n             }\n-            (F::CurrentThread, None) => None,\n+            (F::CurrentThread | F::Local, None) => None,\n             (F::Threaded, worker_threads) if self.rt_multi_thread_available => {",
        "comment_created_at": "2025-06-24T12:45:54+00:00",
        "comment_author": "Darksonn",
        "comment_body": "I think both are okay.",
        "pr_file_module": null
      },
      {
        "comment_id": "2163961617",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7375,
        "pr_file": "tokio-macros/src/entry.rs",
        "discussion_id": "2155498353",
        "commented_code": "@@ -178,14 +180,14 @@ impl Configuration {\n \n         let flavor = self.flavor.unwrap_or(self.default_flavor);\n         let worker_threads = match (flavor, self.worker_threads) {\n-            (F::CurrentThread, Some((_, worker_threads_span))) => {\n+            (F::CurrentThread | F::Local, Some((_, worker_threads_span))) => {\n                 let msg = format!(\n                     \"The `worker_threads` option requires the `multi_thread` runtime flavor. Use `#[{}(flavor = \\\"multi_thread\\\")]`\",\n                     self.macro_name(),\n                 );\n                 return Err(syn::Error::new(worker_threads_span, msg));\n             }\n-            (F::CurrentThread, None) => None,\n+            (F::CurrentThread | F::Local, None) => None,\n             (F::Threaded, worker_threads) if self.rt_multi_thread_available => {",
        "comment_created_at": "2025-06-24T13:08:21+00:00",
        "comment_author": "Twey",
        "comment_body": "This is harder than it appears because [`RUSTFLAGS` is not passed to proc macros](https://doc.rust-lang.org/nightly/cargo/reference/unstable.html#target-applies-to-host).  I guess we have to _emit_ a `cfg` check, so it actually can't live in either of these places.",
        "pr_file_module": null
      },
      {
        "comment_id": "2163987461",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7375,
        "pr_file": "tokio-macros/src/entry.rs",
        "discussion_id": "2155498353",
        "commented_code": "@@ -178,14 +180,14 @@ impl Configuration {\n \n         let flavor = self.flavor.unwrap_or(self.default_flavor);\n         let worker_threads = match (flavor, self.worker_threads) {\n-            (F::CurrentThread, Some((_, worker_threads_span))) => {\n+            (F::CurrentThread | F::Local, Some((_, worker_threads_span))) => {\n                 let msg = format!(\n                     \"The `worker_threads` option requires the `multi_thread` runtime flavor. Use `#[{}(flavor = \\\"multi_thread\\\")]`\",\n                     self.macro_name(),\n                 );\n                 return Err(syn::Error::new(worker_threads_span, msg));\n             }\n-            (F::CurrentThread, None) => None,\n+            (F::CurrentThread | F::Local, None) => None,\n             (F::Threaded, worker_threads) if self.rt_multi_thread_available => {",
        "comment_created_at": "2025-06-24T13:19:45+00:00",
        "comment_author": "Twey",
        "comment_body": "44a31b1be51de957d5d4661599e3b9850bf4b108 seems to work in my local tests.",
        "pr_file_module": null
      },
      {
        "comment_id": "2164249335",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7375,
        "pr_file": "tokio-macros/src/entry.rs",
        "discussion_id": "2155498353",
        "commented_code": "@@ -178,14 +180,14 @@ impl Configuration {\n \n         let flavor = self.flavor.unwrap_or(self.default_flavor);\n         let worker_threads = match (flavor, self.worker_threads) {\n-            (F::CurrentThread, Some((_, worker_threads_span))) => {\n+            (F::CurrentThread | F::Local, Some((_, worker_threads_span))) => {\n                 let msg = format!(\n                     \"The `worker_threads` option requires the `multi_thread` runtime flavor. Use `#[{}(flavor = \\\"multi_thread\\\")]`\",\n                     self.macro_name(),\n                 );\n                 return Err(syn::Error::new(worker_threads_span, msg));\n             }\n-            (F::CurrentThread, None) => None,\n+            (F::CurrentThread | F::Local, None) => None,\n             (F::Threaded, worker_threads) if self.rt_multi_thread_available => {",
        "comment_created_at": "2025-06-24T14:53:31+00:00",
        "comment_author": "Darksonn",
        "comment_body": "Doesn't that also trigger other unrelated errors when it fails?\r\n\r\nWhat we do today is essentially define the `main` macro two times to pass different values to [the `rt_multi_thread` boolean](https://github.com/tokio-rs/tokio/blob/master/tokio-macros/src/entry.rs#L488), and have `lib.rs` do this:\r\n```rs\r\n#[cfg(feature = \"rt-multi-thread\")]\r\npub use tokio_macros::main;\r\n#[cfg(not(feature = \"rt-multi-thread\"))]\r\npub use tokio_macros::main_rt as main;\r\n```\r\nThis way, the macro knows based on the cfgs that apply in the main Tokio crate. We could use the same approach and have four macros.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2096544823",
    "pr_number": 7307,
    "pr_file": "tokio/src/macros/join.rs",
    "created_at": "2025-05-19T22:02:55+00:00",
    "commented_code": "///\n         /// [`tokio::spawn`]: crate::spawn\n         ///\n+        /// # Fairness\n+        ///\n+        /// By default, `join!`'s generated future rotates which contained\n+        /// future is polled first whenever it is woken.\n+        ///\n+        /// This behavior can be overridden by adding `biased;` to the beginning of the\n+        /// macro usage. See the examples for details. This will cause `join` to poll\n+        /// the futures in the order they appear from top to bottom.\n+        ///\n+        /// You may want this if your futures may interact in a way where known polling order is significant.\n+        ///\n+        /// But there is an important caveat to this mode. It becomes your responsibility\n+        /// to ensure that the polling order of your futures is fair. If for example you\n+        /// are joining a stream and a shutdown future, and the stream has a\n+        /// huge volume of messages that takes a long time to finish processing per poll, you should\n+        /// place the shutdown future earlier in the `join!` list to ensure that it is\n+        /// always polled, and will not be delayed due to the stream future taking a long time to return\n+        /// `Poll::Pending`.",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "2096544823",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7307,
        "pr_file": "tokio/src/macros/join.rs",
        "discussion_id": "2096544823",
        "commented_code": "@@ -32,6 +32,25 @@ macro_rules! doc {\n         ///\n         /// [`tokio::spawn`]: crate::spawn\n         ///\n+        /// # Fairness\n+        ///\n+        /// By default, `join!`'s generated future rotates which contained\n+        /// future is polled first whenever it is woken.\n+        ///\n+        /// This behavior can be overridden by adding `biased;` to the beginning of the\n+        /// macro usage. See the examples for details. This will cause `join` to poll\n+        /// the futures in the order they appear from top to bottom.\n+        ///\n+        /// You may want this if your futures may interact in a way where known polling order is significant.\n+        ///\n+        /// But there is an important caveat to this mode. It becomes your responsibility\n+        /// to ensure that the polling order of your futures is fair. If for example you\n+        /// are joining a stream and a shutdown future, and the stream has a\n+        /// huge volume of messages that takes a long time to finish processing per poll, you should\n+        /// place the shutdown future earlier in the `join!` list to ensure that it is\n+        /// always polled, and will not be delayed due to the stream future taking a long time to return\n+        /// `Poll::Pending`.",
        "comment_created_at": "2025-05-19T22:02:55+00:00",
        "comment_author": "Darksonn",
        "comment_body": "I don't think that a shutdown future is an amazing example here. That makes sense for `select!`, but you wouldn't really have a shutdown future in `join!`. Not sure what a better example would be, though.",
        "pr_file_module": null
      },
      {
        "comment_id": "2098758517",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7307,
        "pr_file": "tokio/src/macros/join.rs",
        "discussion_id": "2096544823",
        "commented_code": "@@ -32,6 +32,25 @@ macro_rules! doc {\n         ///\n         /// [`tokio::spawn`]: crate::spawn\n         ///\n+        /// # Fairness\n+        ///\n+        /// By default, `join!`'s generated future rotates which contained\n+        /// future is polled first whenever it is woken.\n+        ///\n+        /// This behavior can be overridden by adding `biased;` to the beginning of the\n+        /// macro usage. See the examples for details. This will cause `join` to poll\n+        /// the futures in the order they appear from top to bottom.\n+        ///\n+        /// You may want this if your futures may interact in a way where known polling order is significant.\n+        ///\n+        /// But there is an important caveat to this mode. It becomes your responsibility\n+        /// to ensure that the polling order of your futures is fair. If for example you\n+        /// are joining a stream and a shutdown future, and the stream has a\n+        /// huge volume of messages that takes a long time to finish processing per poll, you should\n+        /// place the shutdown future earlier in the `join!` list to ensure that it is\n+        /// always polled, and will not be delayed due to the stream future taking a long time to return\n+        /// `Poll::Pending`.",
        "comment_created_at": "2025-05-20T20:00:13+00:00",
        "comment_author": "jlizen",
        "comment_body": "Here is a real-world example usage involving a shutdown signal: https://github.com/awslabs/aws-lambda-rust-runtime/blob/main/lambda-runtime/src/lib.rs#L227\r\n\r\nThe distinction here is that the other task is a _server_ future, not a stream future, meaning it will generally keep running and generating new request futures. So we need to continue driving it. Even if the shutdown future will only ever come up once and then resolve, we still need to check it first every time.\r\n\r\nI guess technically the server future will generally be dispatching work to read from sockets rather than processing the messages directly (ie not long polls as a concern), but anyway you want to shut down before dispatching that work.\r\n\r\nAnyway I'll tweak wording from stream -> server and finesse it a bit more.",
        "pr_file_module": null
      },
      {
        "comment_id": "2098764824",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7307,
        "pr_file": "tokio/src/macros/join.rs",
        "discussion_id": "2096544823",
        "commented_code": "@@ -32,6 +32,25 @@ macro_rules! doc {\n         ///\n         /// [`tokio::spawn`]: crate::spawn\n         ///\n+        /// # Fairness\n+        ///\n+        /// By default, `join!`'s generated future rotates which contained\n+        /// future is polled first whenever it is woken.\n+        ///\n+        /// This behavior can be overridden by adding `biased;` to the beginning of the\n+        /// macro usage. See the examples for details. This will cause `join` to poll\n+        /// the futures in the order they appear from top to bottom.\n+        ///\n+        /// You may want this if your futures may interact in a way where known polling order is significant.\n+        ///\n+        /// But there is an important caveat to this mode. It becomes your responsibility\n+        /// to ensure that the polling order of your futures is fair. If for example you\n+        /// are joining a stream and a shutdown future, and the stream has a\n+        /// huge volume of messages that takes a long time to finish processing per poll, you should\n+        /// place the shutdown future earlier in the `join!` list to ensure that it is\n+        /// always polled, and will not be delayed due to the stream future taking a long time to return\n+        /// `Poll::Pending`.",
        "comment_created_at": "2025-05-20T20:04:48+00:00",
        "comment_author": "jlizen",
        "comment_body": "Also renaming the section `Fairness` -> `Poll Ordering`, it's not really about fairness anymore in the example given.",
        "pr_file_module": null
      },
      {
        "comment_id": "2100882281",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7307,
        "pr_file": "tokio/src/macros/join.rs",
        "discussion_id": "2096544823",
        "commented_code": "@@ -32,6 +32,25 @@ macro_rules! doc {\n         ///\n         /// [`tokio::spawn`]: crate::spawn\n         ///\n+        /// # Fairness\n+        ///\n+        /// By default, `join!`'s generated future rotates which contained\n+        /// future is polled first whenever it is woken.\n+        ///\n+        /// This behavior can be overridden by adding `biased;` to the beginning of the\n+        /// macro usage. See the examples for details. This will cause `join` to poll\n+        /// the futures in the order they appear from top to bottom.\n+        ///\n+        /// You may want this if your futures may interact in a way where known polling order is significant.\n+        ///\n+        /// But there is an important caveat to this mode. It becomes your responsibility\n+        /// to ensure that the polling order of your futures is fair. If for example you\n+        /// are joining a stream and a shutdown future, and the stream has a\n+        /// huge volume of messages that takes a long time to finish processing per poll, you should\n+        /// place the shutdown future earlier in the `join!` list to ensure that it is\n+        /// always polled, and will not be delayed due to the stream future taking a long time to return\n+        /// `Poll::Pending`.",
        "comment_created_at": "2025-05-21T18:02:30+00:00",
        "comment_author": "jlizen",
        "comment_body": "Actually, I changed it back. My initial rework was basically restating that deterministic ordering is useful. But it's important for readers to consider the case that one future might take a long time to poll and starve the other, that was the point of the fairness discussion.\r\n\r\nBased on the above lambda runtime link, I do think there are cases where you would be joining a shutdown future, so it's probably still relevant? Anyway I think it does a good job of illustrating the fairness risk even if the specific use case isn't the most universal?\r\n\r\nGlad to keep thinking about it though if not sold and try to come up with another example.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2126138222",
    "pr_number": 7307,
    "pr_file": "tokio/src/macros/try_join.rs",
    "created_at": "2025-06-04T09:29:20+00:00",
    "commented_code": "///\n         /// [`tokio::spawn`]: crate::spawn\n         ///\n+        /// # Fairness",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "2126138222",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7307,
        "pr_file": "tokio/src/macros/try_join.rs",
        "discussion_id": "2126138222",
        "commented_code": "@@ -30,6 +30,25 @@ macro_rules! doc {\n         ///\n         /// [`tokio::spawn`]: crate::spawn\n         ///\n+        /// # Fairness",
        "comment_created_at": "2025-06-04T09:29:20+00:00",
        "comment_author": "Darksonn",
        "comment_body": "Please make sure that the section names for `try_join!` match those we have for `join!`.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2134799770",
    "pr_number": 7307,
    "pr_file": "tokio/src/macros/try_join.rs",
    "created_at": "2025-06-08T19:01:31+00:00",
    "commented_code": "///\n         /// [`tokio::spawn`]: crate::spawn\n         ///\n+        /// ## Fairness\n+        ///\n+        /// By default, `try_join!`'s generated future rotates which\n+        /// contained future is polled first whenever it is woken.\n+        ///\n+        /// This behavior can be overridden by adding `biased;` to the beginning of the\n+        /// macro usage. See the examples for details. This will cause `try_join` to poll\n+        /// the futures in the order they appear from top to bottom.\n+        ///\n+        /// You may want this if your futures may interact in a way where known polling order is significant.\n+        ///\n+        /// But there is an important caveat to this mode. It becomes your responsibility\n+        /// to ensure that the polling order of your futures is fair. If for example you\n+        /// are joining a stream and a shutdown future, and the stream has a\n+        /// huge volume of messages that takes a long time to finish processing per poll, you should\n+        /// place the shutdown future earlier in the `join!` list to ensure that it is",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "2134799770",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7307,
        "pr_file": "tokio/src/macros/try_join.rs",
        "discussion_id": "2134799770",
        "commented_code": "@@ -30,6 +30,25 @@ macro_rules! doc {\n         ///\n         /// [`tokio::spawn`]: crate::spawn\n         ///\n+        /// ## Fairness\n+        ///\n+        /// By default, `try_join!`'s generated future rotates which\n+        /// contained future is polled first whenever it is woken.\n+        ///\n+        /// This behavior can be overridden by adding `biased;` to the beginning of the\n+        /// macro usage. See the examples for details. This will cause `try_join` to poll\n+        /// the futures in the order they appear from top to bottom.\n+        ///\n+        /// You may want this if your futures may interact in a way where known polling order is significant.\n+        ///\n+        /// But there is an important caveat to this mode. It becomes your responsibility\n+        /// to ensure that the polling order of your futures is fair. If for example you\n+        /// are joining a stream and a shutdown future, and the stream has a\n+        /// huge volume of messages that takes a long time to finish processing per poll, you should\n+        /// place the shutdown future earlier in the `join!` list to ensure that it is",
        "comment_created_at": "2025-06-08T19:01:31+00:00",
        "comment_author": "Darksonn",
        "comment_body": "```suggestion\r\n        /// place the shutdown future earlier in the `try_join!` list to ensure that it is\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2134800556",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7307,
        "pr_file": "tokio/src/macros/try_join.rs",
        "discussion_id": "2134799770",
        "commented_code": "@@ -30,6 +30,25 @@ macro_rules! doc {\n         ///\n         /// [`tokio::spawn`]: crate::spawn\n         ///\n+        /// ## Fairness\n+        ///\n+        /// By default, `try_join!`'s generated future rotates which\n+        /// contained future is polled first whenever it is woken.\n+        ///\n+        /// This behavior can be overridden by adding `biased;` to the beginning of the\n+        /// macro usage. See the examples for details. This will cause `try_join` to poll\n+        /// the futures in the order they appear from top to bottom.\n+        ///\n+        /// You may want this if your futures may interact in a way where known polling order is significant.\n+        ///\n+        /// But there is an important caveat to this mode. It becomes your responsibility\n+        /// to ensure that the polling order of your futures is fair. If for example you\n+        /// are joining a stream and a shutdown future, and the stream has a\n+        /// huge volume of messages that takes a long time to finish processing per poll, you should\n+        /// place the shutdown future earlier in the `join!` list to ensure that it is",
        "comment_created_at": "2025-06-08T19:05:06+00:00",
        "comment_author": "jlizen",
        "comment_body": "Thanks, sorry to miss thay",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2182919345",
    "pr_number": 7431,
    "pr_file": "tokio/tests/rt_threaded.rs",
    "created_at": "2025-07-03T14:19:11+00:00",
    "commented_code": "})\n }\n \n+// Tests that when a task is notified by another task and is placed in the LIFO\n+// slot, and then the notifying task blocks the runtime, the notified task will\n+// be stolen by another worker thread.\n+//\n+// Integration test for: https://github.com/tokio-rs/tokio/issues/4941\n+#[test]\n+fn lifo_stealable() {\n+    use std::time::Duration;\n+\n+    let (unblock_tx, unblock_rx) = tokio::sync::oneshot::channel();\n+    let (task_started_tx, task_started_rx) = tokio::sync::oneshot::channel();\n+    let (block_thread_tx, block_thread_rx) = mpsc::channel::<()>();\n+    let rt = runtime::Builder::new_multi_thread()\n+        // Make sure there are enough workers that one can be parked running the\n+        // I/O driver and another can be parked running the timer wheel and\n+        // there's still at least one worker free to steal the blocked task.\n+        .worker_threads(4)\n+        .enable_time()\n+        .build()\n+        .unwrap();\n+\n+    rt.block_on(async {\n+        // Keep the runtime busy so that the workers that might steal the\n+        // blocked task don't all park themselves forever.\n+        let churn = tokio::spawn(async move {\n+            loop {\n+                tokio::time::sleep(Duration::from_millis(64)).await;\n+            }\n+        });\n+\n+        let blocked_task_joined = tokio::spawn(async move {\n+            println!(\"[LIFO] task started\");\n+            task_started_tx.send(()).unwrap();\n+            println!(\"[LIFO] task waiting for wakeup...\");\n+            unblock_rx.await.unwrap();\n+            println!(\"[LIFO] task running after wakeup\");\n+        });",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "2182919345",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7431,
        "pr_file": "tokio/tests/rt_threaded.rs",
        "discussion_id": "2182919345",
        "commented_code": "@@ -692,6 +692,77 @@ fn mutex_in_block_in_place() {\n     })\n }\n \n+// Tests that when a task is notified by another task and is placed in the LIFO\n+// slot, and then the notifying task blocks the runtime, the notified task will\n+// be stolen by another worker thread.\n+//\n+// Integration test for: https://github.com/tokio-rs/tokio/issues/4941\n+#[test]\n+fn lifo_stealable() {\n+    use std::time::Duration;\n+\n+    let (unblock_tx, unblock_rx) = tokio::sync::oneshot::channel();\n+    let (task_started_tx, task_started_rx) = tokio::sync::oneshot::channel();\n+    let (block_thread_tx, block_thread_rx) = mpsc::channel::<()>();\n+    let rt = runtime::Builder::new_multi_thread()\n+        // Make sure there are enough workers that one can be parked running the\n+        // I/O driver and another can be parked running the timer wheel and\n+        // there's still at least one worker free to steal the blocked task.\n+        .worker_threads(4)\n+        .enable_time()\n+        .build()\n+        .unwrap();\n+\n+    rt.block_on(async {\n+        // Keep the runtime busy so that the workers that might steal the\n+        // blocked task don't all park themselves forever.\n+        let churn = tokio::spawn(async move {\n+            loop {\n+                tokio::time::sleep(Duration::from_millis(64)).await;\n+            }\n+        });\n+\n+        let blocked_task_joined = tokio::spawn(async move {\n+            println!(\"[LIFO] task started\");\n+            task_started_tx.send(()).unwrap();\n+            println!(\"[LIFO] task waiting for wakeup...\");\n+            unblock_rx.await.unwrap();\n+            println!(\"[LIFO] task running after wakeup\");\n+        });",
        "comment_created_at": "2025-07-03T14:19:11+00:00",
        "comment_author": "ADD-SP",
        "comment_body": "```suggestion\r\n        // this task will be pushed into the LIFO slot\r\n        let blocked_task_joined = tokio::spawn(async move {\r\n            // this task was taken out the LIFO slot\r\n            println!(\"[LIFO] task started\");\r\n            task_started_tx.send(()).unwrap();\r\n            println!(\"[LIFO] task waiting for wakeup...\");\r\n            unblock_rx.await.unwrap();\r\n            println!(\"[LIFO] task running after wakeup\");\r\n        });\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2134798086",
    "pr_number": 7396,
    "pr_file": "tokio/src/runtime/park.rs",
    "created_at": "2025-06-08T18:53:20+00:00",
    "commented_code": "const PARKED: usize = 1;\n const NOTIFIED: usize = 2;\n \n-tokio_thread_local! {\n-    static CURRENT_PARKER: ParkThread = ParkThread::new();\n-}",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "2134798086",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 7396,
        "pr_file": "tokio/src/runtime/park.rs",
        "discussion_id": "2134798086",
        "commented_code": "@@ -29,10 +28,6 @@ const EMPTY: usize = 0;\n const PARKED: usize = 1;\n const NOTIFIED: usize = 2;\n \n-tokio_thread_local! {\n-    static CURRENT_PARKER: ParkThread = ParkThread::new();\n-}",
        "comment_created_at": "2025-06-08T18:53:20+00:00",
        "comment_author": "Darksonn",
        "comment_body": "The current logic exists to reuse the thread parker logic when `block_on` is used many times. What is the reason for not reusing it?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1701806449",
    "pr_number": 6742,
    "pr_file": "tokio/src/runtime/builder.rs",
    "created_at": "2024-08-02T12:50:56+00:00",
    "commented_code": "self\n     }\n \n+    /// Executes function `f` just before a task is spawned.\n+    ///\n+    /// `f` is called within the Tokio context, so functions like\n+    /// [`tokio::spawn`](crate::spawn) can be called, and may result in this callback being\n+    /// invoked immediately.\n+    ///\n+    /// This can be used for bookkeeping or monitoring purposes.\n+    ///\n+    /// Note: There can only be one spawn callback for a runtime; calling this function more\n+    /// than once replaces the last callback defined, rather than adding to it.\n+    ///\n+    /// This *does not* support [`LocalSet`](crate::task::LocalSet) at this time.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// # use tokio::runtime;\n+    /// # pub fn main() {\n+    /// let runtime = runtime::Builder::new_current_thread()\n+    ///     .on_task_spawn(|_| {\n+    ///         println!(\"spawning task\");\n+    ///     })\n+    ///     .build()\n+    ///     .unwrap();\n+    ///\n+    /// runtime.block_on(async {\n+    ///     tokio::task::spawn(std::future::ready(()));\n+    ///\n+    ///     for _ in 0..64 {\n+    ///         tokio::task::yield_now().await;\n+    ///     }\n+    /// })\n+    /// # }\n+    /// ```\n+    #[cfg(not(loom))]\n+    pub fn on_task_spawn<F>(&mut self, f: F) -> &mut Self\n+    where\n+        F: Fn(&TaskMeta<'_>) + Send + Sync + 'static,\n+    {\n+        self.before_spawn = Some(std::sync::Arc::new(f));\n+        self\n+    }",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "1701806449",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6742,
        "pr_file": "tokio/src/runtime/builder.rs",
        "discussion_id": "1701806449",
        "commented_code": "@@ -677,6 +690,91 @@ impl Builder {\n         self\n     }\n \n+    /// Executes function `f` just before a task is spawned.\n+    ///\n+    /// `f` is called within the Tokio context, so functions like\n+    /// [`tokio::spawn`](crate::spawn) can be called, and may result in this callback being\n+    /// invoked immediately.\n+    ///\n+    /// This can be used for bookkeeping or monitoring purposes.\n+    ///\n+    /// Note: There can only be one spawn callback for a runtime; calling this function more\n+    /// than once replaces the last callback defined, rather than adding to it.\n+    ///\n+    /// This *does not* support [`LocalSet`](crate::task::LocalSet) at this time.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// # use tokio::runtime;\n+    /// # pub fn main() {\n+    /// let runtime = runtime::Builder::new_current_thread()\n+    ///     .on_task_spawn(|_| {\n+    ///         println!(\"spawning task\");\n+    ///     })\n+    ///     .build()\n+    ///     .unwrap();\n+    ///\n+    /// runtime.block_on(async {\n+    ///     tokio::task::spawn(std::future::ready(()));\n+    ///\n+    ///     for _ in 0..64 {\n+    ///         tokio::task::yield_now().await;\n+    ///     }\n+    /// })\n+    /// # }\n+    /// ```\n+    #[cfg(not(loom))]\n+    pub fn on_task_spawn<F>(&mut self, f: F) -> &mut Self\n+    where\n+        F: Fn(&TaskMeta<'_>) + Send + Sync + 'static,\n+    {\n+        self.before_spawn = Some(std::sync::Arc::new(f));\n+        self\n+    }",
        "comment_created_at": "2024-08-02T12:50:56+00:00",
        "comment_author": "Darksonn",
        "comment_body": "This is proposing to add them as stable despite the `LocalSet` question?",
        "pr_file_module": null
      },
      {
        "comment_id": "1701812516",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6742,
        "pr_file": "tokio/src/runtime/builder.rs",
        "discussion_id": "1701806449",
        "commented_code": "@@ -677,6 +690,91 @@ impl Builder {\n         self\n     }\n \n+    /// Executes function `f` just before a task is spawned.\n+    ///\n+    /// `f` is called within the Tokio context, so functions like\n+    /// [`tokio::spawn`](crate::spawn) can be called, and may result in this callback being\n+    /// invoked immediately.\n+    ///\n+    /// This can be used for bookkeeping or monitoring purposes.\n+    ///\n+    /// Note: There can only be one spawn callback for a runtime; calling this function more\n+    /// than once replaces the last callback defined, rather than adding to it.\n+    ///\n+    /// This *does not* support [`LocalSet`](crate::task::LocalSet) at this time.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// # use tokio::runtime;\n+    /// # pub fn main() {\n+    /// let runtime = runtime::Builder::new_current_thread()\n+    ///     .on_task_spawn(|_| {\n+    ///         println!(\"spawning task\");\n+    ///     })\n+    ///     .build()\n+    ///     .unwrap();\n+    ///\n+    /// runtime.block_on(async {\n+    ///     tokio::task::spawn(std::future::ready(()));\n+    ///\n+    ///     for _ in 0..64 {\n+    ///         tokio::task::yield_now().await;\n+    ///     }\n+    /// })\n+    /// # }\n+    /// ```\n+    #[cfg(not(loom))]\n+    pub fn on_task_spawn<F>(&mut self, f: F) -> &mut Self\n+    where\n+        F: Fn(&TaskMeta<'_>) + Send + Sync + 'static,\n+    {\n+        self.before_spawn = Some(std::sync::Arc::new(f));\n+        self\n+    }",
        "comment_created_at": "2024-08-02T12:56:20+00:00",
        "comment_author": "Noah-Kennedy",
        "comment_body": "Yes, I figured we could say for now that this doesn't currently fire on LocalSet, but may do so in the future.\r\n\r\nWe could also pass a parameter for `is_local` to the hook in case people care specifically about not invoking logic on localset task spawns and terminations.",
        "pr_file_module": null
      },
      {
        "comment_id": "1701813048",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6742,
        "pr_file": "tokio/src/runtime/builder.rs",
        "discussion_id": "1701806449",
        "commented_code": "@@ -677,6 +690,91 @@ impl Builder {\n         self\n     }\n \n+    /// Executes function `f` just before a task is spawned.\n+    ///\n+    /// `f` is called within the Tokio context, so functions like\n+    /// [`tokio::spawn`](crate::spawn) can be called, and may result in this callback being\n+    /// invoked immediately.\n+    ///\n+    /// This can be used for bookkeeping or monitoring purposes.\n+    ///\n+    /// Note: There can only be one spawn callback for a runtime; calling this function more\n+    /// than once replaces the last callback defined, rather than adding to it.\n+    ///\n+    /// This *does not* support [`LocalSet`](crate::task::LocalSet) at this time.\n+    ///\n+    /// # Examples\n+    ///\n+    /// ```\n+    /// # use tokio::runtime;\n+    /// # pub fn main() {\n+    /// let runtime = runtime::Builder::new_current_thread()\n+    ///     .on_task_spawn(|_| {\n+    ///         println!(\"spawning task\");\n+    ///     })\n+    ///     .build()\n+    ///     .unwrap();\n+    ///\n+    /// runtime.block_on(async {\n+    ///     tokio::task::spawn(std::future::ready(()));\n+    ///\n+    ///     for _ in 0..64 {\n+    ///         tokio::task::yield_now().await;\n+    ///     }\n+    /// })\n+    /// # }\n+    /// ```\n+    #[cfg(not(loom))]\n+    pub fn on_task_spawn<F>(&mut self, f: F) -> &mut Self\n+    where\n+        F: Fn(&TaskMeta<'_>) + Send + Sync + 'static,\n+    {\n+        self.before_spawn = Some(std::sync::Arc::new(f));\n+        self\n+    }",
        "comment_created_at": "2024-08-02T12:56:46+00:00",
        "comment_author": "Noah-Kennedy",
        "comment_body": "Especially as this may not support LocalSet ever, I did not want this to be blocked on figuring that out",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1618827739",
    "pr_number": 6584,
    "pr_file": "tokio/src/runtime/time/mod.rs",
    "created_at": "2024-05-29T12:48:06+00:00",
    "commented_code": "now = lock.elapsed();\n         }\n \n-        while let Some(entry) = lock.poll(now) {\n-            debug_assert!(unsafe { entry.is_pending() });\n-\n-            // SAFETY: We hold the driver lock, and just removed the entry from any linked lists.\n-            if let Some(waker) = unsafe { entry.fire(Ok(())) } {\n-                waker_list.push(waker);\n-\n-                if !waker_list.can_push() {\n-                    // Wake a batch of wakers. To avoid deadlock, we must do this with the lock temporarily dropped.\n-                    drop(lock);\n-\n-                    waker_list.wake_all();\n-\n-                    lock = self.inner.lock_sharded_wheel(id);\n+        while let Some(expiration) = lock.poll(now) {\n+            // Gets the number of entries in this slot, which will be\n+            // the maximum number of times we traverse.\n+            // Limiting the maximum number of iterations is very important,\n+            // because it's possible that those entries might need to be\n+            // reinserted into the same slot.\n+\n+            // This happens on the highest level, when an entry is inserted\n+            // more than MAX_DURATION into the future. When this happens, we wrap\n+            // around, and process some entries a multiple of MAX_DURATION before\n+            // they actually need to be dropped down a level. We then reinsert them\n+            // back into the same position; we must make sure we don't then process\n+            // those entries again or we'll end up in an infinite loop.\n+\n+            // This can also happens when other threads concurrently add entries to\n+            // this currently traversing slot.\n+            let count = lock.get_entries_count(&expiration);\n+            for _ in 0..count {",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "1618827739",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6584,
        "pr_file": "tokio/src/runtime/time/mod.rs",
        "discussion_id": "1618827739",
        "commented_code": "@@ -319,23 +319,54 @@ impl Handle {\n             now = lock.elapsed();\n         }\n \n-        while let Some(entry) = lock.poll(now) {\n-            debug_assert!(unsafe { entry.is_pending() });\n-\n-            // SAFETY: We hold the driver lock, and just removed the entry from any linked lists.\n-            if let Some(waker) = unsafe { entry.fire(Ok(())) } {\n-                waker_list.push(waker);\n-\n-                if !waker_list.can_push() {\n-                    // Wake a batch of wakers. To avoid deadlock, we must do this with the lock temporarily dropped.\n-                    drop(lock);\n-\n-                    waker_list.wake_all();\n-\n-                    lock = self.inner.lock_sharded_wheel(id);\n+        while let Some(expiration) = lock.poll(now) {\n+            // Gets the number of entries in this slot, which will be\n+            // the maximum number of times we traverse.\n+            // Limiting the maximum number of iterations is very important,\n+            // because it's possible that those entries might need to be\n+            // reinserted into the same slot.\n+\n+            // This happens on the highest level, when an entry is inserted\n+            // more than MAX_DURATION into the future. When this happens, we wrap\n+            // around, and process some entries a multiple of MAX_DURATION before\n+            // they actually need to be dropped down a level. We then reinsert them\n+            // back into the same position; we must make sure we don't then process\n+            // those entries again or we'll end up in an infinite loop.\n+\n+            // This can also happens when other threads concurrently add entries to\n+            // this currently traversing slot.\n+            let count = lock.get_entries_count(&expiration);\n+            for _ in 0..count {",
        "comment_created_at": "2024-05-29T12:48:06+00:00",
        "comment_author": "Darksonn",
        "comment_body": "The way we usually handle this kind of thing is to move _all_ entries in the list to another list (using the guarded linked list), and then we wake entries from the guarded list in batches. Can we not do the same here?",
        "pr_file_module": null
      },
      {
        "comment_id": "1619793149",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6584,
        "pr_file": "tokio/src/runtime/time/mod.rs",
        "discussion_id": "1618827739",
        "commented_code": "@@ -319,23 +319,54 @@ impl Handle {\n             now = lock.elapsed();\n         }\n \n-        while let Some(entry) = lock.poll(now) {\n-            debug_assert!(unsafe { entry.is_pending() });\n-\n-            // SAFETY: We hold the driver lock, and just removed the entry from any linked lists.\n-            if let Some(waker) = unsafe { entry.fire(Ok(())) } {\n-                waker_list.push(waker);\n-\n-                if !waker_list.can_push() {\n-                    // Wake a batch of wakers. To avoid deadlock, we must do this with the lock temporarily dropped.\n-                    drop(lock);\n-\n-                    waker_list.wake_all();\n-\n-                    lock = self.inner.lock_sharded_wheel(id);\n+        while let Some(expiration) = lock.poll(now) {\n+            // Gets the number of entries in this slot, which will be\n+            // the maximum number of times we traverse.\n+            // Limiting the maximum number of iterations is very important,\n+            // because it's possible that those entries might need to be\n+            // reinserted into the same slot.\n+\n+            // This happens on the highest level, when an entry is inserted\n+            // more than MAX_DURATION into the future. When this happens, we wrap\n+            // around, and process some entries a multiple of MAX_DURATION before\n+            // they actually need to be dropped down a level. We then reinsert them\n+            // back into the same position; we must make sure we don't then process\n+            // those entries again or we'll end up in an infinite loop.\n+\n+            // This can also happens when other threads concurrently add entries to\n+            // this currently traversing slot.\n+            let count = lock.get_entries_count(&expiration);\n+            for _ in 0..count {",
        "comment_created_at": "2024-05-30T03:22:05+00:00",
        "comment_author": "wathenjiang",
        "comment_body": "I hope I understand you correctly.\r\n\r\nWhat I want to address is to avoid moving all entries in the list to another list at once.\r\n\r\nI currently see `GuardedLinkedList ` used in broadcast and notify, and it seems that it must remove all entries from the original linked list at once through calling `std::mem::take`.\r\n\r\nUsing the `std::mem::take`, we have no way to address the goal of traversing the Linked List only once. Because once the TimerHandle is removed from the original linked list, other threads need to know that it is no longer in the original linked list (they can be dropped concurrently). Here, synchronization must be achieved through locks. After modifying the state of the TimerHandle, we can not wake it up immediately because the lock is held at this time, and we need to avoid deadlock.\r\n\r\nIn short,\r\n\r\n- Because all entries are moved at once through `std::mem::take`, we must traverse the entire list and mark them as no longer in the original linked list.\r\n- And wakeup does not allow holding locks, so we must temporarily store these entries in the pending linked list.\r\n\r\n\r\n\r\nThe master version is:\r\n\r\n- Get the lock\r\n- Remove all entries from the slot linked list at once through calling `std::mem::take`.\r\n- Traverse the slot linked list, mark all entries as `STATE_PENDING_FIRE`.\r\n- Release the lock\r\n- After that, other threads can know their `TimerHanle`s are stored in the pending linked list instead of the original one.\r\n- Traverse the pending linked list in batch:\r\n  - Get the lock\r\n  - Traverse the pending linked list, mark some entries as `STATE_DEREGISTERED` in batch, and get their waker (32 in batch).\r\n  - Release the lock\r\n  - After that, other threads can know their `TimerHanle`s are not in the pending linked list or the slot linked list.\r\n  - Wake them up.\r\n  - Get the lock again ...\r\n\r\nThe current Version is:\r\n\r\nTraverse the slot linked list in batch:\r\n\r\n- Get the lock\r\n- Traverse the slot linked list, mark some entries as `STATE_FIRING` and then `STATE_DEREGISTERED` in batch, and get their waker (32 in batch).\r\n- Release the lock\r\n- After that, other threads can know their `TimerHanle`s are not in the slot linked list.\r\n- Wake them up.\r\n- Get the lock again ...\r\n\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1636316143",
    "pr_number": 6584,
    "pr_file": "tokio/src/runtime/time/mod.rs",
    "created_at": "2024-06-12T11:42:41+00:00",
    "commented_code": "now = lock.elapsed();\n         }\n \n-        while let Some(entry) = lock.poll(now) {\n-            debug_assert!(unsafe { entry.is_pending() });\n-\n-            // SAFETY: We hold the driver lock, and just removed the entry from any linked lists.\n-            if let Some(waker) = unsafe { entry.fire(Ok(())) } {\n-                waker_list.push(waker);\n-\n-                if !waker_list.can_push() {\n-                    // Wake a batch of wakers. To avoid deadlock, we must do this with the lock temporarily dropped.\n-                    drop(lock);\n-\n-                    waker_list.wake_all();\n-\n-                    lock = self.inner.lock_sharded_wheel(id);\n+        while let Some(expiration) = lock.poll(now) {\n+            lock.set_elapsed(expiration.deadline);\n+            // Note that we need to take _all_ of the entries off the list before\n+            // processing any of them. This is important because it's possible that\n+            // those entries might need to be reinserted into the same slot.\n+            //\n+            // This happens only on the highest level, when an entry is inserted\n+            // more than MAX_DURATION into the future. When this happens, we wrap\n+            // around, and process some entries a multiple of MAX_DURATION before\n+            // they actually need to be dropped down a level. We then reinsert them\n+            // back into the same position; we must make sure we don't then process\n+            // those entries again or we'll end up in an infinite loop.\n+            let unguarded_list = lock.take_entries(&expiration);\n+            // It is critical for `GuardedLinkedList` safety that the guard node is\n+            // pinned in memory and is not dropped until the guarded list is dropped.\n+            let guard = TimerShared::new(id);\n+            pin!(guard);\n+            let guard_ptr = NonNull::from(guard.as_ref().get_ref());\n+            // GuardedLinkedList ensures that the concurrent drop of Entry in this slot is safe.\n+            let mut guarded_list = unguarded_list.into_guarded(guard_ptr);\n+\n+            while let Some(entry) = guarded_list.pop_back() {\n+                let entry = unsafe { entry.as_ref().handle() };\n+                let deadline = expiration.deadline;\n+                // Try to expire the entry; this is cheap (doesn't synchronize) if\n+                // the timer is not expired, and updates cached_when.\n+                match unsafe { entry.mark_firing(deadline) } {\n+                    Ok(()) => {\n+                        // Entry was expired.\n+                        // SAFETY: We hold the driver lock, and just removed the entry from any linked lists.\n+                        if let Some(waker) = unsafe { entry.fire(Ok(())) } {\n+                            waker_list.push(waker);\n+\n+                            if !waker_list.can_push() {\n+                                // Wake a batch of wakers. To avoid deadlock,\n+                                // we must do this with the lock temporarily dropped.\n+                                drop(lock);\n+                                waker_list.wake_all();",
    "repo_full_name": "tokio-rs/tokio",
    "discussion_comments": [
      {
        "comment_id": "1636316143",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6584,
        "pr_file": "tokio/src/runtime/time/mod.rs",
        "discussion_id": "1636316143",
        "commented_code": "@@ -319,23 +319,59 @@ impl Handle {\n             now = lock.elapsed();\n         }\n \n-        while let Some(entry) = lock.poll(now) {\n-            debug_assert!(unsafe { entry.is_pending() });\n-\n-            // SAFETY: We hold the driver lock, and just removed the entry from any linked lists.\n-            if let Some(waker) = unsafe { entry.fire(Ok(())) } {\n-                waker_list.push(waker);\n-\n-                if !waker_list.can_push() {\n-                    // Wake a batch of wakers. To avoid deadlock, we must do this with the lock temporarily dropped.\n-                    drop(lock);\n-\n-                    waker_list.wake_all();\n-\n-                    lock = self.inner.lock_sharded_wheel(id);\n+        while let Some(expiration) = lock.poll(now) {\n+            lock.set_elapsed(expiration.deadline);\n+            // Note that we need to take _all_ of the entries off the list before\n+            // processing any of them. This is important because it's possible that\n+            // those entries might need to be reinserted into the same slot.\n+            //\n+            // This happens only on the highest level, when an entry is inserted\n+            // more than MAX_DURATION into the future. When this happens, we wrap\n+            // around, and process some entries a multiple of MAX_DURATION before\n+            // they actually need to be dropped down a level. We then reinsert them\n+            // back into the same position; we must make sure we don't then process\n+            // those entries again or we'll end up in an infinite loop.\n+            let unguarded_list = lock.take_entries(&expiration);\n+            // It is critical for `GuardedLinkedList` safety that the guard node is\n+            // pinned in memory and is not dropped until the guarded list is dropped.\n+            let guard = TimerShared::new(id);\n+            pin!(guard);\n+            let guard_ptr = NonNull::from(guard.as_ref().get_ref());\n+            // GuardedLinkedList ensures that the concurrent drop of Entry in this slot is safe.\n+            let mut guarded_list = unguarded_list.into_guarded(guard_ptr);\n+\n+            while let Some(entry) = guarded_list.pop_back() {\n+                let entry = unsafe { entry.as_ref().handle() };\n+                let deadline = expiration.deadline;\n+                // Try to expire the entry; this is cheap (doesn't synchronize) if\n+                // the timer is not expired, and updates cached_when.\n+                match unsafe { entry.mark_firing(deadline) } {\n+                    Ok(()) => {\n+                        // Entry was expired.\n+                        // SAFETY: We hold the driver lock, and just removed the entry from any linked lists.\n+                        if let Some(waker) = unsafe { entry.fire(Ok(())) } {\n+                            waker_list.push(waker);\n+\n+                            if !waker_list.can_push() {\n+                                // Wake a batch of wakers. To avoid deadlock,\n+                                // we must do this with the lock temporarily dropped.\n+                                drop(lock);\n+                                waker_list.wake_all();",
        "comment_created_at": "2024-06-12T11:42:41+00:00",
        "comment_author": "Darksonn",
        "comment_body": "I'm worried about panics here. What happens to entries still in the guarded list?\r\n\r\nI think some other examples of this wrap the guarded list in something that removes all entries from the list without waking their wakers.",
        "pr_file_module": null
      },
      {
        "comment_id": "1636398112",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6584,
        "pr_file": "tokio/src/runtime/time/mod.rs",
        "discussion_id": "1636316143",
        "commented_code": "@@ -319,23 +319,59 @@ impl Handle {\n             now = lock.elapsed();\n         }\n \n-        while let Some(entry) = lock.poll(now) {\n-            debug_assert!(unsafe { entry.is_pending() });\n-\n-            // SAFETY: We hold the driver lock, and just removed the entry from any linked lists.\n-            if let Some(waker) = unsafe { entry.fire(Ok(())) } {\n-                waker_list.push(waker);\n-\n-                if !waker_list.can_push() {\n-                    // Wake a batch of wakers. To avoid deadlock, we must do this with the lock temporarily dropped.\n-                    drop(lock);\n-\n-                    waker_list.wake_all();\n-\n-                    lock = self.inner.lock_sharded_wheel(id);\n+        while let Some(expiration) = lock.poll(now) {\n+            lock.set_elapsed(expiration.deadline);\n+            // Note that we need to take _all_ of the entries off the list before\n+            // processing any of them. This is important because it's possible that\n+            // those entries might need to be reinserted into the same slot.\n+            //\n+            // This happens only on the highest level, when an entry is inserted\n+            // more than MAX_DURATION into the future. When this happens, we wrap\n+            // around, and process some entries a multiple of MAX_DURATION before\n+            // they actually need to be dropped down a level. We then reinsert them\n+            // back into the same position; we must make sure we don't then process\n+            // those entries again or we'll end up in an infinite loop.\n+            let unguarded_list = lock.take_entries(&expiration);\n+            // It is critical for `GuardedLinkedList` safety that the guard node is\n+            // pinned in memory and is not dropped until the guarded list is dropped.\n+            let guard = TimerShared::new(id);\n+            pin!(guard);\n+            let guard_ptr = NonNull::from(guard.as_ref().get_ref());\n+            // GuardedLinkedList ensures that the concurrent drop of Entry in this slot is safe.\n+            let mut guarded_list = unguarded_list.into_guarded(guard_ptr);\n+\n+            while let Some(entry) = guarded_list.pop_back() {\n+                let entry = unsafe { entry.as_ref().handle() };\n+                let deadline = expiration.deadline;\n+                // Try to expire the entry; this is cheap (doesn't synchronize) if\n+                // the timer is not expired, and updates cached_when.\n+                match unsafe { entry.mark_firing(deadline) } {\n+                    Ok(()) => {\n+                        // Entry was expired.\n+                        // SAFETY: We hold the driver lock, and just removed the entry from any linked lists.\n+                        if let Some(waker) = unsafe { entry.fire(Ok(())) } {\n+                            waker_list.push(waker);\n+\n+                            if !waker_list.can_push() {\n+                                // Wake a batch of wakers. To avoid deadlock,\n+                                // we must do this with the lock temporarily dropped.\n+                                drop(lock);\n+                                waker_list.wake_all();",
        "comment_created_at": "2024-06-12T12:48:31+00:00",
        "comment_author": "wathenjiang",
        "comment_body": "Yes. We shoud ensure the list is empty before dropping it and no double panic, even if it occurs panic. I will wrap it.",
        "pr_file_module": null
      },
      {
        "comment_id": "1636639299",
        "repo_full_name": "tokio-rs/tokio",
        "pr_number": 6584,
        "pr_file": "tokio/src/runtime/time/mod.rs",
        "discussion_id": "1636316143",
        "commented_code": "@@ -319,23 +319,59 @@ impl Handle {\n             now = lock.elapsed();\n         }\n \n-        while let Some(entry) = lock.poll(now) {\n-            debug_assert!(unsafe { entry.is_pending() });\n-\n-            // SAFETY: We hold the driver lock, and just removed the entry from any linked lists.\n-            if let Some(waker) = unsafe { entry.fire(Ok(())) } {\n-                waker_list.push(waker);\n-\n-                if !waker_list.can_push() {\n-                    // Wake a batch of wakers. To avoid deadlock, we must do this with the lock temporarily dropped.\n-                    drop(lock);\n-\n-                    waker_list.wake_all();\n-\n-                    lock = self.inner.lock_sharded_wheel(id);\n+        while let Some(expiration) = lock.poll(now) {\n+            lock.set_elapsed(expiration.deadline);\n+            // Note that we need to take _all_ of the entries off the list before\n+            // processing any of them. This is important because it's possible that\n+            // those entries might need to be reinserted into the same slot.\n+            //\n+            // This happens only on the highest level, when an entry is inserted\n+            // more than MAX_DURATION into the future. When this happens, we wrap\n+            // around, and process some entries a multiple of MAX_DURATION before\n+            // they actually need to be dropped down a level. We then reinsert them\n+            // back into the same position; we must make sure we don't then process\n+            // those entries again or we'll end up in an infinite loop.\n+            let unguarded_list = lock.take_entries(&expiration);\n+            // It is critical for `GuardedLinkedList` safety that the guard node is\n+            // pinned in memory and is not dropped until the guarded list is dropped.\n+            let guard = TimerShared::new(id);\n+            pin!(guard);\n+            let guard_ptr = NonNull::from(guard.as_ref().get_ref());\n+            // GuardedLinkedList ensures that the concurrent drop of Entry in this slot is safe.\n+            let mut guarded_list = unguarded_list.into_guarded(guard_ptr);\n+\n+            while let Some(entry) = guarded_list.pop_back() {\n+                let entry = unsafe { entry.as_ref().handle() };\n+                let deadline = expiration.deadline;\n+                // Try to expire the entry; this is cheap (doesn't synchronize) if\n+                // the timer is not expired, and updates cached_when.\n+                match unsafe { entry.mark_firing(deadline) } {\n+                    Ok(()) => {\n+                        // Entry was expired.\n+                        // SAFETY: We hold the driver lock, and just removed the entry from any linked lists.\n+                        if let Some(waker) = unsafe { entry.fire(Ok(())) } {\n+                            waker_list.push(waker);\n+\n+                            if !waker_list.can_push() {\n+                                // Wake a batch of wakers. To avoid deadlock,\n+                                // we must do this with the lock temporarily dropped.\n+                                drop(lock);\n+                                waker_list.wake_all();",
        "comment_created_at": "2024-06-12T14:58:15+00:00",
        "comment_author": "wathenjiang",
        "comment_body": "Now, we use `EntryWaitersList` instead. It will address our purpose of memory safety.",
        "pr_file_module": null
      }
    ]
  }
]