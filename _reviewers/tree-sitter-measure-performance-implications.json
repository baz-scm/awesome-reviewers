[
  {
    "discussion_id": "1898776517",
    "pr_number": 3938,
    "pr_file": "lib/include/tree_sitter/api.h",
    "created_at": "2024-12-28T02:15:15+00:00",
    "commented_code": "*/\n uint32_t ts_language_state_count(const TSLanguage *self);\n \n+/**\n+ * Get the number of supertype symbols in the language.\n+*/\n+uint32_t ts_language_supertype_count(const TSLanguage *self);\n+\n+/**\n+ * Get a list of all supertype symbols for the language.\n+*/\n+const TSSymbol *ts_language_supertypes(const TSLanguage *self);\n+\n+/**\n+ * Get a list of all subtype symbol names for a given supertype symbol. Returns\n+ * the size of said list.\n+*/\n+uint16_t ts_language_supertype_map(\n+  const TSLanguage *self,\n+  TSSymbol supertype,\n+  const char *const **start",
    "repo_full_name": "tree-sitter/tree-sitter",
    "discussion_comments": [
      {
        "comment_id": "1898776517",
        "repo_full_name": "tree-sitter/tree-sitter",
        "pr_number": 3938,
        "pr_file": "lib/include/tree_sitter/api.h",
        "discussion_id": "1898776517",
        "commented_code": "@@ -1166,6 +1166,26 @@ uint32_t ts_language_symbol_count(const TSLanguage *self);\n */\n uint32_t ts_language_state_count(const TSLanguage *self);\n \n+/**\n+ * Get the number of supertype symbols in the language.\n+*/\n+uint32_t ts_language_supertype_count(const TSLanguage *self);\n+\n+/**\n+ * Get a list of all supertype symbols for the language.\n+*/\n+const TSSymbol *ts_language_supertypes(const TSLanguage *self);\n+\n+/**\n+ * Get a list of all subtype symbol names for a given supertype symbol. Returns\n+ * the size of said list.\n+*/\n+uint16_t ts_language_supertype_map(\n+  const TSLanguage *self,\n+  TSSymbol supertype,\n+  const char *const **start",
        "comment_created_at": "2024-12-28T02:15:15+00:00",
        "comment_author": "amaanq",
        "comment_body": "I don't think we should be writing C-style strings, as this function is giving us the subtype symbol names, of which we can't really do much with. It would make a lot more sense imo, to store the supertype info in the parser as a map of symbol ids to an array of symbol ids, which is a lot better for the parser binary size and memory usage (esp in wasm). With the symbol ids, they are a lot more useful to us and we can always fetch the symbol names with this array of ids.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "128104000",
    "pr_number": 92,
    "pr_file": "test/helpers/spy_input.cc",
    "created_at": "2017-07-18T21:43:22+00:00",
    "commented_code": "* This class stores its entire `content` in a contiguous buffer, but we want\n    * to ensure that the code under test cannot accidentally read more than\n    * `*bytes_read` bytes past the returned pointer. To make sure that this type\n-   * of error does not fly, we copy the chunk into a zeroed-out buffer and\n+   * of error does not fly, we allocate a separate buffer for each request and\n    * return a reference to that buffer, rather than a pointer into the main\n-   * content.\n+   * content. The temporary buffer only fits `*bytes_read` bytes so valgrind\n+   * can detect code reading too many bytes from the buffer.\n    */\n-  memset(spy->buffer, 0, spy->buffer_size);\n-  memcpy(spy->buffer, result.data(), byte_count);\n+  delete[] spy->buffer;\n+  if (byte_count) {\n+    spy->buffer = new char[byte_count];\n+    memcpy(spy->buffer, result.data(), byte_count);\n+  } else {\n+    spy->buffer = nullptr;\n+  }\n+",
    "repo_full_name": "tree-sitter/tree-sitter",
    "discussion_comments": [
      {
        "comment_id": "128104000",
        "repo_full_name": "tree-sitter/tree-sitter",
        "pr_number": 92,
        "pr_file": "test/helpers/spy_input.cc",
        "discussion_id": "128104000",
        "commented_code": "@@ -57,12 +56,19 @@ const char * SpyInput::read(void *payload, uint32_t *bytes_read) {\n    * This class stores its entire `content` in a contiguous buffer, but we want\n    * to ensure that the code under test cannot accidentally read more than\n    * `*bytes_read` bytes past the returned pointer. To make sure that this type\n-   * of error does not fly, we copy the chunk into a zeroed-out buffer and\n+   * of error does not fly, we allocate a separate buffer for each request and\n    * return a reference to that buffer, rather than a pointer into the main\n-   * content.\n+   * content. The temporary buffer only fits `*bytes_read` bytes so valgrind\n+   * can detect code reading too many bytes from the buffer.\n    */\n-  memset(spy->buffer, 0, spy->buffer_size);\n-  memcpy(spy->buffer, result.data(), byte_count);\n+  delete[] spy->buffer;\n+  if (byte_count) {\n+    spy->buffer = new char[byte_count];\n+    memcpy(spy->buffer, result.data(), byte_count);\n+  } else {\n+    spy->buffer = nullptr;\n+  }\n+",
        "comment_created_at": "2017-07-18T21:43:22+00:00",
        "comment_author": "maxbrunsfeld",
        "comment_body": "Does calling `delete` and `new` on every chunk slow down the tests at all? I'm wondering if we really need to do this everywhere, or if we can just do something custom for this one test, like calling `ts_document_set_input_string_with_length`.",
        "pr_file_module": null
      },
      {
        "comment_id": "128115546",
        "repo_full_name": "tree-sitter/tree-sitter",
        "pr_number": 92,
        "pr_file": "test/helpers/spy_input.cc",
        "discussion_id": "128104000",
        "commented_code": "@@ -57,12 +56,19 @@ const char * SpyInput::read(void *payload, uint32_t *bytes_read) {\n    * This class stores its entire `content` in a contiguous buffer, but we want\n    * to ensure that the code under test cannot accidentally read more than\n    * `*bytes_read` bytes past the returned pointer. To make sure that this type\n-   * of error does not fly, we copy the chunk into a zeroed-out buffer and\n+   * of error does not fly, we allocate a separate buffer for each request and\n    * return a reference to that buffer, rather than a pointer into the main\n-   * content.\n+   * content. The temporary buffer only fits `*bytes_read` bytes so valgrind\n+   * can detect code reading too many bytes from the buffer.\n    */\n-  memset(spy->buffer, 0, spy->buffer_size);\n-  memcpy(spy->buffer, result.data(), byte_count);\n+  delete[] spy->buffer;\n+  if (byte_count) {\n+    spy->buffer = new char[byte_count];\n+    memcpy(spy->buffer, result.data(), byte_count);\n+  } else {\n+    spy->buffer = nullptr;\n+  }\n+",
        "comment_created_at": "2017-07-18T22:46:31+00:00",
        "comment_author": "philipturnbull",
        "comment_body": "The cost of `new` and `delete` get lost in the noise afaict.\r\n\r\nWith `master`:\r\n```\r\n$ git rev-parse HEAD\r\nafb499bf2e5c9aee78ae9a8611268008e1136359\r\n$ for x in $(echo \"1 2 3 4 5\"); do time ./out/Test/tests >/dev/null; done\r\nreal    0m20.394s\r\nuser    0m20.068s\r\nsys     0m0.148s\r\n\r\nreal    0m21.864s\r\nuser    0m21.492s\r\nsys     0m0.168s\r\n\r\nreal    0m20.518s\r\nuser    0m20.136s\r\nsys     0m0.168s\r\n\r\nreal    0m20.215s\r\nuser    0m19.908s\r\nsys     0m0.148s\r\n\r\nreal    0m20.478s\r\nuser    0m20.116s\r\nsys     0m0.192s\r\n```\r\n\r\nthis branch:\r\n```\r\n$ git rev-parse HEAD\r\n52cec9ed39a56f226d47499db6362a192138fd5a\r\n$ for x in $(echo \"1 2 3 4 5\"); do time ./out/Test/tests >/dev/null; done\r\n\r\nreal    0m19.423s\r\nuser    0m19.084s\r\nsys     0m0.160s\r\n\r\nreal    0m19.946s\r\nuser    0m19.588s\r\nsys     0m0.188s\r\n\r\nreal    0m21.006s\r\nuser    0m20.672s\r\nsys     0m0.172s\r\n\r\nreal    0m19.634s\r\nuser    0m19.304s\r\nsys     0m0.160s\r\n\r\nreal    0m19.492s\r\nuser    0m19.188s\r\nsys     0m0.128s\r\n```\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "128128269",
        "repo_full_name": "tree-sitter/tree-sitter",
        "pr_number": 92,
        "pr_file": "test/helpers/spy_input.cc",
        "discussion_id": "128104000",
        "commented_code": "@@ -57,12 +56,19 @@ const char * SpyInput::read(void *payload, uint32_t *bytes_read) {\n    * This class stores its entire `content` in a contiguous buffer, but we want\n    * to ensure that the code under test cannot accidentally read more than\n    * `*bytes_read` bytes past the returned pointer. To make sure that this type\n-   * of error does not fly, we copy the chunk into a zeroed-out buffer and\n+   * of error does not fly, we allocate a separate buffer for each request and\n    * return a reference to that buffer, rather than a pointer into the main\n-   * content.\n+   * content. The temporary buffer only fits `*bytes_read` bytes so valgrind\n+   * can detect code reading too many bytes from the buffer.\n    */\n-  memset(spy->buffer, 0, spy->buffer_size);\n-  memcpy(spy->buffer, result.data(), byte_count);\n+  delete[] spy->buffer;\n+  if (byte_count) {\n+    spy->buffer = new char[byte_count];\n+    memcpy(spy->buffer, result.data(), byte_count);\n+  } else {\n+    spy->buffer = nullptr;\n+  }\n+",
        "comment_created_at": "2017-07-19T00:24:12+00:00",
        "comment_author": "maxbrunsfeld",
        "comment_body": "Ah ok, thanks for investigating!",
        "pr_file_module": null
      }
    ]
  }
]