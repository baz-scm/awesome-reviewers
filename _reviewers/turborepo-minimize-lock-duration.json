[
  {
    "discussion_id": "1761782794",
    "pr_number": 9154,
    "pr_file": "crates/turborepo-lib/src/run/watch.rs",
    "created_at": "2024-09-16T19:42:21+00:00",
    "commented_code": "let run_fut = async {\n             loop {\n                 notify_run.notified().await;\n-                let changed_packages_guard = changed_packages.lock().await;\n-                if !changed_packages_guard.borrow().is_empty() {\n-                    let changed_packages = changed_packages_guard.take();\n+                let some_changed_packages = {",
    "repo_full_name": "vercel/turborepo",
    "discussion_comments": [
      {
        "comment_id": "1761782794",
        "repo_full_name": "vercel/turborepo",
        "pr_number": 9154,
        "pr_file": "crates/turborepo-lib/src/run/watch.rs",
        "discussion_id": "1761782794",
        "commented_code": "@@ -189,9 +189,13 @@ impl WatchClient {\n         let run_fut = async {\n             loop {\n                 notify_run.notified().await;\n-                let changed_packages_guard = changed_packages.lock().await;\n-                if !changed_packages_guard.borrow().is_empty() {\n-                    let changed_packages = changed_packages_guard.take();\n+                let some_changed_packages = {",
        "comment_created_at": "2024-09-16T19:42:21+00:00",
        "comment_author": "chris-olszewski",
        "comment_body": "We only acquire the guard in the block so we ensure we release the lock once we take the changed packages. This lets the `event_fut` make progress while `self.execute_run` is pending.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1761784264",
    "pr_number": 9154,
    "pr_file": "crates/turborepo-lib/src/run/watch.rs",
    "created_at": "2024-09-16T19:43:37+00:00",
    "commented_code": "let run_fut = async {\n             loop {\n                 notify_run.notified().await;\n-                let changed_packages_guard = changed_packages.lock().await;\n-                if !changed_packages_guard.borrow().is_empty() {\n-                    let changed_packages = changed_packages_guard.take();\n+                let some_changed_packages = {\n+                    let mut changed_packages_guard =\n+                        changed_packages.lock().expect(\"poisoned lock\");\n+                    (!changed_packages_guard.is_empty())\n+                        .then(|| std::mem::take(changed_packages_guard.deref_mut()))\n+                };\n+                if let Some(changed_packages) = some_changed_packages {\n                     self.execute_run(changed_packages).await?;",
    "repo_full_name": "vercel/turborepo",
    "discussion_comments": [
      {
        "comment_id": "1761784264",
        "repo_full_name": "vercel/turborepo",
        "pr_number": 9154,
        "pr_file": "crates/turborepo-lib/src/run/watch.rs",
        "discussion_id": "1761784264",
        "commented_code": "@@ -189,9 +189,13 @@ impl WatchClient {\n         let run_fut = async {\n             loop {\n                 notify_run.notified().await;\n-                let changed_packages_guard = changed_packages.lock().await;\n-                if !changed_packages_guard.borrow().is_empty() {\n-                    let changed_packages = changed_packages_guard.take();\n+                let some_changed_packages = {\n+                    let mut changed_packages_guard =\n+                        changed_packages.lock().expect(\"poisoned lock\");\n+                    (!changed_packages_guard.is_empty())\n+                        .then(|| std::mem::take(changed_packages_guard.deref_mut()))\n+                };\n+                if let Some(changed_packages) = some_changed_packages {\n                     self.execute_run(changed_packages).await?;",
        "comment_created_at": "2024-09-16T19:43:37+00:00",
        "comment_author": "chris-olszewski",
        "comment_body": "`changed_packages_guard` is still held while run is being executed, this prevents any events from being handled. ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1713930993",
    "pr_number": 8895,
    "pr_file": "crates/turborepo-ui/src/wui/mod.rs",
    "created_at": "2024-08-12T14:48:38+00:00",
    "commented_code": "+//! Web UI for Turborepo. Creates a WebSocket server that can be subscribed to\n+//! by a web client to display the status of tasks.\n+\n+use std::{\n+    cell::RefCell,\n+    collections::HashSet,\n+    io::Write,\n+    sync::{atomic::AtomicU32, Arc},\n+};\n+\n+use axum::{\n+    extract::{\n+        ws::{Message, WebSocket},\n+        State, WebSocketUpgrade,\n+    },\n+    http::Method,\n+    response::IntoResponse,\n+    routing::get,\n+    Router,\n+};\n+use serde::{Deserialize, Serialize};\n+use thiserror::Error;\n+use tokio::{select, sync::Mutex};\n+use tower_http::cors::{Any, CorsLayer};\n+use tracing::log::warn;\n+\n+use crate::{\n+    sender::{TaskSender, UISender},\n+    tui::event::{CacheResult, OutputLogs, TaskResult},\n+};\n+\n+#[derive(Debug, Error)]\n+pub enum Error {\n+    #[error(\"failed to start websocket server\")]\n+    Server(#[from] std::io::Error),\n+    #[error(\"failed to start websocket server: {0}\")]\n+    WebSocket(#[source] axum::Error),\n+    #[error(\"failed to serialize message: {0}\")]\n+    Serde(#[from] serde_json::Error),\n+    #[error(\"failed to send message\")]\n+    Send(#[from] axum::Error),\n+    #[error(\"failed to send message through channel\")]\n+    Broadcast(#[from] tokio::sync::broadcast::error::SendError<WebUIEvent>),\n+}\n+\n+#[derive(Debug, Clone)]\n+pub struct WebUISender {\n+    pub tx: tokio::sync::broadcast::Sender<WebUIEvent>,\n+}\n+\n+impl WebUISender {\n+    pub fn start_task(&self, task: String, output_logs: OutputLogs) {\n+        self.tx\n+            .send(WebUIEvent::StartTask { task, output_logs })\n+            .ok();\n+    }\n+\n+    pub fn end_task(&self, task: String, result: TaskResult) {\n+        self.tx.send(WebUIEvent::EndTask { task, result }).ok();\n+    }\n+\n+    pub fn status(&self, task: String, status: String, result: CacheResult) {\n+        self.tx\n+            .send(WebUIEvent::Status {\n+                task,\n+                status,\n+                result,\n+            })\n+            .ok();\n+    }\n+\n+    pub fn set_stdin(&self, _: String, _: Box<dyn Write + Send>) {\n+        warn!(\"stdin is not supported (yet) in web ui\");\n+    }\n+\n+    pub fn task(&self, task: String) -> TaskSender {\n+        TaskSender {\n+            name: task,\n+            handle: UISender::Wui(self.clone()),\n+            logs: Default::default(),\n+        }\n+    }\n+\n+    pub fn stop(&self) {\n+        self.tx.send(WebUIEvent::Stop).ok();\n+    }\n+\n+    pub fn update_tasks(&self, tasks: Vec<String>) -> Result<(), crate::Error> {\n+        self.tx\n+            .send(WebUIEvent::UpdateTasks { tasks })\n+            .map_err(Error::Broadcast)?;\n+\n+        Ok(())\n+    }\n+\n+    pub fn output(&self, task: String, output: Vec<u8>) -> Result<(), crate::Error> {\n+        self.tx\n+            .send(WebUIEvent::TaskOutput { task, output })\n+            .map_err(Error::Broadcast)?;\n+\n+        Ok(())\n+    }\n+}\n+\n+// Specific events that the websocket server can send to the client,\n+// not all the `Event` types from the TUI\n+#[derive(Debug, Clone, Serialize)]\n+#[serde(tag = \"type\", content = \"payload\")]\n+pub enum WebUIEvent {\n+    StartTask {\n+        task: String,\n+        output_logs: OutputLogs,\n+    },\n+    TaskOutput {\n+        task: String,\n+        output: Vec<u8>,\n+    },\n+    EndTask {\n+        task: String,\n+        result: TaskResult,\n+    },\n+    Status {\n+        task: String,\n+        status: String,\n+        result: CacheResult,\n+    },\n+    UpdateTasks {\n+        tasks: Vec<String>,\n+    },\n+    Stop,\n+}\n+\n+#[derive(Debug, Clone, Serialize)]\n+pub struct ServerMessage<'a> {\n+    pub id: u32,\n+    #[serde(flatten)]\n+    pub payload: &'a WebUIEvent,\n+}\n+\n+#[derive(Debug, Clone, Serialize, Deserialize)]\n+#[serde(tag = \"type\", content = \"payload\")]\n+pub enum ClientMessage {\n+    /// Acknowledges the receipt of a message.\n+    /// If we don't receive an ack, we will resend the message\n+    Ack { id: u32 },\n+    /// Asks for all messages from the given id onwards\n+    CatchUp { start_id: u32 },\n+}\n+\n+struct AppState {\n+    rx: tokio::sync::broadcast::Receiver<WebUIEvent>,\n+    // We use a tokio::sync::Mutex here because we want this future to be Send.\n+    #[allow(clippy::type_complexity)]\n+    messages: Arc<Mutex<RefCell<Vec<(WebUIEvent, u32)>>>>,\n+    current_id: Arc<AtomicU32>,\n+}\n+\n+impl Clone for AppState {\n+    fn clone(&self) -> Self {\n+        Self {\n+            rx: self.rx.resubscribe(),\n+            messages: self.messages.clone(),\n+            current_id: self.current_id.clone(),\n+        }\n+    }\n+}\n+\n+async fn handler(ws: WebSocketUpgrade, State(state): State<AppState>) -> impl IntoResponse {\n+    ws.on_upgrade(|socket| handle_socket(socket, state))\n+}\n+\n+async fn handle_socket(socket: WebSocket, state: AppState) {\n+    if let Err(e) = handle_socket_inner(socket, state).await {\n+        warn!(\"error handling socket: {e}\");\n+    }\n+}\n+\n+async fn handle_socket_inner(mut socket: WebSocket, state: AppState) -> Result<(), Error> {\n+    let mut state = state.clone();\n+    let mut acks = HashSet::new();\n+    let mut interval = tokio::time::interval(std::time::Duration::from_millis(100));\n+    'socket_loop: loop {\n+        select! {\n+            biased;\n+            Ok(event) = state.rx.recv() => {\n+                let id = state.current_id.fetch_add(1, std::sync::atomic::Ordering::SeqCst);\n+\n+                let message_payload = serde_json::to_string(&ServerMessage {\n+                    id,\n+                    payload: &event\n+                })?;\n+                state.messages.lock().await.borrow_mut().push((event, id));\n+\n+                socket.send(Message::Text(message_payload)).await?;\n+            }\n+            // Every 100ms, check if we need to resend any messages\n+            _ = interval.tick() => {\n+                let messages = state.messages.lock().await;\n+                let mut messages_to_send = Vec::new();\n+                for (event, id) in messages.borrow().iter() {\n+                    if !acks.contains(id) {\n+                        let message_payload = serde_json::to_string(event).unwrap();\n+                        messages_to_send.push(Message::Text(message_payload));\n+                    }\n+                };\n+\n+                for message in messages_to_send {\n+                    socket.send(message).await?;\n+                }",
    "repo_full_name": "vercel/turborepo",
    "discussion_comments": [
      {
        "comment_id": "1713930993",
        "repo_full_name": "vercel/turborepo",
        "pr_number": 8895,
        "pr_file": "crates/turborepo-ui/src/wui/mod.rs",
        "discussion_id": "1713930993",
        "commented_code": "@@ -0,0 +1,275 @@\n+//! Web UI for Turborepo. Creates a WebSocket server that can be subscribed to\n+//! by a web client to display the status of tasks.\n+\n+use std::{\n+    cell::RefCell,\n+    collections::HashSet,\n+    io::Write,\n+    sync::{atomic::AtomicU32, Arc},\n+};\n+\n+use axum::{\n+    extract::{\n+        ws::{Message, WebSocket},\n+        State, WebSocketUpgrade,\n+    },\n+    http::Method,\n+    response::IntoResponse,\n+    routing::get,\n+    Router,\n+};\n+use serde::{Deserialize, Serialize};\n+use thiserror::Error;\n+use tokio::{select, sync::Mutex};\n+use tower_http::cors::{Any, CorsLayer};\n+use tracing::log::warn;\n+\n+use crate::{\n+    sender::{TaskSender, UISender},\n+    tui::event::{CacheResult, OutputLogs, TaskResult},\n+};\n+\n+#[derive(Debug, Error)]\n+pub enum Error {\n+    #[error(\"failed to start websocket server\")]\n+    Server(#[from] std::io::Error),\n+    #[error(\"failed to start websocket server: {0}\")]\n+    WebSocket(#[source] axum::Error),\n+    #[error(\"failed to serialize message: {0}\")]\n+    Serde(#[from] serde_json::Error),\n+    #[error(\"failed to send message\")]\n+    Send(#[from] axum::Error),\n+    #[error(\"failed to send message through channel\")]\n+    Broadcast(#[from] tokio::sync::broadcast::error::SendError<WebUIEvent>),\n+}\n+\n+#[derive(Debug, Clone)]\n+pub struct WebUISender {\n+    pub tx: tokio::sync::broadcast::Sender<WebUIEvent>,\n+}\n+\n+impl WebUISender {\n+    pub fn start_task(&self, task: String, output_logs: OutputLogs) {\n+        self.tx\n+            .send(WebUIEvent::StartTask { task, output_logs })\n+            .ok();\n+    }\n+\n+    pub fn end_task(&self, task: String, result: TaskResult) {\n+        self.tx.send(WebUIEvent::EndTask { task, result }).ok();\n+    }\n+\n+    pub fn status(&self, task: String, status: String, result: CacheResult) {\n+        self.tx\n+            .send(WebUIEvent::Status {\n+                task,\n+                status,\n+                result,\n+            })\n+            .ok();\n+    }\n+\n+    pub fn set_stdin(&self, _: String, _: Box<dyn Write + Send>) {\n+        warn!(\"stdin is not supported (yet) in web ui\");\n+    }\n+\n+    pub fn task(&self, task: String) -> TaskSender {\n+        TaskSender {\n+            name: task,\n+            handle: UISender::Wui(self.clone()),\n+            logs: Default::default(),\n+        }\n+    }\n+\n+    pub fn stop(&self) {\n+        self.tx.send(WebUIEvent::Stop).ok();\n+    }\n+\n+    pub fn update_tasks(&self, tasks: Vec<String>) -> Result<(), crate::Error> {\n+        self.tx\n+            .send(WebUIEvent::UpdateTasks { tasks })\n+            .map_err(Error::Broadcast)?;\n+\n+        Ok(())\n+    }\n+\n+    pub fn output(&self, task: String, output: Vec<u8>) -> Result<(), crate::Error> {\n+        self.tx\n+            .send(WebUIEvent::TaskOutput { task, output })\n+            .map_err(Error::Broadcast)?;\n+\n+        Ok(())\n+    }\n+}\n+\n+// Specific events that the websocket server can send to the client,\n+// not all the `Event` types from the TUI\n+#[derive(Debug, Clone, Serialize)]\n+#[serde(tag = \"type\", content = \"payload\")]\n+pub enum WebUIEvent {\n+    StartTask {\n+        task: String,\n+        output_logs: OutputLogs,\n+    },\n+    TaskOutput {\n+        task: String,\n+        output: Vec<u8>,\n+    },\n+    EndTask {\n+        task: String,\n+        result: TaskResult,\n+    },\n+    Status {\n+        task: String,\n+        status: String,\n+        result: CacheResult,\n+    },\n+    UpdateTasks {\n+        tasks: Vec<String>,\n+    },\n+    Stop,\n+}\n+\n+#[derive(Debug, Clone, Serialize)]\n+pub struct ServerMessage<'a> {\n+    pub id: u32,\n+    #[serde(flatten)]\n+    pub payload: &'a WebUIEvent,\n+}\n+\n+#[derive(Debug, Clone, Serialize, Deserialize)]\n+#[serde(tag = \"type\", content = \"payload\")]\n+pub enum ClientMessage {\n+    /// Acknowledges the receipt of a message.\n+    /// If we don't receive an ack, we will resend the message\n+    Ack { id: u32 },\n+    /// Asks for all messages from the given id onwards\n+    CatchUp { start_id: u32 },\n+}\n+\n+struct AppState {\n+    rx: tokio::sync::broadcast::Receiver<WebUIEvent>,\n+    // We use a tokio::sync::Mutex here because we want this future to be Send.\n+    #[allow(clippy::type_complexity)]\n+    messages: Arc<Mutex<RefCell<Vec<(WebUIEvent, u32)>>>>,\n+    current_id: Arc<AtomicU32>,\n+}\n+\n+impl Clone for AppState {\n+    fn clone(&self) -> Self {\n+        Self {\n+            rx: self.rx.resubscribe(),\n+            messages: self.messages.clone(),\n+            current_id: self.current_id.clone(),\n+        }\n+    }\n+}\n+\n+async fn handler(ws: WebSocketUpgrade, State(state): State<AppState>) -> impl IntoResponse {\n+    ws.on_upgrade(|socket| handle_socket(socket, state))\n+}\n+\n+async fn handle_socket(socket: WebSocket, state: AppState) {\n+    if let Err(e) = handle_socket_inner(socket, state).await {\n+        warn!(\"error handling socket: {e}\");\n+    }\n+}\n+\n+async fn handle_socket_inner(mut socket: WebSocket, state: AppState) -> Result<(), Error> {\n+    let mut state = state.clone();\n+    let mut acks = HashSet::new();\n+    let mut interval = tokio::time::interval(std::time::Duration::from_millis(100));\n+    'socket_loop: loop {\n+        select! {\n+            biased;\n+            Ok(event) = state.rx.recv() => {\n+                let id = state.current_id.fetch_add(1, std::sync::atomic::Ordering::SeqCst);\n+\n+                let message_payload = serde_json::to_string(&ServerMessage {\n+                    id,\n+                    payload: &event\n+                })?;\n+                state.messages.lock().await.borrow_mut().push((event, id));\n+\n+                socket.send(Message::Text(message_payload)).await?;\n+            }\n+            // Every 100ms, check if we need to resend any messages\n+            _ = interval.tick() => {\n+                let messages = state.messages.lock().await;\n+                let mut messages_to_send = Vec::new();\n+                for (event, id) in messages.borrow().iter() {\n+                    if !acks.contains(id) {\n+                        let message_payload = serde_json::to_string(event).unwrap();\n+                        messages_to_send.push(Message::Text(message_payload));\n+                    }\n+                };\n+\n+                for message in messages_to_send {\n+                    socket.send(message).await?;\n+                }",
        "comment_created_at": "2024-08-12T14:48:38+00:00",
        "comment_author": "chris-olszewski",
        "comment_body": "We should drop the lock before we do a serial send.",
        "pr_file_module": null
      }
    ]
  }
]