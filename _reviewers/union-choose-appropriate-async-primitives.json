[
  {
    "discussion_id": "1768599888",
    "pr_number": 2579,
    "pr_file": "mpc/client/src/main.rs",
    "created_at": "2024-09-20T13:16:15+00:00",
    "commented_code": "+mod types;\n+mod ui;\n+\n+use std::{\n+    io,\n+    net::SocketAddr,\n+    os::unix::fs::MetadataExt,\n+    str::FromStr,\n+    sync::{\n+        atomic::{AtomicBool, Ordering},\n+        Arc,\n+    },\n+    time::{Duration, Instant, UNIX_EPOCH},\n+};\n+\n+use async_sqlite::{rusqlite::OpenFlags, JournalMode, PoolBuilder};\n+use base64::{prelude::BASE64_STANDARD, Engine};\n+use crossterm::{cursor::Show, event, execute};\n+use http_body_util::{BodyExt, Full};\n+use httpdate::parse_http_date;\n+use hyper::{\n+    body::{Buf, Bytes},\n+    service::service_fn,\n+    Method,\n+};\n+use hyper_util::{rt::TokioIo, server::graceful::GracefulShutdown};\n+use mpc_shared::{phase2_contribute, signed_message, supabase::SupabaseMPCApi, CONTRIBUTION_SIZE};\n+use pgp::{\n+    cleartext::CleartextSignedMessage,\n+    crypto::{hash::HashAlgorithm, sym::SymmetricKeyAlgorithm},\n+    types::SecretKeyTrait,\n+    ArmorOptions, Deserializable, KeyType, SecretKeyParamsBuilder, SignedSecretKey,\n+};\n+use ratatui::{backend::CrosstermBackend, Terminal, Viewport};\n+use reqwest::{header::LOCATION, Body};\n+use serde::Deserialize;\n+use tokio::{\n+    net::TcpListener,\n+    sync::{\n+        broadcast::{self, Receiver, Sender},\n+        mpsc, oneshot, RwLock,\n+    },\n+};\n+use tokio_util::sync::CancellationToken;\n+use types::Status;\n+\n+const CONTRIBUTE_ENDPOINT: &str = \"/contribute\";\n+const SK_ENDPOINT: &str = \"/secret_key\";\n+\n+const ZKGM_DIR: &str = \"zkgm\";\n+const CONTRIB_SK_PATH: &str = \"zkgm/contrib_key.sk.asc\";\n+const SUCCESSFUL_PATH: &str = \".zkgm_successful\";\n+\n+#[derive(PartialEq, Eq, Debug, Clone, Deserialize)]\n+#[serde(rename_all = \"camelCase\")]\n+struct Contribute {\n+    supabase_project: String,\n+    bucket: String,\n+    jwt: String,\n+    api_key: String,\n+    contributor_id: String,\n+    payload_id: String,\n+    user_email: Option<String>,\n+}\n+\n+#[derive(thiserror::Error, Debug, Clone)]\n+enum Error {\n+    #[error(\"we are not the current contributor.\")]\n+    NotCurrentContributor,\n+    #[error(\"couldn't find expected header: {0}\")]\n+    HeaderNotFound(String),\n+    #[error(\"current contributor not found.\")]\n+    ContributorNotFound,\n+    #[error(\"current payload not found.\")]\n+    PayloadNotFound,\n+    #[error(transparent)]\n+    Phase2ContributionFailed(#[from] mpc_shared::Phase2ContributionError),\n+    #[error(transparent)]\n+    Phase2VerificationFailed(#[from] mpc_shared::Phase2VerificationError),\n+    #[error(\"pgp key couldn't be found\")]\n+    PGPKeyNotFound,\n+}\n+\n+type BoxBody = http_body_util::combinators::BoxBody<Bytes, hyper::Error>;\n+\n+type DynError = Box<dyn std::error::Error + Send + Sync>;\n+\n+fn temp_file(payload_id: &str) -> String {\n+    format!(\"{ZKGM_DIR}/{payload_id}\")\n+}\n+\n+fn generate_pgp_key(email: String) -> SignedSecretKey {\n+    let mut key_params = SecretKeyParamsBuilder::default();\n+    key_params\n+        .key_type(KeyType::EdDSA)\n+        .can_certify(false)\n+        .can_sign(true)\n+        .can_encrypt(false)\n+        .primary_user_id(email)\n+        .preferred_symmetric_algorithms(\n+            [SymmetricKeyAlgorithm::AES256].to_vec().try_into().unwrap(),\n+        )\n+        .preferred_hash_algorithms([HashAlgorithm::None].to_vec().try_into().unwrap());\n+    let secret_key_params = key_params.build().expect(\"impossible\");\n+    let secret_key = secret_key_params.generate().expect(\"impossible\");\n+    let passwd_fn = || String::new();\n+    let signed_secret_key = secret_key.sign(passwd_fn).expect(\"impossible\");\n+    signed_secret_key\n+}\n+\n+async fn is_already_successful() -> bool {\n+    tokio::fs::metadata(SUCCESSFUL_PATH).await.is_ok()\n+}\n+\n+async fn wait_successful(tx_status: Sender<Status>) {\n+    loop {\n+        if is_already_successful().await {\n+            tx_status.send(Status::Successful).expect(\"impossible\");\n+            tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;\n+            break;\n+        }\n+    }\n+}\n+\n+async fn contribute(\n+    tx_status: Sender<Status>,\n+    Contribute {\n+        supabase_project,\n+        bucket,\n+        jwt,\n+        api_key,\n+        contributor_id,\n+        payload_id,\n+        ..\n+    }: Contribute,\n+) -> Result<(), DynError> {\n+    if is_already_successful().await {\n+        return Ok(());\n+    }\n+    let mut secret_key = if let Ok(_) = tokio::fs::metadata(CONTRIB_SK_PATH).await {\n+        SignedSecretKey::from_armor_single::<&[u8]>(\n+            tokio::fs::read(CONTRIB_SK_PATH).await?.as_ref(),\n+        )\n+        .expect(\"impossible\")\n+        .0\n+    } else {\n+        return Err(Error::PGPKeyNotFound.into());\n+    };\n+    let client = SupabaseMPCApi::new(supabase_project.clone(), api_key, jwt);\n+    let current_contributor = client\n+        .current_contributor()\n+        .await?\n+        .ok_or(Error::ContributorNotFound)?;\n+    if current_contributor.id != contributor_id {\n+        return Err(Error::NotCurrentContributor.into());\n+    }\n+    let current_payload = client\n+        .current_payload()\n+        .await?\n+        .ok_or(Error::PayloadNotFound)?;\n+    tx_status\n+        .send(Status::DownloadStarted(current_payload.id.clone()))\n+        .expect(\"impossible\");\n+    let payload = client\n+        .download_payload(&current_payload.id, &current_payload.id, |percent| {\n+            let tx_status = tx_status.clone();\n+            let current_payload_clone = current_payload.id.clone();\n+            async move {\n+                tx_status\n+                    .send(Status::Downloading(current_payload_clone, percent as u8))\n+                    .expect(\"impossible\");\n+            }\n+        })\n+        .await?;\n+    tx_status\n+        .send(Status::DownloadEnded(current_payload.id.clone()))\n+        .expect(\"impossible\");\n+    let phase2_contribution = if let Ok(true) = tokio::fs::metadata(temp_file(&payload_id))\n+        .await\n+        .map(|meta| meta.size() as usize == CONTRIBUTION_SIZE)\n+    {\n+        tokio::fs::read(temp_file(&payload_id)).await?\n+    } else {\n+        tx_status\n+            .send(Status::ContributionStarted)\n+            .expect(\"impossible\");\n+        let (tx_contrib, rx_contrib) = oneshot::channel();\n+        let handle = tokio::task::spawn_blocking(move || {\n+            tx_contrib\n+                .send(phase2_contribute(&payload))\n+                .expect(\"impossible\");\n+        });\n+        let phase2_contribution = rx_contrib.await??;\n+        handle.await?;\n+        tx_status\n+            .send(Status::ContributionEnded)\n+            .expect(\"impossible\");\n+        tokio::fs::write(temp_file(&payload_id), &phase2_contribution).await?;\n+        phase2_contribution\n+    };\n+\n+    // ------------------------\n+    // Sign and submits the sig\n+    // Gnark phase2 contribution appends the sha256 hash at the end\n+    let phase2_contribution_hash = &phase2_contribution[phase2_contribution.len() - 32..];\n+    let signature = CleartextSignedMessage::sign(\n+        &signed_message(\n+            &current_payload.id,\n+            &payload_id,\n+            &hex::encode(phase2_contribution_hash),\n+        ),\n+        &mut secret_key,\n+        || String::new(),\n+    )\n+    .expect(\"impossible\");\n+    let public_key = secret_key\n+        .public_key()\n+        .sign(&secret_key, || String::new())\n+        .expect(\"impossible\")\n+        .to_armored_bytes(ArmorOptions::default())\n+        .expect(\"impossible\");\n+    client\n+        .insert_contribution_signature(\n+            current_contributor.id,\n+            public_key,\n+            signature\n+                .to_armored_bytes(ArmorOptions::default())\n+                .expect(\"impossible\"),\n+        )\n+        .await?;\n+    let pool = PoolBuilder::new()\n+        .path(temp_file(\"state.sqlite3\"))\n+        .flags(\n+            OpenFlags::SQLITE_OPEN_READ_WRITE\n+                | OpenFlags::SQLITE_OPEN_CREATE\n+                | OpenFlags::SQLITE_OPEN_FULL_MUTEX\n+                | OpenFlags::SQLITE_OPEN_URI,\n+        )\n+        .journal_mode(JournalMode::Wal)\n+        .num_conns(1)\n+        .open()\n+        .await?;\n+    pool.conn(|conn| {\n+        conn.execute(\n+            \"CREATE TABLE IF NOT EXISTS resumable_upload (\n+                         location TEXT PRIMARY KEY NOT NULL,\n+                         create_at TIMESTAMPTZ NOT NULL DEFAULT(unixepoch()),\n+                         expire TIMSTAMPTZ NOT NULL\n+                     )\",\n+            (), // empty list of parameters.\n+        )?;\n+        Ok(())\n+    })\n+    .await?;\n+    let mut upload_location = pool\n+        .conn(move |conn| {\n+            let mut stmt = conn.prepare(\n+                \"SELECT location FROM resumable_upload WHERE expire > unixepoch() LIMIT 1\",\n+            )?;\n+            let mut rows = stmt.query(())?;\n+            if let Some(row) = rows.next()? {\n+                Ok(Some(row.get::<_, String>(0)?))\n+            } else {\n+                Ok(None)\n+            }\n+        })\n+        .await?;\n+    let upload_client = client.new_reqwest_builder()?.build()?;\n+    if let Some(ref location) = upload_location {\n+        if upload_client\n+            .head(location)\n+            .header(\"Tus-Resumable\", \"1.0.0\")\n+            .send()\n+            .await?\n+            .error_for_status()\n+            .is_err()\n+        {\n+            upload_location = None;\n+        }\n+    }\n+    let upload_location = match upload_location {\n+        Some(location) => location,\n+        None => {\n+            // =====================================================\n+            // https://tus.io/protocols/resumable-upload#creation ==\n+            // =====================================================\n+            let response = upload_client\n+                .post(format!(\"{supabase_project}/storage/v1/upload/resumable\"))\n+                .header(\"Tus-Resumable\", \"1.0.0\")\n+                .header(\"Upload-Length\", CONTRIBUTION_SIZE.to_string())\n+                .header(\n+                    \"Upload-Metadata\",\n+                    format!(\n+                        \"bucketName {},objectName {}\",\n+                        BASE64_STANDARD.encode(&bucket),\n+                        BASE64_STANDARD.encode(&payload_id)\n+                    ),\n+                )\n+                .send()\n+                .await?\n+                .error_for_status()?;\n+            let location = response\n+                .headers()\n+                .get(LOCATION)\n+                .ok_or(Error::HeaderNotFound(LOCATION.as_str().into()))?\n+                .to_str()?\n+                .to_string();\n+            let expire = response\n+                .headers()\n+                .get(\"Upload-Expires\")\n+                .ok_or(Error::HeaderNotFound(\"Upload-Expires\".into()))?\n+                .to_str()?\n+                .into();\n+            let expire = parse_http_date(expire)?;\n+            let expire_timestamp = expire.duration_since(UNIX_EPOCH)?.as_secs();\n+            let location_clone = location.clone();\n+            pool.conn(move |conn| {\n+                let mut stmt =\n+                    conn.prepare(\"INSERT INTO resumable_upload (location, expire) VALUES (?, ?)\")?;\n+                let r = stmt.execute((location_clone, expire_timestamp))?;\n+                assert!(r == 1);\n+                Ok(())\n+            })\n+            .await?;\n+            location\n+        }\n+    };\n+    // =================================================\n+    // https://tus.io/protocols/resumable-upload#head ==\n+    // =================================================\n+    let response = upload_client\n+        .head(&upload_location)\n+        .header(\"Tus-Resumable\", \"1.0.0\")\n+        .send()\n+        .await?\n+        .error_for_status()?;\n+    let upload_length = usize::from_str(\n+        response\n+            .headers()\n+            .get(\"Upload-Length\")\n+            .ok_or(Error::HeaderNotFound(\"Upload-Length\".into()))?\n+            .to_str()?,\n+    )?;\n+    let upload_offset = usize::from_str(\n+        response\n+            .headers()\n+            .get(\"Upload-Offset\")\n+            .ok_or(Error::HeaderNotFound(\"Upload-Offset\".into()))?\n+            .to_str()?,\n+    )?;\n+    assert!(upload_length == CONTRIBUTION_SIZE, \"invalid upload-length.\");\n+    if upload_offset < upload_length {\n+        tx_status\n+            .send(Status::UploadStarted(payload_id.clone()))\n+            .expect(\"impossible\");\n+        // ==================================================\n+        // https://tus.io/protocols/resumable-upload#patch ==\n+        // ==================================================\n+        let chunks = phase2_contribution\n+            .into_iter()\n+            .skip(upload_offset)\n+            .collect::<Vec<_>>()\n+            // 1mb\n+            .chunks(1024 * 1024)\n+            .map(|x| Ok::<_, std::io::Error>(x.to_vec()))\n+            .collect::<Vec<_>>();\n+        upload_client\n+            .patch(&upload_location)\n+            .header(\"Tus-Resumable\", \"1.0.0\")\n+            .header(\"Content-Type\", \"application/offset+octet-stream\")\n+            .header(\"Upload-Offset\", upload_offset.to_string())\n+            .body(Body::wrap_stream(futures_util::stream::iter(chunks)))\n+            .send()\n+            .await?\n+            .error_for_status()?;\n+        tx_status\n+            .send(Status::UploadEnded(payload_id.clone()))\n+            .expect(\"impossible\");\n+    }\n+    pool.close().await?;\n+    Ok(())\n+}\n+\n+fn full<T: Into<Bytes>>(chunk: T) -> BoxBody {\n+    Full::new(chunk.into())\n+        .map_err(|never| match never {})\n+        .boxed()\n+}\n+\n+async fn handle(\n+    lock: Arc<AtomicBool>,\n+    tx_status: Sender<Status>,\n+    latest_status: Arc<RwLock<Status>>,\n+    req: hyper::Request<hyper::body::Incoming>,\n+) -> Result<hyper::Response<BoxBody>, DynError> {\n+    let response = |status, body| {\n+        Ok(hyper::Response::builder()\n+            .header(hyper::header::ACCESS_CONTROL_ALLOW_ORIGIN, \"*\")\n+            .header(hyper::header::CONTENT_TYPE, \"application/json\")\n+            .status(status)\n+            .body(body)\n+            .unwrap())\n+    };\n+    let file_response = |status, body| {\n+        Ok(hyper::Response::builder()\n+            .header(hyper::header::ACCESS_CONTROL_ALLOW_ORIGIN, \"*\")\n+            .header(hyper::header::CONTENT_TYPE, \"application/octet-stream\")\n+            .header(\n+                hyper::header::CONTENT_DISPOSITION,\n+                format!(\"attachment; filename={CONTRIB_SK_PATH}\"),\n+            )\n+            .status(status)\n+            .body(body)\n+            .unwrap())\n+    };\n+    let response_empty = |status| response(status, BoxBody::default());\n+    match (req.method(), req.uri().path()) {\n+        (&Method::POST, SK_ENDPOINT) => {\n+            let whole_body = req.collect().await?.aggregate();\n+            let email = serde_json::from_reader(whole_body.reader())?;\n+            let guard = latest_status.write().await;\n+            let result = {\n+                if let Err(_) = tokio::fs::metadata(CONTRIB_SK_PATH).await {\n+                    let secret_key = generate_pgp_key(email);\n+                    let secret_key_serialized = secret_key\n+                        .to_armored_bytes(ArmorOptions::default())\n+                        .expect(\"impossible\");\n+                    tokio::fs::write(CONTRIB_SK_PATH, &secret_key_serialized).await?;\n+                    response_empty(hyper::StatusCode::CREATED)\n+                } else {\n+                    response_empty(hyper::StatusCode::OK)\n+                }\n+            };\n+            drop(guard);\n+            result\n+        }\n+        (&Method::GET, SK_ENDPOINT) => {\n+            if let Err(_) = tokio::fs::metadata(CONTRIB_SK_PATH).await {\n+                response_empty(hyper::StatusCode::NOT_FOUND)\n+            } else {\n+                let content = tokio::fs::read(CONTRIB_SK_PATH).await?;\n+                file_response(hyper::StatusCode::OK, full(content))\n+            }\n+        }\n+        (&Method::POST, CONTRIBUTE_ENDPOINT)\n+            if lock\n+                .compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst)\n+                .is_ok() =>\n+        {\n+            tx_status.send(Status::Initializing).expect(\"impossible\");\n+            tokio::spawn(async move {\n+                let result = (|| async {\n+                    let whole_body = req.collect().await?.aggregate();\n+                    contribute(\n+                        tx_status.clone(),\n+                        serde_json::from_reader(whole_body.reader())?,\n+                    )\n+                    .await?;\n+                    Ok::<_, DynError>(())\n+                })()\n+                .await;\n+                match result {\n+                    Ok(_) => {\n+                        let _ = tokio::fs::write(SUCCESSFUL_PATH, &[1u8]).await;\n+                        let _ = tokio::fs::remove_dir(ZKGM_DIR).await;\n+                    }\n+                    Err(e) => {\n+                        tx_status\n+                            .send(Status::Failed(format!(\"{:?}\", e)))\n+                            .expect(\"impossible\");\n+                    }\n+                }\n+            });\n+            response_empty(hyper::StatusCode::ACCEPTED)\n+        }\n+        // FE must poll GET and dispatch accordingly.\n+        (&Method::POST, CONTRIBUTE_ENDPOINT) => {\n+            response_empty(hyper::StatusCode::SERVICE_UNAVAILABLE)\n+        }\n+        (&Method::GET, CONTRIBUTE_ENDPOINT) => match latest_status.read().await.clone() {\n+            Status::Failed(e) => {\n+                lock.compare_exchange(true, false, Ordering::SeqCst, Ordering::SeqCst)\n+                    .expect(\"impossible\");\n+                // Only idle if the FE poll after a failure.\n+                tx_status.send(Status::Idle).expect(\"impossible\");\n+                response(\n+                    hyper::StatusCode::INTERNAL_SERVER_ERROR,\n+                    full(serde_json::to_vec(&format!(\"{:#?}\", e)).expect(\"impossible\")),\n+                )\n+            }\n+            x => response(\n+                hyper::StatusCode::OK,\n+                full(serde_json::to_vec(&x).expect(\"impossible\")),\n+            ),\n+        },\n+        // CORS preflight request.\n+        (&Method::OPTIONS, CONTRIBUTE_ENDPOINT | SK_ENDPOINT) => Ok(hyper::Response::builder()\n+            .header(hyper::header::ACCESS_CONTROL_ALLOW_ORIGIN, \"*\")\n+            .header(\n+                hyper::header::ACCESS_CONTROL_ALLOW_HEADERS,\n+                format!(\n+                    \"{}, {}\",\n+                    hyper::header::CONTENT_TYPE,\n+                    hyper::header::CONTENT_DISPOSITION\n+                ),\n+            )\n+            .header(\n+                hyper::header::ACCESS_CONTROL_ALLOW_METHODS,\n+                format!(\n+                    \"{}, {}, {}\",\n+                    Method::OPTIONS.as_str(),\n+                    Method::GET.as_str(),\n+                    Method::POST.as_str()\n+                ),\n+            )\n+            .status(hyper::StatusCode::OK)\n+            .body(BoxBody::default())\n+            .unwrap()),\n+        _ => response_empty(hyper::StatusCode::NOT_FOUND),\n+    }\n+}\n+\n+async fn input_and_status_handling(\n+    latest_status: Arc<RwLock<Status>>,\n+    mut rx_status: Receiver<Status>,\n+    tx_ui: mpsc::UnboundedSender<ui::Event>,\n+) {\n+    let tx_ui_clone = tx_ui.clone();\n+    tokio::spawn(async move {\n+        while let Ok(status) = rx_status.recv().await {\n+            *latest_status.write().await = status.clone();\n+            if let Err(_) = tx_ui_clone.send(ui::Event::NewStatus(status)) {\n+                break;\n+            }\n+        }\n+    });\n+    tokio::spawn(async move {\n+        let tick_rate = Duration::from_millis(1000 / 60);\n+        let mut last_tick = Instant::now();\n+        loop {\n+            // poll for tick rate duration, if no events, sent tick event.\n+            let timeout = tick_rate.saturating_sub(last_tick.elapsed());\n+            if event::poll(timeout).unwrap() {\n+                match event::read().unwrap() {\n+                    event::Event::Key(key) => tx_ui.send(ui::Event::Input(key)).unwrap(),\n+                    event::Event::Resize(_, _) => tx_ui.send(ui::Event::Resize).unwrap(),\n+                    _ => {}\n+                };\n+            }\n+            if last_tick.elapsed() >= tick_rate {\n+                if let Err(_) = tx_ui.send(ui::Event::Tick) {\n+                    break;\n+                }\n+                last_tick = Instant::now();\n+            }\n+        }\n+    });\n+}\n+\n+#[tokio::main]\n+async fn main() -> Result<(), DynError> {\n+    if let Err(_) = tokio::fs::metadata(ZKGM_DIR).await {\n+        tokio::fs::create_dir(ZKGM_DIR).await?;\n+    }\n+    let status = Arc::new(RwLock::new(Status::Idle));\n+    let lock = Arc::new(AtomicBool::new(false));\n+    let (tx_status, rx_status) = broadcast::channel(64);\n+    let graceful = GracefulShutdown::new();\n+    let status_clone = status.clone();\n+    let token = CancellationToken::new();\n+    let token_clone = token.clone();\n+    let tx_status_clone = tx_status.clone();\n+    let handle = tokio::spawn(async move {\n+        let addr = SocketAddr::from(([0, 0, 0, 0], 0x1337));\n+        let listener = TcpListener::bind(addr).await.unwrap();\n+        loop {\n+            tokio::select! {\n+                Ok((stream, _)) = listener.accept() => {\n+                    let io = TokioIo::new(stream);\n+                    let status_clone = status_clone.clone();\n+                    let tx_status_clone = tx_status_clone.clone();\n+                    let lock_clone = lock.clone();\n+                    let conn = hyper::server::conn::http1::Builder::new().serve_connection(\n+                        io,\n+                        service_fn(move |req| {\n+                            handle(\n+                                lock_clone.clone(),\n+                                tx_status_clone.clone(),\n+                                status_clone.clone(),\n+                                req,\n+                            )\n+                        }),\n+                    );\n+                    let fut = graceful.watch(conn);\n+                    tokio::task::spawn(async move {\n+                        let _ = fut.await;\n+                    });\n+                }\n+                _ = token_clone.cancelled() => {\n+                    break;\n+                }\n+            }",
    "repo_full_name": "unionlabs/union",
    "discussion_comments": [
      {
        "comment_id": "1768599888",
        "repo_full_name": "unionlabs/union",
        "pr_number": 2579,
        "pr_file": "mpc/client/src/main.rs",
        "discussion_id": "1768599888",
        "commented_code": "@@ -0,0 +1,628 @@\n+mod types;\n+mod ui;\n+\n+use std::{\n+    io,\n+    net::SocketAddr,\n+    os::unix::fs::MetadataExt,\n+    str::FromStr,\n+    sync::{\n+        atomic::{AtomicBool, Ordering},\n+        Arc,\n+    },\n+    time::{Duration, Instant, UNIX_EPOCH},\n+};\n+\n+use async_sqlite::{rusqlite::OpenFlags, JournalMode, PoolBuilder};\n+use base64::{prelude::BASE64_STANDARD, Engine};\n+use crossterm::{cursor::Show, event, execute};\n+use http_body_util::{BodyExt, Full};\n+use httpdate::parse_http_date;\n+use hyper::{\n+    body::{Buf, Bytes},\n+    service::service_fn,\n+    Method,\n+};\n+use hyper_util::{rt::TokioIo, server::graceful::GracefulShutdown};\n+use mpc_shared::{phase2_contribute, signed_message, supabase::SupabaseMPCApi, CONTRIBUTION_SIZE};\n+use pgp::{\n+    cleartext::CleartextSignedMessage,\n+    crypto::{hash::HashAlgorithm, sym::SymmetricKeyAlgorithm},\n+    types::SecretKeyTrait,\n+    ArmorOptions, Deserializable, KeyType, SecretKeyParamsBuilder, SignedSecretKey,\n+};\n+use ratatui::{backend::CrosstermBackend, Terminal, Viewport};\n+use reqwest::{header::LOCATION, Body};\n+use serde::Deserialize;\n+use tokio::{\n+    net::TcpListener,\n+    sync::{\n+        broadcast::{self, Receiver, Sender},\n+        mpsc, oneshot, RwLock,\n+    },\n+};\n+use tokio_util::sync::CancellationToken;\n+use types::Status;\n+\n+const CONTRIBUTE_ENDPOINT: &str = \"/contribute\";\n+const SK_ENDPOINT: &str = \"/secret_key\";\n+\n+const ZKGM_DIR: &str = \"zkgm\";\n+const CONTRIB_SK_PATH: &str = \"zkgm/contrib_key.sk.asc\";\n+const SUCCESSFUL_PATH: &str = \".zkgm_successful\";\n+\n+#[derive(PartialEq, Eq, Debug, Clone, Deserialize)]\n+#[serde(rename_all = \"camelCase\")]\n+struct Contribute {\n+    supabase_project: String,\n+    bucket: String,\n+    jwt: String,\n+    api_key: String,\n+    contributor_id: String,\n+    payload_id: String,\n+    user_email: Option<String>,\n+}\n+\n+#[derive(thiserror::Error, Debug, Clone)]\n+enum Error {\n+    #[error(\"we are not the current contributor.\")]\n+    NotCurrentContributor,\n+    #[error(\"couldn't find expected header: {0}\")]\n+    HeaderNotFound(String),\n+    #[error(\"current contributor not found.\")]\n+    ContributorNotFound,\n+    #[error(\"current payload not found.\")]\n+    PayloadNotFound,\n+    #[error(transparent)]\n+    Phase2ContributionFailed(#[from] mpc_shared::Phase2ContributionError),\n+    #[error(transparent)]\n+    Phase2VerificationFailed(#[from] mpc_shared::Phase2VerificationError),\n+    #[error(\"pgp key couldn't be found\")]\n+    PGPKeyNotFound,\n+}\n+\n+type BoxBody = http_body_util::combinators::BoxBody<Bytes, hyper::Error>;\n+\n+type DynError = Box<dyn std::error::Error + Send + Sync>;\n+\n+fn temp_file(payload_id: &str) -> String {\n+    format!(\"{ZKGM_DIR}/{payload_id}\")\n+}\n+\n+fn generate_pgp_key(email: String) -> SignedSecretKey {\n+    let mut key_params = SecretKeyParamsBuilder::default();\n+    key_params\n+        .key_type(KeyType::EdDSA)\n+        .can_certify(false)\n+        .can_sign(true)\n+        .can_encrypt(false)\n+        .primary_user_id(email)\n+        .preferred_symmetric_algorithms(\n+            [SymmetricKeyAlgorithm::AES256].to_vec().try_into().unwrap(),\n+        )\n+        .preferred_hash_algorithms([HashAlgorithm::None].to_vec().try_into().unwrap());\n+    let secret_key_params = key_params.build().expect(\"impossible\");\n+    let secret_key = secret_key_params.generate().expect(\"impossible\");\n+    let passwd_fn = || String::new();\n+    let signed_secret_key = secret_key.sign(passwd_fn).expect(\"impossible\");\n+    signed_secret_key\n+}\n+\n+async fn is_already_successful() -> bool {\n+    tokio::fs::metadata(SUCCESSFUL_PATH).await.is_ok()\n+}\n+\n+async fn wait_successful(tx_status: Sender<Status>) {\n+    loop {\n+        if is_already_successful().await {\n+            tx_status.send(Status::Successful).expect(\"impossible\");\n+            tokio::time::sleep(tokio::time::Duration::from_millis(2000)).await;\n+            break;\n+        }\n+    }\n+}\n+\n+async fn contribute(\n+    tx_status: Sender<Status>,\n+    Contribute {\n+        supabase_project,\n+        bucket,\n+        jwt,\n+        api_key,\n+        contributor_id,\n+        payload_id,\n+        ..\n+    }: Contribute,\n+) -> Result<(), DynError> {\n+    if is_already_successful().await {\n+        return Ok(());\n+    }\n+    let mut secret_key = if let Ok(_) = tokio::fs::metadata(CONTRIB_SK_PATH).await {\n+        SignedSecretKey::from_armor_single::<&[u8]>(\n+            tokio::fs::read(CONTRIB_SK_PATH).await?.as_ref(),\n+        )\n+        .expect(\"impossible\")\n+        .0\n+    } else {\n+        return Err(Error::PGPKeyNotFound.into());\n+    };\n+    let client = SupabaseMPCApi::new(supabase_project.clone(), api_key, jwt);\n+    let current_contributor = client\n+        .current_contributor()\n+        .await?\n+        .ok_or(Error::ContributorNotFound)?;\n+    if current_contributor.id != contributor_id {\n+        return Err(Error::NotCurrentContributor.into());\n+    }\n+    let current_payload = client\n+        .current_payload()\n+        .await?\n+        .ok_or(Error::PayloadNotFound)?;\n+    tx_status\n+        .send(Status::DownloadStarted(current_payload.id.clone()))\n+        .expect(\"impossible\");\n+    let payload = client\n+        .download_payload(&current_payload.id, &current_payload.id, |percent| {\n+            let tx_status = tx_status.clone();\n+            let current_payload_clone = current_payload.id.clone();\n+            async move {\n+                tx_status\n+                    .send(Status::Downloading(current_payload_clone, percent as u8))\n+                    .expect(\"impossible\");\n+            }\n+        })\n+        .await?;\n+    tx_status\n+        .send(Status::DownloadEnded(current_payload.id.clone()))\n+        .expect(\"impossible\");\n+    let phase2_contribution = if let Ok(true) = tokio::fs::metadata(temp_file(&payload_id))\n+        .await\n+        .map(|meta| meta.size() as usize == CONTRIBUTION_SIZE)\n+    {\n+        tokio::fs::read(temp_file(&payload_id)).await?\n+    } else {\n+        tx_status\n+            .send(Status::ContributionStarted)\n+            .expect(\"impossible\");\n+        let (tx_contrib, rx_contrib) = oneshot::channel();\n+        let handle = tokio::task::spawn_blocking(move || {\n+            tx_contrib\n+                .send(phase2_contribute(&payload))\n+                .expect(\"impossible\");\n+        });\n+        let phase2_contribution = rx_contrib.await??;\n+        handle.await?;\n+        tx_status\n+            .send(Status::ContributionEnded)\n+            .expect(\"impossible\");\n+        tokio::fs::write(temp_file(&payload_id), &phase2_contribution).await?;\n+        phase2_contribution\n+    };\n+\n+    // ------------------------\n+    // Sign and submits the sig\n+    // Gnark phase2 contribution appends the sha256 hash at the end\n+    let phase2_contribution_hash = &phase2_contribution[phase2_contribution.len() - 32..];\n+    let signature = CleartextSignedMessage::sign(\n+        &signed_message(\n+            &current_payload.id,\n+            &payload_id,\n+            &hex::encode(phase2_contribution_hash),\n+        ),\n+        &mut secret_key,\n+        || String::new(),\n+    )\n+    .expect(\"impossible\");\n+    let public_key = secret_key\n+        .public_key()\n+        .sign(&secret_key, || String::new())\n+        .expect(\"impossible\")\n+        .to_armored_bytes(ArmorOptions::default())\n+        .expect(\"impossible\");\n+    client\n+        .insert_contribution_signature(\n+            current_contributor.id,\n+            public_key,\n+            signature\n+                .to_armored_bytes(ArmorOptions::default())\n+                .expect(\"impossible\"),\n+        )\n+        .await?;\n+    let pool = PoolBuilder::new()\n+        .path(temp_file(\"state.sqlite3\"))\n+        .flags(\n+            OpenFlags::SQLITE_OPEN_READ_WRITE\n+                | OpenFlags::SQLITE_OPEN_CREATE\n+                | OpenFlags::SQLITE_OPEN_FULL_MUTEX\n+                | OpenFlags::SQLITE_OPEN_URI,\n+        )\n+        .journal_mode(JournalMode::Wal)\n+        .num_conns(1)\n+        .open()\n+        .await?;\n+    pool.conn(|conn| {\n+        conn.execute(\n+            \"CREATE TABLE IF NOT EXISTS resumable_upload (\n+                         location TEXT PRIMARY KEY NOT NULL,\n+                         create_at TIMESTAMPTZ NOT NULL DEFAULT(unixepoch()),\n+                         expire TIMSTAMPTZ NOT NULL\n+                     )\",\n+            (), // empty list of parameters.\n+        )?;\n+        Ok(())\n+    })\n+    .await?;\n+    let mut upload_location = pool\n+        .conn(move |conn| {\n+            let mut stmt = conn.prepare(\n+                \"SELECT location FROM resumable_upload WHERE expire > unixepoch() LIMIT 1\",\n+            )?;\n+            let mut rows = stmt.query(())?;\n+            if let Some(row) = rows.next()? {\n+                Ok(Some(row.get::<_, String>(0)?))\n+            } else {\n+                Ok(None)\n+            }\n+        })\n+        .await?;\n+    let upload_client = client.new_reqwest_builder()?.build()?;\n+    if let Some(ref location) = upload_location {\n+        if upload_client\n+            .head(location)\n+            .header(\"Tus-Resumable\", \"1.0.0\")\n+            .send()\n+            .await?\n+            .error_for_status()\n+            .is_err()\n+        {\n+            upload_location = None;\n+        }\n+    }\n+    let upload_location = match upload_location {\n+        Some(location) => location,\n+        None => {\n+            // =====================================================\n+            // https://tus.io/protocols/resumable-upload#creation ==\n+            // =====================================================\n+            let response = upload_client\n+                .post(format!(\"{supabase_project}/storage/v1/upload/resumable\"))\n+                .header(\"Tus-Resumable\", \"1.0.0\")\n+                .header(\"Upload-Length\", CONTRIBUTION_SIZE.to_string())\n+                .header(\n+                    \"Upload-Metadata\",\n+                    format!(\n+                        \"bucketName {},objectName {}\",\n+                        BASE64_STANDARD.encode(&bucket),\n+                        BASE64_STANDARD.encode(&payload_id)\n+                    ),\n+                )\n+                .send()\n+                .await?\n+                .error_for_status()?;\n+            let location = response\n+                .headers()\n+                .get(LOCATION)\n+                .ok_or(Error::HeaderNotFound(LOCATION.as_str().into()))?\n+                .to_str()?\n+                .to_string();\n+            let expire = response\n+                .headers()\n+                .get(\"Upload-Expires\")\n+                .ok_or(Error::HeaderNotFound(\"Upload-Expires\".into()))?\n+                .to_str()?\n+                .into();\n+            let expire = parse_http_date(expire)?;\n+            let expire_timestamp = expire.duration_since(UNIX_EPOCH)?.as_secs();\n+            let location_clone = location.clone();\n+            pool.conn(move |conn| {\n+                let mut stmt =\n+                    conn.prepare(\"INSERT INTO resumable_upload (location, expire) VALUES (?, ?)\")?;\n+                let r = stmt.execute((location_clone, expire_timestamp))?;\n+                assert!(r == 1);\n+                Ok(())\n+            })\n+            .await?;\n+            location\n+        }\n+    };\n+    // =================================================\n+    // https://tus.io/protocols/resumable-upload#head ==\n+    // =================================================\n+    let response = upload_client\n+        .head(&upload_location)\n+        .header(\"Tus-Resumable\", \"1.0.0\")\n+        .send()\n+        .await?\n+        .error_for_status()?;\n+    let upload_length = usize::from_str(\n+        response\n+            .headers()\n+            .get(\"Upload-Length\")\n+            .ok_or(Error::HeaderNotFound(\"Upload-Length\".into()))?\n+            .to_str()?,\n+    )?;\n+    let upload_offset = usize::from_str(\n+        response\n+            .headers()\n+            .get(\"Upload-Offset\")\n+            .ok_or(Error::HeaderNotFound(\"Upload-Offset\".into()))?\n+            .to_str()?,\n+    )?;\n+    assert!(upload_length == CONTRIBUTION_SIZE, \"invalid upload-length.\");\n+    if upload_offset < upload_length {\n+        tx_status\n+            .send(Status::UploadStarted(payload_id.clone()))\n+            .expect(\"impossible\");\n+        // ==================================================\n+        // https://tus.io/protocols/resumable-upload#patch ==\n+        // ==================================================\n+        let chunks = phase2_contribution\n+            .into_iter()\n+            .skip(upload_offset)\n+            .collect::<Vec<_>>()\n+            // 1mb\n+            .chunks(1024 * 1024)\n+            .map(|x| Ok::<_, std::io::Error>(x.to_vec()))\n+            .collect::<Vec<_>>();\n+        upload_client\n+            .patch(&upload_location)\n+            .header(\"Tus-Resumable\", \"1.0.0\")\n+            .header(\"Content-Type\", \"application/offset+octet-stream\")\n+            .header(\"Upload-Offset\", upload_offset.to_string())\n+            .body(Body::wrap_stream(futures_util::stream::iter(chunks)))\n+            .send()\n+            .await?\n+            .error_for_status()?;\n+        tx_status\n+            .send(Status::UploadEnded(payload_id.clone()))\n+            .expect(\"impossible\");\n+    }\n+    pool.close().await?;\n+    Ok(())\n+}\n+\n+fn full<T: Into<Bytes>>(chunk: T) -> BoxBody {\n+    Full::new(chunk.into())\n+        .map_err(|never| match never {})\n+        .boxed()\n+}\n+\n+async fn handle(\n+    lock: Arc<AtomicBool>,\n+    tx_status: Sender<Status>,\n+    latest_status: Arc<RwLock<Status>>,\n+    req: hyper::Request<hyper::body::Incoming>,\n+) -> Result<hyper::Response<BoxBody>, DynError> {\n+    let response = |status, body| {\n+        Ok(hyper::Response::builder()\n+            .header(hyper::header::ACCESS_CONTROL_ALLOW_ORIGIN, \"*\")\n+            .header(hyper::header::CONTENT_TYPE, \"application/json\")\n+            .status(status)\n+            .body(body)\n+            .unwrap())\n+    };\n+    let file_response = |status, body| {\n+        Ok(hyper::Response::builder()\n+            .header(hyper::header::ACCESS_CONTROL_ALLOW_ORIGIN, \"*\")\n+            .header(hyper::header::CONTENT_TYPE, \"application/octet-stream\")\n+            .header(\n+                hyper::header::CONTENT_DISPOSITION,\n+                format!(\"attachment; filename={CONTRIB_SK_PATH}\"),\n+            )\n+            .status(status)\n+            .body(body)\n+            .unwrap())\n+    };\n+    let response_empty = |status| response(status, BoxBody::default());\n+    match (req.method(), req.uri().path()) {\n+        (&Method::POST, SK_ENDPOINT) => {\n+            let whole_body = req.collect().await?.aggregate();\n+            let email = serde_json::from_reader(whole_body.reader())?;\n+            let guard = latest_status.write().await;\n+            let result = {\n+                if let Err(_) = tokio::fs::metadata(CONTRIB_SK_PATH).await {\n+                    let secret_key = generate_pgp_key(email);\n+                    let secret_key_serialized = secret_key\n+                        .to_armored_bytes(ArmorOptions::default())\n+                        .expect(\"impossible\");\n+                    tokio::fs::write(CONTRIB_SK_PATH, &secret_key_serialized).await?;\n+                    response_empty(hyper::StatusCode::CREATED)\n+                } else {\n+                    response_empty(hyper::StatusCode::OK)\n+                }\n+            };\n+            drop(guard);\n+            result\n+        }\n+        (&Method::GET, SK_ENDPOINT) => {\n+            if let Err(_) = tokio::fs::metadata(CONTRIB_SK_PATH).await {\n+                response_empty(hyper::StatusCode::NOT_FOUND)\n+            } else {\n+                let content = tokio::fs::read(CONTRIB_SK_PATH).await?;\n+                file_response(hyper::StatusCode::OK, full(content))\n+            }\n+        }\n+        (&Method::POST, CONTRIBUTE_ENDPOINT)\n+            if lock\n+                .compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst)\n+                .is_ok() =>\n+        {\n+            tx_status.send(Status::Initializing).expect(\"impossible\");\n+            tokio::spawn(async move {\n+                let result = (|| async {\n+                    let whole_body = req.collect().await?.aggregate();\n+                    contribute(\n+                        tx_status.clone(),\n+                        serde_json::from_reader(whole_body.reader())?,\n+                    )\n+                    .await?;\n+                    Ok::<_, DynError>(())\n+                })()\n+                .await;\n+                match result {\n+                    Ok(_) => {\n+                        let _ = tokio::fs::write(SUCCESSFUL_PATH, &[1u8]).await;\n+                        let _ = tokio::fs::remove_dir(ZKGM_DIR).await;\n+                    }\n+                    Err(e) => {\n+                        tx_status\n+                            .send(Status::Failed(format!(\"{:?}\", e)))\n+                            .expect(\"impossible\");\n+                    }\n+                }\n+            });\n+            response_empty(hyper::StatusCode::ACCEPTED)\n+        }\n+        // FE must poll GET and dispatch accordingly.\n+        (&Method::POST, CONTRIBUTE_ENDPOINT) => {\n+            response_empty(hyper::StatusCode::SERVICE_UNAVAILABLE)\n+        }\n+        (&Method::GET, CONTRIBUTE_ENDPOINT) => match latest_status.read().await.clone() {\n+            Status::Failed(e) => {\n+                lock.compare_exchange(true, false, Ordering::SeqCst, Ordering::SeqCst)\n+                    .expect(\"impossible\");\n+                // Only idle if the FE poll after a failure.\n+                tx_status.send(Status::Idle).expect(\"impossible\");\n+                response(\n+                    hyper::StatusCode::INTERNAL_SERVER_ERROR,\n+                    full(serde_json::to_vec(&format!(\"{:#?}\", e)).expect(\"impossible\")),\n+                )\n+            }\n+            x => response(\n+                hyper::StatusCode::OK,\n+                full(serde_json::to_vec(&x).expect(\"impossible\")),\n+            ),\n+        },\n+        // CORS preflight request.\n+        (&Method::OPTIONS, CONTRIBUTE_ENDPOINT | SK_ENDPOINT) => Ok(hyper::Response::builder()\n+            .header(hyper::header::ACCESS_CONTROL_ALLOW_ORIGIN, \"*\")\n+            .header(\n+                hyper::header::ACCESS_CONTROL_ALLOW_HEADERS,\n+                format!(\n+                    \"{}, {}\",\n+                    hyper::header::CONTENT_TYPE,\n+                    hyper::header::CONTENT_DISPOSITION\n+                ),\n+            )\n+            .header(\n+                hyper::header::ACCESS_CONTROL_ALLOW_METHODS,\n+                format!(\n+                    \"{}, {}, {}\",\n+                    Method::OPTIONS.as_str(),\n+                    Method::GET.as_str(),\n+                    Method::POST.as_str()\n+                ),\n+            )\n+            .status(hyper::StatusCode::OK)\n+            .body(BoxBody::default())\n+            .unwrap()),\n+        _ => response_empty(hyper::StatusCode::NOT_FOUND),\n+    }\n+}\n+\n+async fn input_and_status_handling(\n+    latest_status: Arc<RwLock<Status>>,\n+    mut rx_status: Receiver<Status>,\n+    tx_ui: mpsc::UnboundedSender<ui::Event>,\n+) {\n+    let tx_ui_clone = tx_ui.clone();\n+    tokio::spawn(async move {\n+        while let Ok(status) = rx_status.recv().await {\n+            *latest_status.write().await = status.clone();\n+            if let Err(_) = tx_ui_clone.send(ui::Event::NewStatus(status)) {\n+                break;\n+            }\n+        }\n+    });\n+    tokio::spawn(async move {\n+        let tick_rate = Duration::from_millis(1000 / 60);\n+        let mut last_tick = Instant::now();\n+        loop {\n+            // poll for tick rate duration, if no events, sent tick event.\n+            let timeout = tick_rate.saturating_sub(last_tick.elapsed());\n+            if event::poll(timeout).unwrap() {\n+                match event::read().unwrap() {\n+                    event::Event::Key(key) => tx_ui.send(ui::Event::Input(key)).unwrap(),\n+                    event::Event::Resize(_, _) => tx_ui.send(ui::Event::Resize).unwrap(),\n+                    _ => {}\n+                };\n+            }\n+            if last_tick.elapsed() >= tick_rate {\n+                if let Err(_) = tx_ui.send(ui::Event::Tick) {\n+                    break;\n+                }\n+                last_tick = Instant::now();\n+            }\n+        }\n+    });\n+}\n+\n+#[tokio::main]\n+async fn main() -> Result<(), DynError> {\n+    if let Err(_) = tokio::fs::metadata(ZKGM_DIR).await {\n+        tokio::fs::create_dir(ZKGM_DIR).await?;\n+    }\n+    let status = Arc::new(RwLock::new(Status::Idle));\n+    let lock = Arc::new(AtomicBool::new(false));\n+    let (tx_status, rx_status) = broadcast::channel(64);\n+    let graceful = GracefulShutdown::new();\n+    let status_clone = status.clone();\n+    let token = CancellationToken::new();\n+    let token_clone = token.clone();\n+    let tx_status_clone = tx_status.clone();\n+    let handle = tokio::spawn(async move {\n+        let addr = SocketAddr::from(([0, 0, 0, 0], 0x1337));\n+        let listener = TcpListener::bind(addr).await.unwrap();\n+        loop {\n+            tokio::select! {\n+                Ok((stream, _)) = listener.accept() => {\n+                    let io = TokioIo::new(stream);\n+                    let status_clone = status_clone.clone();\n+                    let tx_status_clone = tx_status_clone.clone();\n+                    let lock_clone = lock.clone();\n+                    let conn = hyper::server::conn::http1::Builder::new().serve_connection(\n+                        io,\n+                        service_fn(move |req| {\n+                            handle(\n+                                lock_clone.clone(),\n+                                tx_status_clone.clone(),\n+                                status_clone.clone(),\n+                                req,\n+                            )\n+                        }),\n+                    );\n+                    let fut = graceful.watch(conn);\n+                    tokio::task::spawn(async move {\n+                        let _ = fut.await;\n+                    });\n+                }\n+                _ = token_clone.cancelled() => {\n+                    break;\n+                }\n+            }",
        "comment_created_at": "2024-09-20T13:16:15+00:00",
        "comment_author": "benluelo",
        "comment_body": "this can be https://docs.rs/tokio-util/latest/tokio_util/sync/struct.CancellationToken.html#method.run_until_cancelled",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1758153981",
    "pr_number": 2944,
    "pr_file": "hubble/src/indexer/fetcher.rs",
    "created_at": "2024-09-13T04:18:37+00:00",
    "commented_code": "+use std::{ops::Range, time::Duration};\n+\n+use color_eyre::eyre::Report;\n+use tokio::{\n+    sync::mpsc::{self},\n+    time::sleep,\n+};\n+use tracing::{debug, error, info, info_span, Instrument};\n+\n+use super::{\n+    api::{BlockHeight, FetchMessage, FetcherClient},\n+    Indexer,\n+};\n+use crate::indexer::{\n+    api::{BlockHandle, BlockRange, BlockReference, FetcherError},\n+    postgres::{get_current_height, update_block_status, update_current_height},\n+};\n+\n+trait Chunkeable {\n+    type T;\n+\n+    fn range_chunks(self, chunk_size: usize) -> impl Iterator<Item = Range<Self::T>>;\n+}\n+\n+impl Chunkeable for BlockRange {\n+    type T = BlockHeight;\n+\n+    fn range_chunks(\n+        self: BlockRange,\n+        chunk_size: usize,\n+    ) -> impl Iterator<Item = Range<BlockHeight>> {\n+        self.clone().step_by(chunk_size).map(move |block_start| {\n+            let block_end = (block_start + chunk_size as u64).min(self.end);\n+            block_start..block_end\n+        })\n+    }\n+}\n+\n+impl<T: FetcherClient> Indexer<T> {\n+    pub async fn run_fetcher(&self, fetcher_client: T) -> Result<(), Report> {\n+        self.run_to_finalized(&fetcher_client)\n+            .instrument(info_span!(\"run-to-finalized\"))\n+            .await?;\n+        self.run_to_tip(&fetcher_client)\n+            .instrument(info_span!(\"run-to-tip\"))\n+            .await?;\n+        Ok(())\n+    }\n+\n+    async fn run_to_finalized(&self, fetcher_client: &T) -> Result<(), Report> {\n+        // run to finalized\n+        loop {\n+            debug!(\"fetching last finalized block\");\n+            match fetcher_client.fetch(BlockReference::LastFinalized).await? {\n+                None => {\n+                    info!(\"no finalized block => start 'run to tip'\");\n+                    return Ok(());\n+                }\n+                Some(last_finalized) => {\n+                    let next_height = self.next_height().await?;\n+                    if next_height + self.chunk_size as u64 > last_finalized.height()? {\n+                        info!(\"near finalized height (current: {} finalized: {}) => start 'run to tip'\", next_height, last_finalized.height()?);\n+                        return Ok(());\n+                    }\n+\n+                    let catch_up_range: BlockRange = next_height..last_finalized.height()?;\n+                    info!(\n+                        \"missing blocks: {}..{}\",\n+                        catch_up_range.start, catch_up_range.end\n+                    );\n+\n+                    for slice in catch_up_range.range_chunks(self.chunk_size).into_iter() {\n+                        info!(\"handling chunk: {}..{}\", slice.start, slice.end);\n+\n+                        let (tx, mut rx) = mpsc::channel(self.chunk_size);\n+                        last_finalized\n+                            .fetch_range(tx, slice.clone())\n+                            .instrument(info_span!(\"fetch\"))\n+                            .await?;\n+\n+                        let mut expected_next_height = slice.start;\n+\n+                        while let Some(message) = rx.recv().await {\n+                            expected_next_height = self\n+                                .handle_fetch_message(message, expected_next_height)\n+                                .instrument(info_span!(\"store\"))\n+                                .await?\n+                        }",
    "repo_full_name": "unionlabs/union",
    "discussion_comments": [
      {
        "comment_id": "1758153981",
        "repo_full_name": "unionlabs/union",
        "pr_number": 2944,
        "pr_file": "hubble/src/indexer/fetcher.rs",
        "discussion_id": "1758153981",
        "commented_code": "@@ -0,0 +1,212 @@\n+use std::{ops::Range, time::Duration};\n+\n+use color_eyre::eyre::Report;\n+use tokio::{\n+    sync::mpsc::{self},\n+    time::sleep,\n+};\n+use tracing::{debug, error, info, info_span, Instrument};\n+\n+use super::{\n+    api::{BlockHeight, FetchMessage, FetcherClient},\n+    Indexer,\n+};\n+use crate::indexer::{\n+    api::{BlockHandle, BlockRange, BlockReference, FetcherError},\n+    postgres::{get_current_height, update_block_status, update_current_height},\n+};\n+\n+trait Chunkeable {\n+    type T;\n+\n+    fn range_chunks(self, chunk_size: usize) -> impl Iterator<Item = Range<Self::T>>;\n+}\n+\n+impl Chunkeable for BlockRange {\n+    type T = BlockHeight;\n+\n+    fn range_chunks(\n+        self: BlockRange,\n+        chunk_size: usize,\n+    ) -> impl Iterator<Item = Range<BlockHeight>> {\n+        self.clone().step_by(chunk_size).map(move |block_start| {\n+            let block_end = (block_start + chunk_size as u64).min(self.end);\n+            block_start..block_end\n+        })\n+    }\n+}\n+\n+impl<T: FetcherClient> Indexer<T> {\n+    pub async fn run_fetcher(&self, fetcher_client: T) -> Result<(), Report> {\n+        self.run_to_finalized(&fetcher_client)\n+            .instrument(info_span!(\"run-to-finalized\"))\n+            .await?;\n+        self.run_to_tip(&fetcher_client)\n+            .instrument(info_span!(\"run-to-tip\"))\n+            .await?;\n+        Ok(())\n+    }\n+\n+    async fn run_to_finalized(&self, fetcher_client: &T) -> Result<(), Report> {\n+        // run to finalized\n+        loop {\n+            debug!(\"fetching last finalized block\");\n+            match fetcher_client.fetch(BlockReference::LastFinalized).await? {\n+                None => {\n+                    info!(\"no finalized block => start 'run to tip'\");\n+                    return Ok(());\n+                }\n+                Some(last_finalized) => {\n+                    let next_height = self.next_height().await?;\n+                    if next_height + self.chunk_size as u64 > last_finalized.height()? {\n+                        info!(\"near finalized height (current: {} finalized: {}) => start 'run to tip'\", next_height, last_finalized.height()?);\n+                        return Ok(());\n+                    }\n+\n+                    let catch_up_range: BlockRange = next_height..last_finalized.height()?;\n+                    info!(\n+                        \"missing blocks: {}..{}\",\n+                        catch_up_range.start, catch_up_range.end\n+                    );\n+\n+                    for slice in catch_up_range.range_chunks(self.chunk_size).into_iter() {\n+                        info!(\"handling chunk: {}..{}\", slice.start, slice.end);\n+\n+                        let (tx, mut rx) = mpsc::channel(self.chunk_size);\n+                        last_finalized\n+                            .fetch_range(tx, slice.clone())\n+                            .instrument(info_span!(\"fetch\"))\n+                            .await?;\n+\n+                        let mut expected_next_height = slice.start;\n+\n+                        while let Some(message) = rx.recv().await {\n+                            expected_next_height = self\n+                                .handle_fetch_message(message, expected_next_height)\n+                                .instrument(info_span!(\"store\"))\n+                                .await?\n+                        }",
        "comment_created_at": "2024-09-13T04:18:37+00:00",
        "comment_author": "KaiserKarel",
        "comment_body": "More of a style issue, but it is better to have fetch_range return a Stream vs using a channel to pass messages. That will allow you to handle messages concurrently, as well as make debugging easier (slap a .inspect on the stream).\r\n\r\nAPI would then be:\r\n\r\n```\r\nlet stream = last_finalized.fetch_range(...).instrument(...);\r\nstream.for_each(self.handle_fetch_message).await;\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "1763087399",
        "repo_full_name": "unionlabs/union",
        "pr_number": 2944,
        "pr_file": "hubble/src/indexer/fetcher.rs",
        "discussion_id": "1758153981",
        "commented_code": "@@ -0,0 +1,212 @@\n+use std::{ops::Range, time::Duration};\n+\n+use color_eyre::eyre::Report;\n+use tokio::{\n+    sync::mpsc::{self},\n+    time::sleep,\n+};\n+use tracing::{debug, error, info, info_span, Instrument};\n+\n+use super::{\n+    api::{BlockHeight, FetchMessage, FetcherClient},\n+    Indexer,\n+};\n+use crate::indexer::{\n+    api::{BlockHandle, BlockRange, BlockReference, FetcherError},\n+    postgres::{get_current_height, update_block_status, update_current_height},\n+};\n+\n+trait Chunkeable {\n+    type T;\n+\n+    fn range_chunks(self, chunk_size: usize) -> impl Iterator<Item = Range<Self::T>>;\n+}\n+\n+impl Chunkeable for BlockRange {\n+    type T = BlockHeight;\n+\n+    fn range_chunks(\n+        self: BlockRange,\n+        chunk_size: usize,\n+    ) -> impl Iterator<Item = Range<BlockHeight>> {\n+        self.clone().step_by(chunk_size).map(move |block_start| {\n+            let block_end = (block_start + chunk_size as u64).min(self.end);\n+            block_start..block_end\n+        })\n+    }\n+}\n+\n+impl<T: FetcherClient> Indexer<T> {\n+    pub async fn run_fetcher(&self, fetcher_client: T) -> Result<(), Report> {\n+        self.run_to_finalized(&fetcher_client)\n+            .instrument(info_span!(\"run-to-finalized\"))\n+            .await?;\n+        self.run_to_tip(&fetcher_client)\n+            .instrument(info_span!(\"run-to-tip\"))\n+            .await?;\n+        Ok(())\n+    }\n+\n+    async fn run_to_finalized(&self, fetcher_client: &T) -> Result<(), Report> {\n+        // run to finalized\n+        loop {\n+            debug!(\"fetching last finalized block\");\n+            match fetcher_client.fetch(BlockReference::LastFinalized).await? {\n+                None => {\n+                    info!(\"no finalized block => start 'run to tip'\");\n+                    return Ok(());\n+                }\n+                Some(last_finalized) => {\n+                    let next_height = self.next_height().await?;\n+                    if next_height + self.chunk_size as u64 > last_finalized.height()? {\n+                        info!(\"near finalized height (current: {} finalized: {}) => start 'run to tip'\", next_height, last_finalized.height()?);\n+                        return Ok(());\n+                    }\n+\n+                    let catch_up_range: BlockRange = next_height..last_finalized.height()?;\n+                    info!(\n+                        \"missing blocks: {}..{}\",\n+                        catch_up_range.start, catch_up_range.end\n+                    );\n+\n+                    for slice in catch_up_range.range_chunks(self.chunk_size).into_iter() {\n+                        info!(\"handling chunk: {}..{}\", slice.start, slice.end);\n+\n+                        let (tx, mut rx) = mpsc::channel(self.chunk_size);\n+                        last_finalized\n+                            .fetch_range(tx, slice.clone())\n+                            .instrument(info_span!(\"fetch\"))\n+                            .await?;\n+\n+                        let mut expected_next_height = slice.start;\n+\n+                        while let Some(message) = rx.recv().await {\n+                            expected_next_height = self\n+                                .handle_fetch_message(message, expected_next_height)\n+                                .instrument(info_span!(\"store\"))\n+                                .await?\n+                        }",
        "comment_created_at": "2024-09-17T11:42:38+00:00",
        "comment_author": "qlp",
        "comment_body": "done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1649697512",
    "pr_number": 2127,
    "pr_file": "sentinel/src/chains.rs",
    "created_at": "2024-06-22T13:18:23+00:00",
    "commented_code": "+use std::{collections::HashMap, str::FromStr, sync::Arc, time::Duration};\n+\n+use bech32::FromBase32;\n+use chain_utils::{\n+    cosmos_sdk::{BroadcastTxCommitError, CosmosSdkChainExt},\n+    ethereum::{EthereumExecutionRpcs, EthereumExecutionRpcsExt, IBCHandlerEvents},\n+};\n+use chrono::Utc;\n+use contracts::{\n+    erc20,\n+    ibc_packet::IBCPacketEvents,\n+    ucs01_relay::{LocalToken, UCS01Relay},\n+};\n+use ethers::{\n+    abi::RawLog,\n+    contract::EthLogDecode,\n+    core::k256::ecdsa,\n+    middleware::{NonceManagerMiddleware, SignerMiddleware},\n+    providers::{Middleware, Provider, Ws},\n+    signers::LocalWallet,\n+    types::{Address, Filter},\n+    utils::secret_key_to_address,\n+};\n+use futures::StreamExt;\n+use hex::{self, encode as hex_encode};\n+use prost::Message;\n+use protos::{google::protobuf::Any, ibc::applications::transfer::v1::MsgTransfer};\n+use rand::{rngs::StdRng, Rng, SeedableRng};\n+use serde::{Deserialize, Serialize};\n+use tendermint_rpc::{event::EventData, SubscriptionClient};\n+use ucs01_relay::msg::{ExecuteMsg, TransferMsg};\n+use ucs01_relay_api::types::{Ics20Ack, JsonWasm, Ucs01Ack};\n+use unionlabs::{\n+    cosmos::base::coin::Coin,\n+    cosmwasm::wasm::msg_execute_contract::MsgExecuteContract,\n+    encoding::{self, DecodeAs},\n+    events::{AcknowledgePacket, RecvPacket, SendPacket, WriteAcknowledgement},\n+    google::protobuf::any,\n+    hash::H160,\n+    ibc::core::{channel::channel::Channel, client::height::Height},\n+    id::{ChannelId, ClientId},\n+    tendermint::abci::{event::Event as TendermintEvent, event_attribute::EventAttribute},\n+    uint::U256,\n+    validated::ValidateT,\n+};\n+\n+use crate::{\n+    config::{CosmosConfig, EthereumConfig, TransferModule},\n+    context::SharedMap,\n+};\n+pub type IbcEvent = unionlabs::events::IbcEvent<ClientId, String, ClientId>;\n+\n+pub trait IbcTransfer: Send + Sync {\n+    async fn send_ibc_transfer(\n+        &self,\n+        protocol: Protocol,\n+        channel: ChannelId,\n+        destination_channel: ChannelId,\n+        denom: String,\n+        amount: u64,\n+        memo: String,\n+    );\n+}\n+\n+pub trait IbcListen: Send + Sync {\n+    async fn listen(&self, shared_map: &SharedMap);\n+\n+    // TODO(caglankaan): How can i know the protocol type here? On listen we don't know what is the destination chain\n+    // It can be anything, if i am listening on union since there is only one listener for union there could be 2 different\n+    // chains which are sending request to me 1- ethereum with ucs01 and 2- osmosis with ics20 so i am not sure how can i know\n+    // the protocol here. For know i'll try bruteforce but it's not a good solution.\n+    fn write_handler_packet_ack_hex_controller(\n+        &self,\n+        ack_hex: Vec<u8>, //protocol: Protocol\n+    ) -> bool {\n+        // match protocol {\n+        //     Protocol::Ics20 => {\n+        //         let val = Ics20Ack::try_from(cosmwasm_std::Binary::from(ack_hex)).unwrap();\n+        //         match val {\n+        //             Ics20Ack::Result(_) => {\n+        //                 return true;\n+        //             }\n+        //             Ics20Ack::Error(_) => {\n+        //                 return false;\n+        //             }\n+        //         }\n+        //     }\n+        //     Protocol::Ucs01 => {\n+        //         return (\n+        //             Ucs01Ack::try_from(cosmwasm_std::Binary::from(ack_hex)).unwrap() ==\n+        //             Ucs01Ack::Success\n+        //         );\n+        //     }\n+        //     _ => {\n+        //         tracing::error!(\"Unknown protocol {:?} -> {:?}\", protocol, ack_hex);\n+        //         return false;\n+        //     }\n+        // }\n+\n+        // Try to decode as Ics20Ack first;\n+        if let Ok(val) =\n+            Ics20Ack::decode_as::<JsonWasm>(cosmwasm_std::Binary::from(ack_hex.clone()).as_slice())\n+        {\n+            match val {\n+                Ics20Ack::Result(_) => {\n+                    tracing::info!(\"Ics20Ack::Result successfully decoded.\");\n+                    return true;\n+                }\n+                Ics20Ack::Error(_) => {\n+                    tracing::warn!(\"Ics20Ack::Result failed decode.\");\n+                }\n+            }\n+        }\n+\n+        if let Ok(val) = Ucs01Ack::decode_as::<encoding::EthAbi>(\n+            cosmwasm_std::Binary::from(ack_hex.clone()).as_slice(),\n+        ) {\n+            tracing::info!(\n+                \"Ucs01Ack:: successfully decoded: {}\",\n+                val == Ucs01Ack::Success\n+            );\n+            return val == Ucs01Ack::Success;\n+        } else {\n+            tracing::warn!(\"Failed to decode ack_hex: {:?}\", ack_hex);\n+            return false;\n+        }\n+    }\n+\n+    async fn handle_ibc_event(\n+        &self,\n+        ibc_event: IbcEvent,\n+        shared_map: &SharedMap,\n+        block_number: u64,\n+    );\n+\n+    fn handle_ibc_event_boxed<'a>(\n+        &'a self,\n+        ibc_event: IbcEvent,\n+        shared_map: &'a SharedMap,\n+        _block_number: u64,\n+    ) -> std::pin::Pin<Box<dyn std::future::Future<Output = ()> + Send + 'a>> {\n+        Box::pin(async move {\n+            let (packet_sequence, key) = match &ibc_event {\n+                IbcEvent::SendPacket(e) => (\n+                    e.packet_sequence,\n+                    format!(\"{}->{}\", e.packet_src_channel, e.packet_dst_channel),\n+                ),\n+                IbcEvent::RecvPacket(e) => (\n+                    e.packet_sequence,\n+                    format!(\"{}->{}\", e.packet_src_channel, e.packet_dst_channel),\n+                ),\n+                IbcEvent::WriteAcknowledgement(e) => (\n+                    e.packet_sequence,\n+                    format!(\"{}->{}\", e.packet_src_channel, e.packet_dst_channel),\n+                ),\n+                IbcEvent::AcknowledgePacket(e) => (\n+                    e.packet_sequence,\n+                    format!(\"{}->{}\", e.packet_src_channel, e.packet_dst_channel),\n+                ),\n+                // Handle other events if necessary,\n+                _ => {\n+                    return;\n+                }\n+            };\n+            tracing::info!(\"packet_sequence: {:?}, key: {:?}\", packet_sequence, key);\n+\n+            let sequence = packet_sequence.get() as i32;\n+            {\n+                let mut map = shared_map.lock().await;",
    "repo_full_name": "unionlabs/union",
    "discussion_comments": [
      {
        "comment_id": "1649697512",
        "repo_full_name": "unionlabs/union",
        "pr_number": 2127,
        "pr_file": "sentinel/src/chains.rs",
        "discussion_id": "1649697512",
        "commented_code": "@@ -0,0 +1,997 @@\n+use std::{collections::HashMap, str::FromStr, sync::Arc, time::Duration};\n+\n+use bech32::FromBase32;\n+use chain_utils::{\n+    cosmos_sdk::{BroadcastTxCommitError, CosmosSdkChainExt},\n+    ethereum::{EthereumExecutionRpcs, EthereumExecutionRpcsExt, IBCHandlerEvents},\n+};\n+use chrono::Utc;\n+use contracts::{\n+    erc20,\n+    ibc_packet::IBCPacketEvents,\n+    ucs01_relay::{LocalToken, UCS01Relay},\n+};\n+use ethers::{\n+    abi::RawLog,\n+    contract::EthLogDecode,\n+    core::k256::ecdsa,\n+    middleware::{NonceManagerMiddleware, SignerMiddleware},\n+    providers::{Middleware, Provider, Ws},\n+    signers::LocalWallet,\n+    types::{Address, Filter},\n+    utils::secret_key_to_address,\n+};\n+use futures::StreamExt;\n+use hex::{self, encode as hex_encode};\n+use prost::Message;\n+use protos::{google::protobuf::Any, ibc::applications::transfer::v1::MsgTransfer};\n+use rand::{rngs::StdRng, Rng, SeedableRng};\n+use serde::{Deserialize, Serialize};\n+use tendermint_rpc::{event::EventData, SubscriptionClient};\n+use ucs01_relay::msg::{ExecuteMsg, TransferMsg};\n+use ucs01_relay_api::types::{Ics20Ack, JsonWasm, Ucs01Ack};\n+use unionlabs::{\n+    cosmos::base::coin::Coin,\n+    cosmwasm::wasm::msg_execute_contract::MsgExecuteContract,\n+    encoding::{self, DecodeAs},\n+    events::{AcknowledgePacket, RecvPacket, SendPacket, WriteAcknowledgement},\n+    google::protobuf::any,\n+    hash::H160,\n+    ibc::core::{channel::channel::Channel, client::height::Height},\n+    id::{ChannelId, ClientId},\n+    tendermint::abci::{event::Event as TendermintEvent, event_attribute::EventAttribute},\n+    uint::U256,\n+    validated::ValidateT,\n+};\n+\n+use crate::{\n+    config::{CosmosConfig, EthereumConfig, TransferModule},\n+    context::SharedMap,\n+};\n+pub type IbcEvent = unionlabs::events::IbcEvent<ClientId, String, ClientId>;\n+\n+pub trait IbcTransfer: Send + Sync {\n+    async fn send_ibc_transfer(\n+        &self,\n+        protocol: Protocol,\n+        channel: ChannelId,\n+        destination_channel: ChannelId,\n+        denom: String,\n+        amount: u64,\n+        memo: String,\n+    );\n+}\n+\n+pub trait IbcListen: Send + Sync {\n+    async fn listen(&self, shared_map: &SharedMap);\n+\n+    // TODO(caglankaan): How can i know the protocol type here? On listen we don't know what is the destination chain\n+    // It can be anything, if i am listening on union since there is only one listener for union there could be 2 different\n+    // chains which are sending request to me 1- ethereum with ucs01 and 2- osmosis with ics20 so i am not sure how can i know\n+    // the protocol here. For know i'll try bruteforce but it's not a good solution.\n+    fn write_handler_packet_ack_hex_controller(\n+        &self,\n+        ack_hex: Vec<u8>, //protocol: Protocol\n+    ) -> bool {\n+        // match protocol {\n+        //     Protocol::Ics20 => {\n+        //         let val = Ics20Ack::try_from(cosmwasm_std::Binary::from(ack_hex)).unwrap();\n+        //         match val {\n+        //             Ics20Ack::Result(_) => {\n+        //                 return true;\n+        //             }\n+        //             Ics20Ack::Error(_) => {\n+        //                 return false;\n+        //             }\n+        //         }\n+        //     }\n+        //     Protocol::Ucs01 => {\n+        //         return (\n+        //             Ucs01Ack::try_from(cosmwasm_std::Binary::from(ack_hex)).unwrap() ==\n+        //             Ucs01Ack::Success\n+        //         );\n+        //     }\n+        //     _ => {\n+        //         tracing::error!(\"Unknown protocol {:?} -> {:?}\", protocol, ack_hex);\n+        //         return false;\n+        //     }\n+        // }\n+\n+        // Try to decode as Ics20Ack first;\n+        if let Ok(val) =\n+            Ics20Ack::decode_as::<JsonWasm>(cosmwasm_std::Binary::from(ack_hex.clone()).as_slice())\n+        {\n+            match val {\n+                Ics20Ack::Result(_) => {\n+                    tracing::info!(\"Ics20Ack::Result successfully decoded.\");\n+                    return true;\n+                }\n+                Ics20Ack::Error(_) => {\n+                    tracing::warn!(\"Ics20Ack::Result failed decode.\");\n+                }\n+            }\n+        }\n+\n+        if let Ok(val) = Ucs01Ack::decode_as::<encoding::EthAbi>(\n+            cosmwasm_std::Binary::from(ack_hex.clone()).as_slice(),\n+        ) {\n+            tracing::info!(\n+                \"Ucs01Ack:: successfully decoded: {}\",\n+                val == Ucs01Ack::Success\n+            );\n+            return val == Ucs01Ack::Success;\n+        } else {\n+            tracing::warn!(\"Failed to decode ack_hex: {:?}\", ack_hex);\n+            return false;\n+        }\n+    }\n+\n+    async fn handle_ibc_event(\n+        &self,\n+        ibc_event: IbcEvent,\n+        shared_map: &SharedMap,\n+        block_number: u64,\n+    );\n+\n+    fn handle_ibc_event_boxed<'a>(\n+        &'a self,\n+        ibc_event: IbcEvent,\n+        shared_map: &'a SharedMap,\n+        _block_number: u64,\n+    ) -> std::pin::Pin<Box<dyn std::future::Future<Output = ()> + Send + 'a>> {\n+        Box::pin(async move {\n+            let (packet_sequence, key) = match &ibc_event {\n+                IbcEvent::SendPacket(e) => (\n+                    e.packet_sequence,\n+                    format!(\"{}->{}\", e.packet_src_channel, e.packet_dst_channel),\n+                ),\n+                IbcEvent::RecvPacket(e) => (\n+                    e.packet_sequence,\n+                    format!(\"{}->{}\", e.packet_src_channel, e.packet_dst_channel),\n+                ),\n+                IbcEvent::WriteAcknowledgement(e) => (\n+                    e.packet_sequence,\n+                    format!(\"{}->{}\", e.packet_src_channel, e.packet_dst_channel),\n+                ),\n+                IbcEvent::AcknowledgePacket(e) => (\n+                    e.packet_sequence,\n+                    format!(\"{}->{}\", e.packet_src_channel, e.packet_dst_channel),\n+                ),\n+                // Handle other events if necessary,\n+                _ => {\n+                    return;\n+                }\n+            };\n+            tracing::info!(\"packet_sequence: {:?}, key: {:?}\", packet_sequence, key);\n+\n+            let sequence = packet_sequence.get() as i32;\n+            {\n+                let mut map = shared_map.lock().await;",
        "comment_created_at": "2024-06-22T13:18:23+00:00",
        "comment_author": "benluelo",
        "comment_body": "unless you hold this lock across an await point, you should use the std locks or the ones from [`parking_lot`](https://docs.rs/parking_lot/latest/parking_lot/)",
        "pr_file_module": null
      }
    ]
  }
]