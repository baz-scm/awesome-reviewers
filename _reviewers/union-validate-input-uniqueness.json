[
  {
    "discussion_id": "2140527824",
    "pr_number": 4681,
    "pr_file": "cosmwasm/ibc-union/lightclient/parlia/src/client.rs",
    "created_at": "2025-06-11T15:46:09+00:00",
    "commented_code": "}\n \n     fn misbehaviour(\n-        _ctx: IbcClientCtx<Self>,\n+        ctx: IbcClientCtx<Self>,\n         _caller: Addr,\n-        _misbehaviour: Self::Misbehaviour,\n+        misbehaviour: Self::Misbehaviour,\n         _relayer: Addr,\n     ) -> Result<Self::ClientState, IbcClientError<Self>> {\n-        Err(Error::Unimplemented.into())\n+        let ClientState::V1(client_state) = ctx.read_self_client_state()?;\n+\n+        if misbehaviour.attestation_1.number != misbehaviour.attestation_2.number {",
    "repo_full_name": "unionlabs/union",
    "discussion_comments": [
      {
        "comment_id": "2140527824",
        "repo_full_name": "unionlabs/union",
        "pr_number": 4681,
        "pr_file": "cosmwasm/ibc-union/lightclient/parlia/src/client.rs",
        "discussion_id": "2140527824",
        "commented_code": "@@ -168,22 +182,64 @@ impl IbcClient for ParliaLightClient {\n     }\n \n     fn misbehaviour(\n-        _ctx: IbcClientCtx<Self>,\n+        ctx: IbcClientCtx<Self>,\n         _caller: Addr,\n-        _misbehaviour: Self::Misbehaviour,\n+        misbehaviour: Self::Misbehaviour,\n         _relayer: Addr,\n     ) -> Result<Self::ClientState, IbcClientError<Self>> {\n-        Err(Error::Unimplemented.into())\n+        let ClientState::V1(client_state) = ctx.read_self_client_state()?;\n+\n+        if misbehaviour.attestation_1.number != misbehaviour.attestation_2.number {",
        "comment_created_at": "2025-06-11T15:46:09+00:00",
        "comment_author": "aeryz",
        "comment_body": "we must check whether the attestation or target whatever is not the same thing. otherwise one can provide a valid misbehaviour by giving the same data twice.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2135596095",
    "pr_number": 4669,
    "pr_file": "lib/parlia-verifier/src/lib.rs",
    "created_at": "2025-06-09T12:03:34+00:00",
    "commented_code": "+#![feature(array_chunks)]\n+\n+use std::ops::{Mul, Sub};\n+\n+use parlia_types::{ParliaHeader, Valset, VoteAttestation};\n+use unionlabs_primitives::{ByteArrayExt, H160, H384, H768, U256};\n+\n+// post-maxwell\n+// const TURN_LENGTH: u64 = 16;\n+// const EPOCH_LENGTH: u64 = 1000;\n+\n+// pre-maxwell\n+pub const TURN_LENGTH: u64 = 8;\n+pub const EPOCH_LENGTH: u64 = 500;\n+\n+pub const EXTRA_SEAL_LEN: usize = 65;\n+pub const EXTRA_VANITY_LEN: usize = 32;\n+// const NEXT_FORK_HASH_SIZE: usize = 4;\n+pub const NEXT_TURN_LENGTH_SIZE: usize = 1;\n+pub const VAL_COUNT_SIZE: usize = 1;\n+\n+pub const VAL_ENTRY_LEN: usize = <H160>::BYTES_LEN + <H384>::BYTES_LEN;\n+\n+pub const EXTRA_DATA_MIN_LEN: usize = EXTRA_VANITY_LEN + EXTRA_SEAL_LEN;\n+\n+#[derive(Debug, Clone, thiserror::Error)]\n+pub enum ExtraDataDecodeError {\n+    #[error(\"invalid extra data len\")]\n+    InvalidExtraDataLen,\n+    #[error(\"invalid turn length (found {0}, expected {TURN_LENGTH})\")]\n+    InvalidTurnLength(u64),\n+    #[error(\"not enough validators present in extra data\")]\n+    NotEnoughVals,\n+    #[error(transparent)]\n+    Rlp(#[from] rlp::DecoderError),\n+}\n+\n+pub fn parse_epoch_rotation_header_extra_data(\n+    data: &[u8],\n+) -> Result<(VoteAttestation, Valset), ExtraDataDecodeError> {\n+    if data.len() <= EXTRA_DATA_MIN_LEN {\n+        return Err(ExtraDataDecodeError::InvalidExtraDataLen);\n+    }\n+\n+    let data = &data[EXTRA_VANITY_LEN..(data.len() - EXTRA_SEAL_LEN)];\n+\n+    let num = data[0];\n+    let vals = data[1..]\n+        .array_chunks::<VAL_ENTRY_LEN>()\n+        .map(|x| {\n+            (\n+                x.array_slice::<0, 20>().into(),\n+                x.array_slice::<20, 48>().into(),\n+            )\n+        })\n+        .take(num.into())\n+        .collect::<Vec<_>>();\n+\n+    if vals.len() != num as usize {\n+        return Err(ExtraDataDecodeError::NotEnoughVals);\n+    }\n+\n+    let turn_length = data[VAL_COUNT_SIZE + (VAL_ENTRY_LEN * num as usize)];\n+    if turn_length as u64 != TURN_LENGTH {\n+        return Err(ExtraDataDecodeError::InvalidTurnLength(turn_length as u64));\n+    }\n+\n+    let va = rlp::decode::<VoteAttestation>(\n+        &data[(VAL_COUNT_SIZE + (VAL_ENTRY_LEN * num as usize) + NEXT_TURN_LENGTH_SIZE)..],\n+    )?;\n+\n+    Ok((va, Valset::new(vals)))\n+}\n+\n+pub fn parse_header_extra_data(data: &[u8]) -> Result<VoteAttestation, ExtraDataDecodeError> {\n+    if data.len() <= EXTRA_DATA_MIN_LEN {\n+        return Err(ExtraDataDecodeError::InvalidExtraDataLen);\n+    }\n+\n+    let data = &data[EXTRA_VANITY_LEN..(data.len() - EXTRA_SEAL_LEN)];\n+\n+    let va = rlp::decode::<VoteAttestation>(data)?;\n+\n+    Ok(va)\n+}\n+\n+pub fn get_vote_attestation_from_header_extra_data(\n+    header: &ParliaHeader,\n+) -> Result<VoteAttestation, ExtraDataDecodeError> {\n+    if is_epoch_rotation_header(header) {\n+        parse_epoch_rotation_header_extra_data(&header.extra_data).map(|x| x.0)\n+    } else {\n+        parse_header_extra_data(&header.extra_data)\n+    }\n+}\n+\n+pub fn is_epoch_rotation_header(header: &ParliaHeader) -> bool {\n+    header.number % U256::from(EPOCH_LENGTH) == U256::ZERO\n+}\n+\n+pub fn calculate_signing_valset_epoch_block_number(h: u64, valset_size: u64) -> u64 {\n+    h.sub(TURN_LENGTH.mul(valset_size.div_ceil(2)))\n+        .sub(EPOCH_LENGTH)\n+        .div_ceil(EPOCH_LENGTH)\n+        .mul(EPOCH_LENGTH)\n+}\n+\n+#[derive(Debug, Clone, thiserror::Error)]\n+pub enum Error<E> {\n+    #[error(\"invalid attestation chain\")]\n+    InvalidAttestationChain,\n+    #[error(transparent)]\n+    ExtraDataDecode(#[from] ExtraDataDecodeError),\n+    #[error(transparent)]\n+    ContextError(E),\n+    #[error(\"trusted valset not found for block {0}\")]\n+    TrustedValsetNotFound(u64),\n+    #[error(\"less than 2/3+1 of the valset signed the attestation\")]\n+    InsufficientParticipation,\n+    #[error(\"block number > u64::MAX\")]\n+    BlockNumberTooLarge,\n+    #[error(\n+        \"provided {expected} as the expected trusted valset block number, \\\n+        but the attestation was signed by the valset at block {found}\"\n+    )]\n+    InvalidTrustedValsetEpochBlockNumber { expected: u64, found: u64 },\n+    #[error(\"the valset is not sorted\")]\n+    ValsetNotSorted,\n+}\n+\n+pub trait VerificationContext {\n+    type Error: std::error::Error;\n+\n+    fn get_valset(&self, epoch_block_number: u64) -> Result<Valset, Self::Error>;\n+\n+    fn verify<'pk>(\n+        &self,\n+        public_keys: impl IntoIterator<Item = &'pk H384>,\n+        msg: &[u8],\n+        signature: H768,\n+    ) -> Result<(), Self::Error>;\n+}\n+\n+/// Given 3 headers: source `S`, target `T`, and attestation `A`, where `A` contains the vote data for `S` and `T`:\n+/// 1. verify that `S \u2208 T \u2208 A`\n+/// 2. validate the signature contained in `A` with the valset that signed it\n+/// 3. if `S` is an epoch change block, return the epoch change block number and the new valset\n+pub fn verify_header<C: VerificationContext>(\n+    source: &ParliaHeader,\n+    target: &ParliaHeader,\n+    attestation: &ParliaHeader,\n+    trusted_valset_epoch_block_number: u64,\n+    ctx: C,\n+) -> Result<Option<(u64, Valset)>, Error<C::Error>> {\n+    // 1.\n+    if source.number + U256::ONE != target.number || target.number + U256::ONE != attestation.number\n+    {\n+        return Err(Error::InvalidAttestationChain);\n+    }\n+\n+    if target.parent_hash != source.hash() || attestation.parent_hash != target.hash() {\n+        return Err(Error::InvalidAttestationChain);\n+    }\n+\n+    let vote_attestation = get_vote_attestation_from_header_extra_data(attestation)?;\n+\n+    let trusted_valset = ctx\n+        .get_valset(trusted_valset_epoch_block_number)\n+        .map_err(Error::ContextError)?;\n+\n+    let epoch_block_number = calculate_signing_valset_epoch_block_number(\n+        attestation\n+            .number\n+            .try_into()\n+            .map_err(|()| Error::BlockNumberTooLarge)?,\n+        trusted_valset.len().try_into().unwrap(),\n+    );\n+\n+    if trusted_valset_epoch_block_number != epoch_block_number {\n+        return Err(Error::InvalidTrustedValsetEpochBlockNumber {\n+            expected: trusted_valset_epoch_block_number,\n+            found: epoch_block_number,\n+        });\n+    }\n+\n+    if vote_attestation.vote_address_set.count() as usize <= (trusted_valset.len() * 2) / 3 {\n+        return Err(Error::InsufficientParticipation);\n+    }\n+\n+    let signing_valset = trusted_valset\n+        .iter()\n+        .enumerate()\n+        .filter(|(idx, _)| vote_attestation.vote_address_set.is_set(*idx));\n+\n+    if !signing_valset.clone().is_sorted_by(|a, b| a.1 < b.1) {\n+        return Err(Error::ValsetNotSorted);\n+    }\n+\n+    // 2.\n+    ctx.verify(\n+        signing_valset.map(|x| &x.1 .1),\n+        vote_attestation.data.hash().get(),",
    "repo_full_name": "unionlabs/union",
    "discussion_comments": [
      {
        "comment_id": "2135596095",
        "repo_full_name": "unionlabs/union",
        "pr_number": 4669,
        "pr_file": "lib/parlia-verifier/src/lib.rs",
        "discussion_id": "2135596095",
        "commented_code": "@@ -0,0 +1,519 @@\n+#![feature(array_chunks)]\n+\n+use std::ops::{Mul, Sub};\n+\n+use parlia_types::{ParliaHeader, Valset, VoteAttestation};\n+use unionlabs_primitives::{ByteArrayExt, H160, H384, H768, U256};\n+\n+// post-maxwell\n+// const TURN_LENGTH: u64 = 16;\n+// const EPOCH_LENGTH: u64 = 1000;\n+\n+// pre-maxwell\n+pub const TURN_LENGTH: u64 = 8;\n+pub const EPOCH_LENGTH: u64 = 500;\n+\n+pub const EXTRA_SEAL_LEN: usize = 65;\n+pub const EXTRA_VANITY_LEN: usize = 32;\n+// const NEXT_FORK_HASH_SIZE: usize = 4;\n+pub const NEXT_TURN_LENGTH_SIZE: usize = 1;\n+pub const VAL_COUNT_SIZE: usize = 1;\n+\n+pub const VAL_ENTRY_LEN: usize = <H160>::BYTES_LEN + <H384>::BYTES_LEN;\n+\n+pub const EXTRA_DATA_MIN_LEN: usize = EXTRA_VANITY_LEN + EXTRA_SEAL_LEN;\n+\n+#[derive(Debug, Clone, thiserror::Error)]\n+pub enum ExtraDataDecodeError {\n+    #[error(\"invalid extra data len\")]\n+    InvalidExtraDataLen,\n+    #[error(\"invalid turn length (found {0}, expected {TURN_LENGTH})\")]\n+    InvalidTurnLength(u64),\n+    #[error(\"not enough validators present in extra data\")]\n+    NotEnoughVals,\n+    #[error(transparent)]\n+    Rlp(#[from] rlp::DecoderError),\n+}\n+\n+pub fn parse_epoch_rotation_header_extra_data(\n+    data: &[u8],\n+) -> Result<(VoteAttestation, Valset), ExtraDataDecodeError> {\n+    if data.len() <= EXTRA_DATA_MIN_LEN {\n+        return Err(ExtraDataDecodeError::InvalidExtraDataLen);\n+    }\n+\n+    let data = &data[EXTRA_VANITY_LEN..(data.len() - EXTRA_SEAL_LEN)];\n+\n+    let num = data[0];\n+    let vals = data[1..]\n+        .array_chunks::<VAL_ENTRY_LEN>()\n+        .map(|x| {\n+            (\n+                x.array_slice::<0, 20>().into(),\n+                x.array_slice::<20, 48>().into(),\n+            )\n+        })\n+        .take(num.into())\n+        .collect::<Vec<_>>();\n+\n+    if vals.len() != num as usize {\n+        return Err(ExtraDataDecodeError::NotEnoughVals);\n+    }\n+\n+    let turn_length = data[VAL_COUNT_SIZE + (VAL_ENTRY_LEN * num as usize)];\n+    if turn_length as u64 != TURN_LENGTH {\n+        return Err(ExtraDataDecodeError::InvalidTurnLength(turn_length as u64));\n+    }\n+\n+    let va = rlp::decode::<VoteAttestation>(\n+        &data[(VAL_COUNT_SIZE + (VAL_ENTRY_LEN * num as usize) + NEXT_TURN_LENGTH_SIZE)..],\n+    )?;\n+\n+    Ok((va, Valset::new(vals)))\n+}\n+\n+pub fn parse_header_extra_data(data: &[u8]) -> Result<VoteAttestation, ExtraDataDecodeError> {\n+    if data.len() <= EXTRA_DATA_MIN_LEN {\n+        return Err(ExtraDataDecodeError::InvalidExtraDataLen);\n+    }\n+\n+    let data = &data[EXTRA_VANITY_LEN..(data.len() - EXTRA_SEAL_LEN)];\n+\n+    let va = rlp::decode::<VoteAttestation>(data)?;\n+\n+    Ok(va)\n+}\n+\n+pub fn get_vote_attestation_from_header_extra_data(\n+    header: &ParliaHeader,\n+) -> Result<VoteAttestation, ExtraDataDecodeError> {\n+    if is_epoch_rotation_header(header) {\n+        parse_epoch_rotation_header_extra_data(&header.extra_data).map(|x| x.0)\n+    } else {\n+        parse_header_extra_data(&header.extra_data)\n+    }\n+}\n+\n+pub fn is_epoch_rotation_header(header: &ParliaHeader) -> bool {\n+    header.number % U256::from(EPOCH_LENGTH) == U256::ZERO\n+}\n+\n+pub fn calculate_signing_valset_epoch_block_number(h: u64, valset_size: u64) -> u64 {\n+    h.sub(TURN_LENGTH.mul(valset_size.div_ceil(2)))\n+        .sub(EPOCH_LENGTH)\n+        .div_ceil(EPOCH_LENGTH)\n+        .mul(EPOCH_LENGTH)\n+}\n+\n+#[derive(Debug, Clone, thiserror::Error)]\n+pub enum Error<E> {\n+    #[error(\"invalid attestation chain\")]\n+    InvalidAttestationChain,\n+    #[error(transparent)]\n+    ExtraDataDecode(#[from] ExtraDataDecodeError),\n+    #[error(transparent)]\n+    ContextError(E),\n+    #[error(\"trusted valset not found for block {0}\")]\n+    TrustedValsetNotFound(u64),\n+    #[error(\"less than 2/3+1 of the valset signed the attestation\")]\n+    InsufficientParticipation,\n+    #[error(\"block number > u64::MAX\")]\n+    BlockNumberTooLarge,\n+    #[error(\n+        \"provided {expected} as the expected trusted valset block number, \\\n+        but the attestation was signed by the valset at block {found}\"\n+    )]\n+    InvalidTrustedValsetEpochBlockNumber { expected: u64, found: u64 },\n+    #[error(\"the valset is not sorted\")]\n+    ValsetNotSorted,\n+}\n+\n+pub trait VerificationContext {\n+    type Error: std::error::Error;\n+\n+    fn get_valset(&self, epoch_block_number: u64) -> Result<Valset, Self::Error>;\n+\n+    fn verify<'pk>(\n+        &self,\n+        public_keys: impl IntoIterator<Item = &'pk H384>,\n+        msg: &[u8],\n+        signature: H768,\n+    ) -> Result<(), Self::Error>;\n+}\n+\n+/// Given 3 headers: source `S`, target `T`, and attestation `A`, where `A` contains the vote data for `S` and `T`:\n+/// 1. verify that `S \u2208 T \u2208 A`\n+/// 2. validate the signature contained in `A` with the valset that signed it\n+/// 3. if `S` is an epoch change block, return the epoch change block number and the new valset\n+pub fn verify_header<C: VerificationContext>(\n+    source: &ParliaHeader,\n+    target: &ParliaHeader,\n+    attestation: &ParliaHeader,\n+    trusted_valset_epoch_block_number: u64,\n+    ctx: C,\n+) -> Result<Option<(u64, Valset)>, Error<C::Error>> {\n+    // 1.\n+    if source.number + U256::ONE != target.number || target.number + U256::ONE != attestation.number\n+    {\n+        return Err(Error::InvalidAttestationChain);\n+    }\n+\n+    if target.parent_hash != source.hash() || attestation.parent_hash != target.hash() {\n+        return Err(Error::InvalidAttestationChain);\n+    }\n+\n+    let vote_attestation = get_vote_attestation_from_header_extra_data(attestation)?;\n+\n+    let trusted_valset = ctx\n+        .get_valset(trusted_valset_epoch_block_number)\n+        .map_err(Error::ContextError)?;\n+\n+    let epoch_block_number = calculate_signing_valset_epoch_block_number(\n+        attestation\n+            .number\n+            .try_into()\n+            .map_err(|()| Error::BlockNumberTooLarge)?,\n+        trusted_valset.len().try_into().unwrap(),\n+    );\n+\n+    if trusted_valset_epoch_block_number != epoch_block_number {\n+        return Err(Error::InvalidTrustedValsetEpochBlockNumber {\n+            expected: trusted_valset_epoch_block_number,\n+            found: epoch_block_number,\n+        });\n+    }\n+\n+    if vote_attestation.vote_address_set.count() as usize <= (trusted_valset.len() * 2) / 3 {\n+        return Err(Error::InsufficientParticipation);\n+    }\n+\n+    let signing_valset = trusted_valset\n+        .iter()\n+        .enumerate()\n+        .filter(|(idx, _)| vote_attestation.vote_address_set.is_set(*idx));\n+\n+    if !signing_valset.clone().is_sorted_by(|a, b| a.1 < b.1) {\n+        return Err(Error::ValsetNotSorted);\n+    }\n+\n+    // 2.\n+    ctx.verify(\n+        signing_valset.map(|x| &x.1 .1),\n+        vote_attestation.data.hash().get(),",
        "comment_created_at": "2025-06-09T12:03:34+00:00",
        "comment_author": "aeryz",
        "comment_body": "can we make sure that we are verifying `block.hash() == vote_attestation.data.source_hash`?",
        "pr_file_module": null
      }
    ]
  }
]