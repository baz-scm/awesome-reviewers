[
  {
    "discussion_id": "2029393032",
    "pr_number": 12676,
    "pr_file": "docs/concepts/cache.md",
    "created_at": "2025-04-04T20:22:26+00:00",
    "commented_code": "integration job to ensure maximum cache efficiency. For an example, see the\n [GitHub integration guide](../guides/integration/github.md#caching).\n \n+## Sharing caching with multiple (parallel running) containers\n+\n+UV supports using the same cache between multiple processes on the same machine but this also might\n+work between different containers running on the same machine.\n+\n+This is especially useful in CI systems when you run - in parallel - multiple, containers running\n+your CI tests where you want to tun `uv sync` as part of your CI tests. In such case you can share\n+the cache between the containers to speed up the installation of dependencies and limit network\n+traffic and load on the registry you are using.\n+\n+In order to do it, the folder where the cache is stored must be mounted to the ~/.cache/uv directory",
    "repo_full_name": "astral-sh/uv",
    "discussion_comments": [
      {
        "comment_id": "2029393032",
        "repo_full_name": "astral-sh/uv",
        "pr_number": 12676,
        "pr_file": "docs/concepts/cache.md",
        "discussion_id": "2029393032",
        "commented_code": "@@ -156,6 +156,19 @@ built from source. We recommend running `uv cache prune --ci` at the end of your\n integration job to ensure maximum cache efficiency. For an example, see the\n [GitHub integration guide](../guides/integration/github.md#caching).\n \n+## Sharing caching with multiple (parallel running) containers\n+\n+UV supports using the same cache between multiple processes on the same machine but this also might\n+work between different containers running on the same machine.\n+\n+This is especially useful in CI systems when you run - in parallel - multiple, containers running\n+your CI tests where you want to tun `uv sync` as part of your CI tests. In such case you can share\n+the cache between the containers to speed up the installation of dependencies and limit network\n+traffic and load on the registry you are using.\n+\n+In order to do it, the folder where the cache is stored must be mounted to the ~/.cache/uv directory",
        "comment_created_at": "2025-04-04T20:22:26+00:00",
        "comment_author": "jscheffl",
        "comment_body": "```suggestion\r\nIn order to do it, the folder where the cache is stored must be mounted to the `~/.cache/uv` directory\r\n```",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2047222993",
    "pr_number": 12676,
    "pr_file": "docs/concepts/cache.md",
    "created_at": "2025-04-16T15:45:07+00:00",
    "commented_code": "integration job to ensure maximum cache efficiency. For an example, see the\n [GitHub integration guide](../guides/integration/github.md#caching).\n \n+## Sharing caching with multiple (parallel running) containers\n+\n+UV supports using the same cache between multiple processes on the same machine but this also might\n+work between different containers running on the same machine.\n+\n+This is especially useful in CI systems when you run - in parallel - multiple, containers running\n+your CI tests where you want to run `uv sync` as part of your CI tests. In such case you can share\n+the cache between the containers to speed up the installation of dependencies and limit network\n+traffic and load on the registry you are using.",
    "repo_full_name": "astral-sh/uv",
    "discussion_comments": [
      {
        "comment_id": "2047222993",
        "repo_full_name": "astral-sh/uv",
        "pr_number": 12676,
        "pr_file": "docs/concepts/cache.md",
        "discussion_id": "2047222993",
        "commented_code": "@@ -156,6 +156,19 @@ built from source. We recommend running `uv cache prune --ci` at the end of your\n integration job to ensure maximum cache efficiency. For an example, see the\n [GitHub integration guide](../guides/integration/github.md#caching).\n \n+## Sharing caching with multiple (parallel running) containers\n+\n+UV supports using the same cache between multiple processes on the same machine but this also might\n+work between different containers running on the same machine.\n+\n+This is especially useful in CI systems when you run - in parallel - multiple, containers running\n+your CI tests where you want to run `uv sync` as part of your CI tests. In such case you can share\n+the cache between the containers to speed up the installation of dependencies and limit network\n+traffic and load on the registry you are using.",
        "comment_created_at": "2025-04-16T15:45:07+00:00",
        "comment_author": "zanieb",
        "comment_body": "Is the parallel part particularly important here? Isn't it helpful that the cache is shared regardless of concurrency?",
        "pr_file_module": null
      },
      {
        "comment_id": "2160415817",
        "repo_full_name": "astral-sh/uv",
        "pr_number": 12676,
        "pr_file": "docs/concepts/cache.md",
        "discussion_id": "2047222993",
        "commented_code": "@@ -156,6 +156,19 @@ built from source. We recommend running `uv cache prune --ci` at the end of your\n integration job to ensure maximum cache efficiency. For an example, see the\n [GitHub integration guide](../guides/integration/github.md#caching).\n \n+## Sharing caching with multiple (parallel running) containers\n+\n+UV supports using the same cache between multiple processes on the same machine but this also might\n+work between different containers running on the same machine.\n+\n+This is especially useful in CI systems when you run - in parallel - multiple, containers running\n+your CI tests where you want to run `uv sync` as part of your CI tests. In such case you can share\n+the cache between the containers to speed up the installation of dependencies and limit network\n+traffic and load on the registry you are using.",
        "comment_created_at": "2025-06-22T17:46:44+00:00",
        "comment_author": "potiuk",
        "comment_body": "I think it's not obvious that you can do it for parallel docker containers but yes I think it makes sense to mention that until your machine is run the cache will also be used when running containers sequentially.\r\n\r\nI reworded it a bit and in the \"docker,md\" I split caching strategy into two cases:\r\n\r\n1) when you run containers locally or on long running VMs -> better to use cache mount in this case\r\n2) when you run containers on CI (there it makes more sense to use mounted volume when you run parallel or sequential builds ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2063219595",
    "pr_number": 13163,
    "pr_file": "docs/guides/integration/github.md",
    "created_at": "2025-04-28T08:55:21+00:00",
    "commented_code": "```yaml title=\"example.yml\"\n - name: Define a cache dependency glob\n-  uses: astral-sh/setup-uv@v5\n+  uses: astral-sh/setup-uv@v6\n   with:\n     enable-cache: true\n     cache-dependency-glob: \"uv.lock\"",
    "repo_full_name": "astral-sh/uv",
    "discussion_comments": [
      {
        "comment_id": "2063219595",
        "repo_full_name": "astral-sh/uv",
        "pr_number": 13163,
        "pr_file": "docs/guides/integration/github.md",
        "discussion_id": "2063219595",
        "commented_code": "@@ -231,7 +231,7 @@ Or invalidate it when the lockfile changes:\n \n ```yaml title=\"example.yml\"\n - name: Define a cache dependency glob\n-  uses: astral-sh/setup-uv@v5\n+  uses: astral-sh/setup-uv@v6\n   with:\n     enable-cache: true\n     cache-dependency-glob: \"uv.lock\"",
        "comment_created_at": "2025-04-28T08:55:21+00:00",
        "comment_author": "konstin",
        "comment_body": "CC @eifinger is this still a good example?",
        "pr_file_module": null
      },
      {
        "comment_id": "2063244551",
        "repo_full_name": "astral-sh/uv",
        "pr_number": 13163,
        "pr_file": "docs/guides/integration/github.md",
        "discussion_id": "2063219595",
        "commented_code": "@@ -231,7 +231,7 @@ Or invalidate it when the lockfile changes:\n \n ```yaml title=\"example.yml\"\n - name: Define a cache dependency glob\n-  uses: astral-sh/setup-uv@v5\n+  uses: astral-sh/setup-uv@v6\n   with:\n     enable-cache: true\n     cache-dependency-glob: \"uv.lock\"",
        "comment_created_at": "2025-04-28T09:08:21+00:00",
        "comment_author": "eifinger",
        "comment_body": "Mh while this still works and might be a valid usecase in an exotic usecase (make sure ONLY the lock file invalidates the cache) I think it would be better if we remove examples involving `cache-dependency-glob`.\r\n\r\nThe new default should be sufficient for most users and I don't think examples should contain edge cases most users will never need to think about.\r\n\r\nFor those edge cases the README in `setup-uv` still contains the information",
        "pr_file_module": null
      },
      {
        "comment_id": "2063336614",
        "repo_full_name": "astral-sh/uv",
        "pr_number": 13163,
        "pr_file": "docs/guides/integration/github.md",
        "discussion_id": "2063219595",
        "commented_code": "@@ -231,7 +231,7 @@ Or invalidate it when the lockfile changes:\n \n ```yaml title=\"example.yml\"\n - name: Define a cache dependency glob\n-  uses: astral-sh/setup-uv@v5\n+  uses: astral-sh/setup-uv@v6\n   with:\n     enable-cache: true\n     cache-dependency-glob: \"uv.lock\"",
        "comment_created_at": "2025-04-28T10:01:11+00:00",
        "comment_author": "konstin",
        "comment_body": "Do you want to make a PR updating the docs? You know the intended configuration better than me.",
        "pr_file_module": null
      },
      {
        "comment_id": "2063362200",
        "repo_full_name": "astral-sh/uv",
        "pr_number": 13163,
        "pr_file": "docs/guides/integration/github.md",
        "discussion_id": "2063219595",
        "commented_code": "@@ -231,7 +231,7 @@ Or invalidate it when the lockfile changes:\n \n ```yaml title=\"example.yml\"\n - name: Define a cache dependency glob\n-  uses: astral-sh/setup-uv@v5\n+  uses: astral-sh/setup-uv@v6\n   with:\n     enable-cache: true\n     cache-dependency-glob: \"uv.lock\"",
        "comment_created_at": "2025-04-28T10:18:15+00:00",
        "comment_author": "eifinger",
        "comment_body": "Sure, I will put it on my todo list 👍 ",
        "pr_file_module": null
      }
    ]
  }
]