[
  {
    "discussion_id": "2100745290",
    "pr_number": 18281,
    "pr_file": "go/vt/vttablet/tabletserver/gc/tablegc.go",
    "created_at": "2025-05-21T16:43:37+00:00",
    "commented_code": "return nil\n \t}\n \n+\t// Reinitialize the pool if it was closed\n+\tif collector.pool == nil {\n+\t\t// Pass empty name so that metrics are not re-registered.\n+\t\tcollector.pool = newPool(collector.env, \"\")\n+\t}\n+",
    "repo_full_name": "vitessio/vitess",
    "discussion_comments": [
      {
        "comment_id": "2100745290",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 18281,
        "pr_file": "go/vt/vttablet/tabletserver/gc/tablegc.go",
        "discussion_id": "2100745290",
        "commented_code": "@@ -176,6 +173,12 @@ func (collector *TableGC) Open() (err error) {\n \t\treturn nil\n \t}\n \n+\t// Reinitialize the pool if it was closed\n+\tif collector.pool == nil {\n+\t\t// Pass empty name so that metrics are not re-registered.\n+\t\tcollector.pool = newPool(collector.env, \"\")\n+\t}\n+",
        "comment_created_at": "2025-05-21T16:43:37+00:00",
        "comment_author": "deepthi",
        "comment_body": "Will we still get metrics recorded correctly?",
        "pr_file_module": null
      },
      {
        "comment_id": "2100786142",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 18281,
        "pr_file": "go/vt/vttablet/tabletserver/gc/tablegc.go",
        "discussion_id": "2100745290",
        "commented_code": "@@ -176,6 +173,12 @@ func (collector *TableGC) Open() (err error) {\n \t\treturn nil\n \t}\n \n+\t// Reinitialize the pool if it was closed\n+\tif collector.pool == nil {\n+\t\t// Pass empty name so that metrics are not re-registered.\n+\t\tcollector.pool = newPool(collector.env, \"\")\n+\t}\n+",
        "comment_created_at": "2025-05-21T17:07:18+00:00",
        "comment_author": "mhamza15",
        "comment_body": "At first I had thought so, but on a second glance, this new instance will not have the timings set up properly. Was getting this error when reinitializing the pool:\r\n\r\n```\r\npanic: Reuse of exported var name: TableGCPoolGetConnTime\r\n```\r\n\r\nWill come up with a different way.",
        "pr_file_module": null
      },
      {
        "comment_id": "2100827475",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 18281,
        "pr_file": "go/vt/vttablet/tabletserver/gc/tablegc.go",
        "discussion_id": "2100745290",
        "commented_code": "@@ -176,6 +173,12 @@ func (collector *TableGC) Open() (err error) {\n \t\treturn nil\n \t}\n \n+\t// Reinitialize the pool if it was closed\n+\tif collector.pool == nil {\n+\t\t// Pass empty name so that metrics are not re-registered.\n+\t\tcollector.pool = newPool(collector.env, \"\")\n+\t}\n+",
        "comment_created_at": "2025-05-21T17:33:17+00:00",
        "comment_author": "mhamza15",
        "comment_body": "Changed. The `expvar` package in Go doesn't allow deleting a registered var, so I instead chose to skip re-registering an already registered var.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1970573906",
    "pr_number": 17858,
    "pr_file": "go/vt/vtgate/vstream_manager.go",
    "created_at": "2025-02-25T21:32:48+00:00",
    "commented_code": "vstreamsCreated: exporter.NewCountersWithMultiLabels(\n \t\t\t\"VStreamsCreated\",\n \t\t\t\"Number of vstreams created\",\n-\t\t\t[]string{\"Keyspace\", \"ShardName\", \"TabletType\"}),\n+\t\t\t[]string{\"Keyspace\", \"ShardName\", \"TabletType\", \"TabletHostname\"}),",
    "repo_full_name": "vitessio/vitess",
    "discussion_comments": [
      {
        "comment_id": "1970573906",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 17858,
        "pr_file": "go/vt/vtgate/vstream_manager.go",
        "discussion_id": "1970573906",
        "commented_code": "@@ -151,10 +154,22 @@ func newVStreamManager(resolver *srvtopo.Resolver, serv srvtopo.Server, cell str\n \t\tvstreamsCreated: exporter.NewCountersWithMultiLabels(\n \t\t\t\"VStreamsCreated\",\n \t\t\t\"Number of vstreams created\",\n-\t\t\t[]string{\"Keyspace\", \"ShardName\", \"TabletType\"}),\n+\t\t\t[]string{\"Keyspace\", \"ShardName\", \"TabletType\", \"TabletHostname\"}),",
        "comment_created_at": "2025-02-25T21:32:48+00:00",
        "comment_author": "mattlord",
        "comment_body": "I don't think that we should include the hostname. 1) it changes across the lifespan of a vtgate vstream (we retry for the shard in vstream manager on tablet stream errors) 2) in many deployment envs it's not really helpful 3) it can explode the size of the metric over time as e.g. in k8s deployments, which are the norm today for Vitess, you regularly roll the tablet pods. IMO this kind of context is better used in log messages if we want it. I'm not dead set against it though, so I'm open to discussion.",
        "pr_file_module": null
      },
      {
        "comment_id": "1972108171",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 17858,
        "pr_file": "go/vt/vtgate/vstream_manager.go",
        "discussion_id": "1970573906",
        "commented_code": "@@ -151,10 +154,22 @@ func newVStreamManager(resolver *srvtopo.Resolver, serv srvtopo.Server, cell str\n \t\tvstreamsCreated: exporter.NewCountersWithMultiLabels(\n \t\t\t\"VStreamsCreated\",\n \t\t\t\"Number of vstreams created\",\n-\t\t\t[]string{\"Keyspace\", \"ShardName\", \"TabletType\"}),\n+\t\t\t[]string{\"Keyspace\", \"ShardName\", \"TabletType\", \"TabletHostname\"}),",
        "comment_created_at": "2025-02-26T18:10:00+00:00",
        "comment_author": "twthorn",
        "comment_body": "Updated",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1970597338",
    "pr_number": 17858,
    "pr_file": "go/vt/vtgate/vstream_manager.go",
    "created_at": "2025-02-25T21:54:19+00:00",
    "commented_code": "vs.wg.Add(1)\n \tgo func() {\n \t\tdefer vs.wg.Done()\n+\n+\t\tlabels := []string{sgtid.Keyspace, sgtid.Shard, vs.tabletType.String()}\n+\t\tvs.vsm.vstreamsEndedWithErrors.Add(labels, 0)",
    "repo_full_name": "vitessio/vitess",
    "discussion_comments": [
      {
        "comment_id": "1970597338",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 17858,
        "pr_file": "go/vt/vtgate/vstream_manager.go",
        "discussion_id": "1970597338",
        "commented_code": "@@ -378,11 +393,17 @@ func (vs *vstream) startOneStream(ctx context.Context, sgtid *binlogdatapb.Shard\n \tvs.wg.Add(1)\n \tgo func() {\n \t\tdefer vs.wg.Done()\n+\n+\t\tlabels := []string{sgtid.Keyspace, sgtid.Shard, vs.tabletType.String()}\n+\t\tvs.vsm.vstreamsEndedWithErrors.Add(labels, 0)",
        "comment_created_at": "2025-02-25T21:54:19+00:00",
        "comment_author": "mattlord",
        "comment_body": "I had assumed that this was a count of vtgate vstreams rather than tablet streams. Is this really supposed to be a count of tablet streams (one per shard, per vtgate vstream)?",
        "pr_file_module": null
      },
      {
        "comment_id": "1971938916",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 17858,
        "pr_file": "go/vt/vtgate/vstream_manager.go",
        "discussion_id": "1970597338",
        "commented_code": "@@ -378,11 +393,17 @@ func (vs *vstream) startOneStream(ctx context.Context, sgtid *binlogdatapb.Shard\n \tvs.wg.Add(1)\n \tgo func() {\n \t\tdefer vs.wg.Done()\n+\n+\t\tlabels := []string{sgtid.Keyspace, sgtid.Shard, vs.tabletType.String()}\n+\t\tvs.vsm.vstreamsEndedWithErrors.Add(labels, 0)",
        "comment_created_at": "2025-02-26T16:30:53+00:00",
        "comment_author": "twthorn",
        "comment_body": "I believe the most useful for observability is to have per shard per vtgate stream. For example, with the lag metric, if the vstream has multiple shards, we cannot accurately report lag (do we do the max, min, avg, etc.). \r\n\r\nI believe the same is true\r\n1. errors -  it saves operator the time to find in a log which stream has error\r\n2. active streams - if the vtgate is operating slow the vstream count is not enough granularity if those vstreams have hundreds of shards, we want to know how many shards this vtgate is handling\r\n3. events streamed - help operator detect which shard has disproportionately high load\r\n\r\nI agree per tablet is maybe too granular, but per-shard would be very useful. I am going to update PR based on this",
        "pr_file_module": null
      },
      {
        "comment_id": "1973731386",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 17858,
        "pr_file": "go/vt/vtgate/vstream_manager.go",
        "discussion_id": "1970597338",
        "commented_code": "@@ -378,11 +393,17 @@ func (vs *vstream) startOneStream(ctx context.Context, sgtid *binlogdatapb.Shard\n \tvs.wg.Add(1)\n \tgo func() {\n \t\tdefer vs.wg.Done()\n+\n+\t\tlabels := []string{sgtid.Keyspace, sgtid.Shard, vs.tabletType.String()}\n+\t\tvs.vsm.vstreamsEndedWithErrors.Add(labels, 0)",
        "comment_created_at": "2025-02-27T14:48:51+00:00",
        "comment_author": "mattlord",
        "comment_body": "OK, makes sense. Thanks!",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1973808406",
    "pr_number": 17858,
    "pr_file": "go/vt/vtgate/vstream_manager.go",
    "created_at": "2025-02-27T15:19:42+00:00",
    "commented_code": "vs.wg.Add(1)\n \tgo func() {\n \t\tdefer vs.wg.Done()\n+\n+\t\tlabelValues := []string{sgtid.Keyspace, sgtid.Shard, vs.tabletType.String()}\n+\t\tvs.vsm.vstreamsEndedWithErrors.Add(labelValues, 0)",
    "repo_full_name": "vitessio/vitess",
    "discussion_comments": [
      {
        "comment_id": "1973808406",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 17858,
        "pr_file": "go/vt/vtgate/vstream_manager.go",
        "discussion_id": "1973808406",
        "commented_code": "@@ -378,11 +394,19 @@ func (vs *vstream) startOneStream(ctx context.Context, sgtid *binlogdatapb.Shard\n \tvs.wg.Add(1)\n \tgo func() {\n \t\tdefer vs.wg.Done()\n+\n+\t\tlabelValues := []string{sgtid.Keyspace, sgtid.Shard, vs.tabletType.String()}\n+\t\tvs.vsm.vstreamsEndedWithErrors.Add(labelValues, 0)",
        "comment_created_at": "2025-02-27T15:19:42+00:00",
        "comment_author": "mattlord",
        "comment_body": "I don't see any value in adding 0. Am I missing something?",
        "pr_file_module": null
      },
      {
        "comment_id": "1974127646",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 17858,
        "pr_file": "go/vt/vtgate/vstream_manager.go",
        "discussion_id": "1973808406",
        "commented_code": "@@ -378,11 +394,19 @@ func (vs *vstream) startOneStream(ctx context.Context, sgtid *binlogdatapb.Shard\n \tvs.wg.Add(1)\n \tgo func() {\n \t\tdefer vs.wg.Done()\n+\n+\t\tlabelValues := []string{sgtid.Keyspace, sgtid.Shard, vs.tabletType.String()}\n+\t\tvs.vsm.vstreamsEndedWithErrors.Add(labelValues, 0)",
        "comment_created_at": "2025-02-27T18:26:18+00:00",
        "comment_author": "twthorn",
        "comment_body": "This is to initialize the counter to zero for this keyspace/shard/tablet type. This is a [best practice](https://prometheus.io/docs/practices/instrumentation/#avoid-missing-metrics). Metrics are hard to work with if they only sometimes exist. This is also seen in the unit test for metrics that we can't assert that there were zero errors for a vstream that worked fine (the metric is simply missing)",
        "pr_file_module": null
      },
      {
        "comment_id": "1974146140",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 17858,
        "pr_file": "go/vt/vtgate/vstream_manager.go",
        "discussion_id": "1973808406",
        "commented_code": "@@ -378,11 +394,19 @@ func (vs *vstream) startOneStream(ctx context.Context, sgtid *binlogdatapb.Shard\n \tvs.wg.Add(1)\n \tgo func() {\n \t\tdefer vs.wg.Done()\n+\n+\t\tlabelValues := []string{sgtid.Keyspace, sgtid.Shard, vs.tabletType.String()}\n+\t\tvs.vsm.vstreamsEndedWithErrors.Add(labelValues, 0)",
        "comment_created_at": "2025-02-27T18:37:02+00:00",
        "comment_author": "twthorn",
        "comment_body": "I changed to Reset to hopefully make it more clear, as Add zero does appear to be not useful",
        "pr_file_module": null
      },
      {
        "comment_id": "1974165648",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 17858,
        "pr_file": "go/vt/vtgate/vstream_manager.go",
        "discussion_id": "1973808406",
        "commented_code": "@@ -378,11 +394,19 @@ func (vs *vstream) startOneStream(ctx context.Context, sgtid *binlogdatapb.Shard\n \tvs.wg.Add(1)\n \tgo func() {\n \t\tdefer vs.wg.Done()\n+\n+\t\tlabelValues := []string{sgtid.Keyspace, sgtid.Shard, vs.tabletType.String()}\n+\t\tvs.vsm.vstreamsEndedWithErrors.Add(labelValues, 0)",
        "comment_created_at": "2025-02-27T18:52:18+00:00",
        "comment_author": "mattlord",
        "comment_body": "Is Reset what you really want? It's a counter and not a gauge. I assumed that it was meant to be a counter that spanned the life of the vtgate as the description is `\"Number of vstreams that ended with errors\"`. ",
        "pr_file_module": null
      },
      {
        "comment_id": "1974188631",
        "repo_full_name": "vitessio/vitess",
        "pr_number": 17858,
        "pr_file": "go/vt/vtgate/vstream_manager.go",
        "discussion_id": "1973808406",
        "commented_code": "@@ -378,11 +394,19 @@ func (vs *vstream) startOneStream(ctx context.Context, sgtid *binlogdatapb.Shard\n \tvs.wg.Add(1)\n \tgo func() {\n \t\tdefer vs.wg.Done()\n+\n+\t\tlabelValues := []string{sgtid.Keyspace, sgtid.Shard, vs.tabletType.String()}\n+\t\tvs.vsm.vstreamsEndedWithErrors.Add(labelValues, 0)",
        "comment_created_at": "2025-02-27T19:09:20+00:00",
        "comment_author": "twthorn",
        "comment_body": "Ah yes good point, this could be called multiple times. So we will just keep with Add zero.",
        "pr_file_module": null
      }
    ]
  }
]