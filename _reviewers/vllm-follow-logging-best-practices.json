[
  {
    "discussion_id": "2145741574",
    "pr_number": 19619,
    "pr_file": "vllm/engine/arg_utils.py",
    "created_at": "2025-06-13T18:14:36+00:00",
    "commented_code": "override_attention_dtype=self.override_attention_dtype,\n         )\n \n+    def no_valid_tensorizer_args_in_model_loader_extra_config(self) -> bool:\n+\n+        if self.model_loader_extra_config:\n+            for allowed_to_pass in [\"tensorizer_uri\", \"tensorizer_dir\"]:\n+                try:\n+                    logger.info(\"Got %s\", self.model_loader_extra_config)",
    "repo_full_name": "vllm-project/vllm",
    "discussion_comments": [
      {
        "comment_id": "2145856528",
        "repo_full_name": "vllm-project/vllm",
        "pr_number": 19619,
        "pr_file": "vllm/engine/arg_utils.py",
        "discussion_id": "2145741574",
        "commented_code": "@@ -952,11 +953,33 @@ def create_model_config(self) -> ModelConfig:\n             override_attention_dtype=self.override_attention_dtype,\n         )\n \n+    def no_valid_tensorizer_args_in_model_loader_extra_config(self) -> bool:\n+\n+        if self.model_loader_extra_config:\n+            for allowed_to_pass in [\"tensorizer_uri\", \"tensorizer_dir\"]:\n+                try:\n+                    logger.info(\"Got %s\", self.model_loader_extra_config)",
        "comment_created_at": "2025-06-13T18:40:22+00:00",
        "comment_author": "sangstar",
        "comment_body": "Irrelevant here; this is looping over 2 values.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2190455590",
    "pr_number": 20570,
    "pr_file": "vllm/transformers_utils/configs/mistral.py",
    "created_at": "2025-07-07T15:48:31+00:00",
    "commented_code": "+# SPDX-License-Identifier: Apache-2.0\n+# SPDX-FileCopyrightText: Copyright contributors to the vLLM project\n+from typing import Any\n+\n+from transformers import PretrainedConfig\n+\n+from vllm.logger import init_logger\n+\n+logger = init_logger(__name__)\n+\n+\n+def adapt_config_dict(config_dict: dict[str, Any],\n+                      **kwargs) -> PretrainedConfig:\n+    config_dict.update(kwargs)\n+\n+    is_quant = bool(config_dict.get(\"quantization\"))\n+    is_vision = bool(\n+        (config_dict.get(\"multimodal\") or {}).get(\"vision_encoder_args\")\n+        or config_dict.get(\"vision_encoder\"))\n+    is_moe = bool(config_dict.get(\"moe\"))\n+    is_yarn = bool(config_dict.get(\"yarn\"))\n+\n+    config_dict = _remap_general_mistral_args(config_dict)\n+    if is_quant:\n+        config_dict = _remap_mistral_quantization_args(config_dict)\n+\n+    if is_moe:\n+        config_dict[\"architectures\"] = [\"MixtralForCausalLM\"]\n+    else:\n+        config_dict[\"architectures\"] = [\"MistralForCausalLM\"]\n+\n+    if is_yarn:\n+        config_dict = _remap_mistral_yarn_args(config_dict)\n+    if is_vision:\n+        config_dict = _remap_mistral_vision_args(config_dict)\n+\n+    config = PretrainedConfig.from_dict(config_dict)\n+\n+    logger.info(\"Initialized config\", config)",
    "repo_full_name": "vllm-project/vllm",
    "discussion_comments": [
      {
        "comment_id": "2190455590",
        "repo_full_name": "vllm-project/vllm",
        "pr_number": 20570,
        "pr_file": "vllm/transformers_utils/configs/mistral.py",
        "discussion_id": "2190455590",
        "commented_code": "@@ -0,0 +1,132 @@\n+# SPDX-License-Identifier: Apache-2.0\n+# SPDX-FileCopyrightText: Copyright contributors to the vLLM project\n+from typing import Any\n+\n+from transformers import PretrainedConfig\n+\n+from vllm.logger import init_logger\n+\n+logger = init_logger(__name__)\n+\n+\n+def adapt_config_dict(config_dict: dict[str, Any],\n+                      **kwargs) -> PretrainedConfig:\n+    config_dict.update(kwargs)\n+\n+    is_quant = bool(config_dict.get(\"quantization\"))\n+    is_vision = bool(\n+        (config_dict.get(\"multimodal\") or {}).get(\"vision_encoder_args\")\n+        or config_dict.get(\"vision_encoder\"))\n+    is_moe = bool(config_dict.get(\"moe\"))\n+    is_yarn = bool(config_dict.get(\"yarn\"))\n+\n+    config_dict = _remap_general_mistral_args(config_dict)\n+    if is_quant:\n+        config_dict = _remap_mistral_quantization_args(config_dict)\n+\n+    if is_moe:\n+        config_dict[\"architectures\"] = [\"MixtralForCausalLM\"]\n+    else:\n+        config_dict[\"architectures\"] = [\"MistralForCausalLM\"]\n+\n+    if is_yarn:\n+        config_dict = _remap_mistral_yarn_args(config_dict)\n+    if is_vision:\n+        config_dict = _remap_mistral_vision_args(config_dict)\n+\n+    config = PretrainedConfig.from_dict(config_dict)\n+\n+    logger.info(\"Initialized config\", config)",
        "comment_created_at": "2025-07-07T15:48:31+00:00",
        "comment_author": "ywang96",
        "comment_body": "Can we change this it `debug`? We're trying to improve startup log noise and I'm a bit concerned that printing out this entire `PretrainedConfig` might be too much. WDYT?",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2167724211",
    "pr_number": 18293,
    "pr_file": "vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py",
    "created_at": "2025-06-25T22:09:03+00:00",
    "commented_code": "self.tp_rank)\n \n             # Register with NIXL.\n-            descs = self.nixl_wrapper.get_xfer_descs(blocks_data, \"VRAM\")\n+            descs = self.nixl_wrapper.get_xfer_descs(blocks_data,\n+                                                     self.nixl_memory_type)\n             self.dst_xfer_side_handles[\n                 engine_id] = self.nixl_wrapper.prep_xfer_dlist(\n                     remote_agent_name, descs)\n \n         return remote_agent_name\n \n+    def sync_recved_kv_to_device(self,\n+                                 req_id: str,\n+                                 meta: Optional[ReqMeta] = None):\n+        \"\"\"copy recved kv from host buffer to device.\"\"\"\n+        if not self.use_host_buffer:\n+            return\n+        assert self.copy_blocks is not None\n+\n+        if meta is None:\n+            meta = self._recving_metadata.get(req_id)\n+        if meta and req_id not in self._recving_transfers:\n+            # local decode only\n+            if not meta.do_remote_prefill:\n+                return\n+            local_block_ids = meta.local_block_ids\n+            self.copy_blocks(self.host_xfer_buffers, self.device_kv_caches,\n+                             local_block_ids, local_block_ids, \"h2d\")\n+            logger.debug(\n+                \"synced recved kv of request[%s] to device kv buffer,\"\n+                \"local_block_ids: %s. \", req_id,\n+                \",\".join(map(str, meta.local_block_ids)))",
    "repo_full_name": "vllm-project/vllm",
    "discussion_comments": [
      {
        "comment_id": "2167724211",
        "repo_full_name": "vllm-project/vllm",
        "pr_number": 18293,
        "pr_file": "vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py",
        "discussion_id": "2167724211",
        "commented_code": "@@ -766,13 +952,56 @@ def add_remote_agent(self,\n                 self.tp_rank)\n \n             # Register with NIXL.\n-            descs = self.nixl_wrapper.get_xfer_descs(blocks_data, \"VRAM\")\n+            descs = self.nixl_wrapper.get_xfer_descs(blocks_data,\n+                                                     self.nixl_memory_type)\n             self.dst_xfer_side_handles[\n                 engine_id] = self.nixl_wrapper.prep_xfer_dlist(\n                     remote_agent_name, descs)\n \n         return remote_agent_name\n \n+    def sync_recved_kv_to_device(self,\n+                                 req_id: str,\n+                                 meta: Optional[ReqMeta] = None):\n+        \"\"\"copy recved kv from host buffer to device.\"\"\"\n+        if not self.use_host_buffer:\n+            return\n+        assert self.copy_blocks is not None\n+\n+        if meta is None:\n+            meta = self._recving_metadata.get(req_id)\n+        if meta and req_id not in self._recving_transfers:\n+            # local decode only\n+            if not meta.do_remote_prefill:\n+                return\n+            local_block_ids = meta.local_block_ids\n+            self.copy_blocks(self.host_xfer_buffers, self.device_kv_caches,\n+                             local_block_ids, local_block_ids, \"h2d\")\n+            logger.debug(\n+                \"synced recved kv of request[%s] to device kv buffer,\"\n+                \"local_block_ids: %s. \", req_id,\n+                \",\".join(map(str, meta.local_block_ids)))",
        "comment_created_at": "2025-06-25T22:09:03+00:00",
        "comment_author": "njhill",
        "comment_body": "Best to guard these with `if logger.isEnabledFor(logging.DEBUG):` to avoid nontrivial parameter computation",
        "pr_file_module": null
      },
      {
        "comment_id": "2169527773",
        "repo_full_name": "vllm-project/vllm",
        "pr_number": 18293,
        "pr_file": "vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py",
        "discussion_id": "2167724211",
        "commented_code": "@@ -766,13 +952,56 @@ def add_remote_agent(self,\n                 self.tp_rank)\n \n             # Register with NIXL.\n-            descs = self.nixl_wrapper.get_xfer_descs(blocks_data, \"VRAM\")\n+            descs = self.nixl_wrapper.get_xfer_descs(blocks_data,\n+                                                     self.nixl_memory_type)\n             self.dst_xfer_side_handles[\n                 engine_id] = self.nixl_wrapper.prep_xfer_dlist(\n                     remote_agent_name, descs)\n \n         return remote_agent_name\n \n+    def sync_recved_kv_to_device(self,\n+                                 req_id: str,\n+                                 meta: Optional[ReqMeta] = None):\n+        \"\"\"copy recved kv from host buffer to device.\"\"\"\n+        if not self.use_host_buffer:\n+            return\n+        assert self.copy_blocks is not None\n+\n+        if meta is None:\n+            meta = self._recving_metadata.get(req_id)\n+        if meta and req_id not in self._recving_transfers:\n+            # local decode only\n+            if not meta.do_remote_prefill:\n+                return\n+            local_block_ids = meta.local_block_ids\n+            self.copy_blocks(self.host_xfer_buffers, self.device_kv_caches,\n+                             local_block_ids, local_block_ids, \"h2d\")\n+            logger.debug(\n+                \"synced recved kv of request[%s] to device kv buffer,\"\n+                \"local_block_ids: %s. \", req_id,\n+                \",\".join(map(str, meta.local_block_ids)))",
        "comment_created_at": "2025-06-26T17:14:30+00:00",
        "comment_author": "juncgu",
        "comment_body": "updated.",
        "pr_file_module": null
      }
    ]
  }
]