[
  {
    "discussion_id": "2161349796",
    "pr_number": 4345,
    "pr_file": "pkg/scheduler/plugins/network-topology-aware/network_topology_aware.go",
    "created_at": "2025-06-23T11:12:46+00:00",
    "commented_code": "nodeScores := make(map[string]float64)\n \n \t\ttaskJob := ssn.Jobs[task.Job]\n-\t\thardMode, _ := taskJob.IsHardTopologyMode()\n-\t\tif hardMode {\n+\t\tif !taskJob.IsTopologyMode() {",
    "repo_full_name": "volcano-sh/volcano",
    "discussion_comments": [
      {
        "comment_id": "2161349796",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 4345,
        "pr_file": "pkg/scheduler/plugins/network-topology-aware/network_topology_aware.go",
        "discussion_id": "2161349796",
        "commented_code": "@@ -122,8 +122,7 @@ func (nta *networkTopologyAwarePlugin) OnSessionOpen(ssn *framework.Session) {\n \t\tnodeScores := make(map[string]float64)\n \n \t\ttaskJob := ssn.Jobs[task.Job]\n-\t\thardMode, _ := taskJob.IsHardTopologyMode()\n-\t\tif hardMode {\n+\t\tif !taskJob.IsTopologyMode() {",
        "comment_created_at": "2025-06-23T11:12:46+00:00",
        "comment_author": "JesseStutler",
        "comment_body": "After thinking about it, the judgement added here was to prevent scoring twice in hard mode, but after your modification, now hard mode will scoring twice( About hardnode tier and task nums). I also discuss with @Monokaix, we think we can remove scoring logic about hardnode tier and task nums, only keep hypernode resource usage judgement in the future: https://github.com/volcano-sh/volcano/issues/4368. What do you think?",
        "pr_file_module": null
      },
      {
        "comment_id": "2162832182",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 4345,
        "pr_file": "pkg/scheduler/plugins/network-topology-aware/network_topology_aware.go",
        "discussion_id": "2161349796",
        "commented_code": "@@ -122,8 +122,7 @@ func (nta *networkTopologyAwarePlugin) OnSessionOpen(ssn *framework.Session) {\n \t\tnodeScores := make(map[string]float64)\n \n \t\ttaskJob := ssn.Jobs[task.Job]\n-\t\thardMode, _ := taskJob.IsHardTopologyMode()\n-\t\tif hardMode {\n+\t\tif !taskJob.IsTopologyMode() {",
        "comment_created_at": "2025-06-24T02:18:22+00:00",
        "comment_author": "kingeasternsun",
        "comment_body": "\r\nI believe the problem addressed by the current PR is distinct from the one outlined in [**issue #4368**](https://github.com/volcano-sh/volcano/issues/4368).\r\n\r\nThis PR prioritizes **performance**, aiming to concentrate a job's pods onto the fewest possible HyperNodes to enhance communication efficiency. In contrast, issue [#4368](https://github.com/volcano-sh/volcano/issues/4368) focuses on **utilization**, seeking to fill fragmented resources so that subsequent large-scale tasks have contiguous HyperNodes available for scheduling. Clearly, these two objectives are fundamentally different and often conflicting.\r\n\r\nTo my knowledge, Ascend's topology-aware scheduler plugin categorizes tasks into two types: **FillJobs**, which have lower communication performance requirements and follow a fragment-filling logic similar to issue [#4368](https://github.com/volcano-sh/volcano/issues/4368), and **high-performance Job**, which adhere to the logic implemented in the current PR.",
        "pr_file_module": null
      },
      {
        "comment_id": "2163911663",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 4345,
        "pr_file": "pkg/scheduler/plugins/network-topology-aware/network_topology_aware.go",
        "discussion_id": "2161349796",
        "commented_code": "@@ -122,8 +122,7 @@ func (nta *networkTopologyAwarePlugin) OnSessionOpen(ssn *framework.Session) {\n \t\tnodeScores := make(map[string]float64)\n \n \t\ttaskJob := ssn.Jobs[task.Job]\n-\t\thardMode, _ := taskJob.IsHardTopologyMode()\n-\t\tif hardMode {\n+\t\tif !taskJob.IsTopologyMode() {",
        "comment_created_at": "2025-06-24T12:48:35+00:00",
        "comment_author": "JesseStutler",
        "comment_body": "No, I don't mean you're conflicting with #4368. I know this is two different scenarios. What I mean is that after turning off the hard mode validation here in the node scoring, both hypernode and node have the same scoring logic in hard mode (for the number of tasks in tier and hypernode), so there's no need to score the same logic twice. You can remove the scoring logic for tier and tasknum from the hypernode scoring",
        "pr_file_module": null
      },
      {
        "comment_id": "2166210121",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 4345,
        "pr_file": "pkg/scheduler/plugins/network-topology-aware/network_topology_aware.go",
        "discussion_id": "2161349796",
        "commented_code": "@@ -122,8 +122,7 @@ func (nta *networkTopologyAwarePlugin) OnSessionOpen(ssn *framework.Session) {\n \t\tnodeScores := make(map[string]float64)\n \n \t\ttaskJob := ssn.Jobs[task.Job]\n-\t\thardMode, _ := taskJob.IsHardTopologyMode()\n-\t\tif hardMode {\n+\t\tif !taskJob.IsTopologyMode() {",
        "comment_created_at": "2025-06-25T09:04:00+00:00",
        "comment_author": "kingeasternsun",
        "comment_body": "> No, I don't mean you're conflicting with #4368. I know this is two different scenarios. What I mean is that after turning off the hard mode validation here in the node scoring, both hypernode and node have the same scoring logic in hard mode (for the number of tasks in tier and hypernode), so there's no need to score the same logic twice. You can remove the scoring logic for tier and tasknum from the hypernode scoring\r\n\r\nOK\uff0c got it.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2250788733",
    "pr_number": 4508,
    "pr_file": "pkg/scheduler/plugins/util/nodelock/nodelock.go",
    "created_at": "2025-08-04T08:30:22+00:00",
    "commented_code": "}\n \tif time.Since(lockTime) > time.Minute*5 {\n \t\tklog.V(3).InfoS(\"Node lock expired\", \"node\", nodeName, \"lockTime\", lockTime)\n-\t\terr = ReleaseNodeLock(nodeName, lockName)",
    "repo_full_name": "volcano-sh/volcano",
    "discussion_comments": [
      {
        "comment_id": "2250788733",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 4508,
        "pr_file": "pkg/scheduler/plugins/util/nodelock/nodelock.go",
        "discussion_id": "2250788733",
        "commented_code": "@@ -145,11 +126,6 @@ func LockNode(nodeName string, lockName string) error {\n \t}\n \tif time.Since(lockTime) > time.Minute*5 {\n \t\tklog.V(3).InfoS(\"Node lock expired\", \"node\", nodeName, \"lockTime\", lockTime)\n-\t\terr = ReleaseNodeLock(nodeName, lockName)",
        "comment_created_at": "2025-08-04T08:30:22+00:00",
        "comment_author": "Monokaix",
        "comment_body": "Why remove this?",
        "pr_file_module": null
      },
      {
        "comment_id": "2251293316",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 4508,
        "pr_file": "pkg/scheduler/plugins/util/nodelock/nodelock.go",
        "discussion_id": "2250788733",
        "commented_code": "@@ -145,11 +126,6 @@ func LockNode(nodeName string, lockName string) error {\n \t}\n \tif time.Since(lockTime) > time.Minute*5 {\n \t\tklog.V(3).InfoS(\"Node lock expired\", \"node\", nodeName, \"lockTime\", lockTime)\n-\t\terr = ReleaseNodeLock(nodeName, lockName)",
        "comment_created_at": "2025-08-04T12:12:31+00:00",
        "comment_author": "wangao1236",
        "comment_body": "Even if we don\u2019t remove this line, new annotations will be set later, overwriting the old one. So why can\u2019t we directly update the Annotation to reduce one node update operation? \r\n\u200b\u200b\u200b\u200bIn large-scale clusters, shouldn't we minimize node update operations as much as possible to reduce cluster pressure?\u200b @Monokaix \r\n\r\n",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1988736903",
    "pr_number": 3894,
    "pr_file": "pkg/scheduler/plugins/networktopologyaware/networktopologyaware.go",
    "created_at": "2025-03-11T09:01:23+00:00",
    "commented_code": "+/*\n+Copyright 2019 The Volcano Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+*/\n+\n+package networktopologyaware\n+\n+import (\n+\t\"k8s.io/klog/v2\"\n+\n+\t\"volcano.sh/volcano/pkg/scheduler/api\"\n+\t\"volcano.sh/volcano/pkg/scheduler/framework\"\n+\t\"volcano.sh/volcano/pkg/scheduler/util\"\n+)\n+\n+const (\n+\t// PluginName indicates name of volcano scheduler plugin.\n+\tPluginName            = \"networktopologyaware\"\n+\tBaseScore             = 100.0\n+\tZeroScore             = 0.0\n+\tNetworkTopologyWeight = \"weight\"\n+)\n+\n+type networkTopologyAwarePlugin struct {\n+\t// Arguments given for the plugin\n+\tpluginArguments     framework.Arguments\n+\thyperNodeTierWeight int\n+\ttaskNumWeight       int\n+\t*hyperNodesTier\n+}\n+\n+type hyperNodesTier struct {\n+\tmaxTier int\n+\tminTier int\n+}\n+\n+func (h *hyperNodesTier) init(hyperNodesSetByTier []int) {\n+\tif len(hyperNodesSetByTier) == 0 {\n+\t\treturn\n+\t}\n+\th.minTier = hyperNodesSetByTier[0]\n+\th.maxTier = hyperNodesSetByTier[len(hyperNodesSetByTier)-1]\n+}\n+\n+// New function returns prioritizePlugin object\n+func New(arguments framework.Arguments) framework.Plugin {\n+\treturn &networkTopologyAwarePlugin{\n+\t\tpluginArguments:     arguments,\n+\t\thyperNodesTier:      &hyperNodesTier{},\n+\t\thyperNodeTierWeight: calculateWeight(arguments),\n+\t\ttaskNumWeight:       calculateWeight(arguments),",
    "repo_full_name": "volcano-sh/volcano",
    "discussion_comments": [
      {
        "comment_id": "1988736903",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3894,
        "pr_file": "pkg/scheduler/plugins/networktopologyaware/networktopologyaware.go",
        "discussion_id": "1988736903",
        "commented_code": "@@ -0,0 +1,224 @@\n+/*\n+Copyright 2019 The Volcano Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+*/\n+\n+package networktopologyaware\n+\n+import (\n+\t\"k8s.io/klog/v2\"\n+\n+\t\"volcano.sh/volcano/pkg/scheduler/api\"\n+\t\"volcano.sh/volcano/pkg/scheduler/framework\"\n+\t\"volcano.sh/volcano/pkg/scheduler/util\"\n+)\n+\n+const (\n+\t// PluginName indicates name of volcano scheduler plugin.\n+\tPluginName            = \"networktopologyaware\"\n+\tBaseScore             = 100.0\n+\tZeroScore             = 0.0\n+\tNetworkTopologyWeight = \"weight\"\n+)\n+\n+type networkTopologyAwarePlugin struct {\n+\t// Arguments given for the plugin\n+\tpluginArguments     framework.Arguments\n+\thyperNodeTierWeight int\n+\ttaskNumWeight       int\n+\t*hyperNodesTier\n+}\n+\n+type hyperNodesTier struct {\n+\tmaxTier int\n+\tminTier int\n+}\n+\n+func (h *hyperNodesTier) init(hyperNodesSetByTier []int) {\n+\tif len(hyperNodesSetByTier) == 0 {\n+\t\treturn\n+\t}\n+\th.minTier = hyperNodesSetByTier[0]\n+\th.maxTier = hyperNodesSetByTier[len(hyperNodesSetByTier)-1]\n+}\n+\n+// New function returns prioritizePlugin object\n+func New(arguments framework.Arguments) framework.Plugin {\n+\treturn &networkTopologyAwarePlugin{\n+\t\tpluginArguments:     arguments,\n+\t\thyperNodesTier:      &hyperNodesTier{},\n+\t\thyperNodeTierWeight: calculateWeight(arguments),\n+\t\ttaskNumWeight:       calculateWeight(arguments),",
        "comment_created_at": "2025-03-11T09:01:23+00:00",
        "comment_author": "Monokaix",
        "comment_body": "call `calculateWeight` once is enough.",
        "pr_file_module": null
      },
      {
        "comment_id": "1990451039",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3894,
        "pr_file": "pkg/scheduler/plugins/networktopologyaware/networktopologyaware.go",
        "discussion_id": "1988736903",
        "commented_code": "@@ -0,0 +1,224 @@\n+/*\n+Copyright 2019 The Volcano Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+*/\n+\n+package networktopologyaware\n+\n+import (\n+\t\"k8s.io/klog/v2\"\n+\n+\t\"volcano.sh/volcano/pkg/scheduler/api\"\n+\t\"volcano.sh/volcano/pkg/scheduler/framework\"\n+\t\"volcano.sh/volcano/pkg/scheduler/util\"\n+)\n+\n+const (\n+\t// PluginName indicates name of volcano scheduler plugin.\n+\tPluginName            = \"networktopologyaware\"\n+\tBaseScore             = 100.0\n+\tZeroScore             = 0.0\n+\tNetworkTopologyWeight = \"weight\"\n+)\n+\n+type networkTopologyAwarePlugin struct {\n+\t// Arguments given for the plugin\n+\tpluginArguments     framework.Arguments\n+\thyperNodeTierWeight int\n+\ttaskNumWeight       int\n+\t*hyperNodesTier\n+}\n+\n+type hyperNodesTier struct {\n+\tmaxTier int\n+\tminTier int\n+}\n+\n+func (h *hyperNodesTier) init(hyperNodesSetByTier []int) {\n+\tif len(hyperNodesSetByTier) == 0 {\n+\t\treturn\n+\t}\n+\th.minTier = hyperNodesSetByTier[0]\n+\th.maxTier = hyperNodesSetByTier[len(hyperNodesSetByTier)-1]\n+}\n+\n+// New function returns prioritizePlugin object\n+func New(arguments framework.Arguments) framework.Plugin {\n+\treturn &networkTopologyAwarePlugin{\n+\t\tpluginArguments:     arguments,\n+\t\thyperNodesTier:      &hyperNodesTier{},\n+\t\thyperNodeTierWeight: calculateWeight(arguments),\n+\t\ttaskNumWeight:       calculateWeight(arguments),",
        "comment_created_at": "2025-03-12T02:45:39+00:00",
        "comment_author": "ecosysbin",
        "comment_body": "Ok, Done",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1875964177",
    "pr_number": 3865,
    "pr_file": "pkg/scheduler/cache/cache.go",
    "created_at": "2024-12-09T13:15:09+00:00",
    "commented_code": "return nil, err\n \t}\n \n-\tupdated, err := su.vcclient.SchedulingV1beta1().PodGroups(podgroup.Namespace).Update(context.TODO(), podgroup, metav1.UpdateOptions{})",
    "repo_full_name": "volcano-sh/volcano",
    "discussion_comments": [
      {
        "comment_id": "1875964177",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3865,
        "pr_file": "pkg/scheduler/cache/cache.go",
        "discussion_id": "1875964177",
        "commented_code": "@@ -300,7 +301,22 @@ func (su *defaultStatusUpdater) UpdatePodGroup(pg *schedulingapi.PodGroup) (*sch\n \t\treturn nil, err\n \t}\n \n-\tupdated, err := su.vcclient.SchedulingV1beta1().PodGroups(podgroup.Namespace).Update(context.TODO(), podgroup, metav1.UpdateOptions{})",
        "comment_created_at": "2024-12-09T13:15:09+00:00",
        "comment_author": "hwdef",
        "comment_body": "I'm not sure if this modification is correct. I remember that this function will also update the annotation and label, so it is wrong to only update the status.",
        "pr_file_module": null
      },
      {
        "comment_id": "1876133971",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3865,
        "pr_file": "pkg/scheduler/cache/cache.go",
        "discussion_id": "1875964177",
        "commented_code": "@@ -300,7 +301,22 @@ func (su *defaultStatusUpdater) UpdatePodGroup(pg *schedulingapi.PodGroup) (*sch\n \t\treturn nil, err\n \t}\n \n-\tupdated, err := su.vcclient.SchedulingV1beta1().PodGroups(podgroup.Namespace).Update(context.TODO(), podgroup, metav1.UpdateOptions{})",
        "comment_created_at": "2024-12-09T15:01:19+00:00",
        "comment_author": "jxs1211",
        "comment_body": "> we may rewrite the logic , not to persist these nums fields in podgroups, like this pr: https://github.com/volcano-sh/volcano/pull/3751\r\n\r\nI think the proposal is want to not update the status fields in podgroups, do you mean the annotation and labels still need to be updated?",
        "pr_file_module": null
      },
      {
        "comment_id": "1880383093",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3865,
        "pr_file": "pkg/scheduler/cache/cache.go",
        "discussion_id": "1875964177",
        "commented_code": "@@ -300,7 +301,22 @@ func (su *defaultStatusUpdater) UpdatePodGroup(pg *schedulingapi.PodGroup) (*sch\n \t\treturn nil, err\n \t}\n \n-\tupdated, err := su.vcclient.SchedulingV1beta1().PodGroups(podgroup.Namespace).Update(context.TODO(), podgroup, metav1.UpdateOptions{})",
        "comment_created_at": "2024-12-11T15:11:46+00:00",
        "comment_author": "JesseStutler",
        "comment_body": "Yes, there may be some other fields in spec or status need to be updated. We can't only just update the condition. What I want to do is not to refresh running/failed/succeeded fields in every session, because if session interval is short, there may be a lot of podgroup update requests, which may burden kube-apiserver. ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1952114258",
    "pr_number": 4000,
    "pr_file": "pkg/controllers/podgroup/pg_controller.go",
    "created_at": "2025-02-12T07:30:41+00:00",
    "commented_code": "// normal pod use volcano\n \tklog.V(4).Infof(\"Try to create podgroup for pod %s/%s\", pod.Namespace, pod.Name)\n-\tif err := pg.createNormalPodPGIfNotExist(pod); err != nil {\n+\tminMember := pg.getMinMemberFromUpperRes(pod)",
    "repo_full_name": "volcano-sh/volcano",
    "discussion_comments": [
      {
        "comment_id": "1952114258",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 4000,
        "pr_file": "pkg/controllers/podgroup/pg_controller.go",
        "discussion_id": "1952114258",
        "commented_code": "@@ -172,7 +172,8 @@ func (pg *pgcontroller) processNextReq() bool {\n \n \t// normal pod use volcano\n \tklog.V(4).Infof(\"Try to create podgroup for pod %s/%s\", pod.Namespace, pod.Name)\n-\tif err := pg.createNormalPodPGIfNotExist(pod); err != nil {\n+\tminMember := pg.getMinMemberFromUpperRes(pod)",
        "comment_created_at": "2025-02-12T07:30:41+00:00",
        "comment_author": "Monokaix",
        "comment_body": "This logic should put in `createNormalPodPGIfNotExist`, because when the podgroup is already existed, there is no need to calculate the min member, it will request APIServer which is a heavy operation.\r\nAnd there is also a qustion mentioned here https://github.com/volcano-sh/volcano/issues/3970#issuecomment-2652862212",
        "pr_file_module": null
      },
      {
        "comment_id": "1952310129",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 4000,
        "pr_file": "pkg/controllers/podgroup/pg_controller.go",
        "discussion_id": "1952114258",
        "commented_code": "@@ -172,7 +172,8 @@ func (pg *pgcontroller) processNextReq() bool {\n \n \t// normal pod use volcano\n \tklog.V(4).Infof(\"Try to create podgroup for pod %s/%s\", pod.Namespace, pod.Name)\n-\tif err := pg.createNormalPodPGIfNotExist(pod); err != nil {\n+\tminMember := pg.getMinMemberFromUpperRes(pod)",
        "comment_created_at": "2025-02-12T09:45:16+00:00",
        "comment_author": "sceneryback",
        "comment_body": "very good point \ud83d\udc4d so it's better to keep rs/sts etc informers in pgcontroller and read cache from these informers, right?",
        "pr_file_module": null
      },
      {
        "comment_id": "1952325410",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 4000,
        "pr_file": "pkg/controllers/podgroup/pg_controller.go",
        "discussion_id": "1952114258",
        "commented_code": "@@ -172,7 +172,8 @@ func (pg *pgcontroller) processNextReq() bool {\n \n \t// normal pod use volcano\n \tklog.V(4).Infof(\"Try to create podgroup for pod %s/%s\", pod.Namespace, pod.Name)\n-\tif err := pg.createNormalPodPGIfNotExist(pod); err != nil {\n+\tminMember := pg.getMinMemberFromUpperRes(pod)",
        "comment_created_at": "2025-02-12T09:54:45+00:00",
        "comment_author": "Monokaix",
        "comment_body": "Yeah, DaemonSet and Job should also be considered.",
        "pr_file_module": null
      },
      {
        "comment_id": "1952330373",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 4000,
        "pr_file": "pkg/controllers/podgroup/pg_controller.go",
        "discussion_id": "1952114258",
        "commented_code": "@@ -172,7 +172,8 @@ func (pg *pgcontroller) processNextReq() bool {\n \n \t// normal pod use volcano\n \tklog.V(4).Infof(\"Try to create podgroup for pod %s/%s\", pod.Namespace, pod.Name)\n-\tif err := pg.createNormalPodPGIfNotExist(pod); err != nil {\n+\tminMember := pg.getMinMemberFromUpperRes(pod)",
        "comment_created_at": "2025-02-12T09:57:36+00:00",
        "comment_author": "Monokaix",
        "comment_body": "Also this should also be considered https://github.com/volcano-sh/volcano/issues/3970#issuecomment-2638750095",
        "pr_file_module": null
      },
      {
        "comment_id": "1952409957",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 4000,
        "pr_file": "pkg/controllers/podgroup/pg_controller.go",
        "discussion_id": "1952114258",
        "commented_code": "@@ -172,7 +172,8 @@ func (pg *pgcontroller) processNextReq() bool {\n \n \t// normal pod use volcano\n \tklog.V(4).Infof(\"Try to create podgroup for pod %s/%s\", pod.Namespace, pod.Name)\n-\tif err := pg.createNormalPodPGIfNotExist(pod); err != nil {\n+\tminMember := pg.getMinMemberFromUpperRes(pod)",
        "comment_created_at": "2025-02-12T10:47:35+00:00",
        "comment_author": "sceneryback",
        "comment_body": "> Also this should also be considered [#3970 (comment)](https://github.com/volcano-sh/volcano/issues/3970#issuecomment-2638750095)\r\n\r\nI think it's not necessary to check pod annotation? The annotation is designed for workload, it will be strange to see this in pod",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1894542455",
    "pr_number": 3825,
    "pr_file": "pkg/scheduler/framework/session.go",
    "created_at": "2024-12-21T03:12:21+00:00",
    "commented_code": "// - Unschedulable\n // - UnschedulableAndUnresolvable\n // - ErrorSkipOrWait\n-func (ssn *Session) PredicateForAllocateAction(task *api.TaskInfo, node *api.NodeInfo) error {\n-\terr := ssn.PredicateFn(task, node)\n+func (ssn *Session) PredicateForAllocateAction(task *api.TaskInfo, node *api.NodeInfo, cacheEnable bool) error {\n+\tvar statusSets api.StatusSets\n+\tif node.Allocatable.MaxTaskNum <= len(ssn.NodeMap[node.Name].Pods) {\n+\t\tstatusSets = append(statusSets, &api.Status{Code: api.Unschedulable, Reason: api.NodePodNumberExceeded})\n+\t\treturn api.NewFitErrWithStatus(task, node, statusSets...)\n+\t}\n+\tvar (\n+\t\terr error\n+\t\tok  bool\n+\t)\n+\tif cacheEnable {\n+\t\terr, ok = util.GetPredicateCache(task.Job, task.UID, node.Name, node.HashValue)",
    "repo_full_name": "volcano-sh/volcano",
    "discussion_comments": [
      {
        "comment_id": "1894542455",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3825,
        "pr_file": "pkg/scheduler/framework/session.go",
        "discussion_id": "1894542455",
        "commented_code": "@@ -387,8 +389,23 @@ func (ssn *Session) GetUnschedulableAndUnresolvableNodesForTask(task *api.TaskIn\n // - Unschedulable\n // - UnschedulableAndUnresolvable\n // - ErrorSkipOrWait\n-func (ssn *Session) PredicateForAllocateAction(task *api.TaskInfo, node *api.NodeInfo) error {\n-\terr := ssn.PredicateFn(task, node)\n+func (ssn *Session) PredicateForAllocateAction(task *api.TaskInfo, node *api.NodeInfo, cacheEnable bool) error {\n+\tvar statusSets api.StatusSets\n+\tif node.Allocatable.MaxTaskNum <= len(ssn.NodeMap[node.Name].Pods) {\n+\t\tstatusSets = append(statusSets, &api.Status{Code: api.Unschedulable, Reason: api.NodePodNumberExceeded})\n+\t\treturn api.NewFitErrWithStatus(task, node, statusSets...)\n+\t}\n+\tvar (\n+\t\terr error\n+\t\tok  bool\n+\t)\n+\tif cacheEnable {\n+\t\terr, ok = util.GetPredicateCache(task.Job, task.UID, node.Name, node.HashValue)",
        "comment_created_at": "2024-12-21T03:12:21+00:00",
        "comment_author": "lowang-bh",
        "comment_body": "we can not simply use a cache here. For example, pod affinity/antiaffinity need to be re-considered.",
        "pr_file_module": null
      },
      {
        "comment_id": "1896520888",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3825,
        "pr_file": "pkg/scheduler/framework/session.go",
        "discussion_id": "1894542455",
        "commented_code": "@@ -387,8 +389,23 @@ func (ssn *Session) GetUnschedulableAndUnresolvableNodesForTask(task *api.TaskIn\n // - Unschedulable\n // - UnschedulableAndUnresolvable\n // - ErrorSkipOrWait\n-func (ssn *Session) PredicateForAllocateAction(task *api.TaskInfo, node *api.NodeInfo) error {\n-\terr := ssn.PredicateFn(task, node)\n+func (ssn *Session) PredicateForAllocateAction(task *api.TaskInfo, node *api.NodeInfo, cacheEnable bool) error {\n+\tvar statusSets api.StatusSets\n+\tif node.Allocatable.MaxTaskNum <= len(ssn.NodeMap[node.Name].Pods) {\n+\t\tstatusSets = append(statusSets, &api.Status{Code: api.Unschedulable, Reason: api.NodePodNumberExceeded})\n+\t\treturn api.NewFitErrWithStatus(task, node, statusSets...)\n+\t}\n+\tvar (\n+\t\terr error\n+\t\tok  bool\n+\t)\n+\tif cacheEnable {\n+\t\terr, ok = util.GetPredicateCache(task.Job, task.UID, node.Name, node.HashValue)",
        "comment_created_at": "2024-12-24T08:09:06+00:00",
        "comment_author": "molei20021",
        "comment_body": "I have added task hash which will consider the change of pod affinity/antiaffinity",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1912704592",
    "pr_number": 3964,
    "pr_file": "pkg/scheduler/api/hyper_node_info.go",
    "created_at": "2025-01-13T06:25:04+00:00",
    "commented_code": "+/*\n+Copyright 2025 The Volcano Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+*/\n+\n+package api\n+\n+import (\n+\t\"fmt\"\n+\t\"regexp\"\n+\t\"strconv\"\n+\t\"strings\"\n+\t\"sync\"\n+\t\"sync/atomic\"\n+\n+\tcorev1 \"k8s.io/api/core/v1\"\n+\t\"k8s.io/apimachinery/pkg/labels\"\n+\t\"k8s.io/apimachinery/pkg/util/sets\"\n+\tlisterv1 \"k8s.io/client-go/listers/core/v1\"\n+\t\"k8s.io/klog/v2\"\n+\n+\ttopologyv1alpha1 \"volcano.sh/apis/pkg/apis/topology/v1alpha1\"\n+)\n+\n+// HyperNodesInfo stores and manages the hierarchical structure of HyperNodes.\n+type HyperNodesInfo struct {\n+\tsync.Mutex\n+\n+\t// hyperNodes stores information about all HyperNodes.\n+\thyperNodes map[string]*HyperNodeInfo\n+\t// hyperNodesListByTier stores HyperNode names grouped by their tier.\n+\thyperNodesListByTier map[int]sets.Set[string]\n+\t// realNodesSet stores the set of real nodes for each HyperNode, eg, s0 and s1 are members of s4,\n+\t// s0->node0, node1, s1->node2, node3, s4->node0, node1, s1->node2, node3\n+\trealNodesSet map[string]sets.Set[string]\n+\t// parentMap stores the parent of each HyperNode.\n+\tparentMap map[string]string\n+\t// nodeLister Lister to list Kubernetes nodes.\n+\tnodeLister listerv1.NodeLister\n+\n+\t// ready indicates whether the HyperNodesInfo is ready (build process is complete).\n+\tready *atomic.Bool\n+}\n+\n+// NewHyperNodesInfo initializes a new HyperNodesInfo instance.\n+func NewHyperNodesInfo(lister listerv1.NodeLister) *HyperNodesInfo {\n+\treturn &HyperNodesInfo{\n+\t\thyperNodes:           make(map[string]*HyperNodeInfo),\n+\t\thyperNodesListByTier: make(map[int]sets.Set[string]),\n+\t\trealNodesSet:         make(map[string]sets.Set[string]),\n+\t\tparentMap:            make(map[string]string),\n+\t\tnodeLister:           lister,\n+\t\tready:                new(atomic.Bool),\n+\t}\n+}\n+\n+// NewHyperNodesInfoWithCache initializes a new HyperNodesInfo instance with cache.\n+// This is just used for ut.\n+// TODO: abstract an interface to mock for ut.\n+func NewHyperNodesInfoWithCache(hyperNodesListByTier map[int]sets.Set[string], realNodesSet map[string]sets.Set[string], ready *atomic.Bool) *HyperNodesInfo {\n+\treturn &HyperNodesInfo{\n+\t\thyperNodes:           make(map[string]*HyperNodeInfo),\n+\t\thyperNodesListByTier: hyperNodesListByTier,\n+\t\trealNodesSet:         realNodesSet,\n+\t\tparentMap:            make(map[string]string),\n+\t\tready:                ready,\n+\t}\n+}\n+\n+// HyperNodeInfo stores information about a single HyperNode.\n+type HyperNodeInfo struct {\n+\tName      string\n+\tHyperNode *topologyv1alpha1.HyperNode\n+\tTier      int\n+\n+\tisDeleting bool\n+}\n+\n+// NewHyperNodeInfo creates a new HyperNodeInfo instance.\n+func NewHyperNodeInfo(hn *topologyv1alpha1.HyperNode, tier int) *HyperNodeInfo {\n+\treturn &HyperNodeInfo{\n+\t\tName:      hn.Name,\n+\t\tHyperNode: hn,\n+\t\tTier:      tier,\n+\t}\n+}\n+\n+// String returns a string representation of the HyperNodeInfo.\n+func (hni *HyperNodeInfo) String() string {\n+\treturn strings.Join([]string{hni.Name, strconv.Itoa(hni.Tier)}, \"/\")\n+}\n+\n+// HyperNodes returns the map of all HyperNode information.\n+func (hni *HyperNodesInfo) HyperNodes() map[string]*HyperNodeInfo {\n+\treturn hni.hyperNodes\n+}\n+\n+// HyperNodesListByTier returns a deep copy of the map that groups HyperNode names by their tier.\n+// This ensures that the returned map is independent of the original, preventing unintended modifications.\n+func (hni *HyperNodesInfo) HyperNodesListByTier() map[int]sets.Set[string] {\n+\tcopiedHyperNodesListByTier := make(map[int]sets.Set[string], len(hni.hyperNodesListByTier))\n+\tfor tier, row := range hni.hyperNodesListByTier {\n+\t\tcopiedHyperNodesListByTier[tier] = row.Clone()\n+\t}\n+\n+\treturn copiedHyperNodesListByTier\n+}\n+\n+// RealNodesSet returns a deep copy of the map that stores the sets of real nodes for each HyperNode.\n+// This ensures that the returned map is independent of the original, preventing unintended modifications.\n+func (hni *HyperNodesInfo) RealNodesSet() map[string]sets.Set[string] {\n+\tcopiedRealNodesSet := make(map[string]sets.Set[string], len(hni.realNodesSet))\n+\tfor name, value := range hni.realNodesSet {\n+\t\tcopiedRealNodesSet[name] = value.Clone() // Clone the set to ensure a deep copy.\n+\t}\n+\n+\treturn copiedRealNodesSet\n+}\n+\n+// ParentMap returns the map of parent-child relationships between HyperNodes.\n+func (hni *HyperNodesInfo) ParentMap() map[string]string {\n+\treturn hni.parentMap\n+}\n+\n+// DeleteHyperNode deletes a HyperNode from the cache and update hyperNode tree.\n+func (hni *HyperNodesInfo) DeleteHyperNode(name string) error {\n+\thni.markHyperNodeIsDeleting(name)\n+\tif err := hni.updateAncestors(name); err != nil {\n+\t\treturn err\n+\t}\n+\thni.removeParent(name)\n+\n+\t// We can safely delete hyperNode after updated ancestors.\n+\thni.deleteHyperNode(name)\n+\treturn nil\n+}\n+\n+func (hni *HyperNodesInfo) UpdateHyperNode(hn *topologyv1alpha1.HyperNode) error {\n+\thni.updateHyperNode(hn)\n+\treturn hni.updateAncestors(hn.Name)\n+}\n+\n+func (hni *HyperNodesInfo) BuildHyperNodeCache(hn *HyperNodeInfo, processed sets.Set[string], ancestors sets.Set[string], nodes []*corev1.Node) error {\n+\t// Check for cyclic dependency.\n+\tif ancestors.Has(hn.Name) {\n+\t\thni.setReady(false)\n+\t\treturn fmt.Errorf(\"cyclic dependency detected: HyperNode %s is already in the ancestor chain %v\", hn.Name, sets.List(ancestors))\n+\t}\n+\t// Pruning operation: skip if hyperNode already processed.\n+\tif processed.Has(hn.Name) {\n+\t\treturn nil\n+\t}\n+\n+\tancestors.Insert(hn.Name)\n+\tdefer ancestors.Delete(hn.Name)\n+\n+\tif hni.HyperNodeIsDeleting(hn.Name) {\n+\t\tklog.InfoS(\"HyperNode is being deleted\", \"name\", hn.Name)\n+\t\treturn nil\n+\t}\n+\n+\tfor _, member := range hn.HyperNode.Spec.Members {\n+\t\tswitch member.Type {\n+\t\tcase topologyv1alpha1.MemberTypeNode:\n+\t\t\tif _, ok := hni.realNodesSet[hn.Name]; !ok {\n+\t\t\t\thni.realNodesSet[hn.Name] = sets.New[string]()\n+\t\t\t}\n+\t\t\tmembers := hni.getMembers(member.Selector, nodes)\n+\t\t\tklog.V(5).InfoS(\"Get members of hyperNode\", \"name\", hn.Name, \"members\", members)\n+\t\t\thni.realNodesSet[hn.Name] = hni.realNodesSet[hn.Name].Union(members)\n+\n+\t\tcase topologyv1alpha1.MemberTypeHyperNode:\n+\t\t\t// HyperNode member does not support regex match.\n+\t\t\tmemberName := hni.exactMatchMember(member.Selector)\n+\t\t\tif memberName == \"\" {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\tif err := hni.setParent(hn, memberName); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\n+\t\t\tmemberHn, ok := hni.hyperNodes[memberName]\n+\t\t\tif !ok {\n+\t\t\t\tklog.InfoS(\"HyperNode not exists in cache, maybe not created or not be watched\", \"name\", memberName, \"parent\", hn.Name)\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\t// Recursively build cache for the member HyperNode.\n+\t\t\tif err := hni.BuildHyperNodeCache(memberHn, processed, ancestors, nodes); err != nil {",
    "repo_full_name": "volcano-sh/volcano",
    "discussion_comments": [
      {
        "comment_id": "1912704592",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3964,
        "pr_file": "pkg/scheduler/api/hyper_node_info.go",
        "discussion_id": "1912704592",
        "commented_code": "@@ -0,0 +1,463 @@\n+/*\n+Copyright 2025 The Volcano Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+*/\n+\n+package api\n+\n+import (\n+\t\"fmt\"\n+\t\"regexp\"\n+\t\"strconv\"\n+\t\"strings\"\n+\t\"sync\"\n+\t\"sync/atomic\"\n+\n+\tcorev1 \"k8s.io/api/core/v1\"\n+\t\"k8s.io/apimachinery/pkg/labels\"\n+\t\"k8s.io/apimachinery/pkg/util/sets\"\n+\tlisterv1 \"k8s.io/client-go/listers/core/v1\"\n+\t\"k8s.io/klog/v2\"\n+\n+\ttopologyv1alpha1 \"volcano.sh/apis/pkg/apis/topology/v1alpha1\"\n+)\n+\n+// HyperNodesInfo stores and manages the hierarchical structure of HyperNodes.\n+type HyperNodesInfo struct {\n+\tsync.Mutex\n+\n+\t// hyperNodes stores information about all HyperNodes.\n+\thyperNodes map[string]*HyperNodeInfo\n+\t// hyperNodesListByTier stores HyperNode names grouped by their tier.\n+\thyperNodesListByTier map[int]sets.Set[string]\n+\t// realNodesSet stores the set of real nodes for each HyperNode, eg, s0 and s1 are members of s4,\n+\t// s0->node0, node1, s1->node2, node3, s4->node0, node1, s1->node2, node3\n+\trealNodesSet map[string]sets.Set[string]\n+\t// parentMap stores the parent of each HyperNode.\n+\tparentMap map[string]string\n+\t// nodeLister Lister to list Kubernetes nodes.\n+\tnodeLister listerv1.NodeLister\n+\n+\t// ready indicates whether the HyperNodesInfo is ready (build process is complete).\n+\tready *atomic.Bool\n+}\n+\n+// NewHyperNodesInfo initializes a new HyperNodesInfo instance.\n+func NewHyperNodesInfo(lister listerv1.NodeLister) *HyperNodesInfo {\n+\treturn &HyperNodesInfo{\n+\t\thyperNodes:           make(map[string]*HyperNodeInfo),\n+\t\thyperNodesListByTier: make(map[int]sets.Set[string]),\n+\t\trealNodesSet:         make(map[string]sets.Set[string]),\n+\t\tparentMap:            make(map[string]string),\n+\t\tnodeLister:           lister,\n+\t\tready:                new(atomic.Bool),\n+\t}\n+}\n+\n+// NewHyperNodesInfoWithCache initializes a new HyperNodesInfo instance with cache.\n+// This is just used for ut.\n+// TODO: abstract an interface to mock for ut.\n+func NewHyperNodesInfoWithCache(hyperNodesListByTier map[int]sets.Set[string], realNodesSet map[string]sets.Set[string], ready *atomic.Bool) *HyperNodesInfo {\n+\treturn &HyperNodesInfo{\n+\t\thyperNodes:           make(map[string]*HyperNodeInfo),\n+\t\thyperNodesListByTier: hyperNodesListByTier,\n+\t\trealNodesSet:         realNodesSet,\n+\t\tparentMap:            make(map[string]string),\n+\t\tready:                ready,\n+\t}\n+}\n+\n+// HyperNodeInfo stores information about a single HyperNode.\n+type HyperNodeInfo struct {\n+\tName      string\n+\tHyperNode *topologyv1alpha1.HyperNode\n+\tTier      int\n+\n+\tisDeleting bool\n+}\n+\n+// NewHyperNodeInfo creates a new HyperNodeInfo instance.\n+func NewHyperNodeInfo(hn *topologyv1alpha1.HyperNode, tier int) *HyperNodeInfo {\n+\treturn &HyperNodeInfo{\n+\t\tName:      hn.Name,\n+\t\tHyperNode: hn,\n+\t\tTier:      tier,\n+\t}\n+}\n+\n+// String returns a string representation of the HyperNodeInfo.\n+func (hni *HyperNodeInfo) String() string {\n+\treturn strings.Join([]string{hni.Name, strconv.Itoa(hni.Tier)}, \"/\")\n+}\n+\n+// HyperNodes returns the map of all HyperNode information.\n+func (hni *HyperNodesInfo) HyperNodes() map[string]*HyperNodeInfo {\n+\treturn hni.hyperNodes\n+}\n+\n+// HyperNodesListByTier returns a deep copy of the map that groups HyperNode names by their tier.\n+// This ensures that the returned map is independent of the original, preventing unintended modifications.\n+func (hni *HyperNodesInfo) HyperNodesListByTier() map[int]sets.Set[string] {\n+\tcopiedHyperNodesListByTier := make(map[int]sets.Set[string], len(hni.hyperNodesListByTier))\n+\tfor tier, row := range hni.hyperNodesListByTier {\n+\t\tcopiedHyperNodesListByTier[tier] = row.Clone()\n+\t}\n+\n+\treturn copiedHyperNodesListByTier\n+}\n+\n+// RealNodesSet returns a deep copy of the map that stores the sets of real nodes for each HyperNode.\n+// This ensures that the returned map is independent of the original, preventing unintended modifications.\n+func (hni *HyperNodesInfo) RealNodesSet() map[string]sets.Set[string] {\n+\tcopiedRealNodesSet := make(map[string]sets.Set[string], len(hni.realNodesSet))\n+\tfor name, value := range hni.realNodesSet {\n+\t\tcopiedRealNodesSet[name] = value.Clone() // Clone the set to ensure a deep copy.\n+\t}\n+\n+\treturn copiedRealNodesSet\n+}\n+\n+// ParentMap returns the map of parent-child relationships between HyperNodes.\n+func (hni *HyperNodesInfo) ParentMap() map[string]string {\n+\treturn hni.parentMap\n+}\n+\n+// DeleteHyperNode deletes a HyperNode from the cache and update hyperNode tree.\n+func (hni *HyperNodesInfo) DeleteHyperNode(name string) error {\n+\thni.markHyperNodeIsDeleting(name)\n+\tif err := hni.updateAncestors(name); err != nil {\n+\t\treturn err\n+\t}\n+\thni.removeParent(name)\n+\n+\t// We can safely delete hyperNode after updated ancestors.\n+\thni.deleteHyperNode(name)\n+\treturn nil\n+}\n+\n+func (hni *HyperNodesInfo) UpdateHyperNode(hn *topologyv1alpha1.HyperNode) error {\n+\thni.updateHyperNode(hn)\n+\treturn hni.updateAncestors(hn.Name)\n+}\n+\n+func (hni *HyperNodesInfo) BuildHyperNodeCache(hn *HyperNodeInfo, processed sets.Set[string], ancestors sets.Set[string], nodes []*corev1.Node) error {\n+\t// Check for cyclic dependency.\n+\tif ancestors.Has(hn.Name) {\n+\t\thni.setReady(false)\n+\t\treturn fmt.Errorf(\"cyclic dependency detected: HyperNode %s is already in the ancestor chain %v\", hn.Name, sets.List(ancestors))\n+\t}\n+\t// Pruning operation: skip if hyperNode already processed.\n+\tif processed.Has(hn.Name) {\n+\t\treturn nil\n+\t}\n+\n+\tancestors.Insert(hn.Name)\n+\tdefer ancestors.Delete(hn.Name)\n+\n+\tif hni.HyperNodeIsDeleting(hn.Name) {\n+\t\tklog.InfoS(\"HyperNode is being deleted\", \"name\", hn.Name)\n+\t\treturn nil\n+\t}\n+\n+\tfor _, member := range hn.HyperNode.Spec.Members {\n+\t\tswitch member.Type {\n+\t\tcase topologyv1alpha1.MemberTypeNode:\n+\t\t\tif _, ok := hni.realNodesSet[hn.Name]; !ok {\n+\t\t\t\thni.realNodesSet[hn.Name] = sets.New[string]()\n+\t\t\t}\n+\t\t\tmembers := hni.getMembers(member.Selector, nodes)\n+\t\t\tklog.V(5).InfoS(\"Get members of hyperNode\", \"name\", hn.Name, \"members\", members)\n+\t\t\thni.realNodesSet[hn.Name] = hni.realNodesSet[hn.Name].Union(members)\n+\n+\t\tcase topologyv1alpha1.MemberTypeHyperNode:\n+\t\t\t// HyperNode member does not support regex match.\n+\t\t\tmemberName := hni.exactMatchMember(member.Selector)\n+\t\t\tif memberName == \"\" {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\tif err := hni.setParent(hn, memberName); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\n+\t\t\tmemberHn, ok := hni.hyperNodes[memberName]\n+\t\t\tif !ok {\n+\t\t\t\tklog.InfoS(\"HyperNode not exists in cache, maybe not created or not be watched\", \"name\", memberName, \"parent\", hn.Name)\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\t// Recursively build cache for the member HyperNode.\n+\t\t\tif err := hni.BuildHyperNodeCache(memberHn, processed, ancestors, nodes); err != nil {",
        "comment_created_at": "2025-01-13T06:25:04+00:00",
        "comment_author": "JesseStutler",
        "comment_body": "Only the `realNodesSet` on the ancestors chain will be reset. Can the HyperNode that is not on the ancestor chain don't need to recursively enter `BuildHyperNodeCache`? Just check whether the realNodesSet of this member is not empty.",
        "pr_file_module": null
      },
      {
        "comment_id": "1912882412",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3964,
        "pr_file": "pkg/scheduler/api/hyper_node_info.go",
        "discussion_id": "1912704592",
        "commented_code": "@@ -0,0 +1,463 @@\n+/*\n+Copyright 2025 The Volcano Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+*/\n+\n+package api\n+\n+import (\n+\t\"fmt\"\n+\t\"regexp\"\n+\t\"strconv\"\n+\t\"strings\"\n+\t\"sync\"\n+\t\"sync/atomic\"\n+\n+\tcorev1 \"k8s.io/api/core/v1\"\n+\t\"k8s.io/apimachinery/pkg/labels\"\n+\t\"k8s.io/apimachinery/pkg/util/sets\"\n+\tlisterv1 \"k8s.io/client-go/listers/core/v1\"\n+\t\"k8s.io/klog/v2\"\n+\n+\ttopologyv1alpha1 \"volcano.sh/apis/pkg/apis/topology/v1alpha1\"\n+)\n+\n+// HyperNodesInfo stores and manages the hierarchical structure of HyperNodes.\n+type HyperNodesInfo struct {\n+\tsync.Mutex\n+\n+\t// hyperNodes stores information about all HyperNodes.\n+\thyperNodes map[string]*HyperNodeInfo\n+\t// hyperNodesListByTier stores HyperNode names grouped by their tier.\n+\thyperNodesListByTier map[int]sets.Set[string]\n+\t// realNodesSet stores the set of real nodes for each HyperNode, eg, s0 and s1 are members of s4,\n+\t// s0->node0, node1, s1->node2, node3, s4->node0, node1, s1->node2, node3\n+\trealNodesSet map[string]sets.Set[string]\n+\t// parentMap stores the parent of each HyperNode.\n+\tparentMap map[string]string\n+\t// nodeLister Lister to list Kubernetes nodes.\n+\tnodeLister listerv1.NodeLister\n+\n+\t// ready indicates whether the HyperNodesInfo is ready (build process is complete).\n+\tready *atomic.Bool\n+}\n+\n+// NewHyperNodesInfo initializes a new HyperNodesInfo instance.\n+func NewHyperNodesInfo(lister listerv1.NodeLister) *HyperNodesInfo {\n+\treturn &HyperNodesInfo{\n+\t\thyperNodes:           make(map[string]*HyperNodeInfo),\n+\t\thyperNodesListByTier: make(map[int]sets.Set[string]),\n+\t\trealNodesSet:         make(map[string]sets.Set[string]),\n+\t\tparentMap:            make(map[string]string),\n+\t\tnodeLister:           lister,\n+\t\tready:                new(atomic.Bool),\n+\t}\n+}\n+\n+// NewHyperNodesInfoWithCache initializes a new HyperNodesInfo instance with cache.\n+// This is just used for ut.\n+// TODO: abstract an interface to mock for ut.\n+func NewHyperNodesInfoWithCache(hyperNodesListByTier map[int]sets.Set[string], realNodesSet map[string]sets.Set[string], ready *atomic.Bool) *HyperNodesInfo {\n+\treturn &HyperNodesInfo{\n+\t\thyperNodes:           make(map[string]*HyperNodeInfo),\n+\t\thyperNodesListByTier: hyperNodesListByTier,\n+\t\trealNodesSet:         realNodesSet,\n+\t\tparentMap:            make(map[string]string),\n+\t\tready:                ready,\n+\t}\n+}\n+\n+// HyperNodeInfo stores information about a single HyperNode.\n+type HyperNodeInfo struct {\n+\tName      string\n+\tHyperNode *topologyv1alpha1.HyperNode\n+\tTier      int\n+\n+\tisDeleting bool\n+}\n+\n+// NewHyperNodeInfo creates a new HyperNodeInfo instance.\n+func NewHyperNodeInfo(hn *topologyv1alpha1.HyperNode, tier int) *HyperNodeInfo {\n+\treturn &HyperNodeInfo{\n+\t\tName:      hn.Name,\n+\t\tHyperNode: hn,\n+\t\tTier:      tier,\n+\t}\n+}\n+\n+// String returns a string representation of the HyperNodeInfo.\n+func (hni *HyperNodeInfo) String() string {\n+\treturn strings.Join([]string{hni.Name, strconv.Itoa(hni.Tier)}, \"/\")\n+}\n+\n+// HyperNodes returns the map of all HyperNode information.\n+func (hni *HyperNodesInfo) HyperNodes() map[string]*HyperNodeInfo {\n+\treturn hni.hyperNodes\n+}\n+\n+// HyperNodesListByTier returns a deep copy of the map that groups HyperNode names by their tier.\n+// This ensures that the returned map is independent of the original, preventing unintended modifications.\n+func (hni *HyperNodesInfo) HyperNodesListByTier() map[int]sets.Set[string] {\n+\tcopiedHyperNodesListByTier := make(map[int]sets.Set[string], len(hni.hyperNodesListByTier))\n+\tfor tier, row := range hni.hyperNodesListByTier {\n+\t\tcopiedHyperNodesListByTier[tier] = row.Clone()\n+\t}\n+\n+\treturn copiedHyperNodesListByTier\n+}\n+\n+// RealNodesSet returns a deep copy of the map that stores the sets of real nodes for each HyperNode.\n+// This ensures that the returned map is independent of the original, preventing unintended modifications.\n+func (hni *HyperNodesInfo) RealNodesSet() map[string]sets.Set[string] {\n+\tcopiedRealNodesSet := make(map[string]sets.Set[string], len(hni.realNodesSet))\n+\tfor name, value := range hni.realNodesSet {\n+\t\tcopiedRealNodesSet[name] = value.Clone() // Clone the set to ensure a deep copy.\n+\t}\n+\n+\treturn copiedRealNodesSet\n+}\n+\n+// ParentMap returns the map of parent-child relationships between HyperNodes.\n+func (hni *HyperNodesInfo) ParentMap() map[string]string {\n+\treturn hni.parentMap\n+}\n+\n+// DeleteHyperNode deletes a HyperNode from the cache and update hyperNode tree.\n+func (hni *HyperNodesInfo) DeleteHyperNode(name string) error {\n+\thni.markHyperNodeIsDeleting(name)\n+\tif err := hni.updateAncestors(name); err != nil {\n+\t\treturn err\n+\t}\n+\thni.removeParent(name)\n+\n+\t// We can safely delete hyperNode after updated ancestors.\n+\thni.deleteHyperNode(name)\n+\treturn nil\n+}\n+\n+func (hni *HyperNodesInfo) UpdateHyperNode(hn *topologyv1alpha1.HyperNode) error {\n+\thni.updateHyperNode(hn)\n+\treturn hni.updateAncestors(hn.Name)\n+}\n+\n+func (hni *HyperNodesInfo) BuildHyperNodeCache(hn *HyperNodeInfo, processed sets.Set[string], ancestors sets.Set[string], nodes []*corev1.Node) error {\n+\t// Check for cyclic dependency.\n+\tif ancestors.Has(hn.Name) {\n+\t\thni.setReady(false)\n+\t\treturn fmt.Errorf(\"cyclic dependency detected: HyperNode %s is already in the ancestor chain %v\", hn.Name, sets.List(ancestors))\n+\t}\n+\t// Pruning operation: skip if hyperNode already processed.\n+\tif processed.Has(hn.Name) {\n+\t\treturn nil\n+\t}\n+\n+\tancestors.Insert(hn.Name)\n+\tdefer ancestors.Delete(hn.Name)\n+\n+\tif hni.HyperNodeIsDeleting(hn.Name) {\n+\t\tklog.InfoS(\"HyperNode is being deleted\", \"name\", hn.Name)\n+\t\treturn nil\n+\t}\n+\n+\tfor _, member := range hn.HyperNode.Spec.Members {\n+\t\tswitch member.Type {\n+\t\tcase topologyv1alpha1.MemberTypeNode:\n+\t\t\tif _, ok := hni.realNodesSet[hn.Name]; !ok {\n+\t\t\t\thni.realNodesSet[hn.Name] = sets.New[string]()\n+\t\t\t}\n+\t\t\tmembers := hni.getMembers(member.Selector, nodes)\n+\t\t\tklog.V(5).InfoS(\"Get members of hyperNode\", \"name\", hn.Name, \"members\", members)\n+\t\t\thni.realNodesSet[hn.Name] = hni.realNodesSet[hn.Name].Union(members)\n+\n+\t\tcase topologyv1alpha1.MemberTypeHyperNode:\n+\t\t\t// HyperNode member does not support regex match.\n+\t\t\tmemberName := hni.exactMatchMember(member.Selector)\n+\t\t\tif memberName == \"\" {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\tif err := hni.setParent(hn, memberName); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\n+\t\t\tmemberHn, ok := hni.hyperNodes[memberName]\n+\t\t\tif !ok {\n+\t\t\t\tklog.InfoS(\"HyperNode not exists in cache, maybe not created or not be watched\", \"name\", memberName, \"parent\", hn.Name)\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\t// Recursively build cache for the member HyperNode.\n+\t\t\tif err := hni.BuildHyperNodeCache(memberHn, processed, ancestors, nodes); err != nil {",
        "comment_created_at": "2025-01-13T09:21:21+00:00",
        "comment_author": "JesseStutler",
        "comment_body": "Otherwise there will be some repetitive builds, like: \r\n![image](https://github.com/user-attachments/assets/654f72f7-4e25-45f1-bae2-99cdb5b2d2ac)\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "1913136723",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3964,
        "pr_file": "pkg/scheduler/api/hyper_node_info.go",
        "discussion_id": "1912704592",
        "commented_code": "@@ -0,0 +1,463 @@\n+/*\n+Copyright 2025 The Volcano Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+*/\n+\n+package api\n+\n+import (\n+\t\"fmt\"\n+\t\"regexp\"\n+\t\"strconv\"\n+\t\"strings\"\n+\t\"sync\"\n+\t\"sync/atomic\"\n+\n+\tcorev1 \"k8s.io/api/core/v1\"\n+\t\"k8s.io/apimachinery/pkg/labels\"\n+\t\"k8s.io/apimachinery/pkg/util/sets\"\n+\tlisterv1 \"k8s.io/client-go/listers/core/v1\"\n+\t\"k8s.io/klog/v2\"\n+\n+\ttopologyv1alpha1 \"volcano.sh/apis/pkg/apis/topology/v1alpha1\"\n+)\n+\n+// HyperNodesInfo stores and manages the hierarchical structure of HyperNodes.\n+type HyperNodesInfo struct {\n+\tsync.Mutex\n+\n+\t// hyperNodes stores information about all HyperNodes.\n+\thyperNodes map[string]*HyperNodeInfo\n+\t// hyperNodesListByTier stores HyperNode names grouped by their tier.\n+\thyperNodesListByTier map[int]sets.Set[string]\n+\t// realNodesSet stores the set of real nodes for each HyperNode, eg, s0 and s1 are members of s4,\n+\t// s0->node0, node1, s1->node2, node3, s4->node0, node1, s1->node2, node3\n+\trealNodesSet map[string]sets.Set[string]\n+\t// parentMap stores the parent of each HyperNode.\n+\tparentMap map[string]string\n+\t// nodeLister Lister to list Kubernetes nodes.\n+\tnodeLister listerv1.NodeLister\n+\n+\t// ready indicates whether the HyperNodesInfo is ready (build process is complete).\n+\tready *atomic.Bool\n+}\n+\n+// NewHyperNodesInfo initializes a new HyperNodesInfo instance.\n+func NewHyperNodesInfo(lister listerv1.NodeLister) *HyperNodesInfo {\n+\treturn &HyperNodesInfo{\n+\t\thyperNodes:           make(map[string]*HyperNodeInfo),\n+\t\thyperNodesListByTier: make(map[int]sets.Set[string]),\n+\t\trealNodesSet:         make(map[string]sets.Set[string]),\n+\t\tparentMap:            make(map[string]string),\n+\t\tnodeLister:           lister,\n+\t\tready:                new(atomic.Bool),\n+\t}\n+}\n+\n+// NewHyperNodesInfoWithCache initializes a new HyperNodesInfo instance with cache.\n+// This is just used for ut.\n+// TODO: abstract an interface to mock for ut.\n+func NewHyperNodesInfoWithCache(hyperNodesListByTier map[int]sets.Set[string], realNodesSet map[string]sets.Set[string], ready *atomic.Bool) *HyperNodesInfo {\n+\treturn &HyperNodesInfo{\n+\t\thyperNodes:           make(map[string]*HyperNodeInfo),\n+\t\thyperNodesListByTier: hyperNodesListByTier,\n+\t\trealNodesSet:         realNodesSet,\n+\t\tparentMap:            make(map[string]string),\n+\t\tready:                ready,\n+\t}\n+}\n+\n+// HyperNodeInfo stores information about a single HyperNode.\n+type HyperNodeInfo struct {\n+\tName      string\n+\tHyperNode *topologyv1alpha1.HyperNode\n+\tTier      int\n+\n+\tisDeleting bool\n+}\n+\n+// NewHyperNodeInfo creates a new HyperNodeInfo instance.\n+func NewHyperNodeInfo(hn *topologyv1alpha1.HyperNode, tier int) *HyperNodeInfo {\n+\treturn &HyperNodeInfo{\n+\t\tName:      hn.Name,\n+\t\tHyperNode: hn,\n+\t\tTier:      tier,\n+\t}\n+}\n+\n+// String returns a string representation of the HyperNodeInfo.\n+func (hni *HyperNodeInfo) String() string {\n+\treturn strings.Join([]string{hni.Name, strconv.Itoa(hni.Tier)}, \"/\")\n+}\n+\n+// HyperNodes returns the map of all HyperNode information.\n+func (hni *HyperNodesInfo) HyperNodes() map[string]*HyperNodeInfo {\n+\treturn hni.hyperNodes\n+}\n+\n+// HyperNodesListByTier returns a deep copy of the map that groups HyperNode names by their tier.\n+// This ensures that the returned map is independent of the original, preventing unintended modifications.\n+func (hni *HyperNodesInfo) HyperNodesListByTier() map[int]sets.Set[string] {\n+\tcopiedHyperNodesListByTier := make(map[int]sets.Set[string], len(hni.hyperNodesListByTier))\n+\tfor tier, row := range hni.hyperNodesListByTier {\n+\t\tcopiedHyperNodesListByTier[tier] = row.Clone()\n+\t}\n+\n+\treturn copiedHyperNodesListByTier\n+}\n+\n+// RealNodesSet returns a deep copy of the map that stores the sets of real nodes for each HyperNode.\n+// This ensures that the returned map is independent of the original, preventing unintended modifications.\n+func (hni *HyperNodesInfo) RealNodesSet() map[string]sets.Set[string] {\n+\tcopiedRealNodesSet := make(map[string]sets.Set[string], len(hni.realNodesSet))\n+\tfor name, value := range hni.realNodesSet {\n+\t\tcopiedRealNodesSet[name] = value.Clone() // Clone the set to ensure a deep copy.\n+\t}\n+\n+\treturn copiedRealNodesSet\n+}\n+\n+// ParentMap returns the map of parent-child relationships between HyperNodes.\n+func (hni *HyperNodesInfo) ParentMap() map[string]string {\n+\treturn hni.parentMap\n+}\n+\n+// DeleteHyperNode deletes a HyperNode from the cache and update hyperNode tree.\n+func (hni *HyperNodesInfo) DeleteHyperNode(name string) error {\n+\thni.markHyperNodeIsDeleting(name)\n+\tif err := hni.updateAncestors(name); err != nil {\n+\t\treturn err\n+\t}\n+\thni.removeParent(name)\n+\n+\t// We can safely delete hyperNode after updated ancestors.\n+\thni.deleteHyperNode(name)\n+\treturn nil\n+}\n+\n+func (hni *HyperNodesInfo) UpdateHyperNode(hn *topologyv1alpha1.HyperNode) error {\n+\thni.updateHyperNode(hn)\n+\treturn hni.updateAncestors(hn.Name)\n+}\n+\n+func (hni *HyperNodesInfo) BuildHyperNodeCache(hn *HyperNodeInfo, processed sets.Set[string], ancestors sets.Set[string], nodes []*corev1.Node) error {\n+\t// Check for cyclic dependency.\n+\tif ancestors.Has(hn.Name) {\n+\t\thni.setReady(false)\n+\t\treturn fmt.Errorf(\"cyclic dependency detected: HyperNode %s is already in the ancestor chain %v\", hn.Name, sets.List(ancestors))\n+\t}\n+\t// Pruning operation: skip if hyperNode already processed.\n+\tif processed.Has(hn.Name) {\n+\t\treturn nil\n+\t}\n+\n+\tancestors.Insert(hn.Name)\n+\tdefer ancestors.Delete(hn.Name)\n+\n+\tif hni.HyperNodeIsDeleting(hn.Name) {\n+\t\tklog.InfoS(\"HyperNode is being deleted\", \"name\", hn.Name)\n+\t\treturn nil\n+\t}\n+\n+\tfor _, member := range hn.HyperNode.Spec.Members {\n+\t\tswitch member.Type {\n+\t\tcase topologyv1alpha1.MemberTypeNode:\n+\t\t\tif _, ok := hni.realNodesSet[hn.Name]; !ok {\n+\t\t\t\thni.realNodesSet[hn.Name] = sets.New[string]()\n+\t\t\t}\n+\t\t\tmembers := hni.getMembers(member.Selector, nodes)\n+\t\t\tklog.V(5).InfoS(\"Get members of hyperNode\", \"name\", hn.Name, \"members\", members)\n+\t\t\thni.realNodesSet[hn.Name] = hni.realNodesSet[hn.Name].Union(members)\n+\n+\t\tcase topologyv1alpha1.MemberTypeHyperNode:\n+\t\t\t// HyperNode member does not support regex match.\n+\t\t\tmemberName := hni.exactMatchMember(member.Selector)\n+\t\t\tif memberName == \"\" {\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\tif err := hni.setParent(hn, memberName); err != nil {\n+\t\t\t\treturn err\n+\t\t\t}\n+\n+\t\t\tmemberHn, ok := hni.hyperNodes[memberName]\n+\t\t\tif !ok {\n+\t\t\t\tklog.InfoS(\"HyperNode not exists in cache, maybe not created or not be watched\", \"name\", memberName, \"parent\", hn.Name)\n+\t\t\t\tcontinue\n+\t\t\t}\n+\n+\t\t\t// Recursively build cache for the member HyperNode.\n+\t\t\tif err := hni.BuildHyperNodeCache(memberHn, processed, ancestors, nodes); err != nil {",
        "comment_created_at": "2025-01-13T12:44:26+00:00",
        "comment_author": "Monokaix",
        "comment_body": "done",
        "pr_file_module": null
      }
    ]
  }
]