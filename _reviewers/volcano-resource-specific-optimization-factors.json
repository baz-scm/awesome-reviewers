[
  {
    "discussion_id": "1699903160",
    "pr_number": 3634,
    "pr_file": "docs/design/overcommit-plugin.md",
    "created_at": "2024-08-01T10:18:34+00:00",
    "commented_code": "+# overcommit-plugin\n+\n+[@googs1025](https://github.com/googs1025); Jul. 29, 2024\n+\n+### Background: \n+The overcommit-plugin is used to amplify node resources to achieve resource allocation.\n+### Objective: \n+Use different amplification factors based on different resource types.\n+\n+\n+## Introduction\n+Currently, the overcommit-plugin enhances the Allocatable resources of a node to achieve the functionality of AddJobEnqueuedFn. However, different resources should have different factors, so using the same overcommit-factor is not appropriate.\n+![factor](images/overcommit-plugin.png)\n+- For example:\n+\n+The Binpack plugin assigns different weights to different resources as well.\n+\n+\n+```yaml\n+actions: \"enqueue, reclaim, allocate, backfill, preempt\"\n+tiers:\n+- plugins:\n+  - name: binpack\n+    arguments:\n+      binpack.weight: 10\n+      binpack.cpu: 5\n+      binpack.memory: 1\n+      binpack.resources: nvidia.com/gpu, example.com/foo\n+      binpack.resources.nvidia.com/gpu: 2\n+      binpack.resources.example.com/foo: 3\n+```\n+\n+## Solution\n+We can further break down the overcommit-factor into more granular components: cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor.\n+To maintain compatibility with the existing approach, we will retain the original overcommit-factor field and introduce optional fields for cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor.\n+\n+![factors](images/overcommit-plugin-with-multi-factors.png)\n+\n+The priority of these fields will be from low to high:\n+\n+`defaultOverCommitFactor -> overcommit-factor -> cpu-overcommit-factor, men-overcommit-factor, other overcommit-factor`\n+\n+\n+- overcommitPlugin struct\n+\n+```go\n+type overcommitFactors struct {\n+   cpu    float64\n+   memory float64\n+   other  float64\n+}\n+\n+type overcommitPlugin struct {\n+   // Arguments given for the plugin\n+   pluginArguments  framework.Arguments\n+   totalResource    *api.Resource\n+   idleResource     *api.Resource\n+   inqueueResource  *api.Resource\n+   overCommitFactors overcommitFactors\n+}\n+```\n+\n+#### Example\n+\n+Example 1:\n+Specify all three values: cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor simultaneously.\n+```yaml\n+actions: \"enqueue, allocate, backfill\"\n+tiers:\n+- plugins:\n+  - name: overcommit\n+    arguments:\n+    cpu-overcommit-factor: 1.2\n+    mem-overcommit-factor: 1.0\n+    other-overcommit-factor: 1.2",
    "repo_full_name": "volcano-sh/volcano",
    "discussion_comments": [
      {
        "comment_id": "1699903160",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3634,
        "pr_file": "docs/design/overcommit-plugin.md",
        "discussion_id": "1699903160",
        "commented_code": "@@ -0,0 +1,117 @@\n+# overcommit-plugin\n+\n+[@googs1025](https://github.com/googs1025); Jul. 29, 2024\n+\n+### Background: \n+The overcommit-plugin is used to amplify node resources to achieve resource allocation.\n+### Objective: \n+Use different amplification factors based on different resource types.\n+\n+\n+## Introduction\n+Currently, the overcommit-plugin enhances the Allocatable resources of a node to achieve the functionality of AddJobEnqueuedFn. However, different resources should have different factors, so using the same overcommit-factor is not appropriate.\n+![factor](images/overcommit-plugin.png)\n+- For example:\n+\n+The Binpack plugin assigns different weights to different resources as well.\n+\n+\n+```yaml\n+actions: \"enqueue, reclaim, allocate, backfill, preempt\"\n+tiers:\n+- plugins:\n+  - name: binpack\n+    arguments:\n+      binpack.weight: 10\n+      binpack.cpu: 5\n+      binpack.memory: 1\n+      binpack.resources: nvidia.com/gpu, example.com/foo\n+      binpack.resources.nvidia.com/gpu: 2\n+      binpack.resources.example.com/foo: 3\n+```\n+\n+## Solution\n+We can further break down the overcommit-factor into more granular components: cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor.\n+To maintain compatibility with the existing approach, we will retain the original overcommit-factor field and introduce optional fields for cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor.\n+\n+![factors](images/overcommit-plugin-with-multi-factors.png)\n+\n+The priority of these fields will be from low to high:\n+\n+`defaultOverCommitFactor -> overcommit-factor -> cpu-overcommit-factor, men-overcommit-factor, other overcommit-factor`\n+\n+\n+- overcommitPlugin struct\n+\n+```go\n+type overcommitFactors struct {\n+   cpu    float64\n+   memory float64\n+   other  float64\n+}\n+\n+type overcommitPlugin struct {\n+   // Arguments given for the plugin\n+   pluginArguments  framework.Arguments\n+   totalResource    *api.Resource\n+   idleResource     *api.Resource\n+   inqueueResource  *api.Resource\n+   overCommitFactors overcommitFactors\n+}\n+```\n+\n+#### Example\n+\n+Example 1:\n+Specify all three values: cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor simultaneously.\n+```yaml\n+actions: \"enqueue, allocate, backfill\"\n+tiers:\n+- plugins:\n+  - name: overcommit\n+    arguments:\n+    cpu-overcommit-factor: 1.2\n+    mem-overcommit-factor: 1.0\n+    other-overcommit-factor: 1.2",
        "comment_created_at": "2024-08-01T10:18:34+00:00",
        "comment_author": "lowang-bh",
        "comment_body": "In which scene, other resource will have a overcommit request \uff1f Does gpu support overcommit\uff1f",
        "pr_file_module": null
      },
      {
        "comment_id": "1699939546",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3634,
        "pr_file": "docs/design/overcommit-plugin.md",
        "discussion_id": "1699903160",
        "commented_code": "@@ -0,0 +1,117 @@\n+# overcommit-plugin\n+\n+[@googs1025](https://github.com/googs1025); Jul. 29, 2024\n+\n+### Background: \n+The overcommit-plugin is used to amplify node resources to achieve resource allocation.\n+### Objective: \n+Use different amplification factors based on different resource types.\n+\n+\n+## Introduction\n+Currently, the overcommit-plugin enhances the Allocatable resources of a node to achieve the functionality of AddJobEnqueuedFn. However, different resources should have different factors, so using the same overcommit-factor is not appropriate.\n+![factor](images/overcommit-plugin.png)\n+- For example:\n+\n+The Binpack plugin assigns different weights to different resources as well.\n+\n+\n+```yaml\n+actions: \"enqueue, reclaim, allocate, backfill, preempt\"\n+tiers:\n+- plugins:\n+  - name: binpack\n+    arguments:\n+      binpack.weight: 10\n+      binpack.cpu: 5\n+      binpack.memory: 1\n+      binpack.resources: nvidia.com/gpu, example.com/foo\n+      binpack.resources.nvidia.com/gpu: 2\n+      binpack.resources.example.com/foo: 3\n+```\n+\n+## Solution\n+We can further break down the overcommit-factor into more granular components: cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor.\n+To maintain compatibility with the existing approach, we will retain the original overcommit-factor field and introduce optional fields for cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor.\n+\n+![factors](images/overcommit-plugin-with-multi-factors.png)\n+\n+The priority of these fields will be from low to high:\n+\n+`defaultOverCommitFactor -> overcommit-factor -> cpu-overcommit-factor, men-overcommit-factor, other overcommit-factor`\n+\n+\n+- overcommitPlugin struct\n+\n+```go\n+type overcommitFactors struct {\n+   cpu    float64\n+   memory float64\n+   other  float64\n+}\n+\n+type overcommitPlugin struct {\n+   // Arguments given for the plugin\n+   pluginArguments  framework.Arguments\n+   totalResource    *api.Resource\n+   idleResource     *api.Resource\n+   inqueueResource  *api.Resource\n+   overCommitFactors overcommitFactors\n+}\n+```\n+\n+#### Example\n+\n+Example 1:\n+Specify all three values: cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor simultaneously.\n+```yaml\n+actions: \"enqueue, allocate, backfill\"\n+tiers:\n+- plugins:\n+  - name: overcommit\n+    arguments:\n+    cpu-overcommit-factor: 1.2\n+    mem-overcommit-factor: 1.0\n+    other-overcommit-factor: 1.2",
        "comment_created_at": "2024-08-01T10:49:21+00:00",
        "comment_author": "googs1025",
        "comment_body": "In my understanding, GPU resources should not be over-resolved. (Please correct me if I am wrong.) Originally, this plugin multiplied all resources by a fixed overcommit factor. This proposal is to enhance this. We should not make all configurations consistent. The overcommit factor should be configured more flexibly.",
        "pr_file_module": null
      },
      {
        "comment_id": "1699940659",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3634,
        "pr_file": "docs/design/overcommit-plugin.md",
        "discussion_id": "1699903160",
        "commented_code": "@@ -0,0 +1,117 @@\n+# overcommit-plugin\n+\n+[@googs1025](https://github.com/googs1025); Jul. 29, 2024\n+\n+### Background: \n+The overcommit-plugin is used to amplify node resources to achieve resource allocation.\n+### Objective: \n+Use different amplification factors based on different resource types.\n+\n+\n+## Introduction\n+Currently, the overcommit-plugin enhances the Allocatable resources of a node to achieve the functionality of AddJobEnqueuedFn. However, different resources should have different factors, so using the same overcommit-factor is not appropriate.\n+![factor](images/overcommit-plugin.png)\n+- For example:\n+\n+The Binpack plugin assigns different weights to different resources as well.\n+\n+\n+```yaml\n+actions: \"enqueue, reclaim, allocate, backfill, preempt\"\n+tiers:\n+- plugins:\n+  - name: binpack\n+    arguments:\n+      binpack.weight: 10\n+      binpack.cpu: 5\n+      binpack.memory: 1\n+      binpack.resources: nvidia.com/gpu, example.com/foo\n+      binpack.resources.nvidia.com/gpu: 2\n+      binpack.resources.example.com/foo: 3\n+```\n+\n+## Solution\n+We can further break down the overcommit-factor into more granular components: cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor.\n+To maintain compatibility with the existing approach, we will retain the original overcommit-factor field and introduce optional fields for cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor.\n+\n+![factors](images/overcommit-plugin-with-multi-factors.png)\n+\n+The priority of these fields will be from low to high:\n+\n+`defaultOverCommitFactor -> overcommit-factor -> cpu-overcommit-factor, men-overcommit-factor, other overcommit-factor`\n+\n+\n+- overcommitPlugin struct\n+\n+```go\n+type overcommitFactors struct {\n+   cpu    float64\n+   memory float64\n+   other  float64\n+}\n+\n+type overcommitPlugin struct {\n+   // Arguments given for the plugin\n+   pluginArguments  framework.Arguments\n+   totalResource    *api.Resource\n+   idleResource     *api.Resource\n+   inqueueResource  *api.Resource\n+   overCommitFactors overcommitFactors\n+}\n+```\n+\n+#### Example\n+\n+Example 1:\n+Specify all three values: cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor simultaneously.\n+```yaml\n+actions: \"enqueue, allocate, backfill\"\n+tiers:\n+- plugins:\n+  - name: overcommit\n+    arguments:\n+    cpu-overcommit-factor: 1.2\n+    mem-overcommit-factor: 1.0\n+    other-overcommit-factor: 1.2",
        "comment_created_at": "2024-08-01T10:50:22+00:00",
        "comment_author": "googs1025",
        "comment_body": "This effectively separates incompressible resources from compressible resources and sets them differently.",
        "pr_file_module": null
      },
      {
        "comment_id": "1699951846",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3634,
        "pr_file": "docs/design/overcommit-plugin.md",
        "discussion_id": "1699903160",
        "commented_code": "@@ -0,0 +1,117 @@\n+# overcommit-plugin\n+\n+[@googs1025](https://github.com/googs1025); Jul. 29, 2024\n+\n+### Background: \n+The overcommit-plugin is used to amplify node resources to achieve resource allocation.\n+### Objective: \n+Use different amplification factors based on different resource types.\n+\n+\n+## Introduction\n+Currently, the overcommit-plugin enhances the Allocatable resources of a node to achieve the functionality of AddJobEnqueuedFn. However, different resources should have different factors, so using the same overcommit-factor is not appropriate.\n+![factor](images/overcommit-plugin.png)\n+- For example:\n+\n+The Binpack plugin assigns different weights to different resources as well.\n+\n+\n+```yaml\n+actions: \"enqueue, reclaim, allocate, backfill, preempt\"\n+tiers:\n+- plugins:\n+  - name: binpack\n+    arguments:\n+      binpack.weight: 10\n+      binpack.cpu: 5\n+      binpack.memory: 1\n+      binpack.resources: nvidia.com/gpu, example.com/foo\n+      binpack.resources.nvidia.com/gpu: 2\n+      binpack.resources.example.com/foo: 3\n+```\n+\n+## Solution\n+We can further break down the overcommit-factor into more granular components: cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor.\n+To maintain compatibility with the existing approach, we will retain the original overcommit-factor field and introduce optional fields for cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor.\n+\n+![factors](images/overcommit-plugin-with-multi-factors.png)\n+\n+The priority of these fields will be from low to high:\n+\n+`defaultOverCommitFactor -> overcommit-factor -> cpu-overcommit-factor, men-overcommit-factor, other overcommit-factor`\n+\n+\n+- overcommitPlugin struct\n+\n+```go\n+type overcommitFactors struct {\n+   cpu    float64\n+   memory float64\n+   other  float64\n+}\n+\n+type overcommitPlugin struct {\n+   // Arguments given for the plugin\n+   pluginArguments  framework.Arguments\n+   totalResource    *api.Resource\n+   idleResource     *api.Resource\n+   inqueueResource  *api.Resource\n+   overCommitFactors overcommitFactors\n+}\n+```\n+\n+#### Example\n+\n+Example 1:\n+Specify all three values: cpu-overcommit-factor, mem-overcommit-factor, and other-overcommit-factor simultaneously.\n+```yaml\n+actions: \"enqueue, allocate, backfill\"\n+tiers:\n+- plugins:\n+  - name: overcommit\n+    arguments:\n+    cpu-overcommit-factor: 1.2\n+    mem-overcommit-factor: 1.0\n+    other-overcommit-factor: 1.2",
        "comment_created_at": "2024-08-01T10:58:08+00:00",
        "comment_author": "googs1025",
        "comment_body": "The overcommit plugin is activated when a job is enqueued, and it allows more jobs to enter the Inqueue state by amplifying the factor.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1901429118",
    "pr_number": 3906,
    "pr_file": "docs/design/dynamic-mig.md",
    "created_at": "2025-01-03T02:41:34+00:00",
    "commented_code": "+# NVIDIA GPU MPS and MIG dynamic slice plugin\n+\n+## Special Thanks\n+\n+This feature will not be implemented without the help of @sailorvii.\n+\n+## Introduction\n+\n+The NVIDIA GPU build-in sharing method includes: time-slice, MPS and MIG. The context switch for time slice sharing would waste some time, so we chose the MPS and MIG. The GPU MIG profile is variable, the user could acquire the MIG device in the profile definition, but current implementation only defines the dedicated profile before the user requirement. That limits the usage of MIG. We want to develop an automatic slice plugin and create the slice when the user require it.\n+For the scheduling method, node-level binpack and spread will be supported. Referring to the binpack plugin, we consider the CPU, Mem, GPU memory and other user-defined resource.\n+Volcano already have a [vgpu feature](https://github.com/Project-HAMi/volcano-vgpu-device-plugin) for NVIDIA devices after v1.9, it is done by using [hami-core](https://github.com/Project-HAMi/HAMi-core), which is a cuda-hacking library. But mig is also widely used across the world. A unified API for dynamic-mig and volcano-vgpu is needed.\n+\n+## Targets\n+\n+- CPU, Mem, and GPU combined schedule\n+- GPU dynamic slice: Hami-core and MIG\n+- Support node-level binpack and spread by GPU memory, CPU and Mem\n+- A unified vGPU Pool different virtualization technics\n+- Tasks can choose to use MIG, use HAMi-core, or use both.\n+\n+### Config maps\n+- volcano-device-configMap\n+This configmap defines the plugin configurations including resourceName, and MIG geometries, and node-level configurations.\n+\n+```yaml\n+apiVersion: v1\n+data:\n+  volcano-device-share.conf: |\n+    nvidia:\n+      resourceCountName: volcano.sh/vgpu-number\n+      resourceMemoryName: volcano.sh/vgpu-memory\n+      resourceCoreName: volcano.sh/vgpu-cores\n+      knownMigGeometries:\n+      - models: [ \"A30\" ]\n+        allowedGeometries:\n+          - \n+            - name: 1g.6gb\n+              memory: 6144\n+              count: 4\n+          - \n+            - name: 2g.12gb\n+              memory: 12288\n+              count: 2\n+          - \n+            - name: 4g.24gb\n+              memory: 24576\n+              count: 1\n+      - models: [ \"A100-SXM4-40GB\", \"A100-40GB-PCIe\", \"A100-PCIE-40GB\", \"A100-SXM4-40GB\" ]\n+        allowedGeometries:\n+          - \n+            - name: 1g.5gb\n+              memory: 5120\n+              count: 7\n+          - \n+            - name: 2g.10gb\n+              memory: 10240\n+              count: 3\n+            - name: 1g.5gb\n+              memory: 5120\n+              count: 1\n+          - \n+            - name: 3g.20gb\n+              memory: 20480\n+              count: 2\n+          - \n+            - name: 7g.40gb\n+              memory: 40960\n+              count: 1\n+      - models: [ \"A100-SXM4-80GB\", \"A100-80GB-PCIe\", \"A100-PCIE-80GB\"]\n+        allowedGeometries:\n+          - \n+            - name: 1g.10gb\n+              memory: 10240\n+              count: 7\n+          - \n+            - name: 2g.20gb\n+              memory: 20480\n+              count: 3\n+            - name: 1g.10gb\n+              memory: 10240\n+              count: 1\n+          - \n+            - name: 3g.40gb\n+              memory: 40960\n+              count: 2\n+          - \n+            - name: 7g.79gb\n+              memory: 80896\n+              count: 1\n+      nodeconfig: \n+          - name: nodeA\n+            operatingmode: hami-core\n+          - name: nodeB\n+            operatingmode: mig\n+```\n+\n+## Structure\n+\n+<img src=\"./images/volcano-dynamic-mig-structure.png\" width = \"400\" /> \n+\n+## Examples\n+\n+Dynamic mig is compatable with volcano-vgpu tasks, as the example below: \n+Just Setting `volcano.sh/vgpu-number` and `volcano.sh/vgpu-memory`.\n+\n+```yaml\n+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: gpu-pod1\n+spec:\n+  containers:\n+    - name: ubuntu-container1\n+      image: ubuntu:20.04\n+      command: [\"bash\", \"-c\", \"sleep 86400\"]\n+      resources:\n+        limits:\n+          volcano.sh/vgpu-number: 2 # requesting 2 vGPUs\n+          volcano.sh/vgpu-memory: 8000 # Each vGPU contains 8000m device memory \uff08Optional,Integer\n+```\n+\n+A task can decide only to use `mig` or `hami-core` by setting `annotations.volcano.sh/vgpu-mode` to corresponding value, as the example below shows:\n+\n+```yaml\n+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: gpu-pod1\n+  annotations:\n+    volcano.sh/vgpu-mode: \"mig\"\n+spec:\n+  containers:\n+    - name: ubuntu-container1\n+      image: ubuntu:20.04\n+      command: [\"bash\", \"-c\", \"sleep 86400\"]\n+      resources:\n+        limits:\n+          volcano.sh/vgpu-number: 2 # requesting 2 vGPUs\n+          volcano.sh/vgpu-memory: 8000 # Each vGPU contains 8000m device memory \uff08Optional,Integer\uff09\n+```\n+\n+## Procedures\n+\n+The Procedure of a vGPU task which uses dynamic-mig is shown below:\n+\n+<img src=\"./images/volcano-dynamic-mig-procedure.png\" width = \"800\" /> \n+\n+Note that after submited a task, deviceshare plugin will iterate over templates defined in configMap `volcano-device-share`, and find the first available template to fit. You can always change the content of that configMap, and restart vc-scheduler to customize.\n+\n+If you submit the example on an empty A100-PCIE-40GB node, then it will select a GPU and chosse MIG template below:",
    "repo_full_name": "volcano-sh/volcano",
    "discussion_comments": [
      {
        "comment_id": "1901429118",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3906,
        "pr_file": "docs/design/dynamic-mig.md",
        "discussion_id": "1901429118",
        "commented_code": "@@ -0,0 +1,158 @@\n+# NVIDIA GPU MPS and MIG dynamic slice plugin\n+\n+## Special Thanks\n+\n+This feature will not be implemented without the help of @sailorvii.\n+\n+## Introduction\n+\n+The NVIDIA GPU build-in sharing method includes: time-slice, MPS and MIG. The context switch for time slice sharing would waste some time, so we chose the MPS and MIG. The GPU MIG profile is variable, the user could acquire the MIG device in the profile definition, but current implementation only defines the dedicated profile before the user requirement. That limits the usage of MIG. We want to develop an automatic slice plugin and create the slice when the user require it.\n+For the scheduling method, node-level binpack and spread will be supported. Referring to the binpack plugin, we consider the CPU, Mem, GPU memory and other user-defined resource.\n+Volcano already have a [vgpu feature](https://github.com/Project-HAMi/volcano-vgpu-device-plugin) for NVIDIA devices after v1.9, it is done by using [hami-core](https://github.com/Project-HAMi/HAMi-core), which is a cuda-hacking library. But mig is also widely used across the world. A unified API for dynamic-mig and volcano-vgpu is needed.\n+\n+## Targets\n+\n+- CPU, Mem, and GPU combined schedule\n+- GPU dynamic slice: Hami-core and MIG\n+- Support node-level binpack and spread by GPU memory, CPU and Mem\n+- A unified vGPU Pool different virtualization technics\n+- Tasks can choose to use MIG, use HAMi-core, or use both.\n+\n+### Config maps\n+- volcano-device-configMap\n+This configmap defines the plugin configurations including resourceName, and MIG geometries, and node-level configurations.\n+\n+```yaml\n+apiVersion: v1\n+data:\n+  volcano-device-share.conf: |\n+    nvidia:\n+      resourceCountName: volcano.sh/vgpu-number\n+      resourceMemoryName: volcano.sh/vgpu-memory\n+      resourceCoreName: volcano.sh/vgpu-cores\n+      knownMigGeometries:\n+      - models: [ \"A30\" ]\n+        allowedGeometries:\n+          - \n+            - name: 1g.6gb\n+              memory: 6144\n+              count: 4\n+          - \n+            - name: 2g.12gb\n+              memory: 12288\n+              count: 2\n+          - \n+            - name: 4g.24gb\n+              memory: 24576\n+              count: 1\n+      - models: [ \"A100-SXM4-40GB\", \"A100-40GB-PCIe\", \"A100-PCIE-40GB\", \"A100-SXM4-40GB\" ]\n+        allowedGeometries:\n+          - \n+            - name: 1g.5gb\n+              memory: 5120\n+              count: 7\n+          - \n+            - name: 2g.10gb\n+              memory: 10240\n+              count: 3\n+            - name: 1g.5gb\n+              memory: 5120\n+              count: 1\n+          - \n+            - name: 3g.20gb\n+              memory: 20480\n+              count: 2\n+          - \n+            - name: 7g.40gb\n+              memory: 40960\n+              count: 1\n+      - models: [ \"A100-SXM4-80GB\", \"A100-80GB-PCIe\", \"A100-PCIE-80GB\"]\n+        allowedGeometries:\n+          - \n+            - name: 1g.10gb\n+              memory: 10240\n+              count: 7\n+          - \n+            - name: 2g.20gb\n+              memory: 20480\n+              count: 3\n+            - name: 1g.10gb\n+              memory: 10240\n+              count: 1\n+          - \n+            - name: 3g.40gb\n+              memory: 40960\n+              count: 2\n+          - \n+            - name: 7g.79gb\n+              memory: 80896\n+              count: 1\n+      nodeconfig: \n+          - name: nodeA\n+            operatingmode: hami-core\n+          - name: nodeB\n+            operatingmode: mig\n+```\n+\n+## Structure\n+\n+<img src=\"./images/volcano-dynamic-mig-structure.png\" width = \"400\" /> \n+\n+## Examples\n+\n+Dynamic mig is compatable with volcano-vgpu tasks, as the example below: \n+Just Setting `volcano.sh/vgpu-number` and `volcano.sh/vgpu-memory`.\n+\n+```yaml\n+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: gpu-pod1\n+spec:\n+  containers:\n+    - name: ubuntu-container1\n+      image: ubuntu:20.04\n+      command: [\"bash\", \"-c\", \"sleep 86400\"]\n+      resources:\n+        limits:\n+          volcano.sh/vgpu-number: 2 # requesting 2 vGPUs\n+          volcano.sh/vgpu-memory: 8000 # Each vGPU contains 8000m device memory \uff08Optional,Integer\n+```\n+\n+A task can decide only to use `mig` or `hami-core` by setting `annotations.volcano.sh/vgpu-mode` to corresponding value, as the example below shows:\n+\n+```yaml\n+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: gpu-pod1\n+  annotations:\n+    volcano.sh/vgpu-mode: \"mig\"\n+spec:\n+  containers:\n+    - name: ubuntu-container1\n+      image: ubuntu:20.04\n+      command: [\"bash\", \"-c\", \"sleep 86400\"]\n+      resources:\n+        limits:\n+          volcano.sh/vgpu-number: 2 # requesting 2 vGPUs\n+          volcano.sh/vgpu-memory: 8000 # Each vGPU contains 8000m device memory \uff08Optional,Integer\uff09\n+```\n+\n+## Procedures\n+\n+The Procedure of a vGPU task which uses dynamic-mig is shown below:\n+\n+<img src=\"./images/volcano-dynamic-mig-procedure.png\" width = \"800\" /> \n+\n+Note that after submited a task, deviceshare plugin will iterate over templates defined in configMap `volcano-device-share`, and find the first available template to fit. You can always change the content of that configMap, and restart vc-scheduler to customize.\n+\n+If you submit the example on an empty A100-PCIE-40GB node, then it will select a GPU and chosse MIG template below:",
        "comment_created_at": "2025-01-03T02:41:34+00:00",
        "comment_author": "JesseStutler",
        "comment_body": "If you submit a pod requiring 4GPU, 20GB device memory, and an empty A100-PCIE-40GB node has the following MIG template below: \r\n```yaml\r\n  2g.10gb: 3\r\n  1g.5gb: 1\r\n```\r\nThen two `2g.10gb` profiles will be allocated to this pod, should be like this? Your example here doesn't say how much resources the Pod requests.",
        "pr_file_module": null
      },
      {
        "comment_id": "1901429230",
        "repo_full_name": "volcano-sh/volcano",
        "pr_number": 3906,
        "pr_file": "docs/design/dynamic-mig.md",
        "discussion_id": "1901429118",
        "commented_code": "@@ -0,0 +1,158 @@\n+# NVIDIA GPU MPS and MIG dynamic slice plugin\n+\n+## Special Thanks\n+\n+This feature will not be implemented without the help of @sailorvii.\n+\n+## Introduction\n+\n+The NVIDIA GPU build-in sharing method includes: time-slice, MPS and MIG. The context switch for time slice sharing would waste some time, so we chose the MPS and MIG. The GPU MIG profile is variable, the user could acquire the MIG device in the profile definition, but current implementation only defines the dedicated profile before the user requirement. That limits the usage of MIG. We want to develop an automatic slice plugin and create the slice when the user require it.\n+For the scheduling method, node-level binpack and spread will be supported. Referring to the binpack plugin, we consider the CPU, Mem, GPU memory and other user-defined resource.\n+Volcano already have a [vgpu feature](https://github.com/Project-HAMi/volcano-vgpu-device-plugin) for NVIDIA devices after v1.9, it is done by using [hami-core](https://github.com/Project-HAMi/HAMi-core), which is a cuda-hacking library. But mig is also widely used across the world. A unified API for dynamic-mig and volcano-vgpu is needed.\n+\n+## Targets\n+\n+- CPU, Mem, and GPU combined schedule\n+- GPU dynamic slice: Hami-core and MIG\n+- Support node-level binpack and spread by GPU memory, CPU and Mem\n+- A unified vGPU Pool different virtualization technics\n+- Tasks can choose to use MIG, use HAMi-core, or use both.\n+\n+### Config maps\n+- volcano-device-configMap\n+This configmap defines the plugin configurations including resourceName, and MIG geometries, and node-level configurations.\n+\n+```yaml\n+apiVersion: v1\n+data:\n+  volcano-device-share.conf: |\n+    nvidia:\n+      resourceCountName: volcano.sh/vgpu-number\n+      resourceMemoryName: volcano.sh/vgpu-memory\n+      resourceCoreName: volcano.sh/vgpu-cores\n+      knownMigGeometries:\n+      - models: [ \"A30\" ]\n+        allowedGeometries:\n+          - \n+            - name: 1g.6gb\n+              memory: 6144\n+              count: 4\n+          - \n+            - name: 2g.12gb\n+              memory: 12288\n+              count: 2\n+          - \n+            - name: 4g.24gb\n+              memory: 24576\n+              count: 1\n+      - models: [ \"A100-SXM4-40GB\", \"A100-40GB-PCIe\", \"A100-PCIE-40GB\", \"A100-SXM4-40GB\" ]\n+        allowedGeometries:\n+          - \n+            - name: 1g.5gb\n+              memory: 5120\n+              count: 7\n+          - \n+            - name: 2g.10gb\n+              memory: 10240\n+              count: 3\n+            - name: 1g.5gb\n+              memory: 5120\n+              count: 1\n+          - \n+            - name: 3g.20gb\n+              memory: 20480\n+              count: 2\n+          - \n+            - name: 7g.40gb\n+              memory: 40960\n+              count: 1\n+      - models: [ \"A100-SXM4-80GB\", \"A100-80GB-PCIe\", \"A100-PCIE-80GB\"]\n+        allowedGeometries:\n+          - \n+            - name: 1g.10gb\n+              memory: 10240\n+              count: 7\n+          - \n+            - name: 2g.20gb\n+              memory: 20480\n+              count: 3\n+            - name: 1g.10gb\n+              memory: 10240\n+              count: 1\n+          - \n+            - name: 3g.40gb\n+              memory: 40960\n+              count: 2\n+          - \n+            - name: 7g.79gb\n+              memory: 80896\n+              count: 1\n+      nodeconfig: \n+          - name: nodeA\n+            operatingmode: hami-core\n+          - name: nodeB\n+            operatingmode: mig\n+```\n+\n+## Structure\n+\n+<img src=\"./images/volcano-dynamic-mig-structure.png\" width = \"400\" /> \n+\n+## Examples\n+\n+Dynamic mig is compatable with volcano-vgpu tasks, as the example below: \n+Just Setting `volcano.sh/vgpu-number` and `volcano.sh/vgpu-memory`.\n+\n+```yaml\n+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: gpu-pod1\n+spec:\n+  containers:\n+    - name: ubuntu-container1\n+      image: ubuntu:20.04\n+      command: [\"bash\", \"-c\", \"sleep 86400\"]\n+      resources:\n+        limits:\n+          volcano.sh/vgpu-number: 2 # requesting 2 vGPUs\n+          volcano.sh/vgpu-memory: 8000 # Each vGPU contains 8000m device memory \uff08Optional,Integer\n+```\n+\n+A task can decide only to use `mig` or `hami-core` by setting `annotations.volcano.sh/vgpu-mode` to corresponding value, as the example below shows:\n+\n+```yaml\n+apiVersion: v1\n+kind: Pod\n+metadata:\n+  name: gpu-pod1\n+  annotations:\n+    volcano.sh/vgpu-mode: \"mig\"\n+spec:\n+  containers:\n+    - name: ubuntu-container1\n+      image: ubuntu:20.04\n+      command: [\"bash\", \"-c\", \"sleep 86400\"]\n+      resources:\n+        limits:\n+          volcano.sh/vgpu-number: 2 # requesting 2 vGPUs\n+          volcano.sh/vgpu-memory: 8000 # Each vGPU contains 8000m device memory \uff08Optional,Integer\uff09\n+```\n+\n+## Procedures\n+\n+The Procedure of a vGPU task which uses dynamic-mig is shown below:\n+\n+<img src=\"./images/volcano-dynamic-mig-procedure.png\" width = \"800\" /> \n+\n+Note that after submited a task, deviceshare plugin will iterate over templates defined in configMap `volcano-device-share`, and find the first available template to fit. You can always change the content of that configMap, and restart vc-scheduler to customize.\n+\n+If you submit the example on an empty A100-PCIE-40GB node, then it will select a GPU and chosse MIG template below:",
        "comment_created_at": "2025-01-03T02:42:02+00:00",
        "comment_author": "JesseStutler",
        "comment_body": "typo `chosse`",
        "pr_file_module": null
      }
    ]
  }
]