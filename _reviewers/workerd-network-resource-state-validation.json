[
  {
    "discussion_id": "2283418059",
    "pr_number": 4819,
    "pr_file": "src/workerd/api/http.c++",
    "created_at": "2025-08-18T20:40:31+00:00",
    "commented_code": "if (isRedirectStatusCode(response.statusCode) &&\n       jsRequest->getRedirectEnum() == Request::Redirect::FOLLOW) {\n     KJ_IF_SOME(l, response.headers->get(kj::HttpHeaderId::LOCATION)) {\n-      return handleHttpRedirectResponse(\n-          js, kj::mv(fetcher), kj::mv(jsRequest), kj::mv(urlList), response.statusCode, l);\n+      // Read and discard the entire response body before following the redirect.",
    "repo_full_name": "cloudflare/workerd",
    "discussion_comments": [
      {
        "comment_id": "2283418059",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 4819,
        "pr_file": "src/workerd/api/http.c++",
        "discussion_id": "2283418059",
        "commented_code": "@@ -1524,8 +1524,16 @@ jsg::Promise<jsg::Ref<Response>> handleHttpResponse(jsg::Lock& js,\n   if (isRedirectStatusCode(response.statusCode) &&\n       jsRequest->getRedirectEnum() == Request::Redirect::FOLLOW) {\n     KJ_IF_SOME(l, response.headers->get(kj::HttpHeaderId::LOCATION)) {\n-      return handleHttpRedirectResponse(\n-          js, kj::mv(fetcher), kj::mv(jsRequest), kj::mv(urlList), response.statusCode, l);\n+      // Read and discard the entire response body before following the redirect.",
        "comment_created_at": "2025-08-18T20:40:31+00:00",
        "comment_author": "xortive",
        "comment_body": "huh, how did following redirects in workers work at all (like with global `fetch()`) before this change?",
        "pr_file_module": null
      },
      {
        "comment_id": "2283425888",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 4819,
        "pr_file": "src/workerd/api/http.c++",
        "discussion_id": "2283418059",
        "commented_code": "@@ -1524,8 +1524,16 @@ jsg::Promise<jsg::Ref<Response>> handleHttpResponse(jsg::Lock& js,\n   if (isRedirectStatusCode(response.statusCode) &&\n       jsRequest->getRedirectEnum() == Request::Redirect::FOLLOW) {\n     KJ_IF_SOME(l, response.headers->get(kj::HttpHeaderId::LOCATION)) {\n-      return handleHttpRedirectResponse(\n-          js, kj::mv(fetcher), kj::mv(jsRequest), kj::mv(urlList), response.statusCode, l);\n+      // Read and discard the entire response body before following the redirect.",
        "comment_created_at": "2025-08-18T20:45:17+00:00",
        "comment_author": "tewaro",
        "comment_body": "I'm honestly not entirely sure. But I think other backends can handle disconnects on the socket.",
        "pr_file_module": null
      },
      {
        "comment_id": "2283440018",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 4819,
        "pr_file": "src/workerd/api/http.c++",
        "discussion_id": "2283418059",
        "commented_code": "@@ -1524,8 +1524,16 @@ jsg::Promise<jsg::Ref<Response>> handleHttpResponse(jsg::Lock& js,\n   if (isRedirectStatusCode(response.statusCode) &&\n       jsRequest->getRedirectEnum() == Request::Redirect::FOLLOW) {\n     KJ_IF_SOME(l, response.headers->get(kj::HttpHeaderId::LOCATION)) {\n-      return handleHttpRedirectResponse(\n-          js, kj::mv(fetcher), kj::mv(jsRequest), kj::mv(urlList), response.statusCode, l);\n+      // Read and discard the entire response body before following the redirect.",
        "comment_created_at": "2025-08-18T20:51:14+00:00",
        "comment_author": "kentonv",
        "comment_body": "Normally if the application doesn't consume the entire response body, KJ will discard the whole connection. KJ only reuses a connection if it has fully completed the previous request and response.\r\n\r\nBut when the application provided the socket, KJ will go into a different mode where it pipelines requests on the same socket, possibly even overlapping. In this mode, though, it's a firm requirement that the application fully reads every response body, so that the connection can be reused.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2283447809",
    "pr_number": 4819,
    "pr_file": "src/workerd/api/sockets.c++",
    "created_at": "2025-08-18T20:56:02+00:00",
    "commented_code": "}\n \n  private:\n-  kj::Own<kj::AsyncIoStream> stream;\n-  const kj::HttpHeaderTable& headerTable;\n+  kj::HttpClient& httpClient;\n };\n \n // Implementation of the custom factory for creating WorkerInterface instances from a socket\n class StreamOutgoingFactory final: public Fetcher::OutgoingFactory {\n  public:\n   StreamOutgoingFactory(kj::Own<kj::AsyncIoStream> stream, const kj::HttpHeaderTable& headerTable)\n-      : stream(kj::mv(stream)),\n-        headerTable(headerTable) {}\n+      : httpClient(newHttpClient(headerTable, *stream)),\n+        stream(kj::mv(stream)) {}\n \n   kj::Own<WorkerInterface> newSingleUseClient(kj::Maybe<kj::String> cfStr) override {\n     JSG_ASSERT(stream.get() != nullptr, Error,\n         \"Fetcher created from internalNewHttpClient can only be used once\");\n     // Create a WorkerInterface that wraps the stream\n-    return kj::heap<StreamWorkerInterface>(kj::mv(stream), headerTable);\n+    return kj::heap<StreamWorkerInterface>(*httpClient);",
    "repo_full_name": "cloudflare/workerd",
    "discussion_comments": [
      {
        "comment_id": "2283447809",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 4819,
        "pr_file": "src/workerd/api/sockets.c++",
        "discussion_id": "2283447809",
        "commented_code": "@@ -581,27 +577,26 @@ class StreamWorkerInterface final: public WorkerInterface {\n   }\n \n  private:\n-  kj::Own<kj::AsyncIoStream> stream;\n-  const kj::HttpHeaderTable& headerTable;\n+  kj::HttpClient& httpClient;\n };\n \n // Implementation of the custom factory for creating WorkerInterface instances from a socket\n class StreamOutgoingFactory final: public Fetcher::OutgoingFactory {\n  public:\n   StreamOutgoingFactory(kj::Own<kj::AsyncIoStream> stream, const kj::HttpHeaderTable& headerTable)\n-      : stream(kj::mv(stream)),\n-        headerTable(headerTable) {}\n+      : httpClient(newHttpClient(headerTable, *stream)),\n+        stream(kj::mv(stream)) {}\n \n   kj::Own<WorkerInterface> newSingleUseClient(kj::Maybe<kj::String> cfStr) override {\n     JSG_ASSERT(stream.get() != nullptr, Error,\n         \"Fetcher created from internalNewHttpClient can only be used once\");\n     // Create a WorkerInterface that wraps the stream\n-    return kj::heap<StreamWorkerInterface>(kj::mv(stream), headerTable);\n+    return kj::heap<StreamWorkerInterface>(*httpClient);",
        "comment_created_at": "2025-08-18T20:56:02+00:00",
        "comment_author": "kentonv",
        "comment_body": "We need to make sure that the HttpClient and the underlying stream cannot be destroyed while the request is still in progress. Perhaps StreamOutgoingFactory should be refcounted and StreamWorkerInterface should be given a ref.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2055041698",
    "pr_number": 4005,
    "pr_file": "src/workerd/api/sockets.c++",
    "created_at": "2025-04-22T23:42:45+00:00",
    "commented_code": "jsg::Lock& js, AnySocketAddress address, jsg::Optional<SocketOptions> options) {\n   return connectImpl(js, kj::none, kj::mv(address), kj::mv(options));\n }\n+\n+// Definition of the StreamWorkerInterface class\n+class StreamWorkerInterface final: public WorkerInterface {\n+ public:\n+  StreamWorkerInterface(kj::Own<kj::AsyncIoStream> stream, const kj::HttpHeaderTable& headerTable)\n+      : stream(kj::mv(stream)),\n+        headerTable(headerTable) {}\n+\n+  kj::Promise<void> request(kj::HttpMethod method,\n+      kj::StringPtr url,\n+      const kj::HttpHeaders& headers,\n+      kj::AsyncInputStream& requestBody,\n+      kj::HttpService::Response& response) override {\n+    // Parse the URL to extract the path\n+    auto parsedUrl = KJ_REQUIRE_NONNULL(\n+        kj::Url::tryParse(url, kj::Url::Context::HTTP_PROXY_REQUEST), \"invalid url\", url);\n+\n+    // Create a new HTTP client using our stream\n+    auto httpClient = kj::newHttpClient(headerTable, *stream);\n+\n+    // Create a new HTTP service from the client\n+    auto service = kj::newHttpService(*httpClient);\n+\n+    // Prepare headers for the request\n+    auto newHeaders = headers.cloneShallow();\n+    newHeaders.set(kj::HttpHeaderId::HOST, parsedUrl.host);\n+\n+    // Get just the path portion for the request\n+    auto pathUrl = parsedUrl.toString(kj::Url::Context::HTTP_REQUEST);\n+\n+    // Forward the request to the service\n+    return service->request(method, pathUrl, newHeaders, requestBody, response)\n+        .attach(kj::mv(service), kj::mv(httpClient));\n+  }\n+\n+  kj::Promise<void> connect(kj::StringPtr host,\n+      const kj::HttpHeaders& headers,\n+      kj::AsyncIoStream& connection,\n+      ConnectResponse& response,\n+      kj::HttpConnectSettings settings) override {\n+    KJ_UNIMPLEMENTED(\"connect() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<void> prewarm(kj::StringPtr url) override {\n+    KJ_UNIMPLEMENTED(\"prewarm() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<ScheduledResult> runScheduled(kj::Date scheduledTime, kj::StringPtr cron) override {\n+    KJ_UNIMPLEMENTED(\"runScheduled() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<AlarmResult> runAlarm(kj::Date scheduledTime, uint32_t retryCount) override {\n+    KJ_UNIMPLEMENTED(\"runAlarm() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<CustomEvent::Result> customEvent(kj::Own<CustomEvent> event) override {\n+    return event->notSupported();\n+  }\n+\n+ private:\n+  kj::Own<kj::AsyncIoStream> stream;\n+  const kj::HttpHeaderTable& headerTable;\n+};\n+\n+// Implementation of the custom factory for creating WorkerInterface instances from a socket\n+class SocketOutgoingFactory final: public Fetcher::CrossContextOutgoingFactory {\n+ public:\n+  SocketOutgoingFactory(jsg::Ref<Socket> socket): socket(kj::mv(socket)) {}\n+\n+  kj::Own<WorkerInterface> newSingleUseClient(\n+      IoContext& context, kj::Maybe<kj::String> cfStr) override {\n+    // Create a WorkerInterface that wraps the stream\n+    // TODO(now): Is context.getHeaderTable() right here?\n+    return kj::heap<StreamWorkerInterface>(socket->getConnectionStream(), context.getHeaderTable())\n+        .attach(socket.addRef());\n+  }\n+\n+ private:\n+  jsg::Ref<Socket> socket;\n+};\n+\n+jsg::Ref<Fetcher> SocketsModule::createHttpClient(jsg::Lock& js, jsg::Ref<Socket> socket) {\n+  // Create our custom factory that will create client instances from this socket\n+  auto outgoingFactory = kj::heap<SocketOutgoingFactory>(socket.addRef());",
    "repo_full_name": "cloudflare/workerd",
    "discussion_comments": [
      {
        "comment_id": "2055041698",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 4005,
        "pr_file": "src/workerd/api/sockets.c++",
        "discussion_id": "2055041698",
        "commented_code": "@@ -511,4 +511,93 @@ jsg::Ref<Socket> SocketsModule::connect(\n     jsg::Lock& js, AnySocketAddress address, jsg::Optional<SocketOptions> options) {\n   return connectImpl(js, kj::none, kj::mv(address), kj::mv(options));\n }\n+\n+// Definition of the StreamWorkerInterface class\n+class StreamWorkerInterface final: public WorkerInterface {\n+ public:\n+  StreamWorkerInterface(kj::Own<kj::AsyncIoStream> stream, const kj::HttpHeaderTable& headerTable)\n+      : stream(kj::mv(stream)),\n+        headerTable(headerTable) {}\n+\n+  kj::Promise<void> request(kj::HttpMethod method,\n+      kj::StringPtr url,\n+      const kj::HttpHeaders& headers,\n+      kj::AsyncInputStream& requestBody,\n+      kj::HttpService::Response& response) override {\n+    // Parse the URL to extract the path\n+    auto parsedUrl = KJ_REQUIRE_NONNULL(\n+        kj::Url::tryParse(url, kj::Url::Context::HTTP_PROXY_REQUEST), \"invalid url\", url);\n+\n+    // Create a new HTTP client using our stream\n+    auto httpClient = kj::newHttpClient(headerTable, *stream);\n+\n+    // Create a new HTTP service from the client\n+    auto service = kj::newHttpService(*httpClient);\n+\n+    // Prepare headers for the request\n+    auto newHeaders = headers.cloneShallow();\n+    newHeaders.set(kj::HttpHeaderId::HOST, parsedUrl.host);\n+\n+    // Get just the path portion for the request\n+    auto pathUrl = parsedUrl.toString(kj::Url::Context::HTTP_REQUEST);\n+\n+    // Forward the request to the service\n+    return service->request(method, pathUrl, newHeaders, requestBody, response)\n+        .attach(kj::mv(service), kj::mv(httpClient));\n+  }\n+\n+  kj::Promise<void> connect(kj::StringPtr host,\n+      const kj::HttpHeaders& headers,\n+      kj::AsyncIoStream& connection,\n+      ConnectResponse& response,\n+      kj::HttpConnectSettings settings) override {\n+    KJ_UNIMPLEMENTED(\"connect() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<void> prewarm(kj::StringPtr url) override {\n+    KJ_UNIMPLEMENTED(\"prewarm() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<ScheduledResult> runScheduled(kj::Date scheduledTime, kj::StringPtr cron) override {\n+    KJ_UNIMPLEMENTED(\"runScheduled() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<AlarmResult> runAlarm(kj::Date scheduledTime, uint32_t retryCount) override {\n+    KJ_UNIMPLEMENTED(\"runAlarm() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<CustomEvent::Result> customEvent(kj::Own<CustomEvent> event) override {\n+    return event->notSupported();\n+  }\n+\n+ private:\n+  kj::Own<kj::AsyncIoStream> stream;\n+  const kj::HttpHeaderTable& headerTable;\n+};\n+\n+// Implementation of the custom factory for creating WorkerInterface instances from a socket\n+class SocketOutgoingFactory final: public Fetcher::CrossContextOutgoingFactory {\n+ public:\n+  SocketOutgoingFactory(jsg::Ref<Socket> socket): socket(kj::mv(socket)) {}\n+\n+  kj::Own<WorkerInterface> newSingleUseClient(\n+      IoContext& context, kj::Maybe<kj::String> cfStr) override {\n+    // Create a WorkerInterface that wraps the stream\n+    // TODO(now): Is context.getHeaderTable() right here?\n+    return kj::heap<StreamWorkerInterface>(socket->getConnectionStream(), context.getHeaderTable())\n+        .attach(socket.addRef());\n+  }\n+\n+ private:\n+  jsg::Ref<Socket> socket;\n+};\n+\n+jsg::Ref<Fetcher> SocketsModule::createHttpClient(jsg::Lock& js, jsg::Ref<Socket> socket) {\n+  // Create our custom factory that will create client instances from this socket\n+  auto outgoingFactory = kj::heap<SocketOutgoingFactory>(socket.addRef());",
        "comment_created_at": "2025-04-22T23:42:45+00:00",
        "comment_author": "jasnell",
        "comment_body": "This should check to make sure the `socket`'s `readable` or `writable` are not locked, and possibly not disturbed. It especially needs to check to ensure the socket is not closed, and probably needs to wait for the opened promise to be resolved.\r\n\r\nLocked indicates that there is `Reader` or `Writer` associated, in which case wrapping the socket should fail. Disturbed indicates that the socket has been written to or read from, indicating that it may not be in the correct state to be wrapped correctly.",
        "pr_file_module": null
      },
      {
        "comment_id": "2055048316",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 4005,
        "pr_file": "src/workerd/api/sockets.c++",
        "discussion_id": "2055041698",
        "commented_code": "@@ -511,4 +511,93 @@ jsg::Ref<Socket> SocketsModule::connect(\n     jsg::Lock& js, AnySocketAddress address, jsg::Optional<SocketOptions> options) {\n   return connectImpl(js, kj::none, kj::mv(address), kj::mv(options));\n }\n+\n+// Definition of the StreamWorkerInterface class\n+class StreamWorkerInterface final: public WorkerInterface {\n+ public:\n+  StreamWorkerInterface(kj::Own<kj::AsyncIoStream> stream, const kj::HttpHeaderTable& headerTable)\n+      : stream(kj::mv(stream)),\n+        headerTable(headerTable) {}\n+\n+  kj::Promise<void> request(kj::HttpMethod method,\n+      kj::StringPtr url,\n+      const kj::HttpHeaders& headers,\n+      kj::AsyncInputStream& requestBody,\n+      kj::HttpService::Response& response) override {\n+    // Parse the URL to extract the path\n+    auto parsedUrl = KJ_REQUIRE_NONNULL(\n+        kj::Url::tryParse(url, kj::Url::Context::HTTP_PROXY_REQUEST), \"invalid url\", url);\n+\n+    // Create a new HTTP client using our stream\n+    auto httpClient = kj::newHttpClient(headerTable, *stream);\n+\n+    // Create a new HTTP service from the client\n+    auto service = kj::newHttpService(*httpClient);\n+\n+    // Prepare headers for the request\n+    auto newHeaders = headers.cloneShallow();\n+    newHeaders.set(kj::HttpHeaderId::HOST, parsedUrl.host);\n+\n+    // Get just the path portion for the request\n+    auto pathUrl = parsedUrl.toString(kj::Url::Context::HTTP_REQUEST);\n+\n+    // Forward the request to the service\n+    return service->request(method, pathUrl, newHeaders, requestBody, response)\n+        .attach(kj::mv(service), kj::mv(httpClient));\n+  }\n+\n+  kj::Promise<void> connect(kj::StringPtr host,\n+      const kj::HttpHeaders& headers,\n+      kj::AsyncIoStream& connection,\n+      ConnectResponse& response,\n+      kj::HttpConnectSettings settings) override {\n+    KJ_UNIMPLEMENTED(\"connect() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<void> prewarm(kj::StringPtr url) override {\n+    KJ_UNIMPLEMENTED(\"prewarm() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<ScheduledResult> runScheduled(kj::Date scheduledTime, kj::StringPtr cron) override {\n+    KJ_UNIMPLEMENTED(\"runScheduled() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<AlarmResult> runAlarm(kj::Date scheduledTime, uint32_t retryCount) override {\n+    KJ_UNIMPLEMENTED(\"runAlarm() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<CustomEvent::Result> customEvent(kj::Own<CustomEvent> event) override {\n+    return event->notSupported();\n+  }\n+\n+ private:\n+  kj::Own<kj::AsyncIoStream> stream;\n+  const kj::HttpHeaderTable& headerTable;\n+};\n+\n+// Implementation of the custom factory for creating WorkerInterface instances from a socket\n+class SocketOutgoingFactory final: public Fetcher::CrossContextOutgoingFactory {\n+ public:\n+  SocketOutgoingFactory(jsg::Ref<Socket> socket): socket(kj::mv(socket)) {}\n+\n+  kj::Own<WorkerInterface> newSingleUseClient(\n+      IoContext& context, kj::Maybe<kj::String> cfStr) override {\n+    // Create a WorkerInterface that wraps the stream\n+    // TODO(now): Is context.getHeaderTable() right here?\n+    return kj::heap<StreamWorkerInterface>(socket->getConnectionStream(), context.getHeaderTable())\n+        .attach(socket.addRef());\n+  }\n+\n+ private:\n+  jsg::Ref<Socket> socket;\n+};\n+\n+jsg::Ref<Fetcher> SocketsModule::createHttpClient(jsg::Lock& js, jsg::Ref<Socket> socket) {\n+  // Create our custom factory that will create client instances from this socket\n+  auto outgoingFactory = kj::heap<SocketOutgoingFactory>(socket.addRef());",
        "comment_created_at": "2025-04-22T23:45:58+00:00",
        "comment_author": "jasnell",
        "comment_body": "We should probably also arrange it such that the returned `Fetcher` completely takes ownership over the `Socket` such that the `readable` and `writable` streams get closed/detached or locked so that nothing on the JS side mistakenly tries to access them while the socket it bound... e.g.\r\n\r\n```js\r\nconst socket = connect('...');\r\nconst fetcher = getHttpClient(socket);\r\nsocket.readable.getReader();  // should fail!\r\n```",
        "pr_file_module": null
      },
      {
        "comment_id": "2055053991",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 4005,
        "pr_file": "src/workerd/api/sockets.c++",
        "discussion_id": "2055041698",
        "commented_code": "@@ -511,4 +511,93 @@ jsg::Ref<Socket> SocketsModule::connect(\n     jsg::Lock& js, AnySocketAddress address, jsg::Optional<SocketOptions> options) {\n   return connectImpl(js, kj::none, kj::mv(address), kj::mv(options));\n }\n+\n+// Definition of the StreamWorkerInterface class\n+class StreamWorkerInterface final: public WorkerInterface {\n+ public:\n+  StreamWorkerInterface(kj::Own<kj::AsyncIoStream> stream, const kj::HttpHeaderTable& headerTable)\n+      : stream(kj::mv(stream)),\n+        headerTable(headerTable) {}\n+\n+  kj::Promise<void> request(kj::HttpMethod method,\n+      kj::StringPtr url,\n+      const kj::HttpHeaders& headers,\n+      kj::AsyncInputStream& requestBody,\n+      kj::HttpService::Response& response) override {\n+    // Parse the URL to extract the path\n+    auto parsedUrl = KJ_REQUIRE_NONNULL(\n+        kj::Url::tryParse(url, kj::Url::Context::HTTP_PROXY_REQUEST), \"invalid url\", url);\n+\n+    // Create a new HTTP client using our stream\n+    auto httpClient = kj::newHttpClient(headerTable, *stream);\n+\n+    // Create a new HTTP service from the client\n+    auto service = kj::newHttpService(*httpClient);\n+\n+    // Prepare headers for the request\n+    auto newHeaders = headers.cloneShallow();\n+    newHeaders.set(kj::HttpHeaderId::HOST, parsedUrl.host);\n+\n+    // Get just the path portion for the request\n+    auto pathUrl = parsedUrl.toString(kj::Url::Context::HTTP_REQUEST);\n+\n+    // Forward the request to the service\n+    return service->request(method, pathUrl, newHeaders, requestBody, response)\n+        .attach(kj::mv(service), kj::mv(httpClient));\n+  }\n+\n+  kj::Promise<void> connect(kj::StringPtr host,\n+      const kj::HttpHeaders& headers,\n+      kj::AsyncIoStream& connection,\n+      ConnectResponse& response,\n+      kj::HttpConnectSettings settings) override {\n+    KJ_UNIMPLEMENTED(\"connect() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<void> prewarm(kj::StringPtr url) override {\n+    KJ_UNIMPLEMENTED(\"prewarm() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<ScheduledResult> runScheduled(kj::Date scheduledTime, kj::StringPtr cron) override {\n+    KJ_UNIMPLEMENTED(\"runScheduled() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<AlarmResult> runAlarm(kj::Date scheduledTime, uint32_t retryCount) override {\n+    KJ_UNIMPLEMENTED(\"runAlarm() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<CustomEvent::Result> customEvent(kj::Own<CustomEvent> event) override {\n+    return event->notSupported();\n+  }\n+\n+ private:\n+  kj::Own<kj::AsyncIoStream> stream;\n+  const kj::HttpHeaderTable& headerTable;\n+};\n+\n+// Implementation of the custom factory for creating WorkerInterface instances from a socket\n+class SocketOutgoingFactory final: public Fetcher::CrossContextOutgoingFactory {\n+ public:\n+  SocketOutgoingFactory(jsg::Ref<Socket> socket): socket(kj::mv(socket)) {}\n+\n+  kj::Own<WorkerInterface> newSingleUseClient(\n+      IoContext& context, kj::Maybe<kj::String> cfStr) override {\n+    // Create a WorkerInterface that wraps the stream\n+    // TODO(now): Is context.getHeaderTable() right here?\n+    return kj::heap<StreamWorkerInterface>(socket->getConnectionStream(), context.getHeaderTable())\n+        .attach(socket.addRef());\n+  }\n+\n+ private:\n+  jsg::Ref<Socket> socket;\n+};\n+\n+jsg::Ref<Fetcher> SocketsModule::createHttpClient(jsg::Lock& js, jsg::Ref<Socket> socket) {\n+  // Create our custom factory that will create client instances from this socket\n+  auto outgoingFactory = kj::heap<SocketOutgoingFactory>(socket.addRef());",
        "comment_created_at": "2025-04-22T23:50:12+00:00",
        "comment_author": "jasnell",
        "comment_body": "As an additional bit of fun, since `fetch(...)` is cancelable using an AbortSignal, the tests need to verify that canceling a fetch via the returned Fetcher works as expected here. \r\n\r\nAlso, is the `Socket` expected to support multiple http requests or should it be closed when the one http request is finished? Would it be expected to support pipelining (I'd expect no). This would need to ensure that we don't end up with multiple concurrent http requests going over the socket at a time... e.g. \r\n\r\n```js\r\nconst socket = connect('...');\r\nconst fetcher = getHttpClient(socket);\r\nawait Promise.all([ fetcher.fetch('...'), fetcher.fetch('...') ]);\r\n```\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2055061146",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 4005,
        "pr_file": "src/workerd/api/sockets.c++",
        "discussion_id": "2055041698",
        "commented_code": "@@ -511,4 +511,93 @@ jsg::Ref<Socket> SocketsModule::connect(\n     jsg::Lock& js, AnySocketAddress address, jsg::Optional<SocketOptions> options) {\n   return connectImpl(js, kj::none, kj::mv(address), kj::mv(options));\n }\n+\n+// Definition of the StreamWorkerInterface class\n+class StreamWorkerInterface final: public WorkerInterface {\n+ public:\n+  StreamWorkerInterface(kj::Own<kj::AsyncIoStream> stream, const kj::HttpHeaderTable& headerTable)\n+      : stream(kj::mv(stream)),\n+        headerTable(headerTable) {}\n+\n+  kj::Promise<void> request(kj::HttpMethod method,\n+      kj::StringPtr url,\n+      const kj::HttpHeaders& headers,\n+      kj::AsyncInputStream& requestBody,\n+      kj::HttpService::Response& response) override {\n+    // Parse the URL to extract the path\n+    auto parsedUrl = KJ_REQUIRE_NONNULL(\n+        kj::Url::tryParse(url, kj::Url::Context::HTTP_PROXY_REQUEST), \"invalid url\", url);\n+\n+    // Create a new HTTP client using our stream\n+    auto httpClient = kj::newHttpClient(headerTable, *stream);\n+\n+    // Create a new HTTP service from the client\n+    auto service = kj::newHttpService(*httpClient);\n+\n+    // Prepare headers for the request\n+    auto newHeaders = headers.cloneShallow();\n+    newHeaders.set(kj::HttpHeaderId::HOST, parsedUrl.host);\n+\n+    // Get just the path portion for the request\n+    auto pathUrl = parsedUrl.toString(kj::Url::Context::HTTP_REQUEST);\n+\n+    // Forward the request to the service\n+    return service->request(method, pathUrl, newHeaders, requestBody, response)\n+        .attach(kj::mv(service), kj::mv(httpClient));\n+  }\n+\n+  kj::Promise<void> connect(kj::StringPtr host,\n+      const kj::HttpHeaders& headers,\n+      kj::AsyncIoStream& connection,\n+      ConnectResponse& response,\n+      kj::HttpConnectSettings settings) override {\n+    KJ_UNIMPLEMENTED(\"connect() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<void> prewarm(kj::StringPtr url) override {\n+    KJ_UNIMPLEMENTED(\"prewarm() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<ScheduledResult> runScheduled(kj::Date scheduledTime, kj::StringPtr cron) override {\n+    KJ_UNIMPLEMENTED(\"runScheduled() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<AlarmResult> runAlarm(kj::Date scheduledTime, uint32_t retryCount) override {\n+    KJ_UNIMPLEMENTED(\"runAlarm() not supported on StreamWorkerInterface\");\n+  }\n+\n+  kj::Promise<CustomEvent::Result> customEvent(kj::Own<CustomEvent> event) override {\n+    return event->notSupported();\n+  }\n+\n+ private:\n+  kj::Own<kj::AsyncIoStream> stream;\n+  const kj::HttpHeaderTable& headerTable;\n+};\n+\n+// Implementation of the custom factory for creating WorkerInterface instances from a socket\n+class SocketOutgoingFactory final: public Fetcher::CrossContextOutgoingFactory {\n+ public:\n+  SocketOutgoingFactory(jsg::Ref<Socket> socket): socket(kj::mv(socket)) {}\n+\n+  kj::Own<WorkerInterface> newSingleUseClient(\n+      IoContext& context, kj::Maybe<kj::String> cfStr) override {\n+    // Create a WorkerInterface that wraps the stream\n+    // TODO(now): Is context.getHeaderTable() right here?\n+    return kj::heap<StreamWorkerInterface>(socket->getConnectionStream(), context.getHeaderTable())\n+        .attach(socket.addRef());\n+  }\n+\n+ private:\n+  jsg::Ref<Socket> socket;\n+};\n+\n+jsg::Ref<Fetcher> SocketsModule::createHttpClient(jsg::Lock& js, jsg::Ref<Socket> socket) {\n+  // Create our custom factory that will create client instances from this socket\n+  auto outgoingFactory = kj::heap<SocketOutgoingFactory>(socket.addRef());",
        "comment_created_at": "2025-04-23T00:01:41+00:00",
        "comment_author": "danlapid",
        "comment_body": "A few comments here.\r\nRegarding the state of socket when receiving control and after. I left it a bit vague because this is intended to be an internal API only used by one worker really, I don't mind amending the implementation to make it a bit more safe in this regard though.\r\n\r\nSocket is expected to support multiple http requests and there's even a test case for it.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2254825203",
    "pr_number": 4005,
    "pr_file": "src/workerd/api/sockets.c++",
    "created_at": "2025-08-05T16:43:25+00:00",
    "commented_code": "jsg::Lock& js, AnySocketAddress address, jsg::Optional<SocketOptions> options) {\n   return connectImpl(js, kj::none, kj::mv(address), kj::mv(options));\n }\n+\n+kj::Own<kj::AsyncIoStream> Socket::takeConnectionStream(jsg::Lock& js) {\n+  writable->detach(js);\n+  readable->detach(js);",
    "repo_full_name": "cloudflare/workerd",
    "discussion_comments": [
      {
        "comment_id": "2254825203",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 4005,
        "pr_file": "src/workerd/api/sockets.c++",
        "discussion_id": "2254825203",
        "commented_code": "@@ -511,4 +513,117 @@ jsg::Ref<Socket> SocketsModule::connect(\n     jsg::Lock& js, AnySocketAddress address, jsg::Optional<SocketOptions> options) {\n   return connectImpl(js, kj::none, kj::mv(address), kj::mv(options));\n }\n+\n+kj::Own<kj::AsyncIoStream> Socket::takeConnectionStream(jsg::Lock& js) {\n+  writable->detach(js);\n+  readable->detach(js);",
        "comment_created_at": "2025-08-05T16:43:25+00:00",
        "comment_author": "jasnell",
        "comment_body": "Both of these require that there aren't pending reads or writes in flight and will throw if there are. Just want to make sure that's accounted for here. When a socket is in the middle of a starttls upgrade, for instance, we make sure things are drained before proceeding with the upgrade and detaching the original streams. This is to ensure that the streams are in a good state to actually be detached.\r\n\r\nThis likely also needs to account for whether a starttls operation is underway, the socket is already closed, etc... basically just some additional guards around whether the socket is in a good state overall to have the underlying connection removed.",
        "pr_file_module": null
      },
      {
        "comment_id": "2254884819",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 4005,
        "pr_file": "src/workerd/api/sockets.c++",
        "discussion_id": "2254825203",
        "commented_code": "@@ -511,4 +513,117 @@ jsg::Ref<Socket> SocketsModule::connect(\n     jsg::Lock& js, AnySocketAddress address, jsg::Optional<SocketOptions> options) {\n   return connectImpl(js, kj::none, kj::mv(address), kj::mv(options));\n }\n+\n+kj::Own<kj::AsyncIoStream> Socket::takeConnectionStream(jsg::Lock& js) {\n+  writable->detach(js);\n+  readable->detach(js);",
        "comment_created_at": "2025-08-05T17:07:41+00:00",
        "comment_author": "tewaro",
        "comment_body": "I can add a test that checks what happens when starttls is called, and then the conversion.",
        "pr_file_module": null
      },
      {
        "comment_id": "2258141611",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 4005,
        "pr_file": "src/workerd/api/sockets.c++",
        "discussion_id": "2254825203",
        "commented_code": "@@ -511,4 +513,117 @@ jsg::Ref<Socket> SocketsModule::connect(\n     jsg::Lock& js, AnySocketAddress address, jsg::Optional<SocketOptions> options) {\n   return connectImpl(js, kj::none, kj::mv(address), kj::mv(options));\n }\n+\n+kj::Own<kj::AsyncIoStream> Socket::takeConnectionStream(jsg::Lock& js) {\n+  writable->detach(js);\n+  readable->detach(js);",
        "comment_created_at": "2025-08-06T19:53:46+00:00",
        "comment_author": "jasnell",
        "comment_body": "Let's also add a comment in here so folks coming into the code later can have a heads up about the requirements.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2017377138",
    "pr_number": 3813,
    "pr_file": "src/workerd/api/messagechannel.c++",
    "created_at": "2025-03-27T18:14:35+00:00",
    "commented_code": "+#include \"messagechannel.h\"\n+\n+#include \"global-scope.h\"\n+#include \"worker-rpc.h\"\n+\n+#include <workerd/io/worker.h>\n+#include <workerd/jsg/ser.h>\n+\n+#include <capnp/message.h>\n+\n+namespace workerd::api {\n+jsg::Ref<MessagePort::MessageEvent> MessagePort::MessageEvent::New(jsg::Lock& js,\n+    jsg::JsRef<jsg::JsValue> data,\n+    kj::String lastEventId,\n+    jsg::Ref<MessagePort> source,\n+    kj::Array<jsg::Ref<MessagePort>> ports) {\n+  return jsg::alloc<MessagePort::MessageEvent>(\n+      kj::str(\"message\"), kj::mv(data), kj::mv(lastEventId), kj::mv(source), kj::mv(ports));\n+}\n+\n+jsg::Ref<MessagePort::MessageEvent> MessagePort::MessageEvent::NewError(jsg::Lock& js,\n+    jsg::JsRef<jsg::JsValue> data,\n+    kj::String lastEventId,\n+    jsg::Ref<MessagePort> source,\n+    kj::Array<jsg::Ref<MessagePort>> ports) {\n+  return jsg::alloc<MessagePort::MessageEvent>(\n+      kj::str(\"messageerror\"), kj::mv(data), kj::mv(lastEventId), kj::mv(source), kj::mv(ports));\n+}\n+\n+MessagePort::MessagePort(IoContext& ioContext): ioContext(ioContext), state(Pending()) {\n+  // We set a callback on the underlying EventTarget to be notified when\n+  // a listener for the message event is added or removed. When there\n+  // are no listeners, we move back to the Pending state, otherwise we\n+  // will switch to the Started state if necessary.\n+  setEventListenerCallback([&](jsg::Lock& js, kj::StringPtr name, size_t count) {\n+    if (name == \"message\"_kj) {\n+      KJ_SWITCH_ONEOF(state) {\n+        KJ_CASE_ONEOF(pending, Pending) {\n+          // If we are in the pending state, start the port if we have listeners.\n+          // This is technically not spec compliant, but it is what Node.js\n+          // supports. Specifically, adding a new message listener using the\n+          // addEventListener method is *technically* not supposed to start\n+          // the port but we're going to do what Node.js does.\n+          if (count > 0 || onmessageValue != kj::none) {\n+            start(js);\n+          }\n+        }\n+        KJ_CASE_ONEOF(started, Started) {\n+          // If we are in the started state, stop the port if there are no listeners.\n+          if (count == 0 && onmessageValue == kj::none) {\n+            state = Pending();\n+          }\n+        }\n+        KJ_CASE_ONEOF(_, Closed) {\n+          // Nothing to do. We're already closed so we don't care.\n+        }\n+      }\n+    }\n+  });\n+}\n+\n+// Deliver the message to the \"message\" or \"messageerror\" event on this port.\n+void MessagePort::deliver(\n+    jsg::Lock& js, kj::Own<rpc::JsValue::Reader> message, jsg::Ref<MessagePort> port) {\n+  auto event = js.tryCatch([&] {\n+    jsg::Deserializer deserializer(js, message->getV8Serialized());\n+    return MessageEvent::New(\n+        js, jsg::JsRef(js, deserializer.readValue(js)), kj::str(), port->addRef(), {});\n+  }, [&](jsg::Value exception) {\n+    return MessageEvent::NewError(\n+        js, jsg::JsRef(js, jsg::JsValue(exception.getHandle(js))), kj::str(), port->addRef(), {});\n+  });\n+\n+  // If any of the message/messageerror event handlers throw,\n+  // capture the error and pass it to reportError instead of\n+  // propagating up.\n+  js.tryCatch([&] { port->dispatchEventImpl(js, kj::mv(event)); }, [&](jsg::Value exception) {\n+    auto context = js.v8Context();\n+    auto& global =\n+        jsg::extractInternalPointer<ServiceWorkerGlobalScope, true>(context, context->Global());\n+    global.reportError(js, jsg::JsValue(exception.getHandle(js)));\n+  });\n+}\n+\n+// Deliver the message to all the jsrpc remotes we have\n+kj::Promise<void> MessagePort::sendToRpc(kj::Own<rpc::JsValue::Reader> message) {\n+  KJ_IF_SOME(outputLocks, ioContext.waitForOutputLocksIfNecessary()) {\n+    co_await outputLocks;\n+  }\n+  kj::Vector<kj::Promise<void>> promises;\n+  for (rpc::JsMessagePort::Client cap: rpcClients) {\n+    auto req = cap.callRequest();\n+    req.setData(*message);\n+    // TODO(message-port): Removing the port when dropped?\n+    promises.add(req.send().ignoreResult());\n+  }\n+  co_await kj::joinPromises(promises.releaseAsArray());\n+}\n+\n+// Deliver the message to this port, buffering if necessary if the port\n+// has not been started. Buffered messages will be delivered when the\n+// port is started later.\n+void MessagePort::deliverMessage(jsg::Lock& js, rpc::JsValue::Reader value) {\n+  KJ_SWITCH_ONEOF(state) {\n+    KJ_CASE_ONEOF(pending, Pending) {\n+      // We have not yet started the port so buffer to message.\n+      pending.add(capnp::clone(value));\n+    }\n+    KJ_CASE_ONEOF(started, Started) {\n+      ioContext.addTask(sendToRpc(capnp::clone(value)));\n+      deliver(js, capnp::clone(value), addRef());\n+    }\n+    KJ_CASE_ONEOF(_, Closed) {\n+      // Nothing to do in this case. Drop the message on the floor.\n+    }\n+  }\n+}\n+\n+// Binds two ports to each other such that messages posted to one\n+// are delivered on the other.\n+void MessagePort::entangle(MessagePort& port1, MessagePort& port2) {\n+  port1.other = port2.addRef();",
    "repo_full_name": "cloudflare/workerd",
    "discussion_comments": [
      {
        "comment_id": "2017377138",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 3813,
        "pr_file": "src/workerd/api/messagechannel.c++",
        "discussion_id": "2017377138",
        "commented_code": "@@ -0,0 +1,317 @@\n+#include \"messagechannel.h\"\n+\n+#include \"global-scope.h\"\n+#include \"worker-rpc.h\"\n+\n+#include <workerd/io/worker.h>\n+#include <workerd/jsg/ser.h>\n+\n+#include <capnp/message.h>\n+\n+namespace workerd::api {\n+jsg::Ref<MessagePort::MessageEvent> MessagePort::MessageEvent::New(jsg::Lock& js,\n+    jsg::JsRef<jsg::JsValue> data,\n+    kj::String lastEventId,\n+    jsg::Ref<MessagePort> source,\n+    kj::Array<jsg::Ref<MessagePort>> ports) {\n+  return jsg::alloc<MessagePort::MessageEvent>(\n+      kj::str(\"message\"), kj::mv(data), kj::mv(lastEventId), kj::mv(source), kj::mv(ports));\n+}\n+\n+jsg::Ref<MessagePort::MessageEvent> MessagePort::MessageEvent::NewError(jsg::Lock& js,\n+    jsg::JsRef<jsg::JsValue> data,\n+    kj::String lastEventId,\n+    jsg::Ref<MessagePort> source,\n+    kj::Array<jsg::Ref<MessagePort>> ports) {\n+  return jsg::alloc<MessagePort::MessageEvent>(\n+      kj::str(\"messageerror\"), kj::mv(data), kj::mv(lastEventId), kj::mv(source), kj::mv(ports));\n+}\n+\n+MessagePort::MessagePort(IoContext& ioContext): ioContext(ioContext), state(Pending()) {\n+  // We set a callback on the underlying EventTarget to be notified when\n+  // a listener for the message event is added or removed. When there\n+  // are no listeners, we move back to the Pending state, otherwise we\n+  // will switch to the Started state if necessary.\n+  setEventListenerCallback([&](jsg::Lock& js, kj::StringPtr name, size_t count) {\n+    if (name == \"message\"_kj) {\n+      KJ_SWITCH_ONEOF(state) {\n+        KJ_CASE_ONEOF(pending, Pending) {\n+          // If we are in the pending state, start the port if we have listeners.\n+          // This is technically not spec compliant, but it is what Node.js\n+          // supports. Specifically, adding a new message listener using the\n+          // addEventListener method is *technically* not supposed to start\n+          // the port but we're going to do what Node.js does.\n+          if (count > 0 || onmessageValue != kj::none) {\n+            start(js);\n+          }\n+        }\n+        KJ_CASE_ONEOF(started, Started) {\n+          // If we are in the started state, stop the port if there are no listeners.\n+          if (count == 0 && onmessageValue == kj::none) {\n+            state = Pending();\n+          }\n+        }\n+        KJ_CASE_ONEOF(_, Closed) {\n+          // Nothing to do. We're already closed so we don't care.\n+        }\n+      }\n+    }\n+  });\n+}\n+\n+// Deliver the message to the \"message\" or \"messageerror\" event on this port.\n+void MessagePort::deliver(\n+    jsg::Lock& js, kj::Own<rpc::JsValue::Reader> message, jsg::Ref<MessagePort> port) {\n+  auto event = js.tryCatch([&] {\n+    jsg::Deserializer deserializer(js, message->getV8Serialized());\n+    return MessageEvent::New(\n+        js, jsg::JsRef(js, deserializer.readValue(js)), kj::str(), port->addRef(), {});\n+  }, [&](jsg::Value exception) {\n+    return MessageEvent::NewError(\n+        js, jsg::JsRef(js, jsg::JsValue(exception.getHandle(js))), kj::str(), port->addRef(), {});\n+  });\n+\n+  // If any of the message/messageerror event handlers throw,\n+  // capture the error and pass it to reportError instead of\n+  // propagating up.\n+  js.tryCatch([&] { port->dispatchEventImpl(js, kj::mv(event)); }, [&](jsg::Value exception) {\n+    auto context = js.v8Context();\n+    auto& global =\n+        jsg::extractInternalPointer<ServiceWorkerGlobalScope, true>(context, context->Global());\n+    global.reportError(js, jsg::JsValue(exception.getHandle(js)));\n+  });\n+}\n+\n+// Deliver the message to all the jsrpc remotes we have\n+kj::Promise<void> MessagePort::sendToRpc(kj::Own<rpc::JsValue::Reader> message) {\n+  KJ_IF_SOME(outputLocks, ioContext.waitForOutputLocksIfNecessary()) {\n+    co_await outputLocks;\n+  }\n+  kj::Vector<kj::Promise<void>> promises;\n+  for (rpc::JsMessagePort::Client cap: rpcClients) {\n+    auto req = cap.callRequest();\n+    req.setData(*message);\n+    // TODO(message-port): Removing the port when dropped?\n+    promises.add(req.send().ignoreResult());\n+  }\n+  co_await kj::joinPromises(promises.releaseAsArray());\n+}\n+\n+// Deliver the message to this port, buffering if necessary if the port\n+// has not been started. Buffered messages will be delivered when the\n+// port is started later.\n+void MessagePort::deliverMessage(jsg::Lock& js, rpc::JsValue::Reader value) {\n+  KJ_SWITCH_ONEOF(state) {\n+    KJ_CASE_ONEOF(pending, Pending) {\n+      // We have not yet started the port so buffer to message.\n+      pending.add(capnp::clone(value));\n+    }\n+    KJ_CASE_ONEOF(started, Started) {\n+      ioContext.addTask(sendToRpc(capnp::clone(value)));\n+      deliver(js, capnp::clone(value), addRef());\n+    }\n+    KJ_CASE_ONEOF(_, Closed) {\n+      // Nothing to do in this case. Drop the message on the floor.\n+    }\n+  }\n+}\n+\n+// Binds two ports to each other such that messages posted to one\n+// are delivered on the other.\n+void MessagePort::entangle(MessagePort& port1, MessagePort& port2) {\n+  port1.other = port2.addRef();",
        "comment_created_at": "2025-03-27T18:14:35+00:00",
        "comment_author": "anonrig",
        "comment_body": "This has a bug. If this port is entangled with another port, we should disentangle first. If not, port3 that is entangled with port1 will still be entangled with port1, even though port1 is entangled with port2.\r\n\r\nStep 1 of entangle spec step: https://html.spec.whatwg.org/multipage/web-messaging.html#entangle",
        "pr_file_module": null
      },
      {
        "comment_id": "2017378943",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 3813,
        "pr_file": "src/workerd/api/messagechannel.c++",
        "discussion_id": "2017377138",
        "commented_code": "@@ -0,0 +1,317 @@\n+#include \"messagechannel.h\"\n+\n+#include \"global-scope.h\"\n+#include \"worker-rpc.h\"\n+\n+#include <workerd/io/worker.h>\n+#include <workerd/jsg/ser.h>\n+\n+#include <capnp/message.h>\n+\n+namespace workerd::api {\n+jsg::Ref<MessagePort::MessageEvent> MessagePort::MessageEvent::New(jsg::Lock& js,\n+    jsg::JsRef<jsg::JsValue> data,\n+    kj::String lastEventId,\n+    jsg::Ref<MessagePort> source,\n+    kj::Array<jsg::Ref<MessagePort>> ports) {\n+  return jsg::alloc<MessagePort::MessageEvent>(\n+      kj::str(\"message\"), kj::mv(data), kj::mv(lastEventId), kj::mv(source), kj::mv(ports));\n+}\n+\n+jsg::Ref<MessagePort::MessageEvent> MessagePort::MessageEvent::NewError(jsg::Lock& js,\n+    jsg::JsRef<jsg::JsValue> data,\n+    kj::String lastEventId,\n+    jsg::Ref<MessagePort> source,\n+    kj::Array<jsg::Ref<MessagePort>> ports) {\n+  return jsg::alloc<MessagePort::MessageEvent>(\n+      kj::str(\"messageerror\"), kj::mv(data), kj::mv(lastEventId), kj::mv(source), kj::mv(ports));\n+}\n+\n+MessagePort::MessagePort(IoContext& ioContext): ioContext(ioContext), state(Pending()) {\n+  // We set a callback on the underlying EventTarget to be notified when\n+  // a listener for the message event is added or removed. When there\n+  // are no listeners, we move back to the Pending state, otherwise we\n+  // will switch to the Started state if necessary.\n+  setEventListenerCallback([&](jsg::Lock& js, kj::StringPtr name, size_t count) {\n+    if (name == \"message\"_kj) {\n+      KJ_SWITCH_ONEOF(state) {\n+        KJ_CASE_ONEOF(pending, Pending) {\n+          // If we are in the pending state, start the port if we have listeners.\n+          // This is technically not spec compliant, but it is what Node.js\n+          // supports. Specifically, adding a new message listener using the\n+          // addEventListener method is *technically* not supposed to start\n+          // the port but we're going to do what Node.js does.\n+          if (count > 0 || onmessageValue != kj::none) {\n+            start(js);\n+          }\n+        }\n+        KJ_CASE_ONEOF(started, Started) {\n+          // If we are in the started state, stop the port if there are no listeners.\n+          if (count == 0 && onmessageValue == kj::none) {\n+            state = Pending();\n+          }\n+        }\n+        KJ_CASE_ONEOF(_, Closed) {\n+          // Nothing to do. We're already closed so we don't care.\n+        }\n+      }\n+    }\n+  });\n+}\n+\n+// Deliver the message to the \"message\" or \"messageerror\" event on this port.\n+void MessagePort::deliver(\n+    jsg::Lock& js, kj::Own<rpc::JsValue::Reader> message, jsg::Ref<MessagePort> port) {\n+  auto event = js.tryCatch([&] {\n+    jsg::Deserializer deserializer(js, message->getV8Serialized());\n+    return MessageEvent::New(\n+        js, jsg::JsRef(js, deserializer.readValue(js)), kj::str(), port->addRef(), {});\n+  }, [&](jsg::Value exception) {\n+    return MessageEvent::NewError(\n+        js, jsg::JsRef(js, jsg::JsValue(exception.getHandle(js))), kj::str(), port->addRef(), {});\n+  });\n+\n+  // If any of the message/messageerror event handlers throw,\n+  // capture the error and pass it to reportError instead of\n+  // propagating up.\n+  js.tryCatch([&] { port->dispatchEventImpl(js, kj::mv(event)); }, [&](jsg::Value exception) {\n+    auto context = js.v8Context();\n+    auto& global =\n+        jsg::extractInternalPointer<ServiceWorkerGlobalScope, true>(context, context->Global());\n+    global.reportError(js, jsg::JsValue(exception.getHandle(js)));\n+  });\n+}\n+\n+// Deliver the message to all the jsrpc remotes we have\n+kj::Promise<void> MessagePort::sendToRpc(kj::Own<rpc::JsValue::Reader> message) {\n+  KJ_IF_SOME(outputLocks, ioContext.waitForOutputLocksIfNecessary()) {\n+    co_await outputLocks;\n+  }\n+  kj::Vector<kj::Promise<void>> promises;\n+  for (rpc::JsMessagePort::Client cap: rpcClients) {\n+    auto req = cap.callRequest();\n+    req.setData(*message);\n+    // TODO(message-port): Removing the port when dropped?\n+    promises.add(req.send().ignoreResult());\n+  }\n+  co_await kj::joinPromises(promises.releaseAsArray());\n+}\n+\n+// Deliver the message to this port, buffering if necessary if the port\n+// has not been started. Buffered messages will be delivered when the\n+// port is started later.\n+void MessagePort::deliverMessage(jsg::Lock& js, rpc::JsValue::Reader value) {\n+  KJ_SWITCH_ONEOF(state) {\n+    KJ_CASE_ONEOF(pending, Pending) {\n+      // We have not yet started the port so buffer to message.\n+      pending.add(capnp::clone(value));\n+    }\n+    KJ_CASE_ONEOF(started, Started) {\n+      ioContext.addTask(sendToRpc(capnp::clone(value)));\n+      deliver(js, capnp::clone(value), addRef());\n+    }\n+    KJ_CASE_ONEOF(_, Closed) {\n+      // Nothing to do in this case. Drop the message on the floor.\n+    }\n+  }\n+}\n+\n+// Binds two ports to each other such that messages posted to one\n+// are delivered on the other.\n+void MessagePort::entangle(MessagePort& port1, MessagePort& port2) {\n+  port1.other = port2.addRef();",
        "comment_created_at": "2025-03-27T18:15:08+00:00",
        "comment_author": "anonrig",
        "comment_body": "Also disentangle should emit \"close\" event which in this case it never emits.",
        "pr_file_module": null
      },
      {
        "comment_id": "2017420032",
        "repo_full_name": "cloudflare/workerd",
        "pr_number": 3813,
        "pr_file": "src/workerd/api/messagechannel.c++",
        "discussion_id": "2017377138",
        "commented_code": "@@ -0,0 +1,317 @@\n+#include \"messagechannel.h\"\n+\n+#include \"global-scope.h\"\n+#include \"worker-rpc.h\"\n+\n+#include <workerd/io/worker.h>\n+#include <workerd/jsg/ser.h>\n+\n+#include <capnp/message.h>\n+\n+namespace workerd::api {\n+jsg::Ref<MessagePort::MessageEvent> MessagePort::MessageEvent::New(jsg::Lock& js,\n+    jsg::JsRef<jsg::JsValue> data,\n+    kj::String lastEventId,\n+    jsg::Ref<MessagePort> source,\n+    kj::Array<jsg::Ref<MessagePort>> ports) {\n+  return jsg::alloc<MessagePort::MessageEvent>(\n+      kj::str(\"message\"), kj::mv(data), kj::mv(lastEventId), kj::mv(source), kj::mv(ports));\n+}\n+\n+jsg::Ref<MessagePort::MessageEvent> MessagePort::MessageEvent::NewError(jsg::Lock& js,\n+    jsg::JsRef<jsg::JsValue> data,\n+    kj::String lastEventId,\n+    jsg::Ref<MessagePort> source,\n+    kj::Array<jsg::Ref<MessagePort>> ports) {\n+  return jsg::alloc<MessagePort::MessageEvent>(\n+      kj::str(\"messageerror\"), kj::mv(data), kj::mv(lastEventId), kj::mv(source), kj::mv(ports));\n+}\n+\n+MessagePort::MessagePort(IoContext& ioContext): ioContext(ioContext), state(Pending()) {\n+  // We set a callback on the underlying EventTarget to be notified when\n+  // a listener for the message event is added or removed. When there\n+  // are no listeners, we move back to the Pending state, otherwise we\n+  // will switch to the Started state if necessary.\n+  setEventListenerCallback([&](jsg::Lock& js, kj::StringPtr name, size_t count) {\n+    if (name == \"message\"_kj) {\n+      KJ_SWITCH_ONEOF(state) {\n+        KJ_CASE_ONEOF(pending, Pending) {\n+          // If we are in the pending state, start the port if we have listeners.\n+          // This is technically not spec compliant, but it is what Node.js\n+          // supports. Specifically, adding a new message listener using the\n+          // addEventListener method is *technically* not supposed to start\n+          // the port but we're going to do what Node.js does.\n+          if (count > 0 || onmessageValue != kj::none) {\n+            start(js);\n+          }\n+        }\n+        KJ_CASE_ONEOF(started, Started) {\n+          // If we are in the started state, stop the port if there are no listeners.\n+          if (count == 0 && onmessageValue == kj::none) {\n+            state = Pending();\n+          }\n+        }\n+        KJ_CASE_ONEOF(_, Closed) {\n+          // Nothing to do. We're already closed so we don't care.\n+        }\n+      }\n+    }\n+  });\n+}\n+\n+// Deliver the message to the \"message\" or \"messageerror\" event on this port.\n+void MessagePort::deliver(\n+    jsg::Lock& js, kj::Own<rpc::JsValue::Reader> message, jsg::Ref<MessagePort> port) {\n+  auto event = js.tryCatch([&] {\n+    jsg::Deserializer deserializer(js, message->getV8Serialized());\n+    return MessageEvent::New(\n+        js, jsg::JsRef(js, deserializer.readValue(js)), kj::str(), port->addRef(), {});\n+  }, [&](jsg::Value exception) {\n+    return MessageEvent::NewError(\n+        js, jsg::JsRef(js, jsg::JsValue(exception.getHandle(js))), kj::str(), port->addRef(), {});\n+  });\n+\n+  // If any of the message/messageerror event handlers throw,\n+  // capture the error and pass it to reportError instead of\n+  // propagating up.\n+  js.tryCatch([&] { port->dispatchEventImpl(js, kj::mv(event)); }, [&](jsg::Value exception) {\n+    auto context = js.v8Context();\n+    auto& global =\n+        jsg::extractInternalPointer<ServiceWorkerGlobalScope, true>(context, context->Global());\n+    global.reportError(js, jsg::JsValue(exception.getHandle(js)));\n+  });\n+}\n+\n+// Deliver the message to all the jsrpc remotes we have\n+kj::Promise<void> MessagePort::sendToRpc(kj::Own<rpc::JsValue::Reader> message) {\n+  KJ_IF_SOME(outputLocks, ioContext.waitForOutputLocksIfNecessary()) {\n+    co_await outputLocks;\n+  }\n+  kj::Vector<kj::Promise<void>> promises;\n+  for (rpc::JsMessagePort::Client cap: rpcClients) {\n+    auto req = cap.callRequest();\n+    req.setData(*message);\n+    // TODO(message-port): Removing the port when dropped?\n+    promises.add(req.send().ignoreResult());\n+  }\n+  co_await kj::joinPromises(promises.releaseAsArray());\n+}\n+\n+// Deliver the message to this port, buffering if necessary if the port\n+// has not been started. Buffered messages will be delivered when the\n+// port is started later.\n+void MessagePort::deliverMessage(jsg::Lock& js, rpc::JsValue::Reader value) {\n+  KJ_SWITCH_ONEOF(state) {\n+    KJ_CASE_ONEOF(pending, Pending) {\n+      // We have not yet started the port so buffer to message.\n+      pending.add(capnp::clone(value));\n+    }\n+    KJ_CASE_ONEOF(started, Started) {\n+      ioContext.addTask(sendToRpc(capnp::clone(value)));\n+      deliver(js, capnp::clone(value), addRef());\n+    }\n+    KJ_CASE_ONEOF(_, Closed) {\n+      // Nothing to do in this case. Drop the message on the floor.\n+    }\n+  }\n+}\n+\n+// Binds two ports to each other such that messages posted to one\n+// are delivered on the other.\n+void MessagePort::entangle(MessagePort& port1, MessagePort& port2) {\n+  port1.other = port2.addRef();",
        "comment_created_at": "2025-03-27T18:36:15+00:00",
        "comment_author": "jasnell",
        "comment_body": "That shouldn't ever happen. If anything, this should just assert if the port is already entangled, but in every use of this currently there's no way for the ports to already be entangled.",
        "pr_file_module": null
      }
    ]
  }
]