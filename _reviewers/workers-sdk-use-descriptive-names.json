[
  {
    "discussion_id": "2204289226",
    "pr_number": 9861,
    "pr_file": "packages/wrangler/src/__tests__/pages/pages-deployment-tail.test.ts",
    "created_at": "2025-07-14T09:00:08+00:00",
    "commented_code": "/**\n  * Similarly, we need to deserialize from a raw buffer instead\n- * of just JSON.parsing a raw string. This deserializer also then\n- * re-stringifies with some spacing, the same way wrangler tail does.\n+ * of just JSON.parsing a raw string.\n  *\n  * @param message a buffer of data received from the websocket\n- * @returns a string ready to be printed to the terminal or compared against\n+ * @returns a JSON object ready to be compared against\n  */\n-function deserializeToJson(message: WebSocket.RawData): string {\n-\treturn JSON.stringify(JSON.parse(message.toString()), null, 2);\n+function deserializeToJson(message: WebSocket.RawData) {",
    "repo_full_name": "cloudflare/workers-sdk",
    "discussion_comments": [
      {
        "comment_id": "2204289226",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 9861,
        "pr_file": "packages/wrangler/src/__tests__/pages/pages-deployment-tail.test.ts",
        "discussion_id": "2204289226",
        "commented_code": "@@ -849,14 +849,13 @@ function isRequest(event: TailEventMessageType): event is RequestEvent {\n \n /**\n  * Similarly, we need to deserialize from a raw buffer instead\n- * of just JSON.parsing a raw string. This deserializer also then\n- * re-stringifies with some spacing, the same way wrangler tail does.\n+ * of just JSON.parsing a raw string.\n  *\n  * @param message a buffer of data received from the websocket\n- * @returns a string ready to be printed to the terminal or compared against\n+ * @returns a JSON object ready to be compared against\n  */\n-function deserializeToJson(message: WebSocket.RawData): string {\n-\treturn JSON.stringify(JSON.parse(message.toString()), null, 2);\n+function deserializeToJson(message: WebSocket.RawData) {",
        "comment_created_at": "2025-07-14T09:00:08+00:00",
        "comment_author": "alsuren",
        "comment_body": "Since we're no longer re-serializing it **to** json:\r\n\r\n```suggestion\r\nfunction deserializeJson(message: WebSocket.RawData) {\r\n```\r\n\r\nor\r\n\r\n```suggestion\r\nfunction deserializeJsonMessage(message: WebSocket.RawData) {\r\n```\r\n\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2204292430",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 9861,
        "pr_file": "packages/wrangler/src/__tests__/pages/pages-deployment-tail.test.ts",
        "discussion_id": "2204289226",
        "commented_code": "@@ -849,14 +849,13 @@ function isRequest(event: TailEventMessageType): event is RequestEvent {\n \n /**\n  * Similarly, we need to deserialize from a raw buffer instead\n- * of just JSON.parsing a raw string. This deserializer also then\n- * re-stringifies with some spacing, the same way wrangler tail does.\n+ * of just JSON.parsing a raw string.\n  *\n  * @param message a buffer of data received from the websocket\n- * @returns a string ready to be printed to the terminal or compared against\n+ * @returns a JSON object ready to be compared against\n  */\n-function deserializeToJson(message: WebSocket.RawData): string {\n-\treturn JSON.stringify(JSON.parse(message.toString()), null, 2);\n+function deserializeToJson(message: WebSocket.RawData) {",
        "comment_created_at": "2025-07-14T09:01:36+00:00",
        "comment_author": "alsuren",
        "comment_body": "Same in the file below.",
        "pr_file_module": null
      },
      {
        "comment_id": "2204802872",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 9861,
        "pr_file": "packages/wrangler/src/__tests__/pages/pages-deployment-tail.test.ts",
        "discussion_id": "2204289226",
        "commented_code": "@@ -849,14 +849,13 @@ function isRequest(event: TailEventMessageType): event is RequestEvent {\n \n /**\n  * Similarly, we need to deserialize from a raw buffer instead\n- * of just JSON.parsing a raw string. This deserializer also then\n- * re-stringifies with some spacing, the same way wrangler tail does.\n+ * of just JSON.parsing a raw string.\n  *\n  * @param message a buffer of data received from the websocket\n- * @returns a string ready to be printed to the terminal or compared against\n+ * @returns a JSON object ready to be compared against\n  */\n-function deserializeToJson(message: WebSocket.RawData): string {\n-\treturn JSON.stringify(JSON.parse(message.toString()), null, 2);\n+function deserializeToJson(message: WebSocket.RawData) {",
        "comment_created_at": "2025-07-14T12:34:15+00:00",
        "comment_author": "petebacondarwin",
        "comment_body": "0971a8877",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2077417170",
    "pr_number": 8886,
    "pr_file": "packages/create-cloudflare/src/workers.ts",
    "created_at": "2025-05-07T11:28:18+00:00",
    "commented_code": "import { join } from \"path\";\n import { warn } from \"@cloudflare/cli\";\n import { brandColor, dim } from \"@cloudflare/cli/colors\";\n-import { spinner } from \"@cloudflare/cli/interactive\";\n+import TOML from \"@iarna/toml\";\n+import { runCommand } from \"helpers/command\";\n import { getLatestTypesEntrypoint } from \"helpers/compatDate\";\n-import { readFile, usesTypescript, writeFile } from \"helpers/files\";\n+import { readFile, readJSON, usesTypescript, writeFile } from \"helpers/files\";\n import { detectPackageManager } from \"helpers/packageManagers\";\n import { installPackages } from \"helpers/packages\";\n+import { parse as jsoncParse } from \"jsonc-parser\";\n import * as jsonc from \"jsonc-parser\";\n-import type { C3Context } from \"types\";\n+import {\n+\treadWranglerJson,\n+\treadWranglerToml,\n+\twranglerJsonExists,\n+\twranglerTomlExists,\n+} from \"./wrangler/config\";\n+import type { C3Context, PackageJson } from \"types\";\n \n /**\n- * Installs the latest version of the `@cloudflare/workers-types` package\n- * and updates the .tsconfig file to use the latest entrypoint version.\n+ * Generate types using the `cf-typegen` script and update tsconfig\n  */\n-export async function installWorkersTypes(ctx: C3Context) {\n-\tconst { npm } = detectPackageManager();\n \n+export async function generateWorkersTypes(ctx: C3Context) {\n \tif (!usesTypescript(ctx)) {\n \t\treturn;\n \t}\n+\tconst packageJsonPath = join(ctx.project.path, \"package.json\");\n+\tif (!existsSync(packageJsonPath)) {\n+\t\treturn;\n+\t}\n+\tconst packageManifest = readJSON(packageJsonPath) as PackageJson;\n+\tif (!packageManifest.scripts?.[\"cf-typegen\"]) {\n+\t\treturn;\n+\t}\n \n-\tawait installPackages([\"@cloudflare/workers-types\"], {\n-\t\tdev: true,\n-\t\tstartText: \"Installing @cloudflare/workers-types\",\n-\t\tdoneText: `${brandColor(\"installed\")} ${dim(`via ${npm}`)}`,\n+\tconst { npm } = detectPackageManager();\n+\n+\tconst typesCmd = [npm, \"run\", \"cf-typegen\"];\n+\n+\tawait runCommand(typesCmd, {\n+\t\tcwd: ctx.project.path,\n+\t\tsilent: true,\n+\t\tstartText: \"Generating types for your application\",\n+\t\tdoneText: `${brandColor(\"generated\")} ${dim(`to \\`${ctx.template.typesPath}\\` via \\`${typesCmd.join(\" \")}\\``)}`,\n \t});\n-\tawait addWorkersTypesToTsConfig(ctx);\n+\n+\tconst usesNodeCompat = await maybeInstallNodeTypes(ctx, npm);\n+\n+\tdelete packageManifest[\"devDependencies\"]?.[\"@cloudflare/workers-types\"];\n+\n+\twriteFile(packageJsonPath, JSON.stringify(packageManifest, null, 2));\n+\tawait updateTsConfig(ctx, usesNodeCompat);\n }\n \n-export async function addWorkersTypesToTsConfig(ctx: C3Context) {\n-\tconst tsconfigPath = join(ctx.project.path, \"tsconfig.json\");\n-\tif (!existsSync(tsconfigPath)) {\n-\t\treturn;\n+const maybeInstallNodeTypes = async (ctx: C3Context, npm: string) => {\n+\tlet parsedConfig: Record<string, unknown> = {};\n+\tif (wranglerJsonExists(ctx)) {\n+\t\tconst wranglerJsonStr = readWranglerJson(ctx);\n+\t\tparsedConfig = jsoncParse(wranglerJsonStr, undefined, {\n+\t\t\tallowTrailingComma: true,\n+\t\t});\n+\t} else if (wranglerTomlExists(ctx)) {\n+\t\tconst wranglerTomlStr = readWranglerToml(ctx);\n+\t\tparsedConfig = TOML.parse(wranglerTomlStr);\n \t}\n \n-\tconst s = spinner();\n-\ts.start(\"Adding latest types to `tsconfig.json`\");\n+\tconst compatibility_flags = Array.isArray(parsedConfig[\"compatibility_flags\"])\n+\t\t? parsedConfig[\"compatibility_flags\"]\n+\t\t: [];\n \n-\tconst tsconfig = readFile(tsconfigPath);\n-\tconst entrypointVersion = getLatestTypesEntrypoint(ctx);\n-\tif (entrypointVersion === null) {\n-\t\ts.stop(\n-\t\t\t`${brandColor(\n-\t\t\t\t\"skipped\",\n-\t\t\t)} couldn't find latest compatible version of @cloudflare/workers-types`,\n-\t\t);\n-\t\treturn;\n+\tif (\n+\t\tcompatibility_flags.includes(\"nodejs_compat\") ||\n+\t\tcompatibility_flags.includes(\"nodejs_compat_v2\")\n+\t) {\n+\t\tawait installPackages([\"@types/node\"], {\n+\t\t\tdev: true,\n+\t\t\tstartText: \"Installing @types/node\",\n+\t\t\tdoneText: `${brandColor(\"installed\")} ${dim(`via ${npm}`)}`,\n+\t\t});\n+\t\treturn true;\n \t}\n+\treturn false;\n+};\n \n-\tconst typesEntrypoint = `@cloudflare/workers-types/${entrypointVersion}`;\n-\n+/**\n+ * update `types` in tsconfig:\n+ * - set workers-types to latest entrypoint if installed\n+ * - remove workers-types if runtime types have been generated\n+ * - add generated types file if types were generated\n+ * - add node if node compat\n+ */\n+export async function updateTsConfig(ctx: C3Context, usesNodeCompat: boolean) {",
    "repo_full_name": "cloudflare/workers-sdk",
    "discussion_comments": [
      {
        "comment_id": "2077417170",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 8886,
        "pr_file": "packages/create-cloudflare/src/workers.ts",
        "discussion_id": "2077417170",
        "commented_code": "@@ -2,73 +2,145 @@ import { existsSync } from \"fs\";\n import { join } from \"path\";\n import { warn } from \"@cloudflare/cli\";\n import { brandColor, dim } from \"@cloudflare/cli/colors\";\n-import { spinner } from \"@cloudflare/cli/interactive\";\n+import TOML from \"@iarna/toml\";\n+import { runCommand } from \"helpers/command\";\n import { getLatestTypesEntrypoint } from \"helpers/compatDate\";\n-import { readFile, usesTypescript, writeFile } from \"helpers/files\";\n+import { readFile, readJSON, usesTypescript, writeFile } from \"helpers/files\";\n import { detectPackageManager } from \"helpers/packageManagers\";\n import { installPackages } from \"helpers/packages\";\n+import { parse as jsoncParse } from \"jsonc-parser\";\n import * as jsonc from \"jsonc-parser\";\n-import type { C3Context } from \"types\";\n+import {\n+\treadWranglerJson,\n+\treadWranglerToml,\n+\twranglerJsonExists,\n+\twranglerTomlExists,\n+} from \"./wrangler/config\";\n+import type { C3Context, PackageJson } from \"types\";\n \n /**\n- * Installs the latest version of the `@cloudflare/workers-types` package\n- * and updates the .tsconfig file to use the latest entrypoint version.\n+ * Generate types using the `cf-typegen` script and update tsconfig\n  */\n-export async function installWorkersTypes(ctx: C3Context) {\n-\tconst { npm } = detectPackageManager();\n \n+export async function generateWorkersTypes(ctx: C3Context) {\n \tif (!usesTypescript(ctx)) {\n \t\treturn;\n \t}\n+\tconst packageJsonPath = join(ctx.project.path, \"package.json\");\n+\tif (!existsSync(packageJsonPath)) {\n+\t\treturn;\n+\t}\n+\tconst packageManifest = readJSON(packageJsonPath) as PackageJson;\n+\tif (!packageManifest.scripts?.[\"cf-typegen\"]) {\n+\t\treturn;\n+\t}\n \n-\tawait installPackages([\"@cloudflare/workers-types\"], {\n-\t\tdev: true,\n-\t\tstartText: \"Installing @cloudflare/workers-types\",\n-\t\tdoneText: `${brandColor(\"installed\")} ${dim(`via ${npm}`)}`,\n+\tconst { npm } = detectPackageManager();\n+\n+\tconst typesCmd = [npm, \"run\", \"cf-typegen\"];\n+\n+\tawait runCommand(typesCmd, {\n+\t\tcwd: ctx.project.path,\n+\t\tsilent: true,\n+\t\tstartText: \"Generating types for your application\",\n+\t\tdoneText: `${brandColor(\"generated\")} ${dim(`to \\`${ctx.template.typesPath}\\` via \\`${typesCmd.join(\" \")}\\``)}`,\n \t});\n-\tawait addWorkersTypesToTsConfig(ctx);\n+\n+\tconst usesNodeCompat = await maybeInstallNodeTypes(ctx, npm);\n+\n+\tdelete packageManifest[\"devDependencies\"]?.[\"@cloudflare/workers-types\"];\n+\n+\twriteFile(packageJsonPath, JSON.stringify(packageManifest, null, 2));\n+\tawait updateTsConfig(ctx, usesNodeCompat);\n }\n \n-export async function addWorkersTypesToTsConfig(ctx: C3Context) {\n-\tconst tsconfigPath = join(ctx.project.path, \"tsconfig.json\");\n-\tif (!existsSync(tsconfigPath)) {\n-\t\treturn;\n+const maybeInstallNodeTypes = async (ctx: C3Context, npm: string) => {\n+\tlet parsedConfig: Record<string, unknown> = {};\n+\tif (wranglerJsonExists(ctx)) {\n+\t\tconst wranglerJsonStr = readWranglerJson(ctx);\n+\t\tparsedConfig = jsoncParse(wranglerJsonStr, undefined, {\n+\t\t\tallowTrailingComma: true,\n+\t\t});\n+\t} else if (wranglerTomlExists(ctx)) {\n+\t\tconst wranglerTomlStr = readWranglerToml(ctx);\n+\t\tparsedConfig = TOML.parse(wranglerTomlStr);\n \t}\n \n-\tconst s = spinner();\n-\ts.start(\"Adding latest types to `tsconfig.json`\");\n+\tconst compatibility_flags = Array.isArray(parsedConfig[\"compatibility_flags\"])\n+\t\t? parsedConfig[\"compatibility_flags\"]\n+\t\t: [];\n \n-\tconst tsconfig = readFile(tsconfigPath);\n-\tconst entrypointVersion = getLatestTypesEntrypoint(ctx);\n-\tif (entrypointVersion === null) {\n-\t\ts.stop(\n-\t\t\t`${brandColor(\n-\t\t\t\t\"skipped\",\n-\t\t\t)} couldn't find latest compatible version of @cloudflare/workers-types`,\n-\t\t);\n-\t\treturn;\n+\tif (\n+\t\tcompatibility_flags.includes(\"nodejs_compat\") ||\n+\t\tcompatibility_flags.includes(\"nodejs_compat_v2\")\n+\t) {\n+\t\tawait installPackages([\"@types/node\"], {\n+\t\t\tdev: true,\n+\t\t\tstartText: \"Installing @types/node\",\n+\t\t\tdoneText: `${brandColor(\"installed\")} ${dim(`via ${npm}`)}`,\n+\t\t});\n+\t\treturn true;\n \t}\n+\treturn false;\n+};\n \n-\tconst typesEntrypoint = `@cloudflare/workers-types/${entrypointVersion}`;\n-\n+/**\n+ * update `types` in tsconfig:\n+ * - set workers-types to latest entrypoint if installed\n+ * - remove workers-types if runtime types have been generated\n+ * - add generated types file if types were generated\n+ * - add node if node compat\n+ */\n+export async function updateTsConfig(ctx: C3Context, usesNodeCompat: boolean) {",
        "comment_created_at": "2025-05-07T11:28:18+00:00",
        "comment_author": "vicb",
        "comment_body": "I like to write this as\r\n\r\n```\r\n// no default value\r\nupdateTsConfig(ctx: C3Context, {usesNodeCompat} : {usesNodeCompat: boolean})\r\n\r\n// default value\r\nupdateTsConfig(ctx: C3Context, {usesNodeCompat = true} = {})\r\n```\r\n\r\nbecause `updateTsConfig(ctx, {usesNodeCompat: true})` has a better semantic than `updateTsConfig(ctx, true)`\r\n\r\n(especially true when you have `fn(ctx, true, true, 2)`)\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "2077749950",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 8886,
        "pr_file": "packages/create-cloudflare/src/workers.ts",
        "discussion_id": "2077417170",
        "commented_code": "@@ -2,73 +2,145 @@ import { existsSync } from \"fs\";\n import { join } from \"path\";\n import { warn } from \"@cloudflare/cli\";\n import { brandColor, dim } from \"@cloudflare/cli/colors\";\n-import { spinner } from \"@cloudflare/cli/interactive\";\n+import TOML from \"@iarna/toml\";\n+import { runCommand } from \"helpers/command\";\n import { getLatestTypesEntrypoint } from \"helpers/compatDate\";\n-import { readFile, usesTypescript, writeFile } from \"helpers/files\";\n+import { readFile, readJSON, usesTypescript, writeFile } from \"helpers/files\";\n import { detectPackageManager } from \"helpers/packageManagers\";\n import { installPackages } from \"helpers/packages\";\n+import { parse as jsoncParse } from \"jsonc-parser\";\n import * as jsonc from \"jsonc-parser\";\n-import type { C3Context } from \"types\";\n+import {\n+\treadWranglerJson,\n+\treadWranglerToml,\n+\twranglerJsonExists,\n+\twranglerTomlExists,\n+} from \"./wrangler/config\";\n+import type { C3Context, PackageJson } from \"types\";\n \n /**\n- * Installs the latest version of the `@cloudflare/workers-types` package\n- * and updates the .tsconfig file to use the latest entrypoint version.\n+ * Generate types using the `cf-typegen` script and update tsconfig\n  */\n-export async function installWorkersTypes(ctx: C3Context) {\n-\tconst { npm } = detectPackageManager();\n \n+export async function generateWorkersTypes(ctx: C3Context) {\n \tif (!usesTypescript(ctx)) {\n \t\treturn;\n \t}\n+\tconst packageJsonPath = join(ctx.project.path, \"package.json\");\n+\tif (!existsSync(packageJsonPath)) {\n+\t\treturn;\n+\t}\n+\tconst packageManifest = readJSON(packageJsonPath) as PackageJson;\n+\tif (!packageManifest.scripts?.[\"cf-typegen\"]) {\n+\t\treturn;\n+\t}\n \n-\tawait installPackages([\"@cloudflare/workers-types\"], {\n-\t\tdev: true,\n-\t\tstartText: \"Installing @cloudflare/workers-types\",\n-\t\tdoneText: `${brandColor(\"installed\")} ${dim(`via ${npm}`)}`,\n+\tconst { npm } = detectPackageManager();\n+\n+\tconst typesCmd = [npm, \"run\", \"cf-typegen\"];\n+\n+\tawait runCommand(typesCmd, {\n+\t\tcwd: ctx.project.path,\n+\t\tsilent: true,\n+\t\tstartText: \"Generating types for your application\",\n+\t\tdoneText: `${brandColor(\"generated\")} ${dim(`to \\`${ctx.template.typesPath}\\` via \\`${typesCmd.join(\" \")}\\``)}`,\n \t});\n-\tawait addWorkersTypesToTsConfig(ctx);\n+\n+\tconst usesNodeCompat = await maybeInstallNodeTypes(ctx, npm);\n+\n+\tdelete packageManifest[\"devDependencies\"]?.[\"@cloudflare/workers-types\"];\n+\n+\twriteFile(packageJsonPath, JSON.stringify(packageManifest, null, 2));\n+\tawait updateTsConfig(ctx, usesNodeCompat);\n }\n \n-export async function addWorkersTypesToTsConfig(ctx: C3Context) {\n-\tconst tsconfigPath = join(ctx.project.path, \"tsconfig.json\");\n-\tif (!existsSync(tsconfigPath)) {\n-\t\treturn;\n+const maybeInstallNodeTypes = async (ctx: C3Context, npm: string) => {\n+\tlet parsedConfig: Record<string, unknown> = {};\n+\tif (wranglerJsonExists(ctx)) {\n+\t\tconst wranglerJsonStr = readWranglerJson(ctx);\n+\t\tparsedConfig = jsoncParse(wranglerJsonStr, undefined, {\n+\t\t\tallowTrailingComma: true,\n+\t\t});\n+\t} else if (wranglerTomlExists(ctx)) {\n+\t\tconst wranglerTomlStr = readWranglerToml(ctx);\n+\t\tparsedConfig = TOML.parse(wranglerTomlStr);\n \t}\n \n-\tconst s = spinner();\n-\ts.start(\"Adding latest types to `tsconfig.json`\");\n+\tconst compatibility_flags = Array.isArray(parsedConfig[\"compatibility_flags\"])\n+\t\t? parsedConfig[\"compatibility_flags\"]\n+\t\t: [];\n \n-\tconst tsconfig = readFile(tsconfigPath);\n-\tconst entrypointVersion = getLatestTypesEntrypoint(ctx);\n-\tif (entrypointVersion === null) {\n-\t\ts.stop(\n-\t\t\t`${brandColor(\n-\t\t\t\t\"skipped\",\n-\t\t\t)} couldn't find latest compatible version of @cloudflare/workers-types`,\n-\t\t);\n-\t\treturn;\n+\tif (\n+\t\tcompatibility_flags.includes(\"nodejs_compat\") ||\n+\t\tcompatibility_flags.includes(\"nodejs_compat_v2\")\n+\t) {\n+\t\tawait installPackages([\"@types/node\"], {\n+\t\t\tdev: true,\n+\t\t\tstartText: \"Installing @types/node\",\n+\t\t\tdoneText: `${brandColor(\"installed\")} ${dim(`via ${npm}`)}`,\n+\t\t});\n+\t\treturn true;\n \t}\n+\treturn false;\n+};\n \n-\tconst typesEntrypoint = `@cloudflare/workers-types/${entrypointVersion}`;\n-\n+/**\n+ * update `types` in tsconfig:\n+ * - set workers-types to latest entrypoint if installed\n+ * - remove workers-types if runtime types have been generated\n+ * - add generated types file if types were generated\n+ * - add node if node compat\n+ */\n+export async function updateTsConfig(ctx: C3Context, usesNodeCompat: boolean) {",
        "comment_created_at": "2025-05-07T14:20:51+00:00",
        "comment_author": "emily-shen",
        "comment_body": "fair enough, i'm always mildly annoyed about how verbose it is to name arguments in javascript so I tend to rely on my editor showing the type \ud83d\ude05 ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1880665167",
    "pr_number": 7241,
    "pr_file": "packages/create-cloudflare/src/templates.ts",
    "created_at": "2024-12-11T18:00:08+00:00",
    "commented_code": "* to handle config version skew between different versions of c3\n \t */\n \tconfigVersion: number;\n-\t/** The id by which template is referred to internally and keyed in lookup maps*/\n+\t/** The id by which template is referred to internally and keyed in lookup maps */\n \tid: string;\n-\t/** A string that controls how the template is presented to the user in the selection menu*/\n+\t/** A string that controls how the template is presented to the user in the selection menu */\n \tdisplayName: string;\n-\t/** A string that explains what is inside the template, including any resources and how those will be used*/\n+\t/** A string that explains what is inside the template, including any resources and how those will be used */\n \tdescription?: string;\n \t/** The deployment platform for this template */\n \tplatform: \"workers\" | \"pages\";\n-\t/** The name of the framework cli tool that is used to generate this project or undefined if none. */\n+\t/** The name of the framework cli tool that is used to generate this project or undefined if none */\n \tframeworkCli?: string;\n+\t/**\n+\t * A specific version of the framework cli tool to use instead of the standard one taken from the src/frameworks/package.json\n+\t * (which gets managed and bumped by dependabot)\n+\t */\n+\tpinFrameworkCli?: string;",
    "repo_full_name": "cloudflare/workers-sdk",
    "discussion_comments": [
      {
        "comment_id": "1880665167",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 7241,
        "pr_file": "packages/create-cloudflare/src/templates.ts",
        "discussion_id": "1880665167",
        "commented_code": "@@ -65,16 +65,21 @@ export type TemplateConfig = {\n \t * to handle config version skew between different versions of c3\n \t */\n \tconfigVersion: number;\n-\t/** The id by which template is referred to internally and keyed in lookup maps*/\n+\t/** The id by which template is referred to internally and keyed in lookup maps */\n \tid: string;\n-\t/** A string that controls how the template is presented to the user in the selection menu*/\n+\t/** A string that controls how the template is presented to the user in the selection menu */\n \tdisplayName: string;\n-\t/** A string that explains what is inside the template, including any resources and how those will be used*/\n+\t/** A string that explains what is inside the template, including any resources and how those will be used */\n \tdescription?: string;\n \t/** The deployment platform for this template */\n \tplatform: \"workers\" | \"pages\";\n-\t/** The name of the framework cli tool that is used to generate this project or undefined if none. */\n+\t/** The name of the framework cli tool that is used to generate this project or undefined if none */\n \tframeworkCli?: string;\n+\t/**\n+\t * A specific version of the framework cli tool to use instead of the standard one taken from the src/frameworks/package.json\n+\t * (which gets managed and bumped by dependabot)\n+\t */\n+\tpinFrameworkCli?: string;",
        "comment_created_at": "2024-12-11T18:00:08+00:00",
        "comment_author": "vicb",
        "comment_body": "nit on the name: pin<...> make me think Boolean. Why not framewokCliPinnedVersion ?",
        "pr_file_module": null
      },
      {
        "comment_id": "1880668202",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 7241,
        "pr_file": "packages/create-cloudflare/src/templates.ts",
        "discussion_id": "1880665167",
        "commented_code": "@@ -65,16 +65,21 @@ export type TemplateConfig = {\n \t * to handle config version skew between different versions of c3\n \t */\n \tconfigVersion: number;\n-\t/** The id by which template is referred to internally and keyed in lookup maps*/\n+\t/** The id by which template is referred to internally and keyed in lookup maps */\n \tid: string;\n-\t/** A string that controls how the template is presented to the user in the selection menu*/\n+\t/** A string that controls how the template is presented to the user in the selection menu */\n \tdisplayName: string;\n-\t/** A string that explains what is inside the template, including any resources and how those will be used*/\n+\t/** A string that explains what is inside the template, including any resources and how those will be used */\n \tdescription?: string;\n \t/** The deployment platform for this template */\n \tplatform: \"workers\" | \"pages\";\n-\t/** The name of the framework cli tool that is used to generate this project or undefined if none. */\n+\t/** The name of the framework cli tool that is used to generate this project or undefined if none */\n \tframeworkCli?: string;\n+\t/**\n+\t * A specific version of the framework cli tool to use instead of the standard one taken from the src/frameworks/package.json\n+\t * (which gets managed and bumped by dependabot)\n+\t */\n+\tpinFrameworkCli?: string;",
        "comment_created_at": "2024-12-11T18:02:08+00:00",
        "comment_author": "petebacondarwin",
        "comment_body": "Any of these work fine for me.",
        "pr_file_module": null
      },
      {
        "comment_id": "1880673767",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 7241,
        "pr_file": "packages/create-cloudflare/src/templates.ts",
        "discussion_id": "1880665167",
        "commented_code": "@@ -65,16 +65,21 @@ export type TemplateConfig = {\n \t * to handle config version skew between different versions of c3\n \t */\n \tconfigVersion: number;\n-\t/** The id by which template is referred to internally and keyed in lookup maps*/\n+\t/** The id by which template is referred to internally and keyed in lookup maps */\n \tid: string;\n-\t/** A string that controls how the template is presented to the user in the selection menu*/\n+\t/** A string that controls how the template is presented to the user in the selection menu */\n \tdisplayName: string;\n-\t/** A string that explains what is inside the template, including any resources and how those will be used*/\n+\t/** A string that explains what is inside the template, including any resources and how those will be used */\n \tdescription?: string;\n \t/** The deployment platform for this template */\n \tplatform: \"workers\" | \"pages\";\n-\t/** The name of the framework cli tool that is used to generate this project or undefined if none. */\n+\t/** The name of the framework cli tool that is used to generate this project or undefined if none */\n \tframeworkCli?: string;\n+\t/**\n+\t * A specific version of the framework cli tool to use instead of the standard one taken from the src/frameworks/package.json\n+\t * (which gets managed and bumped by dependabot)\n+\t */\n+\tpinFrameworkCli?: string;",
        "comment_created_at": "2024-12-11T18:06:39+00:00",
        "comment_author": "dario-piotrowicz",
        "comment_body": "renamed \ud83d\ude42\ud83d\udc4d ",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1863731167",
    "pr_number": 7291,
    "pr_file": "packages/wrangler/src/metrics/metrics-dispatcher.ts",
    "created_at": "2024-11-29T16:09:06+00:00",
    "commented_code": "*  - additional properties are camelCased\n \t\t */\n \t\tasync sendEvent(name: string, properties: Properties = {}): Promise<void> {\n-\t\t\tawait dispatch({ type: \"event\", name, properties });\n+\t\t\tawait dispatch({\n+\t\t\t\tname,\n+\t\t\t\tproperties: {\n+\t\t\t\t\tcategory: \"Workers\",\n+\t\t\t\t\twranglerVersion,\n+\t\t\t\t\tos: getOS(),\n+\t\t\t\t\t...properties,\n+\t\t\t\t},\n+\t\t\t});\n \t\t},\n \n \t\t/**\n-\t\t * Dispatch a user profile information to the analytics target.\n+\t\t * Dispatches `wrangler command started / completed / errored` events",
    "repo_full_name": "cloudflare/workers-sdk",
    "discussion_comments": [
      {
        "comment_id": "1863731167",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 7291,
        "pr_file": "packages/wrangler/src/metrics/metrics-dispatcher.ts",
        "discussion_id": "1863731167",
        "commented_code": "@@ -19,62 +56,105 @@ export async function getMetricsDispatcher(options: MetricsConfigOptions) {\n \t\t *  - additional properties are camelCased\n \t\t */\n \t\tasync sendEvent(name: string, properties: Properties = {}): Promise<void> {\n-\t\t\tawait dispatch({ type: \"event\", name, properties });\n+\t\t\tawait dispatch({\n+\t\t\t\tname,\n+\t\t\t\tproperties: {\n+\t\t\t\t\tcategory: \"Workers\",\n+\t\t\t\t\twranglerVersion,\n+\t\t\t\t\tos: getOS(),\n+\t\t\t\t\t...properties,\n+\t\t\t\t},\n+\t\t\t});\n \t\t},\n \n \t\t/**\n-\t\t * Dispatch a user profile information to the analytics target.\n+\t\t * Dispatches `wrangler command started / completed / errored` events",
        "comment_created_at": "2024-11-29T16:09:06+00:00",
        "comment_author": "penalosa",
        "comment_body": "I'm a bit confused by this naming. Why do we have a `sendNewEvent()` and also a `sendEvent()`?",
        "pr_file_module": null
      },
      {
        "comment_id": "1867744327",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 7291,
        "pr_file": "packages/wrangler/src/metrics/metrics-dispatcher.ts",
        "discussion_id": "1863731167",
        "commented_code": "@@ -19,62 +56,105 @@ export async function getMetricsDispatcher(options: MetricsConfigOptions) {\n \t\t *  - additional properties are camelCased\n \t\t */\n \t\tasync sendEvent(name: string, properties: Properties = {}): Promise<void> {\n-\t\t\tawait dispatch({ type: \"event\", name, properties });\n+\t\t\tawait dispatch({\n+\t\t\t\tname,\n+\t\t\t\tproperties: {\n+\t\t\t\t\tcategory: \"Workers\",\n+\t\t\t\t\twranglerVersion,\n+\t\t\t\t\tos: getOS(),\n+\t\t\t\t\t...properties,\n+\t\t\t\t},\n+\t\t\t});\n \t\t},\n \n \t\t/**\n-\t\t * Dispatch a user profile information to the analytics target.\n+\t\t * Dispatches `wrangler command started / completed / errored` events",
        "comment_created_at": "2024-12-03T13:42:46+00:00",
        "comment_author": "emily-shen",
        "comment_body": "renamed to sendAdhocEvent and sendCommandEvent c9ecdf82702dfe76c7867597e41b9ef39855261a\r\n\r\nwith the hope that once defineCommand is done we can combine them. tbh we could combine them now but probably not worth the effort at this stage",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1983615066",
    "pr_number": 7334,
    "pr_file": "packages/wrangler/src/dev/remote.ts",
    "created_at": "2025-03-06T15:52:54+00:00",
    "commented_code": "props.modules\n \t);\n \n-\tconst legacyAssets = await syncLegacyAssets(\n+\tconst legacyAssets = await syncWorkersSite(",
    "repo_full_name": "cloudflare/workers-sdk",
    "discussion_comments": [
      {
        "comment_id": "1983615066",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 7334,
        "pr_file": "packages/wrangler/src/dev/remote.ts",
        "discussion_id": "1983615066",
        "commented_code": "@@ -114,7 +114,7 @@ export async function createRemoteWorkerInit(props: {\n \t\tprops.modules\n \t);\n \n-\tconst legacyAssets = await syncLegacyAssets(\n+\tconst legacyAssets = await syncWorkersSite(",
        "comment_created_at": "2025-03-06T15:52:54+00:00",
        "comment_author": "petebacondarwin",
        "comment_body": "NIT: rename `legacyAssets` to `workersSitesAssets`?",
        "pr_file_module": null
      },
      {
        "comment_id": "1983854019",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 7334,
        "pr_file": "packages/wrangler/src/dev/remote.ts",
        "discussion_id": "1983615066",
        "commented_code": "@@ -114,7 +114,7 @@ export async function createRemoteWorkerInit(props: {\n \t\tprops.modules\n \t);\n \n-\tconst legacyAssets = await syncLegacyAssets(\n+\tconst legacyAssets = await syncWorkersSite(",
        "comment_created_at": "2025-03-06T18:21:58+00:00",
        "comment_author": "penalosa",
        "comment_body": "2bc289e2e",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1847059815",
    "pr_number": 7285,
    "pr_file": "packages/wrangler/src/deployment-bundle/resolve-entry.ts",
    "created_at": "2024-11-18T18:22:06+00:00",
    "commented_code": "): {\n \tabsolutePath: string;\n \trelativePath: string;\n+\tdirectory: string;",
    "repo_full_name": "cloudflare/workers-sdk",
    "discussion_comments": [
      {
        "comment_id": "1847059815",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 7285,
        "pr_file": "packages/wrangler/src/deployment-bundle/resolve-entry.ts",
        "discussion_id": "1847059815",
        "commented_code": "@@ -16,11 +16,12 @@ export function resolveEntryWithMain(\n ): {\n \tabsolutePath: string;\n \trelativePath: string;\n+\tdirectory: string;",
        "comment_created_at": "2024-11-18T18:22:06+00:00",
        "comment_author": "petebacondarwin",
        "comment_body": "Can we call this `projectRoot`? Will simplify code elsewhere and is more descriptive than `directory` which could be a directory of anything.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1775758788",
    "pr_number": 6824,
    "pr_file": "packages/miniflare/src/plugins/core/modules.ts",
    "created_at": "2024-09-25T18:26:27+00:00",
    "commented_code": "export class ModuleLocator {\n \treadonly #compiledRules: CompiledModuleRule[];\n-\treadonly #nodejsCompat: boolean;\n+\treadonly #nodejsCompat: NodeJSCompatMode;\n \treadonly #visitedPaths = new Set<string>();\n \treadonly modules: Worker_Module[] = [];\n \n \tconstructor(\n \t\tprivate readonly modulesRoot: string,\n \t\tprivate readonly additionalModuleNames: string[],\n \t\trules: ModuleRule[] = [],\n+\t\tcompatibilityDate?: string,\n \t\tcompatibilityFlags?: string[]\n \t) {\n \t\t// Implicit shallow-copy to avoid mutating argument\n \t\trules = rules.concat(DEFAULT_MODULE_RULES);\n \t\tthis.#compiledRules = compileModuleRules(rules);\n-\t\t// `nodejs_compat` doesn't have a default-on date, so we know whether it's\n-\t\t// enabled just by looking at flags:\n-\t\t// https://github.com/cloudflare/workerd/blob/edcd0300bc7b8f56040d090177db947edd22f91b/src/workerd/io/compatibility-date.capnp#L237-L240\n-\t\tthis.#nodejsCompat = compatibilityFlags?.includes(\"nodejs_compat\") ?? false;\n+\t\tthis.#nodejsCompat = getNodeCompatMode(",
    "repo_full_name": "cloudflare/workers-sdk",
    "discussion_comments": [
      {
        "comment_id": "1775758788",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 6824,
        "pr_file": "packages/miniflare/src/plugins/core/modules.ts",
        "discussion_id": "1775758788",
        "commented_code": "@@ -156,23 +157,24 @@ function getResolveErrorPrefix(referencingPath: string): string {\n \n export class ModuleLocator {\n \treadonly #compiledRules: CompiledModuleRule[];\n-\treadonly #nodejsCompat: boolean;\n+\treadonly #nodejsCompat: NodeJSCompatMode;\n \treadonly #visitedPaths = new Set<string>();\n \treadonly modules: Worker_Module[] = [];\n \n \tconstructor(\n \t\tprivate readonly modulesRoot: string,\n \t\tprivate readonly additionalModuleNames: string[],\n \t\trules: ModuleRule[] = [],\n+\t\tcompatibilityDate?: string,\n \t\tcompatibilityFlags?: string[]\n \t) {\n \t\t// Implicit shallow-copy to avoid mutating argument\n \t\trules = rules.concat(DEFAULT_MODULE_RULES);\n \t\tthis.#compiledRules = compileModuleRules(rules);\n-\t\t// `nodejs_compat` doesn't have a default-on date, so we know whether it's\n-\t\t// enabled just by looking at flags:\n-\t\t// https://github.com/cloudflare/workerd/blob/edcd0300bc7b8f56040d090177db947edd22f91b/src/workerd/io/compatibility-date.capnp#L237-L240\n-\t\tthis.#nodejsCompat = compatibilityFlags?.includes(\"nodejs_compat\") ?? false;\n+\t\tthis.#nodejsCompat = getNodeCompatMode(",
        "comment_created_at": "2024-09-25T18:26:27+00:00",
        "comment_author": "vicb",
        "comment_body": "nit:\r\n- `#nodejsCompat` is inconsistent with `getNodeCompatMode.mode`\r\n- `getNodeCompatMode().mode` is inconsistent\r\n\r\nMaybe `#nodejsCompatMode` and `getNodeCompat` ?",
        "pr_file_module": null
      },
      {
        "comment_id": "1775773034",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 6824,
        "pr_file": "packages/miniflare/src/plugins/core/modules.ts",
        "discussion_id": "1775758788",
        "commented_code": "@@ -156,23 +157,24 @@ function getResolveErrorPrefix(referencingPath: string): string {\n \n export class ModuleLocator {\n \treadonly #compiledRules: CompiledModuleRule[];\n-\treadonly #nodejsCompat: boolean;\n+\treadonly #nodejsCompat: NodeJSCompatMode;\n \treadonly #visitedPaths = new Set<string>();\n \treadonly modules: Worker_Module[] = [];\n \n \tconstructor(\n \t\tprivate readonly modulesRoot: string,\n \t\tprivate readonly additionalModuleNames: string[],\n \t\trules: ModuleRule[] = [],\n+\t\tcompatibilityDate?: string,\n \t\tcompatibilityFlags?: string[]\n \t) {\n \t\t// Implicit shallow-copy to avoid mutating argument\n \t\trules = rules.concat(DEFAULT_MODULE_RULES);\n \t\tthis.#compiledRules = compileModuleRules(rules);\n-\t\t// `nodejs_compat` doesn't have a default-on date, so we know whether it's\n-\t\t// enabled just by looking at flags:\n-\t\t// https://github.com/cloudflare/workerd/blob/edcd0300bc7b8f56040d090177db947edd22f91b/src/workerd/io/compatibility-date.capnp#L237-L240\n-\t\tthis.#nodejsCompat = compatibilityFlags?.includes(\"nodejs_compat\") ?? false;\n+\t\tthis.#nodejsCompat = getNodeCompatMode(",
        "comment_created_at": "2024-09-25T18:38:58+00:00",
        "comment_author": "vicb",
        "comment_body": "An other option being to have 2 distincts `getNodeCompatMode()` and `parseNodeCompatFlags()`\r\n\r\nThe third option is of course to keep things as they currently are :)",
        "pr_file_module": null
      },
      {
        "comment_id": "1775787934",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 6824,
        "pr_file": "packages/miniflare/src/plugins/core/modules.ts",
        "discussion_id": "1775758788",
        "commented_code": "@@ -156,23 +157,24 @@ function getResolveErrorPrefix(referencingPath: string): string {\n \n export class ModuleLocator {\n \treadonly #compiledRules: CompiledModuleRule[];\n-\treadonly #nodejsCompat: boolean;\n+\treadonly #nodejsCompat: NodeJSCompatMode;\n \treadonly #visitedPaths = new Set<string>();\n \treadonly modules: Worker_Module[] = [];\n \n \tconstructor(\n \t\tprivate readonly modulesRoot: string,\n \t\tprivate readonly additionalModuleNames: string[],\n \t\trules: ModuleRule[] = [],\n+\t\tcompatibilityDate?: string,\n \t\tcompatibilityFlags?: string[]\n \t) {\n \t\t// Implicit shallow-copy to avoid mutating argument\n \t\trules = rules.concat(DEFAULT_MODULE_RULES);\n \t\tthis.#compiledRules = compileModuleRules(rules);\n-\t\t// `nodejs_compat` doesn't have a default-on date, so we know whether it's\n-\t\t// enabled just by looking at flags:\n-\t\t// https://github.com/cloudflare/workerd/blob/edcd0300bc7b8f56040d090177db947edd22f91b/src/workerd/io/compatibility-date.capnp#L237-L240\n-\t\tthis.#nodejsCompat = compatibilityFlags?.includes(\"nodejs_compat\") ?? false;\n+\t\tthis.#nodejsCompat = getNodeCompatMode(",
        "comment_created_at": "2024-09-25T18:52:14+00:00",
        "comment_author": "petebacondarwin",
        "comment_body": "I went with the first open. Cheers.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1707348990",
    "pr_number": 6374,
    "pr_file": "packages/wrangler/src/experimental-assets.ts",
    "created_at": "2024-08-07T16:05:41+00:00",
    "commented_code": "+import assert from \"node:assert\";\n import { existsSync } from \"node:fs\";\n-import path from \"node:path\";\n-import { UserError } from \"./errors\";\n+import { readdir, readFile, stat } from \"node:fs/promises\";\n+import * as path from \"node:path\";\n+import chalk from \"chalk\";\n+import { getType } from \"mime\";\n+import PQueue from \"p-queue\";\n+import prettyBytes from \"pretty-bytes\";\n+import { fetchResult } from \"./cfetch\";\n+import { formatTime } from \"./deploy/deploy\";\n+import { FatalError, UserError } from \"./errors\";\n+import { logger, LOGGER_LEVELS } from \"./logger\";\n+import { hashFile } from \"./pages/hash\";\n+import { isJwtExpired } from \"./pages/upload\";\n+import { APIError } from \"./parse\";\n+import { urlSafe } from \"./sites\";\n import type { Config } from \"./config\";\n \n+export type AssetManifest = { [path: string]: { hash: string; size: number } };\n+\n+type InitializeAssetsResponse = {\n+\t// string of file hashes per bucket\n+\tbuckets: string[][];\n+\tjwt: string;\n+};\n+\n+export type UploadPayloadFile = {\n+\tbase64: boolean;\n+\tkey: string;\n+\tvalue: string;\n+\tmetadata: {\n+\t\tcontentType: string;\n+\t};\n+};\n+\n+type UploadResponse = {\n+\tjwt?: string;\n+};\n+\n+// constants same as Pages for now\n+const BULK_UPLOAD_CONCURRENCY = 3;\n+const MAX_ASSET_COUNT = 20_000;\n+const MAX_ASSET_SIZE = 25 * 1024 * 1024;\n+const MAX_UPLOAD_ATTEMPTS = 5;\n+const MAX_UPLOAD_GATEWAY_ERRORS = 5;\n+\n+export const syncExperimentalAssets = async (\n+\taccountId: string | undefined,\n+\tscriptName: string,\n+\tassetDirectory: string | undefined,\n+\tdryRun: boolean | undefined\n+): Promise<string | undefined> => {\n+\tif (assetDirectory === undefined) {\n+\t\treturn;\n+\t}\n+\tif (dryRun) {\n+\t\tlogger.log(\"(Note: doing a dry run, not uploading or deleting anything.)\");\n+\t\treturn;\n+\t}\n+\tassert(accountId, \"Missing accountId\");\n+\n+\t// 1. generate asset manifest\n+\tlogger.info(\"\ud83c\udf00 Building list of assets...\");\n+\tconst manifest = await walk(assetDirectory, {});\n+\n+\t// 2. fetch buckets w/ hashes\n+\tlogger.info(\"\ud83c\udf00 Starting asset upload...\");\n+\tconst initializeAssetsResponse = await fetchResult<InitializeAssetsResponse>(\n+\t\t`/accounts/${accountId}/workers/scripts/${scriptName}/assets-upload-session`,\n+\t\t{\n+\t\t\theaders: { \"Content-Type\": \"application/json\" },\n+\t\t\tmethod: \"POST\",\n+\t\t\tbody: JSON.stringify({ manifest: manifest }),\n+\t\t}\n+\t);\n+\n+\t// if nothing to upload, return\n+\tif (initializeAssetsResponse.buckets.flat().length === 0) {\n+\t\tif (!initializeAssetsResponse.jwt) {\n+\t\t\tthrow new FatalError(\n+\t\t\t\t\"Could not find assets information to attach to deployment. Please try again.\",\n+\t\t\t\t1\n+\t\t\t);\n+\t\t}\n+\t\tlogger.info(`\u2728 Success! (No files to upload)`);\n+\t\treturn initializeAssetsResponse.jwt;\n+\t}\n+\n+\t// 3. fill buckets and upload assets\n+\tconst numberFilesToUpload = initializeAssetsResponse.buckets.flat().length;\n+\tlogger.info(`\ud83c\udf00 Uploading ${numberFilesToUpload} file(s)...`);\n+\n+\t// Create the buckets outside of doUpload so we can retry without losing track of potential duplicate files\n+\t// But don't add the actual content until uploading so we don't run out of memory\n+\tconst manifestLookup = Object.entries(manifest);\n+\tlet assetLogCount = 0;\n+\tconst bucketSkeletons = initializeAssetsResponse.buckets.map((bucket) => {",
    "repo_full_name": "cloudflare/workers-sdk",
    "discussion_comments": [
      {
        "comment_id": "1707348990",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 6374,
        "pr_file": "packages/wrangler/src/experimental-assets.ts",
        "discussion_id": "1707348990",
        "commented_code": "@@ -1,8 +1,299 @@\n+import assert from \"node:assert\";\n import { existsSync } from \"node:fs\";\n-import path from \"node:path\";\n-import { UserError } from \"./errors\";\n+import { readdir, readFile, stat } from \"node:fs/promises\";\n+import * as path from \"node:path\";\n+import chalk from \"chalk\";\n+import { getType } from \"mime\";\n+import PQueue from \"p-queue\";\n+import prettyBytes from \"pretty-bytes\";\n+import { fetchResult } from \"./cfetch\";\n+import { formatTime } from \"./deploy/deploy\";\n+import { FatalError, UserError } from \"./errors\";\n+import { logger, LOGGER_LEVELS } from \"./logger\";\n+import { hashFile } from \"./pages/hash\";\n+import { isJwtExpired } from \"./pages/upload\";\n+import { APIError } from \"./parse\";\n+import { urlSafe } from \"./sites\";\n import type { Config } from \"./config\";\n \n+export type AssetManifest = { [path: string]: { hash: string; size: number } };\n+\n+type InitializeAssetsResponse = {\n+\t// string of file hashes per bucket\n+\tbuckets: string[][];\n+\tjwt: string;\n+};\n+\n+export type UploadPayloadFile = {\n+\tbase64: boolean;\n+\tkey: string;\n+\tvalue: string;\n+\tmetadata: {\n+\t\tcontentType: string;\n+\t};\n+};\n+\n+type UploadResponse = {\n+\tjwt?: string;\n+};\n+\n+// constants same as Pages for now\n+const BULK_UPLOAD_CONCURRENCY = 3;\n+const MAX_ASSET_COUNT = 20_000;\n+const MAX_ASSET_SIZE = 25 * 1024 * 1024;\n+const MAX_UPLOAD_ATTEMPTS = 5;\n+const MAX_UPLOAD_GATEWAY_ERRORS = 5;\n+\n+export const syncExperimentalAssets = async (\n+\taccountId: string | undefined,\n+\tscriptName: string,\n+\tassetDirectory: string | undefined,\n+\tdryRun: boolean | undefined\n+): Promise<string | undefined> => {\n+\tif (assetDirectory === undefined) {\n+\t\treturn;\n+\t}\n+\tif (dryRun) {\n+\t\tlogger.log(\"(Note: doing a dry run, not uploading or deleting anything.)\");\n+\t\treturn;\n+\t}\n+\tassert(accountId, \"Missing accountId\");\n+\n+\t// 1. generate asset manifest\n+\tlogger.info(\"\ud83c\udf00 Building list of assets...\");\n+\tconst manifest = await walk(assetDirectory, {});\n+\n+\t// 2. fetch buckets w/ hashes\n+\tlogger.info(\"\ud83c\udf00 Starting asset upload...\");\n+\tconst initializeAssetsResponse = await fetchResult<InitializeAssetsResponse>(\n+\t\t`/accounts/${accountId}/workers/scripts/${scriptName}/assets-upload-session`,\n+\t\t{\n+\t\t\theaders: { \"Content-Type\": \"application/json\" },\n+\t\t\tmethod: \"POST\",\n+\t\t\tbody: JSON.stringify({ manifest: manifest }),\n+\t\t}\n+\t);\n+\n+\t// if nothing to upload, return\n+\tif (initializeAssetsResponse.buckets.flat().length === 0) {\n+\t\tif (!initializeAssetsResponse.jwt) {\n+\t\t\tthrow new FatalError(\n+\t\t\t\t\"Could not find assets information to attach to deployment. Please try again.\",\n+\t\t\t\t1\n+\t\t\t);\n+\t\t}\n+\t\tlogger.info(`\u2728 Success! (No files to upload)`);\n+\t\treturn initializeAssetsResponse.jwt;\n+\t}\n+\n+\t// 3. fill buckets and upload assets\n+\tconst numberFilesToUpload = initializeAssetsResponse.buckets.flat().length;\n+\tlogger.info(`\ud83c\udf00 Uploading ${numberFilesToUpload} file(s)...`);\n+\n+\t// Create the buckets outside of doUpload so we can retry without losing track of potential duplicate files\n+\t// But don't add the actual content until uploading so we don't run out of memory\n+\tconst manifestLookup = Object.entries(manifest);\n+\tlet assetLogCount = 0;\n+\tconst bucketSkeletons = initializeAssetsResponse.buckets.map((bucket) => {",
        "comment_created_at": "2024-08-07T16:05:41+00:00",
        "comment_author": "CarmenPopoviciu",
        "comment_body": "can we specify the type for `bucketSkeletons` here as opposed to have it inferred?",
        "pr_file_module": null
      },
      {
        "comment_id": "1707350105",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 6374,
        "pr_file": "packages/wrangler/src/experimental-assets.ts",
        "discussion_id": "1707348990",
        "commented_code": "@@ -1,8 +1,299 @@\n+import assert from \"node:assert\";\n import { existsSync } from \"node:fs\";\n-import path from \"node:path\";\n-import { UserError } from \"./errors\";\n+import { readdir, readFile, stat } from \"node:fs/promises\";\n+import * as path from \"node:path\";\n+import chalk from \"chalk\";\n+import { getType } from \"mime\";\n+import PQueue from \"p-queue\";\n+import prettyBytes from \"pretty-bytes\";\n+import { fetchResult } from \"./cfetch\";\n+import { formatTime } from \"./deploy/deploy\";\n+import { FatalError, UserError } from \"./errors\";\n+import { logger, LOGGER_LEVELS } from \"./logger\";\n+import { hashFile } from \"./pages/hash\";\n+import { isJwtExpired } from \"./pages/upload\";\n+import { APIError } from \"./parse\";\n+import { urlSafe } from \"./sites\";\n import type { Config } from \"./config\";\n \n+export type AssetManifest = { [path: string]: { hash: string; size: number } };\n+\n+type InitializeAssetsResponse = {\n+\t// string of file hashes per bucket\n+\tbuckets: string[][];\n+\tjwt: string;\n+};\n+\n+export type UploadPayloadFile = {\n+\tbase64: boolean;\n+\tkey: string;\n+\tvalue: string;\n+\tmetadata: {\n+\t\tcontentType: string;\n+\t};\n+};\n+\n+type UploadResponse = {\n+\tjwt?: string;\n+};\n+\n+// constants same as Pages for now\n+const BULK_UPLOAD_CONCURRENCY = 3;\n+const MAX_ASSET_COUNT = 20_000;\n+const MAX_ASSET_SIZE = 25 * 1024 * 1024;\n+const MAX_UPLOAD_ATTEMPTS = 5;\n+const MAX_UPLOAD_GATEWAY_ERRORS = 5;\n+\n+export const syncExperimentalAssets = async (\n+\taccountId: string | undefined,\n+\tscriptName: string,\n+\tassetDirectory: string | undefined,\n+\tdryRun: boolean | undefined\n+): Promise<string | undefined> => {\n+\tif (assetDirectory === undefined) {\n+\t\treturn;\n+\t}\n+\tif (dryRun) {\n+\t\tlogger.log(\"(Note: doing a dry run, not uploading or deleting anything.)\");\n+\t\treturn;\n+\t}\n+\tassert(accountId, \"Missing accountId\");\n+\n+\t// 1. generate asset manifest\n+\tlogger.info(\"\ud83c\udf00 Building list of assets...\");\n+\tconst manifest = await walk(assetDirectory, {});\n+\n+\t// 2. fetch buckets w/ hashes\n+\tlogger.info(\"\ud83c\udf00 Starting asset upload...\");\n+\tconst initializeAssetsResponse = await fetchResult<InitializeAssetsResponse>(\n+\t\t`/accounts/${accountId}/workers/scripts/${scriptName}/assets-upload-session`,\n+\t\t{\n+\t\t\theaders: { \"Content-Type\": \"application/json\" },\n+\t\t\tmethod: \"POST\",\n+\t\t\tbody: JSON.stringify({ manifest: manifest }),\n+\t\t}\n+\t);\n+\n+\t// if nothing to upload, return\n+\tif (initializeAssetsResponse.buckets.flat().length === 0) {\n+\t\tif (!initializeAssetsResponse.jwt) {\n+\t\t\tthrow new FatalError(\n+\t\t\t\t\"Could not find assets information to attach to deployment. Please try again.\",\n+\t\t\t\t1\n+\t\t\t);\n+\t\t}\n+\t\tlogger.info(`\u2728 Success! (No files to upload)`);\n+\t\treturn initializeAssetsResponse.jwt;\n+\t}\n+\n+\t// 3. fill buckets and upload assets\n+\tconst numberFilesToUpload = initializeAssetsResponse.buckets.flat().length;\n+\tlogger.info(`\ud83c\udf00 Uploading ${numberFilesToUpload} file(s)...`);\n+\n+\t// Create the buckets outside of doUpload so we can retry without losing track of potential duplicate files\n+\t// But don't add the actual content until uploading so we don't run out of memory\n+\tconst manifestLookup = Object.entries(manifest);\n+\tlet assetLogCount = 0;\n+\tconst bucketSkeletons = initializeAssetsResponse.buckets.map((bucket) => {",
        "comment_created_at": "2024-08-07T16:06:14+00:00",
        "comment_author": "CarmenPopoviciu",
        "comment_body": "better yet, maybe have a dedicated type if cleaner",
        "pr_file_module": null
      },
      {
        "comment_id": "1707360294",
        "repo_full_name": "cloudflare/workers-sdk",
        "pr_number": 6374,
        "pr_file": "packages/wrangler/src/experimental-assets.ts",
        "discussion_id": "1707348990",
        "commented_code": "@@ -1,8 +1,299 @@\n+import assert from \"node:assert\";\n import { existsSync } from \"node:fs\";\n-import path from \"node:path\";\n-import { UserError } from \"./errors\";\n+import { readdir, readFile, stat } from \"node:fs/promises\";\n+import * as path from \"node:path\";\n+import chalk from \"chalk\";\n+import { getType } from \"mime\";\n+import PQueue from \"p-queue\";\n+import prettyBytes from \"pretty-bytes\";\n+import { fetchResult } from \"./cfetch\";\n+import { formatTime } from \"./deploy/deploy\";\n+import { FatalError, UserError } from \"./errors\";\n+import { logger, LOGGER_LEVELS } from \"./logger\";\n+import { hashFile } from \"./pages/hash\";\n+import { isJwtExpired } from \"./pages/upload\";\n+import { APIError } from \"./parse\";\n+import { urlSafe } from \"./sites\";\n import type { Config } from \"./config\";\n \n+export type AssetManifest = { [path: string]: { hash: string; size: number } };\n+\n+type InitializeAssetsResponse = {\n+\t// string of file hashes per bucket\n+\tbuckets: string[][];\n+\tjwt: string;\n+};\n+\n+export type UploadPayloadFile = {\n+\tbase64: boolean;\n+\tkey: string;\n+\tvalue: string;\n+\tmetadata: {\n+\t\tcontentType: string;\n+\t};\n+};\n+\n+type UploadResponse = {\n+\tjwt?: string;\n+};\n+\n+// constants same as Pages for now\n+const BULK_UPLOAD_CONCURRENCY = 3;\n+const MAX_ASSET_COUNT = 20_000;\n+const MAX_ASSET_SIZE = 25 * 1024 * 1024;\n+const MAX_UPLOAD_ATTEMPTS = 5;\n+const MAX_UPLOAD_GATEWAY_ERRORS = 5;\n+\n+export const syncExperimentalAssets = async (\n+\taccountId: string | undefined,\n+\tscriptName: string,\n+\tassetDirectory: string | undefined,\n+\tdryRun: boolean | undefined\n+): Promise<string | undefined> => {\n+\tif (assetDirectory === undefined) {\n+\t\treturn;\n+\t}\n+\tif (dryRun) {\n+\t\tlogger.log(\"(Note: doing a dry run, not uploading or deleting anything.)\");\n+\t\treturn;\n+\t}\n+\tassert(accountId, \"Missing accountId\");\n+\n+\t// 1. generate asset manifest\n+\tlogger.info(\"\ud83c\udf00 Building list of assets...\");\n+\tconst manifest = await walk(assetDirectory, {});\n+\n+\t// 2. fetch buckets w/ hashes\n+\tlogger.info(\"\ud83c\udf00 Starting asset upload...\");\n+\tconst initializeAssetsResponse = await fetchResult<InitializeAssetsResponse>(\n+\t\t`/accounts/${accountId}/workers/scripts/${scriptName}/assets-upload-session`,\n+\t\t{\n+\t\t\theaders: { \"Content-Type\": \"application/json\" },\n+\t\t\tmethod: \"POST\",\n+\t\t\tbody: JSON.stringify({ manifest: manifest }),\n+\t\t}\n+\t);\n+\n+\t// if nothing to upload, return\n+\tif (initializeAssetsResponse.buckets.flat().length === 0) {\n+\t\tif (!initializeAssetsResponse.jwt) {\n+\t\t\tthrow new FatalError(\n+\t\t\t\t\"Could not find assets information to attach to deployment. Please try again.\",\n+\t\t\t\t1\n+\t\t\t);\n+\t\t}\n+\t\tlogger.info(`\u2728 Success! (No files to upload)`);\n+\t\treturn initializeAssetsResponse.jwt;\n+\t}\n+\n+\t// 3. fill buckets and upload assets\n+\tconst numberFilesToUpload = initializeAssetsResponse.buckets.flat().length;\n+\tlogger.info(`\ud83c\udf00 Uploading ${numberFilesToUpload} file(s)...`);\n+\n+\t// Create the buckets outside of doUpload so we can retry without losing track of potential duplicate files\n+\t// But don't add the actual content until uploading so we don't run out of memory\n+\tconst manifestLookup = Object.entries(manifest);\n+\tlet assetLogCount = 0;\n+\tconst bucketSkeletons = initializeAssetsResponse.buckets.map((bucket) => {",
        "comment_created_at": "2024-08-07T16:11:05+00:00",
        "comment_author": "CarmenPopoviciu",
        "comment_body": "also, can we name these simply `buckets` or `assetBuckets`? `skeletons` doesn't tell me much?",
        "pr_file_module": null
      }
    ]
  }
]