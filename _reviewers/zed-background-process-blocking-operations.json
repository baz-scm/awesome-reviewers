[
  {
    "discussion_id": "1995296404",
    "pr_number": 26732,
    "pr_file": "crates/assistant_tools/src/path_search_tool.rs",
    "created_at": "2025-03-14T10:21:49+00:00",
    "commented_code": "project: Entity<Project>,\n         cx: &mut App,\n     ) -> Task<Result<String>> {\n-        let glob = match serde_json::from_value::<PathSearchToolInput>(input) {\n-            Ok(input) => input.glob,\n-            Err(err) => return Task::ready(Err(anyhow!(err))),\n-        };\n-        let path_matcher = match PathMatcher::new(&[glob.clone()]) {\n-            Ok(matcher) => matcher,\n-            Err(err) => return Task::ready(Err(anyhow!(\"Invalid glob: {}\", err))),\n-        };\n+        let worktrees: Vec<_> = project.read(cx).worktrees(cx).collect();\n \n-        let mut matches = Vec::new();",
    "repo_full_name": "zed-industries/zed",
    "discussion_comments": [
      {
        "comment_id": "1995296404",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 26732,
        "pr_file": "crates/assistant_tools/src/path_search_tool.rs",
        "discussion_id": "1995296404",
        "commented_code": "@@ -47,42 +47,44 @@ impl Tool for PathSearchTool {\n         project: Entity<Project>,\n         cx: &mut App,\n     ) -> Task<Result<String>> {\n-        let glob = match serde_json::from_value::<PathSearchToolInput>(input) {\n-            Ok(input) => input.glob,\n-            Err(err) => return Task::ready(Err(anyhow!(err))),\n-        };\n-        let path_matcher = match PathMatcher::new(&[glob.clone()]) {\n-            Ok(matcher) => matcher,\n-            Err(err) => return Task::ready(Err(anyhow!(\"Invalid glob: {}\", err))),\n-        };\n+        let worktrees: Vec<_> = project.read(cx).worktrees(cx).collect();\n \n-        let mut matches = Vec::new();",
        "comment_created_at": "2025-03-14T10:21:49+00:00",
        "comment_author": "as-cii",
        "comment_body": "This is still spawning on the main thread. To spawn on a background thread, you should use `cx.background_spawn`.",
        "pr_file_module": null
      },
      {
        "comment_id": "1995989247",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 26732,
        "pr_file": "crates/assistant_tools/src/path_search_tool.rs",
        "discussion_id": "1995296404",
        "commented_code": "@@ -47,42 +47,44 @@ impl Tool for PathSearchTool {\n         project: Entity<Project>,\n         cx: &mut App,\n     ) -> Task<Result<String>> {\n-        let glob = match serde_json::from_value::<PathSearchToolInput>(input) {\n-            Ok(input) => input.glob,\n-            Err(err) => return Task::ready(Err(anyhow!(err))),\n-        };\n-        let path_matcher = match PathMatcher::new(&[glob.clone()]) {\n-            Ok(matcher) => matcher,\n-            Err(err) => return Task::ready(Err(anyhow!(\"Invalid glob: {}\", err))),\n-        };\n+        let worktrees: Vec<_> = project.read(cx).worktrees(cx).collect();\n \n-        let mut matches = Vec::new();",
        "comment_created_at": "2025-03-14T17:29:30+00:00",
        "comment_author": "rtfeldman",
        "comment_body": "@as-cii Should be good now!",
        "pr_file_module": null
      },
      {
        "comment_id": "1998951217",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 26732,
        "pr_file": "crates/assistant_tools/src/path_search_tool.rs",
        "discussion_id": "1995296404",
        "commented_code": "@@ -47,42 +47,44 @@ impl Tool for PathSearchTool {\n         project: Entity<Project>,\n         cx: &mut App,\n     ) -> Task<Result<String>> {\n-        let glob = match serde_json::from_value::<PathSearchToolInput>(input) {\n-            Ok(input) => input.glob,\n-            Err(err) => return Task::ready(Err(anyhow!(err))),\n-        };\n-        let path_matcher = match PathMatcher::new(&[glob.clone()]) {\n-            Ok(matcher) => matcher,\n-            Err(err) => return Task::ready(Err(anyhow!(\"Invalid glob: {}\", err))),\n-        };\n+        let worktrees: Vec<_> = project.read(cx).worktrees(cx).collect();\n \n-        let mut matches = Vec::new();",
        "comment_created_at": "2025-03-17T14:57:34+00:00",
        "comment_author": "rtfeldman",
        "comment_body": "@as-cii FYI, this is now ready to go, only blocked on your approval (if it looks good now).",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1995290968",
    "pr_number": 26715,
    "pr_file": "crates/assistant_tools/src/delete_path_tool.rs",
    "created_at": "2025-03-14T10:17:37+00:00",
    "commented_code": "project: Entity<Project>,\n         cx: &mut App,\n     ) -> Task<Result<String>> {\n-        let glob = match serde_json::from_value::<DeletePathToolInput>(input) {\n-            Ok(input) => input.glob,\n+        let path_str = match serde_json::from_value::<DeletePathToolInput>(input) {\n+            Ok(input) => input.path,\n             Err(err) => return Task::ready(Err(anyhow!(err))),\n         };\n-        let path_matcher = match PathMatcher::new(&[glob.clone()]) {\n-            Ok(matcher) => matcher,\n-            Err(err) => return Task::ready(Err(anyhow!(\"Invalid glob: {}\", err))),\n-        };\n \n-        struct Match {\n-            display_path: String,\n-            path: PathBuf,\n-        }\n+        let mut path = PathBuf::from(&path_str);\n \n-        let mut matches = Vec::new();\n-        let mut deleted_paths = Vec::new();\n-        let mut errors = Vec::new();\n+        // Change a path of \"foo/bar.txt\" to \"/Users/someone/project/foo/bar.txt\"\n+        if !path.is_absolute() {\n+            let mut path_components = path.components();\n \n-        for worktree_handle in project.read(cx).worktrees(cx) {\n-            let worktree = worktree_handle.read(cx);\n-            let worktree_root = worktree.abs_path().to_path_buf();\n+            // Find the worktree whose last abs_path component equals this path's first component,\n+            // e.g. if this path starts with \"foo/\", find the worktree whose abs_path ends in \"foo\"\n+            if let Some(target_root_dir) = path_components.next() {\n+                for worktree in project.read(cx).worktrees(cx) {\n+                    let abs_path = worktree.read(cx).abs_path();\n \n-            // Don't consider ignored entries.\n-            for entry in worktree.entries(false, 0) {\n-                if path_matcher.is_match(&entry.path) {\n-                    matches.push(Match {\n-                        path: worktree_root.join(&entry.path),\n-                        display_path: entry.path.display().to_string(),\n-                    });\n+                    if abs_path.components().last() == Some(target_root_dir) {\n+                        // Use that abs_path as our path's prefix. Join it with the other components\n+                        // so we don't repeat the first component (the one that matched abs_path).\n+                        path = abs_path.join(path_components);\n+                        break;\n+                    }\n                 }\n             }\n-        }\n \n-        if matches.is_empty() {\n-            return Task::ready(Ok(format!(\"No paths in the project matched {glob:?}\")));\n-        }\n-\n-        let paths_matched = matches.len();\n+            if !path.is_absolute() {\n+                return Task::ready(Err(anyhow!(\n+                    \"Couldn't delete {} because it wasn't in any of this project's worktrees.\",\n+                    path.display()\n+                )));\n+            }\n+        };\n \n-        // Delete the files\n-        for Match { path, display_path } in matches {\n+        cx.spawn(|_cx| async move {\n+            // Try to delete the file first\n             match fs::remove_file(&path) {",
    "repo_full_name": "zed-industries/zed",
    "discussion_comments": [
      {
        "comment_id": "1995290968",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 26715,
        "pr_file": "crates/assistant_tools/src/delete_path_tool.rs",
        "discussion_id": "1995290968",
        "commented_code": "@@ -47,119 +46,63 @@ impl Tool for DeletePathTool {\n         project: Entity<Project>,\n         cx: &mut App,\n     ) -> Task<Result<String>> {\n-        let glob = match serde_json::from_value::<DeletePathToolInput>(input) {\n-            Ok(input) => input.glob,\n+        let path_str = match serde_json::from_value::<DeletePathToolInput>(input) {\n+            Ok(input) => input.path,\n             Err(err) => return Task::ready(Err(anyhow!(err))),\n         };\n-        let path_matcher = match PathMatcher::new(&[glob.clone()]) {\n-            Ok(matcher) => matcher,\n-            Err(err) => return Task::ready(Err(anyhow!(\"Invalid glob: {}\", err))),\n-        };\n \n-        struct Match {\n-            display_path: String,\n-            path: PathBuf,\n-        }\n+        let mut path = PathBuf::from(&path_str);\n \n-        let mut matches = Vec::new();\n-        let mut deleted_paths = Vec::new();\n-        let mut errors = Vec::new();\n+        // Change a path of \"foo/bar.txt\" to \"/Users/someone/project/foo/bar.txt\"\n+        if !path.is_absolute() {\n+            let mut path_components = path.components();\n \n-        for worktree_handle in project.read(cx).worktrees(cx) {\n-            let worktree = worktree_handle.read(cx);\n-            let worktree_root = worktree.abs_path().to_path_buf();\n+            // Find the worktree whose last abs_path component equals this path's first component,\n+            // e.g. if this path starts with \"foo/\", find the worktree whose abs_path ends in \"foo\"\n+            if let Some(target_root_dir) = path_components.next() {\n+                for worktree in project.read(cx).worktrees(cx) {\n+                    let abs_path = worktree.read(cx).abs_path();\n \n-            // Don't consider ignored entries.\n-            for entry in worktree.entries(false, 0) {\n-                if path_matcher.is_match(&entry.path) {\n-                    matches.push(Match {\n-                        path: worktree_root.join(&entry.path),\n-                        display_path: entry.path.display().to_string(),\n-                    });\n+                    if abs_path.components().last() == Some(target_root_dir) {\n+                        // Use that abs_path as our path's prefix. Join it with the other components\n+                        // so we don't repeat the first component (the one that matched abs_path).\n+                        path = abs_path.join(path_components);\n+                        break;\n+                    }\n                 }\n             }\n-        }\n \n-        if matches.is_empty() {\n-            return Task::ready(Ok(format!(\"No paths in the project matched {glob:?}\")));\n-        }\n-\n-        let paths_matched = matches.len();\n+            if !path.is_absolute() {\n+                return Task::ready(Err(anyhow!(\n+                    \"Couldn't delete {} because it wasn't in any of this project's worktrees.\",\n+                    path.display()\n+                )));\n+            }\n+        };\n \n-        // Delete the files\n-        for Match { path, display_path } in matches {\n+        cx.spawn(|_cx| async move {\n+            // Try to delete the file first\n             match fs::remove_file(&path) {",
        "comment_created_at": "2025-03-14T10:17:37+00:00",
        "comment_author": "as-cii",
        "comment_body": "These still block the main thread. Spawning just puts the future on the main thread executor, so if we block we're gonna block the main thread.\r\n\r\nIn general, I don't think we should use direct file-system APIs either. Given that we have a `Project`, we should delete files and directories using that abstraction. Those APIs are already asynchronous, so in that case it's okay to just spawn on the main thread like you're already doing.",
        "pr_file_module": null
      },
      {
        "comment_id": "1996201209",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 26715,
        "pr_file": "crates/assistant_tools/src/delete_path_tool.rs",
        "discussion_id": "1995290968",
        "commented_code": "@@ -47,119 +46,63 @@ impl Tool for DeletePathTool {\n         project: Entity<Project>,\n         cx: &mut App,\n     ) -> Task<Result<String>> {\n-        let glob = match serde_json::from_value::<DeletePathToolInput>(input) {\n-            Ok(input) => input.glob,\n+        let path_str = match serde_json::from_value::<DeletePathToolInput>(input) {\n+            Ok(input) => input.path,\n             Err(err) => return Task::ready(Err(anyhow!(err))),\n         };\n-        let path_matcher = match PathMatcher::new(&[glob.clone()]) {\n-            Ok(matcher) => matcher,\n-            Err(err) => return Task::ready(Err(anyhow!(\"Invalid glob: {}\", err))),\n-        };\n \n-        struct Match {\n-            display_path: String,\n-            path: PathBuf,\n-        }\n+        let mut path = PathBuf::from(&path_str);\n \n-        let mut matches = Vec::new();\n-        let mut deleted_paths = Vec::new();\n-        let mut errors = Vec::new();\n+        // Change a path of \"foo/bar.txt\" to \"/Users/someone/project/foo/bar.txt\"\n+        if !path.is_absolute() {\n+            let mut path_components = path.components();\n \n-        for worktree_handle in project.read(cx).worktrees(cx) {\n-            let worktree = worktree_handle.read(cx);\n-            let worktree_root = worktree.abs_path().to_path_buf();\n+            // Find the worktree whose last abs_path component equals this path's first component,\n+            // e.g. if this path starts with \"foo/\", find the worktree whose abs_path ends in \"foo\"\n+            if let Some(target_root_dir) = path_components.next() {\n+                for worktree in project.read(cx).worktrees(cx) {\n+                    let abs_path = worktree.read(cx).abs_path();\n \n-            // Don't consider ignored entries.\n-            for entry in worktree.entries(false, 0) {\n-                if path_matcher.is_match(&entry.path) {\n-                    matches.push(Match {\n-                        path: worktree_root.join(&entry.path),\n-                        display_path: entry.path.display().to_string(),\n-                    });\n+                    if abs_path.components().last() == Some(target_root_dir) {\n+                        // Use that abs_path as our path's prefix. Join it with the other components\n+                        // so we don't repeat the first component (the one that matched abs_path).\n+                        path = abs_path.join(path_components);\n+                        break;\n+                    }\n                 }\n             }\n-        }\n \n-        if matches.is_empty() {\n-            return Task::ready(Ok(format!(\"No paths in the project matched {glob:?}\")));\n-        }\n-\n-        let paths_matched = matches.len();\n+            if !path.is_absolute() {\n+                return Task::ready(Err(anyhow!(\n+                    \"Couldn't delete {} because it wasn't in any of this project's worktrees.\",\n+                    path.display()\n+                )));\n+            }\n+        };\n \n-        // Delete the files\n-        for Match { path, display_path } in matches {\n+        cx.spawn(|_cx| async move {\n+            // Try to delete the file first\n             match fs::remove_file(&path) {",
        "comment_created_at": "2025-03-14T20:02:32+00:00",
        "comment_author": "rtfeldman",
        "comment_body": "I made these changes, but I noticed that before `Project::delete_file` returns its `Task`, it [iterates over all the entries in a worktree](https://github.com/zed-industries/zed/blob/685536c27ee06b63a4fa3bce564e114e3d2da092/crates/worktree/src/worktree.rs#L2644) to do some string matching (`starts_with`) and accumulating matches. The search tool basically does the same operation, except with a regex match instead of `starts_with`, and we'd discussed previously we'd want to background that in case the number of entries is huge.\r\n\r\nWhat do you think - should we do that here too?",
        "pr_file_module": null
      },
      {
        "comment_id": "1997559120",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 26715,
        "pr_file": "crates/assistant_tools/src/delete_path_tool.rs",
        "discussion_id": "1995290968",
        "commented_code": "@@ -47,119 +46,63 @@ impl Tool for DeletePathTool {\n         project: Entity<Project>,\n         cx: &mut App,\n     ) -> Task<Result<String>> {\n-        let glob = match serde_json::from_value::<DeletePathToolInput>(input) {\n-            Ok(input) => input.glob,\n+        let path_str = match serde_json::from_value::<DeletePathToolInput>(input) {\n+            Ok(input) => input.path,\n             Err(err) => return Task::ready(Err(anyhow!(err))),\n         };\n-        let path_matcher = match PathMatcher::new(&[glob.clone()]) {\n-            Ok(matcher) => matcher,\n-            Err(err) => return Task::ready(Err(anyhow!(\"Invalid glob: {}\", err))),\n-        };\n \n-        struct Match {\n-            display_path: String,\n-            path: PathBuf,\n-        }\n+        let mut path = PathBuf::from(&path_str);\n \n-        let mut matches = Vec::new();\n-        let mut deleted_paths = Vec::new();\n-        let mut errors = Vec::new();\n+        // Change a path of \"foo/bar.txt\" to \"/Users/someone/project/foo/bar.txt\"\n+        if !path.is_absolute() {\n+            let mut path_components = path.components();\n \n-        for worktree_handle in project.read(cx).worktrees(cx) {\n-            let worktree = worktree_handle.read(cx);\n-            let worktree_root = worktree.abs_path().to_path_buf();\n+            // Find the worktree whose last abs_path component equals this path's first component,\n+            // e.g. if this path starts with \"foo/\", find the worktree whose abs_path ends in \"foo\"\n+            if let Some(target_root_dir) = path_components.next() {\n+                for worktree in project.read(cx).worktrees(cx) {\n+                    let abs_path = worktree.read(cx).abs_path();\n \n-            // Don't consider ignored entries.\n-            for entry in worktree.entries(false, 0) {\n-                if path_matcher.is_match(&entry.path) {\n-                    matches.push(Match {\n-                        path: worktree_root.join(&entry.path),\n-                        display_path: entry.path.display().to_string(),\n-                    });\n+                    if abs_path.components().last() == Some(target_root_dir) {\n+                        // Use that abs_path as our path's prefix. Join it with the other components\n+                        // so we don't repeat the first component (the one that matched abs_path).\n+                        path = abs_path.join(path_components);\n+                        break;\n+                    }\n                 }\n             }\n-        }\n \n-        if matches.is_empty() {\n-            return Task::ready(Ok(format!(\"No paths in the project matched {glob:?}\")));\n-        }\n-\n-        let paths_matched = matches.len();\n+            if !path.is_absolute() {\n+                return Task::ready(Err(anyhow!(\n+                    \"Couldn't delete {} because it wasn't in any of this project's worktrees.\",\n+                    path.display()\n+                )));\n+            }\n+        };\n \n-        // Delete the files\n-        for Match { path, display_path } in matches {\n+        cx.spawn(|_cx| async move {\n+            // Try to delete the file first\n             match fs::remove_file(&path) {",
        "comment_created_at": "2025-03-16T10:57:48+00:00",
        "comment_author": "as-cii",
        "comment_body": "Yeah there seems to be some synchronous work happening in `Workree::delete_entry` which doesn't feel great (`get_children_ids_recursive` and `RemoteWorktree::delete_entry` both scan the whole directory on the main thread, which is pretty bad). \r\n\r\nI think we should fix it at the `Worktree` level though (as opposed to here), but for now I think it's fine to just ship this as-is.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1801518919",
    "pr_number": 19230,
    "pr_file": "crates/project/src/lsp_store.rs",
    "created_at": "2024-10-15T16:15:01+00:00",
    "commented_code": "},\n                 )\n                 .log_err();\n+\n+            let buffer_handle = buffer_handle.clone();\n+            cx.spawn(move |this, mut cx| async move {\n+                this.update(&mut cx, |this, cx| {",
    "repo_full_name": "zed-industries/zed",
    "discussion_comments": [
      {
        "comment_id": "1801518919",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 19230,
        "pr_file": "crates/project/src/lsp_store.rs",
        "discussion_id": "1801518919",
        "commented_code": "@@ -2886,6 +2887,15 @@ impl LspStore {\n                     },\n                 )\n                 .log_err();\n+\n+            let buffer_handle = buffer_handle.clone();\n+            cx.spawn(move |this, mut cx| async move {\n+                this.update(&mut cx, |this, cx| {",
        "comment_created_at": "2024-10-15T16:15:01+00:00",
        "comment_author": "vitallium",
        "comment_body": "I have doubts about these lines. Am I doing this correctly?",
        "pr_file_module": null
      },
      {
        "comment_id": "1812350513",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 19230,
        "pr_file": "crates/project/src/lsp_store.rs",
        "discussion_id": "1801518919",
        "commented_code": "@@ -2886,6 +2887,15 @@ impl LspStore {\n                     },\n                 )\n                 .log_err();\n+\n+            let buffer_handle = buffer_handle.clone();\n+            cx.spawn(move |this, mut cx| async move {\n+                this.update(&mut cx, |this, cx| {",
        "comment_created_at": "2024-10-23T09:39:42+00:00",
        "comment_author": "SomeoneToIgnore",
        "comment_body": "Nope, alas.\r\n\r\n1. To start with, `pull_diagnostic` has some `.detach()` inside, so here we spawn a task that calls a synchronous function that spawns a task.\r\nThis is sort of noop and odd (even the name is odd, as it actually updates the buffer with the new diagnostics).\r\n\r\nI think it's better to have `pull_diagnostic` to return `Task<anyhow::Result<Vec<Diagnostics>>>` and inside, it will either call to LSP or to protobuf (in the remote client side), similar to how inlays are doing this.\r\n\r\n2. Then, somewhere on this level, we'll have to handle the debounces and tasks better.\r\nRight now, every time we type, we spawn a task that waits for a debounce time, then queries for diagnostics and applies them to the buffer.\r\n\r\nSo, the debounce at its current form does nothing but the delay of the potential query + edit cascade.\r\n\r\nI think the whole approach of placing the pull code here might be a be a bit off-pace.\r\nInstead, we can alter `editor.rs` and adjust around the https://github.com/zed-industries/zed/blob/d53a86b01dd3d02980938cbce1bfd74e35901dda/crates/editor/src/editor.rs#L12167 line.\r\n\r\nWe can store another task and do debounces in it first, similar to what `_scroll_cursor_center_top_bottom_task` has: https://github.com/zed-industries/zed/blob/d53a86b01dd3d02980938cbce1bfd74e35901dda/crates/editor/src/scroll/actions.rs#L77-L87\r\n\r\ndoes, but query LSP store for diagnostics instead after the timeout.\r\nThen, update the diagnostics similar to what applying the diagnostics push + calling `refresh_active_diagnostics` does today.\r\n\r\nWe're lucky that buffer, before updating its diagnostics, checks `diagnostics_timestamp` that it's a newer set.",
        "pr_file_module": null
      },
      {
        "comment_id": "1812379415",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 19230,
        "pr_file": "crates/project/src/lsp_store.rs",
        "discussion_id": "1801518919",
        "commented_code": "@@ -2886,6 +2887,15 @@ impl LspStore {\n                     },\n                 )\n                 .log_err();\n+\n+            let buffer_handle = buffer_handle.clone();\n+            cx.spawn(move |this, mut cx| async move {\n+                this.update(&mut cx, |this, cx| {",
        "comment_created_at": "2024-10-23T09:55:14+00:00",
        "comment_author": "SomeoneToIgnore",
        "comment_body": "One thing the new model implies though, is the need to explicitly query multiple servers.\r\nCurrent code sets up the listeners per language server, so what looks like a single LSP query can be N (e.g. tailwind-css project that will have TS langserver + tailwind langserver + maybe prettier/biome and/or eslint servers on top).\r\n\r\nThe new way will require more code and will make it more explicit with `MultiLspQuery`, but maybe it's even better as simpler to understand?\r\n\r\n",
        "pr_file_module": null
      },
      {
        "comment_id": "1897774159",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 19230,
        "pr_file": "crates/project/src/lsp_store.rs",
        "discussion_id": "1801518919",
        "commented_code": "@@ -2886,6 +2887,15 @@ impl LspStore {\n                     },\n                 )\n                 .log_err();\n+\n+            let buffer_handle = buffer_handle.clone();\n+            cx.spawn(move |this, mut cx| async move {\n+                this.update(&mut cx, |this, cx| {",
        "comment_created_at": "2024-12-26T09:09:13+00:00",
        "comment_author": "vitallium",
        "comment_body": "Changed that to `MultiLspQuery`.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "1944753158",
    "pr_number": 22668,
    "pr_file": "crates/editor/src/editor.rs",
    "created_at": "2025-02-06T13:45:08+00:00",
    "commented_code": "}\n     }\n \n+    pub fn show_inline_diagnostics(&mut self) -> bool {\n+        self.show_inline_diagnostics\n+    }\n+\n+    /// Used to disable the inline diagnostics rendering in the ProjectDiagnostics\n+    /// multi-buffer.\n+    pub fn set_show_inline_diagnostics(&mut self, enabled: bool) {\n+        self.show_inline_diagnostics = enabled;\n+    }\n+\n+    pub fn toggle_show_inline_diagnostics(&mut self, _cx: &mut Context<Self>) {\n+        self.show_inline_diagnostics = !self.show_inline_diagnostics;\n+\n+        // ToDo: if !show, clear preprocessed diagnostics, else, kick off timer\n+        // to collect new diagnostics.\n+    }\n+\n+    fn on_diagnostics_updated(\n+        &mut self,\n+        _: &Entity<MultiBuffer>,\n+        event: &multi_buffer::Event,\n+        window: &mut Window,\n+        cx: &mut Context<Self>,\n+    ) {\n+        if !matches!(event, multi_buffer::Event::DiagnosticsUpdated) {\n+            return;\n+        }\n+\n+        let settings = ProjectSettings::get_global(cx);\n+        if !settings.diagnostics.inline().enabled() {\n+            return;\n+        }\n+\n+        if let Some(delay) = settings.diagnostics.inline().update_debounce_ms() {\n+            self.show_inline_diagnostics_delay_task =\n+                Some(cx.spawn_in(window, |this, mut cx| async move {\n+                    cx.background_executor().timer(delay).await;\n+                    this.update(&mut cx, |this, cx| {\n+                        this.update_inline_diagnostics(cx);\n+                        cx.notify();\n+                    })\n+                    .log_err();\n+                }));\n+        }\n+    }\n+\n+    fn update_inline_diagnostics(&mut self, cx: &mut Context<Self>) {\n+        let display_map = self.display_map.update(cx, |map, cx| map.snapshot(cx));\n+        let buffer = self.buffer.read(cx).snapshot(cx);\n+        let diagnostics = buffer\n+            .diagnostics_in_range::<_, Point>(0..buffer.len())\n+            .sorted_by_key(|diagnostic| {\n+                (\n+                    diagnostic.diagnostic.severity,\n+                    std::cmp::Reverse(diagnostic.diagnostic.is_primary),\n+                    diagnostic.range.start.row,\n+                    diagnostic.range.start.column,\n+                )\n+            })\n+            .collect::<Vec<_>>();\n+\n+        self.inline_diagnostics.clear();",
    "repo_full_name": "zed-industries/zed",
    "discussion_comments": [
      {
        "comment_id": "1944753158",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 22668,
        "pr_file": "crates/editor/src/editor.rs",
        "discussion_id": "1944753158",
        "commented_code": "@@ -11162,6 +11175,116 @@ impl Editor {\n         }\n     }\n \n+    pub fn show_inline_diagnostics(&mut self) -> bool {\n+        self.show_inline_diagnostics\n+    }\n+\n+    /// Used to disable the inline diagnostics rendering in the ProjectDiagnostics\n+    /// multi-buffer.\n+    pub fn set_show_inline_diagnostics(&mut self, enabled: bool) {\n+        self.show_inline_diagnostics = enabled;\n+    }\n+\n+    pub fn toggle_show_inline_diagnostics(&mut self, _cx: &mut Context<Self>) {\n+        self.show_inline_diagnostics = !self.show_inline_diagnostics;\n+\n+        // ToDo: if !show, clear preprocessed diagnostics, else, kick off timer\n+        // to collect new diagnostics.\n+    }\n+\n+    fn on_diagnostics_updated(\n+        &mut self,\n+        _: &Entity<MultiBuffer>,\n+        event: &multi_buffer::Event,\n+        window: &mut Window,\n+        cx: &mut Context<Self>,\n+    ) {\n+        if !matches!(event, multi_buffer::Event::DiagnosticsUpdated) {\n+            return;\n+        }\n+\n+        let settings = ProjectSettings::get_global(cx);\n+        if !settings.diagnostics.inline().enabled() {\n+            return;\n+        }\n+\n+        if let Some(delay) = settings.diagnostics.inline().update_debounce_ms() {\n+            self.show_inline_diagnostics_delay_task =\n+                Some(cx.spawn_in(window, |this, mut cx| async move {\n+                    cx.background_executor().timer(delay).await;\n+                    this.update(&mut cx, |this, cx| {\n+                        this.update_inline_diagnostics(cx);\n+                        cx.notify();\n+                    })\n+                    .log_err();\n+                }));\n+        }\n+    }\n+\n+    fn update_inline_diagnostics(&mut self, cx: &mut Context<Self>) {\n+        let display_map = self.display_map.update(cx, |map, cx| map.snapshot(cx));\n+        let buffer = self.buffer.read(cx).snapshot(cx);\n+        let diagnostics = buffer\n+            .diagnostics_in_range::<_, Point>(0..buffer.len())\n+            .sorted_by_key(|diagnostic| {\n+                (\n+                    diagnostic.diagnostic.severity,\n+                    std::cmp::Reverse(diagnostic.diagnostic.is_primary),\n+                    diagnostic.range.start.row,\n+                    diagnostic.range.start.column,\n+                )\n+            })\n+            .collect::<Vec<_>>();\n+\n+        self.inline_diagnostics.clear();",
        "comment_created_at": "2025-02-06T13:45:08+00:00",
        "comment_author": "SomeoneToIgnore",
        "comment_body": "This is the core place, combining multiple new feedback from this review.\r\n\r\nhttps://github.com/user-attachments/assets/99f8f320-2b24-44cc-a926-9ef928a08fa2\r\n\r\nInteresting, I've intuitively expected that `clear` will cause a lot more issues with flickering, if the diagnostics retrieval is slow due to the amount of the diagnostics, but even on the large example it's not that bad.\r\n\r\nI think we're saved here by the fact that Zed already has issues with large amounts of diagnostics, hence we're not seeing the new ones.\r\nI would propose still, to rework this a slightly:\r\n* accumulate new state (`inline_diagnostics`) first, and mutate the state it in the very end of the task, once\r\n* pass everything that does not depend on `self` and `cx` through `cx.background_spawn(async move { ... }).await` \r\n\r\nCombined, something like\r\n```rs\r\nlet new_inlay_hints = cx.background_spawn(async move {\r\n    let mut new_inlined_diagnostics: Vec<(Anchor, InlineDiagnostic)> = Vec::new();\r\n    let mut prev_diagnostic_line = None;\r\n    for diagnostic in diagnostics {\r\n        //........\r\n        new_inlined_diagnostics..binary_search_by(|probe| {\r\n            diagnostic_anchor.cmp(&probe.0, &buffer)\r\n        });\r\n        //........\r\n    }\r\n}).await;\r\n//........\r\nself.inline_diagnostics = new_inline_diagnostics;\r\n```\r\n\r\nThis way, we'll be usually on a background thread, debounced or computing, cancelled on concequent requests.\r\nOld state will be kept, and Anchor (from Editor) -> DisplayPoint (when laying out) conversion will keep the diagnostics placed on the right lines when rendering, even after adding newlines or undoing.\r\n\r\nLarge diagnostics sets to process will cause more stale diagnostics text during fast editing, but as a somewhat inevitable trade-off, which does not flicker at least.",
        "pr_file_module": null
      }
    ]
  }
]