[
  {
    "discussion_id": "2178047978",
    "pr_number": 29359,
    "pr_file": "crates/project/src/project.rs",
    "created_at": "2025-07-01T16:30:50+00:00",
    "commented_code": "pub value: String,\n }\n \n-#[derive(Debug, Clone)]\n+#[derive(Debug, Clone, PartialEq)]",
    "repo_full_name": "zed-industries/zed",
    "discussion_comments": [
      {
        "comment_id": "2178047978",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 29359,
        "pr_file": "crates/project/src/project.rs",
        "discussion_id": "2178047978",
        "commented_code": "@@ -695,7 +695,7 @@ pub struct MarkupContent {\n     pub value: String,\n }\n \n-#[derive(Debug, Clone)]\n+#[derive(Debug, Clone, PartialEq)]",
        "comment_created_at": "2025-07-01T16:30:50+00:00",
        "comment_author": "XiNiHa",
        "comment_body": "I also considered only comparing the `target` for deduping but went with this for now",
        "pr_file_module": null
      },
      {
        "comment_id": "2178053563",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 29359,
        "pr_file": "crates/project/src/project.rs",
        "discussion_id": "2178047978",
        "commented_code": "@@ -695,7 +695,7 @@ pub struct MarkupContent {\n     pub value: String,\n }\n \n-#[derive(Debug, Clone)]\n+#[derive(Debug, Clone, PartialEq)]",
        "comment_created_at": "2025-07-01T16:34:19+00:00",
        "comment_author": "SomeoneToIgnore",
        "comment_body": "To note, `dedup` is the wrong method to deduplicate things in a `Vec`, as it only works for sequential items:\r\nhttps://doc.rust-lang.org/std/vec/struct.Vec.html#method.dedup\r\n\r\nIt seems that we could try and either use a HashSet (I had to implement a few `Hash` manually for document colors for this approach), or use a method from `Itertools` for a proper deduplication, [`dedup_by`](https://docs.rs/itertools/latest/itertools/trait.Itertools.html#method.dedup_by)",
        "pr_file_module": null
      },
      {
        "comment_id": "2178074282",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 29359,
        "pr_file": "crates/project/src/project.rs",
        "discussion_id": "2178047978",
        "commented_code": "@@ -695,7 +695,7 @@ pub struct MarkupContent {\n     pub value: String,\n }\n \n-#[derive(Debug, Clone)]\n+#[derive(Debug, Clone, PartialEq)]",
        "comment_created_at": "2025-07-01T16:46:06+00:00",
        "comment_author": "XiNiHa",
        "comment_body": "The method used is not `Vec::dedup` but [`Itertools::dedup`](https://docs.rs/itertools/latest/itertools/trait.Itertools.html#method.dedup) (since we're doing `.dedup()` on iterators, not `Vec`s) therefore have same result with `dedup_by` except that it uses `PartialEq` for comparison \ud83d\ude09",
        "pr_file_module": null
      },
      {
        "comment_id": "2178080570",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 29359,
        "pr_file": "crates/project/src/project.rs",
        "discussion_id": "2178047978",
        "commented_code": "@@ -695,7 +695,7 @@ pub struct MarkupContent {\n     pub value: String,\n }\n \n-#[derive(Debug, Clone)]\n+#[derive(Debug, Clone, PartialEq)]",
        "comment_created_at": "2025-07-01T16:50:24+00:00",
        "comment_author": "SomeoneToIgnore",
        "comment_body": "Ahh, traits.\r\nThank you, I would not think of this method seeing a `Vec` around.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2177327681",
    "pr_number": 33490,
    "pr_file": "crates/outline_panel/src/outline_panel.rs",
    "created_at": "2025-07-01T11:24:52+00:00",
    "commented_code": "Some(UPDATE_DEBOUNCE)\n                                     };\n                                     excerpt.outlines = ExcerptOutlines::Outlines(fetched_outlines);\n+\n+                                    // Collect outlines to check for default expansion\n+                                    let outlines_to_check =\n+                                        if let Some(default_depth) = pending_default_depth {\n+                                            if let ExcerptOutlines::Outlines(outlines) =\n+                                                &excerpt.outlines\n+                                            {\n+                                                if default_depth == 0 {\n+                                                    // For depth 0, collapse all outlines with children\n+                                                    outlines.clone()\n+                                                } else {\n+                                                    // For other depths, collapse outlines at or below that depth\n+                                                    outlines\n+                                                        .iter()\n+                                                        .filter(|outline| {\n+                                                            outline.depth >= default_depth\n+                                                        })\n+                                                        .cloned()\n+                                                        .collect::<Vec<_>>()\n+                                                }\n+                                            } else {\n+                                                Vec::new()\n+                                            }\n+                                        } else {\n+                                            Vec::new()\n+                                        };\n+\n+                                    Some((debounce, outlines_to_check))\n+                                } else {\n+                                    None\n+                                };\n+\n+                                // Now check which outlines have children and should be collapsed\n+                                if let Some((debounce, outlines_to_check)) = outlines_to_check {\n+                                    for outline in outlines_to_check {\n+                                        let outline_entry = OutlineEntryOutline {\n+                                            buffer_id,\n+                                            excerpt_id,\n+                                            outline: outline.clone(),\n+                                        };\n+                                        if outline_panel.has_outline_children(&outline_entry, cx) {",
    "repo_full_name": "zed-industries/zed",
    "discussion_comments": [
      {
        "comment_id": "2177327681",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 33490,
        "pr_file": "crates/outline_panel/src/outline_panel.rs",
        "discussion_id": "2177327681",
        "commented_code": "@@ -3267,6 +3373,57 @@ impl OutlinePanel {\n                                         Some(UPDATE_DEBOUNCE)\n                                     };\n                                     excerpt.outlines = ExcerptOutlines::Outlines(fetched_outlines);\n+\n+                                    // Collect outlines to check for default expansion\n+                                    let outlines_to_check =\n+                                        if let Some(default_depth) = pending_default_depth {\n+                                            if let ExcerptOutlines::Outlines(outlines) =\n+                                                &excerpt.outlines\n+                                            {\n+                                                if default_depth == 0 {\n+                                                    // For depth 0, collapse all outlines with children\n+                                                    outlines.clone()\n+                                                } else {\n+                                                    // For other depths, collapse outlines at or below that depth\n+                                                    outlines\n+                                                        .iter()\n+                                                        .filter(|outline| {\n+                                                            outline.depth >= default_depth\n+                                                        })\n+                                                        .cloned()\n+                                                        .collect::<Vec<_>>()\n+                                                }\n+                                            } else {\n+                                                Vec::new()\n+                                            }\n+                                        } else {\n+                                            Vec::new()\n+                                        };\n+\n+                                    Some((debounce, outlines_to_check))\n+                                } else {\n+                                    None\n+                                };\n+\n+                                // Now check which outlines have children and should be collapsed\n+                                if let Some((debounce, outlines_to_check)) = outlines_to_check {\n+                                    for outline in outlines_to_check {\n+                                        let outline_entry = OutlineEntryOutline {\n+                                            buffer_id,\n+                                            excerpt_id,\n+                                            outline: outline.clone(),\n+                                        };\n+                                        if outline_panel.has_outline_children(&outline_entry, cx) {",
        "comment_created_at": "2025-07-01T11:24:52+00:00",
        "comment_author": "SomeoneToIgnore",
        "comment_body": "This is odd: effectively, we go over all `fetched_outlines` and for each, we we-iteratethe outlines list again to find the children.\r\n\r\nIt's a plain O(N^2) for nothing and should be fixed.\r\nWe do `outlines.retain(|outline| {` right above and can prepare a depth map for any decision of a kind.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2164660257",
    "pr_number": 33315,
    "pr_file": "crates/language_models/src/provider/vercel.rs",
    "created_at": "2025-06-24T18:33:12+00:00",
    "commented_code": "}\n \n     fn provided_models(&self, cx: &App) -> Vec<Arc<dyn LanguageModel>> {\n-        let mut models = BTreeMap::default();\n+        let mut models = Vec::new();",
    "repo_full_name": "zed-industries/zed",
    "discussion_comments": [
      {
        "comment_id": "2164660257",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 33315,
        "pr_file": "crates/language_models/src/provider/vercel.rs",
        "discussion_id": "2164660257",
        "commented_code": "@@ -198,35 +198,33 @@ impl LanguageModelProvider for VercelLanguageModelProvider {\n     }\n \n     fn provided_models(&self, cx: &App) -> Vec<Arc<dyn LanguageModel>> {\n-        let mut models = BTreeMap::default();\n+        let mut models = Vec::new();",
        "comment_created_at": "2025-06-24T18:33:12+00:00",
        "comment_author": "imumesh18",
        "comment_body": "moved to vec as btree was automatically sorting the models and they were getting jumbled. Expected order should be Vercel v0 1.5 Small,Vercel v0 1.5 Medium,Vercel v0 1.5 Large but it was sorting it alphabetically and making Vercel v0 1.5 Large first and Small last.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2062684723",
    "pr_number": 29496,
    "pr_file": "crates/open_router/src/open_router.rs",
    "created_at": "2025-04-27T17:36:30+00:00",
    "commented_code": "+use anyhow::{Context, Result, anyhow};\n+use futures::{\n+    AsyncBufReadExt, AsyncReadExt, StreamExt,\n+    io::BufReader,\n+    stream::{self, BoxStream},\n+};\n+use http_client::{AsyncBody, HttpClient, Method, Request as HttpRequest};\n+use serde::{Deserialize, Serialize};\n+use serde_json::Value;\n+use std::{\n+    convert::TryFrom,\n+    future::{self},\n+};\n+\n+pub const OPEN_ROUTER_API_URL: &str = \"https://openrouter.ai/api/v1\";\n+\n+fn is_none_or_empty<T: AsRef<[U]>, U>(opt: &Option<T>) -> bool {\n+    opt.as_ref().map_or(true, |v| v.as_ref().is_empty())\n+}\n+\n+#[derive(Clone, Copy, Serialize, Deserialize, Debug, Eq, PartialEq)]\n+#[serde(rename_all = \"lowercase\")]\n+pub enum Role {\n+    User,\n+    Assistant,\n+    System,\n+    Tool,\n+}\n+\n+impl TryFrom<String> for Role {\n+    type Error = anyhow::Error;\n+\n+    fn try_from(value: String) -> Result<Self> {\n+        match value.as_str() {\n+            \"user\" => Ok(Self::User),\n+            \"assistant\" => Ok(Self::Assistant),\n+            \"system\" => Ok(Self::System),\n+            \"tool\" => Ok(Self::Tool),\n+            _ => Err(anyhow!(\"invalid role '{value}'\")),\n+        }\n+    }\n+}\n+\n+impl From<Role> for String {\n+    fn from(val: Role) -> Self {\n+        match val {\n+            Role::User => \"user\".to_owned(),\n+            Role::Assistant => \"assistant\".to_owned(),\n+            Role::System => \"system\".to_owned(),\n+            Role::Tool => \"tool\".to_owned(),\n+        }\n+    }\n+}\n+\n+#[cfg_attr(feature = \"schemars\", derive(schemars::JsonSchema))]\n+#[derive(Clone, Debug, Default, Serialize, Deserialize, PartialEq)]\n+pub struct Model {\n+    pub name: String,\n+    pub display_name: Option<String>,\n+    pub max_tokens: usize,\n+    pub supports_tool_calls: bool,\n+    pub excels_at_coding: bool,\n+}\n+\n+impl Model {\n+    pub fn default_fast() -> Self {\n+        Self::new(\n+            \"openrouter/auto\",\n+            Some(\"Auto Router\"),\n+            Some(2000000),\n+            true,\n+            true,\n+        )\n+    }\n+\n+    pub fn default() -> Self {\n+        Self::default_fast()\n+    }\n+\n+    pub fn new(\n+        name: &str,\n+        display_name: Option<&str>,\n+        max_tokens: Option<usize>,\n+        supports_tool_calls: bool,\n+        excels_at_coding: bool,\n+    ) -> Self {\n+        Self {\n+            name: name.to_owned(),\n+            display_name: display_name.map(|s| s.to_owned()),\n+            max_tokens: max_tokens.unwrap_or(2000000),\n+            supports_tool_calls,\n+            excels_at_coding,\n+        }\n+    }\n+\n+    pub fn id(&self) -> &str {\n+        &self.name\n+    }\n+\n+    pub fn display_name(&self) -> &str {\n+        self.display_name.as_ref().unwrap_or(&self.name)\n+    }\n+\n+    pub fn max_token_count(&self) -> usize {\n+        self.max_tokens\n+    }\n+\n+    pub fn max_output_tokens(&self) -> Option<u32> {\n+        u32::try_from(self.max_tokens).ok()\n+    }\n+\n+    pub fn supports_tool_calls(&self) -> bool {\n+        self.supports_tool_calls\n+    }\n+\n+    pub fn excels_at_coding(&self) -> bool {\n+        self.excels_at_coding\n+    }\n+\n+    /// Indicates whether the model supports parallel tool calls.\n+    /// Currently, this always returns `false` as the functionality is not implemented.\n+    /// This may serve as a placeholder for future enhancements.\n+    pub fn supports_parallel_tool_calls(&self) -> bool {\n+        false\n+    }\n+}\n+\n+#[derive(Debug, Serialize, Deserialize)]\n+pub struct Request {\n+    pub model: String,\n+    pub messages: Vec<RequestMessage>,\n+    pub stream: bool,\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub max_tokens: Option<u32>,\n+    #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n+    pub stop: Vec<String>,\n+    pub temperature: f32,\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub tool_choice: Option<ToolChoice>,\n+    /// Whether to enable parallel function calling during tool use.\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub parallel_tool_calls: Option<bool>,\n+    #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n+    pub tools: Vec<ToolDefinition>,\n+    /// HTTP referer header for OpenRouter attribution\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub http_referer: Option<String>,\n+    /// HTTP user-agent header for OpenRouter attribution\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub http_user_agent: Option<String>,\n+}\n+\n+#[derive(Debug, Serialize, Deserialize)]\n+#[serde(untagged)]\n+pub enum ToolChoice {\n+    Auto,\n+    Required,\n+    None,\n+    Other(ToolDefinition),\n+}\n+\n+#[cfg_attr(feature = \"schemars\", derive(schemars::JsonSchema))]\n+#[derive(Clone, Deserialize, Serialize, Debug)]\n+#[serde(tag = \"type\", rename_all = \"snake_case\")]\n+pub enum ToolDefinition {\n+    #[allow(dead_code)]\n+    Function { function: FunctionDefinition },\n+}\n+\n+#[cfg_attr(feature = \"schemars\", derive(schemars::JsonSchema))]\n+#[derive(Clone, Debug, Serialize, Deserialize)]\n+pub struct FunctionDefinition {\n+    pub name: String,\n+    pub description: Option<String>,\n+    pub parameters: Option<Value>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+#[serde(tag = \"role\", rename_all = \"lowercase\")]\n+pub enum RequestMessage {\n+    Assistant {\n+        content: Option<String>,\n+        #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n+        tool_calls: Vec<ToolCall>,\n+    },\n+    User {\n+        content: String,\n+    },\n+    System {\n+        content: String,\n+    },\n+    Tool {\n+        content: String,\n+        tool_call_id: String,\n+    },\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct ToolCall {\n+    pub id: String,\n+    #[serde(flatten)]\n+    pub content: ToolCallContent,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+#[serde(tag = \"type\", rename_all = \"lowercase\")]\n+pub enum ToolCallContent {\n+    Function { function: FunctionContent },\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct FunctionContent {\n+    pub name: String,\n+    pub arguments: String,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct ResponseMessageDelta {\n+    pub role: Option<Role>,\n+    pub content: Option<String>,\n+    #[serde(default, skip_serializing_if = \"is_none_or_empty\")]\n+    pub tool_calls: Option<Vec<ToolCallChunk>>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct ToolCallChunk {\n+    pub index: usize,\n+    pub id: Option<String>,\n+    pub function: Option<FunctionChunk>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct FunctionChunk {\n+    pub name: Option<String>,\n+    pub arguments: Option<String>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct Usage {\n+    pub prompt_tokens: u32,\n+    pub completion_tokens: u32,\n+    pub total_tokens: u32,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct ChoiceDelta {\n+    pub index: u32,\n+    pub delta: ResponseMessageDelta,\n+    pub finish_reason: Option<String>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+#[serde(untagged)]\n+pub enum ResponseStreamResult {\n+    Ok(ResponseStreamEvent),\n+    Err { error: String },\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct ResponseStreamEvent {\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub id: Option<String>,\n+    pub created: u32,\n+    pub model: String,\n+    pub choices: Vec<ChoiceDelta>,\n+    pub usage: Option<Usage>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct Response {\n+    pub id: String,\n+    pub object: String,\n+    pub created: u64,\n+    pub model: String,\n+    pub choices: Vec<Choice>,\n+    pub usage: Usage,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct Choice {\n+    pub index: u32,\n+    pub message: RequestMessage,\n+    pub finish_reason: Option<String>,\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct ListModelsResponse {\n+    pub data: Vec<ModelEntry>,\n+}\n+\n+fn is_false(v: &bool) -> bool {\n+    !*v\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct ModelEntry {\n+    pub id: String,\n+    pub name: String,\n+    pub created: i64,\n+    pub description: String,\n+    pub context_length: i64,\n+    pub architecture: Architecture,\n+    pub pricing: Pricing,\n+    pub top_provider: TopProvider,\n+    pub per_request_limits: Value,\n+    /// Indicates whether the model can handle OpenAI\u2011style tool/function calls.\n+    #[serde(default, skip_serializing_if = \"is_false\")]\n+    pub supports_tool_calls: bool,\n+    /// Indicates whether the model is generally strong at code\u2011related tasks.\n+    #[serde(default, skip_serializing_if = \"is_false\")]\n+    pub excels_at_coding: bool,\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct Architecture {\n+    pub modality: String,\n+    pub input_modalities: Vec<String>,\n+    pub output_modalities: Vec<String>,\n+    pub tokenizer: String,\n+    pub instruct_type: Option<String>,\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct Pricing {\n+    pub prompt: String,\n+    pub completion: String,\n+    pub request: Option<String>,\n+    pub image: Option<String>,\n+    pub web_search: Option<String>,\n+    pub internal_reasoning: Option<String>,\n+    pub input_cache_read: Option<String>,\n+    pub input_cache_write: Option<String>,\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct TopProvider {\n+    pub context_length: Option<i64>,\n+    pub max_completion_tokens: Option<i64>,\n+    pub is_moderated: bool,\n+}\n+\n+pub async fn complete(\n+    client: &dyn HttpClient,\n+    api_url: &str,\n+    api_key: &str,\n+    request: Request,\n+) -> Result<Response> {\n+    let uri = format!(\"{api_url}/chat/completions\");\n+    let request_builder = HttpRequest::builder()\n+        .method(Method::POST)\n+        .uri(uri)\n+        .header(\"Content-Type\", \"application/json\")\n+        .header(\"Authorization\", format!(\"Bearer {}\", api_key))\n+        .header(\"HTTP-Referer\", \"zed.dev\")\n+        .header(\"X-Title\", \"Zed Editor\");\n+\n+    let mut request_body = request;\n+    request_body.stream = false;\n+    request_body.http_referer = Some(\"zed.dev\".to_string());\n+    request_body.http_user_agent = Some(\"Zed Editor\".to_string());\n+\n+    let request = request_builder.body(AsyncBody::from(serde_json::to_string(&request_body)?))?;\n+    let mut response = client.send(request).await?;\n+\n+    if response.status().is_success() {\n+        let mut body = String::new();\n+        response.body_mut().read_to_string(&mut body).await?;\n+        let response: Response = serde_json::from_str(&body)?;\n+        Ok(response)\n+    } else {\n+        let mut body = String::new();\n+        response.body_mut().read_to_string(&mut body).await?;\n+\n+        #[derive(Deserialize)]\n+        struct OpenRouterResponse {\n+            error: OpenRouterError,\n+        }\n+\n+        #[derive(Deserialize)]\n+        struct OpenRouterError {\n+            message: String,\n+            #[serde(default)]\n+            code: String,\n+        }\n+\n+        match serde_json::from_str::<OpenRouterResponse>(&body) {\n+            Ok(response) if !response.error.message.is_empty() => {\n+                let error_message = if !response.error.code.is_empty() {\n+                    format!(\"{}: {}\", response.error.code, response.error.message)\n+                } else {\n+                    response.error.message\n+                };\n+\n+                Err(anyhow!(\n+                    \"Failed to connect to OpenRouter API: {}\",\n+                    error_message\n+                ))\n+            }\n+            _ => Err(anyhow!(\n+                \"Failed to connect to OpenRouter API: {} {}\",\n+                response.status(),\n+                body,\n+            )),\n+        }\n+    }\n+}\n+\n+fn adapt_response_to_stream(response: Response) -> ResponseStreamEvent {\n+    ResponseStreamEvent {\n+        id: Some(response.id),\n+        created: response.created as u32,\n+        model: response.model,\n+        choices: response\n+            .choices\n+            .into_iter()\n+            .map(|choice| ChoiceDelta {\n+                index: choice.index,\n+                delta: ResponseMessageDelta {\n+                    role: Some(match choice.message {\n+                        RequestMessage::Assistant { .. } => Role::Assistant,\n+                        RequestMessage::User { .. } => Role::User,\n+                        RequestMessage::System { .. } => Role::System,\n+                        RequestMessage::Tool { .. } => Role::Tool,\n+                    }),\n+                    content: match choice.message {\n+                        RequestMessage::Assistant { content, .. } => content,\n+                        RequestMessage::User { content } => Some(content),\n+                        RequestMessage::System { content } => Some(content),\n+                        RequestMessage::Tool { content, .. } => Some(content),\n+                    },\n+                    tool_calls: None,\n+                },\n+                finish_reason: choice.finish_reason,\n+            })\n+            .collect(),\n+        usage: Some(response.usage),\n+    }\n+}\n+\n+pub async fn stream_completion(\n+    client: &dyn HttpClient,\n+    api_url: &str,\n+    api_key: &str,\n+    request: Request,\n+) -> Result<BoxStream<'static, Result<ResponseStreamEvent>>> {\n+    // Some models don't support streaming\n+    let model_id = &request.model;\n+    let non_streaming_models = [\"meta-llama/\", \"google/\"];\n+    if non_streaming_models\n+        .iter()\n+        .any(|prefix| model_id.starts_with(prefix))\n+    {\n+        let response = complete(client, api_url, api_key, request).await;\n+        let response_stream_event = response.map(adapt_response_to_stream);\n+        return Ok(stream::once(future::ready(response_stream_event)).boxed());\n+    }\n+\n+    let uri = format!(\"{api_url}/chat/completions\");\n+    let request_builder = HttpRequest::builder()\n+        .method(Method::POST)\n+        .uri(uri)\n+        .header(\"Content-Type\", \"application/json\")\n+        .header(\"Authorization\", format!(\"Bearer {}\", api_key))\n+        .header(\"HTTP-Referer\", \"zed.dev\")\n+        .header(\"X-Title\", \"Zed Editor\");\n+\n+    // Add OpenRouter-specific fields\n+    let mut request = request;\n+    request.http_referer = Some(\"zed.dev\".to_string());\n+    request.http_user_agent = Some(\"Zed Editor\".to_string());\n+\n+    let request = request_builder.body(AsyncBody::from(serde_json::to_string(&request)?))?;\n+    let mut response = client.send(request).await?;\n+\n+    if response.status().is_success() {\n+        let reader = BufReader::new(response.into_body());\n+        Ok(reader\n+            .lines()\n+            .filter_map(|line| async move {\n+                match line {\n+                    Ok(line) => {\n+                        // Handle SSE comments that OpenRouter sends to prevent connection timeouts\n+                        if line.starts_with(':') {\n+                            // This is a comment line (e.g., \": OPENROUTER PROCESSING\")\n+                            // We can ignore it per SSE specs\n+                            return None;\n+                        }\n+\n+                        let line = line.strip_prefix(\"data: \")?;\n+                        if line == \"[DONE]\" {\n+                            None\n+                        } else {\n+                            // For OpenRouter, directly parse the stream event rather than expecting\n+                            // an untagged enum like OpenAI\n+                            match serde_json::from_str::<ResponseStreamEvent>(line) {\n+                                Ok(response) => Some(Ok(response)),\n+                                Err(error) => {\n+                                    // Try to parse as an error message\n+                                    #[derive(Deserialize)]\n+                                    struct ErrorResponse {\n+                                        error: String,\n+                                    }\n+\n+                                    match serde_json::from_str::<ErrorResponse>(line) {\n+                                        Ok(err_response) => Some(Err(anyhow!(err_response.error))),\n+                                        Err(_) => {\n+                                            // Check if it's an empty line or other non-JSON content\n+                                            if line.trim().is_empty() {\n+                                                None\n+                                            } else {\n+                                                Some(Err(anyhow!(\n+                                                    \"Failed to parse response: {}. Original content: '{}'\",\n+                                                    error, line\n+                                                )))\n+                                            }\n+                                        }\n+                                    }\n+                                }\n+                            }\n+                        }\n+                    }\n+                    Err(error) => Some(Err(anyhow!(error))),\n+                }\n+            })\n+            .boxed())\n+    } else {\n+        let mut body = String::new();\n+        response.body_mut().read_to_string(&mut body).await?;\n+\n+        #[derive(Deserialize)]\n+        struct OpenRouterResponse {\n+            error: OpenRouterError,\n+        }\n+\n+        #[derive(Deserialize)]\n+        struct OpenRouterError {\n+            message: String,\n+            #[serde(default)]\n+            code: String,\n+        }\n+\n+        match serde_json::from_str::<OpenRouterResponse>(&body) {\n+            Ok(response) if !response.error.message.is_empty() => {\n+                let error_message = if !response.error.code.is_empty() {\n+                    format!(\"{}: {}\", response.error.code, response.error.message)\n+                } else {\n+                    response.error.message\n+                };\n+\n+                Err(anyhow!(\n+                    \"Failed to connect to OpenRouter API: {}\",\n+                    error_message\n+                ))\n+            }\n+            _ => Err(anyhow!(\n+                \"Failed to connect to OpenRouter API: {} {}\",\n+                response.status(),\n+                body,\n+            )),\n+        }\n+    }\n+}\n+\n+pub async fn get_models(client: &dyn HttpClient, api_url: &str) -> Result<Vec<ModelEntry>> {\n+    // Get base model list\n+    let mut models = fetch_models(client, api_url, None).await?;\n+\n+    // Get models that support tool calls\n+    let tool_models = fetch_models(client, api_url, Some(\"supported_parameters=tools\")).await?;\n+    let tool_model_ids: Vec<String> = tool_models.iter().map(|m| m.id.clone()).collect();\n+\n+    // Get models that excel at coding\n+    let coding_models = fetch_models(client, api_url, Some(\"category=programming\")).await?;\n+    let coding_model_ids: Vec<String> = coding_models.iter().map(|m| m.id.clone()).collect();\n+\n+    // Update model flags based on the specialized queries\n+    for model in &mut models {\n+        model.supports_tool_calls = tool_model_ids.contains(&model.id);\n+        model.excels_at_coding = coding_model_ids.contains(&model.id);\n+    }",
    "repo_full_name": "zed-industries/zed",
    "discussion_comments": [
      {
        "comment_id": "2062684723",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 29496,
        "pr_file": "crates/open_router/src/open_router.rs",
        "discussion_id": "2062684723",
        "commented_code": "@@ -0,0 +1,617 @@\n+use anyhow::{Context, Result, anyhow};\n+use futures::{\n+    AsyncBufReadExt, AsyncReadExt, StreamExt,\n+    io::BufReader,\n+    stream::{self, BoxStream},\n+};\n+use http_client::{AsyncBody, HttpClient, Method, Request as HttpRequest};\n+use serde::{Deserialize, Serialize};\n+use serde_json::Value;\n+use std::{\n+    convert::TryFrom,\n+    future::{self},\n+};\n+\n+pub const OPEN_ROUTER_API_URL: &str = \"https://openrouter.ai/api/v1\";\n+\n+fn is_none_or_empty<T: AsRef<[U]>, U>(opt: &Option<T>) -> bool {\n+    opt.as_ref().map_or(true, |v| v.as_ref().is_empty())\n+}\n+\n+#[derive(Clone, Copy, Serialize, Deserialize, Debug, Eq, PartialEq)]\n+#[serde(rename_all = \"lowercase\")]\n+pub enum Role {\n+    User,\n+    Assistant,\n+    System,\n+    Tool,\n+}\n+\n+impl TryFrom<String> for Role {\n+    type Error = anyhow::Error;\n+\n+    fn try_from(value: String) -> Result<Self> {\n+        match value.as_str() {\n+            \"user\" => Ok(Self::User),\n+            \"assistant\" => Ok(Self::Assistant),\n+            \"system\" => Ok(Self::System),\n+            \"tool\" => Ok(Self::Tool),\n+            _ => Err(anyhow!(\"invalid role '{value}'\")),\n+        }\n+    }\n+}\n+\n+impl From<Role> for String {\n+    fn from(val: Role) -> Self {\n+        match val {\n+            Role::User => \"user\".to_owned(),\n+            Role::Assistant => \"assistant\".to_owned(),\n+            Role::System => \"system\".to_owned(),\n+            Role::Tool => \"tool\".to_owned(),\n+        }\n+    }\n+}\n+\n+#[cfg_attr(feature = \"schemars\", derive(schemars::JsonSchema))]\n+#[derive(Clone, Debug, Default, Serialize, Deserialize, PartialEq)]\n+pub struct Model {\n+    pub name: String,\n+    pub display_name: Option<String>,\n+    pub max_tokens: usize,\n+    pub supports_tool_calls: bool,\n+    pub excels_at_coding: bool,\n+}\n+\n+impl Model {\n+    pub fn default_fast() -> Self {\n+        Self::new(\n+            \"openrouter/auto\",\n+            Some(\"Auto Router\"),\n+            Some(2000000),\n+            true,\n+            true,\n+        )\n+    }\n+\n+    pub fn default() -> Self {\n+        Self::default_fast()\n+    }\n+\n+    pub fn new(\n+        name: &str,\n+        display_name: Option<&str>,\n+        max_tokens: Option<usize>,\n+        supports_tool_calls: bool,\n+        excels_at_coding: bool,\n+    ) -> Self {\n+        Self {\n+            name: name.to_owned(),\n+            display_name: display_name.map(|s| s.to_owned()),\n+            max_tokens: max_tokens.unwrap_or(2000000),\n+            supports_tool_calls,\n+            excels_at_coding,\n+        }\n+    }\n+\n+    pub fn id(&self) -> &str {\n+        &self.name\n+    }\n+\n+    pub fn display_name(&self) -> &str {\n+        self.display_name.as_ref().unwrap_or(&self.name)\n+    }\n+\n+    pub fn max_token_count(&self) -> usize {\n+        self.max_tokens\n+    }\n+\n+    pub fn max_output_tokens(&self) -> Option<u32> {\n+        u32::try_from(self.max_tokens).ok()\n+    }\n+\n+    pub fn supports_tool_calls(&self) -> bool {\n+        self.supports_tool_calls\n+    }\n+\n+    pub fn excels_at_coding(&self) -> bool {\n+        self.excels_at_coding\n+    }\n+\n+    /// Indicates whether the model supports parallel tool calls.\n+    /// Currently, this always returns `false` as the functionality is not implemented.\n+    /// This may serve as a placeholder for future enhancements.\n+    pub fn supports_parallel_tool_calls(&self) -> bool {\n+        false\n+    }\n+}\n+\n+#[derive(Debug, Serialize, Deserialize)]\n+pub struct Request {\n+    pub model: String,\n+    pub messages: Vec<RequestMessage>,\n+    pub stream: bool,\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub max_tokens: Option<u32>,\n+    #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n+    pub stop: Vec<String>,\n+    pub temperature: f32,\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub tool_choice: Option<ToolChoice>,\n+    /// Whether to enable parallel function calling during tool use.\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub parallel_tool_calls: Option<bool>,\n+    #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n+    pub tools: Vec<ToolDefinition>,\n+    /// HTTP referer header for OpenRouter attribution\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub http_referer: Option<String>,\n+    /// HTTP user-agent header for OpenRouter attribution\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub http_user_agent: Option<String>,\n+}\n+\n+#[derive(Debug, Serialize, Deserialize)]\n+#[serde(untagged)]\n+pub enum ToolChoice {\n+    Auto,\n+    Required,\n+    None,\n+    Other(ToolDefinition),\n+}\n+\n+#[cfg_attr(feature = \"schemars\", derive(schemars::JsonSchema))]\n+#[derive(Clone, Deserialize, Serialize, Debug)]\n+#[serde(tag = \"type\", rename_all = \"snake_case\")]\n+pub enum ToolDefinition {\n+    #[allow(dead_code)]\n+    Function { function: FunctionDefinition },\n+}\n+\n+#[cfg_attr(feature = \"schemars\", derive(schemars::JsonSchema))]\n+#[derive(Clone, Debug, Serialize, Deserialize)]\n+pub struct FunctionDefinition {\n+    pub name: String,\n+    pub description: Option<String>,\n+    pub parameters: Option<Value>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+#[serde(tag = \"role\", rename_all = \"lowercase\")]\n+pub enum RequestMessage {\n+    Assistant {\n+        content: Option<String>,\n+        #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n+        tool_calls: Vec<ToolCall>,\n+    },\n+    User {\n+        content: String,\n+    },\n+    System {\n+        content: String,\n+    },\n+    Tool {\n+        content: String,\n+        tool_call_id: String,\n+    },\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct ToolCall {\n+    pub id: String,\n+    #[serde(flatten)]\n+    pub content: ToolCallContent,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+#[serde(tag = \"type\", rename_all = \"lowercase\")]\n+pub enum ToolCallContent {\n+    Function { function: FunctionContent },\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct FunctionContent {\n+    pub name: String,\n+    pub arguments: String,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct ResponseMessageDelta {\n+    pub role: Option<Role>,\n+    pub content: Option<String>,\n+    #[serde(default, skip_serializing_if = \"is_none_or_empty\")]\n+    pub tool_calls: Option<Vec<ToolCallChunk>>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct ToolCallChunk {\n+    pub index: usize,\n+    pub id: Option<String>,\n+    pub function: Option<FunctionChunk>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct FunctionChunk {\n+    pub name: Option<String>,\n+    pub arguments: Option<String>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct Usage {\n+    pub prompt_tokens: u32,\n+    pub completion_tokens: u32,\n+    pub total_tokens: u32,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct ChoiceDelta {\n+    pub index: u32,\n+    pub delta: ResponseMessageDelta,\n+    pub finish_reason: Option<String>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+#[serde(untagged)]\n+pub enum ResponseStreamResult {\n+    Ok(ResponseStreamEvent),\n+    Err { error: String },\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct ResponseStreamEvent {\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub id: Option<String>,\n+    pub created: u32,\n+    pub model: String,\n+    pub choices: Vec<ChoiceDelta>,\n+    pub usage: Option<Usage>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct Response {\n+    pub id: String,\n+    pub object: String,\n+    pub created: u64,\n+    pub model: String,\n+    pub choices: Vec<Choice>,\n+    pub usage: Usage,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct Choice {\n+    pub index: u32,\n+    pub message: RequestMessage,\n+    pub finish_reason: Option<String>,\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct ListModelsResponse {\n+    pub data: Vec<ModelEntry>,\n+}\n+\n+fn is_false(v: &bool) -> bool {\n+    !*v\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct ModelEntry {\n+    pub id: String,\n+    pub name: String,\n+    pub created: i64,\n+    pub description: String,\n+    pub context_length: i64,\n+    pub architecture: Architecture,\n+    pub pricing: Pricing,\n+    pub top_provider: TopProvider,\n+    pub per_request_limits: Value,\n+    /// Indicates whether the model can handle OpenAI\u2011style tool/function calls.\n+    #[serde(default, skip_serializing_if = \"is_false\")]\n+    pub supports_tool_calls: bool,\n+    /// Indicates whether the model is generally strong at code\u2011related tasks.\n+    #[serde(default, skip_serializing_if = \"is_false\")]\n+    pub excels_at_coding: bool,\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct Architecture {\n+    pub modality: String,\n+    pub input_modalities: Vec<String>,\n+    pub output_modalities: Vec<String>,\n+    pub tokenizer: String,\n+    pub instruct_type: Option<String>,\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct Pricing {\n+    pub prompt: String,\n+    pub completion: String,\n+    pub request: Option<String>,\n+    pub image: Option<String>,\n+    pub web_search: Option<String>,\n+    pub internal_reasoning: Option<String>,\n+    pub input_cache_read: Option<String>,\n+    pub input_cache_write: Option<String>,\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct TopProvider {\n+    pub context_length: Option<i64>,\n+    pub max_completion_tokens: Option<i64>,\n+    pub is_moderated: bool,\n+}\n+\n+pub async fn complete(\n+    client: &dyn HttpClient,\n+    api_url: &str,\n+    api_key: &str,\n+    request: Request,\n+) -> Result<Response> {\n+    let uri = format!(\"{api_url}/chat/completions\");\n+    let request_builder = HttpRequest::builder()\n+        .method(Method::POST)\n+        .uri(uri)\n+        .header(\"Content-Type\", \"application/json\")\n+        .header(\"Authorization\", format!(\"Bearer {}\", api_key))\n+        .header(\"HTTP-Referer\", \"zed.dev\")\n+        .header(\"X-Title\", \"Zed Editor\");\n+\n+    let mut request_body = request;\n+    request_body.stream = false;\n+    request_body.http_referer = Some(\"zed.dev\".to_string());\n+    request_body.http_user_agent = Some(\"Zed Editor\".to_string());\n+\n+    let request = request_builder.body(AsyncBody::from(serde_json::to_string(&request_body)?))?;\n+    let mut response = client.send(request).await?;\n+\n+    if response.status().is_success() {\n+        let mut body = String::new();\n+        response.body_mut().read_to_string(&mut body).await?;\n+        let response: Response = serde_json::from_str(&body)?;\n+        Ok(response)\n+    } else {\n+        let mut body = String::new();\n+        response.body_mut().read_to_string(&mut body).await?;\n+\n+        #[derive(Deserialize)]\n+        struct OpenRouterResponse {\n+            error: OpenRouterError,\n+        }\n+\n+        #[derive(Deserialize)]\n+        struct OpenRouterError {\n+            message: String,\n+            #[serde(default)]\n+            code: String,\n+        }\n+\n+        match serde_json::from_str::<OpenRouterResponse>(&body) {\n+            Ok(response) if !response.error.message.is_empty() => {\n+                let error_message = if !response.error.code.is_empty() {\n+                    format!(\"{}: {}\", response.error.code, response.error.message)\n+                } else {\n+                    response.error.message\n+                };\n+\n+                Err(anyhow!(\n+                    \"Failed to connect to OpenRouter API: {}\",\n+                    error_message\n+                ))\n+            }\n+            _ => Err(anyhow!(\n+                \"Failed to connect to OpenRouter API: {} {}\",\n+                response.status(),\n+                body,\n+            )),\n+        }\n+    }\n+}\n+\n+fn adapt_response_to_stream(response: Response) -> ResponseStreamEvent {\n+    ResponseStreamEvent {\n+        id: Some(response.id),\n+        created: response.created as u32,\n+        model: response.model,\n+        choices: response\n+            .choices\n+            .into_iter()\n+            .map(|choice| ChoiceDelta {\n+                index: choice.index,\n+                delta: ResponseMessageDelta {\n+                    role: Some(match choice.message {\n+                        RequestMessage::Assistant { .. } => Role::Assistant,\n+                        RequestMessage::User { .. } => Role::User,\n+                        RequestMessage::System { .. } => Role::System,\n+                        RequestMessage::Tool { .. } => Role::Tool,\n+                    }),\n+                    content: match choice.message {\n+                        RequestMessage::Assistant { content, .. } => content,\n+                        RequestMessage::User { content } => Some(content),\n+                        RequestMessage::System { content } => Some(content),\n+                        RequestMessage::Tool { content, .. } => Some(content),\n+                    },\n+                    tool_calls: None,\n+                },\n+                finish_reason: choice.finish_reason,\n+            })\n+            .collect(),\n+        usage: Some(response.usage),\n+    }\n+}\n+\n+pub async fn stream_completion(\n+    client: &dyn HttpClient,\n+    api_url: &str,\n+    api_key: &str,\n+    request: Request,\n+) -> Result<BoxStream<'static, Result<ResponseStreamEvent>>> {\n+    // Some models don't support streaming\n+    let model_id = &request.model;\n+    let non_streaming_models = [\"meta-llama/\", \"google/\"];\n+    if non_streaming_models\n+        .iter()\n+        .any(|prefix| model_id.starts_with(prefix))\n+    {\n+        let response = complete(client, api_url, api_key, request).await;\n+        let response_stream_event = response.map(adapt_response_to_stream);\n+        return Ok(stream::once(future::ready(response_stream_event)).boxed());\n+    }\n+\n+    let uri = format!(\"{api_url}/chat/completions\");\n+    let request_builder = HttpRequest::builder()\n+        .method(Method::POST)\n+        .uri(uri)\n+        .header(\"Content-Type\", \"application/json\")\n+        .header(\"Authorization\", format!(\"Bearer {}\", api_key))\n+        .header(\"HTTP-Referer\", \"zed.dev\")\n+        .header(\"X-Title\", \"Zed Editor\");\n+\n+    // Add OpenRouter-specific fields\n+    let mut request = request;\n+    request.http_referer = Some(\"zed.dev\".to_string());\n+    request.http_user_agent = Some(\"Zed Editor\".to_string());\n+\n+    let request = request_builder.body(AsyncBody::from(serde_json::to_string(&request)?))?;\n+    let mut response = client.send(request).await?;\n+\n+    if response.status().is_success() {\n+        let reader = BufReader::new(response.into_body());\n+        Ok(reader\n+            .lines()\n+            .filter_map(|line| async move {\n+                match line {\n+                    Ok(line) => {\n+                        // Handle SSE comments that OpenRouter sends to prevent connection timeouts\n+                        if line.starts_with(':') {\n+                            // This is a comment line (e.g., \": OPENROUTER PROCESSING\")\n+                            // We can ignore it per SSE specs\n+                            return None;\n+                        }\n+\n+                        let line = line.strip_prefix(\"data: \")?;\n+                        if line == \"[DONE]\" {\n+                            None\n+                        } else {\n+                            // For OpenRouter, directly parse the stream event rather than expecting\n+                            // an untagged enum like OpenAI\n+                            match serde_json::from_str::<ResponseStreamEvent>(line) {\n+                                Ok(response) => Some(Ok(response)),\n+                                Err(error) => {\n+                                    // Try to parse as an error message\n+                                    #[derive(Deserialize)]\n+                                    struct ErrorResponse {\n+                                        error: String,\n+                                    }\n+\n+                                    match serde_json::from_str::<ErrorResponse>(line) {\n+                                        Ok(err_response) => Some(Err(anyhow!(err_response.error))),\n+                                        Err(_) => {\n+                                            // Check if it's an empty line or other non-JSON content\n+                                            if line.trim().is_empty() {\n+                                                None\n+                                            } else {\n+                                                Some(Err(anyhow!(\n+                                                    \"Failed to parse response: {}. Original content: '{}'\",\n+                                                    error, line\n+                                                )))\n+                                            }\n+                                        }\n+                                    }\n+                                }\n+                            }\n+                        }\n+                    }\n+                    Err(error) => Some(Err(anyhow!(error))),\n+                }\n+            })\n+            .boxed())\n+    } else {\n+        let mut body = String::new();\n+        response.body_mut().read_to_string(&mut body).await?;\n+\n+        #[derive(Deserialize)]\n+        struct OpenRouterResponse {\n+            error: OpenRouterError,\n+        }\n+\n+        #[derive(Deserialize)]\n+        struct OpenRouterError {\n+            message: String,\n+            #[serde(default)]\n+            code: String,\n+        }\n+\n+        match serde_json::from_str::<OpenRouterResponse>(&body) {\n+            Ok(response) if !response.error.message.is_empty() => {\n+                let error_message = if !response.error.code.is_empty() {\n+                    format!(\"{}: {}\", response.error.code, response.error.message)\n+                } else {\n+                    response.error.message\n+                };\n+\n+                Err(anyhow!(\n+                    \"Failed to connect to OpenRouter API: {}\",\n+                    error_message\n+                ))\n+            }\n+            _ => Err(anyhow!(\n+                \"Failed to connect to OpenRouter API: {} {}\",\n+                response.status(),\n+                body,\n+            )),\n+        }\n+    }\n+}\n+\n+pub async fn get_models(client: &dyn HttpClient, api_url: &str) -> Result<Vec<ModelEntry>> {\n+    // Get base model list\n+    let mut models = fetch_models(client, api_url, None).await?;\n+\n+    // Get models that support tool calls\n+    let tool_models = fetch_models(client, api_url, Some(\"supported_parameters=tools\")).await?;\n+    let tool_model_ids: Vec<String> = tool_models.iter().map(|m| m.id.clone()).collect();\n+\n+    // Get models that excel at coding\n+    let coding_models = fetch_models(client, api_url, Some(\"category=programming\")).await?;\n+    let coding_model_ids: Vec<String> = coding_models.iter().map(|m| m.id.clone()).collect();\n+\n+    // Update model flags based on the specialized queries\n+    for model in &mut models {\n+        model.supports_tool_calls = tool_model_ids.contains(&model.id);\n+        model.excels_at_coding = coding_model_ids.contains(&model.id);\n+    }",
        "comment_created_at": "2025-04-27T17:36:30+00:00",
        "comment_author": "lj3954",
        "comment_body": "These should probably be sets; using a vector for equality contains is just not that efficient. You also don't have to clone each string here. You can reference the IDs from the existing structs, making a HashSet<&str>. Or, since you're not using coding_models or tool_models again, you can just take ownership by replacing iter() with into_iter().",
        "pr_file_module": null
      },
      {
        "comment_id": "2062698016",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 29496,
        "pr_file": "crates/open_router/src/open_router.rs",
        "discussion_id": "2062684723",
        "commented_code": "@@ -0,0 +1,617 @@\n+use anyhow::{Context, Result, anyhow};\n+use futures::{\n+    AsyncBufReadExt, AsyncReadExt, StreamExt,\n+    io::BufReader,\n+    stream::{self, BoxStream},\n+};\n+use http_client::{AsyncBody, HttpClient, Method, Request as HttpRequest};\n+use serde::{Deserialize, Serialize};\n+use serde_json::Value;\n+use std::{\n+    convert::TryFrom,\n+    future::{self},\n+};\n+\n+pub const OPEN_ROUTER_API_URL: &str = \"https://openrouter.ai/api/v1\";\n+\n+fn is_none_or_empty<T: AsRef<[U]>, U>(opt: &Option<T>) -> bool {\n+    opt.as_ref().map_or(true, |v| v.as_ref().is_empty())\n+}\n+\n+#[derive(Clone, Copy, Serialize, Deserialize, Debug, Eq, PartialEq)]\n+#[serde(rename_all = \"lowercase\")]\n+pub enum Role {\n+    User,\n+    Assistant,\n+    System,\n+    Tool,\n+}\n+\n+impl TryFrom<String> for Role {\n+    type Error = anyhow::Error;\n+\n+    fn try_from(value: String) -> Result<Self> {\n+        match value.as_str() {\n+            \"user\" => Ok(Self::User),\n+            \"assistant\" => Ok(Self::Assistant),\n+            \"system\" => Ok(Self::System),\n+            \"tool\" => Ok(Self::Tool),\n+            _ => Err(anyhow!(\"invalid role '{value}'\")),\n+        }\n+    }\n+}\n+\n+impl From<Role> for String {\n+    fn from(val: Role) -> Self {\n+        match val {\n+            Role::User => \"user\".to_owned(),\n+            Role::Assistant => \"assistant\".to_owned(),\n+            Role::System => \"system\".to_owned(),\n+            Role::Tool => \"tool\".to_owned(),\n+        }\n+    }\n+}\n+\n+#[cfg_attr(feature = \"schemars\", derive(schemars::JsonSchema))]\n+#[derive(Clone, Debug, Default, Serialize, Deserialize, PartialEq)]\n+pub struct Model {\n+    pub name: String,\n+    pub display_name: Option<String>,\n+    pub max_tokens: usize,\n+    pub supports_tool_calls: bool,\n+    pub excels_at_coding: bool,\n+}\n+\n+impl Model {\n+    pub fn default_fast() -> Self {\n+        Self::new(\n+            \"openrouter/auto\",\n+            Some(\"Auto Router\"),\n+            Some(2000000),\n+            true,\n+            true,\n+        )\n+    }\n+\n+    pub fn default() -> Self {\n+        Self::default_fast()\n+    }\n+\n+    pub fn new(\n+        name: &str,\n+        display_name: Option<&str>,\n+        max_tokens: Option<usize>,\n+        supports_tool_calls: bool,\n+        excels_at_coding: bool,\n+    ) -> Self {\n+        Self {\n+            name: name.to_owned(),\n+            display_name: display_name.map(|s| s.to_owned()),\n+            max_tokens: max_tokens.unwrap_or(2000000),\n+            supports_tool_calls,\n+            excels_at_coding,\n+        }\n+    }\n+\n+    pub fn id(&self) -> &str {\n+        &self.name\n+    }\n+\n+    pub fn display_name(&self) -> &str {\n+        self.display_name.as_ref().unwrap_or(&self.name)\n+    }\n+\n+    pub fn max_token_count(&self) -> usize {\n+        self.max_tokens\n+    }\n+\n+    pub fn max_output_tokens(&self) -> Option<u32> {\n+        u32::try_from(self.max_tokens).ok()\n+    }\n+\n+    pub fn supports_tool_calls(&self) -> bool {\n+        self.supports_tool_calls\n+    }\n+\n+    pub fn excels_at_coding(&self) -> bool {\n+        self.excels_at_coding\n+    }\n+\n+    /// Indicates whether the model supports parallel tool calls.\n+    /// Currently, this always returns `false` as the functionality is not implemented.\n+    /// This may serve as a placeholder for future enhancements.\n+    pub fn supports_parallel_tool_calls(&self) -> bool {\n+        false\n+    }\n+}\n+\n+#[derive(Debug, Serialize, Deserialize)]\n+pub struct Request {\n+    pub model: String,\n+    pub messages: Vec<RequestMessage>,\n+    pub stream: bool,\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub max_tokens: Option<u32>,\n+    #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n+    pub stop: Vec<String>,\n+    pub temperature: f32,\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub tool_choice: Option<ToolChoice>,\n+    /// Whether to enable parallel function calling during tool use.\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub parallel_tool_calls: Option<bool>,\n+    #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n+    pub tools: Vec<ToolDefinition>,\n+    /// HTTP referer header for OpenRouter attribution\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub http_referer: Option<String>,\n+    /// HTTP user-agent header for OpenRouter attribution\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub http_user_agent: Option<String>,\n+}\n+\n+#[derive(Debug, Serialize, Deserialize)]\n+#[serde(untagged)]\n+pub enum ToolChoice {\n+    Auto,\n+    Required,\n+    None,\n+    Other(ToolDefinition),\n+}\n+\n+#[cfg_attr(feature = \"schemars\", derive(schemars::JsonSchema))]\n+#[derive(Clone, Deserialize, Serialize, Debug)]\n+#[serde(tag = \"type\", rename_all = \"snake_case\")]\n+pub enum ToolDefinition {\n+    #[allow(dead_code)]\n+    Function { function: FunctionDefinition },\n+}\n+\n+#[cfg_attr(feature = \"schemars\", derive(schemars::JsonSchema))]\n+#[derive(Clone, Debug, Serialize, Deserialize)]\n+pub struct FunctionDefinition {\n+    pub name: String,\n+    pub description: Option<String>,\n+    pub parameters: Option<Value>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+#[serde(tag = \"role\", rename_all = \"lowercase\")]\n+pub enum RequestMessage {\n+    Assistant {\n+        content: Option<String>,\n+        #[serde(default, skip_serializing_if = \"Vec::is_empty\")]\n+        tool_calls: Vec<ToolCall>,\n+    },\n+    User {\n+        content: String,\n+    },\n+    System {\n+        content: String,\n+    },\n+    Tool {\n+        content: String,\n+        tool_call_id: String,\n+    },\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct ToolCall {\n+    pub id: String,\n+    #[serde(flatten)]\n+    pub content: ToolCallContent,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+#[serde(tag = \"type\", rename_all = \"lowercase\")]\n+pub enum ToolCallContent {\n+    Function { function: FunctionContent },\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct FunctionContent {\n+    pub name: String,\n+    pub arguments: String,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct ResponseMessageDelta {\n+    pub role: Option<Role>,\n+    pub content: Option<String>,\n+    #[serde(default, skip_serializing_if = \"is_none_or_empty\")]\n+    pub tool_calls: Option<Vec<ToolCallChunk>>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct ToolCallChunk {\n+    pub index: usize,\n+    pub id: Option<String>,\n+    pub function: Option<FunctionChunk>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug, Eq, PartialEq)]\n+pub struct FunctionChunk {\n+    pub name: Option<String>,\n+    pub arguments: Option<String>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct Usage {\n+    pub prompt_tokens: u32,\n+    pub completion_tokens: u32,\n+    pub total_tokens: u32,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct ChoiceDelta {\n+    pub index: u32,\n+    pub delta: ResponseMessageDelta,\n+    pub finish_reason: Option<String>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+#[serde(untagged)]\n+pub enum ResponseStreamResult {\n+    Ok(ResponseStreamEvent),\n+    Err { error: String },\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct ResponseStreamEvent {\n+    #[serde(default, skip_serializing_if = \"Option::is_none\")]\n+    pub id: Option<String>,\n+    pub created: u32,\n+    pub model: String,\n+    pub choices: Vec<ChoiceDelta>,\n+    pub usage: Option<Usage>,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct Response {\n+    pub id: String,\n+    pub object: String,\n+    pub created: u64,\n+    pub model: String,\n+    pub choices: Vec<Choice>,\n+    pub usage: Usage,\n+}\n+\n+#[derive(Serialize, Deserialize, Debug)]\n+pub struct Choice {\n+    pub index: u32,\n+    pub message: RequestMessage,\n+    pub finish_reason: Option<String>,\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct ListModelsResponse {\n+    pub data: Vec<ModelEntry>,\n+}\n+\n+fn is_false(v: &bool) -> bool {\n+    !*v\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct ModelEntry {\n+    pub id: String,\n+    pub name: String,\n+    pub created: i64,\n+    pub description: String,\n+    pub context_length: i64,\n+    pub architecture: Architecture,\n+    pub pricing: Pricing,\n+    pub top_provider: TopProvider,\n+    pub per_request_limits: Value,\n+    /// Indicates whether the model can handle OpenAI\u2011style tool/function calls.\n+    #[serde(default, skip_serializing_if = \"is_false\")]\n+    pub supports_tool_calls: bool,\n+    /// Indicates whether the model is generally strong at code\u2011related tasks.\n+    #[serde(default, skip_serializing_if = \"is_false\")]\n+    pub excels_at_coding: bool,\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct Architecture {\n+    pub modality: String,\n+    pub input_modalities: Vec<String>,\n+    pub output_modalities: Vec<String>,\n+    pub tokenizer: String,\n+    pub instruct_type: Option<String>,\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct Pricing {\n+    pub prompt: String,\n+    pub completion: String,\n+    pub request: Option<String>,\n+    pub image: Option<String>,\n+    pub web_search: Option<String>,\n+    pub internal_reasoning: Option<String>,\n+    pub input_cache_read: Option<String>,\n+    pub input_cache_write: Option<String>,\n+}\n+\n+#[derive(Default, Debug, Clone, PartialEq, Serialize, Deserialize)]\n+pub struct TopProvider {\n+    pub context_length: Option<i64>,\n+    pub max_completion_tokens: Option<i64>,\n+    pub is_moderated: bool,\n+}\n+\n+pub async fn complete(\n+    client: &dyn HttpClient,\n+    api_url: &str,\n+    api_key: &str,\n+    request: Request,\n+) -> Result<Response> {\n+    let uri = format!(\"{api_url}/chat/completions\");\n+    let request_builder = HttpRequest::builder()\n+        .method(Method::POST)\n+        .uri(uri)\n+        .header(\"Content-Type\", \"application/json\")\n+        .header(\"Authorization\", format!(\"Bearer {}\", api_key))\n+        .header(\"HTTP-Referer\", \"zed.dev\")\n+        .header(\"X-Title\", \"Zed Editor\");\n+\n+    let mut request_body = request;\n+    request_body.stream = false;\n+    request_body.http_referer = Some(\"zed.dev\".to_string());\n+    request_body.http_user_agent = Some(\"Zed Editor\".to_string());\n+\n+    let request = request_builder.body(AsyncBody::from(serde_json::to_string(&request_body)?))?;\n+    let mut response = client.send(request).await?;\n+\n+    if response.status().is_success() {\n+        let mut body = String::new();\n+        response.body_mut().read_to_string(&mut body).await?;\n+        let response: Response = serde_json::from_str(&body)?;\n+        Ok(response)\n+    } else {\n+        let mut body = String::new();\n+        response.body_mut().read_to_string(&mut body).await?;\n+\n+        #[derive(Deserialize)]\n+        struct OpenRouterResponse {\n+            error: OpenRouterError,\n+        }\n+\n+        #[derive(Deserialize)]\n+        struct OpenRouterError {\n+            message: String,\n+            #[serde(default)]\n+            code: String,\n+        }\n+\n+        match serde_json::from_str::<OpenRouterResponse>(&body) {\n+            Ok(response) if !response.error.message.is_empty() => {\n+                let error_message = if !response.error.code.is_empty() {\n+                    format!(\"{}: {}\", response.error.code, response.error.message)\n+                } else {\n+                    response.error.message\n+                };\n+\n+                Err(anyhow!(\n+                    \"Failed to connect to OpenRouter API: {}\",\n+                    error_message\n+                ))\n+            }\n+            _ => Err(anyhow!(\n+                \"Failed to connect to OpenRouter API: {} {}\",\n+                response.status(),\n+                body,\n+            )),\n+        }\n+    }\n+}\n+\n+fn adapt_response_to_stream(response: Response) -> ResponseStreamEvent {\n+    ResponseStreamEvent {\n+        id: Some(response.id),\n+        created: response.created as u32,\n+        model: response.model,\n+        choices: response\n+            .choices\n+            .into_iter()\n+            .map(|choice| ChoiceDelta {\n+                index: choice.index,\n+                delta: ResponseMessageDelta {\n+                    role: Some(match choice.message {\n+                        RequestMessage::Assistant { .. } => Role::Assistant,\n+                        RequestMessage::User { .. } => Role::User,\n+                        RequestMessage::System { .. } => Role::System,\n+                        RequestMessage::Tool { .. } => Role::Tool,\n+                    }),\n+                    content: match choice.message {\n+                        RequestMessage::Assistant { content, .. } => content,\n+                        RequestMessage::User { content } => Some(content),\n+                        RequestMessage::System { content } => Some(content),\n+                        RequestMessage::Tool { content, .. } => Some(content),\n+                    },\n+                    tool_calls: None,\n+                },\n+                finish_reason: choice.finish_reason,\n+            })\n+            .collect(),\n+        usage: Some(response.usage),\n+    }\n+}\n+\n+pub async fn stream_completion(\n+    client: &dyn HttpClient,\n+    api_url: &str,\n+    api_key: &str,\n+    request: Request,\n+) -> Result<BoxStream<'static, Result<ResponseStreamEvent>>> {\n+    // Some models don't support streaming\n+    let model_id = &request.model;\n+    let non_streaming_models = [\"meta-llama/\", \"google/\"];\n+    if non_streaming_models\n+        .iter()\n+        .any(|prefix| model_id.starts_with(prefix))\n+    {\n+        let response = complete(client, api_url, api_key, request).await;\n+        let response_stream_event = response.map(adapt_response_to_stream);\n+        return Ok(stream::once(future::ready(response_stream_event)).boxed());\n+    }\n+\n+    let uri = format!(\"{api_url}/chat/completions\");\n+    let request_builder = HttpRequest::builder()\n+        .method(Method::POST)\n+        .uri(uri)\n+        .header(\"Content-Type\", \"application/json\")\n+        .header(\"Authorization\", format!(\"Bearer {}\", api_key))\n+        .header(\"HTTP-Referer\", \"zed.dev\")\n+        .header(\"X-Title\", \"Zed Editor\");\n+\n+    // Add OpenRouter-specific fields\n+    let mut request = request;\n+    request.http_referer = Some(\"zed.dev\".to_string());\n+    request.http_user_agent = Some(\"Zed Editor\".to_string());\n+\n+    let request = request_builder.body(AsyncBody::from(serde_json::to_string(&request)?))?;\n+    let mut response = client.send(request).await?;\n+\n+    if response.status().is_success() {\n+        let reader = BufReader::new(response.into_body());\n+        Ok(reader\n+            .lines()\n+            .filter_map(|line| async move {\n+                match line {\n+                    Ok(line) => {\n+                        // Handle SSE comments that OpenRouter sends to prevent connection timeouts\n+                        if line.starts_with(':') {\n+                            // This is a comment line (e.g., \": OPENROUTER PROCESSING\")\n+                            // We can ignore it per SSE specs\n+                            return None;\n+                        }\n+\n+                        let line = line.strip_prefix(\"data: \")?;\n+                        if line == \"[DONE]\" {\n+                            None\n+                        } else {\n+                            // For OpenRouter, directly parse the stream event rather than expecting\n+                            // an untagged enum like OpenAI\n+                            match serde_json::from_str::<ResponseStreamEvent>(line) {\n+                                Ok(response) => Some(Ok(response)),\n+                                Err(error) => {\n+                                    // Try to parse as an error message\n+                                    #[derive(Deserialize)]\n+                                    struct ErrorResponse {\n+                                        error: String,\n+                                    }\n+\n+                                    match serde_json::from_str::<ErrorResponse>(line) {\n+                                        Ok(err_response) => Some(Err(anyhow!(err_response.error))),\n+                                        Err(_) => {\n+                                            // Check if it's an empty line or other non-JSON content\n+                                            if line.trim().is_empty() {\n+                                                None\n+                                            } else {\n+                                                Some(Err(anyhow!(\n+                                                    \"Failed to parse response: {}. Original content: '{}'\",\n+                                                    error, line\n+                                                )))\n+                                            }\n+                                        }\n+                                    }\n+                                }\n+                            }\n+                        }\n+                    }\n+                    Err(error) => Some(Err(anyhow!(error))),\n+                }\n+            })\n+            .boxed())\n+    } else {\n+        let mut body = String::new();\n+        response.body_mut().read_to_string(&mut body).await?;\n+\n+        #[derive(Deserialize)]\n+        struct OpenRouterResponse {\n+            error: OpenRouterError,\n+        }\n+\n+        #[derive(Deserialize)]\n+        struct OpenRouterError {\n+            message: String,\n+            #[serde(default)]\n+            code: String,\n+        }\n+\n+        match serde_json::from_str::<OpenRouterResponse>(&body) {\n+            Ok(response) if !response.error.message.is_empty() => {\n+                let error_message = if !response.error.code.is_empty() {\n+                    format!(\"{}: {}\", response.error.code, response.error.message)\n+                } else {\n+                    response.error.message\n+                };\n+\n+                Err(anyhow!(\n+                    \"Failed to connect to OpenRouter API: {}\",\n+                    error_message\n+                ))\n+            }\n+            _ => Err(anyhow!(\n+                \"Failed to connect to OpenRouter API: {} {}\",\n+                response.status(),\n+                body,\n+            )),\n+        }\n+    }\n+}\n+\n+pub async fn get_models(client: &dyn HttpClient, api_url: &str) -> Result<Vec<ModelEntry>> {\n+    // Get base model list\n+    let mut models = fetch_models(client, api_url, None).await?;\n+\n+    // Get models that support tool calls\n+    let tool_models = fetch_models(client, api_url, Some(\"supported_parameters=tools\")).await?;\n+    let tool_model_ids: Vec<String> = tool_models.iter().map(|m| m.id.clone()).collect();\n+\n+    // Get models that excel at coding\n+    let coding_models = fetch_models(client, api_url, Some(\"category=programming\")).await?;\n+    let coding_model_ids: Vec<String> = coding_models.iter().map(|m| m.id.clone()).collect();\n+\n+    // Update model flags based on the specialized queries\n+    for model in &mut models {\n+        model.supports_tool_calls = tool_model_ids.contains(&model.id);\n+        model.excels_at_coding = coding_model_ids.contains(&model.id);\n+    }",
        "comment_created_at": "2025-04-27T18:51:18+00:00",
        "comment_author": "imumesh18",
        "comment_body": "Fixed.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2118340568",
    "pr_number": 31818,
    "pr_file": "crates/editor/src/editor.rs",
    "created_at": "2025-05-31T22:56:54+00:00",
    "commented_code": "}\n         }\n \n+        let mut common_prefix_len = 0;\n+        for (a, b) in old_text.chars().zip(new_text.chars()) {\n+            if a == b {\n+                common_prefix_len += a.len_utf8();\n+            } else {\n+                break;\n+            }\n+        }\n+",
    "repo_full_name": "zed-industries/zed",
    "discussion_comments": [
      {
        "comment_id": "2118340568",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 31818,
        "pr_file": "crates/editor/src/editor.rs",
        "discussion_id": "2118340568",
        "commented_code": "@@ -5475,9 +5475,18 @@ impl Editor {\n             }\n         }\n \n+        let mut common_prefix_len = 0;\n+        for (a, b) in old_text.chars().zip(new_text.chars()) {\n+            if a == b {\n+                common_prefix_len += a.len_utf8();\n+            } else {\n+                break;\n+            }\n+        }\n+",
        "comment_created_at": "2025-05-31T22:56:54+00:00",
        "comment_author": "Peiffap",
        "comment_body": "This does the same thing, but cleaner (imo!)\r\nEdit: removed wrong suggestion, see below.",
        "pr_file_module": null
      },
      {
        "comment_id": "2118582616",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 31818,
        "pr_file": "crates/editor/src/editor.rs",
        "discussion_id": "2118340568",
        "commented_code": "@@ -5475,9 +5475,18 @@ impl Editor {\n             }\n         }\n \n+        let mut common_prefix_len = 0;\n+        for (a, b) in old_text.chars().zip(new_text.chars()) {\n+            if a == b {\n+                common_prefix_len += a.len_utf8();\n+            } else {\n+                break;\n+            }\n+        }\n+",
        "comment_created_at": "2025-06-01T02:25:36+00:00",
        "comment_author": "marcospb19",
        "comment_body": "code in red is exactly as it was before https://github.com/zed-industries/zed/pull/28586\r\n\r\nbut more importantly, you did .as_bytes() + count(), which is slightly different then that += with a.len_utf8()\r\n\r\nthe exact equivalent: \r\n\r\n```suggestion\r\n        let common_prefix_len = old_text\r\n            .chars()\r\n            .iter()\r\n            .zip(new_text.chars())\r\n            .take_while(|(a, b)| a == b)\r\n            .map(|(a, _)| a.len_utf8())\r\n            .sum::<usize>();\r\n```\r\n\r\nI think\r\n\r\nAnd that's not to avoid non-utf8, cause it can't happen here, but to avoid wider characters that match partially",
        "pr_file_module": null
      },
      {
        "comment_id": "2118986744",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 31818,
        "pr_file": "crates/editor/src/editor.rs",
        "discussion_id": "2118340568",
        "commented_code": "@@ -5475,9 +5475,18 @@ impl Editor {\n             }\n         }\n \n+        let mut common_prefix_len = 0;\n+        for (a, b) in old_text.chars().zip(new_text.chars()) {\n+            if a == b {\n+                common_prefix_len += a.len_utf8();\n+            } else {\n+                break;\n+            }\n+        }\n+",
        "comment_created_at": "2025-06-01T10:12:23+00:00",
        "comment_author": "Peiffap",
        "comment_body": "You're right, good catch! I've removed my suggestion to avoid mistakes. I still like your suggestion more than the explicit loop, fwiw!",
        "pr_file_module": null
      },
      {
        "comment_id": "2119358407",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 31818,
        "pr_file": "crates/editor/src/editor.rs",
        "discussion_id": "2118340568",
        "commented_code": "@@ -5475,9 +5475,18 @@ impl Editor {\n             }\n         }\n \n+        let mut common_prefix_len = 0;\n+        for (a, b) in old_text.chars().zip(new_text.chars()) {\n+            if a == b {\n+                common_prefix_len += a.len_utf8();\n+            } else {\n+                break;\n+            }\n+        }\n+",
        "comment_created_at": "2025-06-01T17:22:08+00:00",
        "comment_author": "zeux",
        "comment_body": "Yeah for posterity, the loop in this PR is simply taken from the original code in this file.",
        "pr_file_module": null
      }
    ]
  },
  {
    "discussion_id": "2023113547",
    "pr_number": 25650,
    "pr_file": "crates/tasks_ui/src/tasks_ui.rs",
    "created_at": "2025-04-01T15:36:54+00:00",
    "commented_code": "let did_spawn = workspace\n             .update(cx, |workspace, cx| {\n-                let (task_source_kind, mut target_task) =\n-                    tasks.into_iter().find(|(_, task)| task.label == name)?;\n-                if let Some(overrides) = &overrides {\n-                    if let Some(target_override) = overrides.reveal_target {\n-                        target_task.reveal_target = target_override;\n-                    }\n-                }\n                 let default_context = TaskContext::default();\n                 let active_context = task_contexts.active_context().unwrap_or(&default_context);\n-                schedule_task(\n-                    workspace,\n-                    task_source_kind,\n-                    &target_task,\n-                    active_context,\n-                    false,\n-                    cx,\n-                );\n-                Some(())\n+\n+                tasks.retain_mut(|(task_source_kind, target_task)| {\n+                    if predicate(&(task_source_kind.clone(), target_task.clone())) {",
    "repo_full_name": "zed-industries/zed",
    "discussion_comments": [
      {
        "comment_id": "2023113547",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 25650,
        "pr_file": "crates/tasks_ui/src/tasks_ui.rs",
        "discussion_id": "2023113547",
        "commented_code": "@@ -207,24 +230,31 @@ fn spawn_task_with_name(\n \n         let did_spawn = workspace\n             .update(cx, |workspace, cx| {\n-                let (task_source_kind, mut target_task) =\n-                    tasks.into_iter().find(|(_, task)| task.label == name)?;\n-                if let Some(overrides) = &overrides {\n-                    if let Some(target_override) = overrides.reveal_target {\n-                        target_task.reveal_target = target_override;\n-                    }\n-                }\n                 let default_context = TaskContext::default();\n                 let active_context = task_contexts.active_context().unwrap_or(&default_context);\n-                schedule_task(\n-                    workspace,\n-                    task_source_kind,\n-                    &target_task,\n-                    active_context,\n-                    false,\n-                    cx,\n-                );\n-                Some(())\n+\n+                tasks.retain_mut(|(task_source_kind, target_task)| {\n+                    if predicate(&(task_source_kind.clone(), target_task.clone())) {",
        "comment_created_at": "2025-04-01T15:36:54+00:00",
        "comment_author": "SomeoneToIgnore",
        "comment_body": "Can we change the predicate, so we don't have to clone?\r\nSeems that `F: FnMut((&TaskSourceKind, &TaskTemplate)) -> bool + 'static,` is good enough?",
        "pr_file_module": null
      },
      {
        "comment_id": "2023464386",
        "repo_full_name": "zed-industries/zed",
        "pr_number": 25650,
        "pr_file": "crates/tasks_ui/src/tasks_ui.rs",
        "discussion_id": "2023113547",
        "commented_code": "@@ -207,24 +230,31 @@ fn spawn_task_with_name(\n \n         let did_spawn = workspace\n             .update(cx, |workspace, cx| {\n-                let (task_source_kind, mut target_task) =\n-                    tasks.into_iter().find(|(_, task)| task.label == name)?;\n-                if let Some(overrides) = &overrides {\n-                    if let Some(target_override) = overrides.reveal_target {\n-                        target_task.reveal_target = target_override;\n-                    }\n-                }\n                 let default_context = TaskContext::default();\n                 let active_context = task_contexts.active_context().unwrap_or(&default_context);\n-                schedule_task(\n-                    workspace,\n-                    task_source_kind,\n-                    &target_task,\n-                    active_context,\n-                    false,\n-                    cx,\n-                );\n-                Some(())\n+\n+                tasks.retain_mut(|(task_source_kind, target_task)| {\n+                    if predicate(&(task_source_kind.clone(), target_task.clone())) {",
        "comment_created_at": "2025-04-01T18:18:58+00:00",
        "comment_author": "aevsai",
        "comment_body": "skill issues \ud83d\ude05, fixed this, thanks",
        "pr_file_module": null
      }
    ]
  }
]