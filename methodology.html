---
layout: default
title: About
description: Learn how Awesome Reviewers distills real-world code review wisdom into reusable AI reviewer prompts.
---

<section class="page-container about-hero">
  <div class="container">
    <p class="eyebrow">About Awesome Reviewers</p>
    <h1>Turning expert review habits into reusable playbooks</h1>
    <p class="lead">
      Awesome Reviewers is Baz's open library of AI reviewers built from thousands of production-grade pull request
      discussions. We codify how experienced maintainers protect quality so any team can adopt the same standards in
      minutes.
    </p>
    <div class="about-hero__grid">
      <div class="about-hero__card">
        <h3>Practitioner-sourced</h3>
        <p>Every reviewer starts from real code review threads supplied by trusted maintainers across dozens of ecosystems.</p>
      </div>
      <div class="about-hero__card">
        <h3>High-signal prompts</h3>
        <p>We capture the heuristics, tone, and guardrails that help reviewers surface the right issues without generating noise.</p>
      </div>
      <div class="about-hero__card">
        <h3>Ready for production</h3>
        <p>Each reviewer is validated on fresh pull requests before it lands in the library, so the guidance feels human and actionable.</p>
      </div>
    </div>
  </div>
</section>

<section class="about-section">
  <div class="container">
    <h2>How we evolve the reviewer library</h2>
    <p class="about-section__intro">
      The library grows through a continuous research loop that keeps reviewers aligned with how real teams ship software. Every
      iteration reinforces accuracy, empathy, and language that lands with developers under deadline.
    </p>
    <div class="about-pillars">
      <article class="about-pillars__item">
        <h3>1. Capture real conversations</h3>
        <p>
          We partner with maintainers who share anonymized review threads that explain why changes shipped—or were held back.
          Each example includes the diff, the critique, and the eventual resolution so we understand cause and effect.
        </p>
      </article>
      <article class="about-pillars__item">
        <h3>2. Distill the reviewer mindset</h3>
        <p>
          Baz researchers label the moves inside a comment, mapping patterns like performance budgeting or interface safety to
          the signals that triggered them. The result is a shared vocabulary for what “good” review feedback looks like.
        </p>
      </article>
      <article class="about-pillars__item">
        <h3>3. Ship with feedback loops</h3>
        <p>
          Before a reviewer goes live, we replay it on new pull requests and collect maintainer feedback until the tone and
          recommendations match what they would deliver themselves.
        </p>
      </article>
    </div>
  </div>
</section>

<section class="about-section about-section--diagram">
  <div class="container">
    <div class="about-section__header">
      <h2>From maintainer insight to developer assistant</h2>
      <p>Our curation pipeline keeps human judgment in the loop while automating the repetitive parts of code review.</p>
    </div>
    <div class="diagram-wrapper">
      <div class="mermaid">
sequenceDiagram
    participant Maintainer
    participant BazOps as Baz Research
    participant Library
    participant Developer
    Maintainer->>BazOps: Share review threads & intent
    BazOps->>BazOps: Normalize heuristics & tone
    BazOps->>Library: Publish reviewer prompt
    Developer->>Library: Request reviewer guidance
    Library-->>Developer: Surface targeted findings
    Developer->>Maintainer: Ship aligned fixes
      </div>
    </div>
  </div>
</section>

<section class="about-section about-section--code">
  <div class="container">
    <div class="about-section__header">
      <h2>What a reviewer prompt looks like</h2>
      <p>The structure balances mission, heuristics, and delivery style so AI feedback mirrors the maintainers who inspired it.</p>
    </div>
    <div class="code-sample">
      <pre><code class="language-yaml">reviewer:
  name: Strict Type Guardian
  mission: Protect runtime safety by enforcing explicit type guarantees in critical paths.
  heuristics:
    - Flag optional return values that reach API boundaries without null handling.
    - Require conversion utilities to emit descriptive errors when type assertions fail.
    - Highlight concurrency code where shared state lacks typed synchronization primitives.
  response_style:
    voice: Calm, collaborative
    include_context: true
workflows:
  - trigger: pull_request.opened
    actions:
      - analyze_diff: true
      - highlight_findings: inline
      - summarize_risks: narrative</code></pre>
    </div>
    <p class="about-section__note">
      Reviewers combine precise heuristics with expectations about tone and collaboration so engineering teams can plug them
      into CI without rewriting their culture.
    </p>
  </div>
</section>

<section class="about-section about-section--cta">
  <div class="container">
    <h2>Help shape the next generation of reviewers</h2>
    <p>
      Maintainers and teams can submit repositories for analysis or contribute their own review standards. We are especially
      interested in mobile, data engineering, and infrastructure playbooks that deserve wider adoption.
    </p>
    <a class="btn btn-primary" href="https://awesome.baz.co/request" target="_blank" rel="noopener noreferrer">Submit a repository</a>
  </div>
</section>

<script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js" defer></script>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    if (window.mermaid) {
      const prefersDark = document.documentElement.getAttribute('data-theme') === 'dark';
      mermaid.initialize({ startOnLoad: true, theme: prefersDark ? 'dark' : 'neutral' });
    }
  });
</script>
